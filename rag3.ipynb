{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerie necessarie\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough, RunnableParallel, RunnableLambda\n",
    "from IPython.display import JSON\n",
    "import json\n",
    "from unstructured_client import UnstructuredClient\n",
    "from unstructured_client.models import shared\n",
    "from unstructured_client.models.errors import SDKError\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import dict_to_elements, elements_to_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carica le variabili di ambiente dal file .env\n",
    "load_dotenv()\n",
    "\n",
    "# Ora puoi accedere alle variabili di ambiente\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm studio\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url = \"http://172.17.0.1:1234/v1\",\n",
    "    temperature = 0,\n",
    "    api_key = \"not-needed\",\n",
    "    model_name =\"llama3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollama\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url = \"http://localhost:11434/v1\",\n",
    "    temperature = 0,\n",
    "    api_key = \"not-need\",\n",
    "    model_name =\"llama3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    emperature = 0,\n",
    "     model_name =\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm of Thoughts: Enhancing Exploration of Ideas\n",
      "in Large Language Models\n",
      "Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Ruoxi Jia, and Ming Jin\n",
      "Virginia Tech\n",
      "Abstract\n",
      "Current literature, aiming to surpass the “Chain-of-Thought”\n",
      "approach, often resorts to an external modus operandi in-\n",
      "volving halting, modifying, and then resuming the genera-\n",
      "tion process to boost Large Language Models’ (LLMs) rea-\n",
      "soning capacities. This mode escalates the number of query\n",
      "requests, leading to increased costs, memory, and computa-\n",
      "tional overheads. Addressing this, we propose the Algorithm\n",
      "of Thoughts —a novel strategy that propels LLMs through\n",
      "algorithmic reasoning pathways, pioneering a new mode of\n",
      "in-context learning. By employing algorithmic examples, we\n",
      "exploit the innate recurrence dynamics of LLMs, expand-\n",
      "ing their idea exploration with merely one or a few queries.\n",
      "Our technique outperforms earlier single-query methods and\n",
      "stands on par with a recent multi-query strategy that employs\n",
      "an extensive tree search algorithm. Intriguingly, our results\n",
      "suggest that instructing an LLM using an algorithm can lead\n",
      "to performance surpassing that of the algorithm itself, hinting\n",
      "at LLM’s inherent ability to weave its intuition into optimized\n",
      "searches. We probe into the underpinnings of our method’s\n",
      "efficacy and its nuances in application.\n",
      "Introduction\n",
      "Recent developments in large language models (Chowdhery\n",
      "et al. 2022; Thoppilan et al. 2022; Liu et al. 2023, inter alia )\n",
      "have spotlighted their efficacy in general problem solving\n",
      "(Huang and Chang 2022; Suzgun et al. 2022), code gen-\n",
      "eration (Chen et al. 2021; Austin et al. 2021), and instruc-\n",
      "tion following (Ouyang et al. 2022; Bai et al. 2022). While\n",
      "early models relied on direct answer strategies (Brown et al.\n",
      "2020), contemporary research veers towards linear reason-\n",
      "ing paths (Wei et al. 2022b; Kojima et al. 2022; Zhang et al.\n",
      "2022) by breaking problems into sub-tasks for solution dis-\n",
      "covery, or harnesses external mechanisms to alter token gen-\n",
      "eration by changing the context (Zhou et al. 2022; Drozdov\n",
      "et al. 2022; Yao et al. 2023).\n",
      "Analogous to human cognition (Sloman 1996; Kahneman\n",
      "2011), early LLM strategies seemed to emulate the instan-\n",
      "taneous System 1 , characterized by its impulsive decision-\n",
      "making. In contrast, more recent methodologies like chain-\n",
      "of-thought (CoT) (Wei et al. 2022b) and least-to-most\n",
      "prompting (L2M) (Zhou et al. 2022; Drozdov et al. 2022)\n",
      "Preprint. Under review.reflect the introspective nature of System 2 . Notably, inte-\n",
      "grating intermediary reasoning steps has yielded improve-\n",
      "ments in arithmetic reasoning tasks (Srivastava et al. 2022;\n",
      "Liang et al. 2022).\n",
      "However, as tasks shift towards deeper planning and ex-\n",
      "tensive thought exploration, these methods appear restric-\n",
      "tive. Although CoT integrated with Self-Consistency (CoT-\n",
      "SC) (Wang et al. 2022) enlists multiple LLM outputs for\n",
      "a consensus, the lack of meticulous evaluation can result\n",
      "in model misdirection. The “Tree of Thoughts” (Yao et al.\n",
      "2023; Long 2023) emerges as a notable solution. While one\n",
      "LLM is dedicated to idea generation, another steps in to as-\n",
      "sess the merit of these ideas, following a halting-assessment-\n",
      "resuming cycle. This iterative process, anchored by tree\n",
      "search, has shown marked effectiveness, especially in tasks\n",
      "with a breadth of continuations. We see this progression\n",
      "as akin to humans employing tools to circumvent working\n",
      "memory limitations, serving as an external augmentation for\n",
      "LLMs (Mialon et al. 2023).\n",
      "On the flip side, this enhanced LLM approach is not\n",
      "without pitfalls. A prominent downside is the substantial\n",
      "surge in the number of queries and computational demands.\n",
      "Each query to online LLM APIs such as GPT-4—a focal\n",
      "point of our study—incurs a monetary expense (Chen, Za-\n",
      "haria, and Zou 2023) but also contributes to latency, a sig-\n",
      "nificant limitation especially critical in real-time applica-\n",
      "tions. Cumulative delays from these queries can compro-\n",
      "mise solution efficiency. Infrastructure-wise, continuous in-\n",
      "teractions can stress systems, leading to potential bandwidth\n",
      "constraints and reduced model availability (Aminabadi et al.\n",
      "2022). Moreover, the environmental implications cannot be\n",
      "ignored; incessant querying escalates the energy consump-\n",
      "tion of already power-hungry data centers, exacerbating the\n",
      "carbon footprint (Wu et al. 2022; Dhar 2020).\n",
      "With this in mind, our goal is to dramatically reduce the\n",
      "query counts employed by contemporary multi-query rea-\n",
      "soning methods while maintaining performance for tasks ne-\n",
      "cessitating adept use of world knowledge , thereby steering a\n",
      "more responsible and proficient use of AI resources.\n",
      "Reflecting on the evolution of LLMs from System 1 to\n",
      "System 2, an essential ingredient comes to light: algorithms.\n",
      "Characterized by its methodical nature, the algorithmic per-\n",
      "spective offers a path to keenly explore problem spaces, en-\n",
      "act strategies, and formulate solutions (Helie and Pizlo 2022;arXiv:2308.10379v2  [cs.CL]  28 Sep 2023\n",
      "Chain-of-Thought\n",
      "Model \n",
      "Input\n",
      "Model \n",
      "Output\n",
      "User: \n",
      "8 \n",
      "6 \n",
      "4 \n",
      "4\n",
      "Assistant: \n",
      "8 \n",
      "- \n",
      "6 \n",
      "= \n",
      "2 \n",
      "(left: \n",
      "4, \n",
      "4, \n",
      "2)\n",
      "4 \n",
      "+ \n",
      "2 \n",
      "= \n",
      "6 \n",
      "(left: \n",
      "6, \n",
      "4)\n",
      "6 \n",
      "* \n",
      "4 \n",
      "= \n",
      "24\n",
      "Answer: \n",
      "(4 \n",
      "+ \n",
      "(8 \n",
      "- \n",
      "6)) \n",
      "* \n",
      "4 \n",
      "= \n",
      "24.\n",
      " \n",
      "User: \n",
      "11 \n",
      "10 \n",
      "5 \n",
      "1\n",
      "Assistant:\n",
      "11 \n",
      "- \n",
      "10 \n",
      "= \n",
      "1 \n",
      "(left: \n",
      "1, \n",
      "1, \n",
      "5)\n",
      "1 \n",
      "* \n",
      "1 \n",
      "= \n",
      "1 \n",
      "(left: \n",
      "1, \n",
      "5)\n",
      "5 \n",
      "* \n",
      "1 \n",
      "= \n",
      "5 \n",
      "(left: \n",
      "5)\n",
      "Answer: \n",
      "((11 \n",
      "- \n",
      "10) \n",
      "* \n",
      "1) \n",
      "* \n",
      "5 \n",
      "- \n",
      "1 \n",
      "= \n",
      "24.\n",
      "Algorithm \n",
      "of \n",
      "Thoughts\n",
      "Model \n",
      "Input\n",
      "Model \n",
      "Output\n",
      "User: \n",
      "8 \n",
      "6 \n",
      "4 \n",
      "4\n",
      "Assistant:\n",
      "1. \n",
      "4 \n",
      "- \n",
      "4: \n",
      "(left: \n",
      "8, \n",
      "6, \n",
      "0)\n",
      ".\n",
      ".\n",
      ".\n",
      "3. \n",
      "8 \n",
      "- \n",
      "6: \n",
      "(left: \n",
      "4, \n",
      "4, \n",
      "2)\n",
      "- \n",
      "4 \n",
      "+ \n",
      "4: \n",
      "(left: \n",
      "8, \n",
      "2) \n",
      "10, \n",
      "6, \n",
      "16, \n",
      "4\n",
      "- \n",
      "4 \n",
      "- \n",
      "4: \n",
      "(left: \n",
      "2, \n",
      "0) \n",
      "2, \n",
      "2, \n",
      "0, \n",
      "undefined\n",
      "- \n",
      "4 \n",
      "* \n",
      "4: \n",
      "(left: \n",
      "16, \n",
      "2) \n",
      "18, \n",
      "14, \n",
      "32, \n",
      "8\n",
      "- \n",
      "4 \n",
      "/ \n",
      "4: \n",
      "(left: \n",
      "2, \n",
      "1) \n",
      "3, \n",
      "1, \n",
      "2, \n",
      "2\n",
      "- \n",
      "4 \n",
      "+ \n",
      "2: \n",
      "(left: \n",
      "6, \n",
      "4) \n",
      "10, \n",
      "2, \n",
      "24 \n",
      "= \n",
      "6 \n",
      "* \n",
      "4 \n",
      "-> \n",
      "found \n",
      "it!\n",
      "Answer: \n",
      "(4 \n",
      "+ \n",
      "(8 \n",
      "- \n",
      "6)) \n",
      "* \n",
      "4 \n",
      "= \n",
      "24.\n",
      " \n",
      "User: \n",
      "11 \n",
      "10 \n",
      "5 \n",
      "1\n",
      "Assistant:\n",
      "1. \n",
      "11 \n",
      "- \n",
      "1: \n",
      "(left: \n",
      "10, \n",
      "10, \n",
      "5)\n",
      ".\n",
      ".\n",
      ".\n",
      "5. \n",
      "11 \n",
      "+ \n",
      "1: \n",
      "(left: \n",
      "12, \n",
      "10, \n",
      "5)\n",
      "- \n",
      "12 \n",
      "+ \n",
      "10: \n",
      "(left: \n",
      "22, \n",
      "5) \n",
      "27, \n",
      "17, \n",
      "110, \n",
      "4.4\n",
      "- \n",
      "12 \n",
      "- \n",
      "10: \n",
      "(left: \n",
      "5, \n",
      "2) \n",
      "7, \n",
      "3, \n",
      "10, \n",
      "2.5\n",
      "- \n",
      "12 \n",
      "* \n",
      "10: \n",
      "(left: \n",
      "120, \n",
      "5) \n",
      "24 \n",
      "= \n",
      "120 \n",
      "/ \n",
      "5 \n",
      "-> \n",
      "found \n",
      "it!\n",
      "Answer: \n",
      "((11 \n",
      "+ \n",
      "1) \n",
      "* \n",
      "10) \n",
      "/ \n",
      "5 \n",
      "= \n",
      "24.\n",
      "Standard \n",
      "Prompting\n",
      "Model \n",
      "Input\n",
      "Model \n",
      "Output\n",
      "User: \n",
      "8 \n",
      "6 \n",
      "4 \n",
      "4\n",
      "Assistant: \n",
      "Answer: \n",
      "(4 \n",
      "+ \n",
      "(8 \n",
      "- \n",
      "6)) \n",
      "* \n",
      "4 \n",
      "= \n",
      "24.\n",
      " \n",
      "User: \n",
      "11 \n",
      "10 \n",
      "5 \n",
      "1\n",
      "Assistant:\n",
      "Answer: \n",
      "(11 \n",
      "- \n",
      "1) \n",
      "* \n",
      "(10 \n",
      "- \n",
      "5) \n",
      "= \n",
      "24Figure 1: Comparison between standard prompting, CoT, and AoT in the game of 24. While standard prompting aims for a direct\n",
      "answer, CoT sketches out the successive steps to the final solution. AoT’s in-context example, distinct from CoT, integrates the\n",
      "search process, highlighted by markers ‘1’,..., ‘3’ as “first operations” guiding subtree exploration for the problem set ‘8 6\n",
      "4 4’. For clarity, only a single in-context example is displayed, with a focus on the third subtree exploration. AoT produces\n",
      "prospective search steps (e.g., the subtree exploration ‘5. 11 + 1 ’) and evaluates potential subsequent steps to either progress\n",
      "towards a solution or retrace to another viable subtree.\n",
      "Banerjee et al. 2022). While much of the prevailing literature\n",
      "treats algorithms as external to LLMs, given LLMs’ inher-\n",
      "ent generative recurrence, can we channel this iterative logic\n",
      "tointernalize an algorithm?\n",
      "Drawing upon both the intricate nuances of human rea-\n",
      "soning and the disciplined precision of algorithmic method-\n",
      "ologies, our work aims to fuse these dual facets to aug-\n",
      "ment reasoning capabilities within LLMs. Existing research\n",
      "underscores that humans, when navigating complex prob-\n",
      "lems, instinctively draw upon past efforts, ensuring a com-\n",
      "prehensive contemplation rather than a narrow focus (Mon-\n",
      "sell 2003; Holyoak and Morrison 2005; Baddeley 2003).\n",
      "LLMs, with their generative span bounded only by token\n",
      "limits, appear poised to break through the barriers of human\n",
      "working memory. Spurred by this observation, we investi-\n",
      "gated if LLMs could mirror a similar layered exploration\n",
      "of ideas, referencing prior intermediate steps to sieve out\n",
      "infeasible options, all within their iterative generation cy-\n",
      "cle. And while humans excel with their intuitive acumen, al-\n",
      "gorithms stand out with organized, systematic exploration.\n",
      "Current techniques, like CoT, often sidestep this synergistic\n",
      "potential, imposing undue pressure on LLMs for on-the-spot\n",
      "precision. By capitalizing on LLMs’ recursive capabilities,\n",
      "we emulate a hybrid human-algorithmic approach. This is\n",
      "achieved through our use of algorithmic examples that cap-\n",
      "ture the essence of exploration, from initial candidates to\n",
      "validated solutions. Thus emerges our concept of the Algo-\n",
      "rithm of Thoughts (AoT), as illustrated in Figs. 1 and 2.More broadly, our approach signifies a new paradigm of\n",
      "in-context learning. Instead of the traditional “supervised-\n",
      "learning” mold of [ PROBLEM ,SOLUTION ] or [ PROBLEM ,\n",
      "SUCCESSIVE STEPS TO SOLUTION ], we present a new\n",
      "structure that covers [ PROBLEM ,SEARCH PROCESS ,SO-\n",
      "LUTION ]. Naturally, when instructing an LLM using an al-\n",
      "gorithm, the anticipation leans towards the LLM simply\n",
      "imitating the algorithm’s iterative thinking. However, what\n",
      "emerges as intriguing is the LLM’s ability to infuse its own\n",
      "“intuition” to achieve a search efficiency that even surpasses\n",
      "the algorithm itself (see Fig. 5).\n",
      "In the subsequent sections, we first situate our work\n",
      "within the existing literature, followed by a discussion of\n",
      "our principal idea. We then present our experimental results\n",
      "and probe a series of hypotheses related to this emerging ca-\n",
      "pability of LLM before rounding off with a conclusion.\n",
      "Related Work\n",
      "Standard Prompting. Also known as input-output\n",
      "prompting, it provides a few input-output examples of the\n",
      "task before getting an answer for the test sample from the\n",
      "language model (Brown et al. 2020). Although this method\n",
      "is very general and does not need any special prompting\n",
      "strategy, the performance is also worse compared to more\n",
      "advanced methods (Shao et al. 2023; Wei et al. 2022a; Lyu\n",
      "et al. 2023).\n",
      "Input\n",
      "Output\n",
      "Input\n",
      "Output\n",
      "Input\n",
      "Output\n",
      "Input\n",
      "Output\n",
      "Standard \n",
      "Prompting\n",
      "Chain \n",
      "of \n",
      "Thoughts\n",
      "Tree \n",
      "of \n",
      "Thoughts\n",
      "Algorithm \n",
      "of \n",
      "ThoughtsFigure 2: Illustration outlining various strategies for tackling reasoning problems with LLMs. Each box signifies a distinct\n",
      "thought, functioning as a unified string of words that forms an incremental pathway to reasoning. Green boxes indicate ideas\n",
      "deemed promising by the LLM, while red boxes represent less promising concepts.\n",
      "Chain-of-Thought. In CoT, LLMs are presented with ex-\n",
      "amples where a given question xunfolds through a chain\n",
      "of intermediate reasoning pieces c1, . . . , c nto reach an an-\n",
      "swery, represented as x→c1→. . .→cn→y(Wei\n",
      "et al. 2022b; Lyu et al. 2023). By mimicking the examples\n",
      "in the context, the LLM automatically divides the solution\n",
      "into simpler linear steps to arrive at the answer, improv-\n",
      "ing performance across numerous reasoning benchmarks.\n",
      "Self-consistency (Wang et al. 2022) is a widely used de-\n",
      "coding strategy aimed at generating a variety of reason-\n",
      "ing paths by choosing the final answer through a majority\n",
      "vote, though this necessitates additional generations. Con-\n",
      "trary to CoT’s linear, direct progression, our approach pivots\n",
      "towards the explorative aspect of LLMs. We reconceptual-\n",
      "ize the c1, . . . , c nsequence, not merely as successive steps\n",
      "towards a solution, but as a dynamic, potentially mutable\n",
      "path that resembles an algorithmic search, allowing for ex-\n",
      "ploration, recalibration, and non-linear progression.\n",
      "Least-to-Most prompting (L2M). Taking cues from ed-\n",
      "ucational psychology (Libby et al. 2008), L2M prompting\n",
      "directs the LLM to decompose the central problem into\n",
      "smaller subproblems. Each subproblem is tackled in se-\n",
      "quence, with the outcome appended before progressing to\n",
      "the next (Zhou et al. 2022; Drozdov et al. 2022). While this\n",
      "structured delineation is beneficial for broader generaliza-\n",
      "tion, it operates on the premise of finding a nearly perfect de-\n",
      "composition in a single attempt—ideal for problems with a\n",
      "clear-cut structure. Yet, when tasks intertwine with their de-\n",
      "composition complexities (like games of 24), this method’s\n",
      "inflexibility becomes apparent. Contrastingly, AoT not only\n",
      "underscores the active subproblem (as shown in Fig. 1), but\n",
      "also permits a more contemplative approach by entertaining\n",
      "various options for each subproblem, while maintaining ef-\n",
      "ficacy even with minimal prompts.\n",
      "Tree of Thoughts (ToT). In the cases where each sub-\n",
      "problem has multiple viable options to explore, linear rea-\n",
      "soning paths from CoT or L2M substantially limit the cov-\n",
      "erage of the thought space. Considering possible options for\n",
      "each subproblem, the decision tree can be explored by ex-\n",
      "ternal tree-search mechanisms (e.g., BFS, DFS) (Yao et al.2023). Evaluation capabilities of LLMs can also be used to\n",
      "direct the search by pruning nodes that are hopeless to in-\n",
      "crease efficiency. However, ToT’s Achilles’ heel is its ex-\n",
      "cessive reliance on LLM queries, at times necessitating hun-\n",
      "dreds for just one problem. We tackle this limitation by gen-\n",
      "erating the whole thought process within a single context.\n",
      "Algorithm of Thoughts\n",
      "Our strategy pivots on recognizing a core shortcoming of\n",
      "current in-context learning paradigms. CoT, while enhanc-\n",
      "ing the coherency of thought linkages leading to solutions,\n",
      "occasionally falters, presenting incorrect intermediate steps\n",
      "(Zelikman et al. 2022; Turpin et al. 2023; Lanham et al.\n",
      "2023). Faithful CoT (Lyu et al. 2023) ought to amend this\n",
      "by eliciting symbolic chains of reasoning where the LLM’s\n",
      "output resembles task-specific pseudo-code, primed for de-\n",
      "terministic execution like Python. The intention is only to\n",
      "use the thought processes but not the outputs and inputs of\n",
      "each link since they have a tendency to be unreliable. But,\n",
      "the occasional missteps of CoT may not necessarily due to\n",
      "the LLM’s inability to compute correctly . The LLM, when\n",
      "confronted with questions that closely match conditions of\n",
      "previous in-context examples, may favor echoing those out-\n",
      "puts over generating the appropriate questions. To shed light\n",
      "on this phenomenon, we designed an experiment. Querying\n",
      "text-davinci-003 for arithmetic tasks (e.g., ‘ 11−2 =’), we\n",
      "prefixed them with multiple in-context equations converging\n",
      "to an identical output (e.g. ‘ 15−5 = 10 ,8 + 2 = 10 ’). Our\n",
      "results, presented in Fig. 3, reveal a steep decline in accu-\n",
      "racy, suggesting that the mere presence of correct reasoning\n",
      "in the context might inadvertently compromise even basic\n",
      "arithmetic skills.\n",
      "To offset this bias, diversifying the outputs of examples\n",
      "might seem like a viable solution, but this could subtly skew\n",
      "the distribution of outputs. Merely adding unsuccessful tri-\n",
      "als, much like a random search, might inadvertently encour-\n",
      "age the model to retry rather than truly solve. Capturing\n",
      "the true essence of algorithmic behavior, where both failed\n",
      "searches and subsequent recovering and learning from such\n",
      "attempts play a role, we incorporate in-context examples pat-\n",
      "0 2 4 6 8 10 12\n",
      "# of Equations0.00.20.40.60.81.0Probability of Correct T okenFigure 3: The probability of generating the correct token as\n",
      "we add more in-context examples that are correct but possess\n",
      "identical outputs.\n",
      "terned after search algorithms , notably depth-first search\n",
      "(DFS) and breadth-first search (BFS). See Fig. 1 for an ex-\n",
      "ample.\n",
      "This paper focuses on a broad class of tasks reminiscent of\n",
      "tree-search problems. These tasks necessitate breaking down\n",
      "the main problem, crafting feasible solutions for each seg-\n",
      "ment, and making decisions on the paths to either pursue\n",
      "or forsake, with the option of reevaluating more promising\n",
      "segmentations. Rather than posing separate queries for ev-\n",
      "ery subset, we leverage the iterative capabilities of the LLM\n",
      "to address them in one unified generation sweep. By confin-\n",
      "ing ourselves to one or two LLM interactions, this approach\n",
      "naturally incorporates insights from antecedent context can-\n",
      "didates and tackles intricate issues requiring an in-depth ex-\n",
      "ploration of the solution domain. In alignment with our goal,\n",
      "we also give insights into how small or big those thoughts\n",
      "should be and what type of in-context examples should be\n",
      "given to the LLM to promote token efficiency. Subsequently,\n",
      "we outline key components of tree-search algorithms and\n",
      "their manifestation in our framework.\n",
      "1. Decomposition into Subproblems. Given a problem,\n",
      "constructing a search tree that delineates feasible reasoning\n",
      "pathways is already a demanding task, excluding the actual\n",
      "problem-solving aspect. Any decomposition must consider\n",
      "not just the interrelations between subtasks, but also the ease\n",
      "of addressing each individually. Consider a simple multi-\n",
      "digit addition: while converting numbers to binary might\n",
      "be efficient for a computer, humans typically find base 10\n",
      "arithmetic more intuitive. Furthermore, even if the subprob-\n",
      "lems remain constant, their execution might vary. Intuition\n",
      "can lead to shortcuts between solution steps, while its ab-\n",
      "sence might necessitate more detailed steps. Crafting the\n",
      "right prompt (i.e., in-context algorithmic examples) hinges\n",
      "on these nuances, determining the minimal tokens an LLM\n",
      "would need for dependable performance. This is not only\n",
      "essential to fit within the LLM’s context constraints but also\n",
      "vital for efficacy, as we’d expect LLMs to address problems\n",
      "resonant with its context using a similar token volume.\n",
      "2. Proposing Solutions to Subproblems. A dominant ap-\n",
      "proach in existing works involves direct sampling from\n",
      "LLM token output probabilities (Wang et al. 2022; Yao\n",
      "The \n",
      "first \n",
      "five \n",
      "prime \n",
      "numbers:\n",
      "Text \n",
      "Completion\n",
      "2 \n",
      "= \n",
      "87.6%\n",
      "1 \n",
      "= \n",
      "12.3%\n",
      "...\n",
      "...\n",
      "2, \n",
      "3, \n",
      "5, \n",
      "7, \n",
      "11\n",
      "probabilities \n",
      "for \n",
      "the \n",
      "first \n",
      "tokenFigure 4: An example highlighting the drawback of isolated\n",
      "sampling of sequenced ideas. Input is denoted in blue, with\n",
      "thetext-davinci-003 providing the green completions.\n",
      "et al. 2023). Though effective for one-off answers (Kadavath\n",
      "et al. 2022) (with certain constraints (Robinson and Wingate\n",
      "2022)), this method falls short in scenarios demanding a se-\n",
      "quence of samples to be integrated or evaluated within sub-\n",
      "sequent prompts (Robinson and Wingate 2022). To mini-\n",
      "mize model queries, we adopt an uninterrupted solution cre-\n",
      "ation process. Here, we directly and continuously generate\n",
      "solutions for the prevailing subproblem without any genera-\n",
      "tion pauses.\n",
      "The benefits are three-fold. First, with all generated solu-\n",
      "tions existing within a shared context, there’s no need for in-\n",
      "dividual model queries for each solution evaluation. Second,\n",
      "while it may seem counterintuitive initially, isolated token or\n",
      "token group probabilities might not always yield meaning-\n",
      "ful choices. A simple illustration is found in Fig. 4. When\n",
      "evaluated independently, the second-most probable token for\n",
      "our inaugural number is ‘ 1’—not qualifying as prime. But,\n",
      "when generation remains unbroken, the derived sequence is\n",
      "correct. This incongruence points towards the restrictive na-\n",
      "ture of the Markov property in sequence modeling. Core to\n",
      "our perspective is the premise that for sequential tasks like\n",
      "algorithmic search, LLMs are more adept at generating en-\n",
      "tire sequences than intermittently pausing and re-initiating\n",
      "the token sampling process.\n",
      "3. Gauging the Promise of a Subproblem. As above,\n",
      "existing techniques lean on additional prompting to dis-\n",
      "cern the potential of tree nodes, aiding decisions regard-\n",
      "ing exploration direction. Our observations suggest that if\n",
      "the most promising routes are encapsulated within the in-\n",
      "context examples, LLMs inherently gravitate towards prior-\n",
      "itizing those promising candidates. This diminishes the need\n",
      "for intricate prompt engineering and allows the incorpora-\n",
      "tion of intricate heuristics, whether intuitive or knowledge-\n",
      "driven. Again, the absence of disjoint prompts in our ap-\n",
      "proach allows for an immediate assessment of candidate vi-\n",
      "ability in the same generation.\n",
      "4. Backtracking to a Preferable Juncture. The decision\n",
      "of which node to explore next (including retracing to a prior\n",
      "node) inherently depends on the selected tree-search algo-\n",
      "rithm. While previous studies (Yao et al. 2023) have em-\n",
      "ployed external means such as coded mechanisms for the\n",
      "search process, this restricts its broader appeal and entails\n",
      "additional customization. Our designs predominantly adopt\n",
      "a DFS approach supplemented by pruning. The aim is to\n",
      "maintain proximity between nodes sharing the same par-\n",
      "ent, thereby encouraging the LLM to prioritize local over\n",
      "distant features. Additionally, we present performance met-\n",
      "rics for the AoT approach grounded in BFS. Our reliance\n",
      "on the model’s inherent capacity to glean insights from in-\n",
      "context examples obviates the necessity for additional, be-\n",
      "spoke mechanisms.\n",
      "Experiments\n",
      "We show that AoT surpasses the performance of other\n",
      "single-prompt methods (e.g. standard, CoT/-SC prompting)\n",
      "while remaining competitive even when compared to meth-\n",
      "ods that utilize external mechanisms, such as ToT, in bench-\n",
      "marks like the game of 24 and 5x5 mini crosswords.\n",
      "Game of 24\n",
      "The game of 24 is a mathematical card game in which play-\n",
      "ers are given four numbers and must use addition, subtrac-\n",
      "tion, multiplication, and division (each operation can be used\n",
      "more than once) to manipulate those numbers to total 24.\n",
      "For instance, for the numbers ‘ 8 8 5 4 ’, one solution would\n",
      "be ‘8∗(5−(8/4)) = 24 ’. At first glance, the game might\n",
      "appear straightforward. However, a cursory calculation sug-\n",
      "gests there are nearly 13,000 distinct expressions possible\n",
      "for any set of four numbers (without accounting for the com-\n",
      "mutative properties of addition and multiplication), making\n",
      "it a formidable challenge for present-day LLMs.\n",
      "Task Setup. Adhering to the setup detailed in (Yao et al.\n",
      "2023), we use games from indices 901-1000, sourced from\n",
      "the 1362 games ranked by relative difficulty at 4nums.com .\n",
      "For an attempt to be considered successful, it must derive a\n",
      "total of 24 using the exact numbers provided and only the\n",
      "allowed operations.\n",
      "Baselines. Standard prompting and CoT are used in the 5-\n",
      "shot setting, with CoT integrating 3 steps for the operations.\n",
      "These methods are sampled 100 times, and the averaged suc-\n",
      "cess rates from these samples are reported. CoT-SC is also\n",
      "tested with 100 votes in our setup. For ToT, we use a breadth\n",
      "of 5. The performance metrics from their study are directly\n",
      "cited to obviate the need for needless carbon emissions.\n",
      "AoT Setup. We employ the same 5-shot setting as in stan-\n",
      "dard prompting and CoT baseline setup. Our in-context sam-\n",
      "ples leverage a DFS-style search algorithm, which, for clar-\n",
      "ity, is the same version used when contrasting with tra-\n",
      "ditional DFS in Fig. 5. During each subtree exploration,\n",
      "dubbed either the ‘first step’ or ‘first operation’, we choose\n",
      "two numbers—illustrated by the selection of 8 and 6 in the\n",
      "third ’first step’ (i.e., subtree labeled ‘3’) of Fig. 1—and a\n",
      "corresponding operation (e.g., 8−6). This operation results\n",
      "in a new number, 2, leaving us with three numbers in total.\n",
      "A thorough combing of these three numbers culminates in\n",
      "19 leaf nodes, all visible under the ‘3’ subtree in Fig. 1. We\n",
      "aim to assess two aspects: the ability of the LLM to pin-\n",
      "point promising first operations, which directly impacts the\n",
      "number of resolved leaf nodes, and its performance against\n",
      "a conventional DFS. Details on the prompts we employed\n",
      "are provided in the Appendix. As our method emphasizessequential generation over trajectory sampling, we operate\n",
      "with a temperature setting of 0.\n",
      "Results. From Table 1, it’s evident that standard prompt-\n",
      "ing combined with CoT/-SC significantly lags behind tree\n",
      "search methods when used with LLMs. The “Standard + Re-\n",
      "fine” result, showing a 27% success rate, is referenced from\n",
      "(Yao et al. 2023). This method involves iteratively asking\n",
      "the LLM (up to 10 iterations) to refine its answer if the initial\n",
      "one is incorrect. Meanwhile, ToT is limited to a maximum of\n",
      "100 node visits, translating to several hundred LLM queries\n",
      "for each example. Remarkably, AoT achieves its results with\n",
      "just a single query . Despite reducing the number of requests\n",
      "by more than a factor of 100, AoT still outperforms ToT in\n",
      "this task.\n",
      "Method Success Avg. Queries\n",
      "Standard Prompting 7.3% 1\n",
      "CoT 4.0% 1\n",
      "CoT-SC (k= 100) 9 .0% 100\n",
      "Standard + Refine 27% 10\n",
      "ToT (b= 5) 69% 109 .1\n",
      "AoT (ours) 71% 1\n",
      "Table 1: Game of 24: success rates and the average number\n",
      "of LLM queries for each example.\n",
      "Error Analysis. Using a strictly LLM-centric approach—\n",
      "eschewing any external tooling or edits—we sought to cat-\n",
      "egorize mistakes observed during the game of 24. This aids\n",
      "in highlighting areas for refinement when solely deploying\n",
      "LLMs. We’ve classified these errors into four distinct, ex-\n",
      "haustive categories: 1)Out-of-token error: The LLM reaches\n",
      "its maximum token threshold without identifying a solution.\n",
      "2)Expression misstep: The LLM has the correct logic or\n",
      "steps but fails when trying to express or formulate them into\n",
      "a coherent answer. 3)Non-finalization error: The LLM dis-\n",
      "covers the solution but continues its search without consol-\n",
      "idating the finding. 4)Other errors: This umbrella term en-\n",
      "compasses other mistakes like computational errors that re-\n",
      "sult in overlooking the solution or furnishing incorrect an-\n",
      "swers. To exclusively showcase the AoT’s search capabil-\n",
      "ities, we also present the AoT + Manual Resolution ver-\n",
      "sion. Here, once the LLM pinpoints a solution, its final ar-\n",
      "ticulation is manually processed—a strategy also employed\n",
      "by the ToT method. As evidenced in Table 2, a notable\n",
      "7% of mistakes stem from non-algorithmic factors like non-\n",
      "finalization and expression missteps. In fact, with manual\n",
      "resolution, AoT attains a 78% success rate, surpassing ToT.\n",
      "This underlines the potential for refining our prompt, espe-\n",
      "cially in areas concerning recognizing and expressing suc-\n",
      "cessful problem resolutions. Additionally, the token limi-\n",
      "tation underscores the appeal of expanding the generative\n",
      "context window, which may further bolster LLMs’ recursive\n",
      "reasoning when engaged with algorithmic examples.\n",
      "Error Type Error\n",
      "Out-of-token error 9%\n",
      "Expression misstep 4%\n",
      "Non-finalization error 3%\n",
      "Others 13%\n",
      "Method Success\n",
      "ToT 69%\n",
      "AoT 71%\n",
      "AoT + Manual Resolution 78%\n",
      "Table 2: Game of 24: AoT error analysis.\n",
      "Mini Crosswords\n",
      "The 5×5mini crossword is a compact word puzzle featur-\n",
      "ing a grid of 25 squares arranged in a 5-by-5configuration.\n",
      "Players are tasked with filling the grid based on provided\n",
      "clues for each word. Clues are given for words that run both\n",
      "across (horizontally) and down (vertically). Words intersect\n",
      "at certain letters, offering additional hints to complete the\n",
      "puzzle.\n",
      "Task Setup. Adhering to the setup outlined in (Yao et al.\n",
      "2023), we draw our prompts from games 136, 141, 146, 151,\n",
      "and 156 out of the 156 games available on goobix.com . Our\n",
      "testing focuses on a set of 20 games, specifically games 1, 6,\n",
      ". . ., 91, and 96.\n",
      "Baselines. Mirroring our approach for the game of 24, we\n",
      "benchmark our method against established techniques: stan-\n",
      "dard prompting, CoT, and ToT. For standard prompting, we\n",
      "provide both the crosswords and their respective solutions\n",
      "as in-context examples. CoT augments this by prompting\n",
      "the retrieval of words for each of the ten clues—equally split\n",
      "between horizontal and vertical orientations. We directly ex-\n",
      "tract the success rates of ToT from their original publication\n",
      "for comparison.\n",
      "AoT Setup. We divide the process into two steps, each in-\n",
      "volving a query. Initially, we task the LLM with suggesting\n",
      "five potential words for each row and column. We then pin-\n",
      "point the starting word candidates that have the highest com-\n",
      "patibility with other words within the crossword framework.\n",
      "This preliminary phase mirrors a ’warm-up’ sequence in al-\n",
      "gorithm initialization. In the subsequent step, we exclusively\n",
      "leverage the LLM’s algorithmic reasoning prowess, starting\n",
      "with the pre-selected word. The method involves cyclically\n",
      "choosing a likely option (specifically, a row or column) for\n",
      "insertion, generating candidate words, and assessing their\n",
      "compatibility with the words already on the board. If no\n",
      "match is found, the process shifts focus to another promising\n",
      "candidate. Otherwise, the word is added to the crossword,\n",
      "and the search continues. The cycle concludes either when\n",
      "the board is fully populated or no more suitable words can be\n",
      "found, which may be due to either incorrect existing words\n",
      "or the absence of matching words. Notably, this entire pro-\n",
      "cess unfolds within a single generation window. The algo-\n",
      "rithmic examples in our prompt (detailed in the Appendix)include three that achieve game completion and two that pre-\n",
      "dominantly populate the crossword, filling 8 or 9 slots.\n",
      "Results. Table 3 underscores AoT’s proficiency in the\n",
      "mini crosswords task, showcasing a word success rate—a\n",
      "measure used in existing studies to represent the percent-\n",
      "age of words correctly completed out of the total—that sur-\n",
      "passes earlier methods reliant on various prompting tech-\n",
      "niques. However, it trails behind ToT. An important observa-\n",
      "tion is the sheer volume of queries ToT employs, exceeding\n",
      "AoT’s by over a factor of 100. One factor hindering AoT\n",
      "from surpassing ToT is that the backtracking capability in-\n",
      "herent in the algorithmic example isn’t fully activated. Fully\n",
      "unlocking this capability would lead to a significant elonga-\n",
      "tion in the generation phase. In contrast, ToT has the advan-\n",
      "tage of leveraging external memory for its backtracking.\n",
      "Method Word Success Avg. Queries\n",
      "Standard Prompting 14% 1\n",
      "CoT 15.6% 1\n",
      "ToT 60% >200\n",
      "AoT (ours) 52% 2\n",
      "Table 3: 5×5mini crosswords word: word success rates and\n",
      "the average number of LLM queries for each example.\n",
      "Error Analysis. To understand the prevalent mistakes\n",
      "made by AoT, we’ve categorized the errors into four dis-\n",
      "tinct categories. In our analysis for each game, we focus on\n",
      "the initial error the LLM produces while charting its rea-\n",
      "soning path, given that an early error typically cascades into\n",
      "subsequent failures. 1)No preselections: LLM fails to gen-\n",
      "erate compatible words essential for the warm-start phase.\n",
      "Given a correctly preselected word, the second phase for re-\n",
      "cursive reasoning can exhibit errors including: 2)Expres-\n",
      "sion misstep: The LLM mistakenly believes it has exhausted\n",
      "all choices and jumps to an answer prematurely. 3)Incor-\n",
      "rect pattern extraction: The LLM wrongly extracts a pattern\n",
      "based on the current board layout. 4)Erroneous word place-\n",
      "ment: Despite recognizing the correct pattern, the LLM se-\n",
      "lects a mismatched word or misses better-fitting alternatives.\n",
      "Navigating the crossword complexity arises from outdated\n",
      "terms, esoteric references, and typographical mishaps. Pre-\n",
      "dominantly, the errors observed are due to misguided word\n",
      "placements followed by pattern misinterpretations. Also, the\n",
      "LLM seems challenged in aligning letters at precise indices\n",
      "to create word structures— an obstracle circumvented by an\n",
      "external mechanism in the ToT framework.\n",
      "Discussion\n",
      "In this section, we delve into crucial aspects to consider\n",
      "when crafting prompts for AoT, using the game of 24 as our\n",
      "primary case study.\n",
      "Can AoT surpass the DFS it’s patterned after? A core\n",
      "query of ours is to ascertain if the LLM has the capability\n",
      "to not only mirror but also outdo the efficiency of the al-\n",
      "gorithm introduced in-context. As evidenced in Fig. 5, AoT\n",
      "Error Type Error\n",
      "No preselections 15.8%\n",
      "Expression misstep 5.3%\n",
      "Incorrect pattern extraction 26.3%\n",
      "Erroneous word placement 52.6%\n",
      "Table 4: Breakdown of errors in 5×5mini crosswords with\n",
      "AoT. Numbers indicate the relative percentage of each error\n",
      "type among all errors.\n",
      "systematically navigates fewer nodes than its DFS counter-\n",
      "part. While DFS employs a uniform strategy when choosing\n",
      "the subsequent subtree to investigate, AoT’s LLM integrates\n",
      "its inherent heuristic. This amplification over the base algo-\n",
      "rithm exemplifies the advantages of LLM’s recursive reason-\n",
      "ing capability.\n",
      "0 200 400 600 800 1000\n",
      "# of Visited Nodes048121620# of Games\n",
      "DFS\n",
      "AoT\n",
      "Figure 5: Histogram showing the number of visited nodes\n",
      "for AoT and DFS in the Game of 24.\n",
      "How does algorithm selection influence AoT’s efficacy?\n",
      "To explore the impact of algorithm choice on AoT’s per-\n",
      "formance, we implemented both BFS and random search\n",
      "within the AoT framework. Our findings, presented in Ta-\n",
      "ble 5, reveal that all three AoT variations outperform the\n",
      "single-query CoT. This outcome was anticipated as AoT, ir-\n",
      "respective of the algorithm, undertakes a search and revis-\n",
      "its potential mistakes—either by random retry in the ran-\n",
      "dom search variant or through backtracking in the DFS and\n",
      "BFS configurations. Notably, the structured search versions,\n",
      "AoT (DFS) and AoT (BFS), displayed better efficiency than\n",
      "AoT (Random), underscoring the advantage of algorithmic\n",
      "insights in solution discovery. However, AoT (BFS) lagged\n",
      "behind AoT (DFS). Closer inspection of errors made by AoT\n",
      "(BFS) revealed the LLM faced greater challenges in identi-\n",
      "fying optimal operations than its DFS counterpart.\n",
      "How does the search step count within the algorithmic\n",
      "example modulate AoT’s behavior? We begin with the\n",
      "standard AoT prompt and modify the subtree explorations.\n",
      "In AoT (Short), each in-context example uses one or two\n",
      "steps to reach a solution, while AoT (Long) incorporates\n",
      "three to five extra subtree explorations. The impact on total\n",
      "search steps is illustrated in Fig. 6. Our observations high-\n",
      "light longer generations for AoT (Long) and shorter onesMethod Success Avg. Queries\n",
      "CoT 4% 1\n",
      "CoT-SC (k=100) 9% 100\n",
      "ToT 69% 109 .1\n",
      "AoT (DFS) 71% 1\n",
      "AoT (BFS) 48% 1\n",
      "AoT (Random) 20% 1\n",
      "Table 5: Comparative success rates and average LLM query\n",
      "counts for AoT variations templated by distinct algorithms.\n",
      "for AoT (Short) relative to the original AoT. This suggests\n",
      "that the search step count introduces an implicit bias on the\n",
      "LLM’s search velocity. Notably, even when navigating in-\n",
      "correct steps, it’s essential to emphasize the exploration of\n",
      "promising directions.\n",
      "0 50 100 150 200 250 300 350 400\n",
      "# of Visited Nodes020406080100# of Games\n",
      "AoT (Short)\n",
      "AoT\n",
      "AoT (Long)\n",
      "Figure 6: Comparison of AoT with shorter and longer in-\n",
      "context examples prompted AoT versions: cumulative num-\n",
      "ber of games for the number of visited nodes.\n",
      "Limitations. While AoT substantially cuts down on the\n",
      "number of queries relative to ToT, its resource demands ex-\n",
      "ceed those of standard prompting and CoT, a consequence\n",
      "of its extensive exploration of ideas via token generation.\n",
      "Crafting token-efficient algorithmic examples is one avenue,\n",
      "but there’s also potential in judiciously tapping into or un-\n",
      "locking the LLM’s “tunnel-vision”. Our research primarily\n",
      "spotlighted certain algorithms, with a keen focus on tree-\n",
      "search tasks. It’s pertinent to highlight that we conducted our\n",
      "tests exclusively with GPT-4. Though more costly than other\n",
      "LLMs, GPT-4’s advanced capabilities appear pivotal for\n",
      "AoT’s optimal functioning; models of lesser caliber might\n",
      "not yield comparable performance boosts from AoT.\n",
      "Conclusion\n",
      "This paper presents the Algorithm of Thoughts , a pioneer-\n",
      "ing prompting strategy to navigate reasoning pathways in\n",
      "LLMs using minimal queries. Our findings reveal that this\n",
      "method not only substantially surpasses prior single-query\n",
      "techniques but also rivals external tree-search implementa-\n",
      "tions. Such an approach augments the potential to stream-\n",
      "line idea discovery in LLMs, balancing both cost and com-\n",
      "putational demands. Future work includes designing token-\n",
      "efficient algorithmic examples, developing adaptive mecha-\n",
      "nisms for “tunnel-vision” activation to expedite the search,\n",
      "and deepening the understanding of this fresh mode of in-\n",
      "context learning from theoretical angles.\n",
      "References\n",
      "Aminabadi, R. Y .; Rajbhandari, S.; Awan, A. A.; Li, C.; Li,\n",
      "D.; Zheng, E.; Ruwase, O.; Smith, S.; Zhang, M.; Rasley, J.;\n",
      "et al. 2022. DeepSpeed-inference: enabling efficient infer-\n",
      "ence of transformer models at unprecedented scale. In SC22:\n",
      "International Conference for High Performance Computing,\n",
      "Networking, Storage and Analysis , 1–15. IEEE.\n",
      "Austin, J.; Odena, A.; Nye, M.; Bosma, M.; Michalewski,\n",
      "H.; Dohan, D.; Jiang, E.; Cai, C.; Terry, M.; Le, Q.; et al.\n",
      "2021. Program synthesis with large language models. arXiv\n",
      "preprint arXiv:2108.07732 .\n",
      "Baddeley, A. 2003. Working memory: looking back and\n",
      "looking forward. Nature reviews neuroscience , 4(10): 829–\n",
      "839.\n",
      "Bai, Y .; Kadavath, S.; Kundu, S.; Askell, A.; Kernion, J.;\n",
      "Jones, A.; Chen, A.; Goldie, A.; Mirhoseini, A.; McKinnon,\n",
      "C.; Chen, C.; Olsson, C.; Olah, C.; Hernandez, D.; Drain,\n",
      "D.; Ganguli, D.; Li, D.; Tran-Johnson, E.; Perez, E.; Kerr, J.;\n",
      "Mueller, J.; Ladish, J.; Landau, J.; Ndousse, K.; Lukosuite,\n",
      "K.; Lovitt, L.; Sellitto, M.; Elhage, N.; Schiefer, N.; Mer-\n",
      "cado, N.; DasSarma, N.; Lasenby, R.; Larson, R.; Ringer,\n",
      "S.; Johnston, S.; Kravec, S.; Showk, S. E.; Fort, S.; Lanham,\n",
      "T.; Telleen-Lawton, T.; Conerly, T.; Henighan, T.; Hume,\n",
      "T.; Bowman, S. R.; Hatfield-Dodds, Z.; Mann, B.; Amodei,\n",
      "D.; Joseph, N.; McCandlish, S.; Brown, T.; and Kaplan, J.\n",
      "2022. Constitutional AI: Harmlessness from AI Feedback.\n",
      "ArXiv:2212.08073 [cs].\n",
      "Banerjee, S.; Bringsjord, S.; Giancola, M.; and Govindara-\n",
      "julu, N. S. 2022. Qualitative Mechanical Problem-Solving\n",
      "by Artificial Agents:: Further Progress, Under Psychometric\n",
      "AI. In The International FLAIRS Conference Proceedings ,\n",
      "volume 35.\n",
      "Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;\n",
      "Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,\n",
      "A.; Agarwal, S.; Herbert-V oss, A.; Krueger, G.; Henighan,\n",
      "T.; Child, R.; Ramesh, A.; Ziegler, D.; Wu, J.; Winter,\n",
      "C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.;\n",
      "Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford,\n",
      "A.; Sutskever, I.; and Amodei, D. 2020. Language Mod-\n",
      "els are Few-Shot Learners. Advances in Neural Information\n",
      "Processing Systems , 33: 1877–1901.\n",
      "Chen, L.; Zaharia, M.; and Zou, J. 2023. FrugalGPT: How\n",
      "to Use Large Language Models While Reducing Cost and\n",
      "Improving Performance. arXiv preprint arXiv:2305.05176 .\n",
      "Chen, M.; Tworek, J.; Jun, H.; Yuan, Q.; Pinto, H. P. d. O.;\n",
      "Kaplan, J.; Edwards, H.; Burda, Y .; Joseph, N.; Brockman,\n",
      "G.; et al. 2021. Evaluating large language models trained on\n",
      "code. arXiv preprint arXiv:2107.03374 .\n",
      "Chowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra,\n",
      "G.; Roberts, A.; Barham, P.; Chung, H. W.; Sutton, C.;\n",
      "Gehrmann, S.; et al. 2022. Palm: Scaling language modeling\n",
      "with pathways. arXiv preprint arXiv:2204.02311 .Dhar, P. 2020. The carbon impact of artificial intelligence.\n",
      "Nat. Mach. Intell. , 2(8): 423–425.\n",
      "Drozdov, A.; Sch ¨arli, N.; Aky ¨urek, E.; Scales, N.; Song, X.;\n",
      "Chen, X.; Bousquet, O.; and Zhou, D. 2022. Compositional\n",
      "Semantic Parsing with Large Language Models.\n",
      "Helie, S.; and Pizlo, Z. 2022. When is psychology research\n",
      "useful in artificial intelligence? A case for reducing compu-\n",
      "tational complexity in problem solving. Topics in Cognitive\n",
      "Science , 14(4): 687–701.\n",
      "Holyoak, K. J.; and Morrison, R. G. 2005. The Cambridge\n",
      "handbook of thinking and reasoning . Cambridge University\n",
      "Press.\n",
      "Huang, J.; and Chang, K. C.-C. 2022. Towards reason-\n",
      "ing in large language models: A survey. arXiv preprint\n",
      "arXiv:2212.10403 .\n",
      "Kadavath, S.; Conerly, T.; Askell, A.; Henighan, T.; Drain,\n",
      "D.; Perez, E.; Schiefer, N.; Hatfield-Dodds, Z.; DasSarma,\n",
      "N.; Tran-Johnson, E.; et al. 2022. Language models (mostly)\n",
      "know what they know. arXiv preprint arXiv:2207.05221 .\n",
      "Kahneman, D. 2011. Thinking, fast and slow . macmillan.\n",
      "Kojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y .; and Iwasawa,\n",
      "Y . 2022. Large Language Models are Zero-Shot Reason-\n",
      "ers. Advances in Neural Information Processing Systems ,\n",
      "35: 22199–22213.\n",
      "Lanham, T.; Chen, A.; Radhakrishnan, A.; Steiner, B.; Deni-\n",
      "son, C.; Hernandez, D.; Li, D.; Durmus, E.; Hubinger, E.;\n",
      "Kernion, J.; et al. 2023. Measuring Faithfulness in Chain-\n",
      "of-Thought Reasoning. arXiv preprint arXiv:2307.13702 .\n",
      "Liang, P.; Bommasani, R.; Lee, T.; Tsipras, D.; Soylu, D.;\n",
      "Yasunaga, M.; Zhang, Y .; Narayanan, D.; Wu, Y .; Kumar,\n",
      "A.; et al. 2022. Holistic evaluation of language models.\n",
      "arXiv preprint arXiv:2211.09110 .\n",
      "Libby, M. E.; Weiss, J. S.; Bancroft, S.; and Ahearn, W. H.\n",
      "2008. A comparison of most-to-least and least-to-most\n",
      "prompting on the acquisition of solitary play skills. Behav-\n",
      "ior analysis in practice , 1: 37–43.\n",
      "Liu, Y .; Han, T.; Ma, S.; Zhang, J.; Yang, Y .; Tian, J.; He, H.;\n",
      "Li, A.; He, M.; Liu, Z.; et al. 2023. Summary of chatgpt/gpt-\n",
      "4 research and perspective towards the future of large lan-\n",
      "guage models. arXiv preprint arXiv:2304.01852 .\n",
      "Long, J. 2023. Large Language Model Guided Tree-of-\n",
      "Thought. arXiv preprint arXiv:2305.08291 .\n",
      "Lyu, Q.; Havaldar, S.; Stein, A.; Zhang, L.; Rao, D.; Wong,\n",
      "E.; Apidianaki, M.; and Callison-Burch, C. 2023. Faithful\n",
      "Chain-of-Thought Reasoning. ArXiv:2301.13379 [cs].\n",
      "Mialon, G.; Dess `ı, R.; Lomeli, M.; Nalmpantis, C.; Pa-\n",
      "sunuru, R.; Raileanu, R.; Rozi `ere, B.; Schick, T.; Dwivedi-\n",
      "Yu, J.; Celikyilmaz, A.; et al. 2023. Augmented language\n",
      "models: a survey. arXiv preprint arXiv:2302.07842 .\n",
      "Monsell, S. 2003. Task switching. Trends in cognitive sci-\n",
      "ences , 7(3): 134–140.\n",
      "Ouyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright, C.;\n",
      "Mishkin, P.; Zhang, C.; Agarwal, S.; Slama, K.; Ray, A.;\n",
      "et al. 2022. Training language models to follow instructions\n",
      "with human feedback. Advances in Neural Information Pro-\n",
      "cessing Systems , 35: 27730–27744.\n",
      "Robinson, J.; and Wingate, D. 2022. Leveraging Large Lan-\n",
      "guage Models for Multiple Choice Question Answering.\n",
      "Shao, Z.; Gong, Y .; Shen, Y .; Huang, M.; Duan, N.; and\n",
      "Chen, W. 2023. Synthetic Prompting: Generating Chain-\n",
      "of-Thought Demonstrations for Large Language Models.\n",
      "Sloman, S. A. 1996. The empirical case for two systems of\n",
      "reasoning. Psychological bulletin , 119(1): 3.\n",
      "Srivastava, A.; Rastogi, A.; Rao, A.; Shoeb, A. A. M.; Abid,\n",
      "A.; Fisch, A.; Brown, A. R.; Santoro, A.; Gupta, A.; Garriga-\n",
      "Alonso, A.; et al. 2022. Beyond the imitation game: Quanti-\n",
      "fying and extrapolating the capabilities of language models.\n",
      "arXiv preprint arXiv:2206.04615 .\n",
      "Suzgun, M.; Scales, N.; Sch ¨arli, N.; Gehrmann, S.; Tay,\n",
      "Y .; Chung, H. W.; Chowdhery, A.; Le, Q. V .; Chi, E. H.;\n",
      "Zhou, D.; and Wei, J. 2022. Challenging BIG-Bench\n",
      "Tasks and Whether Chain-of-Thought Can Solve Them.\n",
      "ArXiv:2210.09261 [cs].\n",
      "Thoppilan, R.; De Freitas, D.; Hall, J.; Shazeer, N.; Kul-\n",
      "shreshtha, A.; Cheng, H.-T.; Jin, A.; Bos, T.; Baker, L.; Du,\n",
      "Y .; et al. 2022. Lamda: Language models for dialog appli-\n",
      "cations. arXiv preprint arXiv:2201.08239 .\n",
      "Turpin, M.; Michael, J.; Perez, E.; and Bowman, S. R. 2023.\n",
      "Language Models Don’t Always Say What They Think: Un-\n",
      "faithful Explanations in Chain-of-Thought Prompting. arXiv\n",
      "preprint arXiv:2305.04388 .\n",
      "Wang, X.; Wei, J.; Schuurmans, D.; Le, Q. V .; Chi, E. H.;\n",
      "Narang, S.; Chowdhery, A.; and Zhou, D. 2022. Self-\n",
      "Consistency Improves Chain of Thought Reasoning in Lan-\n",
      "guage Models.\n",
      "Wei, J.; Tay, Y .; Bommasani, R.; Raffel, C.; Zoph, B.;\n",
      "Borgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler,\n",
      "D.; Chi, E. H.; Hashimoto, T.; Vinyals, O.; Liang, P.; Dean,\n",
      "J.; and Fedus, W. 2022a. Emergent Abilities of Large Lan-\n",
      "guage Models. ArXiv:2206.07682 [cs].\n",
      "Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Ichter, B.;\n",
      "Xia, F.; Chi, E.; Le, Q. V .; and Zhou, D. 2022b. Chain-\n",
      "of-Thought Prompting Elicits Reasoning in Large Language\n",
      "Models. Advances in Neural Information Processing Sys-\n",
      "tems, 35: 24824–24837.\n",
      "Wu, C.-J.; Raghavendra, R.; Gupta, U.; Acun, B.; Ardalani,\n",
      "N.; Maeng, K.; Chang, G.; Aga, F.; Huang, J.; Bai, C.; et al.\n",
      "2022. Sustainable ai: Environmental implications, chal-\n",
      "lenges and opportunities. Proceedings of Machine Learning\n",
      "and Systems , 4: 795–813.\n",
      "Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.;\n",
      "Cao, Y .; and Narasimhan, K. 2023. Tree of Thoughts:\n",
      "Deliberate Problem Solving with Large Language Models.\n",
      "ArXiv:2305.10601 [cs].\n",
      "Zelikman, E.; Wu, Y .; Mu, J.; and Goodman, N. 2022. Star:\n",
      "Bootstrapping reasoning with reasoning. Advances in Neu-\n",
      "ral Information Processing Systems , 35: 15476–15488.\n",
      "Zhang, Z.; Zhang, A.; Li, M.; and Smola, A. 2022. Auto-\n",
      "matic Chain of Thought Prompting in Large Language Mod-\n",
      "els.\n",
      "Zhou, D.; Sch ¨arli, N.; Hou, L.; Wei, J.; Scales, N.; Wang,\n",
      "X.; Schuurmans, D.; Cui, C.; Bousquet, O.; Le, Q. V .; andChi, E. H. 2022. Least-to-Most Prompting Enables Complex\n",
      "Reasoning in Large Language Models.\n",
      "Game of 24 - Additional Details\n",
      "In order to avoid confusion in our analysis of AoT in the game of 24, we give additional details in terms of terminologies we\n",
      "use as well as their direct implications in the performance figures. An Illustration of these are given in Fig. 7.\n",
      "4 \n",
      "- \n",
      "4 \n",
      "= \n",
      "8\n",
      "(left: \n",
      "8, \n",
      "6, \n",
      "0)\n",
      "4 \n",
      "+ \n",
      "2 \n",
      "= \n",
      "6\n",
      "(left: \n",
      "6, \n",
      "4)\n",
      "4 \n",
      "/ \n",
      "4 \n",
      "= \n",
      "1\n",
      "(left: \n",
      "2, \n",
      "1)\n",
      "6 \n",
      "* \n",
      "4 \n",
      "= \n",
      "24\n",
      "(left: \n",
      "24)\n",
      "6 \n",
      "+ \n",
      "4 \n",
      "= \n",
      "10\n",
      "(left: \n",
      "10)\n",
      "...\n",
      "Input: \n",
      "8 \n",
      "6 \n",
      "4 \n",
      "4\n",
      "First \n",
      "Operations\n",
      "Second \n",
      "Operations\n",
      "Third \n",
      "Operations\n",
      "Visited \n",
      "Nodes\n",
      "8 \n",
      "- \n",
      "6 \n",
      "= \n",
      "2\n",
      "(left: \n",
      "4, \n",
      "4, \n",
      "2)\n",
      "...\n",
      "Subtree \n",
      "Exploration\n",
      "Figure 7: An illustration of terminologies we use for the game of 24. The yellow nodes represent the first operations and the\n",
      "states they lead to; the green node represents the node where we find the solution; all other nodes are represented by pink.\n",
      "First operations / First iterations. This represents the scenario that after we choose the first two number in the game of 24,\n",
      "the case of either adding, subtracting, multiplying or dividing them.\n",
      "Subtree Exploration. This denotes searching all or most of the nodes coming from the same state, typically states with less\n",
      "than four numbers left.\n",
      "Number of nodes visited. This is the number of states that the method has been on the game of 24. Each state is the set of\n",
      "number we are left with, after our operations in the numbers. For example, after the first operation we might be left with the\n",
      "numbers ‘ 831’. This set of numbers represent a state, as well as the state of ‘ 83’ that we will be left with after another operation\n",
      "of ‘8∗1 = 8 ’.\n",
      "Creative Writing\n",
      "We use the creative writing task, also used by (Yao et al. 2023), where the LLM is provided with four arbitrary sentences.\n",
      "The objective is to craft a cohesive narrative divided into four paragraphs, with each paragraph culminating in one of the given\n",
      "sentences. This exercise not only fosters creativity but also emphasizes strategic deliberation.\n",
      "Task Setup\n",
      "Sentences are randomly sourced from randomwordgenerator.com , resulting in 100 distinct sets of inputs. Given the absence of\n",
      "predetermined correct answers, the primary focus lies in evaluating the coherence of the responses. We have noted that GPT-4\n",
      "consistently aligns with these input guidelines. Evaluation is centered around assessing passage coherence using a GPT-4 zero-\n",
      "shot prompt, where each output is rated on a scale of 1 to 10. Each task response undergoes five such evaluations, with their\n",
      "scores being averaged subsequently.\n",
      "Baselines\n",
      "For this task, both standard and CoT prompts are employed without preliminary training. While the standard prompt directly\n",
      "guides the LLM to fashion a cohesive narrative based on stipulated parameters, the CoT prompt obliges the model to initially\n",
      "outline a succinct plan prior to drafting the narrative, serving as an intermediate cognitive bridge. For each task iteration,\n",
      "ten samples are generated using both the standard and CoT methods. Results of the ToT approach are presented without\n",
      "modification.\n",
      "AoT Setup\n",
      "Mirroring ToT’s methodology, the task is tackled in a zero-shot setting. Our prompt instructs the model to first formulate five\n",
      "distinct plans. Subsequent to this, the model selects the most promising among them to shape a narrative and then refines it for\n",
      "optimal coherence. The exact prompts used for this zero-shot approach will be provided in the subsequent section.\n",
      "Results\n",
      "As depicted in Fig. 8, AoT outpaces other singular query prompting techniques such as standard prompting and CoT in terms\n",
      "of performance. It also exhibits a marked improvement over ToT, although the difference is not statistically significant. Com-\n",
      "prehensive scores, along with the average query count needed for each method, are consolidated in Table 6. Notably, AoT\n",
      "necessitates fewer queries compared to ToT.\n",
      "Standard CoT T oT AoT0246810\n",
      "Figure 8: Comparison of the standard prompting, CoT, ToT and AoT on the creative writing task.\n",
      "Method Score Avg. Queries\n",
      "Standard Prompting 6.19 1\n",
      "CoT 6.93 1\n",
      "ToT 7.56 20\n",
      "AoT 7.58 1\n",
      "Table 6: Performance of the methods determined by GPT-4.\n",
      "CoT vs. Single Iteration AoT in the Game of 24\n",
      "To demonstrate that the tree search mechanism is fundamentally distinct from the CoT prompting, even in scenarios where\n",
      "AoT’s in-context examples include only a single initial operation in the game of 24, we draw a comparison between AoT\n",
      "(Short) and CoT. In this setup, AoT (Short) determines the first operation and subsequently conducts a tree search on the\n",
      "remaining three numbers. Interestingly, AoT (Short) achieves a success rate of 48%, while CoT lags significantly, securing\n",
      "only 4%. These results underscore the notion that even a rudimentary search mechanism can lead to significant performance\n",
      "enhancements.\n",
      "Detailed Analysis on the Effect of the Length of the Prompts\n",
      "In this section, we delve deeper into Fig. 6 by presenting histograms for the successful, unsuccessful, and total games of ‘24’,\n",
      "considering the number of initial steps in methods AoT (Short), AoT, and AoT (Long). These are displayed in Figs. 9-11.\n",
      "From these figures, it becomes evident that the length of the prompts, measured by the number of initial steps included in\n",
      "in-context examples, correlates with the length of their solutions to test examples. This trend is consistent across all three cases,\n",
      "suggesting that AoT’s strategy in determining the number of initial steps is influenced by its in-context examples.\n",
      "Interestingly, when AoT is provided a well-balanced set of initial steps that emphasize the most promising operations, it\n",
      "excels in solving the majority of games in earlier iterations. This indicates AoT’s capacity to prioritize swift problem-solving\n",
      "without sacrificing performance. This tendency is also observed in AoT (Long), albeit with a somewhat reduced success rate,\n",
      "as illustrated in Fig. 9.\n",
      "0 2 4 6 8 10 1202040\n",
      "0 2 4 6 8 10 1202040# of Successful Games\n",
      "0 2 4 6 8 10 12\n",
      "# of First Steps02040\n",
      "AoT (Short)\n",
      "AoT\n",
      "AoT (Long)Figure 9: Histogram of the number of successful games with respect to the number of first steps for AoT (Short), AoT and AoT\n",
      "(Long).\n",
      "0 2 4 6 8 10 1202040\n",
      "0 2 4 6 8 10 1202040# of Unsuccessful Games\n",
      "0 2 4 6 8 10 12\n",
      "# of First Steps02040AoT (Short)\n",
      "AoT\n",
      "AoT (Long)\n",
      "Figure 10: Histogram of the number of unsuccessful games with respect to the number of first steps for AoT (Short), AoT and\n",
      "AoT (Long).\n",
      "Prompts\n",
      "Game of 24\n",
      "Below, we represent the specific prompts employed for the various methods detailed in the experiments section. It’s important\n",
      "to note that the terms “System”,“User”, and “Assistant” are utilized to denote the roles within the OpenAI API when operating\n",
      "in chat completion mode. The line breaks serve to show the transitions between the user and assistant interactions within the\n",
      "API.\n",
      "AoT (DFS)\n",
      "System:\n",
      "0 2 4 6 8 10 12050100\n",
      "0 2 4 6 8 10 12050100# of All Games\n",
      "0 2 4 6 8 10 12\n",
      "# of First Steps050100\n",
      "AoT (Short)\n",
      "AoT\n",
      "AoT (Long)Figure 11: Histogram of the number of all games with respect to the number of first steps for AoT (Short), AoT and AoT\n",
      "(Long).\n",
      "Use numbers and basic arithmetic operations (+ - */) to obtain 24. When\n",
      "considering the next steps, do not choose operations that will result in a\n",
      "negative or fractional number. In order to help with the calculations, the\n",
      "numbers in the parenthesis represent the numbers that are left after the\n",
      "operations and they are in descending order.\n",
      "Another thing we do is when there are only two numbers left in the parenthesis, we\n",
      "check whether we can arrive at 24 only by using basic arithmetic operations\n",
      "(+ - */). Some examples regarding this idea:\n",
      "(21 2) no\n",
      "since 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\n",
      "to 24.\n",
      "(30 6) 30 - 6 = 24 yes\n",
      "(8 3) 8 *3 = 24 yes\n",
      "(12 8) no\n",
      "(48 2) 48 / 2 = 24 yes\n",
      "Most importantly, do not give up, all the numbers that will be given has indeed a\n",
      "solution.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "14 8 8 2\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 + 2: (14, 10, 8)\n",
      "- 14 + 10: (24, 8) 32, 16, 192, 3\n",
      "- 14 - 10: (8, 4) 12, 8, 32, 2\n",
      "- 14 *10: (140, 8) 148, 132, 1120, fractional\n",
      "- 14 / 10: (8, 1.4) fractional\n",
      "- 14 + 8: (22, 10) 32, 12, 220, fractional\n",
      "- 14 - 8: (10, 6) 16, 4, 60, fractional\n",
      "- 14 *8: (112, 10) 122, 102, 1120, fractional\n",
      "- 14 / 8: fractional\n",
      "- 10 + 8: (18, 14) 32, 4, 252, fractional\n",
      "- 10 - 8: (14, 2) 16, 12, 28, 7\n",
      "- 10 *8: (80, 14) 94, 66, big, fractional\n",
      "- 10 / 8: fractional\n",
      "Trying another promising first operation:\n",
      "2. 8 / 2: (14, 8, 4)\n",
      "- 14 + 8: (22, 4) 26, 18, 88, fractional\n",
      "- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 2 = 4\n",
      "Step 2:\n",
      "14 - 8 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\n",
      "answer: (14 - 8) *(8 / 2) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "9 5 5 5\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 9 - 5: (5, 5, 4)\n",
      "- 5 + 5: (10, 4) 14, 6, 40, fractional\n",
      "- 5 - 5: (4, 0) 4, 4, 0, undefined\n",
      "- 5 *5: (25, 4) 29, 21, 100, fractional\n",
      "- 5 / 5: (4, 1) 5, 3, 4, 4\n",
      "- 5 + 4: (9, 5) 14, 4, 45, fractional\n",
      "- 5 - 4: (5, 1) 6, 4, 5, 0.2\n",
      "- 5 *4: (20, 5) 25, 15, 100, fractional\n",
      "- 5 / 4: fractional\n",
      "Trying another promising first operation:\n",
      "2. 5 + 5: (10, 9, 5)\n",
      "- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "5 + 5 = 10\n",
      "Step 2:\n",
      "10 + 9 = 19\n",
      "Step 3:\n",
      "19 + 5 = 24\n",
      "Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\n",
      "answer: ((5 + 5) + 9) + 5 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "8 6 4 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 - 6: (4, 4, 2)\n",
      "- 4 + 4: (8, 2) 10, 6, 16, 4\n",
      "- 4 - 4: (2, 0) 2, 2, 0, undefined\n",
      "- 4 *4: (16, 2) 18, 14, 32, 8\n",
      "- 4 / 4: (2, 1) 3, 1, 2, 2\n",
      "- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 - 6 = 2\n",
      "Step 2:\n",
      "4 + 2 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\n",
      "answer: (4 + (8 - 6)) *4 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "13 10 9 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 13 - 4: (10, 9, 9)\n",
      "- 10 + 9: (19, 9) 28, 10, 171, fractional\n",
      "- 10 - 9: (9, 1) 10, 8, 9, 9\n",
      "- 10 *9: (90, 9) 99, 81, 810, fractional\n",
      "- 10 / 9: fractional\n",
      "- 9 + 9: (18, 10) 28, 8, 180, fractional\n",
      "- 9 - 9: (10, 0) 10, 10, 0, undefined\n",
      "- 9 *9: (81, 10) 91, 71, 810, fractional\n",
      "- 9 / 9: (10, 1) 11, 9, 10, 10\n",
      "Trying another promising first operation:\n",
      "2. 10 - 4: (13, 9, 6)\n",
      "- 13 + 9: (22, 6) 28, 16, 132, fractional\n",
      "- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "10 - 4 = 6\n",
      "Step 2:\n",
      "13 - 9 = 4\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\n",
      "answer: (10 - 4) *(13 - 9) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "8 8 5 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 - 4: (8, 5, 4)\n",
      "- 8 + 5: (13, 4) 17, 9, 52, fractional\n",
      "- 8 - 5: (4, 3) 7, 1, 12, fractional\n",
      "- 8 *5: (40, 4) 44, 36, 160, fractional\n",
      "- 8 / 5: fractional\n",
      "- 8 + 4: (12, 5) 17, 7, 60, fractional\n",
      "- 8 - 4: (5, 4) 9, 1, 20, fractional\n",
      "- 8 *4: (32, 5) 37, 27, 160, fractional\n",
      "- 8 / 4: (5, 2) 7, 3, 10, 2.5\n",
      "- 5 + 4: (9, 8) 17, 1, 72, fractional\n",
      "- 5 - 4: (8, 1) 9, 7, 8, 8\n",
      "- 5 *4: (20, 8) 28, 12, 160, fractional\n",
      "- 5 / 4: fractional\n",
      "Trying another promising first operation:\n",
      "2. 8 / 4: (8, 5, 2)\n",
      "- 8 + 5: (13, 2) 15, 11, 26, fractional\n",
      "- 8 - 5: (3, 2) 5, 1, 6, 1.5\n",
      "- 8 *5: (40, 2) 42, 38, 80, 20\n",
      "- 8 / 5: fractional\n",
      "- 8 + 2: (10, 5) 15, 5, 50, 2\n",
      "- 8 - 2: (6, 5) 11, 1, 30, fractional\n",
      "- 8 *2: (16, 5) 21, 11, 80, fractional\n",
      "- 8 / 2: (5, 4) 9, 1, 20, fractional\n",
      "- 5 + 2: (7, 8) 15, 1, 56, fractional\n",
      "- 5 - 2: (8, 3) 11, 5, 24 = 8 *3 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 4 = 2\n",
      "Step 2:\n",
      "5 - 2 = 3\n",
      "Step 3:\n",
      "8*3 = 24\n",
      "Considering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\n",
      "answer: 8 *(5 - (8 / 4)) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "11 11 1 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 11 - 1: (11, 10, 1)\n",
      "- 11 + 10: (21, 1) 22, 20, 21, 21\n",
      "- 11 - 10: (1, 1) 2, 0, 1, 1\n",
      "- 11 *10: (110, 1) 111, 109, 110, 110\n",
      "- 11 / 10: fractional\n",
      "- 11 + 1: (12, 10) 22, 2, 120, 1.2\n",
      "- 11 - 1: (10, 10) 20, 0, 100, 1\n",
      "- 11 *1: (11, 10) 21, 1, 110, 1.1\n",
      "- 11 / 1: (11, 10) 21, 1, 110, fractional\n",
      "- 10 + 1: (11, 11) 22, 0, 121, 1\n",
      "- 10 - 1: (11, 9) 20, 2, 99, 1.1\n",
      "- 10 *1: (11, 10) 21, 1, 110, 1.1\n",
      "- 10 / 1: (11, 10) 21, 1, 110, 1.1\n",
      "Trying another promising first operation:\n",
      "2. 11 + 1: (12, 11, 1)\n",
      "- 12 + 11: (23, 1) 24 = 23 + 1 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11 + 1 = 12\n",
      "Step 2:\n",
      "12 + 11 = 23\n",
      "Step 3:\n",
      "23 + 1\n",
      "Considering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\n",
      "answer: ((11 + 1) + 11) + 1 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "11 7 4 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 7 *4: (28, 11, 1)\n",
      "- 28 + 11: (39, 1) 40, 38, 39, 39\n",
      "- 28 - 11: (17, 1) 18, 16, 17, 17\n",
      "- 28 *11: (308, 1) 309, 307, 308, 308\n",
      "- 28 / 11: fractional\n",
      "- 28 + 1: (29, 11) 40, 18, 319, fractional\n",
      "- 28 - 1: (27, 11) 38, 16, 297, fractional\n",
      "- 28 *1: (28, 11) 39, 17, 308, fractional\n",
      "- 28 / 1: (28, 11) 39, 17, 308, fractional\n",
      "- 11 + 1: (29, 28) 57, 1, 812, fractional\n",
      "- 11 - 1: (28, 10) 38, 18, 280, fractional\n",
      "- 11 *1: (28, 11) 39, 17, 308, fractional\n",
      "- 11 / 1: (28, 11) 39, 17, 308, fractional\n",
      "Trying another promising first operation:\n",
      "2. 7 + 1: (11 8 4)\n",
      "- 11 + 8: (19, 4) 23, 15, 76, fractional\n",
      "- 11 - 8: (4, 3) 7, 1, 12, fractional\n",
      "- 11 *8: (88, 4) 92, 84, 352, fractional\n",
      "- 11 / 8: fractional\n",
      "- 11 + 4: (15, 8) 23, 7, 120, fractional\n",
      "- 11 - 4: (7, 8) 15, -1, 56, fractional\n",
      "- 11 *4: (44, 8) 52, 36, 352, fractional\n",
      "- 11 / 4: fractional\n",
      "- 8 + 4: (12, 11) 23, -1, 132, fractional\n",
      "- 8 - 4: (11, 4) 15, 7, 44, fractional\n",
      "- 8 *4: (32, 11) 43, 21, 352, fractional\n",
      "- 8 / 4: (11, 2) 13, 9, 22, fractional\n",
      "Trying another promising first operation:\n",
      "3. 4 + 1: (11 7 5)\n",
      "- 11 + 7: (18, 5) 23, 13, 90, fractional\n",
      "- 11 - 7: (5, 4) 9, 1, 20, fractional\n",
      "- 11 *7: (77, 5) 82, 72, 385, fractional\n",
      "- 11 / 7: fractional\n",
      "- 11 + 5: (16, 7) 23, 9, 112, fractional\n",
      "- 11 - 5: (7, 6) 13, 1, 42, fractional\n",
      "- 11 *5: (55, 7) 62, 48, 385, fractional\n",
      "- 11 / 5: fractional\n",
      "- 7 + 5: (12, 11) 23, 1, 132, fractional\n",
      "- 7 - 5: (11, 2) 13, 9, 22, fractional\n",
      "- 7 *5: (35, 11) 46, 24 = 35 - 11 -> found it!\n",
      "Step 1:\n",
      "4 + 1 = 5\n",
      "Step 2:\n",
      "7*5 = 35\n",
      "Step 3:\n",
      "35 - 11 = 24\n",
      "Considering these steps: Backtracking the solution:\n",
      "24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\n",
      "answer: (7 *(4 + 1)) - 11 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "11 5 4 3\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 5 *4: (20, 11, 3)\n",
      "- 20 + 11: (31, 3) 34, 28, 93, fractional\n",
      "- 20 - 11: (9, 3) 12, 6, 27, 3\n",
      "- 20 *11: (220, 3) 223, 217, 660, fractional\n",
      "- 20 / 11: fractional\n",
      "- 20 + 3: (23, 11) 34, 12, 253, fractional\n",
      "- 20 - 3: (17, 11) 28, 6, 187, fractional\n",
      "- 20 *3: (60, 11) 71, 49, 660, fractional\n",
      "- 20 / 3: fractional\n",
      "- 11 + 3: (14, 20) 34, -6, 280, fractional\n",
      "- 11 - 3: (8, 20) 28, -12, 160, fractional\n",
      "- 11 *3: (33, 20) 53, 13, 660, fractional\n",
      "- 11 / 3: fractional\n",
      "Trying another promising first operation:\n",
      "2. 11 - 3: (8, 5, 4)\n",
      "- 8 + 5: (13, 4) 17, 9, 52, fractional\n",
      "- 8 - 5: (4, 3) 7, 1, 12, fractional\n",
      "- 8 *5: (40, 4) 44, 36, 160, fractional\n",
      "- 8 / 5: fractional\n",
      "- 8 + 4: (12, 5) 17, 7, 60, fractional\n",
      "- 8 - 4: (5, 4) 9, 1, 20, fractional\n",
      "- 8 *4: (32, 5) 37, 27, 160, fractional\n",
      "- 8 / 4: (5, 2) 7, 3, 10, 2.5\n",
      "- 5 + 4: (9, 8) 17, 1, 72, fractional\n",
      "- 5 - 4: (8, 1) 9, 7, 8, 8\n",
      "- 5 *4: (20, 8) 28, 12, 160, fractional\n",
      "- 5 / 4: fractional\n",
      "Trying another promising first operation:\n",
      "3. 11 *3: (33, 5, 4)\n",
      "- 33 + 5: (38, 4) 42, 34, 152, fractional\n",
      "- 33 - 5: (28, 4) 32, 24 = 28 - 4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11*3 = 33\n",
      "Step 2:\n",
      "33 - 5 = 28\n",
      "Step 3:\n",
      "28 - 4 = 24\n",
      "Considering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\n",
      "answer: ((11 *3) - 5) - 4 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "13 12 5 2\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 12 + 2: (14, 13, 5)\n",
      "- 14 + 13: (27, 5) 32, 22, 135, fractional\n",
      "- 14 - 13: (5, 1) 6, 4, 5, 5\n",
      "- 14 *13: (182, 5) 187, 177, 910, fractional\n",
      "- 14 / 13: fractional\n",
      "- 14 + 5: (19, 13) 32, 6, 247, fractional\n",
      "- 14 - 5: (13, 9) 22, 4, 117, fractional\n",
      "- 14 *5: (70, 13) 83, 57, 910, fractional\n",
      "- 14 / 5: fractional\n",
      "- 13 + 5: (18, 14) 32, 4, 252, fractional\n",
      "- 13 - 5: (14, 8) 22, 6, 112, fractional\n",
      "- 13 *5: (65, 14) 79, 51, 910, fractional\n",
      "- 13 / 5: fractional\n",
      "Trying another promising first operation:\n",
      "2. 13 + 5: (18, 12, 2)\n",
      "- 18 + 12: (30, 2) 32, 28, 60, fractional\n",
      "- 18 - 12: (6, 2) 8, 4, 12, 3\n",
      "- 18 *12: (216, 2) 218, 214, 432, fractional\n",
      "- 18 / 12: fractional\n",
      "- 18 + 2: (20, 12) 32, 8, 240, fractional\n",
      "- 18 - 2: (16, 12) 28, 4, 192, fractional\n",
      "- 18 *2: (36, 12) 48, 24 = 36 - 12 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "13 + 5 = 18\n",
      "Step 2:\n",
      "18*2 = 36\n",
      "Step 3:\n",
      "36 - 12 = 24\n",
      "Considering these steps: 24 = 36 - 12 = (18 *2) - 12 = ((13 + 5) *2) - 12 = 24.\n",
      "answer: ((13 + 5) *2) - 12 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "9 8 2 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 9 - 1: (8, 8, 2)\n",
      "- 8 + 8: (16, 2) 18, 14, 32, 8\n",
      "- 8 - 8: (2, 0) 2, 2, 0, undefined\n",
      "- 8 *8: (64, 2) 66, 62, 128, 32\n",
      "- 8 / 8: (2, 1) 3, 1, 2, 2\n",
      "- 8 + 2: (10, 8) 18, 2, 80, 4\n",
      "- 8 - 2: (6, 8) 14, -2, 48, fractional\n",
      "- 8 *2: (16, 8) 24 = 16 + 8 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "9 - 1 = 8\n",
      "Step 2:\n",
      "8*2 = 16\n",
      "Step 3:\n",
      "16 + 8 = 24\n",
      "Considering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\n",
      "answer: ((9 - 1) *2) + 8 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "AoT (Long)\n",
      "System:\n",
      "Use numbers and basic arithmetic operations (+ - */) to obtain 24. When\n",
      "considering the next steps, do not choose operations that will result in a\n",
      "negative or fractional number. In order to help with the calculations, the\n",
      "numbers in the parenthesis represent the numbers that are left after the\n",
      "operations and they are in descending order.\n",
      "Another thing we do is when there are only two numbers left in the parenthesis, we\n",
      "check whether we can arrive at 24 only by using basic arithmetic operations\n",
      "(+ - */). Some examples regarding this idea:\n",
      "(21 2) no\n",
      "since 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\n",
      "to 24.\n",
      "(30 6) 30 - 6 = 24 yes\n",
      "(8 3) 8 *3 = 24 yes\n",
      "(12 8) no\n",
      "(48 2) 48 / 2 = 24 yes\n",
      "Most importantly, do not give up, all the numbers that will be given has indeed a\n",
      "solution.\n",
      "User:\n",
      "14 8 8 2\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 + 2: (14, 10, 8)\n",
      "- 14 + 10: (24, 8) 32, 16, 192, 3\n",
      "- 14 - 10: (8, 4) 12, 8, 32, 2\n",
      "- 14 *10: (140, 8) 148, 132, 1120, fractional\n",
      "- 14 / 10: (8, 1.4) fractional\n",
      "- 14 + 8: (22, 10) 32, 12, 220, fractional\n",
      "- 14 - 8: (10, 6) 16, 4, 60, fractional\n",
      "- 14 *8: (112, 10) 122, 102, 1120, fractional\n",
      "- 14 / 8: fractional\n",
      "- 10 + 8: (18, 14) 32, 4, 252, fractional\n",
      "- 10 - 8: (14, 2) 16, 12, 28, 7\n",
      "- 10 *8: (80, 14) 94, 66, big, fractional\n",
      "- 10 / 8: fractional\n",
      "Trying another promising first operation:\n",
      "2. 14 + 8: (22, 8, 2)\n",
      "- 22 + 8: (30, 2) 32, 28, 60, 15\n",
      "- 22 - 8: (14, 2) 16, 12, 28, 7\n",
      "- 22 *8: (176, 2) 178, 174, 88\n",
      "- 22 / 8: (2.75, 2) fractional\n",
      "- 22 + 2: (24, 8) 32, 16, 192, 3\n",
      "- 22 - 2: (20, 8) 28, 12, 160, fractional\n",
      "- 22 *2: (44, 8) 52, 36, 352, fractional\n",
      "- 22 / 2: (11, 8) 19, 3, 88, fractional\n",
      "- 8 + 2: (22, 10) 32, 12, 220, fractional\n",
      "- 8 - 2: (22, 6) 28, 16, 132, fractional\n",
      "- 8 *2: (22, 16) 38, 6, 352, fractional\n",
      "- 8 / 2: (22, 4) 26, 18, 88, fractional\n",
      "Trying another promising first operation:\n",
      "3. 14 + 2: (16, 8, 8)\n",
      "- 16 + 8: (24, 8) 32, 16, 192, 3\n",
      "- 16 - 8: (8, 8) 16, 0, 64, 1\n",
      "- 16 *8: (128, 8) 136, 120, 1024, 16\n",
      "- 16 / 8: (8, 2) 10, 6, 16, 4\n",
      "- 8 + 8: (16, 16 32, 0, 256, 1\n",
      "- 8 - 8: (16, 0) 16, 16, 0, undefined\n",
      "- 8 *8: (64, 16) 80, 48, 1024, 4\n",
      "- 8 / 8: (16, 1) 17, 15, 16, 16\n",
      "Trying another promising first operation:\n",
      "4. 8 - 2: (14, 8, 6)\n",
      "- 14 + 8: (22, 14) 36, 8, 308, fractional\n",
      "- 14 - 8: (6, 6) 12, 0, 36, 1\n",
      "- 14 *8: (112, 6) 118, 106, 672, fractional\n",
      "- 14 / 8: (6, 1.75) fractional\n",
      "- 14 + 6: (20, 8) 22, 12, 160, fractional\n",
      "- 14 - 6: (8, 8) 16, 0, 64, 1\n",
      "- 14 *6: (84, 8) 92, 76, 672, fractional\n",
      "- 14 / 6: (8, 2.3) fractional\n",
      "- 8 + 6: (14, 14) 28, 0, 196, 1\n",
      "- 8 - 6: (14, 2) 16, 12, 28, 7\n",
      "- 8 *6: (48, 14) 62, 34, 672, fractional\n",
      "- 8 / 6: (14, 1.3) fractional\n",
      "Trying another promising first operation:\n",
      "5. 8 *2: (16, 14, 8)\n",
      "- 16 + 14: (30, 8) 38, 22, 240, fractional\n",
      "- 16 - 14: (8, 2) 10, 6, 16, 4\n",
      "- 16 *14: (224, 8) 232, 216, 1792, 28\n",
      "- 16 / 14: (8, 1.1) fractional\n",
      "- 16 + 8: (24, 14) 38, 10, 336, fractional\n",
      "- 16 - 8: (14, 8) 22, 6, 112, fractional\n",
      "- 16 *8: (128, 14) 142, 112, 1792, fractional\n",
      "- 16 / 8: (14, 2) 16, 12, 28, 7\n",
      "- 14 + 8: (22, 16) 38, 6, 352, fractional\n",
      "- 14 - 8: (16, 6) 22, 10, 96, fractional\n",
      "- 14 *8: (112, 16) 128, 96, 1792, 7\n",
      "- 14 / 8: (16, 1.7) fractional\n",
      "Trying another promising first operation:\n",
      "6. 14 *2: (28, 8, 8)\n",
      "- 28 + 8: (36, 8) 44, 28, 288, fractional\n",
      "- 28 - 8: (20, 8) 28, 12, 160, fractional\n",
      "- 28 *8: (224, 8) 232, 216, 1792, 28\n",
      "- 28 / 8: (8, 3.5) fractional, fractional, 28, fractional\n",
      "- 8 + 8: (16, 16 32, 0, 256, 1\n",
      "- 8 - 8: (16, 0) 16, 16, 0, undefined\n",
      "- 8 *8: (64, 16) 80, 48, 1024, 4\n",
      "- 8 / 8: (16, 1) 17, 15, 16, 16\n",
      "Trying another promising first operation:\n",
      "7. 8 / 2: (14, 8, 4)\n",
      "- 14 + 8: (22, 4) 26, 18, 88, fractional\n",
      "- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 2 = 4\n",
      "Step 2:\n",
      "14 - 8 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\n",
      "answer: (14 - 8) *(8 / 2) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "9 5 5 5\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 9 - 5: (5, 5, 4)\n",
      "- 5 + 5: (10, 4) 14, 6, 40, fractional\n",
      "- 5 - 5: (4, 0) 4, 4, 0, undefined\n",
      "- 5 *5: (25, 4) 29, 21, 100, fractional\n",
      "- 5 / 5: (4, 1) 5, 3, 4, 4\n",
      "- 5 + 4: (9, 5) 14, 4, 45, fractional\n",
      "- 5 - 4: (5, 1) 6, 4, 5, 0.2\n",
      "- 5 *4: (20, 5) 25, 15, 100, fractional\n",
      "- 5 / 4: fractional\n",
      "Trying another promising first operation:\n",
      "2. 5 *5: (25, 9, 5)\n",
      "- 25 + 9: (34, 5) 39, 29, 170, fractional\n",
      "- 25 - 9: (16, 5) 21, 11, 80, fractional\n",
      "- 25 *9: (225, 5) 230, 220, 1125, 45\n",
      "- 25 / 9: (5, 2.7) fractional\n",
      "- 25 + 5: (30, 9) 39, 21, 270, fractional\n",
      "- 25 - 5: (20, 9) 29, 11, 180, fractional\n",
      "- 25 *5: (75, 9) 84, 66, 675, fractional\n",
      "- 25 / 5: (9, 5) 14, 4, 45, fractional\n",
      "- 9 + 5: (25, 14) 39, 11, 350, fractional\n",
      "- 9 - 5: (25, 4) 29, 21, 100, fractional\n",
      "- 9 *5: (45, 25) 70, 20, 1125, fractional\n",
      "- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\n",
      "Trying another promising first operation:\n",
      "3. 5 - 5: (9, 5, 0)\n",
      "- 9 + 5: (25, 14) 39, 11, 350, fractional\n",
      "- 9 - 5: (25, 4) 29, 21, 100, fractional\n",
      "- 9 *5: (45, 25) 70, 20, 1125, fractional\n",
      "- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\n",
      "- 9 + 0: (9, 5) 14, 4, 45, fractional\n",
      "- 9 - 0: (9, 5) 14, 4, 45, fractional\n",
      "- 9 *0: (5, 0) 5, 5, 0, undefined\n",
      "- 9 / 0: undefined\n",
      "- 5 + 0: (9, 5) 14, 4, 45, fractional\n",
      "- 5 - 0: (9, 5) 14, 4, 45, fractional\n",
      "- 5 *0: (9, 0) 9, 9, 0, undefined\n",
      "- 5 / 0: undefined\n",
      "Trying another promising first operation:\n",
      "4. 5 / 5: (9, 5, 1)\n",
      "- 9 + 5: (25, 14) 39, 11, 350, fractional\n",
      "- 9 - 5: (25, 4) 29, 21, 100, fractional\n",
      "- 9 *5: (45, 25) 70, 20, 1125, fractional\n",
      "- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\n",
      "- 9 + 1: (10, 5) 15, 5, 50, 2\n",
      "- 9 - 1: (8, 5) 13, 3, 40, fractional\n",
      "- 9 *1: (9, 5) 14, 4, 45, fractional\n",
      "- 9 / 1: (9, 5) 14, 4, 45, fractional\n",
      "- 5 + 1: (9, 6) 15, 3, 54, fractional\n",
      "- 5 - 1: (9, 4) 13, 5, 36, fractional\n",
      "- 5 *1: (9, 5) 14, 4, 45, fractional\n",
      "- 5 / 1: (9, 5) 14, 4, 45, fractional\n",
      "Trying another promising first operation:\n",
      "5. 9 *5: (45, 5, 5)\n",
      "- 45 + 5: (50, 5) 55, 45, 250, 10\n",
      "- 45 - 5: (40, 5) 45, 35, 200, 8\n",
      "- 45 *5: (225, 5) 230, 220, 1125, 45\n",
      "- 45 / 5: (9, 5) 14, 4, 45, fractional\n",
      "- 5 + 5: (10, 4) 14, 6, 40, fractional\n",
      "- 5 - 5: (4, 0) 4, 4, 0, undefined\n",
      "- 5 *5: (25, 4) 29, 21, 100, fractional\n",
      "- 5 / 5: (4, 1) 5, 3, 4, 4\n",
      "Trying another promising first operation:\n",
      "6. 5 + 5: (10, 9, 5)\n",
      "- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "5 + 5 = 10\n",
      "Step 2:\n",
      "10 + 9 = 19\n",
      "Step 3:\n",
      "19 + 5 = 24\n",
      "Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\n",
      "answer: ((5 + 5) + 9) + 5 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "8 6 4 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 *6: (48, 4, 4)\n",
      "- 48 + 4: (52, 4) 56, 48, 208, 13\n",
      "- 48 - 4: (44, 4) 48, 40, 176, 11\n",
      "- 48 *4: (192, 4) 196, 188, 768, 48\n",
      "- 48 / 4: (12, 4) 16, 8, 48, 3\n",
      "- 4 + 4: (48, 8) 56, 40, 384, 6\n",
      "- 4 - 4: (48, 0) 48, 48, 0, undefined\n",
      "- 4 *4: (48, 16) 64, 32, 768, 3\n",
      "- 4 / 4: (48, 1) 49, 47, 48, 48\n",
      "Trying another promising first operation:\n",
      "2. 4 - 4: (8, 6, 0)\n",
      "- 8 + 6: (14, 0) 14, 14, 0, undefined\n",
      "- 8 - 6: (2, 0) 2, 2, 0, undefined\n",
      "- 8 *6: (48, 0) 48, 48, 0, undefined\n",
      "- 8 / 6: (1.3, 0) fractional\n",
      "- 8 + 0: (8, 6) 14, 2, 48, fractional\n",
      "- 8 - 0: (8, 6) 14, 2, 48, fractional\n",
      "- 8 *0: (6, 0) 6, 6, 0, undefined\n",
      "- 8 / 0: undefined\n",
      "- 6 + 0: (8, 6) 14, 2, 48, fractional\n",
      "- 6 - 0: (8, 6) 14, 2, 48, fractional\n",
      "- 6 *0: (8, 0) 8, 8, 0, undefined\n",
      "- 6 / 0: undefined\n",
      "Trying another promising first operation:\n",
      "3. 4 / 4: (8, 6, 1)\n",
      "- 8 + 6: (14, 1) 15, 13, 14, 14\n",
      "- 8 - 6: (2, 1) 3, 1, 2, 2\n",
      "- 8 *6: (48, 1) 49, 47, 48, 48\n",
      "- 8 / 6: (1.3, 1) fractional\n",
      "- 8 + 1: (9, 6) 15, 3, 54, fractional\n",
      "- 8 - 1: (7, 6) 13, 1, 42, fractional\n",
      "- 8 *1: (8, 6) 14, 2, 48, fractional\n",
      "- 8 / 1: (8, 6) 14, 2, 48, fractional\n",
      "- 6 + 1: (8, 7) 15, 1, 56, fractional\n",
      "- 6 - 1: (8, 5) 13, 3, 40, fractional\n",
      "- 6 *1: (8, 6) 14, 2, 48, fractional\n",
      "- 6 / 1: (8, 1) 9, 7, 8, 8\n",
      "Trying another promising first operation:\n",
      "4. 8 - 6: (4, 4, 2)\n",
      "- 4 + 4: (8, 2) 10, 6, 16, 4\n",
      "- 4 - 4: (2, 0) 2, 2, 0, undefined\n",
      "- 4 *4: (16, 2) 18, 14, 32, 8\n",
      "- 4 / 4: (2, 1) 3, 1, 2, 2\n",
      "- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 - 6 = 2\n",
      "Step 2:\n",
      "4 + 2 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\n",
      "answer: (4 + (8 - 6)) *4 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "13 10 9 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 13 - 4: (10, 9, 9)\n",
      "- 10 + 9: (19, 9) 28, 10, 171, fractional\n",
      "- 10 - 9: (9, 1) 10, 8, 9, 9\n",
      "- 10 *9: (90, 9) 99, 81, 810, fractional\n",
      "- 10 / 9: fractional\n",
      "- 9 + 9: (18, 10) 28, 8, 180, fractional\n",
      "- 9 - 9: (10, 0) 10, 10, 0, undefined\n",
      "- 9 *9: (81, 10) 91, 71, 810, fractional\n",
      "- 9 / 9: (10, 1) 11, 9, 10, 10\n",
      "Trying another promising first operation:\n",
      "2. 13 / 10: (9, 4, 1.3)\n",
      "- 9 + 4: (13, 1.3) fractional, fractional, fractional, 10\n",
      "- 9 - 4: (5, 1.3) fractional\n",
      "- 9 *4: (36, 1.3) fractional\n",
      "- 9 / 4: (2.3, 1.3) fractional, 1, fractional, fractional\n",
      "- 9 + 1.3: (10.3, 4) fractional\n",
      "- 9 - 1.3: (7.7, 4) fractional\n",
      "- 9 *1.3: (11.7, 4) fractional\n",
      "- 9 / 1.3: (6.9, 4) fractional\n",
      "- 4 + 1.3: (9, 5.3) fractional\n",
      "- 4 - 1.3: (9, 2.7) fractional\n",
      "- 4 *1.3: (9, 5.2) fractional\n",
      "- 4 / 1.3: (9, 3.1) fractional\n",
      "Trying another promising first operation:\n",
      "3. 9 / 4: (13, 10, 2.3)\n",
      "- 13 + 10: (23, 2.3) fractional, fractional, fractional, 10\n",
      "- 13 - 10: (3, 2.3) fractional\n",
      "- 13 *10: (130, 2.3) fractional\n",
      "- 13 / 10: (2.3, 1.3) fractional, 1, fractional, fractional\n",
      "- 13 + 2.3: (15.3, 10) fractional, fractional, 153, fractional\n",
      "- 13 - 2.3: (11.7, 10) fractional, fractional, 117, fractional\n",
      "- 13 *2.3: (29.9, 10) fractional, fractional, 299, fractional\n",
      "- 13 / 2.3: (10, 5.6) fractional, fractional, 560, fractional\n",
      "- 10 + 2.3: (13, 12.3) fractional\n",
      "- 10 - 2.3: (13, 7.7) fractional\n",
      "- 10 *2.3: (23, 13) 36, 10, 299, fractional\n",
      "- 10 / 2.3: (13, 4.3) fractional\n",
      "Trying another promising first operation:\n",
      "4. 13 / 4: (10, 9, 3.3)\n",
      "- 10 + 9: (19, 3.3) fractional\n",
      "- 10 - 9: (3.3, 1) fractional\n",
      "- 10 *9: (90, 3.3) fractional\n",
      "- 10 / 9: (3.3, 1.1) fractional, fractional, fractional, 3\n",
      "- 10 + 3.3: (13.3, 9) fractional\n",
      "- 10 - 3.3: (9, 6.7) fractional\n",
      "- 10 *3.3: (33, 9) 42, 24, 297, fractional\n",
      "- 10 / 3.3: (3.1, 9) fractional\n",
      "- 9 + 3.3: (12.3, 10) fractional, fractional, 123, fractional\n",
      "- 9 - 3.3: (10, 5.7) fractional, fractional, 57, fractional\n",
      "- 9 *3.3: (29.7, 10) fractional, fractional, 297, fractional\n",
      "- 9 / 3.3: (10, 2.7) fractional, fractional, 27, fractional\n",
      "Trying another promising first operation:\n",
      "5. 13 / 9: (10, 9, 1.4)\n",
      "- 10 + 9: (19, 1.4) fractional\n",
      "- 10 - 9: (1.4, 1) fractional\n",
      "- 10 *9: (90, 1.4) fractional, fractional, 130, fractional\n",
      "- 10 / 9: (1.1, 1.4) fractional\n",
      "- 10 + 1.4: (11.4, 9) fractional\n",
      "- 10 - 1.4: (9, 8.6) fractional\n",
      "- 10 *1.4: (140, 9) 149, 131, 1260, fractional\n",
      "- 10 / 1.4: (9, 7.1) fractional\n",
      "- 9 + 1.4: (10.4, 10) fractional, fractional, 104, fractional\n",
      "- 9 - 1.4: (10, 7.6) fractional, fractional, 76, fractional\n",
      "- 9 *1.4: (12.6, 10) fractional, fractional, 126, fractional\n",
      "- 9 / 1.4: (10, 6.4) fractional, fractional, 64, fractional\n",
      "Trying another promising first operation:\n",
      "6. 10 - 4: (13, 9, 6)\n",
      "- 13 + 9: (22, 6) 28, 16, 132, fractional\n",
      "- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "10 - 4 = 6\n",
      "Step 2:\n",
      "13 - 9 = 4\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\n",
      "answer: (10 - 4) *(13 - 9) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "AoT (Random)\n",
      "System:\n",
      "Use numbers and basic arithmetic operations (+ - */) to obtain 24. Each step, you\n",
      "are only allowed to choose two of the remaining numbers to obtain a new\n",
      "number.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "4 4 6 8.\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "(4 + 4) *6 - 8 = 40.\n",
      "Trying another promising first operation:\n",
      "(8 - 6) *4 + 4 = 12.\n",
      "Trying another promising first operation:\n",
      "(6 - 4) *(4 + 8) = 24.\n",
      "answer: (6 - 4) *(4 + 8) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "2 9 10 12.\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "((12 - 10) / 2) + 9 = 10.\n",
      "Trying another promising first operation:\n",
      "(10 + 9) + (12 / 2) = 25.\n",
      "Trying another promising first operation:\n",
      "(12 *2)*(10 - 9) = 24.\n",
      "answer: (12 *2)*(10 - 9) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "4 9 10 13.\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "((13 - 10) / 4) + 9 = 10.\n",
      "Trying another promising first operation:\n",
      "4*(9 - (13 - 10)) = 24.\n",
      "answer: 4 *(9 - (13 - 10)) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "1 4 8 8.\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "(8 + 1) + 4 *8 + 32.\n",
      "Trying another promising first operation:\n",
      "(1 + 8 / 4) *8 = 24.\n",
      "answer: (1 + 8 / 4) *8 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "5 5 5 9.\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "((5 + 5) + 5) + 9 = 24.\n",
      "answer: ((5 + 5) + 5) + 9 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "AoT (BFS)\n",
      "System:\n",
      "Use numbers and basic arithmetic operations (+ - */) to obtain 24. When\n",
      "considering the next steps, do not choose operations that will result in a\n",
      "negative or fractional number. In order to help with the calculations, the\n",
      "numbers in the parenthesis represent the numbers that are left after the\n",
      "operations and they are in descending order.\n",
      "Another thing we do is when there are only two numbers left in the parenthesis, we\n",
      "check whether we can arrive at 24 only by using basic arithmetic operations\n",
      "(+ - */). Some examples regarding this idea:\n",
      "(21, 2): 23, 19, 42, fractional\n",
      "(30, 6): 36, 24 = 30 - 6 -> found it!\n",
      "(8, 3): 11, 5, 24 = 8 *3 yes\n",
      "(12, 8): 20, 4, 72, fractional\n",
      "In the second steps, when there are three numbers left, we choose the most\n",
      "promising operations so that when we are left with two numbers, we will be\n",
      "able to get to 24.\n",
      "So, when we reach 24 in the third steps, that means we found the solution, we\n",
      "directly backtrack to write the answer.\n",
      "In each step, we want to choose the best operations so that the numbers left, will\n",
      "have a good chance to reach 24.\n",
      "User:\n",
      "14 8 8 2\n",
      "Assistant:\n",
      "Let’s consider the most promising possible first steps:\n",
      "1. 8 + 8: (16, 14, 2)\n",
      "2. 14 - 8: (8, 6, 2)\n",
      "3. 14 + 2: (16, 8, 8)\n",
      "4. 8 / 2: (14, 8, 4)\n",
      "Let’s consider the most promising second steps:\n",
      "1. (16, 14, 2)\n",
      "- 16 - 14: (2, 2)\n",
      "- 16 / 2: (8, 14)\n",
      "- 14 *2: (28, 16)\n",
      "- 14 / 2: (7, 16)\n",
      "2. (8, 6, 2)\n",
      "- 8 - 6: (2, 2)\n",
      "- 8 / 2: (4, 6)\n",
      "- 6 *2: (12, 8)\n",
      "- 6 / 2: (3, 8)\n",
      "3. (16, 8, 8)\n",
      "- 16 - 8: (8, 8)\n",
      "- 16 / 8: (2, 8)\n",
      "- 8 *8: (64, 16)\n",
      "- 8 / 8: (1, 16)\n",
      "4. (14, 8, 4)\n",
      "- 14 - 8: (6, 4)\n",
      "- 14 / 4: (3.5, 8)\n",
      "- 8 *4: (32, 14)\n",
      "- 8 / 4: (2, 14)\n",
      "Let’s consider the most promising third steps:\n",
      "1. 8 + 8 = 16\n",
      "- 16 - 14: (2, 2): 4, 0, 4, 1\n",
      "- 16 / 2: (8, 14): 22, 6, 112, fractional\n",
      "- 14 *2: (28, 16): 44, 12, 448, fractional\n",
      "- 14 / 2: (7, 16): 23, 9, 112, fractional\n",
      "2. 14 - 8 = 6\n",
      "- 8 - 6: (2, 2): 4, 0, 4, 1\n",
      "- 8 / 2: (6, 4): 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "14 - 8 = 6\n",
      "Step 2:\n",
      "8 / 2 = 4\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (14 - 8) *(8 / 2) = 24.\n",
      "answer: (14 - 8) *(8 / 2) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "9 5 5 5\n",
      "Assistant:\n",
      "Let’s consider the most promising first steps:\n",
      "1. 9 - 5: (5, 5, 4)\n",
      "2. 5 + 5: (9, 10, 5)\n",
      "3. 9 + 5: (14, 5, 5)\n",
      "4. 5 - 5: (9, 5, 0)\n",
      "Let’s consider the most promising second steps:\n",
      "1. (5, 5, 4)\n",
      "- 5 + 5: (10, 4)\n",
      "- 5 *4: (20, 5)\n",
      "- 5 - 4: (5, 1)\n",
      "- 5 / 4: (5, 1.25)\n",
      "2. (9, 10, 5)\n",
      "- 10 + 9: (19, 5)\n",
      "- 10 - 5: (9, 5)\n",
      "- 10 *5: (50, 9)\n",
      "- 10 / 5: (9, 2)\n",
      "3. (14, 5, 5)\n",
      "- 14 - 5: (9, 5)\n",
      "- 14 + 5: (19, 5)\n",
      "- 5 *5: (25, 14)\n",
      "- 5 / 5: (14, 1)\n",
      "4. (9, 5, 0)\n",
      "- 9 + 5: (14, 0)\n",
      "- 9 - 5: (4, 0)\n",
      "- 5 *0: (9, 0)\n",
      "- 5 / 0: (9, infinity)\n",
      "Let’s consider the most promising third steps:\n",
      "1. 9 - 5 = 4\n",
      "- 5 + 5: (10, 4): 14, 6, 40, fractional\n",
      "- 5 *4: (20, 5): 25, 15, 100, 4\n",
      "- 5 - 4: (5, 1): 6, 4, 5, 5\n",
      "- 5 / 4: (5, 1.25): 6.25, 3.75, 6.25, 4\n",
      "2. 5 + 5 = 10\n",
      "- 10 + 9: (19, 5): 24 = 19 + 5 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "5 + 5 = 10\n",
      "Step 2:\n",
      "10 + 9 = 19\n",
      "Step 3:\n",
      "19 + 5 = 24\n",
      "Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\n",
      "answer: ((5 + 5) + 9) + 5 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "8 6 4 4\n",
      "Assistant:\n",
      "Let’s consider the most promising first steps:\n",
      "1. 8 *6: (48, 4, 4)\n",
      "2. 8 + 4: (12, 6, 4)\n",
      "3. 8 - 6: (4, 4, 2)\n",
      "4. 6 - 4: (8, 4, 2)\n",
      "Let’s consider the most promising second steps:\n",
      "1. (48, 4, 4)\n",
      "- 4 *4: (48, 16)\n",
      "- 48 / 4: (12, 4)\n",
      "- 4 + 4: (48, 8)\n",
      "- 48 - 4: (44, 4)\n",
      "2. (12, 6, 4)\n",
      "- 12 + 6: (18, 4)\n",
      "- 6 *4: (24, 12)\n",
      "- 6 + 4: (12, 10)\n",
      "- 12 / 4: (6, 3)\n",
      "3. (4, 4, 2)\n",
      "- 4 *4: (16, 2)\n",
      "- 4 + 2: (6, 4)\n",
      "- 4 + 4: (8, 2)\n",
      "- 4 *2: (8, 4)\n",
      "4. (8, 4, 2)\n",
      "- 8 *4: (32, 2)\n",
      "- 4 *2: (8, 8)\n",
      "- 8 + 4: (12, 2)\n",
      "- 8 / 4: (4, 2)\n",
      "Let’s consider the most promising third steps:\n",
      "1. 8 *6 = 48\n",
      "- 4 *4: (48, 16): 64, 32, big, 3\n",
      "- 48 / 4: (12, 4): 16, 8, 48, 3\n",
      "- 4 + 4: (48, 8): 56, 40, big, 6\n",
      "- 48 - 4: (44, 4): 48, 40, big, 11\n",
      "2. 8 + 4 = 12\n",
      "- 12 + 6: (18, 4): 22, 14, 72, fractional\n",
      "- 6 *4: (24, 12): 36, 12, 288, 2\n",
      "- 6 + 4: (12, 10): 22, 2, 120, fractional\n",
      "- 12 / 4: (6, 3): 9, 3, 18, 2\n",
      "3. 8 - 6 = 2\n",
      "- 4 *4: (16, 2): 19, 14, 32, 8\n",
      "- 4 + 2: (6, 4): 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 - 6 = 2\n",
      "Step 2:\n",
      "4 + 2 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\n",
      "answer: (4 + (8 - 6)) *4 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "13 10 9 4\n",
      "Assistant:\n",
      "Let’s consider the most promising first steps:\n",
      "1. 13 - 4: (10, 9, 9)\n",
      "2. 10 - 4: (13, 9, 6)\n",
      "3. 13 + 9: (22, 10, 4)\n",
      "4. 10 - 9: (13, 4, 1)\n",
      "Let’s consider the most promising second steps:\n",
      "1. (10, 9, 9)\n",
      "- 10 + 9: (19, 9)\n",
      "- 10 - 9: (9, 1)\n",
      "- 9 + 9: (18, 10)\n",
      "- 9 / 9: (9, 1)\n",
      "2. (13, 9, 6)\n",
      "- 9 + 6: (15, 13)\n",
      "- 9 *6: (54, 13)\n",
      "- 13 - 9: (6, 4)\n",
      "- 13 - 6: (9, 7)\n",
      "3. (22, 10, 4)\n",
      "- 22 - 10: (12, 4)\n",
      "- 22 - 4: (18, 10)\n",
      "- 10 *4: (40, 22)\n",
      "- 10 / 4: (22, 5.5)\n",
      "4. (13, 4, 1)\n",
      "- 13 - 4: (9, 1)\n",
      "- 13 *4: (52, 1)\n",
      "- 4 - 1: (13, 3)\n",
      "- 13 - 1: (12, 4)\n",
      "Let’s consider the most promising third steps:\n",
      "1. 13 - 4 = 9\n",
      "- 10 + 9: (19, 9): 28, 10, 171, fractional\n",
      "- 10 - 9: (9, 1): 10, 8, 9, 9\n",
      "- 9 + 9: (18, 10): 28, 8, 180, fractional\n",
      "- 9 / 9: (9, 1): 10, 8, 9, 9\n",
      "2. 10 - 4 = 6\n",
      "- 9 + 6: (15, 13): 28, 2, 195, fractional\n",
      "- 9 *6: (54, 13): 67, 41, 702, fractional\n",
      "- 13 - 9: (6, 4): 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "13 - 9 = 4\n",
      "Step 2:\n",
      "10 - 4 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (10 - 4) *(13 - 9) = 24.\n",
      "answer: (10 - 4) *(13 - 9) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "8 8 5 4\n",
      "Assistant:\n",
      "Let’s consider the most promising first steps:\n",
      "1. 5 + 4: (9, 8, 8)\n",
      "2. 8 / 4: (8, 5, 2)\n",
      "3. 8 - 5: (8, 4, 3)\n",
      "4. 8 / 8: (5, 4, 1)\n",
      "Let’s consider the most promising second steps:\n",
      "1. (9, 8, 8)\n",
      "- 9 + 8: (17, 8)\n",
      "- 8 + 8: (16, 9)\n",
      "- 9 *8: (72, 8)\n",
      "- 8 / 8: (9, 1)\n",
      "2. (8, 5, 2)\n",
      "- 5 - 2: (8, 3)\n",
      "- 8 - 2: (6, 5)\n",
      "- 8 + 5: (13, 2)\n",
      "- 5 *2: (10, 8)\n",
      "3. (8, 4, 3)\n",
      "- 8 - 4: (4, 3)\n",
      "- 8 - 3: (5, 4)\n",
      "- 4 *3: (12, 8)\n",
      "- 4 + 3: (8, 7)\n",
      "4. (5, 4, 1)\n",
      "- 5 + 4: (9, 1)\n",
      "- 5 - 4: (1, 1)\n",
      "- 4 - 1: (5, 3)\n",
      "- 5 + 1: (6, 4)\n",
      "Let’s consider the most promising third steps:\n",
      "1. 5 + 4 = 9\n",
      "- 9 + 8: (17, 8): 25, 9, 136, fractional\n",
      "- 8 + 8: (16, 9): 25, 7, 144, fractional\n",
      "- 9 *8: (72, 8): 80, 64, 576, 9\n",
      "- 8 / 8: (9, 1): 10, 8, 9, 9\n",
      "2. 8 / 4 = 2\n",
      "- 5 - 2: (8, 3): 11, 5, 24 = 8 *3 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 4 = 2\n",
      "Step 2:\n",
      "5 - 2 = 3\n",
      "Step 3:\n",
      "8*3 = 24\n",
      "Considering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\n",
      "answer: 8 *(5 - (8 / 4)) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "11 11 1 1\n",
      "Assistant:\n",
      "Let’s consider the most promising first steps:\n",
      "1. 11 - 1: (11, 10, 1)\n",
      "2. 11 + 1: (12, 11, 1)\n",
      "3. 11 + 11: (22, 1, 1)\n",
      "4. 1 + 1: (11, 11, 2)\n",
      "Let’s consider the most promising second steps:\n",
      "1. (11, 10, 1)\n",
      "- 11 + 10: (21, 1)\n",
      "- 10 + 1: (11, 11)\n",
      "- 10 / 1: (11, 10)\n",
      "- 11 / 1: (11, 10)\n",
      "2. (12, 11, 1)\n",
      "- 12 + 11: (23, 1)\n",
      "- 11 + 1: (12, 11)\n",
      "- 11 - 1: (12, 10)\n",
      "- 12 + 1: (13, 11)\n",
      "3. (22, 1, 1)\n",
      "- 22 + 1: (23, 1)\n",
      "- 1 + 1: (22, 2)\n",
      "- 22 / 1: (22, 1)\n",
      "- 1 / 1: (22, 1)\n",
      "4. (11, 11, 2)\n",
      "- 11 + 11: (22, 2)\n",
      "- 11 *2: (22, 11)\n",
      "- 11 + 2: (13, 11)\n",
      "- 2 *11: (22, 11)\n",
      "Let’s consider the most promising third steps:\n",
      "1. 11 - 1 = 10\n",
      "- 11 + 10: (21, 1): 22, 20, 21, 20\n",
      "- 10 + 1: (11, 11): 22, 10, 121, 0\n",
      "- 10 / 1: (11, 10): 21, 1, 110, 0\n",
      "- 11 / 1: (11, 10): 21, 1, 110, 0\n",
      "2. 11 + 1 = 12\n",
      "- 12 + 11: (23, 1): 24 = 23 + 1 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11 + 1 = 12\n",
      "Step 2:\n",
      "12 + 11 = 23\n",
      "Step 3:\n",
      "23 + 1 = 24\n",
      "Considering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\n",
      "answer: ((11 + 1) + 11) + 1 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "11 7 4 1\n",
      "Assistant:\n",
      "Let’s consider the most promising first steps:\n",
      "1. 7 *4: (28, 11, 1)\n",
      "2. 7 + 1: (11, 8, 4)\n",
      "3. 4 + 1: (11, 7, 5)\n",
      "4. 11 - 4: (7, 3, 1)\n",
      "Let’s consider the most promising second steps:\n",
      "1. (28, 11, 1)\n",
      "- 28 - 11: (17, 1)\n",
      "- 28 - 1: (27, 11)\n",
      "- 11 + 1: (29, 28)\n",
      "- 11 - 1: (28, 10)\n",
      "2. (11, 8, 4)\n",
      "- 11 + 8: (19, 4)\n",
      "- 8 + 4: (12, 11)\n",
      "- 11 - 8: (4, 3)\n",
      "- 8 - 4: (7, 11)\n",
      "3. (11, 7, 5)\n",
      "- 11 - 5: (7, 6)\n",
      "- 7 - 5: (11, 2)\n",
      "- 7 *5: (35, 11)\n",
      "- 11 + 5: (16, 7)\n",
      "4. (7, 3, 1)\n",
      "- 7 - 3: (4, 1)\n",
      "- 7 *3: (21, 1)\n",
      "- 3 + 1: (7, 4)\n",
      "- 7 - 1: (6, 3)\n",
      "Let’s consider the most promising third steps:\n",
      "1. 7 *4 = 28\n",
      "- 28 - 11: (17, 1): 18, 16, 17, 17\n",
      "- 28 - 1: (27, 11): 38, 16, 297, 2.45\n",
      "- 11 + 1: (29, 28): 57, 1, 812, 1.03\n",
      "- 11 - 1: (28, 10): 38, 18, 280, 2.8\n",
      "2. 7 + 1 = 8\n",
      "- 11 + 8: (19, 4): 23, 15, 76, 4.75\n",
      "- 8 + 4: (12, 11): 23, 7, 132, 3\n",
      "- 11 - 8: (4, 3): 7, 1, 12, 1.33\n",
      "- 8 - 4: (7, 11): 18, 4, 77, 1.75\n",
      "3. 4 + 1 = 5\n",
      "- 11 - 5: (7, 6): 13, 1, 42, 1.17\n",
      "- 7 - 5: (11, 2): 13, 9, 22, 5.5\n",
      "- 7 *5: (35, 11): 46, 24 = 35 - 11 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "4 + 1 = 5\n",
      "Step 2:\n",
      "7*5 = 35\n",
      "Step 3:\n",
      "35 - 11 = 24\n",
      "Considering these steps: 24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\n",
      "answer: (7 *(4 + 1)) - 11 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "11 5 4 3\n",
      "Assistant:\n",
      "Let’s consider the most promising first steps to reach 24:\n",
      "1. 11 *3: (33, 5, 4)\n",
      "2. 5 + 4: (11, 9, 3)\n",
      "3. 11 - 4: (7, 5, 3)\n",
      "4. 4 + 3: (11, 7, 5)\n",
      "Let’s consider the most promising second steps to reach 24:\n",
      "1. (33, 5, 4)\n",
      "- 33 - 5: (28, 4)\n",
      "- 33 - 4: (29, 5)\n",
      "- 5 + 4: (33, 9)\n",
      "- 5 *4: (20, 33)\n",
      "2. (11, 9, 3)\n",
      "- 11 *3: (33, 9)\n",
      "- 11 + 3: (14, 9)\n",
      "- 9 + 3: (12, 11)\n",
      "- 9 / 3: (11, 3)\n",
      "3. (7, 5, 3)\n",
      "- 7 - 3: (4, 5)\n",
      "- 7 + 5: (12, 3)\n",
      "- 5 + 3: (8, 7)\n",
      "- 5 *3: (7, 6)\n",
      "4. (11, 7, 5)\n",
      "- 11 + 7: (18, 5)\n",
      "- 11 - 5: (6, 7)\n",
      "- 7 + 5: (12, 11)\n",
      "- 7 - 5: (2, 11)\n",
      "Let’s consider the most promising third steps to reach 24:\n",
      "1. 11 *3 = 33\n",
      "- 33 - 5: (28, 4): 32, 24 = 28 - 4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11*3 = 33\n",
      "Step 2:\n",
      "33 - 5 = 28\n",
      "Step 3:\n",
      "28 - 4 = 24\n",
      "Considering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\n",
      "answer: ((11 *3) - 5) - 4 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "13 12 5 2\n",
      "Assistant:\n",
      "Let’s consider the most promising first steps to reach 24:\n",
      "1. 12 / 2: (13, 6, 5)\n",
      "2. 13 + 5: (18, 12, 2)\n",
      "3. 12 - 5: (13, 7, 2)\n",
      "4. 5 - 2: (13, 12, 3)\n",
      "Let’s consider the most promising second steps to reach 24:\n",
      "1. (13, 6, 5)\n",
      "- 13 + 6: (19, 5)\n",
      "- 13 - 5: (8, 6)\n",
      "- 6 *5: (30, 13)\n",
      "- 6 - 5: (13, 1)\n",
      "2. (18, 12, 2)\n",
      "- 18 *2: (36, 12)\n",
      "- 12 / 2: (18, 6)\n",
      "- 18 - 2: (16, 12)\n",
      "- 12 *2: (24, 18)\n",
      "3. (13, 7, 2)\n",
      "- 13 + 7: (20, 2)\n",
      "- 13 - 2: (11, 7)\n",
      "- 7 *2: (14, 13)\n",
      "- 7 - 2: (13, 5)\n",
      "4. (13, 12, 3)\n",
      "- 13 *3: (39, 12)\n",
      "- 13 - 3: (10, 12)\n",
      "- 12 *3: (36, 13)\n",
      "- 12 / 3: (13, 4)\n",
      "Let’s consider the most promising third steps to reach 24:\n",
      "1. 12 / 2 = 6\n",
      "- 13 + 6: (19, 5): 24 = 19 + 5 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "12 / 2 = 6\n",
      "Step 2:\n",
      "13 + 6 = 19\n",
      "Step 3:\n",
      "19 + 5 = 24\n",
      "Considering these steps: 24 = 19 + 5 = (13 + 6) + 5 = (13 + (12 / 2)) + 5 = 24.\n",
      "answer: (13 + (12 / 2)) + 5 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "9 8 2 1\n",
      "Assistant:\n",
      "Let’s consider the most promising first steps to reach 24:\n",
      "1. 9 - 1: (8, 8, 2)\n",
      "2. 8 + 2: (10, 9, 1)\n",
      "3. 9 + 1: (10, 8, 2)\n",
      "4. 2 + 1: (9, 8, 3)\n",
      "Let’s consider the most promising second steps to reach 24:\n",
      "1. (8, 8, 2)\n",
      "- 8 + 8: (16, 2)\n",
      "- 8 *2: (16, 8)\n",
      "- 8 - 2: (6, 8)\n",
      "- 8 + 8: (16, 2)\n",
      "2. (10, 9, 1)\n",
      "- 10 + 9: (19, 1)\n",
      "- 10 - 1: (9, 9)\n",
      "- 9 + 1: (10, 10)\n",
      "- 9 / 1: (8, 10)\n",
      "3. (10, 8, 2)\n",
      "- 10 + 8: (18, 2)\n",
      "- 10 *2: (8, 8)\n",
      "- 8 + 2: (10, 10)\n",
      "- 8 / 2: (6, 10)\n",
      "4. (9, 8, 3)\n",
      "- 9 + 8: (17, 3)\n",
      "- 9 / 3: (6, 8)\n",
      "- 8 + 3: (11, 9)\n",
      "- 8 *3: (24, 9)\n",
      "Let’s consider the most promising third steps to reach 24:\n",
      "1. 9 - 1 = 8\n",
      "- 8 + 8: (16, 2): 18, 14, 32, 8\n",
      "- 8 *2: (16, 8): 24 = 16 + 8 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "9 - 1 = 8\n",
      "Step 2:\n",
      "8*2 = 16\n",
      "Step 3:\n",
      "16 + 8 = 24\n",
      "Considering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\n",
      "answer: ((9 - 1) *2) + 8 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "AoT (Short)\n",
      "System:\n",
      "Use numbers and basic arithmetic operations (+ - */) to obtain 24. When\n",
      "considering the next steps, do not choose operations that will result in a\n",
      "negative or fractional number. In order to help with the calculations, the\n",
      "numbers in the parenthesis represent the numbers that are left after the\n",
      "operations and they are in descending order.\n",
      "Another thing we do is when there are only two numbers left in the parenthesis, we\n",
      "check whether we can arrive at 24 only by using basic arithmetic operations\n",
      "(+ - */). Some examples regarding this idea:\n",
      "(21 2) no\n",
      "since 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\n",
      "to 24.\n",
      "(30 6) 30 - 6 = 24 yes\n",
      "(8 3) 8 *3 = 24 yes\n",
      "(12 8) no\n",
      "(48 2) 48 / 2 = 24 yes\n",
      "Most importantly, do not give up, all the numbers that will be given has indeed a\n",
      "solution.\n",
      "User:\n",
      "14 8 8 2\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 / 2: (14, 8, 4)\n",
      "- 14 + 8: (22, 4) 26, 18, 88, fractional\n",
      "- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 2 = 4\n",
      "Step 2:\n",
      "14 - 8 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\n",
      "answer: (14 - 8) *(8 / 2) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "9 5 5 5\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 5 + 5: (10, 9, 5)\n",
      "- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "5 + 5 = 10\n",
      "Step 2:\n",
      "10 + 9 = 19\n",
      "Step 3:\n",
      "19 + 5 = 24\n",
      "Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\n",
      "answer: ((5 + 5) + 9) + 5 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "8 6 4 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 - 6: (4, 4, 2)\n",
      "- 4 + 4: (8, 2) 10, 6, 16, 4\n",
      "- 4 - 4: (2, 0) 2, 2, 0, undefined\n",
      "- 4 *4: (16, 2) 18, 14, 32, 8\n",
      "- 4 / 4: (2, 1) 3, 1, 2, 2\n",
      "- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 - 6 = 2\n",
      "Step 2:\n",
      "4 + 2 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\n",
      "answer: (4 + (8 - 6)) *4 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "13 10 9 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 10 - 4: (13, 9, 6)\n",
      "- 13 + 9: (22, 6) 28, 16, 132, fractional\n",
      "- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "10 - 4 = 6\n",
      "Step 2:\n",
      "13 - 9 = 4\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\n",
      "answer: (10 - 4) *(13 - 9) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "8 8 5 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 / 4: (8, 5, 2)\n",
      "- 8 + 5: (13, 2) 15, 11, 26, fractional\n",
      "- 8 - 5: (3, 2) 5, 1, 6, 1.5\n",
      "- 8 *5: (40, 2) 42, 38, 80, 20\n",
      "- 8 / 5: fractional\n",
      "- 8 + 2: (10, 5) 15, 5, 50, 2\n",
      "- 8 - 2: (6, 5) 11, 1, 30, fractional\n",
      "- 8 *2: (16, 5) 21, 11, 80, fractional\n",
      "- 8 / 2: (5, 4) 9, 1, 20, fractional\n",
      "- 5 + 2: (7, 8) 15, 1, 56, fractional\n",
      "- 5 - 2: (8, 3) 11, 5, 24 = 8 *3 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 4 = 2\n",
      "Step 2:\n",
      "5 - 2 = 3\n",
      "Step 3:\n",
      "8*3 = 24\n",
      "Considering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\n",
      "answer: 8 *(5 - (8 / 4)) = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "11 11 1 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 11 + 1: (12, 11, 1)\n",
      "- 12 + 11: (23, 1) 24 = 23 + 1 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11 + 1 = 12\n",
      "Step 2:\n",
      "12 + 11 = 23\n",
      "Step 3:\n",
      "23 + 1\n",
      "Considering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\n",
      "answer: ((11 + 1) + 11) + 1 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "11 7 4 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 4 + 1: (11 7 5)\n",
      "- 11 + 7: (18, 5) 23, 13, 90, fractional\n",
      "- 11 - 7: (5, 4) 9, 1, 20, fractional\n",
      "- 11 *7: (77, 5) 82, 72, 385, fractional\n",
      "- 11 / 7: fractional\n",
      "- 11 + 5: (16, 7) 23, 9, 112, fractional\n",
      "- 11 - 5: (7, 6) 13, 1, 42, fractional\n",
      "- 11 *5: (55, 7) 62, 48, 385, fractional\n",
      "- 11 / 5: fractional\n",
      "- 7 + 5: (12, 11) 23, 1, 132, fractional\n",
      "- 7 - 5: (11, 2) 13, 9, 22, fractional\n",
      "- 7 *5: (35, 11) 46, 24 = 35 - 11 -> found it!\n",
      "Step 1:\n",
      "4 + 1 = 5\n",
      "Step 2:\n",
      "7*5 = 35\n",
      "Step 3:\n",
      "35 - 11 = 24\n",
      "Considering these steps: Backtracking the solution:\n",
      "24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\n",
      "answer: (7 *(4 + 1)) - 11 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "11 5 4 3\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 11 *3: (33, 5, 4)\n",
      "- 33 + 5: (38, 4) 42, 34, 152, fractional\n",
      "- 33 - 5: (28, 4) 32, 24 = 28 - 4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11*3 = 33\n",
      "Step 2:\n",
      "33 - 5 = 28\n",
      "Step 3:\n",
      "28 - 4 = 24\n",
      "Considering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\n",
      "answer: ((11 *3) - 5) - 4 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "13 12 5 2\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 13 + 5: (18, 12, 2)\n",
      "- 18 + 12: (30, 2) 32, 28, 60, fractional\n",
      "- 18 - 12: (6, 2) 8, 4, 12, 3\n",
      "- 18 *12: (216, 2) 218, 214, 432, fractional\n",
      "- 18 / 12: fractional\n",
      "- 18 + 2: (20, 12) 32, 8, 240, fractional\n",
      "- 18 - 2: (16, 12) 28, 4, 192, fractional\n",
      "- 18 *2: (36, 12) 48, 24 = 36 - 12 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "13 + 5 = 18\n",
      "Step 2:\n",
      "18*2 = 36\n",
      "Step 3:\n",
      "36 - 12 = 24\n",
      "Considering these steps: 24 = 36 - 12 = (18 *2) - 12 = ((13 + 5) *2) - 12 = 24.\n",
      "answer: ((13 + 5) *2) - 12 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "9 8 2 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 9 - 1: (8, 8, 2)\n",
      "- 8 + 8: (16, 2) 18, 14, 32, 8\n",
      "- 8 - 8: (2, 0) 2, 2, 0, undefined\n",
      "- 8 *8: (64, 2) 66, 62, 128, 32\n",
      "- 8 / 8: (2, 1) 3, 1, 2, 2\n",
      "- 8 + 2: (10, 8) 18, 2, 80, 4\n",
      "- 8 - 2: (6, 8) 14, -2, 48, fractional\n",
      "- 8 *2: (16, 8) 24 = 16 + 8 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "9 - 1 = 8\n",
      "Step 2:\n",
      "8*2 = 16\n",
      "Step 3:\n",
      "16 + 8 = 24\n",
      "Considering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\n",
      "answer: ((9 - 1) *2) + 8 = 24.\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "5×5Mini Crosswords Prompts\n",
      "In the following we give all the exact prompts we used for the methods given in the experiments section and some selection of\n",
      "the generations from the LLM. In the prompts the keywords “System”, “User” and “Assistant” used are the roles in the OpenAI\n",
      "API in chat completion mode. The line breaks are to show the turns between the user and assistant in the API.\n",
      "AoT\n",
      "User:\n",
      "h1. A lunar valley\n",
      "h2. A fatty oil\n",
      "h3. To entice\n",
      "h4. To lower; to reduce\n",
      "h5. A solitary person\n",
      "v1. According to the roster\n",
      "v2. Another name for Port-Francqui\n",
      "v3. An illicit lover; a European lake\n",
      "v4. To lisp\n",
      "v5. To come in\n",
      "The words I already found are:\n",
      "h1. rille\n",
      "h3. tempt\n",
      "v2. ilebo\n",
      "v5. enter\n",
      "Assistant:\n",
      "There are two horizontal and two vertical words. Since they are the amount, let’s\n",
      "consider the next unfound horizontal word, which is h2. Since we are\n",
      "considering the second horizontal word, we need to look at the second letters\n",
      "of the vertical words we found:\n",
      "- What is the second letter of ilebo: e\n",
      "- What is the second letter of enter: n\n",
      "The word we are looking fits the clue \"A fatty oil\" and needs to have the letters\n",
      "e and n in its (v2, two) second and (v5, five) fifth letters: _ e _ _ n. The\n",
      "candidates are: oleic, olein, olive.\n",
      "- oleic (o l e i c, _ e _ _ n) doesn’t fit\n",
      "- olein (o l e i n, _ e _ _ n) fits\n",
      "- olive (o l i v e, _ e _ _ n) doesn’t fit\n",
      "We add the word olein for h2. The current words are:\n",
      "h1. rille\n",
      "h2. olein\n",
      "h3. tempt\n",
      "v2. ilebo\n",
      "v5. enter\n",
      "Now, let’s consider the next unfound vertical word, which is v1. Since we are\n",
      "considering the first vertical word, we need to look at the first letters of\n",
      "the horizontal words we found:\n",
      "- What is the first letter of rille: r\n",
      "- What is the first letter of olein: o\n",
      "- What is the first letter of tempt: t\n",
      "The word we are looking fits the clue \"According to the roster\" and needs to have\n",
      "the letters r, o, and t in its (h1, one) first, (h2, two) second, and (h3,\n",
      "three) third letters: r o t _ _. The candidates are: none\n",
      "Now, let’s consider the next unfound vertical word, which is v3. Since we are\n",
      "considering the third vertical word, we need to look at the third letters of\n",
      "the horizontal words we found:\n",
      "- What is the third letter of rille: l\n",
      "- What is the third letter of olein: e\n",
      "- What is the third letter of tempt: m\n",
      "The word we are looking fits the clue \"An illicit lover; a European lake\" and\n",
      "needs to have the letters l, e, and m in its (h1, one) first, (h2, two) second\n",
      ", and (h3, three) third letters: l e m _ _. The candidates are: leman.\n",
      "- leman (l e m a n, l e m _ _) fits\n",
      "We add the word leman for v3. The current words are:\n",
      "h1. rille\n",
      "h2. olein\n",
      "h3. tempt\n",
      "v2. ilebo\n",
      "v3. leman\n",
      "v5. enter\n",
      "Now, let’s consider the next unfound horizontal word, which is h4. Since we are\n",
      "considering the fourth horizontal word, we need to look at the fourth letters\n",
      "of the vertical words we found:\n",
      "- What is the fourth letter of ilebo: b\n",
      "- What is the fourth letter of leman: a\n",
      "- What is the fourth letter of enter: e\n",
      "The word we are looking fits the clue \"To lower; to reduce\" and needs to have the\n",
      "letters b, a, and e in its (v2, two) second, (v3, three) third, and (v5, five)\n",
      "fifth letters: _ b a _ e. The candidates are: abase, abate.\n",
      "- abase (a b a s e, _ b a _ e) fits\n",
      "- abate (a b a t e, _ b a _ e) fits\n",
      "Since both fits, let’s consider another word.\n",
      "Now, let’s consider the last unfound vertical word, which is v4. Since we are\n",
      "considering the fourth vertical word, we need to look at the fourth letters of\n",
      "the horizontal words we found:\n",
      "- What is the fourth letter of rille: l\n",
      "- What is the fourth letter of olein: i\n",
      "- What is the fourth letter of tempt: p\n",
      "The word we are looking fits the clue \"To lisp\" and needs to have the letters l, i\n",
      ", p, and s in its (h1, one) first, (h2, two) second, (h3, three) third letters\n",
      ": l i p _ _. The candidates are: The candidate is \"lisps\".\n",
      "- lisps (l i s p s, l i p _ _) doesn’t fit\n",
      "We have considered all of the words for the horizontal words, we have two options:\n",
      "abase and abate, let’s choose one of them.\n",
      "answer:\n",
      "h1. rille\n",
      "h2. olein\n",
      "h3. tempt\n",
      "h4. abase\n",
      "v2. ilebo\n",
      "v3. leman\n",
      "v5. enter\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "h1. One who saws\n",
      "h2. A fungus genus\n",
      "h3. An assessor\n",
      "h4. Pasture land\n",
      "h5. Receiving by the ear\n",
      "v1. To swell; to increase\n",
      "v2. The Brazilian macaw; an Australian bird\n",
      "v3. A Timorese island\n",
      "v4. Excessive fluid accumulation\n",
      "v5. Dewy; roscid\n",
      "The words I already found are:\n",
      "h1. sawer\n",
      "h3. rater\n",
      "v1. surge\n",
      "v4. edema\n",
      "Assistant:\n",
      "There are two horizontal and two vertical words. Since they are the amount, let’s\n",
      "consider the next unfound horizontal word, which is h2. Since we are\n",
      "considering the second horizontal word, we need to look at the second letters\n",
      "of the vertical words we found:\n",
      "- What is the second letter of surge: u\n",
      "- What is the second letter of edema: d\n",
      "The word we are looking fits the clue \"A fungus genus\" and needs to have the\n",
      "letters u and d in its (v1, one) first and (v4, four) fourth letters: u _ _ d\n",
      "_. The candidates are: uredo.\n",
      "- uredo (u r e d o, u _ _ d _) fits\n",
      "We add the word uredo for h2. The current words are:\n",
      "h1. sawer\n",
      "h2. uredo\n",
      "h3. rater\n",
      "v1. surge\n",
      "v4. edema\n",
      "Now, let’s consider the next unfound vertical word, which is v2. Since we are\n",
      "considering the second vertical word, we need to look at the second letters of\n",
      "the horizontal words we found:\n",
      "- What is the second letter of sawer: a\n",
      "- What is the second letter of uredo: r\n",
      "- What is the second letter of rater: a\n",
      "The word we are looking fits the clue \"The Brazilian macaw; an Australian bird\"\n",
      "and needs to have the letters a, r, and a in its (h1, one) first, (h2, two)\n",
      "second, and (h3, third) third letters: a r a _ _. The candidates are: arara.\n",
      "- arara (a r a r a, a r a _ _) fits\n",
      "We add the word arara for v2. The current words are:\n",
      "h1. sawer\n",
      "h2. uredo\n",
      "h3. rater\n",
      "v1. surge\n",
      "v2. arara\n",
      "v4. edema\n",
      "Now, let’s consider the next unfound horizontal word, which is h4. Since we are\n",
      "considering the fourth horizontal word, we need to look at the fourth letters\n",
      "of the vertical words we found:\n",
      "- What is the fourth letter of surge: g\n",
      "- What is the fourth letter of arara: r\n",
      "- What is the fourth letter of edema: m\n",
      "the word we are looking fits the clue \"Pasture land\" and needs to have the letters\n",
      "g, r, and m in its (v1, one) first, (v2, two) second, and (v4, four) fourth\n",
      "letters: g r _ m _. The candidates are: grama.\n",
      "- grama (g r a m a, g r a _ _) fits\n",
      "We add the word grama for h4. The current words are:\n",
      "h1. Sawer\n",
      "h2. Uredos\n",
      "h3. Rater\n",
      "h4. Grama\n",
      "v1. surge\n",
      "v2. arara\n",
      "v4. edema\n",
      "Now, let’s consider the next unfound vertical word, which is v3. Since we are\n",
      "considering the third vertical word, we need to look at the third letters of\n",
      "the horizontal words we found:\n",
      "- What is the third letter of sawer: w\n",
      "- What is the third letter of uredo: e\n",
      "- What is the third letter of rater: t\n",
      "- What is the third letter of grama: a\n",
      "The word we are looking fits the clue \"A Timorese island\" and needs to have the\n",
      "letters w, e, t, and a in its (h1, one) first, (h2, two) second, (h3, three)\n",
      "third, and (h4, four) fourth letters: w e t a _. The candidates are: The\n",
      "candidate is \"wetar\".\n",
      "- wetar (w e t a r, w e t a _) fits\n",
      "We add the word wetar for v3. The current words are:\n",
      "h1. sawer\n",
      "h2. uredo\n",
      "h3. rater\n",
      "h4. grama\n",
      "v1. surge\n",
      "v2. arara\n",
      "v3. wetar\n",
      "v4. edema\n",
      "Now, let’s consider the last unfound horizontal word, which is h5. Since we are\n",
      "considering the fifth horizontal word, we need to look at the fifth letters of\n",
      "the vertical words we found:\n",
      "- What is the fifth letter of surge: e\n",
      "- What is the fifth letter of arara: a\n",
      "- What is the fifth letter of wetar: r\n",
      "- What is the fifth letter of edema: a\n",
      "The word we are looking fits the clue \"Receiving by the ear\" and needs to have the\n",
      "letters e, a, r, and a in its (v1, one) first, (v2, two) second, (v3, three)\n",
      "third, and (v4, four) fourth letters: e a r a _. The candidates are: The\n",
      "candidate is \"earal\".\n",
      "- earal (e a r a l, e a r a _) fits\n",
      "We add the word earal for h5. The current words are:\n",
      "h1. sawer\n",
      "h2. uredo\n",
      "h3. rater\n",
      "h4. grama\n",
      "h5. earal\n",
      "v1. surge\n",
      "v2. arara\n",
      "v3. wetar\n",
      "v4. edema\n",
      "Since we found all horizontal words:\n",
      "answer:\n",
      "h1. sawer\n",
      "h2. uredo\n",
      "h3. rater\n",
      "h4. grama\n",
      "h5. earal\n",
      "v1. surge\n",
      "v2. arara\n",
      "v3. wetar\n",
      "v4. edema\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "User:\n",
      "h1. Dandruff; scum; the bull-trout\n",
      "h2. One who greets; to vacillate; a British river\n",
      "h3. A Turkish written decree\n",
      "h4. Mignon; petty; little\n",
      "h5. A bishop’s permission for a priest to leave a diocese\n",
      "v1. To steal; to brush across\n",
      "v2. A sedge (a primitive three-sided grass)\n",
      "v3. Grape jam\n",
      "v4. A flatworm larva\n",
      "v5. Ore refuse; to prepare material for glass by heat\n",
      "h2. waver\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "Assistant:\n",
      "Let’s consider the next unfound horizontal word, which is h1. Since we are\n",
      "considering the first horizontal word, we need to look at the first letters of\n",
      "the vertical words we found:\n",
      "- What is the first letter of swipe: s\n",
      "- What is the first letter of carex: c\n",
      "The word we are looking fits the clue \"Dandruff; scum; the bull-trout\" and needs\n",
      "to have the letters s and c in its (v1, one) first and (v2, two) second\n",
      "letters: s c _ _ _. The candidates are: scurf.\n",
      "- scurf (s c u r f, s c _ _ _) fits\n",
      "We add the word scurf for h1. The current words are:\n",
      "h1. scurf\n",
      "h2. waver\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "Now, let’s consider the next unfound vertical word, which is v3. Since we are\n",
      "considering the third vertical word, we need to look at the third letters of\n",
      "the horizontal words we found:\n",
      "- What is the third letter of scurf: u\n",
      "- What is the third letter of waver: v\n",
      "- What is the third letter of exeat: e\n",
      "The word we are looking fits the clue \"Grape jam\" and needs to have the letters u,\n",
      "v, and e in its (h1, one) first, (h2, two) second, and (h5, five) fifth\n",
      "letters: u v _ _ e. The candidates are: The candidate is \"uvetta\".\n",
      "- uvetta (u v e t t a, u v _ _ e) doesn’t fit\n",
      "Let’s consider the next unfound vertical word, which is v4. Since we are\n",
      "considering the fourth vertical word, we need to look at the fourth letters of\n",
      "the horizontal words we found:\n",
      "- What is the fourth letter of scurf: r\n",
      "- What is the fourth letter of waver: e\n",
      "- What is the fourth letter of exeat: a\n",
      "The word we are looking fits the clue \"A flatworm larva\" and needs to have the\n",
      "letters r, e, and a in its (h1, one) first, (h2, two) second, and (h5, five)\n",
      "fifth letters: r e _ _ a. The candidates are: redia.\n",
      "- redia (r e d i a, r e _ _ a) fits\n",
      "We add the word redia for v4. The current words are:\n",
      "h1. scurf\n",
      "h2. waver\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "v4. redia\n",
      "Now, let’s consider the next unfound horizontal word, which is h3. Since we are\n",
      "considering the third horizontal word, we need to look at the third letters of\n",
      "the vertical words we found:\n",
      "- What is the third letter of swipe: i\n",
      "- What is the third letter of carex: r\n",
      "- What is the third letter of redia: d\n",
      "The word we are looking fits the clue \"A Turkish written decree\" and needs to have\n",
      "the letters i, r, and d in its (v1, one) first, (v2, two) second, and (v4,\n",
      "four) fourth letters: i r _ d _. The candidates are: irade.\n",
      "- irade (i r a d e, i r _ d _) fits\n",
      "We add the word irade for h3. The current words are:\n",
      "h1. scurf\n",
      "h2. waver\n",
      "h3. irade\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "v4. redia\n",
      "Now, let’s consider the last unfound vertical word, which is v5. Since we are\n",
      "considering the fifth vertical word, we need to look at the fifth letters of\n",
      "the horizontal words we found:\n",
      "- What is the fifth letter of scurf: f\n",
      "- What is the fifth letter of waver: r\n",
      "- What is the fifth letter of irade: e\n",
      "- What is the fifth letter of exeat: t\n",
      "The word we are looking fits the clue \"Ore refuse; to prepare material for glass\n",
      "by heat\" and needs to have the letters f, r, e, and t in its (h1, one) first,\n",
      "(h2, two) second, (h3, three) third, and (h5, five) fifth letters: f r e _ t.\n",
      "The candidates are: The candidate is \"frett\".\n",
      "- frett (f r e t t, f r e _ t) fits\n",
      "We add the word frett for v5. The current words are:\n",
      "h1. scurf\n",
      "h2. waver\n",
      "h3. irade\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "v4. redia\n",
      "v5. frett\n",
      "Since we found all horizontal words:\n",
      "answer:\n",
      "h1. scurf\n",
      "h2. waver\n",
      "h3. irade\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "v4. redia\n",
      "v5. frett\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "Propose Words\n",
      "User:\n",
      "h1. A lunar valley\n",
      "h2. A fatty oil\n",
      "h3. To entice\n",
      "h4. To lower; to reduce\n",
      "h5. A solitary person\n",
      "v1. According to the roster\n",
      "v2. Another name for Port-Francqui\n",
      "v3. An illicit lover; a European lake\n",
      "v4. To lisp\n",
      "v5. To come in\n",
      "Assistant:\n",
      "All possible 5-letters words for each clue, for each clue we give 10 options:\n",
      "h1. RILLE, VALLIS, CRATER, BASINS, PLAINS\n",
      "h2. OLEIC, OLEIN, GREASE, BUTTER, ANIMAL\n",
      "h3. LURE, TEMPT, SEDUCE, ENTICE, DRAWIN\n",
      "h4. ABASE, LOWER, REDUCE, LESSEN, DEBASE\n",
      "h5. HERMIT, ALONE, LONER, SINGLE, SOLITARY\n",
      "v1. ONTAP, LISTED, ROSTER, SCHEDULE, PLANNED\n",
      "v2. ILEBO, PORTF, CONGO, AFRICA, COLONY\n",
      "v3. LOVER, AMOUR, GENEVA, LEMAN, ZURICH\n",
      "v4. SLUR, LISPS, STUTTER, MUMBLE, STAMMER\n",
      "v5. ENTER, ARRIVE, COMEIN, APPEAR, SHOWUP\n",
      "˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\n",
      "Creative Writing\n",
      "AoT\n",
      "\"Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph\n",
      "must be:\n",
      "{0}\n",
      "Firstly, make five different plans for a coherent passage, then write. Your output\n",
      "should be of the following format:\n",
      "Plan 1:\n",
      "Your plan here.\n",
      "Plan 2:\n",
      "Your plan here.\n",
      "Plan 3:\n",
      "Your plan here.\n",
      "Plan 4:\n",
      "Your plan here.\n",
      "Plan 5:\n",
      "Your plan here.\n",
      "Secondly, given an instruction and several plans, decide which choice is most\n",
      "promising. Analyze each choice in detail, then conclude in the last line \"The best\n",
      "choice is {{s}}\", where s the integer id of the choice.\n",
      "Thirdly, write the passage according to that chosen plan in the most coherent way. Add\n",
      "\"Passage:\" before writing the passage under it.\n",
      "Passage:\n",
      "Your passage here.\n",
      "Finally, refine the passage in the most coherent way, but you still have to end each\n",
      "paragraph with the given sentences as before.\n",
      "Final Passage:\n",
      "Final passage here.\n",
      "Score Prompt\n",
      "Analyze the following passage, then at the last line conclude \"Thus the coherency\n",
      "score is {{s}}\", where s is an integer from 1 to 10.\n",
      "{0}\n",
      "Acknowledgment: We appreciate the discussions and assistance provided by L. Wang.\n",
      "Contributions: B. Sel played a pivotal role in shaping the primary concept, spearheading the experimental design and eval-\n",
      "uation, and leading the paper’s writing process. A. Tawaha actively engaged in discussions and conducted experiments. V .\n",
      "Khattar collaborated through discussions and played a role in conducting the experiments. R. Jia and M. Jin both engaged in\n",
      "constructive discussions, with M. Jin also offering advisory guidance.\n",
      "Additional info about the changes from the first version (dated 8/20/2023) can be found in this link (https://tinyurl.com/\n",
      "2vnjxw93).\n",
      "Beyond Chain-of-Thought, Effective\n",
      "Graph-of-Thought Reasoning in Large Language\n",
      "Models\n",
      "Yao Yao1,2, Zuchao Li3,∗and Hai Zhao1,2,∗\n",
      "1Department of Computer Science and Engineering, Shanghai Jiao Tong University\n",
      "2MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University\n",
      "3National Engineering Research Center for Multimedia Software,\n",
      "School of Computer Science, Wuhan University, Wuhan, 430072, P. R. China\n",
      "yaoyao27@sjtu.edu.cn, zcli-charlie@whu.edu.cn,\n",
      "zhaohai@cs.sjtu.edu.cn\n",
      "Abstract\n",
      "With the widespread use of large language models (LLMs) in NLP tasks, re-\n",
      "searchers have discovered the potential of Chain-of-thought (CoT) to assist LLMs\n",
      "in accomplishing complex reasoning tasks by generating intermediate steps. How-\n",
      "ever, human thought processes are often non-linear, rather than simply sequential\n",
      "chains of thoughts. Therefore, we propose Graph-of-Thought (GoT) reasoning,\n",
      "which models human thought processes not only as a chain but also as a graph. By\n",
      "representing thought units as nodes and connections between them as edges, our\n",
      "approach captures the non-sequential nature of human thinking and allows for a\n",
      "more realistic modeling of thought processes. Similar to Multimodal-CoT [ 1], we\n",
      "modeled GoT reasoning as a two-stage framework, generating rationales first and\n",
      "then producing the final answer. Specifically, we employ an additional graph-of-\n",
      "thoughts encoder for GoT representation learning and fuse the GoT representation\n",
      "with the original input representation through a gated fusion mechanism. We\n",
      "implement a GoT reasoning model on the T5 pre-trained model and evaluate its\n",
      "performance on a text-only reasoning task (GSM8K) and a multimodal reasoning\n",
      "task (ScienceQA). Our model achieves significant improvement over the strong\n",
      "CoT baseline with 3.41% and 5.08% on the GSM8K test set with T5-base and\n",
      "T5-large architectures, respectively. Additionally, our model boosts accuracy from\n",
      "84.91% to 91.54% using the T5-base model and from 91.68% to 92.77% using the\n",
      "T5-large model over the state-of-the-art Multimodal-CoT on the ScienceQA test\n",
      "set. Experiments have shown that GoT achieves comparable results to Multimodal-\n",
      "CoT largewith over 700M parameters, despite having fewer than 250M backbone\n",
      "model parameters, demonstrating the effectiveness of GoT.\n",
      "1 Introduction\n",
      "In the field of human cognition, it has long been recognized that the human thought process is far\n",
      "more complex and non-linear than could be captured by a simple, sequential chain of thoughts [ 2].\n",
      "Human thinking is often characterized by its ability to make sudden leaps and connections between\n",
      "seemingly unrelated ideas, which can lead to novel insights and solutions. This non-linear, jumping\n",
      "thought process is a hallmark of human creativity, reasoning, and problem-solving abilities. However,\n",
      "it also poses a significant challenge for cognitive modeling and understanding.\n",
      "∗Corresponding author.†Equal contribution.\n",
      "Preprint. Under review.arXiv:2305.16582v1  [cs.CL]  26 May 2023\n",
      "Recently, Large Language Models (LLMs) have been advancing at an unprecedented pace. With the\n",
      "emergence of breakthroughs such as GPT-3 [ 3], PaLM [ 4], and GPT-4 [ 5], the field of natural language\n",
      "processing has entered a new era of possibilities. Recent studies [ 6–8] have shown that the reasoning\n",
      "ability of LLMs can be unlocked by Chain-of-Thought (CoT) prompting. CoT prompting involves a\n",
      "series of intermediate natural language rationales that lead to the final answer. In addition, Zhang\n",
      "et al. [1]have introduced Multimodal-CoT, which combines both language and visual modalities to\n",
      "help surpass the limitations of textual information. More detailed related works about CoT can be\n",
      "found in Appendix A.1.\n",
      "Previous works on Chain-of-Thought (CoT) prompting, which have been limited to textual and\n",
      "visual information, often represented the human reasoning process as sequential thought chains. This\n",
      "approach overlooks the modeling of humans’ jumping thought process and neglects to incorporate\n",
      "the complex structural information of reasoning thoughts into the model. To address this limitation,\n",
      "we propose the Graph-of-Thought (GoT), a novel approach to modeling human thought processes\n",
      "not only as a chain but also as a graph. Our method is based on the assumption that the human mind\n",
      "works by connecting and recombining ideas in a non-sequential, graph fashion, rather than following\n",
      "a strict sequential chain. By representing thought units as nodes and connections between thoughts as\n",
      "edges, the Graph-of-Thought captures the rich, non-sequential nature of human thinking and allows\n",
      "for a more realistic and logical modeling of reasoning processes.\n",
      "Do ferns produce seeds?Text Features\n",
      "(A) Yes (B) No\n",
      "This diagram shows the life cycle of \n",
      "a fern.\n",
      "Vision Features (Optional) Graph -of-Thought Features\n",
      "produceseedsferns\n",
      "showslife \n",
      "cycle\n",
      "ofdiagram\n",
      "Fern plants reproduce using both asexual reproduction \n",
      "and sexual reproduction … The heart -shaped plant \n",
      "begins the fern's sexual reproduction stage … The mature \n",
      "fern can make spores and begin the fern life cycle again.Rationale\n",
      "Ferns do not produce seeds. Mature ferns produce spores, \n",
      "and heart -shaped plants produce eggs and sperm.Answer\n",
      "The answer \n",
      "is (B)Graph -of-Thought with Rationale\n",
      "produce seeds ferns\n",
      "showslife \n",
      "cycle\n",
      "ofdiagramhassexual \n",
      "production\n",
      "stage\n",
      "Figure 1: An example of GoT reasoning. Vision features are optional and are only required in\n",
      "multimodal reasoning task.\n",
      "An example of GoT reasoning is shown in Figure 1. Inspired by Multimodal-CoT [ 1], we have\n",
      "adopted a two-stage reasoning framework. It first generates rationales and then generates the final\n",
      "answer based on the predicted rationales. In addition to text features, graph features of GoT are\n",
      "integrated during the rationale generation and answer inference. Specifically, GoT is first constructed\n",
      "with an Extract-Cluster-Coreference (ECC) process, which simulates the deductive process in human\n",
      "reasoning. We have used T5 [ 9] pre-trained language model as our backbone model. GoT is encoded\n",
      "with a graph attention network and then fused with the original representation via a gated fusion\n",
      "network.\n",
      "Furthermore, we have also presented a multimodal GoT, which integrates not only text features and\n",
      "GoT features but also visual features. For our experiments, we have used both UnifiedQA (T5)-base\n",
      "and UnifiedQA (T5)-large [10] as our backbone models.\n",
      "We implement GoT as a two-stage framework and fine-tuning language models and integrating text,\n",
      "thought graph, and vision features for a more realistic and accurate reasoning process. GoT demon-\n",
      "strates exceptional performance on both text-only GSM8K [ 11] and multimodal ScienceQA [ 12]\n",
      "benchmarks, surpassing the accuracy of online system ChatGPT [ 5] by 25.08%, 14.46%, strong\n",
      "baseline Multimodal-CoT [ 1] by 6.63%, and even exceeding human performance, establishing a new\n",
      "state-of-the-art on ScienceQA test set with far more less parameters.\n",
      "2\n",
      "2 Graph-of-Thought\n",
      "Thought Graph\n",
      "Image (Optional)\n",
      "Graph -of-Thought \n",
      "Constructor\n",
      "Input Text \n",
      "Question: Do ferns \n",
      "produce seeds?\n",
      "Choices: (A) Yes (B) No\n",
      "Context: This diagram \n",
      "shows the life cycle of \n",
      "a fern.\n",
      "Predicted \n",
      "RationalesInput Encoder\n",
      "GoT\n",
      "Encoder\n",
      "Text\n",
      "encoder\n",
      "Vision \n",
      "encoderGraph \n",
      "Attention \n",
      "Network \n",
      "Transformer\n",
      "Encoder\n",
      "Feature\n",
      "ExtractorCross\n",
      "Attention\n",
      "Cross\n",
      "AttentionGated\n",
      "Fusion\n",
      "LayerTransformer\n",
      "Decoder\n",
      "Stage 1\n",
      "Predict Rationales\n",
      "Lecture：Fern plants reproduce \n",
      "using both asexual reproduction \n",
      "and sexual reproduction…\n",
      "Solution :  Ferns do not produce \n",
      "seeds. Mature ferns produce \n",
      "spores…\n",
      "The answer is (B).Decoder\n",
      "Output Feature FusionStage 2\n",
      "Stage 2\n",
      "Predict Answers\n",
      "Figure 2: Graph-of-Thought framework overview\n",
      "The overview of our proposed GoT can be seen in Figure 2. Inspired by Multimodal-CoT [ 1], GoT\n",
      "also adopts a two-stage framework. (1) Rationale generation stage: In the first stage, the model\n",
      "generates rationales based on the input text (including question, context, and choices) the vision\n",
      "features, and the generated thought graph corresponding to the input text. GoT employs independent\n",
      "encoders to encode input data for each modality. We use a Transformer encoder to encode input text,\n",
      "a vision encoder to encode an image, and a graph attention network to encode the thought graph.\n",
      "The encoded features are further passed into cross-attention to align text tokens with image patches\n",
      "and graph nodes, respectively. We then use a gated fusion layer to fuse these three features further\n",
      "and pass them into the Transformer decoder to predict the target rationales. (2) Answer generation\n",
      "stage: The second stage aims at generating the final answer and is largely similar to the first stage.\n",
      "The main difference is that the input text is concatenated with the predicted rationales from the first\n",
      "stage. It is worth noting that the above process describes a general multimodal reasoning framework.\n",
      "However, for text-only reasoning tasks, there are no image features, so the image encoding and vision\n",
      "feature fusion processes mentioned above can be omitted. In the following section, we will provide a\n",
      "detailed exposition of the two key steps of our GoT reasoning framework: GoT construction and GoT\n",
      "encoding and integration.\n",
      "2.1 GoT Construction\n",
      "The word earthquake \n",
      "comes from the words \n",
      "earth and quake. The word \n",
      "earth means ground, and \n",
      "the word quake means to \n",
      "shake.Earthquakecomes \n",
      "fromearth\n",
      "quakemeansground\n",
      "shakeGoT Rationales\n",
      "Figure 3: Graph-of-Thought deduction example\n",
      "3\n",
      "GoT employs thought graphs to simulate human deductive reasoning, thereby modeling humans’\n",
      "ability for leaps of thought. Our aim is to reflect the most fundamental deduction process by con-\n",
      "structing a thought graph. If we have evidence that x→yandy→z, then it follows that x→z. In\n",
      "Figure 3, the deduction reasoning can be formulated as follows: Earthquakecomes from−→ { earth, quake },\n",
      "{earth, quake }means−→ { ground, shake }. It is easy to reason that Earthquake −→{ ground, shake }.\n",
      "We propose a novel Extract-Clustering-\n",
      "Coreference (ECC) process to construct\n",
      "thought graphs. ECC first extracts deductive\n",
      "triplets T={ti= (ti\n",
      "x, ti\n",
      "y, ti\n",
      "z)}as the discrete\n",
      "raw graph, where ti\n",
      "x,ti\n",
      "y, and ti\n",
      "zare thought\n",
      "units of the i-th triplet, and there exists an\n",
      "edgeei\n",
      "xybetween ti\n",
      "xandti\n",
      "y, and an edge ei\n",
      "yz\n",
      "between ti\n",
      "yandti\n",
      "z. Then, ECC clusters the\n",
      "nodes that refer to the same mentions to con-\n",
      "duct coreference resolution. Specifically, we\n",
      "replace every graph node that belongs to a\n",
      "coreference cluster with the most representa-\n",
      "tive mention in the cluster. By adopting this\n",
      "technique, our model is better equipped with\n",
      "denser thought graphs and the ability for de-\n",
      "ductive reasoning. The detailed algorithm is\n",
      "illustrated in Algorithm 1.Algorithm 1 ECC process\n",
      "Input: Input text S\n",
      "Output: Thought graph G(N,E)\n",
      "Extract deductive triplet set Tfrom S\n",
      "T={t0, t1, ..., tn},ti= (ti\n",
      "x, ti\n",
      "y, ti\n",
      "z)\n",
      "forevery triplet ti∈Tdo\n",
      "Nr← N r∪ {ti\n",
      "x, ti\n",
      "y, ti\n",
      "z}\n",
      "Er← Er∪ {ei\n",
      "xy, ei\n",
      "yz}\n",
      "end for\n",
      "extract coreference clusters CforNr\n",
      "forevery node ni∈ Nrdo\n",
      "ifni∈ ∀cj∈ Cthen\n",
      "n∗\n",
      "j←most representative mention in cj\n",
      "N ← N ∪ { n∗\n",
      "j}\n",
      "end if\n",
      "end for\n",
      "Reconnect Nbased on Erto construct E\n",
      "return N,E\n",
      "In GoT construction, during the rationale generation stage, the input text consists of concatenated\n",
      "question, context, and choices. In multimodal GoT, image caption [ 12] is appended to the input text\n",
      "for GoT to incorporate image information. During the answer inference stage, the predicted rationales\n",
      "from the rationale generation stage are further concatenated with the input text for corresponding\n",
      "GoT construction.\n",
      "In our implementation of ECC process, inspired by [ 13], we utilize open information extraction (Ope-\n",
      "nIE) systems2[14] to extract subject-verb-object triplets as thought unit nodes. We apply coreference\n",
      "resolution to the extracted nodes using the Stanford CoreNLP system [ 15]. The constructed thought\n",
      "graph is denoted as G(N,E), where Nrepresents the nodes extracted by OpenIE and Erepresents\n",
      "the adjacency matrix. Rows and columns correspond to the nodes in the graph, and if there is an edge\n",
      "between two nodes, the corresponding matrix element is 1; otherwise, it is 0.\n",
      "2.2 GoT Encoding and Integration\n",
      "GoT reasoning utilizes separate encoders to encode input data for each modality. The thought graph\n",
      "is encoded using a graph attention network, while the input text is encoded using a Transformer\n",
      "encoder. In multimodal GoT reasoning, the image is encoded using an additional vision encoder.\n",
      "2.2.1 Base Encoder\n",
      "Text Encoder For text representation, we use the Transformer encoder (e.g. T5 [ 9]) to encode the\n",
      "input text. Given input sentence S={w0, ..., w l}, we extract the hidden states from the last layer of\n",
      "the Transformer encoder to obtain the text representation HT:\n",
      "HT={h0, h1, ..., h l}=Encoder text(S) (1)\n",
      "where hiis the hidden representation of token iandlrepresents the length of the text input.\n",
      "Vision Encoder (Optional) For multimodal reasoning where vision modality is required, follow-\n",
      "ing [ 1], we extract patch-level features of image Iusing readily available vision extraction model\n",
      "2https://github.com/philipperemy/Stanford-OpenIE-Python\n",
      "4\n",
      "as vision encoder Encoder vision and then employ a trainable projection matrix WIto project the\n",
      "extracted features into the vision representation HIwhich have the same shape with HT.\n",
      "HI=WIEncoder vision(I) (2)\n",
      "2.2.2 GoT Encoder\n",
      "Node Embedding We first use special tokens <s>\n",
      "and</s> to highlight every thought graph node.\n",
      "Specifically, for node set with jnodesN={n0, ...n j}\n",
      ", we construct the node input as p. we then feed the p\n",
      "into the same text encoder and utilize the output repre-\n",
      "sentation of the special token <s> as the initial node\n",
      "representation. Formally,\n",
      "p= [<s>, n0,</s> , ...,<s>, nj,</s> ] (3)\n",
      "[hs\n",
      "0, hn\n",
      "0, he\n",
      "0, ..., hs\n",
      "j, hn\n",
      "j, he\n",
      "j] =Encoder text(p)(4)\n",
      "where the hs\n",
      "iandhe\n",
      "i∈RDare the representation of <s>\n",
      "and</s> for node nirespectively, Dis the dimension\n",
      "of node embedding, and the hn\n",
      "i={hn\n",
      "i,1, ..., hn\n",
      "i,m}is\n",
      "the representations of node niwithmtokens. we use\n",
      "thehs\n",
      "ito represent the node representation of ni.\n",
      "GAT Encoder We employ a graph attention network\n",
      "(GAT) [ 16,13] to encode the thought graph. For every\n",
      "node niin graph G(N,E), thegraph attention layer\n",
      "is designed as:\n",
      "Dropout\n",
      "GoT inputG𝑁,𝐸Graph \n",
      "Attention LayerGraph \n",
      "Attention LayerConcatenateDropoutGraph \n",
      "Attention LayerFFNNLayernormGoT representation\n",
      "Multi -head \n",
      "attentionResidual connection\n",
      "ℎ𝑔′ℎ𝑔′𝐻𝐺\n",
      "…Figure 4: Architecture of GoT encoder\n",
      "aij=Attention (\u0002\n",
      "Whs\n",
      "i||Whs\n",
      "j\u0003\n",
      "); qij=LeakyReLU (aij) (5)\n",
      "αij=Softmax (qij) =exp (qij)P\n",
      "k∈K iexp (qik); hg′\n",
      "i=GELU\n",
      "X\n",
      "j∈K iαijWhs\n",
      "j\n",
      " (6)\n",
      "where ||denotes concatenate operation, the Wis a trainable weight and the set Kicontains the node\n",
      "ni’s neighbours in thought graph G. Our graph attention layer first employed a shared attention\n",
      "mechanism Attention (.) :RD′×RD′→Rto compute the attention weights, where D′is the\n",
      "attention layer output dimension. The attention weights aijmeasures the importance of node ni’s\n",
      "features to nj’s features. By only calculating the attention weights between nodes who are neighbours,\n",
      "our graph attention layer demonstrates the ability to perceive structural information of graphs. In\n",
      "our implementation, we adopt a single-layer feed-forward neural network (FFNN) as the attention\n",
      "mechanism which is both simple and straight-forward.\n",
      "The architecture of our GoT encoder can be seen in Figure 4. Our GoT encoder employs a multi-head\n",
      "graph attention layer, following [ 16], we concatenate the output of each graph attention layer and\n",
      "further pass it to a output graph attention layer with the same architecture:\n",
      "hg′\n",
      "i=∥K\n",
      "k=1GELU\n",
      "X\n",
      "j∈N iαk\n",
      "ijWkhs\n",
      "j\n",
      "; hg′′\n",
      "i=GELU\n",
      "X\n",
      "j∈N iαijWhg′\n",
      "j\n",
      " (7)\n",
      "where Kis the number of attention heads, ||is the concatenate operation, and nis the number of\n",
      "nodes in thought graph. We then use a single-layer feed-forward neural network (FFNN) to obtain\n",
      "the final thought graph embedding HG:\n",
      "hg′′= [hg′′\n",
      "0, ..., hg′′\n",
      "n]; HG=FFNN (hg′′) (8)\n",
      "5\n",
      "2.3 Feature Fusion\n",
      "After obtaining the encoded features, we use a single head attention to align the text representation\n",
      "HTwith image representation HIand thought graph representation HG, respectively. The image\n",
      "attention output HIand thought graph attention output HGare calculated by:\n",
      "HI=Softmax\u0012HTHI⊤\n",
      "√\n",
      "d\u0013\n",
      "HI;HG=Softmax\u0012HTHG⊤\n",
      "√\n",
      "d\u0013\n",
      "HG(9)\n",
      "where QisHTanddis the dimension of HT. We take both KIandVIasHIandKGandVGas\n",
      "HG. Please note that image representation is optional and is only required for multimodal dataset.\n",
      "Next, a gated fusion mechanism [ 17,1,18,19] is applied to combine the attention outputs HIand\n",
      "HGwith the text representation HT. The feature fusion output Hcan be calculated by:\n",
      "λ=(\n",
      "Sigmoid\u0000\n",
      "WTHT+WGHG\u0001\n",
      "text-only reasoning\n",
      "Sigmoid\u0000\n",
      "WTHT+WIHI+WGHG\u0001\n",
      "multimodal reasoning(10)\n",
      "H=(\n",
      "(1−λ)·HT+λ·HGtext-only reasoning\n",
      "(1−λ)·HT+λ·HI+λ·HGmultimodal reasoning(11)\n",
      "where WT,WIandWGare all trainable weights. We then input the fused feature output Hinto the\n",
      "decoder to predict the rationales or the final answer.\n",
      "3 Experiments\n",
      "Dataset We evaluate our model on the text-only GSM8K [ 11] and multimodal ScienceQA bench-\n",
      "mark [ 12]. GSM8K benchmark comprises 8.5K meticulously crafted grade school math problems\n",
      "with annotated 2 to 8 problem solution steps. For GSM8K, the model is trained to reasoning through\n",
      "the steps to generate the final answer. ScienceQA benchmark is the pioneering large-scale dataset\n",
      "for multimodal science questions, equipped with comprehensive annotations for answers, including\n",
      "detailed lectures and explanations. The dataset contains 21k questions covering three subjects: natural\n",
      "science, language science, and social science. Each question is presented with a context in the form\n",
      "of natural language or an optional image. The model is trained to elucidate the reasoning process in\n",
      "natural language while choosing the answer from a set of options. The detailed dataset statistics are\n",
      "shown in Appendix A.2.\n",
      "Model Setup In our experiments, we used T5 [ 9] as our basic model architecture, including both\n",
      "T5-base and T5-large model sizes. Specifically, to ensure a fair comparison, we initialized our model\n",
      "with the pre-trained T5 checkpoint - UnifiedQA [ 10] and used DETR [ 20] for the vision encoder,\n",
      "following [ 7]. We fine-tuned the models for 50 epochs with a learning rate of 5e-5. The detailed\n",
      "training parameters are available in Appendix A.3. We trained our models on four NVIDIA GeForce\n",
      "RTX 4090 24G GPUs.\n",
      "4 Results and Discussion\n",
      "4.1 Main Results\n",
      "Baselines For GSM8K, our baselines include: (1) few-shot LLMs including GPT-3 [ 21], GPT-\n",
      "3.5 [ 5], GPT-4 [ 5], and code-davinci-002 [ 22] (2) LLMs with CoT: To have a fair comparison we\n",
      "also fine-tuned UnifiedQA baseand UnifiedQA large[10] on GSM8K with traditional two-stage CoT.\n",
      "For ScienceQA, following [ 1,12], our adopted baselines include: (1) Vision question answering\n",
      "(VQA) baseline models [ 23–30]; (2) Text-to-text LLMs [ 31,32] and (3) Text-to-text LLMs with\n",
      "CoT prompting [ 12,1]. Both UnifiedQA [ 12] and GPT-3.5 [ 12] use generated image captions to\n",
      "incorporate vision semantics. Whereas, Mutimodal-CoT [ 1] injects generated image features into\n",
      "traditional CoT reasoning.\n",
      "6\n",
      "Table 1: Rationale generation results (%). (*: we re-run the Mutimodal-CoT baseto report the full\n",
      "rouge scores)\n",
      "MODELS ROUGE-L ROUGE-1 ROUGE-2 ROUGE-LSUM\n",
      "GSM8K\n",
      "UnifiedQA base[31] 70.61 75.32 51.13 70.24\n",
      "UnifiedQA large [31] 72.83 76.91 54.25 72.34\n",
      "GoT-T5 base 71.08 75.46 51.85 70.61\n",
      "GoT-T5 large 72.91 76.93 54.57 72.45\n",
      "ScienceQA\n",
      "Mutimodal-CoT∗\n",
      "base[1] 96.98 97.26 94.00 97.16\n",
      "GoT-T5 base 98.29 98.43 96.23 98.37\n",
      "GoT-T5 large 98.35 98.45 96.30 98.41\n",
      "Results The rationales generation results can be seen in Table 1. The overall results are reported in\n",
      "Table 2 and Table 3. On the GSM8K dataset, for rationale generation in the first stage, our GoT base\n",
      "model achieves a 0.47 improvement in ROUGE-L compared to the UnifiedQA basemodel that did\n",
      "not incorporate GoT and the GoT largemodel achieves a 0.08 improvement. In the second stage of\n",
      "answer generation, the GoT base model showed a 3.41% increase in accuracy, while the GoT large\n",
      "model achieved a 5.08% improvement. GoT outperformed GPT-3 by 27.18% in accuracy while using\n",
      "significantly fewer parameters than GPT-3. Although GPT-4 achieves a result of 92%, there is a high\n",
      "probability it has over 175 billion parameters. Our model, compared to UnifiedQA large, reduces the\n",
      "accuracy gap by 5%.\n",
      "For ScienceQA dataset, in rationale generation stage, we can see from Table 1 that our model\n",
      "achieves a ROUGE-L of 98.29 and outperforms the Mutimodal-CoT baseby 1.31. For the final answer\n",
      "generation stage, our GoT achieves SOTA in all subjects and all grades. The most direct comparison\n",
      "is that our model achieves an accuracy of 91.68% which is 6.77% higher than that of the Mutimodal-\n",
      "CoT basewith the similar number of parameters and is competitive to the Mutimodal-CoT largewith\n",
      "738M parameters.\n",
      "We can observe from Table 1 that the impact of GoT on rationale generation is limited. We attribute\n",
      "this limitation to the fact that the input text for thought graph construction only includes questions\n",
      "and choices. Consequently, the thought graph constructed from such limited information can only\n",
      "facilitate constrained deductive reasoning. However, in the answer generation stage, when provided\n",
      "with rationales, the model needs to possess stronger deductive reasoning capabilities to understand the\n",
      "relationship between rationales, questions, and choices. Therefore, GoT demonstrates a significant\n",
      "advantage over traditional CoT, elevating the accuracy from 62.70% to 66.11% in GSM8K and\n",
      "from 84.91% to 91.54% in ScienceQA task. The results sufficiently suggest that utilizing thought\n",
      "graph features for deductive reasoning is a more effective approach than the existing methods, which\n",
      "only consider text or vision features by simply incorporating image captions or fusing generated\n",
      "image features. In conclusion, our results confirm the effectiveness of utilizing two-dimensional\n",
      "graph-of-thought and demonstrate the potential of incorporating GoT into reasoning for LLMs.\n",
      "Table 2: Main test accuracy results (ACC%) of GSM8K. Size=backbone model size.\n",
      "MODELS TRAINING SIZE ACC(%)\n",
      "GPT-3 [21] train-set 175B 55.00\n",
      "code-davinci-002 [22] few-shot 175B 68.01\n",
      "GPT-3.5 [5] few-shot - 57.10\n",
      "GPT-4 [5] few-shot - 92.00\n",
      "UnifiedQA base[10] train-set 223M 62.70\n",
      "GoT-T5 base train-set 223M 66.11\n",
      "UnifiedQA large[10] train-set 738M 77.10\n",
      "GoT-T5 large train-set 738M 82.18\n",
      "7\n",
      "Table 3: Main test accuracy results (%) of ScienceQA. SIZE=backbone model size. Question classes:\n",
      "NAT = natural science, SOC = social science, LAN = language science, TXT = text context, IMG =\n",
      "image context, NO = no context, G1-6 = grades 1-6, G7-12 = grades 7-12, A VG= average accuracy\n",
      "scores\n",
      "MODEL TRAINING SIZE NAT SOC LAN TXT IMG NO G1-6 G7-12 A VG\n",
      "Human - - 90.23 84.97 87.48 89.60 87.50 88.10 91.59 82.42 88.40\n",
      "Vision question answering baselines\n",
      "MCAN [23] train-set 95M 56.08 46.23 58.09 59.43 51.17 55.40 51.65 59.72 54.54\n",
      "Top-Down [24] train-set 70M 59.50 54.33 61.82 62.90 54.88 59.79 57.27 62.16 59.02\n",
      "BAN [25] train-set 112M 60.88 46.57 66.64 62.61 52.60 65.51 56.83 63.94 59.37\n",
      "DFAF [26] train-set 74M 64.03 48.82 63.55 65.88 54.49 64.11 57.12 67.17 60.72\n",
      "ViLT [27] train-set 113M 60.48 63.89 60.27 63.20 61.38 57.00 60.72 61.90 61.14\n",
      "Patch-TRM [28] train-set 90M 65.19 46.79 65.55 66.96 55.28 64.95 58.04 67.50 61.42\n",
      "VisualBERT [29, 30] train-set 111M 59.33 69.18 61.18 62.71 62.17 58.54 62.96 59.92 61.87\n",
      "Text-to-text LLMs\n",
      "UnifiedQA base[31] zero-shot 223M 68.16 69.18 74.91 63.78 61.38 77.84 72.98 65.00 70.12\n",
      "GPT-3.5 [32] zero-shot 175B 74.64 69.74 76.00 74.44 67.28 77.42 76.80 68.89 73.97\n",
      "Text-to-text LLMs with CoT\n",
      "UnifiedQA base(CoT) [12] zero-shot 223M 71.00 76.04 78.91 66.42 66.53 81.81 77.06 68.82 74.11\n",
      "GPT-3.5 (CoT) [12] 2-shot 175B 75.44 70.87 78.09 74.68 67.43 79.93 78.23 69.68 75.17\n",
      "ChatGPT (CoT) [33] few-shot - 78.82 70.98 83.18 77.37 67.92 86.13 80.72 74.03 78.31\n",
      "GPT-4 (CoT) [33] few-shot - 85.48 72.44 90.27 82.65 71.49 92.89 86.66 79.04 83.99\n",
      "Mutimodal-CoT base[1] train-set 223M 87.52 77.17 85.82 87.88 82.90 86.83 84.65 85.37 84.91\n",
      "GoT-T5 base train-set 223M92.51 88.98 91.61 92.39 90.84 92.33 91.68 91.27 91.54\n",
      "±0.24 ±0.37 ±0.78 ±0.23 ±0.39 ±0.60 ±0.05 ±0.36 ±0.12\n",
      "Mutimodal-CoT large[1] train-set 738M 95.91 82.00 90.82 95.26 88.80 92.89 92.44 90.31 91.68\n",
      "GoT-T5 large train-set 738M96.51 82.26 93.61 96.56 89.56 94.29 93.83 90.86 92.77\n",
      "±0.25 ±0.21 ±0.19 ±0.26 ±0.29 ±0.10 ±0.18 ±0.38 ±0.18\n",
      "4.2 Further Exploration\n",
      "4.2.1 Ablation Study\n",
      "In order to make sure that: (1) our GoT’s performance gain is not simply due to the increase of\n",
      "parameters. We conduct an ablation study where we enlarge the number of parameters of Mutimodal-\n",
      "CoT baseto the same size 233M with our model. The enlarged model is denoted as Mutimodal-\n",
      "CoT base(enlarged). (2) introducing thought graphs into GoT reasoning indeed boost the performance.\n",
      "We construct a random thought graph by randomly select graph nodes. (3) the multi-head attention\n",
      "mechanism in GoT encoder is necessary. We employ a single-head attention. The overall ablation\n",
      "results can be found in Table 4.\n",
      "Table 4: Ablation results of GoT.\n",
      "MODEL MODEL SIZE G1-6 G7-12 A VG ∆\n",
      "GoT-T5 base\n",
      "233M91.68 91.27 91.54 -\n",
      "w/ Random Connection 91.23 90.18 90.85 -0.69\n",
      "w/ Single-head attention 91.08 90.77 90.97 -0.53\n",
      "Mutimodal-CoT base(enlarged) 233M 89.28 87.21 88.54 -3.00\n",
      "From the table, we can see that our model significantly outperforms the enlarged Mutimodal-CoT by\n",
      "an accuracy of 3.00%. The results sufficiently proved the importance of introducing thought graphs\n",
      "into multimodal reasoning. When reducing the multi-head attention to single-head attention, GoT\n",
      "suffers a loss of 0.53% accuracy, indicating the necessity of multi-head attention mechanism for GoT\n",
      "encoder. By randomly construct thought graphs to disrupt the deductive reasoning process, our model\n",
      "suffers a loss of 0.69%, indicating the effectiveness of GoT.\n",
      "4.2.2 Analysis\n",
      "Performance on Different Classes In order to investigate the impact of GoT on the overall\n",
      "model performance across different subjects , we calculated the accuracy for different subjects and\n",
      "compared it with that of enlarged Mutimodal-CoT. We also compare the performance of two models\n",
      "on different question classes.The radar Figure 5 shows the overall results for our base model. With\n",
      "respect to various subjects and question classes, our model demonstrates superior performance over\n",
      "8\n",
      "the Mutimodal-CoT baseand attains a more consistent and enhanced outcome. Our model presents\n",
      "outstanding advantages especially in the field of social science, with an accuracy improvement of\n",
      "8.01%. For different question classes, our model demonstrates the largest improvement on questions\n",
      "involving images. Our hypothesis is that by constructing a thought graph and integrating the three\n",
      "features of text, image, and thought graph, we can better align the textual and visual information\n",
      "for the model, thus maximizing the utilization of visual information and obtaining more accurate\n",
      "answers.\n",
      "75.0080.0085.0090.0095.00100.00NAT\n",
      "SOC\n",
      "LAN\n",
      "TXTIMGNOMutimodal-CoT(enlarged) Ours(base)\n",
      "Figure 5: Performance on different question\n",
      "classes5 1080859095100\n",
      "GradesAccuracy(%)\n",
      "Ours base\n",
      "Mutimodal-CoT base(enlarged)\n",
      "Figure 6: Performance on different grades\n",
      "Performance on Different Grades It can be seen from the Table 4 that the enlarged Mutimodal-\n",
      "CoT experience a decrease in accuracy of 2.07 as the grade level of the given question increases\n",
      "while GoT only has minor decrease of 0.41. We believe the main reason is that by incorporating\n",
      "GoT, models acquires the ability for deductive reasoning and can better comprehend the relationships\n",
      "between different entities and thus better understand the meaning of the problems. Through this\n",
      "method, for higher-grade problems with greater complexity, the model can construct a thought graph\n",
      "to help itself generate a more complete logical chain for deduction, thereby generating more accurate\n",
      "answers. More detailed model performance on different grades can be found in Figure 6. We can see\n",
      "from the figure that in the lower grade, two models achieves a similar performance. As the grade level\n",
      "increases and the difficulty of the questions becomes more challenging, the gap between our model\n",
      "and the Mutimodal-CoT model gradually widens. Due to the small number of questions ( ≤130)\n",
      "available for each grade in grade 1 and grades 9-12, there is greater fluctuation in the accuracy of\n",
      "both models. Nevertheless, it is evident from the table that our model exhibits stronger and more\n",
      "stable advantages over Mutimodal-CoT in each grade.\n",
      "Case Study and Limitation In order to gain a deeper understanding of the performance of GoT, we\n",
      "conduct a manual investigation of randomly selected examples generated by our approach which can\n",
      "be found in Appendix A.4. We also visualize the attention weights aijin GoT encoder to demonstrate\n",
      "how GoT performs deductive reasoning to generate more accurate answers in Appendix A.5\n",
      "For the limitation of this work, compared to CoT, GoT may result in additional computational costs\n",
      "and slightly slower training times. Detailed limitation analysis can be found in Appendix A.6.\n",
      "5 Conclusion\n",
      "We introduce a novel Graph-of-Thought (GoT) reasoning approach, which is an innovative method\n",
      "for modeling the non-sequential nature of human thinking within large language models (LLMs).\n",
      "GoT enhances LLMs with deductive reasoning abilities, providing a more realistic representation of\n",
      "9\n",
      "thought processes. Our experiments showcases the superiority of GoT on the text-only reasoning\n",
      "dataset, achieving an accuracy of 82.18% on the GSM8K test set, outperforming GPT-3 significantly\n",
      "while utilizing significantly fewer parameters. Furthermore, GoT establishes a new state-of-the-art\n",
      "on the multimodal reasoning benchmark, ScienceQA, achieving an impressive accuracy of 92.77%\n",
      "with fewer parameters. This performance surpasses strong ChatGPT and GPT-4 systems, as well as\n",
      "human performance, demonstrating the efficacy of GoT. Through comprehensive case studies and\n",
      "ablation studies, we provide substantial evidence of the effectiveness of GoT in reasoning tasks. If\n",
      "you want it, you GoT it!\n",
      "References\n",
      "[1]Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multi-\n",
      "modal chain-of-thought reasoning in language models. CoRR , abs/2302.00923, 2023. doi: 10.\n",
      "48550/arXiv.2302.00923. URL https://doi.org/10.48550/arXiv.2302.00923 .\n",
      "[2]Lawrence W Barsalou. Perceptual symbol systems. Behavioral and brain sciences , 22(4):\n",
      "577–660, 1999.\n",
      "[3]Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-\n",
      "wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,\n",
      "Ariel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M.\n",
      "Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz\n",
      "Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish,\n",
      "Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learn-\n",
      "ers. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and\n",
      "Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual\n",
      "Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-\n",
      "12, 2020, virtual , 2020. URL https://proceedings.neurips.cc/paper/2020/\n",
      "hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html .\n",
      "[4]Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\n",
      "Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\n",
      "Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay,\n",
      "Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope,\n",
      "James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke,\n",
      "Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant\n",
      "Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek\n",
      "Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal,\n",
      "Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor\n",
      "Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou,\n",
      "Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\n",
      "Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language\n",
      "modeling with pathways. CoRR , abs/2204.02311, 2022. doi: 10.48550/arXiv.2204.02311. URL\n",
      "https://doi.org/10.48550/arXiv.2204.02311 .\n",
      "[5]OpenAI. Gpt-4 technical report. 2023. URL https://cdn.openai.com/papers/\n",
      "gpt-4.pdf .\n",
      "[6]Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi, Quoc Le, and\n",
      "Denny Zhou. Chain of thought prompting elicits reasoning in large language models. CoRR ,\n",
      "abs/2201.11903, 2022. URL https://arxiv.org/abs/2201.11903 .\n",
      "[7]Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V . Le, Ed H. Chi, and Denny Zhou. Self-\n",
      "consistency improves chain of thought reasoning in language models. CoRR , abs/2203.11171,\n",
      "2022. doi: 10.48550/arXiv.2203.11171. URL https://doi.org/10.48550/arXiv.\n",
      "2203.11171 .\n",
      "[8]Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. Automatic chain of thought prompting\n",
      "in large language models. CoRR , abs/2210.03493, 2022. doi: 10.48550/arXiv.2210.03493.\n",
      "URL https://doi.org/10.48550/arXiv.2210.03493 .\n",
      "10\n",
      "[9]Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\n",
      "Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified\n",
      "text-to-text transformer. Journal of Machine Learning Research , 21(140):1–67, 2020. URL\n",
      "http://jmlr.org/papers/v21/20-074.html .\n",
      "[10] Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark,\n",
      "and Hannaneh Hajishirzi. Unifiedqa: Crossing format boundaries with a single QA system. In\n",
      "Trevor Cohn, Yulan He, and Yang Liu, editors, Findings of the Association for Computational\n",
      "Linguistics: EMNLP 2020, Online Event, 16-20 November 2020 , volume EMNLP 2020 of\n",
      "Findings of ACL , pages 1896–1907. Association for Computational Linguistics, 2020. doi:\n",
      "10.18653/v1/2020.findings-emnlp.171. URL https://doi.org/10.18653/v1/2020.\n",
      "findings-emnlp.171 .\n",
      "[11] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christo-\n",
      "pher Hesse, and John Schulman. Training verifiers to solve math word problems. CoRR ,\n",
      "abs/2110.14168, 2021. URL https://arxiv.org/abs/2110.14168 .\n",
      "[12] Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind\n",
      "Tafjord, Peter Clark, and Ashwin Kalyan. Learn to explain: Multimodal reasoning via thought\n",
      "chains for science question answering. In The 36th Conference on Neural Information Process-\n",
      "ing Systems (NeurIPS) , 2022.\n",
      "[13] Jiaao Chen and Diyi Yang. Structure-aware abstractive conversation summarization via discourse\n",
      "and action graphs. In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-\n",
      "Tür, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou, editors,\n",
      "Proceedings of the 2021 Conference of the North American Chapter of the Association for\n",
      "Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-\n",
      "11, 2021 , pages 1380–1391. Association for Computational Linguistics, 2021. doi: 10.18653/v1/\n",
      "2021.naacl-main.109. URL https://doi.org/10.18653/v1/2021.naacl-main.\n",
      "109.\n",
      "[14] Gabor Angeli, Melvin Jose Johnson Premkumar, and Christopher D. Manning. Leveraging\n",
      "linguistic structure for open domain information extraction. In Proceedings of the 53rd Annual\n",
      "Meeting of the Association for Computational Linguistics and the 7th International Joint\n",
      "Conference on Natural Language Processing (Volume 1: Long Papers) , pages 344–354, Beijing,\n",
      "China, July 2015. Association for Computational Linguistics. doi: 10.3115/v1/P15-1034. URL\n",
      "https://aclanthology.org/P15-1034 .\n",
      "[15] Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, and David\n",
      "McClosky. The Stanford CoreNLP natural language processing toolkit. In Proceedings of 52nd\n",
      "Annual Meeting of the Association for Computational Linguistics: System Demonstrations ,\n",
      "pages 55–60, Baltimore, Maryland, June 2014. Association for Computational Linguistics. doi:\n",
      "10.3115/v1/P14-5010. URL https://aclanthology.org/P14-5010 .\n",
      "[16] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua\n",
      "Bengio. Graph attention networks. In 6th International Conference on Learning Representations,\n",
      "ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings .\n",
      "OpenReview.net, 2018. URL https://openreview.net/forum?id=rJXMpikCZ .\n",
      "[17] Zhiyong Wu, Lingpeng Kong, Wei Bi, Xiang Li, and Ben Kao. Good for misconceived reasons:\n",
      "An empirical revisiting on the need for visual context in multimodal machine translation. In\n",
      "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the\n",
      "11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) ,\n",
      "pages 6153–6166, Online, August 2021. Association for Computational Linguistics. doi: 10.\n",
      "18653/v1/2021.acl-long.480. URL https://aclanthology.org/2021.acl-long.\n",
      "480.\n",
      "[18] Bei Li, Chuanhao Lv, Zefan Zhou, Tao Zhou, Tong Xiao, Anxiang Ma, and JingBo Zhu. On\n",
      "vision features in multimodal machine translation. In Proceedings of the 60th Annual Meeting\n",
      "of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 6327–6337,\n",
      "Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.\n",
      "acl-long.438. URL https://aclanthology.org/2022.acl-long.438 .\n",
      "11\n",
      "[19] Zhuosheng Zhang, Kehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita, Zuchao Li, and\n",
      "Hai Zhao. Neural machine translation with universal visual representation. In 8th International\n",
      "Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020 .\n",
      "OpenReview.net, 2020. URL https://openreview.net/forum?id=Byl8hhNYPS .\n",
      "[20] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kir-\n",
      "illov, and Sergey Zagoruyko. End-to-end object detection with transformers. In Andrea\n",
      "Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm, editors, Computer Vision\n",
      "- ECCV 2020 - 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceed-\n",
      "ings, Part I , volume 12346 of Lecture Notes in Computer Science , pages 213–229. Springer,\n",
      "2020. doi: 10.1007/978-3-030-58452-8\\_13. URL https://doi.org/10.1007/\n",
      "978-3-030-58452-8_13 .\n",
      "[21] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\n",
      "language models are zero-shot reasoners. CoRR , abs/2205.11916, 2022. doi: 10.48550/arXiv.\n",
      "2205.11916. URL https://doi.org/10.48550/arXiv.2205.11916 .\n",
      "[22] Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale\n",
      "Schuurmans, Olivier Bousquet, Quoc Le, and Ed H. Chi. Least-to-most prompting enables\n",
      "complex reasoning in large language models. CoRR , abs/2205.10625, 2022. doi: 10.48550/\n",
      "arXiv.2205.10625. URL https://doi.org/10.48550/arXiv.2205.10625 .\n",
      "[23] Zhou Yu, Jun Yu, Yuhao Cui, Dacheng Tao, and Qi Tian. Deep modular co-attention\n",
      "networks for visual question answering. In IEEE Conference on Computer Vision and Pattern\n",
      "Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019 , pages 6281–6290.\n",
      "Computer Vision Foundation / IEEE, 2019. doi: 10.1109/CVPR.2019.00644. URL\n",
      "http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Deep_\n",
      "Modular_Co-Attention_Networks_for_Visual_Question_Answering_\n",
      "CVPR_2019_paper.html .\n",
      "[24] Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen\n",
      "Gould, and Lei Zhang. Bottom-up and top-down attention for image captioning and vi-\n",
      "sual question answering. In 2018 IEEE Conference on Computer Vision and Pattern\n",
      "Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018 , pages 6077–6086.\n",
      "Computer Vision Foundation / IEEE Computer Society, 2018. doi: 10.1109/CVPR.2018.\n",
      "00636. URL http://openaccess.thecvf.com/content_cvpr_2018/html/\n",
      "Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.html .\n",
      "[25] Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang. Bilinear attention networks. In Samy Ben-\n",
      "gio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman\n",
      "Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on\n",
      "Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal,\n",
      "Canada , pages 1571–1581, 2018. URL https://proceedings.neurips.cc/paper/\n",
      "2018/hash/96ea64f3a1aa2fd00c72faacf0cb8ac9-Abstract.html .\n",
      "[26] Peng Gao, Zhengkai Jiang, Haoxuan You, Pan Lu, Steven C. H. Hoi, Xiaogang Wang, and\n",
      "Hongsheng Li. Dynamic fusion with intra- and inter-modality attention flow for visual question\n",
      "answering. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019,\n",
      "Long Beach, CA, USA, June 16-20, 2019 , pages 6639–6648. Computer Vision Foundation\n",
      "/ IEEE, 2019. doi: 10.1109/CVPR.2019.00680. URL http://openaccess.thecvf.\n",
      "com/content_CVPR_2019/html/Gao_Dynamic_Fusion_With_Intra-_and_\n",
      "Inter-Modality_Attention_Flow_for_Visual_CVPR_2019_paper.html .\n",
      "[27] Wonjae Kim, Bokyung Son, and Ildoo Kim. Vilt: Vision-and-language transformer without\n",
      "convolution or region supervision. In Marina Meila and Tong Zhang, editors, Proceedings of\n",
      "the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual\n",
      "Event , volume 139 of Proceedings of Machine Learning Research , pages 5583–5594. PMLR,\n",
      "2021. URL http://proceedings.mlr.press/v139/kim21k.html .\n",
      "[28] Pan Lu, Liang Qiu, Jiaqi Chen, Tanglin Xia, Yizhou Zhao, Wei Zhang, Zhou Yu, Xiaodan\n",
      "Liang, and Song-Chun Zhu. Iconqa: A new benchmark for abstract diagram understand-\n",
      "ing and visual language reasoning. In Joaquin Vanschoren and Sai-Kit Yeung, editors,\n",
      "12\n",
      "Proceedings of the Neural Information Processing Systems Track on Datasets and Bench-\n",
      "marks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual , 2021. URL\n",
      "https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/\n",
      "hash/d3d9446802a44259755d38e6d163e820-Abstract-round2.html .\n",
      "[29] Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang. Visualbert: A\n",
      "simple and performant baseline for vision and language. CoRR , abs/1908.03557, 2019. URL\n",
      "http://arxiv.org/abs/1908.03557 .\n",
      "[30] Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang. What does BERT\n",
      "with vision look at? In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel R. Tetreault, editors,\n",
      "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL\n",
      "2020, Online, July 5-10, 2020 , pages 5265–5275. Association for Computational Linguistics,\n",
      "2020. doi: 10.18653/v1/2020.acl-main.469. URL https://doi.org/10.18653/v1/\n",
      "2020.acl-main.469 .\n",
      "[31] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\n",
      "Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified\n",
      "text-to-text transformer. J. Mach. Learn. Res. , 21:140:1–140:67, 2020. URL http://jmlr.\n",
      "org/papers/v21/20-074.html .\n",
      "[32] Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey E.\n",
      "Hinton. Big self-supervised models are strong semi-supervised learners. In Hugo\n",
      "Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien\n",
      "Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference\n",
      "on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,\n",
      "virtual , 2020. URL https://proceedings.neurips.cc/paper/2020/hash/\n",
      "fcbc95ccdd551da181207c0c1400c655-Abstract.html .\n",
      "[33] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-\n",
      "Chun Zhu, and Jianfeng Gao. Chameleon: Plug-and-play compositional reasoning with large\n",
      "language models. CoRR , abs/2304.09842, 2023. doi: 10.48550/arXiv.2304.09842. URL\n",
      "https://doi.org/10.48550/arXiv.2304.09842 .\n",
      "13\n",
      "A Appendix\n",
      "A.1 Related Works\n",
      "In chain-of-thought reasoning, one idea leads to the next in a logical sequence and builds on previous\n",
      "knowledge. Each idea is supported by evidence or reasoning, and the conclusions drawn from the\n",
      "chain are logical and sound. Most CoT methods can be divided into two categories based on how to\n",
      "generate the final answer: (1) prompting for CoT, including zero-shot CoT and few-shot CoT; and (2)\n",
      "fine-tuning for CoT.\n",
      "Zero-shot CoT Prompting As large language models continue to advance rapidly, many re-\n",
      "searchers are beginning to explore CoT reasoning for LLMs. The zero-shot CoT method proposed\n",
      "by Kojima et al. [21] consists of two stages: (1) adding a \" Let’s think step by step \" prompt to generate\n",
      "CoT, and (2) concatenating the generated CoT and adding the phrase \" So the answer is \" to obtain the\n",
      "final answer.\n",
      "Few-shot CoT Prompting Few-shot CoT reasoning for LLMs, however, utilizes multiple input-\n",
      "output pairs to prompt the LLMs to output CoT and obtain the final answer. Due to its ability to\n",
      "provide better performance compared to Zero-shot CoT, Few-shot CoT has gained more attention in\n",
      "research, particularly through effective demonstrations. Few-shot CoT prompting was first formally\n",
      "explored by Wei et al. [6]and is a form of discrete prompt learning that involves context learning\n",
      "in large models. Compared to traditional in-context learning, which prompts LLMs with a list of\n",
      "input-output demonstration pairs along with a test input to allow the model to predict output, Few-shot\n",
      "CoT prompting outputs additional logical reasoning procedures apart from the target output. Wang\n",
      "et al. [7]proposed a follow-up method to [ 6]. The main improvement is that the model uses the\n",
      "majority vote for the answers, which was found to significantly improve the performance of the\n",
      "CoT. However, these few-shot CoT models depend on hand-crafted demonstrations. To solve this\n",
      "problem, Zhang et al. [8]proposed Auto-CoT, which maintains the diversity of sampled questions\n",
      "and generates reasoning chains to automatically construct demonstrations. Specifically, Auto-CoT\n",
      "consists of two main stages: (1) Problem clustering: divide the given dataset of problems into several\n",
      "clusters; (2) Demonstration sampling: select a representative problem from each cluster and use a\n",
      "simple heuristic method to generate its reasoning chain. Furthermore, Lu et al. [33] also explores\n",
      "few-shot CoT reasoning for recently popular LLMs ChatGPT and GPT-4 [5].\n",
      "CoT Fine-tuning In Zhang et al. [1], it was proposed to fine-tune smaller language models instead\n",
      "of prompting them in LLMs. And this approach enabled the CoT to go beyond textual information\n",
      "and incorporate visual (image) modalities using a gated fusion mechanism into a two-stage CoT. The\n",
      "results demonstrated that CoT fine-tuning with fewer parameters has potential. Therefore, in this\n",
      "work, we focus on fine-tuning for CoT to reduce the number of required model parameters and help\n",
      "LLMs better comprehend different modalities. However, previous CoT research has been limited\n",
      "to different modalities, such as textual and vision information, without considering the deduction\n",
      "reasoning process. Therefore, in this work, we move beyond modeling the reasoning process solely\n",
      "as a thought chain and elevate it to a thought graph. We provide a more comprehensive and nuanced\n",
      "representation, enabling LLMs to perceive the deduction reasoning process accurately, resulting in\n",
      "more precise answer generation.\n",
      "14\n",
      "A.2 Dataset statistics\n",
      "Splits #Problems\n",
      "Train 7,473\n",
      "Test 1,319\n",
      "Table 5: GSM8K dataset statistics (# denotes\n",
      "numbers)Statistic Number\n",
      "Splits\n",
      "#Train 12,726\n",
      "#Dev 4,241\n",
      "#Test 4,241\n",
      "#Total 21,208\n",
      "Attribute\n",
      "#Subjects 3\n",
      "#Topic 26\n",
      "#Category 127\n",
      "#Skill 379\n",
      "Table 6: ScienceQA dataset statistics (# denotes\n",
      "numbers)\n",
      "A.3 Training Parameters\n",
      "Parameters Value\n",
      "Epochs 50\n",
      "Batch size for T5-base (per device) 4\n",
      "Batch size for T5-large (per device) 2\n",
      "Learning rate 5e-5\n",
      "Weight decay 0.01\n",
      "Max input length 512\n",
      "Max number of nodes 150\n",
      "Table 7: Training parameters for GoT\n",
      "A.4 Case Study\n",
      "To facilitate a more illustrative comparison between GoT and the CoT, we have selected several\n",
      "representative examples. Figure 11 demonstrates examples for GSM8K dataset. Figure 8 to Figure\n",
      "10 illustrates examples from ScienceQA dataset. From Figure 7 and Figure 8, we can see that GoT\n",
      "can better understand the rationales and generate more accurate result. In Figure 9, we can see that\n",
      "when provided with wrong rationale, our model is more robust to the noise and can focus on more\n",
      "important key information. (We highlight the noisy wrong rationale in red and correct key rationale in\n",
      "green). Figure 10 presents a language problem which have less context and requires a certain amount\n",
      "of common sense knowledge. Hence, the impact of constructing a mind map on enhancing the model\n",
      "is not significant. Therefore, both GoT and CoT predict wrong answers.\n",
      "A.5 Representation Visualization\n",
      "In order to demonstrate the deductive reasoning process of GoT more intuitively, we visualized the\n",
      "attention weights of the GoT encoder. The visualization results can be found in Figure 12. We took\n",
      "Figure 9 as an example. In Figure 9, even given a wrong rationale, GoT still manages to generate the\n",
      "right answer. We select 14 representative thought nodes and found that \"blue\",\"color\", and \"common\"\n",
      "have the greatest weights which indicates that GoT guides the model to focus on more important\n",
      "words and conduct correct deductive reasoning. For the disruptive node \"a hard object,\" our model\n",
      "can effectively discriminate against it and assign a lower attention weight to prevent the model from\n",
      "selecting incorrect answers, as traditional CoT models often do due to erroneous rationales.\n",
      "A.6 Limitation\n",
      "Compared to Mutimodal-CoT [ 1], incorporating GoT may result in additional computational costs\n",
      "and slightly slower training times. The training parameters and inference times of the different\n",
      "models are presented in Table 8, which reveals that our model requires a 0.2% increase in parameters\n",
      "compared to Mutimodal-CoT.\n",
      "15\n",
      "Table 8: The number of training parameters and inference time of different models (# denotes\n",
      "numbers)\n",
      "#ParametersInference time\n",
      "(eval samples/per second)\n",
      "Mutimodal-CoT base[1] 227M 16.33\n",
      "Ours 233M 13.38\n",
      "16\n",
      "Dataset\n",
      "GoT Prediction\n",
      "CoT PredictionQuestion: Would you find the word pink on a dictionary page with the following guide words?\n",
      "parrot –property\n",
      "Choices: (A) yes (B) no\n",
      "Rationale :lecture :Guide words appear oneach page ofadictionary .They tellyouthefirst\n",
      "word andlastword onthepage .Theother words onthepage come between theguide\n",
      "words inalphabetical order .Toputwords inalphabetical order, putthem inorder bytheir\n",
      "firstletters .Ifthefirstletters arethesame, look atthesecond letters .Ifthesecond letters\n",
      "arethesame, look atthethird letters, andsoon.Ifoneword isshorter, andthere areno\n",
      "more letters tocompare, then theshorter word comes first inalphabetical order .For\n",
      "example, becomes before bed.\n",
      "solution :Putthewords inalphabetical order .Since pink isbetween theguide words parrot -\n",
      "property, itwould befound onthatpage .\n",
      "Answer :Theanswer is(A)\n",
      "Rationale :Solution :Guide words appear oneach page ofadictionary .They tellyouthefirst\n",
      "word andlastword onthepage .Theother words onthepage come between theguide\n",
      "words inalphabetical order .Toputwords inalphabetical order, putthem inorder bytheir\n",
      "firstletters .Ifthefirstletters arethesame, look atthesecond letters .Ifthesecond letters\n",
      "arethesame, look atthethird letters, andsoon.Ifoneword isshorter, andthere areno\n",
      "more letters tocompare, then theshorter word comes first inalphabetical order .For\n",
      "example, becomes before bed.Putthewords inalphabetical order .Since pink isbetween\n",
      "theguide words parrot -property, itwould befound onthatpage .\n",
      "Answer :Theanswer is(A)\n",
      "Rationale :Solution :Guide words appear oneach page ofadictionary .They tellyouthefirst\n",
      "word andlastword onthepage .Theother words onthepage come between theguide\n",
      "words inalphabetical order .Toputwords inalphabetical order, putthem inorder bytheir\n",
      "firstletters .Ifthefirstletters arethesame, look atthesecond letters .Ifthesecond letters\n",
      "arethesame, look atthethird letters, andsoon.Ifoneword isshorter, andthere areno\n",
      "more letters tocompare, then theshorter word comes first inalphabetical order .For\n",
      "example, becomes before bed.Putthewords inalphabetical order .Since pink isbetween\n",
      "theguide words parrot -property, itwould befound onthatpage .\n",
      "Answer :Theanswer is(B)right rationales right answer\n",
      "right rationales wrong answerFigure 7: Examples of ScienceQA\n",
      "17\n",
      "Dataset\n",
      "GoT Prediction\n",
      "CoT PredictionQuestion: What is the name of the colony shown ?\n",
      "Choices: (A) New Hampshire (B) Vermont\n",
      "(C) New York\n",
      "Rationale :The colony isNew York.During the\n",
      "colonial era,New Hampshire andNew York both\n",
      "claimed theterritory that would later become the\n",
      "state ofVermont .Vermont was never itsown\n",
      "colony .\n",
      "Answer :Theanswer is(C)\n",
      "Rationale :Solution :Thecolony isNew York.During thecolonial era,New Hampshire and\n",
      "New York both claimed theterritory that would later become thestate ofVermont .\n",
      "Vermont wasnever itsown colony .\n",
      "Answer :Theanswer is(C)\n",
      "Rationale :Solution :Thecolony isDelaware York.During thecolonial era,New Hampshire\n",
      "andNew York both claimed theterritory that would later become thestate ofVermont .\n",
      "Vermont wasnever itsown colony .\n",
      "Answer :Theanswer is(D)\n",
      "(D) Delaware\n",
      "right rationales right answer\n",
      "wrong rationales wrong answerFigure 8: Examples of ScienceQA\n",
      "18\n",
      "Dataset\n",
      "GoT Prediction\n",
      "CoT PredictionQuestion: Which property do these three \n",
      "objects have in common?\n",
      "Choices: (A) blue (B) hard\n",
      "(C) sticky\n",
      "Rationale :lecture :Anobject hasdifferent properties .Aproperty ofanobject cantellyou\n",
      "how itlooks, feels, tastes, orsmells .Properties canalso tellyouhow anobject willbehave\n",
      "when something happens toit.Different objects canhave properties incommon .Youcan\n",
      "usethese properties toputobjects intogroups .\n",
      "Solution :Look ateach object .Foreach object, decide ifithasthatproperty .Asticky object\n",
      "canattach orstick toother things .Thetoothpaste issticky, butthesoccer shorts andthe\n",
      "water slide arenot.Blue isacolor .Thiscolor isblue.Allthree objects areblue.Ahard object\n",
      "does notchange shape when pressed orsqueezed .The water slide ishard, butthe\n",
      "toothpaste and thesoccer shorts arenot.The property that allthree objects have in\n",
      "common isblue.\n",
      "Answer :Theanswer is(A)\n",
      "Rationale :Solution :Anobject hasdifferent properties .Aproperty ofanobject cantellyou\n",
      "how itlooks, feels, tastes, orsmells .Properties canalso tellyouhow anobject willbehave\n",
      "when something happens toit.Different objects canhave properties incommon .Youcan\n",
      "usethese properties toputobjects intogroups .Look ateach object .Foreach object, decide\n",
      "ifithasthatproperty .Ahard object canattach orstick toother things .The issticky, butthe\n",
      "shorts andthepitcher arenot.Blue isacolor .Thiscolor isblue.Thethree objects areblue.\n",
      "Ahard object does notchange shape when pressed orsqueezed .Thetennis slide andhard,\n",
      "butthetennis and thewater shorts arenot.Theproperty that allthree objects have in\n",
      "common isblue.\n",
      "Answer :Theanswer is(A)\n",
      "Rationale :Solution :Anobject hasdifferent properties .Aproperty ofanobject cantellyou\n",
      "how itlooks, feels, tastes, orsmells .Properties canalso tellyouhow anobject willbehave\n",
      "when something happens toit.Different objects canhave properties incommon .Youcan\n",
      "usethese properties toputobjects intogroups .Look ateach object .Foreach object, decide\n",
      "ifithasthatproperty .Asticky object canattach orstick toother things .Theissticky, butthe\n",
      "shorts andtheblue bottle arenot.Blue isacolor .Thiscolor isblue.None three objects are\n",
      "blue.Ahard object does notchange shape when pressed orsqueezed .None tennis slide\n",
      "andhard, buttheisthewater shorts arenot.Theproperty that allthree objects have in\n",
      "common issticky .\n",
      "Answer :Theanswer is(C)wrong rationales right answer\n",
      "wrong rationales wrong answerFigure 9: Examples of ScienceQA\n",
      "19\n",
      "Dataset\n",
      "GoT Prediction\n",
      "CoT PredictionQuestion: Select the action that doesn't belong\n",
      "Choices:(A) chop (B) blend\n",
      "(C) stir\n",
      "Rationale :Chop doesn't belong .Blend, mix,andstiralldescribe ways tocombine\n",
      "things\n",
      "Answer :Theanswer is(A)\n",
      "Rationale :Solution :Mixp doesn‘tbelong .Murend, chop, andchop allname things toget\n",
      "things .\n",
      "Answer :Theanswer is(D)\n",
      "Rationale :Solution :Blendp doesn't belong ..Murend ,chop, andblend allname things to\n",
      "getAnswer :Theanswer is(B)(D) mix\n",
      "wrong rationales wrong answerwrong rationales wrong answerFigure 10: Examples of ScienceQA\n",
      "20\n",
      "Dataset\n",
      "GoT Prediction\n",
      "CoT PredictionQuestion: James is putting together 4 tables.  Each table has 4 legs and each leg needs 2 \n",
      "screws.  He has 40 screws.  How many screws will he have left over?\n",
      "Rationale :Each table will take 4*2=<<4*2=8>>8screws .So he needs\n",
      "8*4=<<8*4=32>>32screws \\nThat means hewillhave 40-32=<<40-32=8>>8screws\n",
      "leftover\n",
      "Answer :Theanswer is8\n",
      "Rationale :Each table needs have 4*2=4*2=8>>8screws .Soheneeds 8*4=8*4=32>>32\n",
      "screws .That means heneeds have 40-32=40-32=8>>8leftleftover\n",
      "Answer :Theanswer is8\n",
      "Rationale :Hetable needs have 4*2=4*2=8>>8screws .Sohewill8*4=8*4=32>>32screws .\n",
      "Someans heneeds have 40-32=40-32=16>>8screws leftover\n",
      "Answer :Theanswer is168\n",
      "wrong rationales wrong answerright rationales right answer\n",
      "Dataset\n",
      "GoT Prediction\n",
      "CoT PredictionQuestion: The caretaker of the docks needs to buy some new line. He wants 3 feet of line \n",
      "for every foot of dock. Right now, there is 200 feet of dock, and he has 6 feet of new line. \n",
      "How many feet of line does he need to buy in total?\n",
      "Rationale :200*3=<<200*3=600>>600feetofline.Thecaretaker needs tobuy600-6=\n",
      "<<600-6=594>>594feetofline.\n",
      "Answer :Theanswer is594\n",
      "Rationale :Thefeet3=200*3=3>>600feetofline.Hecaretaker needs 600buy600/6=600-\n",
      "6=1>>>594feetofline.\n",
      "Answer :Theanswer is594\n",
      "Rationale :Thefeet3=200*3=3>>600feetofline.Hecaretaker needs 600buy600/6=600-\n",
      "6=15>>594feetofline.\n",
      "Answer :Theanswer is1594\n",
      "wrong rationales wrong answerwrong rationales right answerFigure 11: Examples of GSM8K\n",
      "21\n",
      "three objects\n",
      "have in\n",
      "common\n",
      "object\n",
      "has\n",
      "different properties\n",
      "put objects into\n",
      "groups\n",
      "a hard object\n",
      "can attach to\n",
      "other things\n",
      "is\n",
      "color\n",
      "blue49.56\n",
      "44.00\n",
      "Figure 12: Representation visualization\n",
      "22\n",
      "Chain-of-Thought Prompting Elicits Reasoning\n",
      "in Large Language Models\n",
      "Jason Wei Xuezhi Wang Dale Schuurmans Maarten Bosma\n",
      "Brian Ichter Fei Xia Ed H. Chi Quoc V . Le Denny Zhou\n",
      "Google Research, Brain Team\n",
      "{jasonwei,dennyzhou}@google.com\n",
      "Abstract\n",
      "We explore how generating a chain of thought —a series of intermediate reasoning\n",
      "steps—signiﬁcantly improves the ability of large language models to perform\n",
      "complex reasoning. In particular, we show how such reasoning abilities emerge\n",
      "naturally in sufﬁciently large language models via a simple method called chain-of-\n",
      "thought prompting , where a few chain of thought demonstrations are provided as\n",
      "exemplars in prompting.\n",
      "Experiments on three large language models show that chain-of-thought prompting\n",
      "improves performance on a range of arithmetic, commonsense, and symbolic\n",
      "reasoning tasks. The empirical gains can be striking. For instance, prompting a\n",
      "PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art\n",
      "accuracy on the GSM8K benchmark of math word problems, surpassing even\n",
      "ﬁnetuned GPT-3 with a veriﬁer.\n",
      "A: The cafeteria had 23 apples originally. They used 20 to make lunch. So they had 23 - 20 = 3. They bought 6 more apples, so they have 3 + 6 = 9. The answer is 9.Chain-of-Thought PromptingQ: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? A: The answer is 11. Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?A: The answer is 27.Standard Prompting\n",
      "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11. Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?Model Input\n",
      "Model OutputModel OutputModel Input\n",
      "Figure 1: Chain-of-thought prompting enables large language models to tackle complex arithmetic,\n",
      "commonsense, and symbolic reasoning tasks. Chain-of-thought reasoning processes are highlighted.\n",
      "36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2201.11903v6  [cs.CL]  10 Jan 2023\n",
      "1 Introduction\n",
      "Math Word Problems (GSM8K)020406080100\n",
      "3355\n",
      "1857Solve rate (%)Finetuned GPT-3 175B\n",
      "Prior best\n",
      "PaLM 540B: standard prompting\n",
      "PaLM 540B: chain-of-thought prompting\n",
      "Figure 2: PaLM 540B uses chain-of-\n",
      "thought prompting to achieve new state-\n",
      "of-the-art performance on the GSM8K\n",
      "benchmark of math word problems.\n",
      "Finetuned GPT-3 and prior best are from\n",
      "Cobbe et al. (2021).The NLP landscape has recently been revolutionized by\n",
      "language models (Peters et al., 2018; Devlin et al., 2019;\n",
      "Brown et al., 2020, inter alia ). Scaling up the size of lan-\n",
      "guage models has been shown to confer a range of beneﬁts,\n",
      "such as improved performance and sample efﬁciency (Ka-\n",
      "plan et al., 2020; Brown et al., 2020, inter alia ). However,\n",
      "scaling up model size alone has not proved sufﬁcient for\n",
      "achieving high performance on challenging tasks such as\n",
      "arithmetic, commonsense, and symbolic reasoning (Rae\n",
      "et al., 2021).\n",
      "This work explores how the reasoning ability of large\n",
      "language models can be unlocked by a simple method\n",
      "motivated by two ideas. First, techniques for arithmetic\n",
      "reasoning can beneﬁt from generating natural language\n",
      "rationales that lead to the ﬁnal answer. Prior work has\n",
      "given models the ability to generate natural language inter-\n",
      "mediate steps by training from scratch (Ling et al., 2017)\n",
      "or ﬁnetuning a pretrained model (Cobbe et al., 2021), in\n",
      "addition to neuro-symbolic methods that use formal lan-\n",
      "guages instead of natural language (Roy and Roth, 2015;\n",
      "Chiang and Chen, 2019; Amini et al., 2019; Chen et al.,\n",
      "2019). Second, large language models offer the exciting\n",
      "prospect of in-context few-shot learning via prompting . That is, instead of ﬁnetuning a separate\n",
      "language model checkpoint for each new task, one can simply “prompt” the model with a few\n",
      "input–output exemplars demonstrating the task. Remarkably, this has been successful for a range of\n",
      "simple question-answering tasks (Brown et al., 2020).\n",
      "Both of the above ideas, however, have key limitations. For rationale-augmented training and\n",
      "ﬁnetuning methods, it is costly to create a large set of high quality rationales, which is much more\n",
      "complicated than simple input–output pairs used in normal machine learning. For the traditional few-\n",
      "shot prompting method used in Brown et al. (2020), it works poorly on tasks that require reasoning\n",
      "abilities, and often does not improve substantially with increasing language model scale (Rae et al.,\n",
      "2021). In this paper, we combine the strengths of these two ideas in a way that avoids their limitations.\n",
      "Speciﬁcally, we explore the ability of language models to perform few-shot prompting for reasoning\n",
      "tasks, given a prompt that consists of triples: ⟨input, chain of thought , output⟩. Achain of thought is\n",
      "a series of intermediate natural language reasoning steps that lead to the ﬁnal output, and we refer to\n",
      "this approach as chain-of-thought prompting . An example prompt is shown in Figure 1.\n",
      "We present empirical evaluations on arithmetic, commonsense, and symbolic reasoning benchmarks,\n",
      "showing that chain-of-thought prompting outperforms standard prompting, sometimes to a striking\n",
      "degree. Figure 2 illustrates one such result—on the GSM8K benchmark of math word problems\n",
      "(Cobbe et al., 2021), chain-of-thought prompting with PaLM 540B outperforms standard prompting\n",
      "by a large margin and achieves new state-of-the-art performance. A prompting only approach is\n",
      "important because it does not require a large training dataset and because a single model checkpoint\n",
      "can perform many tasks without loss of generality. This work underscores how large language models\n",
      "can learn via a few examples with natural language data about the task (c.f. automatically learning\n",
      "the patterns underlying inputs and outputs via a large training dataset).\n",
      "2 Chain-of-Thought Prompting\n",
      "Consider one’s own thought process when solving a complicated reasoning task such as a multi-step\n",
      "math word problem. It is typical to decompose the problem into intermediate steps and solve each\n",
      "before giving the ﬁnal answer: “After Jane gives 2 ﬂowers to her mom she has 10 ...then after she\n",
      "gives 3 to her dad she will have 7 ...so the answer is 7. ” The goal of this paper is to endow language\n",
      "models with the ability to generate a similar chain of thought —a coherent series of intermediate\n",
      "reasoning steps that lead to the ﬁnal answer for a problem. We will show that sufﬁciently large\n",
      "2\n",
      "language models can generate chains of thought if demonstrations of chain-of-thought reasoning are\n",
      "provided in the exemplars for few-shot prompting.\n",
      "Figure 1 shows an example of a model producing a chain of thought to solve a math word problem\n",
      "that it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\n",
      "and can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\n",
      "mimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\n",
      "typically come after the ﬁnal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\n",
      "2022, inter alia )).\n",
      "Chain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\n",
      "in language models.\n",
      "1.First, chain of thought, in principle, allows models to decompose multi-step problems into\n",
      "intermediate steps, which means that additional computation can be allocated to problems\n",
      "that require more reasoning steps.\n",
      "2.Second, a chain of thought provides an interpretable window into the behavior of the model,\n",
      "suggesting how it might have arrived at a particular answer and providing opportunities\n",
      "to debug where the reasoning path went wrong (although fully characterizing a model’s\n",
      "computations that support an answer remains an open question).\n",
      "3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\n",
      "commonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\n",
      "in principle) to any task that humans can solve via language.\n",
      "4.Finally, chain-of-thought reasoning can be readily elicited in sufﬁciently large off-the-shelf\n",
      "language models simply by including examples of chain of thought sequences into the\n",
      "exemplars of few-shot prompting.\n",
      "In empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\n",
      "reasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\n",
      "3 Arithmetic Reasoning\n",
      "We begin by considering math word problems of the form in Figure 1, which measure the arithmetic\n",
      "reasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\n",
      "language models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\n",
      "of-thought prompting when used with the 540B parameter language model performs comparably with\n",
      "task-speciﬁc ﬁnetuned models on several tasks, even achieving new state of the art on the challenging\n",
      "GSM8K benchmark (Cobbe et al., 2021).\n",
      "3.1 Experimental Setup\n",
      "We explore chain-of-thought prompting for various language models on multiple benchmarks.\n",
      "Benchmarks. We consider the following ﬁve math word problem benchmarks: (1)theGSM8K\n",
      "benchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\n",
      "problems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\n",
      "problems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\n",
      "benchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\n",
      "Standard prompting. For the baseline, we consider standard few-shot prompting, popularized by\n",
      "Brown et al. (2020), in which a language model is given in-context exemplars of input–output pairs\n",
      "before outputting a prediction for a test-time example. Exemplars are formatted as questions and\n",
      "answers. The model gives the answer directly, as shown in Figure 1 (left).\n",
      "Chain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\n",
      "prompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\n",
      "of the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\n",
      "with chains of thought for prompting—Figure 1 (right) shows one chain of thought exemplar, and the\n",
      "full set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\n",
      "prompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\n",
      "chain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\n",
      "3\n",
      "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.Q: Sammy wanted to go to where the people were. Where might he go? Options: (a) race track (b) populated areas (c) desert (d) apartment (e) roadblock A: The answer must be a place with a lot of people. Race tracks, desert, apartments, and roadblocks don't have a lot of people, but populated areas do. So the answer is (b). Q: Yes or no: Would a pear sink in water? A: The density of a pear is about 0.6 g/cm^3, which is less than water. Thus, a pear would float. So the answer is no.Q: The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10 days ago in MM/DD/YYYY?  A: One day after 06/01/1943 is 06/02/1943, so today is 06/02/1943. 10 days before today is 05/23/1943. So the answer is 05/23/1943. Q: Is the following sentence plausible? \"Joao Moutinho caught the screen pass in the NFC championship.\"  A: Joao Moutinho is a soccer player. The NFC championship is part of American football, not soccer. So the answer is no.Q: Take the last letters of the words in “Lady Gaga” and concatenate them. A: The last letter of “Lady” is “y”. The last letter of “Gaga” is “a”. Concatenating them is “ya”. So the answer is ya.Q: A coin is heads up. Maybelle flips the coin. Shalonda does not flip the coin. Is the coin still heads up? A: The coin was flipped by Maybelle. So the coin was flipped 1 time, which is an odd number. The coin started heads up, so after an odd number of flips, it will be tails up. So the answer is no.Math Word Problems (free response)Math Word Problems (multiple choice)CSQA (commonsense)\n",
      "StrategyQADate UnderstandingSports Understanding\n",
      "Last Letter ConcatenationCoin Flip (state tracking)Q: How many keystrokes are needed to type the numbers from 1 to 500?Answer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788 A: There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401 three-digit numbers from 100 to 500. 9 + 90(2) + 401(3) = 1392. The answer is (b).\n",
      "SayCan (Instructing a robot)Human: How would you bring me something that isn’t a fruit? Explanation: the user wants something to eat that isn’t a fruit. An energy bar is not a fruit, so I will bring the user an energy bar.  Plan: 1. find(energy bar) 2. pick(energy bar) 3. find(user) 4. put(energy bar) 5. done().Figure 3: Examples of ⟨input, chain of thought, output ⟩triples for arithmetic, commonsense, and\n",
      "symbolic reasoning benchmarks. Chains of thought are highlighted. Full prompts in Appendix G.\n",
      "math word problems, we used this single set of eight chain of thought exemplars for all benchmarks\n",
      "except AQuA, which is multiple choice instead of free response. For AQuA, we used four exemplars\n",
      "and solutions from the training set, as given in Appendix Table 21.\n",
      "Language models. We evaluate ﬁve large language models. The ﬁrst is GPT-3 (Brown et al.,\n",
      "2020), for which we use text-ada-001, text-babbage-001, text-curie-001, and text-davinci-002, which\n",
      "presumably correspond to InstructGPT models of 350M, 1.3B, 6.7B, and 175B parameters (Ouyang\n",
      "et al., 2022).The second is LaMDA (Thoppilan et al., 2022), which has models of 422M, 2B, 8B,\n",
      "68B, and 137B parameters. The third is PaLM , which has models of 8B, 62B, and 540B parameters.\n",
      "The fourth is UL2 20B (Tay et al., 2022), and the ﬁfth is Codex (Chen et al., 2021, code-davinci-002\n",
      "in the OpenAI API). We sample from the models via greedy decoding (though follow-up work shows\n",
      "chain-of-thought prompting can be improved by taking the majority ﬁnal answer over many sampled\n",
      "generations (Wang et al., 2022a)). For LaMDA, we report averaged results over ﬁve random seeds,\n",
      "where each seed had a different randomly shufﬂed order of exemplars. As LaMDA experiments\n",
      "did not show large variance among different seeds, to save compute we report results for a single\n",
      "exemplar order for all other models.\n",
      "3.2 Results\n",
      "The strongest results of chain-of-thought prompting are summarized in Figure 4, with all experimental\n",
      "outputs for each model collection, model size, and benchmark shown in Table 2 in the Appendix.\n",
      "There are three key takeaways. First, Figure 4 shows that chain-of-thought prompting is an emergent\n",
      "ability of model scale (Wei et al., 2022b). That is, chain-of-thought prompting does not positively\n",
      "impact performance for small models, and only yields performance gains when used with models of\n",
      "∼100B parameters. We qualitatively found that models of smaller scale produced ﬂuent but illogical\n",
      "chains of thought, leading to lower performance than standard prompting.\n",
      "4\n",
      "0204060GSM8K\n",
      "solve rate (%)LaMDA GPT PaLMStandard prompting\n",
      "Chain-of-thought prompting\n",
      "Prior supervised best\n",
      "020406080SV AMP\n",
      "solve rate (%)\n",
      "0.4 81370255075100MAWPS\n",
      "solve rate (%)\n",
      "0.4 7175 862540\n",
      "Model scale (# parameters in billions)\n",
      "Figure 4: Chain-of-thought prompting enables\n",
      "large language models to solve challenging math\n",
      "problems. Notably, chain-of-thought reasoning\n",
      "is an emergent ability of increasing model scale.\n",
      "Prior best numbers are from Cobbe et al. (2021)\n",
      "for GSM8K, Jie et al. (2022) for SV AMP, and Lan\n",
      "et al. (2021) for MAWPS.Second, chain-of-thought prompting has larger\n",
      "performance gains for more-complicated prob-\n",
      "lems. For instance, for GSM8K (the dataset\n",
      "with the lowest baseline performance), perfor-\n",
      "mance more than doubled for the largest GPT\n",
      "and PaLM models. On the other hand, for Sin-\n",
      "gleOp, the easiest subset of MAWPS which only\n",
      "requires a single step to solve, performance im-\n",
      "provements were either negative or very small\n",
      "(see Appendix Table 3).\n",
      "Third, chain-of-thought prompting via GPT-3\n",
      "175B and PaLM 540B compares favorably to\n",
      "prior state of the art, which typically ﬁnetunes a\n",
      "task-speciﬁc model on a labeled training dataset.\n",
      "Figure 4 shows how PaLM 540B uses chain-of-\n",
      "thought prompting to achieve new state of the art\n",
      "on GSM8K, SV AMP, and MAWPS (though note\n",
      "that standard prompting already passed the prior\n",
      "best for SV AMP). On the other two datasets,\n",
      "AQuA and ASDiv, PaLM with chain-of-thought\n",
      "prompting reaches within 2% of the state of the\n",
      "art (Appendix Table 2).\n",
      "To better understand why chain-of-thought\n",
      "prompting works, we manually examined model-\n",
      "generated chains of thought by LaMDA 137B\n",
      "for GSM8K. Of 50 random examples where the\n",
      "model returned the correct ﬁnal answer, all of\n",
      "the generated chains of thought were also log-\n",
      "ically and mathematically correct except two\n",
      "that coincidentally arrived at the correct answer\n",
      "(see Appendix D.1, and Table 8 for examples\n",
      "of correct model-generated chains of thought).\n",
      "We also randomly examined 50 random sam-\n",
      "ples for which the model gave the wrong answer.\n",
      "The summary of this analysis is that 46% of the\n",
      "chains of thought were almost correct, barring\n",
      "minor mistakes (calculator error, symbol map-\n",
      "ping error, or one reasoning step missing), and that the other 54% of the chains of thought had major\n",
      "errors in semantic understanding or coherence (see Appendix D.2). To provide a small insight into\n",
      "why scaling improves chain-of-thought reasoning ability, we performed a similar analysis of errors\n",
      "made by PaLM 62B and whether those errors were ﬁxed by scaling to PaLM 540B. The summary\n",
      "is that scaling PaLM to 540B ﬁxes a large portion of one-step missing and semantic understanding\n",
      "errors in the 62B model (see Appendix A.1).\n",
      "3.3 Ablation Study\n",
      "The observed beneﬁts of using chain-of-thought prompting raises the natural question of whether the\n",
      "same performance improvements can be conferred via other types of prompting. Figure 5 shows an\n",
      "ablation study with three variations of chain of thought described below.\n",
      "Equation only. One reason for why chain-of-thought prompting might help is that it produces the\n",
      "mathematical equation to be evaluated, and so we test a variation where the model is prompted\n",
      "to output only a mathematical equation before giving the answer. Figure 5 shows that equation\n",
      "only prompting does not help much for GSM8K, which implies that the semantics of the questions\n",
      "in GSM8K are too challenging to directly translate into an equation without the natural language\n",
      "reasoning steps in chain of thought. For datasets of one-step or two-step problems, however, we ﬁnd\n",
      "that equation only prompting does improve performance, since the equation can be easily derived\n",
      "from the question (see Appendix Table 6).\n",
      "5\n",
      "LaMDA PaLM0204060GSM8K solve rate (%)Standard prompting\n",
      "Equation only\n",
      "Variable compute only\n",
      "Reasoning after answer\n",
      "Chain-of-thought prompting\n",
      "Figure 5: Ablation study for dif-\n",
      "ferent variations of prompting us-\n",
      "ing LaMDA 137B and PaLM 540B.\n",
      "Results for other datasets are given\n",
      "in Appendix Table 6 and Table 7.Variable compute only. Another intuition is that chain of\n",
      "thought allows the model to spend more computation (i.e.,\n",
      "intermediate tokens) on harder problems. To isolate the effect\n",
      "of variable computation from chain-of-thought reasoning, we\n",
      "test a conﬁguration where the model is prompted to output a\n",
      "only sequence of dots ( ...) equal to the number of characters in\n",
      "the equation needed to solve the problem. This variant performs\n",
      "about the same as the baseline, which suggests that variable\n",
      "computation by itself is not the reason for the success of chain-\n",
      "of-thought prompting, and that there appears to be utility from\n",
      "expressing intermediate steps via natural language.\n",
      "Chain of thought after answer. Another potential beneﬁt of\n",
      "chain-of-thought prompting could simply be that such prompts\n",
      "allow the model to better access relevant knowledge acquired\n",
      "during pretraining. Therefore, we test an alternative conﬁgura-\n",
      "tion where the chain of thought prompt is only given after the\n",
      "answer, isolating whether the model actually depends on the\n",
      "produced chain of thought to give the ﬁnal answer. This variant\n",
      "performs about the same as the baseline, which suggests that\n",
      "the sequential reasoning embodied in the chain of thought is\n",
      "useful for reasons beyond just activating knowledge.\n",
      "3.4 Robustness of Chain of Thought\n",
      "GSM8K05101520Solve rate (%)Standard prompting\n",
      "Chain-of-thought prompting\n",
      "·different annotator (B)\n",
      "·different annotator (C)\n",
      "·intentionally concise style\n",
      "·exemplars from GSM8K ( α)\n",
      "·exemplars from GSM8K ( β)\n",
      "·exemplars from GSM8K ( γ)\n",
      "MAWPS0204060\n",
      "Figure 6: Chain-of-thought prompting\n",
      "has variance for different prompt exam-\n",
      "ples (as expected) but outperforms stan-\n",
      "dard prompting for various annotators as\n",
      "well as for different exemplars.Sensitivity to exemplars is a key consideration of prompt-\n",
      "ing approaches—for instance, varying the permutation of\n",
      "few-shot exemplars can cause the accuracy of GPT-3 on\n",
      "SST-2 to range from near chance (54.3%) to near state of\n",
      "the art (93.4%) (Zhao et al., 2021). In this ﬁnal subsec-\n",
      "tion, we evaluate robustness to chains of thought written\n",
      "by different annotators. In addition to the results above,\n",
      "which used chains of thought written by an Annotator\n",
      "A, two other co-authors of this paper (Annotators B and\n",
      "C) independently wrote chains of thought for the same\n",
      "few-shot exemplars (shown in Appendix H). Annotator A\n",
      "also wrote another chain of thought that was more concise\n",
      "than the original, following the style of solutions given in\n",
      "Cobbe et al. (2021).1\n",
      "Figure 6 shows these results for LaMDA 137B on GSM8K\n",
      "and MAWPS (ablation results for other datasets are given\n",
      "in Appendix Table 6 / Table 7). Although there is variance\n",
      "among different chain of thought annotations, as would be\n",
      "expected when using exemplar-based prompting (Le Scao\n",
      "and Rush, 2021; Reynolds and McDonell, 2021; Zhao\n",
      "et al., 2021), all sets of chain of thought prompts outper-\n",
      "form the standard baseline by a large margin. This result\n",
      "implies that successful use of chain of thought does not\n",
      "depend on a particular linguistic style.\n",
      "To conﬁrm that successful chain-of-thought prompting\n",
      "works for other sets of exemplars, we also run experiments\n",
      "with three sets of eight exemplars randomly sampled from the GSM8K training set, an independent\n",
      "1For instance, whereas original chain of thought uses several short sentences ( “’There were originally 9\n",
      "computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is\n",
      "29. ”), the concise chain of thought would read “5 * 4 = 20 new computers were added. So there are 9 + 20 = 29\n",
      "new computers in the server room now” .\n",
      "6\n",
      "source (examples in this dataset already included reasoning steps like a chain of thought).2Fig-\n",
      "ure 6 shows that these prompts performed comparably with our manually written exemplars, also\n",
      "substantially outperforming standard prompting.\n",
      "In addition to robustness to annotators, independently-written chains of thought, different exemplars,\n",
      "and various language models, we also ﬁnd that chain-of-thought prompting for arithmetic reasoning\n",
      "is robust to different exemplar orders and varying numbers of exemplars (see Appendix A.2).\n",
      "4 Commonsense Reasoning\n",
      "Although chain of thought is particularly suitable for math word problems, the language-based nature\n",
      "of chain of thought actually makes it applicable to a broad class of commonsense reasoning problems,\n",
      "which involve reasoning about physical and human interactions under the presumption of general\n",
      "background knowledge. Commonsense reasoning is key for interacting with the world and is still\n",
      "beyond the reach of current natural language understanding systems (Talmor et al., 2021).\n",
      "Benchmarks. We consider ﬁve datasets covering a diverse range of commonsense reasoning types.\n",
      "The popular CSQA (Talmor et al., 2019) asks commonsense questions about the world involving\n",
      "complex semantics that often require prior knowledge. StrategyQA (Geva et al., 2021) requires\n",
      "models to infer a multi-hop strategy to answer questions. We choose two specialized evaluation sets\n",
      "from the BIG-bench effort (BIG-bench collaboration, 2021): Date Understanding, which involves\n",
      "inferring a date from a given context, and Sports Understanding, which involves determining whether\n",
      "a sentence relating to sports is plausible or implausible. Finally, the SayCan dataset (Ahn et al.,\n",
      "2022) involves mapping a natural language instruction to a sequence of robot actions from a discrete\n",
      "set. Figure 3 shows examples with chain of thought annotations for all datasets.\n",
      "Prompts. We follow the same experimental setup as the prior section. For CSQA and StrategyQA,\n",
      "we randomly selected examples from the training set and manually composed chains of thought for\n",
      "them to use as few-shot exemplars. The two BIG-bench tasks do not have training sets, so we selected\n",
      "the ﬁrst ten examples as exemplars in the evaluation set as few-shot exemplars and report numbers on\n",
      "the rest of the evaluation set. For SayCan, we use six examples from the training set used in Ahn et al.\n",
      "(2022) and also manually composed chains of thought.\n",
      "Results. Figure 7 highlights these results for PaLM (full results for LaMDA, GPT-3, and different\n",
      "model scales are shown in Table 4). For all tasks, scaling up model size improved the performance\n",
      "of standard prompting; chain-of-thought prompting led to further gains, with improvements appear-\n",
      "ing to be largest for PaLM 540B. With chain-of-thought prompting, PaLM 540B achieved strong\n",
      "performance relative to baselines, outperforming the prior state of the art on StrategyQA (75.6% vs\n",
      "69.4%) and outperforming an unaided sports enthusiast on sports understanding (95.4% vs 84%).\n",
      "These results demonstrate that chain-of-thought prompting can also improve performance on tasks\n",
      "requiring a range of commonsense reasoning abilities (though note that gain was minimal on CSQA).\n",
      "86254020406080100 Solve rate (%)CSQA\n",
      "8625405060708090StrategyQA\n",
      "Standard prompting\n",
      "Chain of thought\n",
      "Prior supervised best\n",
      "Human\n",
      "862540020406080\n",
      "Model scale (# parameters in billions)Date\n",
      "862540406080100Sports\n",
      "86254020406080100SayCan\n",
      "Figure 7: Chain-of-thought prompting also improves the commonsense reasoning abilities of\n",
      "language models. The language model shown here is PaLM. Prior best numbers are from the\n",
      "leaderboards of CSQA (Talmor et al., 2019) and StrategyQA (Geva et al., 2021) (single-model only,\n",
      "as of May 5, 2022). Additional results using various sizes of LaMDA, GPT-3, and PaLM are shown\n",
      "in Table 4.\n",
      "2We sample examples ≤60tokens to ﬁt into our input context window, and also limit the examples to ≤2\n",
      "steps to solve for a fair comparison with the eight exemplars that we composed.\n",
      "7\n",
      "5 Symbolic Reasoning\n",
      "0255075100 Solve rate (%)Letter Concat: 2\n",
      "(in domain)Letter Concat: 4\n",
      "(OOD)Standard prompting\n",
      "Chain-of-thought prompting\n",
      "8 62 540406080100 Solve rate (%)Coin Flip: 2\n",
      "(in domain)\n",
      "8 62 540\n",
      "Model scale (# parameters in billions)Coin Flip: 4\n",
      "(OOD)\n",
      "Figure 8: Using chain-of-thought\n",
      "prompting facilitates generalization to\n",
      "longer sequences in two symbolic rea-\n",
      "soning tasks.Our ﬁnal experimental evaluation considers symbolic rea-\n",
      "soning, which is simple for humans but potentially chal-\n",
      "lenging for language models. We show that chain-of-\n",
      "thought prompting not only enables language models to\n",
      "perform symbolic reasoning tasks that are challenging in\n",
      "the standard prompting setting, but also facilitates length\n",
      "generalization to inference-time inputs longer than those\n",
      "seen in the few-shot exemplars.\n",
      "Tasks. We use the following two toy tasks.\n",
      "•Last letter concatenation. This task asks the model\n",
      "to concatenate the last letters of words in a name (e.g.,\n",
      "“Amy Brown”→“yn” ). It is a more challenging version\n",
      "of ﬁrst letter concatenation, which language models can\n",
      "already perform without chain of thought.3We generate\n",
      "full names by randomly concatenating names from the\n",
      "top one-thousand ﬁrst and last names from name census\n",
      "data ( https://namecensus.com/ ).\n",
      "•Coin ﬂip. This task asks the model to answer whether a\n",
      "coin is still heads up after people either ﬂip or don’t ﬂip\n",
      "the coin (e.g., “A coin is heads up. Phoebe ﬂips the coin.\n",
      "Osvaldo does not ﬂip the coin. Is the coin still heads up?”\n",
      "→“no” ).\n",
      "As the construction of these symbolic reasoning tasks is\n",
      "well-deﬁned, for each task we consider an in-domain test\n",
      "set for which examples had the same number of steps as\n",
      "the training/few-shot exemplars, as well as an out-of-domain (OOD) test set, for which evaluation\n",
      "examples had more steps than those in the exemplars. For last letter concatenation, the model only\n",
      "sees exemplars of names with two words, and then performs last letter concatenation on names with 3\n",
      "and 4 words.4We do the same for the number of potential ﬂips in the coin ﬂip task. Our experimental\n",
      "setup uses the same methods and models as in the prior two sections. We again manually compose\n",
      "chains of thought for the few-shot exemplars for each task, which are given in Figure 3.\n",
      "Results. The results of these in-domain and OOD evaluations are shown in Figure 8 for PaLM,\n",
      "with results for LaMDA shown in Appendix Table 5. With PaLM 540B, chain-of-thought prompting\n",
      "leads to almost 100% solve rates (note that standard prompting already solves coin ﬂip with PaLM\n",
      "540, though not for LaMDA 137B). Note that these in-domain evaluations are “toy tasks” in the\n",
      "sense that perfect solution structures are already provided by the chains of thought in the few-shot\n",
      "exemplars; all the model has to do is repeat the same steps with the new symbols in the test-time\n",
      "example. And yet, small models still fail—the ability to perform abstract manipulations on unseen\n",
      "symbols for these three tasks only arises at the scale of 100B model parameters.\n",
      "As for the OOD evaluations, standard prompting fails for both tasks. With chain-of-thought prompting,\n",
      "language models achieve upward scaling curves (though performance is lower than in the in-domain\n",
      "setting). Hence, chain-of-thought prompting facilitates length generalization beyond seen chains of\n",
      "thought for language models of sufﬁcient scale.\n",
      "6 Discussion\n",
      "We have explored chain-of-thought prompting as a simple mechanism for eliciting multi-step rea-\n",
      "soning behavior in large language models. We ﬁrst saw that chain-of-thought prompting improves\n",
      "performance by a large margin on arithmetic reasoning, yielding improvements that are much stronger\n",
      "than ablations and robust to different annotators, exemplars, and language models (Section 3). Next,\n",
      "3We tested 10 common names using GPT-3 davinci and it got all but one correct.\n",
      "4For names of length longer than 2 words, we concatenate multiple ﬁrst and last names together.\n",
      "8\n",
      "experiments on commonsense reasoning underscored how the linguistic nature of chain-of-thought\n",
      "reasoning makes it generally applicable (Section 4). Finally, we showed that for symbolic reasoning,\n",
      "chain-of-thought prompting facilitates OOD generalization to longer sequence lengths (Section 5). In\n",
      "all experiments, chain-of-thought reasoning is elicited simply by prompting an off-the-shelf language\n",
      "model. No language models were ﬁnetuned in the process of writing this paper.\n",
      "The emergence of chain-of-thought reasoning as a result of model scale has been a prevailing theme\n",
      "(Wei et al., 2022b). For many reasoning tasks where standard prompting has a ﬂat scaling curve, chain-\n",
      "of-thought prompting leads to dramatically increasing scaling curves. Chain-of-thought prompting\n",
      "appears to expand the set of tasks that large language models can perform successfully—in other\n",
      "words, our work underscores that standard prompting only provides a lower bound on the capabilities\n",
      "of large language models. This observation likely raises more questions than it answers—for instance,\n",
      "how much more can we expect reasoning ability to improve with a further increase in model scale?\n",
      "What other prompting methods might expand the range of tasks that language models can solve?\n",
      "As for limitations, we ﬁrst qualify that although chain of thought emulates the thought processes of\n",
      "human reasoners, this does not answer whether the neural network is actually “reasoning,” which\n",
      "we leave as an open question. Second, although the cost of manually augmenting exemplars with\n",
      "chains of thought is minimal in the few-shot setting, such annotation costs could be prohibitive for\n",
      "ﬁnetuning (though this could potentially be surmounted with synthetic data generation, or zero-shot\n",
      "generalization). Third, there is no guarantee of correct reasoning paths, which can lead to both correct\n",
      "and incorrect answers; improving factual generations of language models is an open direction for\n",
      "future work (Rashkin et al., 2021; Ye and Durrett, 2022; Wiegreffe et al., 2022, inter alia ). Finally,\n",
      "the emergence of chain-of-thought reasoning only at large model scales makes it costly to serve in\n",
      "real-world applications; further research could explore how to induce reasoning in smaller models.\n",
      "7 Related Work\n",
      "This work is inspired by many research areas, which we detail in an extended related work section\n",
      "(Appendix C). Here we describe two directions and associated papers that are perhaps most relevant.\n",
      "The ﬁrst relevant direction is using intermediate steps to solve reasoning problems. Ling et al. (2017)\n",
      "pioneer the idea of using natural language rationales to solve math word problems through a series\n",
      "of intermediate steps. Their work is a remarkable contrast to the literature using formal languages\n",
      "to reason (Roy et al., 2015; Chiang and Chen, 2019; Amini et al., 2019; Chen et al., 2019). Cobbe\n",
      "et al. (2021) extend Ling et al. (2017) by creating a larger dataset and using it to ﬁnetune a pretrained\n",
      "language model rather than training a model from scratch. In the domain of program synthesis,\n",
      "Nye et al. (2021) leverage language models to predict the ﬁnal outputs of Python programs via\n",
      "ﬁrst line-to-line predicting the intermediate computational results, and show that their step-by-step\n",
      "prediction method performs better than directly predicting the ﬁnal outputs.\n",
      "Naturally, this paper also relates closely to the large body of recent work on prompting. Since the\n",
      "popularization of few-shot prompting as given by Brown et al. (2020), several general approaches\n",
      "have improved the prompting ability of models, such as automatically learning prompts (Lester et al.,\n",
      "2021) or giving models instructions describing a task (Wei et al., 2022a; Sanh et al., 2022; Ouyang\n",
      "et al., 2022). Whereas these approaches improve or augment the input part of the prompt (e.g.,\n",
      "instructions that are prepended to inputs), our work takes the orthogonal direction of augmenting the\n",
      "outputs of language models with a chain of thought.\n",
      "8 Conclusions\n",
      "We have explored chain-of-thought prompting as a simple and broadly applicable method for enhanc-\n",
      "ing reasoning in language models. Through experiments on arithmetic, symbolic, and commonsense\n",
      "reasoning, we ﬁnd that chain-of-thought reasoning is an emergent property of model scale that allows\n",
      "sufﬁciently large language models to perform reasoning tasks that otherwise have ﬂat scaling curves.\n",
      "Broadening the range of reasoning tasks that language models can perform will hopefully inspire\n",
      "further work on language-based approaches to reasoning.\n",
      "9\n",
      "Acknowledgements\n",
      "We thank Jacob Devlin, Claire Cui, Andrew Dai, and Ellie Pavlick for providing feedback on the\n",
      "paper. We thank Jacob Austin, Yuhuai Wu, Henryk Michalewski, Aitor Lewkowycz, Charles Sutton,\n",
      "and Aakanksha Chowdhery for helpful discussions. We thank Sid Maxwell for notifying us about a\n",
      "mistake in the manual error analysis in the original manuscript.\n",
      "References\n",
      "Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea\n",
      "Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, et al. 2022. Do as I can, not as I\n",
      "say: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691 .\n",
      "Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh\n",
      "Hajishirzi. 2019. MathQA: Towards interpretable math word problem solving with operation-\n",
      "based formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the\n",
      "Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and\n",
      "Short Papers) , Minneapolis, Minnesota. Association for Computational Linguistics.\n",
      "Daniel Andor, Luheng He, Kenton Lee, and Emily Pitler. 2019. Giving BERT a calculator: Finding\n",
      "operations and arguments with reading comprehension. EMNLP .\n",
      "Jacob Andreas, Dan Klein, and Sergey Levine. 2018. Learning with latent language. NAACL .\n",
      "Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\n",
      "Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. 2021. Program synthesis with large language\n",
      "models. arXiv preprint arXiv:2108.07732 .\n",
      "BIG-bench collaboration. 2021. Beyond the imitation game: Measuring and extrapolating the\n",
      "capabilities of language models. In preparation .\n",
      "Kaj Bostrom, Xinyu Zhao, Swarat Chaudhuri, and Greg Durrett. 2021. Flexible generation of natural\n",
      "language deductions. EMNLP .\n",
      "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\n",
      "Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\n",
      "Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,\n",
      "Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\n",
      "Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\n",
      "and Dario Amodei. 2020. Language models are few-shot learners. NeurIPS .\n",
      "Jonathon Cai, Richard Shin, and Dawn Song. 2017. Making neural programming architectures\n",
      "generalize via recursion. ICLR .\n",
      "Oana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom. 2018. e-SNLI:\n",
      "Natural language inference with natural language explanations. NeurIPS .\n",
      "Howard Chen, Jacqueline He, Karthik Narasimhan, and Danqi Chen. 2022. Can rationalization\n",
      "improve robustness? NAACL .\n",
      "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\n",
      "Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating\n",
      "large language models trained on code. arXiv preprint arXiv:2107.03374 .\n",
      "Xinyun Chen, Chen Liang, Adams Wei Yu, Denny Zhou, Dawn Song, and Quoc V . Le. 2019. Neural\n",
      "symbolic reader: Scalable integration of distributed and symbolic representations for reading\n",
      "comprehension. ICLR .\n",
      "Ting-Rui Chiang and Yun-Nung Chen. 2019. Semantically-aligned equation generation for solving\n",
      "and reasoning math word problems. In Proceedings of the 2019 Conference of the North Ameri-\n",
      "can Chapter of the Association for Computational Linguistics: Human Language Technologies,\n",
      "Volume 1 (Long and Short Papers) , pages 2656–2668, Minneapolis, Minnesota. Association for\n",
      "Computational Linguistics.\n",
      "10\n",
      "Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over\n",
      "language. IJCAI .\n",
      "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher\n",
      "Hesse, and John Schulman. 2021. Training veriﬁers to solve math word problems. arXiv preprint\n",
      "arXiv:2110.14168 .\n",
      "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of\n",
      "deep bidirectional transformers for language understanding. NAACL .\n",
      "Honghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, and Denny Zhou. 2019. Neural\n",
      "logic machines. ICLR .\n",
      "Dheeru Dua, Sameer Singh, and Matt Gardner. 2020. Beneﬁts of intermediate annotations in reading\n",
      "comprehension. ACL.\n",
      "Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021. Did\n",
      "aristotle use a laptop? A question answering benchmark with implicit reasoning strategies. TACL .\n",
      "Yuling Gu, Bhavana Dalvi Mishra, and Peter Clark. 2022. DREAM: Uncovering mental models\n",
      "behind language models. NAACL .\n",
      "Braden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, and Christopher\n",
      "Ré. 2018. Training classiﬁers with natural language explanations. ACL.\n",
      "Peter Hase and Mohit Bansal. 2022. When can models learn from explanations? a formal framework\n",
      "for understanding the roles of explanation data. ACL.\n",
      "Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song,\n",
      "and Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. arXiv\n",
      "preprint arXiv:2103.03874 .\n",
      "Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. Learning\n",
      "to solve arithmetic word problems with verb categorization. EMNLP .\n",
      "Zhanming Jie, Jierui Li, and Wei Lu. 2022. Learning to reason deductively: Math word problem\n",
      "solving as complex relation extraction. arXiv preprint arXiv:2203.10316 .\n",
      "Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child,\n",
      "Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language\n",
      "models. arXiv preprint arXiv:2001.08361 .\n",
      "Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016.\n",
      "MAWPS: A math word problem repository. NAACL .\n",
      "Andrew K. Lampinen, Ishita Dasgupta, Stephanie C.Y . Chan, Kory Matthewson, Michael Henry\n",
      "Tessler, Antonia Creswell, James L. McClelland, Jane X. Wang, and Felix Hill. 2022. Can language\n",
      "models learn from explanations in context? arXiv preprint arXiv:2204.02329 .\n",
      "Yihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,\n",
      "and Ee-Peng Lim. 2021. MWPToolkit: An open-source framework for deep learning-based math\n",
      "word problem solvers. arXiv preprint arXiv:2109.00799 .\n",
      "Teven Le Scao and Alexander Rush. 2021. How many data points is a prompt worth? NAACL .\n",
      "Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efﬁcient\n",
      "prompt tuning. EMNLP .\n",
      "Iddo Lev, Bill MacCartney, Christopher Manning, and Roger Levy. 2004. Solving logic puzzles:\n",
      "From robust processing to precise semantics. Proceedings of the 2nd Workshop on Text Meaning\n",
      "and Interpretation .\n",
      "Xiang Lisa Li and Percy Liang. 2021. Preﬁx-tuning: Optimizing continuous prompts for generation.\n",
      "ACL.\n",
      "11\n",
      "Zhengzhong Liang, Steven Bethard, and Mihai Surdeanu. 2021. Explainable multi-hop verbal\n",
      "reasoning through internal monologue. NAACL .\n",
      "Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program induction by rationale\n",
      "generation: Learning to solve and explain algebraic word problems. ACL.\n",
      "Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021.\n",
      "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language\n",
      "processing. arXiv preprint arXiv:2107.13586 .\n",
      "Bodhisattwa Prasad Majumder, Oana-Maria Camburu, Thomas Lukasiewicz, and Julian McAuley.\n",
      "2021. Rationale-inspired natural language explanations with commonsense. arXiv preprint\n",
      "arXiv:2106.13876 .\n",
      "Ana Marasovi ´c, Iz Beltagy, Doug Downey, and Matthew E Peters. 2022. Few-shot self-rationalization\n",
      "with natural language prompts. NAACL Findings .\n",
      "Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. On faithfulness and\n",
      "factuality in abstractive summarization. In ACL.\n",
      "Shen Yun Miao, Chao Chun Liang, and Keh Yih Su. 2020. A diverse corpus for evaluating and\n",
      "developing English math word problem solvers. ACL.\n",
      "Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke\n",
      "Zettlemoyer. 2022. Rethinking the role of demonstrations: What makes in-context learning work?\n",
      "arXiv preprint arXiv:2202.12837 .\n",
      "Sharan Narang, Colin Raffel, Katherine Lee, Adam Roberts, Noah Fiedel, and Karishma Malkan.\n",
      "2020. WT5?! Training text-to-text models to explain their predictions. arXiv preprint\n",
      "arXiv:2004.14546 .\n",
      "Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\n",
      "Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work:\n",
      "Scratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114 .\n",
      "Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong\n",
      "Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to\n",
      "follow instructions with human feedback. arXiv preprint arXiv:2203.02155 .\n",
      "Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021. Are NLP models really able to solve\n",
      "simple math word problems? NAACL .\n",
      "Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and\n",
      "Luke Zettlemoyer. 2018. Deep contextualized word representations. NAACL .\n",
      "Xinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and\n",
      "Weizhu Chen. 2022. Reasoning like program executors. arXiv preprint arXiv:2201.11473 .\n",
      "Piotr Pi˛ ekos, Mateusz Malinowski, and Henryk Michalewski. 2021. Measuring and improving\n",
      "BERT’s mathematical abilities by predicting the order of reasoning. ACL.\n",
      "Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John\n",
      "Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling language models:\n",
      "Methods, analysis & insights from training Gopher. arXiv preprint arXiv:2112.11446 .\n",
      "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi\n",
      "Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a uniﬁed\n",
      "text-to-text transformer. Journal of Machine Learning Research , 21:1–67.\n",
      "Dheeraj Rajagopal, Vidhisha Balachandran, Eduard H. Hovy, and Yulia Tsvetkov. 2021. SelfExplain:\n",
      "A self-explaining architecture for neural text classiﬁers. EMNLP .\n",
      "Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain\n",
      "yourself! Leveraging language models for commonsense reasoning. ACL.\n",
      "12\n",
      "Qiu Ran, Yankai Lin, Peng Li, Jie Zhou, and Zhiyuan Liu. 2019. NumNet: Machine reading\n",
      "comprehension with numerical reasoning. EMNLP .\n",
      "Hannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Michael Collins, Dipanjan Das, Slav Petrov,\n",
      "Gaurav Singh Tomar, Iulia Turc, and David Reitter. 2021. Measuring attribution in natural language\n",
      "generation models. arXiv preprint arXiv:2112.12870 .\n",
      "Gabriel Recchia. 2021. Teaching autoregressive language models complex tasks by demonstration.\n",
      "arXiv preprint arXiv:2109.02102 .\n",
      "Emily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, and Jason Wei. 2022.\n",
      "A recipe for arbitrary text style transfer with large language models. ACL.\n",
      "Laria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond\n",
      "the few-shot paradigm. Extended Abstracts of the 2021 CHI Conference on Human Factors in\n",
      "Computing Systems .\n",
      "Subhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. EMNLP .\n",
      "Subhro Roy, Tim Vieira, and Dan Roth. 2015. Reasoning about Quantities in Natural Language.\n",
      "TACL .\n",
      "Mohammed Saeed, Naser Ahmadi, Preslav Nakov, and Paolo Papotti. 2021. RuleBERT: Teaching\n",
      "soft rules to pre-trained language models. EMNLP .\n",
      "Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai,\n",
      "Antoine Chafﬁn, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2022. Multitask prompted\n",
      "training enables zero-shot task generalization. ICLR .\n",
      "Jianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, and Qun Liu. 2021.\n",
      "Generate & rank: A multi-task framework for math word problems. In Findings of the Association\n",
      "for Computational Linguistics: EMNLP 2021 .\n",
      "Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A\n",
      "question answering challenge targeting commonsense knowledge. NAACL .\n",
      "Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, and Jonathan Berant. 2020. Leap-of-\n",
      "thought: Teaching pre-trained models to systematically reason over implicit knowledge. NeurIPS .\n",
      "Alon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and\n",
      "Jonathan Berant. 2021. CommonsenseQA 2.0: Exposing the limits of ai through gamiﬁcation.\n",
      "NeurIPS Track on Datasets and Benchmarks .\n",
      "Yi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven\n",
      "Zheng, Neil Houlsby, and Donald Metzler. 2022. Unifying language learning paradigms. arXiv\n",
      "preprint arXiv:2205.05131 .\n",
      "Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze\n",
      "Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. LaMDA: Language models for\n",
      "dialog applications. arXiv preprint arXiv:2201.08239 .\n",
      "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022a.\n",
      "Self-consistency improves chain of thought reasoning in language models. arXiv preprint\n",
      "arXiv:2203.11171 .\n",
      "Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana\n",
      "Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022b.\n",
      "Benchmarking generalization via in-context instructions on 1,600+ language tasks. arXiv preprint\n",
      "arXiv:2204.07705 .\n",
      "Jason Wei, Maarten Bosma, Vincent Y . Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\n",
      "Andrew M. Dai, and Quoc V . Le. 2022a. Finetuned language models are zero-shot learners. ICLR .\n",
      "13\n",
      "Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,\n",
      "Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022b. Emergent abilities of large language\n",
      "models. Transactions on Machine Learning Research .\n",
      "Sarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark Riedl, and Yejin Choi. 2022. Reframing\n",
      "human-AI collaboration for generating free-text explanations. NAACL .\n",
      "Sarah Wiegreffe and Ana Marasovi ´c. 2021. Teach me to explain: A review of datasets for explainable\n",
      "NLP. NeurIPS .\n",
      "Sarah Wiegreffe, Ana Marasovi ´c, and Noah A. Smith. 2021. Measuring association between labels\n",
      "and free-text rationales. EMNLP .\n",
      "Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and\n",
      "Carrie J Cai. 2022a. PromptChainer: Chaining large language model prompts through visual\n",
      "programming. CHI Extended Abstracts .\n",
      "Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b. AI chains: Transparent and controllable\n",
      "human-AI interaction by chaining large language model prompts. CHI.\n",
      "Yujun Yan, Kevin Swersky, Danai Koutra, Parthasarathy Ranganathan, and Milad Hashemi. 2020.\n",
      "Neural execution engines: Learning to execute subroutines. NeurIPS .\n",
      "Huihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin, and Xiang Ren. 2021. Reﬁning language models\n",
      "with compositional explanations. NeurIPS .\n",
      "Xi Ye and Greg Durrett. 2022. The unreliability of explanations in few-shot in-context learning.\n",
      "arXiv preprint arXiv:2205.03401 .\n",
      "Yordan Yordanov, Vid Kocijan, Thomas Lukasiewicz, and Oana-Maria Camburu. 2021. Few-shot\n",
      "out-of-domain transfer learning of natural language explanations. arXiv preprint arXiv:2112.06204 .\n",
      "Omar Zaidan, Jason Eisner, and Christine Piatko. 2007. Using “annotator rationales” to improve\n",
      "machine learning for text categorization. NAACL .\n",
      "Wojciech Zaremba and Ilya Sutskever. 2014. Learning to execute. arXiv preprint arXiv:1410.4615 .\n",
      "Eric Zelikman, Yuhuai Wu, and Noah D. Goodman. 2022. STaR: Bootstrapping reasoning with\n",
      "reasoning. arXiv preprint arXiv:2203.14465 .\n",
      "Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use:\n",
      "Improving few-shot performance of language models. ICML .\n",
      "Wangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun, Chenyan Xiong, and\n",
      "Jian Tang. 2020. Towards interpretable natural language understanding with explanations as latent\n",
      "variables. NeurIPS .\n",
      "14\n",
      "Checklist\n",
      "1. For all authors...\n",
      "(a)Do the main claims made in the abstract and introduction accurately reﬂect the paper’s\n",
      "contributions and scope? [Yes]\n",
      "(b)Did you describe the limitations of your work? [Yes] See Section 6 and Appendix A.2.\n",
      "(c)Did you discuss any potential negative societal impacts of your work? [Yes] We don’t\n",
      "expect negative societal impacts as a direct result of the contributions in our paper. One\n",
      "consideration, however, is that generated chain of thought is not always factual, which\n",
      "is noted as a limitation in Appendix D.1 (and note that we do not suggest using such\n",
      "chains of thought in a factual manner or in any real-world scenario).\n",
      "(d)Have you read the ethics review guidelines and ensured that your paper conforms to\n",
      "them? [Yes]\n",
      "2. If you are including theoretical results...\n",
      "(a) Did you state the full set of assumptions of all theoretical results? [N/A]\n",
      "(b) Did you include complete proofs of all theoretical results? [N/A]\n",
      "3. If you ran experiments...\n",
      "(a)Did you include the code, data, and instructions needed to reproduce the main experi-\n",
      "mental results (either in the supplemental material or as a URL)? [Yes] We included\n",
      "inputs, outputs, and targets for LaMDA and GPT-3 in the supplementary material.\n",
      "Although we use proprietary models, we GPT-3 results are fully reproducible. Repro-\n",
      "ducibility is further discussed in Appendix E.1.\n",
      "(b)Did you specify all the training details (e.g., data splits, hyperparameters, how they\n",
      "were chosen)? [Yes] Data splits were speciﬁed, N/A for hyperparams.\n",
      "(c)Did you report error bars (e.g., with respect to the random seed after running exper-\n",
      "iments multiple times)? [Yes] Standard deviation for multiple seeds using LaMDA\n",
      "137B, where each seed is a different random order of exemplars, is given in Table 6\n",
      "and Table 7.\n",
      "(d)Did you include the total amount of compute and the type of resources used (e.g., type\n",
      "of GPUs, internal cluster, or cloud provider)? [Yes] Type of resources are described in\n",
      "Appendix E.2, though we did not estimate the total amount of compute.\n",
      "4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\n",
      "(a)If your work uses existing assets, did you cite the creators? [Yes] We used two models\n",
      "that we anonymized based on the recommendation of the NeurIPS chairs. These models\n",
      "will be cited in the camera-ready version of the paper.\n",
      "(b) Did you mention the license of the assets? [Yes] See Appendix E.3.\n",
      "(c)Did you include any new assets either in the supplemental material or as a URL? [Yes]\n",
      "The coinﬂip and last letter concatenation datasets are the only new assets, and they are\n",
      "given in the Supplementary Materials.\n",
      "(d)Did you discuss whether and how consent was obtained from people whose data you’re\n",
      "using/curating? [N/A] No human data collected.\n",
      "(e)Did you discuss whether the data you are using/curating contains personally identiﬁable\n",
      "information or offensive content? [N/A] No human data collected.\n",
      "5. If you used crowdsourcing or conducted research with human subjects...\n",
      "(a)Did you include the full text of instructions given to participants and screenshots, if\n",
      "applicable? [N/A]\n",
      "(b)Did you describe any potential participant risks, with links to Institutional Review\n",
      "Board (IRB) approvals, if applicable? [N/A]\n",
      "(c)Did you include the estimated hourly wage paid to participants and the total amount\n",
      "spent on participant compensation? [N/A]\n",
      "15\n",
      "A Frequently Asked Questions\n",
      "A.1 Why does increasing model scale improve chain-of-thought prompting?\n",
      "The ﬁnding that successful chain-of-thought reasoning predictably emerges only at certain model\n",
      "scales is intriguing. Scaling up language models has been shown to confer beneﬁts such as improved\n",
      "performance and sample efﬁciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\n",
      "in the sense that its success cannot be predicted only by extrapolating the performance of small scale\n",
      "models, as chain of thought actually hurts performance for most models smaller than 10B parameters.\n",
      "The question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\n",
      "we made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\n",
      "manually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\n",
      "(20 errors), one step missing (18 errors), and other errors (7 errors). The “other category” included\n",
      "hallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\n",
      "borrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\n",
      "conceived based on what improvements were needed to make the chain of thought correct.\n",
      "As shown in Figure 9, scaling PaLM to 540B parameters ﬁxed a substantial portion of errors in all\n",
      "three categories. Examples of semantic understanding and one-step missing errors that were ﬁxed by\n",
      "scaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\n",
      "language models acquire a range of semantic understanding and logical reasoning skills as a function\n",
      "of model scale (though note that model scale is often conﬂated with other factors, such as amount of\n",
      "training compute).\n",
      "Semantic understanding\n",
      "(62B made 20 errors of this type, 540B ﬁxes 6 of them)One step missing\n",
      "(62B made 18 errors of this type, 540B ﬁxes 12 of them)Other\n",
      "(62B made 7 errors of this type, 540B ﬁxes 4 of them)Types of errors made by a 62B language model:Errors ﬁxed by scaling from 62B to 540B\n",
      "Figure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\n",
      "that semantic understanding, one step missing, and other. The other category includes hallucinations,\n",
      "repetitive outputs, and symbol mapping errors. Scaling PaLM to 540B ﬁxed a substantial portion of\n",
      "errors in all categories.\n",
      "There are also three notable points regarding why small language models fail. The ﬁrst observation\n",
      "is that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\n",
      "in Section 5, for even symbolic reasoning tasks that only require generalization to new examples\n",
      "using the same chain of thought logical structure that was given in the few-shot exemplars, small\n",
      "language models still failed. The second observation is that small language models seem to have\n",
      "inherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\n",
      "arithmetic operations (without semantic understanding) requires sufﬁcient model scale. Finally, we\n",
      "noticed qualitatively that small language models often did not generate a ﬁnal answer that could be\n",
      "parsed, due to either repetitions or logic that never arrived at a ﬁnal answer.\n",
      "In summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\n",
      "phenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\n",
      "mapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\n",
      "investigate what properties of pretraining data, model architecture, and optimization objective causally\n",
      "enable such reasoning capabilities.\n",
      "16\n",
      "Tracy used a piece of wire 4 feet long to support tomato plants in the garden. The wire was cut into pieces 6 inches long. How many pieces did she obtain?She cut the wire into 6 inch pieces. This means she got 4 * 6 = 24 pieces. The answer is 24. (Incorrect: semantic understanding error)62B Model OutputQuestion540B Model OutputThe wire was 4 feet long. This means it was 4 * 12 = 48 inches long. It was cut into pieces 6 inches long. This means she obtained 48 / 6 = 8 pieces. The answer is 8. (Correct)Tom's ship can travel at 10 miles per hour. He is sailing from 1 to 4 PM. He then travels back at a rate of 6 mph. How long does it take him to get back?He travels from 1 to 4 PM. That means he travels for 3 hours. He travels back at 6 mph. That means he travels for 3 * 6 = 18 miles. The answer is 18. (Incorrect: semantic understanding error)He travels at 10 mph from 1 to 4 PM. This means he travels 3 hours. 3 hours at 10 mph means he travels 3 * 10 = 30 miles. He then travels back at 6 mph. This means he travels 6 miles per hour. He has to travel 30 miles, so it takes him 30 / 6 = 5 hours. The answer is 5. (Correct)Stephen placed an online order for groceries. His final bill came to $40.00. Because this was through a delivery vendor, they tacked on a 25% fee to his final total and charged him $3.00 in delivery fees. Stephen also added a $4.00 tip. After the extra fees, what was the final price of Stephen's groceries?The final price of Stephen's groceries was $40.00. The delivery vendor added 25% to the final total, so the final total was 125% of $40.00. This means the final total was 125% * $40.00 = $50.00. The delivery vendor also charged $3.00 in delivery fees. So the final price of Stephen's groceries was $50.00 + $3.00 = $53.00. The answer is $53.00. (Incorrect: one step missing error)Stephen's bill was $40.00. The delivery vendor added 25% to the bill. This means the bill was increased by 25% of $40.00. This is 0.25 * $40.00 = $10.00. The delivery fee was $3.00. The tip was $4.00. So the total bill was $40.00 + $10.00 + $3.00 + 540b model $4.00 = $57.00. The answer is 57. (Correct)There are four schools competing at a basketball tournament. Each school has sent a girls’ basketball team and a boys’ basketball team and each team has 5 players each. Each school has also sent a coach for each team. In total, how many people have all of the schools sent?There are 4 schools. Each school has sent a girls’ basketball team and a boys’ basketball team. Each team has 5 players each. That means there are 4 * 2 * 5 = 40 players. Each team has a coach. That means there are 40 + 4 = 44 coaches. The answer is 44. (Incorrect: one step missing error)Each school has sent 2 teams, each with 5 players. This means each school has sent 2 * 5 = 10 players. Each school has also sent 2 coaches. This means each school has sent 10 + 2 = 12 people. There are 4 schools, so in total all of the schools have sent 4 * 12 = 48 people. The answer is 48. (Correct)62B Model Output\n",
      "62B Model Output\n",
      "62B Model Output540B Model Output\n",
      "540B Model Output\n",
      "540B Model OutputQuestion\n",
      "Question\n",
      "QuestionFigure 10: Examples of semantic understanding and one-step missing errors that were ﬁxed by\n",
      "scaling PaLM from 62B to 540B.\n",
      "A.2 What is the role of prompt engineering?\n",
      "One of the key considerations of prompting is sensitivity to the exact prompt. There is no shortage\n",
      "of work showing that prompts affect language models in unexpected ways (Min et al., 2022). The\n",
      "general way that we created chain of thought annotations was by taking eight exemplars from the\n",
      "training set and decomposing the reasoning process into multiple steps leading to the ﬁnal answer.\n",
      "Examples of chain of thought annotations are provided in Figure 3, with full prompts given in\n",
      "Appendix G. To analyze how sensitive chain of thought is to prompt engineering, we performed\n",
      "robustness experiments with respect to various factors.\n",
      "•Different annotators. We ﬁrst analyze robustness to three different annotators (Section 3.4 and\n",
      "Figure 6). Although there is notable variance in performance (which we will discuss later), chain\n",
      "of thought performed better than the baseline by a large margin for all three annotators on eight\n",
      "datasets in arithmetic, commonsense, and symbolic reasoning (Table 6 and Table 7). Similar to the\n",
      "annotation process in Cobbe et al. (2021), annotators were not given speciﬁc instructions about\n",
      "17\n",
      "how to write the chain of thought annotations other than to simply write the step-by-step reasoning\n",
      "process that led to the ﬁnal answer. Thus, the annotations were written in each annotator’s own\n",
      "linguistic “chain of thought” writing style.\n",
      "•Annotators without machine learning background. The GSM8K dataset (Cobbe et al., 2021)\n",
      "conveniently provides a training set with reasoning chains written by crowd compute workers,\n",
      "which enables us to investigate whether chain of thought still works with reasoning chains from an\n",
      "independent source without a background in machine learning. So we randomly sampled three sets\n",
      "of eight exemplars with chains of thought from GSM8K. These chain of thought annotations also\n",
      "outperformed the baseline by a large margin for all four arithmetic datasets (Table 6), indicating\n",
      "that chain of thought is not dependent on a particular set of annotators.\n",
      "•Different exemplars. The different GSM8K exemplars experiment above (Table 6) also shows\n",
      "that chain-of-thought prompting works for different sets of exemplars. Notably, we test every set of\n",
      "exemplars on all four arithmetic datasets (instead of picking exemplars from the training set for\n",
      "each dataset), which suggests that the exemplars do not necessarily have to come from the same\n",
      "dataset distribution as the test examples.\n",
      "•Different order of exemplars. Prior work has shown that in some cases (e.g., classiﬁcation) even\n",
      "the order of prompts matter—varying the permutation of few-shot exemplars can cause the accuracy\n",
      "of GPT-3 on SST-2 to range from near chance (54.3%) to near SOTA (93.4%) (Zhao et al., 2021).\n",
      "We show the standard deviation of performance from different exemplars in Table 6 and Table 7.\n",
      "Standard deviations with respect to prompt order are relatively minimal in almost all cases. The\n",
      "one exception is the coin ﬂip task, for which exemplar orders have high standard deviation, likely\n",
      "for the reason cited in Zhao et al. (2021)—for classiﬁcation, many exemplars of the same category\n",
      "in a row biases the model outputs).\n",
      "•Different number of exemplars. We also found that gains from chain-of-thought prompting\n",
      "generally still held when there was a varying number of few-shot exemplars. This is shown for ﬁve\n",
      "datasets in Figure 11 (we did not have the compute to run this for all datasets). We also found in\n",
      "preliminary experiments that further increasing the number of exemplars in standard prompting\n",
      "did not lead to signiﬁcant gains (e.g., increasing from 8 to 16 exemplars did not improve the\n",
      "performance of standard prompting enough to catch up with chain-of-thought prompting).\n",
      "•Different language models. Another interesting question is whether certain prompts that work\n",
      "better for one model work better for other large language models. We ﬁnd that with the same\n",
      "prompts, chain-of-thought prompting improves performance across all three models (LaMDA,\n",
      "GPT-3, and PaLM) for all datasets except CSQA and StrategyQA for GPT-3 (Table 1, Table 4,\n",
      "Table 5). The fact that gains from chain of thought did not transfer perfectly among models is\n",
      "a limitation; further work could investigate why how different pre-training datasets and model\n",
      "architectures affect the performance gain from chain-of-thought prompting.\n",
      "Prompt engineering still matters, though. Although the results are relatively robust to the prompt\n",
      "for arithmetic reasoning, we want to be clear that prompt engineering still does matter, and can\n",
      "improve performance signiﬁcantly in many cases. Though most chain of thought annotations\n",
      "outperform standard prompting, there is large variation in many cases. For instance, for the coin\n",
      "ﬂip task, the performance varied from 99.6% for Annotator A to 71.4% for Annotator C, though\n",
      "both were above standard prompting = 50.0% (see Table 7). There are even tasks where prompt\n",
      "engineering is a requirement for good performance. In preliminary experiments, we tried using chain\n",
      "of thought to enable language models to reverse the order of a list of 5 items. While two co-authors\n",
      "were not able to write chain of thought prompts that solved the task despite their best attempts, a third\n",
      "co-author was able to write a chain of thought that perfectly solved the task.\n",
      "How to generate chain of thought annotations in a robust fashion could be an interesting direction\n",
      "for future work. For instance, an idea here could be to use a large language model to automatically\n",
      "generate chains of thought via prompting (and potentially optimize this over a validation set).\n",
      "A.3 Will chain-of-thought prompting improve performance for my task of interest?\n",
      "While chain-of-thought prompting is in principle applicable for any text-to-text task, it is more\n",
      "helpful for some tasks than others. Based on the experiments in this paper, our intuition is that chain\n",
      "of thought helps the most when three conditions are met: (1) the task is challenging and requires\n",
      "18\n",
      "multi-step reasoning, (2) a large language model is used, and (3) the scaling curve is relatively ﬂat.\n",
      "Conversely, the beneﬁts are smaller when one or more of these conditions are not met.\n",
      "These intuitions are perhaps supported by the arithmetic reasoning results. The performance gain\n",
      "from chain-of-thought prompting is largest for PaLM 540B on GSM8K (challenging multi-step\n",
      "problems, ﬂat scaling curve), which meets these conditions. The performance gain is small for the\n",
      "subsets of MAWPS that only require one or two steps (SingleOP, SingleEq, and AddSub), for which\n",
      "PaLM 540B already achieves performance of 90% or higher (and it is also generally true that there is\n",
      "less headroom for improvement when performance is already strong).\n",
      "Although in this paper we focused on multi-step reasoning tasks (arithmetic, commonsense, and\n",
      "symbolic), chain-of-thought prompting can potentially be applied to any task for which humans use a\n",
      "“chain of thought” to solve (at least in principle). We leave the empirical evaluation of chain-of-thought\n",
      "prompting on such diverse tasks (e.g., machine translation, etc.) to future work.\n",
      "A.4 Why is prompting with the equation only not enough for some arithmetic reasoning\n",
      "datasets?\n",
      "Prompting with the equation only as an intermediate step does help on many datasets, especially when\n",
      "the datasets only require a few reasoning steps (SV AMP, ASDiv, MAWPS). For GSM8K, however,\n",
      "using the equation only did not improve performance substantially. Based on qualitative analysis, we\n",
      "believe that these questions are too semantically challenging for the model to directly translate them\n",
      "into a math equation. Consider this example from LaMDA 137B:\n",
      "QUESTION :Mike plays ping pong for 40 minutes. In the ﬁrst 20 minutes, he scores 4\n",
      "points. In the second 20 minutes, he scores 25% more points. How many total points did he\n",
      "score?\n",
      "EQUATION ONLY (WRONG ANSWER ):(4 + 20 * 0.25) = 6. The answer is 6.\n",
      "CHAIN OF THOUGHT (CORRECT ):Mike played ping pong for 40 minutes. In the ﬁrst\n",
      "20 minutes, he scored 4 points. In the second 20 minutes, he scored 25% more points. So\n",
      "he scored 25% more in the second 20 minutes. 4 x 1.25 = 5. So he scored 5 points in the\n",
      "second 20 minutes. So he scored 9 points in total. The answer is 9.\n",
      "It is hard for the model to directly translate all of the semantics into a single equation, but chain of\n",
      "thought allows it to better reason about each part of the question via intermediate steps in natural\n",
      "language.\n",
      "19\n",
      "B All Experimental Results\n",
      "This section contains tables for experimental results for varying models and model sizes, on all\n",
      "benchmarks, for standard prompting vs. chain-of-thought prompting.\n",
      "For the arithmetic reasoning benchmarks, some chains of thought (along with the equations produced)\n",
      "were correct, except the model performed an arithmetic operation incorrectly. A similar observation\n",
      "was made in Cobbe et al. (2021). Hence, we can further add a Python program as an external\n",
      "calculator (using the Python eval function) to all the equations in the generated chain of thought.\n",
      "When there are multiple equations in a chain of thought, we propagate the external calculator results\n",
      "from one equation to the following equations via string matching. As shown in Table 1, we see that\n",
      "adding a calculator signiﬁcantly boosts performance of chain-of-thought prompting on most tasks.\n",
      "Table 1: Chain of thought prompting outperforms standard prompting for various large language\n",
      "models on ﬁve arithmetic reasoning benchmarks. All metrics are accuracy (%). Ext. calc.: post-hoc\n",
      "external calculator for arithmetic computations only. Prior best numbers are from the following. a:\n",
      "Cobbe et al. (2021). b&e: Pi et al. (2022), c: Lan et al. (2021), d: Pi˛ ekos et al. (2021).\n",
      "Prompting GSM8K SV AMP ASDiv AQuA MAWPS\n",
      "Prior best N/A (ﬁnetuning) 55a57.4b75.3c37.9d88.4e\n",
      "UL2 20B Standard 4.1 10.1 16.0 20.5 16.6\n",
      "Chain of thought 4.4 (+0.3) 12.5 (+2.4) 16.9 (+0.9) 23.6 (+3.1) 19.1 (+2.5)\n",
      "+ ext. calc 6.9 28.3 34.3 23.6 42.7\n",
      "LaMDA 137B Standard 6.5 29.5 40.1 25.5 43.2\n",
      "Chain of thought 14.3 (+7.8) 37.5 (+8.0) 46.6 (+6.5) 20.6 (-4.9) 57.9 (+14.7)\n",
      "+ ext. calc 17.8 42.1 53.4 20.6 69.3\n",
      "GPT-3 175B Standard 15.6 65.7 70.3 24.8 72.7\n",
      "(text-davinci-002) Chain of thought 46.9 (+31.3) 68.9 (+3.2) 71.3 (+1.0) 35.8 (+11.0) 87.1 (+14.4)\n",
      "+ ext. calc 49.6 70.3 71.1 35.8 87.5\n",
      "Codex Standard 19.7 69.9 74.0 29.5 78.7\n",
      "(code-davinci-002) Chain of thought 63.1 (+43.4) 76.4 (+6.5) 80.4 (+6.4) 45.3 (+15.8) 92.6 (+13.9)\n",
      "+ ext. calc 65.4 77.0 80.0 45.3 93.3\n",
      "PaLM 540B Standard 17.9 69.4 72.1 25.2 79.2\n",
      "Chain of thought 56.9 (+39.0) 79.0 (+9.6) 73.9 (+1.8) 35.8 (+10.6) 93.3 (+14.2)\n",
      "+ ext. calc 58.6 79.8 72.6 35.8 93.5\n",
      "20\n",
      "Table 2: Standard prompting versus chain of thought prompting on ﬁve arithmetic reasoning bench-\n",
      "marks. Note that chain of thought prompting is an emergent ability of model scale—it does not\n",
      "positively impact performance until used with a model of sufﬁcient scale.\n",
      "GSM8K SV AMP ASDiv AQuA MAWPS\n",
      "Model standard CoT standard CoT standard CoT standard CoT standard CoT\n",
      "UL2 20B 4.1 4.4 10.1 12.5 16.0 16.9 20.5 23.6 16.6 19.1\n",
      "LaMDA 420M 2.6 0.4 2.5 1.6 3.2 0.8 23.5 8.3 3.2 0.9\n",
      "2B 3.6 1.9 3.3 2.4 4.1 3.8 22.9 17.7 3.9 3.1\n",
      "8B 3.2 1.6 4.3 3.4 5.9 5.0 22.8 18.6 5.3 4.8\n",
      "68B 5.7 8.2 13.6 18.8 21.8 23.1 22.3 20.2 21.6 30.6\n",
      "137B 6.5 14.3 29.5 37.5 40.1 46.6 25.5 20.6 43.2 57.9\n",
      "GPT 350M 2.2 0.5 1.4 0.8 2.1 0.8 18.1 8.7 2.4 1.1\n",
      "1.3B 2.4 0.5 1.5 1.7 2.6 1.4 12.6 4.3 3.1 1.7\n",
      "6.7B 4.0 2.4 6.1 3.1 8.6 3.6 15.4 13.4 8.8 3.5\n",
      "175B 15.6 46.9 65.7 68.9 70.3 71.3 24.8 35.8 72.7 87.1\n",
      "Codex - 19.7 63.1 69.9 76.4 74.0 80.4 29.5 45.3 78.7 92.6\n",
      "PaLM 8B 4.9 4.1 15.1 16.8 23.7 25.2 19.3 21.7 26.2 30.5\n",
      "62B 9.6 29.9 48.2 46.7 58.7 61.9 25.6 22.4 61.8 80.3\n",
      "540B 17.9 56.9 69.4 79.0 72.1 73.9 25.2 35.8 79.2 93.3\n",
      "Table 3: Standard prompting versus chain of thought prompting on the four subsets of the MAWPS\n",
      "benchmark. The point of stratifying the MAWPS benchmark is to show that performance gains are\n",
      "minimal on easy one-step or two-step problems where large language models already achieve high\n",
      "performance (e.g., SingleOp, SingleEq, and AddSub).\n",
      "SingleOp SingleEq AddSub MultiArith\n",
      "Model standard CoT standard CoT standard CoT standard CoT\n",
      "UL2 20B 24.9 27.2 18.0 20.2 18.5 18.2 5.0 10.7\n",
      "LaMDA 420M 2.8 1.0 2.4 0.4 1.9 0.7 5.8 1.5\n",
      "2B 4.6 4.1 2.4 3.3 2.7 3.2 5.8 1.8\n",
      "8B 8.0 7.0 4.5 4.4 3.4 5.2 5.2 2.4\n",
      "68B 36.5 40.8 23.9 26.0 17.3 23.2 8.732.4\n",
      "137B 73.2 76.2 48.8 58.7 43.0 51.9 7.644.9\n",
      "GPT 350M 3.2 1.8 2.0 0.2 2.0 1.5 2.3 0.8\n",
      "1.3B 5.3 3.0 2.4 1.6 2.3 1.5 2.2 0.5\n",
      "6.7B 13.5 3.9 8.7 4.9 8.6 2.5 4.5 2.8\n",
      "175B 90.9 88.8 82.7 86.6 83.3 81.3 33.8 91.7\n",
      "Codex - 93.1 91.8 86.8 93.1 90.9 89.1 44.0 96.2\n",
      "PaLM 8B 41.8 46.6 29.5 28.2 29.4 31.4 4.215.8\n",
      "62B 87.9 85.6 77.2 83.5 74.7 78.2 7.373.7\n",
      "540B 94.1 94.1 86.5 92.3 93.9 91.9 42.2 94.7\n",
      "21\n",
      "Table 4: Standard prompting versus chain of thought prompting on ﬁve commonsense reasoning\n",
      "benchmarks. Chain of thought prompting is an emergent ability of model scale—it does not positively\n",
      "impact performance until used with a model of sufﬁcient scale.\n",
      "CSQA StrategyQA Date Sports SayCan\n",
      "Model standard CoT standard CoT standard CoT standard CoT standard CoT\n",
      "UL2 20B 34.2 51.4 59.0 53.3 13.5 14.0 57.9 65.3 20.0 41.7\n",
      "LaMDA 420M 20.1 19.2 46.4 24.9 1.9 1.6 50.0 49.7 7.5 7.5\n",
      "2B 20.2 19.6 52.6 45.2 8.0 6.8 49.3 57.5 8.3 8.3\n",
      "8B 19.0 20.3 54.1 46.8 9.5 5.4 50.0 52.1 28.3 33.3\n",
      "68B 37.0 44.1 59.6 62.2 15.5 18.6 55.2 77.5 35.0 42.5\n",
      "137B 53.6 57.9 62.4 65.4 21.5 26.8 59.5 85.8 43.3 46.6\n",
      "GPT 350M 14.7 15.2 20.6 0.9 4.3 0.9 33.8 41.6 12.5 0.8\n",
      "1.3B 12.0 19.2 45.8 35.7 4.0 1.4 0.0 26.9 20.8 9.2\n",
      "6.7B 19.0 24.0 53.6 50.0 8.9 4.9 0.0 4.4 17.5 35.0\n",
      "175B 79.5 73.5 65.9 65.4 43.8 52.1 69.6 82.4 81.7 87.5\n",
      "Codex - 82.3 77.9 67.1 73.2 49.0 64.8 71.7 98.5 85.8 88.3\n",
      "PaLM 8B 19.8 24.9 55.6 53.5 12.9 13.1 55.1 75.2 34.2 40.0\n",
      "62B 65.4 68.1 58.4 63.4 29.8 44.7 72.1 93.6 65.8 70.0\n",
      "540B 78.1 79.9 68.6 77.8 49.0 65.3 80.5 95.4 80.8 91.7\n",
      "Table 5: Standard prompting versus chain of thought prompting enables length generalization to\n",
      "longer inference examples on two symbolic manipulation tasks.\n",
      "Last Letter Concatenation Coin Flip (state tracking)\n",
      "2 OOD: 3 OOD: 4 2 OOD: 3 OOD: 4\n",
      "Model standard CoT standard CoT standard CoT standard CoT standard CoT standard CoT\n",
      "UL2 20B 0.6 18.8 0.0 0.2 0.0 0.0 70.4 67.1 51.6 52.2 48.7 50.4\n",
      "LaMDA 420M 0.3 1.6 0.0 0.0 0.0 0.0 52.9 49.6 50.0 50.5 49.5 49.1\n",
      "2B 2.3 6.0 0.0 0.0 0.0 0.0 54.9 55.3 47.4 48.7 49.8 50.2\n",
      "8B 1.5 11.5 0.0 0.0 0.0 0.0 52.9 55.5 48.2 49.6 51.2 50.6\n",
      "68B 4.4 52.0 0.0 0.8 0.0 2.5 56.2 83.2 50.4 69.1 50.9 59.6\n",
      "137B 5.8 77.5 0.034.4 0.013.5 49.0 99.6 50.7 91.0 49.1 74.5\n",
      "PaLM 8B 2.6 18.8 0.0 0.0 0.0 0.2 60.0 74.4 47.3 57.1 50.9 51.8\n",
      "62B 6.8 85.0 0.059.6 0.013.4 91.4 96.8 43.9 91.0 38.3 72.4\n",
      "540B 7.6 99.4 0.294.8 0.063.0 98.1 100.0 49.3 98.6 54.8 90.2\n",
      "22\n",
      "Table 6: Ablation and robustness results for arithmetic reasoning datasets. Chain of thought generally\n",
      "outperforms ablations by a large amount. “Equation only” performs in between standard prompting\n",
      "and chain of thought prompting, as it allows for intermediate reasoning steps via equations but does\n",
      "not leverage natural language. Chain of thought prompting has variance (as expected) when used\n",
      "with prompts written by different annotators or when using other exemplars, but still outperforms\n",
      "standard prompting by a large margin. Standard deviation shown is for different order of few-shot\n",
      "prompting exemplars, with ﬁve different random seeds. Results here are shown for LaMDA 137B, as\n",
      "additional queries for GPT-3 and PaLM are both limited and expensive.\n",
      "GSM8K SV AMP ASDiv MAWPS\n",
      "Standard prompting 6.5 ±0.4 29.5±0.6 40.1±0.6 43.2±0.9\n",
      "Chain of thought prompting 14.3 ±0.4 36.7±0.4 46.6±0.7 57.9±1.5\n",
      "Ablations\n",
      "·equation only 5.4 ±0.2 35.1±0.4 45.9±0.6 50.1±1.0\n",
      "·variable compute only 6.4 ±0.3 28.0±0.6 39.4±0.4 41.3±1.1\n",
      "·reasoning after answer 6.1 ±0.4 30.7±0.9 38.6±0.6 43.6±1.0\n",
      "Robustness\n",
      "·different annotator (B) 15.5 ±0.6 35.2±0.4 46.5±0.4 58.2±1.0\n",
      "·different annotator (C) 17.6 ±1.0 37.5±2.0 48.7±0.7 60.1±2.0\n",
      "·intentionally concise style 11.1 ±0.3 38.7±0.8 48.0±0.3 59.6±0.7\n",
      "·exemplars from GSM8K ( α) 12.6 ±0.6 32.8±1.1 44.1±0.9 53.9±1.1\n",
      "·exemplars from GSM8K ( β) 12.7 ±0.5 34.8±1.1 46.9±0.6 60.9±0.8\n",
      "·exemplars from GSM8K ( γ) 12.6 ±0.7 35.6±0.5 44.4±2.6 54.2±4.7\n",
      "Table 7: Ablation and robustness results for four datasets in commonsense and symbolic reasoning.\n",
      "Chain of thought generally outperforms ablations by a large amount. Chain of thought prompting has\n",
      "variance (as expected) when used with prompts written by different annotators or when using other\n",
      "exemplars, but still outperforms standard prompting by a large margin. Standard deviation shown\n",
      "is for different order of few-shot prompting exemplars, with ﬁve different random seeds. Results\n",
      "here are shown for LaMDA 137B, as additional queries for GPT-3 and PaLM are both limited and\n",
      "expensive. The exception is that we run SayCan using PaLM here, as the SayCan evaluation set is\n",
      "only 120 examples and therefore less expensive to run multiple times.\n",
      "Commonsense Symbolic\n",
      "Date Sports SayCan Concat Coin\n",
      "Standard prompting 21.5 ±0.6 59.5±3.0 80.8±1.8 5.8±0.6 49.0±2.1\n",
      "Chain of thought prompting 26.8 ±2.1 85.8±1.8 91.7±1.4 77.5±3.8 99.6±0.3\n",
      "Ablations\n",
      "·variable compute only 21.3 ±0.7 61.6±2.2 74.2±2.3 7.2±1.6 50.7±0.7\n",
      "·reasoning after answer 20.9 ±1.0 63.0±2.0 83.3±0.6 0.0±0.0 50.2±0.5\n",
      "Robustness\n",
      "·different annotator (B) 27.4 ±1.7 75.4±2.7 88.3±1.4 76.0±1.9 77.5±7.9\n",
      "·different annotator (C) 25.5 ±2.5 81.1±3.6 85.0±1.8 68.1±2.2 71.4±11.1\n",
      "23\n",
      "C Extended Related Work\n",
      "Chain-of-thought prompting is a general approach that is inspired by several prior directions: prompt-\n",
      "ing, natural language explanations, program synthesis/execution, numeric and logical reasoning, and\n",
      "intermediate language steps.\n",
      "C.1 Prompting\n",
      "The recent success of large-scale language models has led to growing interest in improving their\n",
      "capability to perform tasks via prompting (Brown et al. (2020), and see Liu et al. (2021) for a\n",
      "survey). This paper falls in the category of general prompting approaches, whereby input prompts are\n",
      "optimized to allow a single large language model to better perform a variety of tasks (Li and Liang,\n",
      "2021; Lester et al., 2021; Reif et al., 2022, inter alia ).\n",
      "One recent line of work aims to improve the ability of language models to perform a task by providing\n",
      "instructions that describe the task (Raffel et al., 2020; Wei et al., 2022a; Ouyang et al., 2022; Sanh\n",
      "et al., 2022; Wang et al., 2022b). This line of work is related because it also augments input–output\n",
      "pairs with meta-data. But whereas an instruction augments the input to a task (instructions are typically\n",
      "prepended to the inputs), chain-of-thought prompting augments the outputs of language models.\n",
      "Another related direction is sequentially combining the outputs of language models; human–computer\n",
      "interaction (HCI) work (Wu et al., 2022a,b) has shown that combining sequential generations of\n",
      "language models improves task outcomes in a 20-person user study.\n",
      "C.2 Natural language explanations\n",
      "Another closely related direction uses natural language explanations (NLEs), often with the goal of\n",
      "improving model interpretability (Zhou et al., 2020; Wiegreffe and Marasovi ´c, 2021, inter alia ). That\n",
      "line of work typically focuses on natural language inference (Camburu et al., 2018; Yordanov et al.,\n",
      "2021; Bostrom et al., 2021), and produces explanations either simultaneously to or after the ﬁnal\n",
      "prediction (Narang et al., 2020; Majumder et al., 2021; Wiegreffe et al., 2021, 2022). By contrast,\n",
      "the chain of thought processing considered in this paper occurs before the ﬁnal answer. And while\n",
      "NLE aims mostly to improve neural network interpretability (Rajagopal et al., 2021), the goal of\n",
      "chain-of-thought prompting is to allow models to decompose multi-hop reasoning tasks into multiple\n",
      "steps—interpretability is just a side effect. Marasovi ´c et al. (2022) show that prompt-based ﬁnetuning\n",
      "with NLE improves NLI and classiﬁcation performance, though they largely focus on evaluating\n",
      "explanation plausibility. In comparison, our work focuses on a range of arithmetic, commonsense,\n",
      "and symbolic tasks that require multi-hop reasoning.\n",
      "C.3 Program synthesis and execution\n",
      "Using intermediate reasoning steps has a long history in program synthesis and execution (Zaremba\n",
      "and Sutskever, 2014, inter alia ). Recent work along in this direction has included a number of\n",
      "architectural innovations (Cai et al., 2017; Dong et al., 2019; Yan et al., 2020), as well as the use of\n",
      "large language models (Chen et al., 2021; Austin et al., 2021). The program execution work closest to\n",
      "ours is perhaps Nye et al. (2021), which show that large language models can perform up to 10-digit\n",
      "addition, evaluate polynomials, and execute python programs. Whereas generating a program and\n",
      "then executing it can be viewed as a type of reasoning, our work generalizes such domain-speciﬁc\n",
      "primitives to natural language, which is open-domain and relevant to any text-to-text NLP task in\n",
      "principle.\n",
      "C.4 Numeric and logical reasoning\n",
      "Numeric and logical reasoning has been a long-studied task in machine learning and natural language\n",
      "processing (Lev et al., 2004, inter alia ). Recent work has also aimed to inject numeric reasoning\n",
      "abilities in language models in various ways, such as augmenting BERT with a predeﬁned set of\n",
      "executable operations (Andor et al., 2019), including a graph neural network (Ran et al., 2019), and\n",
      "using specialized training procedures (Pi˛ ekos et al., 2021). Another line of work aims to enable\n",
      "language models to perform logical or formal reasoning, often by verablizing the rules in natural\n",
      "language formal rules using language (Clark et al., 2020; Saeed et al., 2021; Liang et al., 2021).\n",
      "24\n",
      "Perhaps the most-related work here is Recchia (2021), which shows that ﬁnetuning enables longhand\n",
      "module operations, which has previously been difﬁcult for performers. Whereas work in this direction\n",
      "is often task-speciﬁc and uses ﬁnetuning, we show that chain-of-thought prompting works for a broad\n",
      "range of tasks without any ﬁnetuning.\n",
      "C.5 Intermediate language steps\n",
      "Extensive prior work has shown the beneﬁts of endowing neural networks with the ability to produce\n",
      "intermediate steps via training or ﬁnetuning confers various beneﬁts in a range of scenarios. As\n",
      "examples, it has been shown that natural language intermediate steps can improve performance\n",
      "(Zaidan et al., 2007; Yao et al., 2021; Hase and Bansal, 2022; Gu et al., 2022), improve robustness\n",
      "(Chen et al., 2022), speed up training (Hancock et al., 2018), mitigate bias (Dua et al., 2020), and\n",
      "even help in image and reinforcement learning settings (Andreas et al., 2018). To endow models with\n",
      "the ability to produce intermediate steps, prior work typically ﬁnetunes models on either manually\n",
      "annotated training datasets (Camburu et al., 2018; Rajani et al., 2019, inter alia ) or generates synthetic\n",
      "datasets (Talmor et al., 2020; Zelikman et al., 2022). Compared with these training or ﬁnetuning\n",
      "methods, our work shows that various natural language reasoning abilities can be elicited in off-the-\n",
      "shelf language models of sufﬁcient scale simply via prompting. This prompting setup is important\n",
      "because it allows for intermediate step reasoning without a large number of labeled annotations, and\n",
      "because a single model can perform a range of reasoning tasks without any gradient updates.\n",
      "D Appendix: Additional Analysis\n",
      "D.1 Correct Chain of Thought Analysis\n",
      "As mentioned in the main text, we analyze 50 chains of thought from LaMDA 137B that led to\n",
      "correct answers in the GSM8K dataset. Of these 50, only one arrived at the correct answer through\n",
      "incorrect reasoning (shown in Table 9: “correct by chance”). The other 49 had correct logic and\n",
      "math, with examples shown in Table 8. Five had minor imperfections while maintaining coherent and\n",
      "understandable logic:\n",
      "• One had underspeciﬁed statements (shown in Table 9: “correct but underspeciﬁed statements”).\n",
      "•One made an unrelated but correct statement (shown in Table 9: “correct but unrelated statement”).\n",
      "•Two had the correct logic but omitted speciﬁc steps in the equation, though it was still understand-\n",
      "able (shown in Table 9: “correct but imperfect equation”).\n",
      "•One had the correct math but inverted the semantics (shown in Table 9: “correct but inverted\n",
      "semantics”)\n",
      "Table 8: Example of correct chains of thought produced by the model for the GSM8K dataset.\n",
      "QUESTION :James decides to run 3 sprints 3 times a week. He runs 60 meters each sprint. How many total\n",
      "meters does he run a week?\n",
      "MODEL ANSWER (CORRECT): James decides to run 3 sprints 3 times a week. He runs 60 meters each\n",
      "sprint. So he runs 60 meters x 3 sprints x 3 times a week. That is 60 meters x 9. The answer is 540. ✓\n",
      "QUESTION :Brandon’s iPhone is four times as old as Ben’s iPhone. Ben’s iPhone is two times older than Suzy’s\n",
      "iPhone. If Suzy’s iPhone is 1 year old, how old is Brandon’s iPhone?\n",
      "MODEL ANSWER (CORRECT): Brandon’s iPhone is 4 times as old as Ben’s iPhone. Ben’s iPhone is 2\n",
      "times older than Suzy’s iPhone. So Brandon’s iPhone is 4 x 2 = 8 times older than Suzy’s iPhone. Suzy’s iPhone\n",
      "is 1 year old. So Brandon’s iPhone is 8 x 1 = 8 years old. The answer is 8. ✓\n",
      "QUESTION :Jean has 30 lollipops. Jean eats 2 of the lollipops. With the remaining lollipops, Jean wants to\n",
      "package 2 lollipops in one bag. How many bags can Jean ﬁll?\n",
      "MODEL ANSWER (CORRECT): Jean started with 30 lollipops. She ate 2 of them. So she has 28 lollipops\n",
      "left. She wants to package 2 lollipops in one bag. So she can package 28 / 2 = 14 bags. The answer is 14. ✓\n",
      "Although we ﬁnd that chain-of-thought reasoning is mostly correct for math questions where the ﬁnal\n",
      "answer was correct, this is likely because it is hard to arrive at the correct ﬁnal answer by coincidence\n",
      "for free response questions. For multiple choice or binary classiﬁcation problems, it was much more\n",
      "25\n",
      "likely that models could arrive at the correct answer via an incorrect reasoning path (e.g., all the\n",
      "commmonsense reasoning datasets we evaluate). This is a limitation, and future work should perform\n",
      "an analysis of the factuality of such chains of thought.\n",
      "Table 9: Of 50 examples that the model got correct, there were 7 salient cases where the chain of\n",
      "thought the model generated was imperfect. We found the other 43 to be equivalent to what a human\n",
      "would potentially generate as a ground truth.\n",
      "QUESTION :There are 36 penguins sunbathing in the snow. One-third of them jump in and swim in the ocean.\n",
      "Another one-third go inside the cave to eat their dinner. How many penguins are still left sunbathing?\n",
      "MODEL ANSWER (CORRECT BY CHANCE ):There are 36 penguins. One-third of them jump in and swim in\n",
      "the ocean. So that is 12 penguins. Another one-third go inside the cave to eat their dinner. So that is 12 penguins.\n",
      "The answer is 12.\n",
      "QUESTION :John has 2 houses with 3 bedrooms each. Each bedroom has 2 windows each. There are an\n",
      "additional 4 windows in each house not connected to bedrooms. How many total windows are there between the\n",
      "houses?\n",
      "MODEL ANSWER (CORRECT BUT UNDERSPECIFIED STATEMENTS ):There are 2 houses with 3 bedrooms\n",
      "each. Each bedroom has 2 windows each. So there are 2 x 3 = 6 windows in each house. There are an additional\n",
      "4 windows in each house not connected to bedrooms. So there are 4 + 4 = 8 windows in each house. So there are\n",
      "6 x 2 = 12 windows in each house. So there are 12 + 8 = 20 windows in both houses. The answer is 20.\n",
      "QUESTION :If Ann is 9 years old and her brother is twice her age, how old will her brother be in 3 years?\n",
      "MODEL ANSWER (CORRECT BUT UNRELATED STATEMENT ):Ann is 9 years old. Her brother is twice her\n",
      "age. So her brother is 18 years old. In 3 years, she will be 12. So her brother will be 18 + 3 = 21 years old. The\n",
      "answer is 21.\n",
      "QUESTION :A local gas station is selling gas for $3.00 a gallon. An app company is offering $.20 cashback per\n",
      "gallon if you ﬁll up at this station. If someone buys 10 gallons of gas, how much with their gas be, after the\n",
      "cashback rewards?\n",
      "MODEL ANSWER (CORRECT BUT IMPERFECT EQUATION ):The gas is originally 3 dollars per gallon. If\n",
      "you buy 10 gallons, that is 3 x 10 = 30 dollars. If you get 20 cents off per gallon, that is 20 x 10 = 2 dollars. So\n",
      "the total is 30 - 2 = 28 dollars. The answer is 28 dollars.\n",
      "QUESTION :Nissa hires 60 seasonal workers to play elves in her department store’s Santa village. A third of\n",
      "the elves quit after children vomit on them, then 10 of the remaining elves quit after kids kick their shins. How\n",
      "many elves are left?\n",
      "MODEL ANSWER (CORRECT BUT IMPERFECT EQUATION ):Nissa hires 60 seasonal workers. A third of\n",
      "them quit. So 60 - 1/3 = 40 elves are left. Then 10 elves quit. So 40 - 10 = 30 elves are left. The answer is 30\n",
      "elves.\n",
      "QUESTION :Grandma Jones baked 5 apple pies for the ﬁreman’s luncheon. She cut each pie into 8 pieces and\n",
      "set the ﬁve pies out on the buffet table for the guests to serve themselves. At the end of the evening, after the\n",
      "guests had taken and eaten their pieces of pie, there were 14 pieces of pie remaining. How many pieces were\n",
      "taken by the guests?\n",
      "MODEL ANSWER (CORRECT BUT INVERTED SEMANTICS ):5 pies were baked and cut into 8 pieces each.\n",
      "The 5 pies were then served to the guests. 8 x 5 = 40 pieces of pie. The guests ate 14 pieces of pie. 40 - 14 = 26\n",
      "pieces of pie were left. The answer is 26. ✓\n",
      "26\n",
      "D.2 Incorrect Chain of Thought Analysis\n",
      "We also manually analyze 50 randomly sampled outputs of the model that were incorrect on GSM8K\n",
      "for LaMDA 137B. There are many ways that a chain of thought can be incorrect, making the design\n",
      "of error categorization non-trivial. We decided to categorize errors into what changes are needed to\n",
      "make the chain of thought correct, with the goal of elucidating how the model can be improved in the\n",
      "future.\n",
      "We found that many chains of thought can be made correct with one of the following three classes of\n",
      "modiﬁcation.\n",
      "•Calculator error only. We found that 8% of the chains of thought were completely correct except\n",
      "for a calculator error—in other words, applying an external calculator to equations, as done in\n",
      "Cobbe et al. (2021), would make the chain of thought correct. An example of this type of error is\n",
      "shown in Table 10: “calculator error only”. Indeed, the solve rate of chain-of-thought prompting\n",
      "on for LaMDA 137B GSM8K went up from 14.3% to 17.3% when we added a Python program\n",
      "as an external calculator, as shown in Table 2. Also, 34% of the examples contained calculator\n",
      "errors in addition to other types of errors. However, we perform the rest of the error categorization\n",
      "independently of calculator errors.\n",
      "•Symbol mapping error. We next found that 16% percent of the chains of thought were correct\n",
      "except for what we call symbol mapping errors. We deﬁne a symbol mapping error as when the\n",
      "chain of thought is correct except for the number symbols, and it could be made totally correct by\n",
      "modifying only the equations and not the words. As one might argue that they could simply place\n",
      "the correct ﬁnal equation in any chain of thought, we constrain this category to chains of thought\n",
      "where the chain of thought can be modiﬁed to be a completely correct reasoning process (not just\n",
      "ﬁnal answer). An example of this error category is shown in Table 10: “symbol mapping error”.\n",
      "•One step missing error. Our next category of error is chains of thought which were correct except\n",
      "that they were missing a single step. In other words, these chains of thoughts could be rewritten to\n",
      "be correct by adding in an additional reasoning step that was missed by the model. An example of\n",
      "this error category is shown in Table 10: “one step missing error”. We found that 22% percent of\n",
      "the errors fell into this category.\n",
      "Table 10: Example of incorrect chains of thought, categorized as described in Appendix D.2.\n",
      "QUESTION :Dan plants 3 rose bushes. Each rose bush has 25 roses. Each rose has 8 thorns. How many thorns\n",
      "are there total?\n",
      "MODEL ANSWER (INCORRECT ;CALCULATOR ERROR ONLY ):Dan plants 3 rose bushes. Each rose bush\n",
      "has 25 roses. Each rose has 8 thorns. So 3 x 25 x 8 = 300. The answer is 300. \u0017\n",
      "EXPLANATION FOR ERROR CATEGORY :The produced chain of thought could be made correct just by\n",
      "running the equation through an external calculator, instead of asking the model to do the computation.\n",
      "QUESTION :Jill gets paid $20 per hour to teach and $30 to be a cheerleading coach. If she works 50 weeks a\n",
      "year, 35 hours a week as a teacher and 15 hours a week as a coach, what’s her annual salary?\n",
      "MODEL ANSWER (INCORRECT ;SYMBOL MAPPING ERROR ):Jill gets paid 20 dollars per hour to teach\n",
      "and 30 dollars per hour to be a cheerleading coach. If she works 50 weeks a year, 35 hours a week as a teacher\n",
      "and 15 hours a week as a coach, then she works 50 x 35 = 1750 hours as a teacher and 15 x 30 = 450 hours as a\n",
      "coach. So she works 1750 + 450 = 2200 hours. She gets paid 20 dollars per hour for 1750 hours and 30 dollars\n",
      "per hour for 450 hours. So her annual salary is 20 x 1750 + 30 x 450 = $36,500. The answer is $36,500. \u0017\n",
      "EXPLANATION FOR ERROR CATEGORY :The model incorrectly mapped “15 x 30” instead of “15 x 50”, and\n",
      "the chain of thought would be made correct by ﬁxing just that one change (with an external calculator).\n",
      "QUESTION :Kelian has two recipes for preparing dishes, one having 20 instructions and the second one having\n",
      "twice as many instructions as the ﬁrst one. How many instructions does Kelian have to read to prepare the two\n",
      "dishes?\n",
      "MODEL ANSWER (INCORRECT ;ONE STEP MISSING ERROR ):Kelian has two recipes. One has 20 instruc-\n",
      "tions. The other has twice as many instructions as the ﬁrst one. So the second one has 40 instructions. So Kelian\n",
      "has to read 40 instructions to prepare the two dishes. The answer is 40. \u0017\n",
      "EXPLANATION FOR ERROR CATEGORY :The model answer could be made correct just adding one additional\n",
      "step (in this case, adding 20 and 40).\n",
      "27\n",
      "We found that the remaining chains of thought (27 of 50; 54%) would require substantial edits to make\n",
      "into a correct chain of thought. Almost all cases here involved some error in semantic understanding\n",
      "(see Table 11: “semantic understanding error”), and 8 of the 27 also had incoherent chain of thoughts,\n",
      "meaning that some statements in the generated chain of thought did not follow from prior ones or\n",
      "violated basic world knowledge (see Table 11: “incoherent chain of thought error”).\n",
      "Table 11: Example of incorrect chains of thought, categorized as described in Appendix D.2. These\n",
      "chains of thought had multiple mistakes that could not be ﬁxed with minor edits.\n",
      "QUESTION :Gretchen has 110 coins. There are 30 more gold coins than silver coins. How many gold coins\n",
      "does Gretchen have?\n",
      "MODEL ANSWER (INCORRECT ;SEMANTIC UNDERSTANDING ERROR ):Gretchen has 110 coins. There\n",
      "are 30 more gold coins than silver coins. So there are 110 - 30 = 80 silver coins. So there are 80 silver coins and\n",
      "110 - 80 = 30 gold coins. The answer is 30. \u0017\n",
      "EXPLANATION FOR ERROR CATEGORY :The model does not understand that 110 coins are in total and that\n",
      "it must solve an equation to get the number of gold and silver coins.\n",
      "QUESTION :In a dance class of 20 students, 20% enrolled in contemporary dance, 25% of the remaining\n",
      "enrolled in jazz dance, and the rest enrolled in hip-hop dance. What percentage of the entire students enrolled in\n",
      "hip-hop dance?\n",
      "MODEL ANSWER (INCORRECT ;INCOHERENT CHAIN OF THOUGHT ERROR ):20% of the students en-\n",
      "rolled in contemporary dance. 25% of the remaining students enrolled in jazz dance. The rest enrolled in hip-hop\n",
      "dance. So the percentage of the entire students enrolled in hip-hop dance is the percentage of the students\n",
      "enrolled in hip-hop dance, minus the percentage of the students enrolled in contemporary dance, minus the\n",
      "percentage of the students enrolled in jazz dance. So the percentage of the entire students enrolled in hip-hop\n",
      "dance is (25 + 20) - (25 + 20) = 100%. The answer is 100%. \u0017\n",
      "EXPLANATION FOR ERROR CATEGORY :This chain of thought is incoherent in that the percent of entire\n",
      "students enrolled in hip-hope dance cannot be the percent of student enrolled in hip-hop dance minus another\n",
      "term.\n",
      "Overall, there are no guarantees that the reasoning processes generated by large language models\n",
      "are coherent or factually correct, as underscored by the recent work evaluating the factuality of\n",
      "language model generations and explanations (Maynez et al., 2020; Rashkin et al., 2021; Ye and\n",
      "Durrett, 2022; Marasovi ´c et al., 2022; Wiegreffe et al., 2022). Incorrect reasoning processes can lead\n",
      "to both incorrect ﬁnal answers as well as accidentally correct ﬁnal answers (with accidentally correct\n",
      "ﬁnal answers being more likely for tasks such as binary classiﬁcation as opposed to free response).\n",
      "Improving the factuality of language model generations with respect to context and world knowledge\n",
      "is an important direction open problems in language model research and could also be expected to\n",
      "potentially improve multi-step reasoning abilities of language models. One potential method for\n",
      "improving the quality of decoding could involve generating multiple reasoning paths and scoring\n",
      "each of them with a veriﬁer, though this requires training the veriﬁer (Cobbe et al., 2021; Shen et al.,\n",
      "2021; Thoppilan et al., 2022).\n",
      "D.3 Additional Robustness Analysis\n",
      "As the experiments in the main paper use a ﬁxed number of few-shot exemplars (8; as constrained by\n",
      "the input length of 1024 tokens), we verify that the chain-of-thought prompting is robust to various\n",
      "numbers of few-shot exemplars. We run experiments for LaMDA 137B, comparing chain-of-thought\n",
      "prompting with standard prompting for the ﬁve datasets where standard prompting had a mostly ﬂat\n",
      "scaling curve (the largest model did not achieve high performance). As shown in Figure 11, the\n",
      "improvement of chain-of-thought prompting over standard prompting remains robust to varying the\n",
      "number of few-shot exemplars in the prompt.\n",
      "28\n",
      "12468051015 Solve rate (%)GSM8K\n",
      "124680204060MultiArith\n",
      "(MAWPS)\n",
      "124680255075100\n",
      "Number of few-shot exemplarsSports\n",
      "UnderstandingStandard prompting\n",
      "Chain of thought prompting\n",
      "124680255075100Coin Flip\n",
      "12340255075100Last Letter\n",
      "Concatenation\n",
      "Figure 11: The improvement of chain of thought prompting over standard prompting appears robust\n",
      "to varying the number of few-shot exemplars in the prompt.\n",
      "Table 12: Summary of math word problem benchmarks we use in this paper with examples. N:\n",
      "number of evaluation examples.\n",
      "Dataset N Example problem\n",
      "GSM8K 1,319 Josh decides to try ﬂipping a house. He buys a house for $80,000 and then puts\n",
      "in $50,000 in repairs. This increased the value of the house by 150%. How\n",
      "much proﬁt did he make?\n",
      "SV AMP 1,000 Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each\n",
      "pack. How much do you have to pay to buy each pack?\n",
      "ASDiv 2,096 Ellen has six more balls than Marin. Marin has nine balls. How many balls does\n",
      "Ellen have?\n",
      "AQuA 254 A car is being driven, in a straight line and at a uniform speed, towards the base\n",
      "of a vertical tower. The top of the tower is observed from the car and, in the\n",
      "process, it takes 10 minutes for the angle of elevation to change from 45◦to 60◦.\n",
      "After how much more time will this car reach the base of the tower? Answer\n",
      "Choices: (a) 5√\n",
      "3+ 1 (b) 6√\n",
      "3+√\n",
      "2(c) 7√\n",
      "3- 1 (d) 8√\n",
      "3- 2 (e) None of these\n",
      "MAWPS: SingleOp 562 If there are 7 bottle caps in a box and Linda puts 7 more bottle caps inside, how\n",
      "many bottle caps are in the box?\n",
      "MAWPS: SingleEq 508 Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27\n",
      "dollars. How much did each candy bar cost?\n",
      "MAWPS: AddSub 395 There were 6 roses in the vase. Mary cut some roses from her ﬂower garden.\n",
      "There are now 16 roses in the vase. How many roses did she cut?\n",
      "MAWPS: MultiArith 600 The school cafeteria ordered 42 red apples and 7 green apples for students\n",
      "lunches. But, if only 9 students wanted fruit, how many extra did the cafeteria\n",
      "end up with?\n",
      "29\n",
      "E Additional Details\n",
      "Version Control\n",
      "V5→V6. Fixed minor typo in Figure 3.\n",
      "V4→V5. Added Codex and UL2 results. Small changes to writing and style of paper.\n",
      "V3→V4. Fixed typo in Figure 3 and added a couple citations.\n",
      "V2→V3. Added GPT-3 results. Added SV AMP and AQuA eval datasets for math. Added SayCan\n",
      "eval for commonsense. Added Extended Related Work section (Appendix C). Added ablations for\n",
      "Commonsense and Symbolic Reasoning (Table 7). Added FAQ section (Appendix A). Added raw\n",
      "results in Appendix B.\n",
      "V1→V2. Added PaLM results (V1 only had LaMDA).\n",
      "E.1 Reproducibility Statement\n",
      "As our results make use of two sets of large language models that is not publicly available, we take\n",
      "the following actions to facilitate reproducibility. First, we provide the exact input prompts for all\n",
      "tasks in Table 20–Table 27 in Appendix G (and emphasize that we do not perform any ﬁnetuning and\n",
      "only apply prompting to off-the-shelf language models). Second, we conduct experiments using the\n",
      "publicly available GPT-3 API for four model scales text-ada-001, text-babbage-001, text-curie-001,\n",
      "text-davinci-002). Finally, we make exact inputs, targets, and predictions for LaMDA 137B for each\n",
      "task available as a zip ﬁle in the supplementary material.\n",
      "E.2 Computational Resources\n",
      "For all three language models we evaluated, we did prompting-based inference only. No ﬁnetuning\n",
      "was done for this paper. For inference on LaMDA 137B we use TPU v3 (8x8 conﬁguration, 64 chips\n",
      "/ 128 cores), and for inference on PaLM 540B we use TPU v4 (4x4x12 conﬁguration, 192 chips / 384\n",
      "cores). GPT-3 experiments were done using the public API.5\n",
      "E.3 Dataset Details and Licenses\n",
      "We list the details and licenses for all arithmetic and commonsense datasets used in this paper. The\n",
      "symbolic reasoning datasets were created synthetically, as described in Section 4.\n",
      "Arithmetic reasoning\n",
      "•Math Word Problem Repository (Koncel-Kedziorski et al., 2016): AddSub (Hosseini\n",
      "et al., 2014): https://www.cs.washington.edu/nlp/arithmetic ; MultiArith (Roy\n",
      "and Roth, 2015), license: CC BY 4.0.\n",
      "• ASDiv (Miao et al., 2020): https://github.com/chaochun/nlu-asdiv-dataset .\n",
      "•AQuA (Ling et al., 2017): https://github.com/deepmind/AQuA , license: https://\n",
      "github.com/deepmind/AQuA/blob/master/LICENSE .\n",
      "•GSM8K (Cobbe et al., 2021): https://github.com/openai/grade-school-math ,\n",
      "MIT license: https://github.com/openai/grade-school-math/blob/master/\n",
      "LICENSE .\n",
      "•SV AMP (Patel et al., 2021): https://github.com/arkilpatel/SVAMP , MIT license:\n",
      "https://github.com/arkilpatel/SVAMP/blob/main/LICENSE .\n",
      "Commonsense reasoning\n",
      "•CSQA (Talmor et al., 2019): https://www.tau-nlp.org/commonsenseqa ,https://\n",
      "github.com/jonathanherzig/commonsenseqa .\n",
      "5https://beta.openai.com/docs/api-reference/making-requests\n",
      "30\n",
      "•StrategyQA (Geva et al., 2021): we use the open-domain setting (question-only set)\n",
      "from BIG-bench collaboration (2021): https://github.com/google/BIG-bench/\n",
      "tree/main/bigbench/benchmark_tasks/strategyqa . The original dataset is from\n",
      "https://github.com/eladsegal/strategyqa , MIT license: https://github.com/\n",
      "eladsegal/strategyqa/blob/main/LICENSE .\n",
      "•Date understanding and sports understanding from BIG-Bench (BIG-bench collaboration,\n",
      "2021): Apache License v.2: https://github.com/google/BIG-bench/blob/main/\n",
      "LICENSE .\n",
      "•SayCan (Ahn et al., 2022): SayCan dataset can be accessed at https://say-can.github.\n",
      "io/under CC BY 4.0 license.\n",
      "31\n",
      "F Appendix: Input/Output Examples\n",
      "Table 13: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the\n",
      "letter concatenation task.\n",
      "QUESTION :Take the last letters of the words in “Waldo Schmidt” and concatenate them.\n",
      "MODEL ANSWER (CORRECT): The last letter of “Waldo” is “o”. The last letter of “Schmidt” is “t”.\n",
      "Concatenating them is “ot”. So the answer is ot. ✓\n",
      "QUESTION :Take the last letters of the words in “Daniel Friedman” and concatenate them.\n",
      "MODEL ANSWER (INCORRECT): The last letter of “Daniel” is “l”. The last letter of “Friedman” is “m”.\n",
      "Concatenating them is “lm”. So the answer is lm. \u0017\n",
      "Table 14: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the\n",
      "coinﬂip task.\n",
      "QUESTION :A coin is heads up. Andree ﬂips the coin. Audrie does not ﬂip the coin. Is the coin still heads up?\n",
      "MODEL ANSWER (CORRECT): The coin was ﬂipped by Andree. So the coin was ﬂipped 1 time, which is\n",
      "an odd number. The coin started heads up, so after an odd number of ﬂips, it will be tails up. So the answer is no.\n",
      "✓\n",
      "QUESTION :A coin is heads up. Kristian does not ﬂip the coin. Dallas does not ﬂip the coin. Is the coin still\n",
      "heads up?\n",
      "MODEL ANSWER (INCORRECT): The coin was ﬂipped by Kristian. So the coin was ﬂipped 1 time, which\n",
      "is an odd number. The coin started heads up, so after an odd number of ﬂips, it will be tails up. So the answer is\n",
      "no.\u0017\n",
      "Table 15: Examples of correct and incorrect chains of thought produced by LaMDA 137B on CSQA.\n",
      "QUESTION :When a person is beginning work, what are they building?\n",
      "Answer Choices: (a) time (b) accomplishing (c) working (d) momentum (e) tiredness\n",
      "MODEL ANSWER (CORRECT): The answer must be something that is built. Of the above choices, only\n",
      "momentum is built. So the answer is (d). ✓\n",
      "QUESTION :Where are you likely to ﬁnd a hamburger?\n",
      "Answer Choices: (a) fast food restaurant (b) pizza (c) ground up dead cows (d) mouth (e) cow carcus\n",
      "MODEL ANSWER (CORRECT): The answer must be a place where hamburgers are found. Of the above\n",
      "choices, only fast food restaurants serve hamburgers. So the answer is (a). ✓\n",
      "QUESTION :Aside from water and nourishment what does your dog need?\n",
      "Answer Choices: (a) bone (b) charm (c) petted (d) lots of attention (e) walked\n",
      "MODEL ANSWER (INCORRECT): The answer must be something that a dog needs. Of the above choices,\n",
      "only bone is something that a dog needs. So the answer is (a). \u0017(Ground truth is (d).)\n",
      "QUESTION :What are you waiting alongside with when you’re in a reception area?\n",
      "Answer Choices: (a) motel (b) chair (c) hospital (d) people (e) hotels\n",
      "MODEL ANSWER (INCORRECT): The answer must be something that is waiting with you in a reception\n",
      "area. Of the above choices, only people are waiting with you in a reception area. So the answer is (e). \u0017(Ground\n",
      "truth is (d).)\n",
      "32\n",
      "Table 16: Examples of correct and incorrect chains of thought produced by LaMDA 137B on\n",
      "StrategyQA.\n",
      "QUESTION :Will The Exorcist stimulate limbic system?\n",
      "MODEL ANSWER (CORRECT): The Exorcist is a horror movie. Horror movies are scary. The limbic system\n",
      "is involved in fear. Thus, The Exorcist will stimulate the limbic system. So the answer is yes. ✓\n",
      "QUESTION :Was Jackson Pollock trained by Leonardo da Vinci?\n",
      "MODEL ANSWER (CORRECT): Leonardo da Vinci lived in the 15th century. Jackson Pollock lived in the\n",
      "20th century. Thus, Jackson Pollock could not have been trained by Leonardo da Vinci. So the answer is no. ✓\n",
      "QUESTION :Can Harry Potter book a ﬂight on Asiana Airlines?\n",
      "MODEL ANSWER (INCORRECT): Harry Potter is a ﬁctional character. Thus, Harry Potter can do anything.\n",
      "So the answer is yes. \u0017(Ground truth is “no”.)\n",
      "QUESTION :Would a sophist use an épée?\n",
      "MODEL ANSWER (INCORRECT): A sophist is a person who is skilled in the art of persuasion. An épée is\n",
      "a type of sword. Thus, a sophist could use an épée. So the answer is yes. \u0017(Ground truth is “no”.)\n",
      "Table 17: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Date\n",
      "Understanding.\n",
      "QUESTION :May 6, 1992 is like yesterday to Jane, but that is actually ten years ago. What is the date a month\n",
      "ago in MM/DD/YYYY?\n",
      "MODEL ANSWER (CORRECT): May 6, 1992 is ten years ago, so today is May 6, 2002. So a month ago will\n",
      "be April 6, 2002. So the answer is 04/06/2002. ✓\n",
      "QUESTION :This is the last day of 1899. What is the date 24 hours later in MM/DD/YYYY?\n",
      "MODEL ANSWER (CORRECT): Today is 12/31/1899. 24 hours later will be 01/01/1900. So the answer is\n",
      "01/01/1900. ✓\n",
      "QUESTION :Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one\n",
      "week ago from today in MM/DD/YYYY?\n",
      "MODEL ANSWER (INCORRECT): Tomorrow is 7/9/1972. One week ago from today is 7/2/1972. So the\n",
      "answer is 7/2/1972. \u0017(Ground truth is 07/01/1972.)\n",
      "QUESTION :Today is the palindrome day of 2020, because the MMDDYYYY format of the date is the same\n",
      "backwards as forwards. What is the date tomorrow in MM/DD/YYYY?\n",
      "MODEL ANSWER (INCORRECT): Today is 02/29/2020. Tomorrow will be 03/01/2020. So the answer is\n",
      "03/01/2020. \u0017(Ground truth is “02/03/2020”.)\n",
      "Table 18: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Sports\n",
      "Understanding.\n",
      "QUESTION :Is the following sentence plausible? “Joao Moutinho was out at third.”\n",
      "MODEL ANSWER (CORRECT): Joao Moutinho is a soccer player. Being out at third is part of baseball, not\n",
      "soccer. So the answer is no. ✓\n",
      "QUESTION :Is the following sentence plausible? “Malcolm Brogdon eurostepped to the basket in the NBA\n",
      "Championship.”\n",
      "MODEL ANSWER (CORRECT): Malcolm Brogdon is a basketball player. Eurostepping to the basket is part\n",
      "of basketball. So the answer is yes. ✓\n",
      "QUESTION :Is the following sentence plausible? “Derrick White backhanded a shot.”\n",
      "MODEL ANSWER (INCORRECT): Derrick White is a basketball player. Backhanding a shot is part of\n",
      "basketball. So the answer is yes. \u0017(Ground truth is “no”, backhanding a shot is part of hockey.)\n",
      "QUESTION :Is the following sentence plausible? “Nazem Kadri was out at home.”\n",
      "MODEL ANSWER (INCORRECT): Nazem Kadri is a hockey player. Being out at home is part of hockey.\n",
      "So the answer is yes. \u0017(Ground truth is “no”, being out at home is part of baseball.)\n",
      "33\n",
      "Table 19: Examples of correct and incorrect chains of thought produced by PaLM 540B on SayCan\n",
      "robot planning tasks.\n",
      "QUESTION :I spilled my coke on the table, could you throw it away and then bring me something to help clean?\n",
      "MODEL ANSWER (CORRECT): Explanation: The user has spilled their coke on the table. I will throw away\n",
      "the coke and then bring the user a sponge. Plan: ﬁnd(coke), pick(coke), ﬁnd(trash), put(coke), ﬁnd(sponge),\n",
      "pick(sponge), ﬁnd(table), put(sponge). ✓\n",
      "QUESTION :Could you compost that apple for me?\n",
      "MODEL ANSWER (CORRECT): Explanation: The user would like me to compost the apple. I will move the\n",
      "apple to the compost. Plan: ﬁnd(apple), pick(apple), ﬁnd(trash), put(apple). ✓\n",
      "QUESTION :Can you bring me a drink that is not coke?\n",
      "MODEL ANSWER (INCORRECT): Explanation: The user asked me to bring a drink that is not coke, I will\n",
      "bring a sprite. Plan: ﬁnd(sprite), pick(sprite), ﬁnd(user), put(sprite). \u0017(Feasible answers including ﬁnding lime\n",
      "soda, pepsi, grapefruit soda or water, because there is no sprite in the scene as deﬁned in Table 28.)\n",
      "QUESTION :Can you bring me something salty?\n",
      "MODEL ANSWER (INCORRECT): Explanation: The user would like something salty. There are several\n",
      "options in the objects list, so I will bring the user a lime soda. Plan: ﬁnd(lime soda), pick(lime soda), ﬁnd(user),\n",
      "put(lime soda). \u0017(Feasible answers including ﬁnding chips. The model misidentify lime soda as salty.)\n",
      "34\n",
      "G Appendix: Full Prompts\n",
      "Table 20: Few-shot exemplars for full chain of thought prompt for math word problems. This set of\n",
      "exemplars was used for all math word problem datasets except AQuA.\n",
      "PROMPT FOR MATH WORD PROBLEMS\n",
      "Q:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\n",
      "will be 21 trees. How many trees did the grove workers plant today?\n",
      "A:There are15trees originally. Then there were 21trees aftersome more were planted. Sothere must have\n",
      "been 21-15=6. The answer is 6.\n",
      "Q:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A:There areoriginally 3cars. 2more carsarrive. 3+2=5. The answer is 5.\n",
      "Q:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
      "A:Originally, Leah had32choco lates. Hersisterhad42.Sointotalthey had32+42=74.Aftereating35,they\n",
      "had74-35=39. The answer is 39.\n",
      "Q:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\n",
      "Jason give to Denny?\n",
      "A:Jasonstarted with 20lollipops. Then hehad12aftergivingsome toDenny. Sohegave Denny 20-12=8.\n",
      "The answer is 8.\n",
      "Q:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\n",
      "have now?\n",
      "A:Shawn started with 5toys. Ifhegot2toys each from hismom anddad, then thatis4more toys. 5+4=9.\n",
      "The answer is 9.\n",
      "Q:There were nine computers in the server room. Five more computers were installed each day, from monday\n",
      "to thursday. How many computers are now in the server room?\n",
      "A:There were originally 9computers.Foreach of4days, 5more computerswere added. So5*4=20\n",
      "computerswere added. 9+20is29. The answer is 29.\n",
      "Q:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\n",
      "balls did he have at the end of wednesday?\n",
      "A:Michael started with 58golfballs. Afterlosing23ontuesday, hehad58-23=35.Afterlosing2more, he\n",
      "had35-2=33golfballs. The answer is 33.\n",
      "Q:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\n",
      "A:Olivia had23dollars. 5bagels for3dollarseach willbe5x3=15dollars. Soshehas23-15dollarsleft.23\n",
      "-15is8. The answer is 8.\n",
      "35\n",
      "Table 21: Few-shot exemplars for full chain of thought prompt for AQuA.\n",
      "PROMPT FOR AQ UAALGEBRAIC WORD PROBLEMS\n",
      "Q:John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers\n",
      "is?\n",
      "Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\n",
      "A:If10isadded toeach number,then themean ofthenumbers alsoincreases by10.Sothenewmean would be\n",
      "50. The answer is (a).\n",
      "Q:If a / b = 3/4 and 8a + 5b = 22,then ﬁnd the value of a.\n",
      "Answer Choices: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e) 7/2\n",
      "A:Ifa/b=3/4,then b=4a/3.So8a+5(4a /3)=22.This simpliﬁesto8a+20a/3=22,which means 44a/3\n",
      "=22.Soaisequal to3/2. The answer is (b).\n",
      "Q:A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then ﬁnd the distance?\n",
      "Answer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km\n",
      "A:Thedistance thatthepersontraveled would have been 20km/hr *2.5hrs=50km. The answer is (e).\n",
      "Q:How many keystrokes are needed to type the numbers from 1 to 500?\n",
      "Answer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788\n",
      "A:There are9one-digit numbers from 1to9.There are90two-digit numbers from 10to99.There are401\n",
      "three -digit numbers from 100to500. 9+90(2) +401(3) =1392. The answer is (b).\n",
      "Table 22: Few-shot exemplars for full chain of thought prompt for the last letter concatenation task.\n",
      "PROMPT FOR LAST LETTER CONCATENATION\n",
      "Q:Take the last letters of the words in \"Elon Musk\" and concatenate them.\n",
      "A:Thelastletterof\"Elon\" is\"n\".Thelastletterof\"Musk\" is\"k\".Concatenatingthem is\"nk\". The answer is nk.\n",
      "Q:Take the last letters of the words in \"Larry Page\" and concatenate them.\n",
      "A:Thelastletterof\"Larry\" is\"y\".Thelastletterof\"Page\" is\"e\".Concatenatingthem is\"ye\". The answer is ye.\n",
      "Q:Take the last letters of the words in \"Sergey Brin\" and concatenate them.\n",
      "A:Thelastletterof\"Sergey\" is\"y\".Thelastletterof\"Brin\" is\"n\".Concatenatingthem is\"yn\". The answer is\n",
      "yn.\n",
      "Q:Take the last letters of the words in \"Bill Gates\" and concatenate them.\n",
      "A:Thelastletterof\"Bill\" is\"l\".Thelastletterof\"Gates\" is\"s\".Concatenatingthem is\"ls\". The answer is ls.\n",
      "36\n",
      "Table 23: Few-shot exemplars for full chain of thought prompt for the coinﬂip task.\n",
      "PROMPT FOR COIN FLIP\n",
      "Q:Q: A coin is heads up. Ka ﬂips the coin. Sherrie ﬂips the coin. Is the coin still heads up?\n",
      "A:Thecoin wasﬂipped byKaandSherrie.Sothecoin wasﬂipped 2times, which isaneven number.Thecoin\n",
      "started heads up,soafteraneven numberofﬂips, itwillstillbeheads up. So the answer is yes.\n",
      "Q:A coin is heads up. Jamey ﬂips the coin. Teressa ﬂips the coin. Is the coin still heads up?\n",
      "A:Thecoin wasﬂipped byJamey andTeressa. Sothecoin wasﬂipped 2times, which isaneven number.The\n",
      "coin started heads up,soafteraneven numberofﬂips, itwillstillbeheads up. So the answer is yes.\n",
      "Q:A coin is heads up. Maybelle ﬂips the coin. Shalonda does not ﬂip the coin. Is the coin still heads up?\n",
      "A:Thecoin wasﬂipped byMaybelle. Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin started\n",
      "heads up,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\n",
      "Q:A coin is heads up. Millicent does not ﬂip the coin. Conception ﬂips the coin. Is the coin still heads up?\n",
      "A:Thecoin wasﬂipped byConception. Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin\n",
      "started heads up,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\n",
      "Q:A coin is heads up. Sal ﬂips the coin. Raymond does not ﬂip the coin. Is the coin still heads up?\n",
      "A:Thecoin wasﬂipped bySal.Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin started heads\n",
      "up,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\n",
      "Q:A coin is heads up. Conception ﬂips the coin. Kristian does not ﬂip the coin. Is the coin still heads up?\n",
      "A:Thecoin wasﬂipped byConception. Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin\n",
      "started heads up,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\n",
      "Q:A coin is heads up. Inga does not ﬂip the coin. Elanor does not ﬂip the coin. Is the coin still heads up?\n",
      "A:Thecoin wasﬂipped bynoone. Sothecoin wasﬂipped 0times. Thecoin started heads up,anditwasnot\n",
      "ﬂipped, soitisstillheads up. So the answer is yes.\n",
      "Q:A coin is heads up. Ryan ﬂips the coin. Shaunda ﬂips the coin. Is the coin still heads up?\n",
      "A:Thecoin wasﬂipped byRyan andShaunda. Sothecoin wasﬂipped 2times, which isaneven number.The\n",
      "coin started heads up,soafteraneven numberofﬂips, itwillstillbeheads up. So the answer is yes.\n",
      "37\n",
      "Table 24: Few-shot exemplars for full chain of thought prompt for CSQA. There are newlines\n",
      "between the answer choices that are omitted in the table for space reasons.\n",
      "PROMPT FOR CSQA\n",
      "Q:What do people use to absorb extra ink from a fountain pen? Answer Choices: (a) shirt pocket (b)\n",
      "calligrapher’s hand (c) inkwell (d) desk drawer (e) blotter\n",
      "A:Theanswer must beanitem thatcanabsorb ink.Oftheabove choices, only blottersareused toabsorb ink.\n",
      "So the answer is (e).\n",
      "Q:What home entertainment equipment requires cable?\n",
      "Answer Choices: (a) radio shack (b) substation (c) television (d) cabinet\n",
      "A:Theanswer must require cable.Oftheabove choices, only television requires cable. So the answer is (c).\n",
      "Q:The fox walked from the city into the forest, what was it looking for? Answer Choices: (a) pretty ﬂowers (b)\n",
      "hen house (c) natural habitat (d) storybook\n",
      "A:Theanswer must besome thing intheforest.Oftheabove choices, only naturalhabitatisintheforest. So the\n",
      "answer is (b).\n",
      "Q:Sammy wanted to go to where the people were. Where might he go? Answer Choices: (a) populated areas\n",
      "(b) race track (c) desert (d) apartment (e) roadblock\n",
      "A:Theanswer must beaplace with alotofpeople.Oftheabove choices, only populated areashave alotof\n",
      "people. So the answer is (a).\n",
      "Q:Where do you put your grapes just before checking out? Answer Choices: (a) mouth (b) grocery cart (c)super\n",
      "market (d) fruit basket (e) fruit market\n",
      "A:Theanswer should betheplace where grocery items areplaced beforecheck ingout.Oftheabove choices,\n",
      "grocery cartmakes themost sense forholdinggrocery items. So the answer is (b).\n",
      "Q:Google Maps and other highway and street GPS services have replaced what? Answer Choices: (a) united\n",
      "states (b) mexico (c) countryside (d) atlas\n",
      "A:Theanswer must besome thing thatused todowhat Google Maps andGPS services do,which istogive\n",
      "directions. Oftheabove choices, only atlases areused togive directions. So the answer is (d).\n",
      "Q:Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (a) harder (b)\n",
      "anguish (c) bitterness (d) tears (e) sadness\n",
      "A:Theanswer should bethefeelingofsome onegettingdivorced who wasdoingallthework. Oftheabove\n",
      "choices, theclosestfeelingisbitterness. So the answer is (c).\n",
      "38\n",
      "Table 25: Few-shot exemplars for full chain of thought prompt for StrategyQA.\n",
      "PROMPT FOR STRATEGY QA\n",
      "Q:Do hamsters provide food for any animals?\n",
      "A:Ham sters areprey animals. Prey arefood forpreda tors. Thus, hamsters provide food forsome animals. So\n",
      "the answer is yes.\n",
      "Q:Could Brooke Shields succeed at University of Pennsylvania?\n",
      "A:Brooke Shields went toPrince tonUniversity. Prince tonUniversityisabout asacademically rigorousasthe\n",
      "UniversityofPenn sylvania.Thus, Brooke Shields could alsosucceed attheUniversityofPenn sylvania. So the\n",
      "answer is yes.\n",
      "Q:Yes or no: Hydrogen’s atomic number squared exceeds number of Spice Girls?\n",
      "A:Hydrogenhasanatomic numberof1.1squared is1.There are5Spice Girls. Thus, Hydrogen’s atomic\n",
      "numbersquared islessthan 5. So the answer is no.\n",
      "Q:Yes or no: Is it common to see frost during some college commencements?\n",
      "A:College commence ment ceremonies canhappeninDecember,May, andJune. Decemberisinthewinter,so\n",
      "there canbefrost. Thus, there could befrost atsome commence ments. So the answer is yes.\n",
      "Q:Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?\n",
      "A:TheWar inVietnam was6months. Thegestationperiod forallama is11months, which ismore than 6\n",
      "months. Thus, allama could notgive birth twice duringtheWar inVietnam. So the answer is no.\n",
      "Q:Yes or no: Would a pear sink in water?\n",
      "A:Thedensityofapear isabout 0.6g/cm3,which islessthan water.Objects lessdense than waterﬂoat. Thus,\n",
      "apear would ﬂoat. So the answer is no.\n",
      "Table 26: Few-shot exemplars for full chain of thought prompt for Date Understanding.\n",
      "PROMPT FOR DATE UNDERSTANDING\n",
      "Q:2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?\n",
      "A:If2015 iscomingin36hours, then itiscomingin2days. 2days before01/01/2015 is12/30/2014, sotoday\n",
      "is12/30/2014. Sooneweek from todaywillbe01/05/2015. So the answer is 01/05/2015.\n",
      "Q:The ﬁrst day of 2019 is a Tuesday, and today is the ﬁrst Monday of 2019. What is the date today in\n",
      "MM/DD/YYYY?\n",
      "A:Iftheﬁrstdayof2019 wasTues day,then 01/01/2019 wasaTues day.Todayistheﬁrstmonday,would besix\n",
      "days later. Sotodayis01/07/2019. So the answer is 01/07/2019.\n",
      "Q:The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10\n",
      "days ago in MM/DD/YYYY?\n",
      "A:One dayafter06/01/1943 is06/02/1943, sotodayis06/02/1943. 10days beforetodayis05/23/1943. So the\n",
      "answer is 05/23/1943.\n",
      "Q:It is 4/19/1969 today. What is the date 24 hours later in MM/DD/YYYY?\n",
      "A:Todayis04/19/1969. 24hours later isonedayaftertoday, which would be04/20/1969. So the answer is\n",
      "04/20/1969.\n",
      "Q:Jane thought today is 3/11/2002, but today is in fact Mar 12, which is 1 day later. What is the date 24 hours\n",
      "later in MM/DD/YYYY?\n",
      "A:Todayis03/12/2002. Sothedate 24hours later willbe03/13/2002. So the answer is 03/13/2002.\n",
      "Q:Jane was born on the last day of Feburary in 2001. Today is her 16-year-old birthday. What is the date\n",
      "yesterday in MM/DD/YYYY?\n",
      "A:ThelastdayofFebru aryisthe28th, soJane wasborn on02/28/2001. Todayisher16-year oldbirth day, so\n",
      "todayis02/28/2017. Soyesterdaywas02/27/2017. So the answer is 02/27/2017.\n",
      "39\n",
      "Table 27: Few-shot exemplars for full chain of thought prompt for Sports Understanding.\n",
      "PROMPT FOR SPORTS UNDERSTANDING\n",
      "Q:Is the following sentence plausible? “Kyle Palmieri was called for slashing.”\n",
      "A:Kyle Palmieri isahockey player. Beingcalled forslash ingispartofhockey. So the answer is yes.\n",
      "Q:Is the following sentence plausible? “Joao Moutinho caught the screen pass in the NFC championship.”\n",
      "A:Joao Moutinho isasoccerplayer. TheNFC cham pionship ispartofAmer icanfootball, notsoccer. So the\n",
      "answer is no.\n",
      "Q:Is the following sentence plausible? “Carson Wentz set the pick and roll.”\n",
      "A:CarsonWentz isanAmer icanfootballplayer. Pick androllispartofbasketball, notfootball. So the answer\n",
      "is no.\n",
      "Q:Is the following sentence plausible? “Jonas Valanciunas beat the buzzer.”\n",
      "A:Jonas Valan ciunasisabasketballplayer. Beatingthebuzzer ispartofbasketball. So the answer is yes.\n",
      "Q:Is the following sentence plausible? “Jamel Murray was perfect from the line.”\n",
      "A:JamalMurrayisabasketballplayer. Beingperfectfrom thelineispartofbasketball. So the answer is yes.\n",
      "Q:Is the following sentence plausible? “Sam Darnold passed the puck.”\n",
      "A:Sam Darnold isaAmer icanfootballplayer. Passingthepuck ispartofhockey, notAmer icanfootball. So the\n",
      "answer is no.\n",
      "Q:Is the following sentence plausible? “Draymond Green threw a touchdown.”\n",
      "A:Dray mond Green isanbasketballplayer. Throw ingatouch down ispartoffootball, notbasketball. So the\n",
      "answer is no.\n",
      "Q:Is the following sentence plausible? “Malcolm Brogdon banked the shot in.”\n",
      "A:Malcolm Brog donisabasketballplayer. Bank ingtheshot inispartofbasketball. So the answer is yes.\n",
      "40\n",
      "Table 28: Few-shot exemplars for full chain of thought prompt for SayCan robot planning tasks.\n",
      "PROMPT FOR SAYCANROBOT PLANNING\n",
      "Locations = [counter, table, user, trash, bowl].\n",
      "Objects = [7up, apple, kettle chips, tea, multigrain chips, coke, lime soda, jalapeno chips, rice chips, orange,\n",
      "grapefruit soda, pepsi, redbull, energy bar, sponge, water].\n",
      "The robot can pick up items with pick(object) and put down items with put(object) as well as ﬁnd objects or\n",
      "locations with ﬁnd(). The robot can only understand the explicit locations and objects listed.\n",
      "Human : I’m hungry, can you bring me some chips.\n",
      "Explanation :Theuser ishungryandhasasked forchips. There areseveraltypes ofchips avail able, Iwillbring\n",
      "theuser thekettlechips.\n",
      "Plan : 1. ﬁnd(kettle chips), 2. pick(kettle chips), 3. ﬁnd(user), 4. put(kettle chips), 5. done().\n",
      "Human : How would you move the grapefruit drink from the table to the counter?\n",
      "Explanation :Theuser hasasked metomove thegrape fruit drink tothecounter.\n",
      "Plan : 1. ﬁnd(grapefruit soda), 2. pick(grapefruit soda), 3. ﬁnd(counter), 4. put(grapefruit soda), 5. done().\n",
      "Human : How would you bring me some snacks?\n",
      "Explanation :Theuser hasasked forsnacks, Iwillchoose twoitems andbring them. Iwillbring jalapeno chips\n",
      "andanapple.\n",
      "Plan : 1. ﬁnd(jalapeno chips), 2. pick(jalapeno chips), 3. ﬁnd(user), 4. put(jalapeno chips), 5. ﬁnd(apple), 6.\n",
      "pick(apple), 7. ﬁnd(user), 8. put(apple), 9. done().\n",
      "Human : How would you bring me something to eat that isn’t a fruit?\n",
      "Explanation :Theuser hasasked forafood thatisn’t afruit, Iwillbring anenergy bartothem.\n",
      "Plan : 1. ﬁnd(energy bar), 2. pick(energy bar), 3. ﬁnd(user), 4. put(energy bar), 5. done().\n",
      "Human : How would you put the rice chips in the bowl and then move the tea to the table?\n",
      "Explanation :Theuser hasasked metodotwotasks, Iwilldooneandthen theother.\n",
      "Plan : 1. ﬁnd(rice chips), 2. pick(rice chips), 3. ﬁnd(bowl), 4. put(rice chips), 5. ﬁnd(tea), 6. pick(tea), 7.\n",
      "ﬁnd(table), 8. put(tea), 9. done().\n",
      "Human : How would you throw away a redbull?\n",
      "Explanation :Theuser hasasked metothrow away theredbull, Iwillmove ittothetrash.\n",
      "Plan : 1. ﬁnd(redbull), 2. pick(redbull), 3. ﬁnd(trash), 4. put(redbull), 5. done().\n",
      "Human : Bring me a drink.\n",
      "Explanation :Theuser hasasked foradrink andthere aremany options. Iwillbring them awater.\n",
      "Plan : 1. ﬁnd(water), 2. pick(water), 3. ﬁnd(user), 4. put(water), 5. done().\n",
      "41\n",
      "H Appendix: Alternate Annotators for MWP\n",
      "Table 29: Few-shot exemplars for full chain of thought prompt for math word problems. These\n",
      "exemplars are the same as in Table 20, except that the chains of thought were written by a different\n",
      "annotator (“Annotator B” instead of “Annotator A”). Annotators were co-authors and familiar with\n",
      "the goal of chain of thought prompting.\n",
      "PROMPT FOR MATH WORD PROBLEMS\n",
      "Q:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\n",
      "will be 21 trees. How many trees did the grove workers plant today?\n",
      "A:There are21trees now andthere are15trees inthebeginning, sothework ersplant 21-15=6trees. The\n",
      "answer is 6.\n",
      "Q:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A:There are3carsinthebeginning, 2more arrive, sonow there should be3+2=5cars. The answer is 5.\n",
      "Q:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
      "A:Leah had32choco lates andhersisterhad42,intotalthey have 32+42=74choco lates. Afterthey ate35,\n",
      "now there are74-35=39choco lates. The answer is 39.\n",
      "Q:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\n",
      "Jason give to Denny?\n",
      "A:Jasonstarted with 20lollipops, butnow heonly has12,sohegave Denny 20-12=8lollipops. The answer\n",
      "is 8.\n",
      "Q:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\n",
      "have now?\n",
      "A:Shawn got2toys each from hismom anddad, sohegot2*2=4more, now hewillhave 5+4=9toys. The\n",
      "answer is 9.\n",
      "Q:There were nine computers in the server room. Five more computers were installed each day, from monday\n",
      "to thursday. How many computers are now in the server room?\n",
      "A:5computerswere installed from mondaytothurs day, sointotal5*4=20computersareinstalled. 9\n",
      "computersarethere inthebeginning, sonow there are20+9=29computers. The answer is 29.\n",
      "Q:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\n",
      "balls did he have at the end of wednesday?\n",
      "A:Michael started with 58golfballs andlost23,sohehas58-23=35.Afterhelost2more, hehas35-2=33\n",
      "balls now. The answer is 33.\n",
      "Q:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\n",
      "A:5bagels for$3each should cost5*3=15dollars. Olivia had$23inthebeginning, sonow shehas23-15=\n",
      "8dollarsleft. The answer is 8.\n",
      "42\n",
      "Table 30: Few-shot exemplars for full chain of thought prompt for math word problems. These\n",
      "exemplars are the same as in Table 20, except that the chains of thought were written by a different\n",
      "annotator (“Annotator C” instead of “Annotator A”).\n",
      "PROMPT FOR MATH WORD PROBLEMS\n",
      "Q:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\n",
      "will be 21 trees. How many trees did the grove workers plant today?\n",
      "A:Westart with 15trees. Later wehave 21trees. Thedifference must bethenumberoftrees they planted. So,\n",
      "they must have planted 21-15=6trees. The answer is 6.\n",
      "Q:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A:There are3carsintheparkinglotalready. 2more arrive. Now there are3+2=5cars. The answer is 5.\n",
      "Q:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
      "A:Leah had32choco lates andLeah’s sisterhad42.That means there were originally 32+42=74choco lates.\n",
      "35have been eaten. Sointotalthey stillhave 74-35=39choco lates. The answer is 39.\n",
      "Q:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\n",
      "Jason give to Denny?\n",
      "A:Jasonhad20lollipops. Since heonly has12now, hemust have given theresttoDenny. Thenumberof\n",
      "lollipops hehasgiven toDenny must have been 20-12=8lollipops. The answer is 8.\n",
      "Q:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\n",
      "have now?\n",
      "A:Hehas5toys. Hegot2from mom, soafterthathehas5+2=7toys. Then hegot2more from dad, soin\n",
      "totalhehas7+2=9toys. The answer is 9.\n",
      "Q:There were nine computers in the server room. Five more computers were installed each day, from monday\n",
      "to thursday. How many computers are now in the server room?\n",
      "A:There are4days from mondaytothurs day.5computerswere added each day.That means intotal4*5=20\n",
      "computerswere added. There were 9computersinthebeginning, sonow there are9+20=29computers. The\n",
      "answer is 29.\n",
      "Q:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\n",
      "balls did he have at the end of wednesday?\n",
      "A:Michael initially had58balls. Helost23onTues day, soafterthathehas58-23=35balls. OnWednes day\n",
      "helost2more sonow hehas35-2=33balls. The answer is 33.\n",
      "Q:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\n",
      "A:Shebought 5bagels for$3each. This means shespent 5*$3=$15onthebagels. Shehad$23inbeginning,\n",
      "sonow shehas$23-$15=$8. The answer is 8.\n",
      "43\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "SKELETON -OF-THOUGHT : L ARGE LANGUAGE MOD-\n",
      "ELSCANDOPARALLEL DECODING\n",
      "Xuefei Ning1∗\n",
      "foxdoraame@gmail.comZinan Lin2∗\n",
      "linzinan1995@gmail.com\n",
      "Zixuan Zhou1∗\n",
      "zhouzx21@mails.tsinghua.edu.cnZifu Wang3\n",
      "zifu.wang@kuleuven.be\n",
      "Huazhong Yang1\n",
      "yanghz@tsinghua.edu.cnYu Wang1\n",
      "yu-wang@tsinghua.edu.cn\n",
      "1Department of Electronic Engineering, Tsinghua University, Beijing, China\n",
      "2Microsoft Research, Redmond, Washington, USA\n",
      "3ESAT-PSI, KU Leuven, Leuven, Belgium\n",
      "Website: https://sites.google.com/view/sot-llm\n",
      "ABSTRACT\n",
      "This work aims at decreasing the end-to-end generation latency of large language\n",
      "models (LLMs). One of the major causes of the high generation latency is the\n",
      "sequential decoding approach adopted by almost all state-of-the-art LLMs. In\n",
      "this work, motivated by the thinking and writing process of humans, we propose\n",
      "Skeleton-of-Thought (SoT) , which first guides LLMs to generate the skeleton of\n",
      "the answer, and then conducts parallel API calls or batched decoding to com-\n",
      "plete the contents of each skeleton point in parallel . Not only does SoT provide\n",
      "considerable speed-ups across 12 LLMs, but it can also potentially improve the\n",
      "answer quality on several question categories. SoT is an initial attempt at data-\n",
      "centric optimization for inference efficiency, and further underscores the potential\n",
      "of pushing LLMs to think more like a human for answer quality.\n",
      "1 I NTRODUCTION\n",
      "Large language models (LLMs) (Brown et al., 2020; Touvron et al., 2023a; Du et al., 2022; OpenAI,\n",
      "2023; Zheng et al., 2023) have shown exceptional performance in natural language processing and\n",
      "chatbot systems. However, the inference process of the state-of-the-art LLMs is slow, hindering their\n",
      "interactive use. For example, it takes 22 seconds for Claude (Anthropic, 2023) (accessed through\n",
      "Slack API) and 43 seconds for Vicuna-33B V1.3 (a 33B LLaMA-based model, running locally on\n",
      "one NVIDIA A100 GPU) to answer the question in Fig. 1.\n",
      "We conclude three major causes of LLMs’ slow inference: (1) A large model size requires a large\n",
      "amount of memory, memory access, and computation. For example, the FP16 weights of 175B GPT-\n",
      "3 take 350GB memory, which means at least 5 ×80GB A100 GPUs are needed to keep the model\n",
      "in GPU memory. Even with enough GPUs, the heavy memory access and computation slow down\n",
      "the inference. (2) The attention operation in the prevailing transformer architecture is I/O bounded\n",
      "and has a quadratic memory and computation complexity in sequence length. (3) The sequential\n",
      "decoding approach in inference generates tokens one by one. This approach introduces a significant\n",
      "∗Equal contribution.\n",
      "†The main updates in arXiv V2 are as follows: (1) Add the quality and efficiency evaluation of SoT on\n",
      "GPT-4. (2) Use GPT-4 as the judge for answer quality evaluation. The old results with ChatGPT-3.5 as the\n",
      "judge are moved to App. I.3. (3) Add the SoT with Router (SoT-R) method (§ 4) which adaptively triggers SoT\n",
      "on suitable questions. (4) Move detailed answer analysis to the appendices.\n",
      "1arXiv:2307.15337v2  [cs.CL]  8 Oct 2023\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Answer1.Active listening involves fully concentrating on …2.Identify issues. Look into the root causes of …3.Compromise. Look for a middle ground …What are the most effective strategies for conflict resolution in the workplace?QuestionSkeleton-of-Thought Decoding\n",
      "Generatesanswerssequentially ➔SlowerNormal Decoding1. Active listening2. Identify issues3. CompromiseGeneratesanswersinparallel➔Faster(1)Skeletonstage(2)Point-expandingstage\n",
      "1.0 1.2 1.4 1.6 1.8\n",
      "Speed-up−0.20.00.20.4Net win ratesVicuna-13B V1.3StableVicuna-13B\n",
      "UltraLM-13B\n",
      "Vicuna-33B V1.3\n",
      "LLaMA2-Chat-7B\n",
      "LLaMA2-Chat-13BVicuna-7B V1.3ChatGPT-3.5\n",
      "Claude\n",
      "Vicuna-7B V1.1OpenChat-13BGPT-4\n",
      "Baseline\n",
      "Figure 1: Left: An illustration of Skeleton-of-Thought (SoT). Instead of producing answers se-\n",
      "quentially, SoT produces different parts of answers in parallel . In more detail, given the question,\n",
      "SoT first prompts the LLM to give out the skeleton, then conducts batched decoding or parallel API\n",
      "calls to expand multiple points in parallel, and finally aggregates the outputs to get the final answer.\n",
      "Right: The net win rates and speed-ups of SoT with router (SoT-R) compared to normal generation\n",
      "on Vicuna-80. The net win rate is the difference between the fraction of questions that SoT-R has\n",
      "better and worse answers than normal generation. The speed-up is the ratio between the latency\n",
      "of normal and SoT-R generation. (1.0,0.0)represents normal generation. Higher is better on both\n",
      "axes. For most models, SoT-R not only accelerates the generation but also improves the quality of\n",
      "the answers (evaluated with FastChat metric (Zheng et al., 2023)). See § 3.2 and 4 for more details.\n",
      "inference latency since the generation of tokens cannot be parallelized. There is a bunch of literature\n",
      "addressing the first two axes: large model size (Xiao et al., 2022; Frantar et al., 2022; Lin et al., 2023;\n",
      "Sheng et al., 2023; Wang et al., 2021) and attention operation (Kitaev et al., 2020; Wang et al., 2020;\n",
      "Dao et al., 2022; Zaheer et al., 2020; Chen et al., 2023b). These works either compress/redesign the\n",
      "model (Xiao et al., 2022; Frantar et al., 2022; Lin et al., 2023; Kitaev et al., 2020; Wang et al., 2020;\n",
      "Dao et al., 2022; Zaheer et al., 2020) or redesign the serving system (Sheng et al., 2023; Chen et al.,\n",
      "2023b) and hardware (Wang et al., 2021).\n",
      "In contrast to prior work, we tackle the third axis and question the common assumption that LLMs\n",
      "have to do fully sequential decoding. We show the feasibility of parallel decoding of off-the-shelf\n",
      "LLMs without any changes to their model, system, or hardware . For instance, for the question\n",
      "in Fig. 1, we can reduce the latency from 22 seconds to 12 seconds (1.83 ×speed-up) with Claude,\n",
      "and from 43 seconds to 16 seconds (2.69 ×speed-up) with Vicuna-33B V1.3 on an NVIDIA A100.\n",
      "The idea stems from reflecting on how humans ourselves answer questions. Humans do notalways\n",
      "think about questions and write answers in a sequential fashion. In contrast, for many question\n",
      "types, we first derive the skeleton according to some protocols and strategies, and then add evidence\n",
      "and details to refine and explicate each point. This is especially the case on formal occasions like\n",
      "offering consultancy, taking tests, writing papers, and so on. Can we make LLMs think in the same\n",
      "way? To this end, we propose Skeleton-of-Thought (SoT) . Specifically, as shown in Fig. 1, we guide\n",
      "the LLM to derive a skeleton first by itself. Based on the skeleton, the LLMs can complete each\n",
      "point in parallel so that we get a speed-up. SoT can be utilized to accelerate both open-source\n",
      "models with batched decoding and API-based models with parallel API calls.\n",
      "To make the overall solution more practical, we also design an extension, SoT with router (SoT-R),\n",
      "which employs a router to only trigger SoT for suitable questions.\n",
      "We test SoT on 12 recently released LLMs. Not only does SoT provide considerable speed-ups (up\n",
      "to 2.39 ×), but it can also improve the answer quality in many cases (Fig. 1).\n",
      "Note that in contrast to existing model- and system-level efforts for inference efficiency, SoT takes\n",
      "a novel “data-level” pathway by letting the LLM organize its output content. This novel perspective\n",
      "is becoming feasible and is expected to grow in relevance, owing to the evolving capabilities of\n",
      "state-of-the-art LLMs. We hope this work can stimulate more research in the realm of data-centric\n",
      "optimization (Zha et al., 2023; HazyResearch, 2023) for efficiency.\n",
      "2\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Prompt 1. Skeleton Prompt Template Ts\n",
      "[User:] You’re an organizer responsible for only giving the skeleton (not the full content) for answering the question.\n",
      "Provide the skeleton in a list of points (numbered 1., 2., 3., etc.) to answer the question. Instead of writing a full sentence,\n",
      "each skeleton point should be very short with only 3 ∼5 words. Generally, the skeleton should have 3 ∼10 points. Now,\n",
      "please provide the skeleton for the following question.\n",
      "{question }\n",
      "Skeleton:\n",
      "[Assistant:] 1.\n",
      "Prompt 2. Point-Expanding Prompt Template Tpe\n",
      "[User:] You’re responsible for continuing the writing of one and only one point in the overall answer to the following\n",
      "question.\n",
      "{question }\n",
      "The skeleton of the answer is\n",
      "{skeleton }\n",
      "Continue and only continue the writing of point {point index }. Write it **very shortly** in 1 ∼2 sentence and\n",
      "do not continue with other points!\n",
      "[Assistant:] {point index }.{point skeleton }\n",
      "The rest of the paper is organized as follows. We first introduce SoT in § 2 and show its results in\n",
      "§ 3. Then, we expand on the SoT-R extension in § 4. § 5 positions SoT in the research ecosystem\n",
      "(expanded in App. D). Finally, we analyze the limitations and share outlooks of SoT in § 6.\n",
      "2 S KELETON -OF-THOUGHT (SOT)\n",
      "2.1 M ETHOD\n",
      "Overview. Based on the intuition that humans usually think about and answer a question in an\n",
      "organized way, the core idea of this work is to guide the LLM itself to give a skeleton first and then\n",
      "write the overall answer parallelly instead of sequentially. Fig. 1 illustrates how SoT produces the\n",
      "final answer to a user question q.\n",
      "(1) Skeleton stage. SoT first assembles a skeleton request ,Ts(question =q), using the skeleton\n",
      "prompt template Ts(Prompt 1, and Prompt 3 in App. B.1) with the question qas the parameter. The\n",
      "skeleton prompt template is written to guide the LLM to output a concise skeleton of the answer.\n",
      "Then, we extract the Bpoints from the skeleton response Rsof the LLM.\n",
      "(2) Point-expanding stage. Based on the skeleton, we let the LLM expand on each point in parallel.\n",
      "Specifically, for the point with index band skeleton Rs\n",
      "b, SoT uses Tpe(question =q,skeleton =\n",
      "Rs,point index =b,point skeleton =Rs\n",
      "b)as the point-expanding request for the LLM, where\n",
      "Tpeis the point-expanding prompt template (Prompt 2). Finally, after completing all points, we\n",
      "concatenate the point-expanding responses {Rpe\n",
      "b}b=1,···,Bto get the final answer .\n",
      "Parallel point expanding. We conduct parallel point-expanding so that SoT is able to achieve a\n",
      "speed-up than normal decoding.\n",
      "(1) For proprietary models with only API access , we can issue multiple parallel API calls to get an\n",
      "end-to-end latency gain at the cost of an increased number of API requests and tokens.\n",
      "(2) For open-source models that we can run locally , we let them process the point-expanding re-\n",
      "quests as a batch (paddings are added to the left of the point-expanding requests). We explain below\n",
      "why this could achieve speed-ups. A typical LLM generative process consists of two phases: (a)\n",
      "theprefilling phase in which the prompt is parsed to generate the key-value cache for further use,\n",
      "and (b) the decoding phase in which tokens are generated one by one in a sequential manner. The\n",
      "decoding phase accounts for the majority of the end-to-end latency, especially when generating a\n",
      "long response. Note that the decoding phase is bottlenecked by weight loading instead of activation\n",
      "3\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "loading or computation.1Consequently, running LLM inference with increased batch sizes does not\n",
      "increase the per-token latency much. Therefore, SoT allows us to decode roughly B×more tokens\n",
      "within the same amount of time if we parallelly decode Bpoints. See App. E for the expanded\n",
      "discussions and the supporting experiments.\n",
      "Please refer to App. B for more implementation details of SoT.\n",
      "3 S OT E VALUATION\n",
      "Datasets. We evaluate SoT on two recent assistant-style datasets: (1) Vicuna-80 (Chiang et al.,\n",
      "2023), which contains 80 questions spanning nine categories, such as coding ,math ,writing ,role-\n",
      "play, and so on, and (2) WizardLM (Xu et al., 2023), which contains 218 questions spanning more\n",
      "categories and diverse difficulties. Due to space constraints, we only report Vicuna-80 results in the\n",
      "main paper, and defer WizardLM results to the Apps. G and I.\n",
      "Models. We test SoT on 12 recently released models, including 9 open-source models and 3 API-\n",
      "based models (Table 1). We obtain the weights of all the open-source models from Hugging Face.\n",
      "See App. A for more details.\n",
      "3.1 E VALUATION OF EFFICIENCY\n",
      "API-based models. We record the latency of every API call with\n",
      "start = time.time(); ...; elapsed_time = time.time() - start , and\n",
      "add the latency of the skeleton API call and the slowest point-expanding API call as the SoT latency.\n",
      "Open-source models. All open-source models we currently evaluate are based on the LLaMA 7B,\n",
      "13B, or 33B architectures. Thus, to enable fast analysis, we first make a latency profiling table for\n",
      "each LLaMA architecture on NVIDIA A100. The table contains the architecture’s (1) latency for\n",
      "prefilling sequences of length 1 to 700 with different batch sizes (from 1 to 16), and (2) decoding\n",
      "one token with a context of length 1 to 1024 with different batch sizes (from 1 to 16). With these\n",
      "three latency profiling tables, given the number of points B, the token lengths of the requests and\n",
      "responses in the skeleton and point-expanding stages, we can quickly estimate the SoT latency\n",
      "by simply looking up entries in the tables and adding them up. See App. F for a more detailed\n",
      "description of how we conduct the profiling and estimate the latency.\n",
      "In addition to the above approach, we also compare the actual latency of SoT and normal sequential\n",
      "generation (abbreviated as “normal” in the following discussion) in App. G.1.4.\n",
      "The rest of this section shows the speed-ups of SoT on different models (§ 3.1.1) and question\n",
      "categories (§ 3.1.2). In addition, we also report the latency breakdown of SoT stages in App. G.1.2\n",
      "and the SoT speed-ups on an RTX 3090 GPU in App. G.1.3.\n",
      "3.1.1 S PEED -UPBREAKDOWN : M ODELS\n",
      "We investigate how SoT reduces the end-to-end latency on different models. Fig. 2a shows the\n",
      "average speed-up for each model across all question categories. We can see that SoT obtains a >2×\n",
      "speed-up (up to 2.39 ×) on 8 out of 12 models.\n",
      "We report the detailed statistics about token lengths and numbers of points in Fig. 11. (1) In terms\n",
      "ofthe point number B(Fig. 11a), LLaMA2, Vicuna-7B V1.1, Vicuna-7B V1.3, and ChatGPT-3.5\n",
      "yield relatively fewer points ( <6), while GPT-4 and StableVicuna-13B generates the largest number\n",
      "of points on average ( ≈9). (2) Regarding the point-expanding response length , Figs. 11b to 11d\n",
      "show that the API-based models, ChatGPT-3.5, Claude, and GPT-4, follow the point-expanding\n",
      "request better and generate shorter point-expanding responses than the open-source models. One\n",
      "can also notice that StableVicuna-13B’s longest point-expanding responses for many question cat-\n",
      "egories can be as lengthy as the overall normal answer, since it fails to adhere to the “Write it\n",
      "**very shortly**” instruction in the point-expanding request. Consequently, SoT cannot accelerate\n",
      "StableVicuna-13B well. (3) Regarding the length balance degree between point responses , Fig. 11e\n",
      "shows that LLaMA2 and the API-based models generate more balanced point-expanding responses.\n",
      "1This is true when the number of concurrent queries is small; see § 6 for discussion on other scenarios.\n",
      "4\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "(4) As for the overall length of the final aggregated answer (Fig. 11f), employing SoT on most\n",
      "models results in answers that are, on average, 1 ∼2×longer than the normal answer.\n",
      "1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8StableVicuna-13BClaudeVicuna-13B V1.3ChatGPT-3.5GPT-4Vicuna-7B V1.3UltraLM-13BVicuna-33B V1.3OpenChat-13BVicuna-7B V1.1LLaMA2-Chat-13BLLaMA2-Chat-7B\n",
      "1.13×1.31×1.91×1.97×2.00×2.01×2.18×2.24×2.28×2.30×2.38×2.39×\n",
      "(a) Different models.\n",
      "1.01.21.41.61.82.02.22.42.62.8mathfermicounterfactualroleplaycodingcommon-sensewritinggenericknowledge\n",
      "1.34×1.69×1.89×1.95×2.06×2.24×2.26×2.31×2.33× (b) Different categories.\n",
      "Figure 2: Average speed-ups of SoT on different models and question categories.\n",
      "3.1.2 S PEED -UPBREAKDOWN : QUESTION CATEGORIES\n",
      "Here we investigate how SoT reduces the end-to-end latency for different question categories.\n",
      "Fig. 2b shows the average speed-up for each question category across all models. The question\n",
      "categories for which SoT can provide high-quality answers are marked in green, and other cate-\n",
      "gories are marked in red (see § 3.2.3 for the answer quality evaluation). We can see that SoT can\n",
      "obtain speed-ups for all question categories. For the five question categories that SoT can provide\n",
      "high-quality answers (i.e., knowledge ,generic ,common-sense ,roleplay ,counterfactual ), SoT can\n",
      "speed up the overall answer generation process by 1.89 ×to 2.33 ×in the meantime.\n",
      "3.2 E VALUATION OF ANSWER QUALITY\n",
      "In order to compare the answer quality of the normal sequential generation (abbreviated as “normal”\n",
      "in the following discussion) and SoT generation, we adopt two LLM-based evaluation frameworks:\n",
      "FastChat (Zheng et al., 2023) and LLMZoo (Chen et al., 2023c). The evaluation process is to present\n",
      "a question and a pair of answers (from normal or SoT generation) to an LLM judge (GPT-4 in the\n",
      "main paper; see App. I.3 for the results evaluated using ChatGPT-3.5) and ask for its preference.\n",
      "The response can be that SoT’s answer wins/ties/loses compared to the normal answer.\n",
      "Here are more details about the evaluation of the answer quality:\n",
      "(1) Detailed metrics. FastChat evaluation provides one metric for the general quality of the answers.\n",
      "In addition to a general metric, LLMZoo provides five detailed metrics on the answers’ coherence,\n",
      "diversity, immersion, integrity, and relevance.\n",
      "(2) Question categories. FastChat provides two special evaluation prompts for coding and math\n",
      "questions for more accurate evaluation, whereas LLMZoo does not. Following the implementation\n",
      "in LLMZoo, we exclude math and coding questions in all LLMZoo evaluation results.\n",
      "(3) Extentions to avoid evaluation bias. To avoid the potential bias from the order of the two answers\n",
      "presented to the LLM judge, we extend FastChat and LLMZoo evaluation frameworks by running\n",
      "the evaluation twice with either ordering of the two answers. In either evaluation, a score of 1,\n",
      "0, and -1 is assigned when SoT wins, ties, or loses, respectively. The final evaluation is that SoT\n",
      "wins/ties/loses when the sum of the two scores is positive/zero/negative. For example, if SoT wins\n",
      "in one evaluation and loses in the other evaluation, the result is “tie”. If SoT wins (loses) in one\n",
      "evaluation and ties in the other, the result is “win” (“lose”).\n",
      "(4) Net win rates. We further define net win rates to give a summarized view of the answer quality.\n",
      "Given the number of questions that SoT wins (#win) and loses (#lose), we define net win rates\n",
      "as#win−#lose/total number of questions . 0% means that SoT performs competitively to the normal baseline\n",
      "(wins and loses in the same number of questions). Higher values mean that SoT performs better.\n",
      "The organization of this section on answer quality evaluation is as follows. We first present the over-\n",
      "all quality of SoT answers (§ 3.2.1), and then go into the details across different question categories\n",
      "(§ 3.2.3), models (§ 3.2.2), and metrics (§ 3.2.4).\n",
      "5\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "3.2.1 O VERALL QUALITY\n",
      "In Fig. 3, we show the win/tie/lose rates (the percentage of the cases when SoT wins/ties/loses\n",
      "compared to normal generation) across all models and questions using the two metrics from FastChat\n",
      "and LLMZoo that capture the general quality of the answers. We notice a discrepancy between the\n",
      "two metrics on when SoT is strictly better than the baseline (45.8% v.s. 29.5%). Despite that, the\n",
      "two metrics agree that SoT is not worse than the baseline in around 60% of the cases, and the win\n",
      "rates are close to the lose rates. This result suggests that the answers of SoT maintain good quality\n",
      "of that of the normal generation.\n",
      "0% 20% 40% 60% 80% 100%General quality (LLMZoo)General quality (FastChat)\n",
      "45.8%29.5%\n",
      "19.6%29.3%\n",
      "34.5%41.2%Win Tie Lose\n",
      "Figure 3: Win/tie/lose rates of SoT v.s. normal generation using “general” metrics from FastChat\n",
      "and LLMZoo. SoT performs better than or equal to normal generation in around 60% cases.\n",
      "3.2.2 Q UALITY BREAKDOWN : M ODELS\n",
      "Next, we investigate how SoT performs on different models. We compute net win rates on all\n",
      "models in Fig. 4. Again, we see that the two general metrics from FastChat and LLMZoo have\n",
      "different absolute values but similar rankings. In particular, both metrics agree that OpenChat-13B,\n",
      "Vicuna-7B V1.1, Claude, LLaMA2-Chat-13B have lownet win rates, whereas Vicuna-13B V1.3,\n",
      "StableVicuna-13B, and UltraLM-13B have high net win rates.\n",
      "-60% -40% -20% 0% 20%StableVicuna-13BUltraLM-13BVicuna-13B V1.3GPT-4LLaMA2-Chat-7BVicuna-33B V1.3Vicuna-7B V1.3ChatGPT-3.5LLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.1Claude\n",
      "(a) Metric: general quality (FastChat).\n",
      "-40% -20% 0% 20% 40% 60%StableVicuna-13BUltraLM-13BVicuna-13B V1.3GPT-4LLaMA2-Chat-7BVicuna-33B V1.3Vicuna-7B V1.3ChatGPT-3.5LLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.1Claude (b) Metric: general quality (LLMZoo).\n",
      "Figure 4: Net win rates of SoT on different models.\n",
      "We investigate the answers in App. I.1.1, and summarize the key takeaways as follows. Some\n",
      "models have low SoT quality as they cannot understand the skeleton and point-expanding prompts\n",
      "well. Some other models have low SoT quality as their normal answers already have good quality,\n",
      "making it hard for SoT to beat them (e.g., Claude). For models that are able to understand the\n",
      "SoT prompts, the answer quality is improved. We expect that further improving SoT prompts or\n",
      "fine-tuning the models can make it easier for LLMs to understand the skeleton and point-expanding\n",
      "prompts and ultimately result in better answer quality.\n",
      "3.2.3 Q UALITY BREAKDOWN : QUESTION CATEGORIES\n",
      "Next, we investigate how SoT performs on different question categories. We compute net win rates\n",
      "(win rates minus lose rates) on all question categories in Fig. 5. Similar to Fig. 3, we see that\n",
      "LLMZoo tends to be more optimistic about the quality of SoT than FastChat. Nevertheless, the\n",
      "conclusions are consistent: SoT performs relatively well ongeneric ,common-sense ,knowledge ,\n",
      "roleplay , and counterfactual . SoT performs relatively poorly onwriting ,fermi ,math , and coding .\n",
      "We investigate the answers in App. I.1.2, and summarize the key takeaways as follows. SoT per-\n",
      "forms well when the question can be answered in several points whose details can be expanded\n",
      "independently. This includes a wide range of real-world questions. On the other hand, it is fun-\n",
      "damentally challenging to apply SoT on questions that require step-by-step thinking, in which the\n",
      "6\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "-80% -60% -40% -20% 0% 20% 40%counterfactualgenericcommon-senseknowledgeroleplayfermiwritingmathcoding\n",
      "(a) Metric: general quality (FastChat).\n",
      "-20% 0% 20% 40% 60%counterfactualgenericcommon-senseknowledgeroleplayfermiwriting (b) Metric: general quality (LLMZoo).\n",
      "Figure 5: Net win rates of SoT on different question categories.\n",
      "latter steps require the details from the earlier steps, such as math questions. To make SoT general\n",
      "across broader question categories, one promising pathway is to enable SoT to adaptively fall back\n",
      "to normal generation, which we explore in § 4. Interestingly, our results suggest that some LLMs\n",
      "are already able to do that occasionally without special prompting or tuning (see App. I.1.2).\n",
      "3.2.4 Q UALITY BREAKDOWN : M ETRICS\n",
      "All previous evaluations use metrics about the general quality of the answer. In Fig. 6, we show\n",
      "more detailed metrics from LLMZoo to reveal in which aspects SoT can improve or hurt the answer\n",
      "quality. On average, we can see that SoT improves the diversity and relevance while hurting the\n",
      "immersion and coherence.\n",
      "0% 20% 40% 60% 80% 100%IntegrityCoherenceImmersionRelevanceDiversity\n",
      "23.2%29.8%40.5%61.4%\n",
      "99.9%34.6%30.6%23.7%11.3%\n",
      "0.1%42.1%39.6%35.8%27.3%Win Tie Lose\n",
      "Figure 6: Win/tie/lose rates of SoT v.s. normal generations using metrics from LLMZoo. SoT\n",
      "performs well on diversity and relevance, and relatively worse on coherence and immersion.\n",
      "Through answer investigation (App. I.1.3), we summarize the key takeaways as follows. The skele-\n",
      "ton stage of SoT explicitly require LLMs to discuss the answers from multiple aspects without filler\n",
      "words. This improves the diversity and relevance of the answers. As for coherence and immersion,\n",
      "SoT is not worse than the normal generation around 60% of the time. One future direction is to\n",
      "improve the SoT prompts or pipeline so that the answers can be better in more metrics.\n",
      "4 S OTWITH ROUTER (SOT-R): A DAPATIVELY TRIGGERING SOT\n",
      "In § 3, we see that SoT provides considerable speed-ups while maintaining (or even improving)\n",
      "answer quality for many question types. However, the biggest limitation is that SoT is not suitable\n",
      "for questions that require step-by-step reasoning (§ 3.2.3). Towards pushing the practical adoption\n",
      "of SoT, we explore the possibility of adaptively triggering SoT only when it is suitable. To achieve\n",
      "that, we propose a router module that decides if SoT should be applied for the user request, and\n",
      "then call either SoT or normal decoding accordingly. This paradigm aligns with the recent trends\n",
      "of composing multiple models to solve complicated tasks (Chase, 2022; Shen et al., 2023). To\n",
      "implement the router, we explore two options: LLM prompting as the router (no model training is\n",
      "needed) (§ 4.1), and trained RoBERTa as the router (§ 4.2). The evaluation is provided in § 4.3.\n",
      "4.1 P ROMPTING ROUTER\n",
      "We directly ask an LLM if the question is suitable for SoT. More specifically, we ask the LLM if the\n",
      "desired answer is in a list of independent points (see App. C.1 for the prompt). If the answer is yes,\n",
      "7\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "we will use SoT; otherwise, we will use normal generation (i.e., directly feeding the question to the\n",
      "LLM). We employ GPT-4 as the LLM router given its strong capability.\n",
      "4.2 T RAINED ROUTER\n",
      "While leveraging GPT-4 as the router obviates the need for model training, its performance remains\n",
      "sensitive to prompt design. Therefore, we approach the problem as a sequence classification task by\n",
      "fine-tuning a small language model as the router. Specifically, we annotate the LIMA dataset (Zhou\n",
      "et al., 2023) as the training set to train a RoBERTa model (Liu et al., 2019), which has only 120M\n",
      "parameters. Comprehensive details regarding the annotation and training processes can be found in\n",
      "Apps. C.2.1 and C.2.2, respectively.\n",
      "4.3 S OT-R E VALUATION\n",
      "We compare SoT and SoT-R under the same evaluation setup in § 3. Besides the prompting and\n",
      "trained routers, we also consider a “human router” where we manually judge whether SoT should\n",
      "be applied for each question. This serves as a benchmark for comparison.\n",
      "4.3.1 E VALUATION OF EFFICIENCY\n",
      "Fig. 7 shows the speed-ups of SoT and SoT-R for different models on the Vicuna-80 dataset (see\n",
      "App. G.2 for more results on the WizardLM dataset). We can see that: (1) As expected, SoT-R\n",
      "obtains lower speed-ups than SoT, since SoT is not triggered for some questions and the router\n",
      "induces a small latency overhead. Nevertheless, SoT-R can still benefit most models with >1×\n",
      "speed-ups. (2) SoT-R with the trained router obtains slightly higher speed-ups for 7 out of 12 models\n",
      "on Vicuna-80, while SoT-R with the prompting router obtains higher speed-ups for all models on\n",
      "the WizardLM dataset (see Fig. 17 in App. G.2).\n",
      "1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75StableVicuna-13BClaudeVicuna-13B V1.3ChatGPT-3.5GPT-4Vicuna-7B V1.3UltraLM-13BVicuna-33B V1.3OpenChat-13BVicuna-7B V1.1LLaMA2-Chat-13BLLaMA2-Chat-7B\n",
      "SoT (w/o router)\n",
      "SoT-R w/ prompting router\n",
      "SoT-R w/ trained router\n",
      "Figure 7: Speed-ups of SoT and SoT-R on dif-\n",
      "ferent models across all question categories of\n",
      "the Vicuna-80 dataset.\n",
      "-80% -60% -40% -20% 0% 20% 40%counterfactualgenericcommon-senseknowledgeroleplayfermiwritingmathcoding\n",
      "SoT (w/o router)\n",
      "SoT-R w/ prompting router\n",
      "SoT-R w/ trained router\n",
      "SoT-R w/ human routerFigure 8: Net win rates of SoT and SoT-R on\n",
      "different question categories of the Vicuna-80\n",
      "dataset (evaluated with the FastChat metrics).\n",
      "4.3.2 E VALUATION OF ANSWER QUALITY\n",
      "Fig. 8 shows the net win rates (averaged across all models) of SoT and SoT-R on Vicuna-80 with the\n",
      "FastChat metrics (see App. I.2 for results of the WizardLM dataset and LLMZoo metrics). We can\n",
      "see that: (1) SoT-R significantly improves the answer quality on questions where SoT is not suitable\n",
      "(e.g., coding ,math ,writing ,fermi ) by falling back to normal decoding. At the same time, SoT-R\n",
      "maintains answer quality improvements on questions where SoT is good at. (2) The trained router\n",
      "performs similar to (on Vicuna-80) or better than (on WizardLM; see App. I.2) the prompting router.\n",
      "This accords with our intuition in § 4.2. (3) The prompting and trained routers could even surpass\n",
      "human router (e.g., on roleplay questions; see more examples on WizardLM in App. I.2).\n",
      "We discuss the consistency across three routers in App. C.3. The primary takeaways include: (1)\n",
      "on Vicuna-80, there is a notable consistency among all three routers, and (2) on WizardLM, greater\n",
      "discrepancies emerge, with the trained router showing higher alignment with human annotations.\n",
      "5 R ELATED WORK\n",
      "This section positions SoT in related work to reveal how SoT (1) is connected to, (2) is different\n",
      "from, and (3) can harness the power of other methods. See App. D for the expanded discussion.\n",
      "Efficient LLM methods at model and system levels. At the model level, prior work proposes ef-\n",
      "ficient architectures, including dynamic mixture-of-experts (Lepikhin et al., 2021), low-complexity\n",
      "8\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "attention (Kitaev et al., 2020), and multi-query attention (Shazeer, 2019). However, they usually\n",
      "require a significant re-training cost. In contrast, compression methods require a smaller amount\n",
      "of fine-tuning cost by reducing the complexity of pre-trained LLMs, such as quantization (Frantar\n",
      "et al., 2022) and weight or activation sparsification (Mishra et al., 2021; Zaheer et al., 2020).\n",
      "At the system level, prior work (1) optimizes the computational graph (Dao et al., 2022), (2) op-\n",
      "timizes the assignment and scheduling of computational graph on devices (Sheng et al., 2023), or\n",
      "(3) designs batching or caching mechanisms for serving multiple users (Fang et al., 2021). These\n",
      "techniques address the large memory access and footprint posed by the vast model scale and atten-\n",
      "tion mechanism, and mainly aim at enhancing the throughput rather than the end-to-end latency.\n",
      "As SoT trades off throughput for end-to-end latency, SoT can make these throughput-oriented tech-\n",
      "niques help with end-to-end latency . This interesting synergy offers opportunities for achieving\n",
      "better trade-offs between latency and throughput in future serving systems.\n",
      "In contrast to model- and system-level techniques, SoT is a data-level technique in a new “content\n",
      "co-organization for efficiency” paradigm . See § 6 for more discussions.\n",
      "Efficient LLM methods through parallel generation. Some prior work also addresses the sequen-\n",
      "tial decoding issues. Speculative decoding (SD) methods (Stern et al., 2018) employ smaller models\n",
      "to generate some consecutive tokens sequentially and apply the target LLMs to verify them paral-\n",
      "lelly. Non-autoregressive generation (NAG) methods (Gu et al., 2018; Xiao et al., 2023) sample and\n",
      "refine consecutive tokens parallelly, often with the support of a modified and tuned model.\n",
      "Relying on either assisting models or special models and sampling schemes, SD and NAG methods\n",
      "conduct parallel verification or sampling and refinement of consecutive tokens . In contrast, SoT\n",
      "prompts the LLM itself to plan the contents in a way that permits the parallel generation of tokens in\n",
      "different segments , by exploiting the emerging instruction-following and planning ability of LLMs.\n",
      "Prompting methods for LLMs. Recent years have witnessed the emergence of the “pre-train,\n",
      "prompt, and predict” paradigm, which has shown promise in enhancing LLMs’ quality in math and\n",
      "commonsense reasoning (Wei et al., 2022; Kojima et al., 2022; Wang et al., 2022; Chen et al., 2022)\n",
      "and planning for multi-modality tasks (Shen et al., 2023; Zhu et al., 2023). Instead of focusing on\n",
      "answer quality, SoT is a first attempt at exploiting the power of prompting to improve efficiency .\n",
      "6 L IMITATIONS , FUTURE WORK,AND OPEN QUESTIONS\n",
      "Answer quality evaluation. Our answer quality evaluation is far from perfect due to the limited\n",
      "prompt set, the potential bias of GPT-4 judges, and the inherent difficulty of evaluating LLM gener-\n",
      "ations. Currently, we did not conduct human evaluation since it is easy for a human to tell whether\n",
      "an answer is generated with SoT due to its distinctive pattern, which might cause evaluation bias.\n",
      "We leave a more thorough evaluation of answer quality to future work.\n",
      "Eliciting or improving LLMs’ ability. § 3.2.4 demonstrates SoT’s potential of enhancing answer\n",
      "quality. It is part of a broader trend in recent research, exemplified by work including CoT (Kojima\n",
      "et al., 2022; Wei et al., 2022), ToT (Yao et al., 2023), and ReAct (Yao et al., 2022), which collectively\n",
      "affirm the notion that explicitly articulating the thought process in language can elicit high-quality\n",
      "answers from LLMs . These findings resemble human thinking: rather than relying solely on the\n",
      "first intuition or purely sequential thinking, we often document step-by-step reasoning or thought\n",
      "organization to attain high-quality answers. This intriguing parallel prompts us to explore further\n",
      "how we can draw from the human thinking process to facilitate more effective and efficient AI.\n",
      "For instance, SoT currently ignores the dependencies between points. A conceptually better way is\n",
      "to organize the points as Graph-of-Thoughts , where the edges represent the dependencies, and each\n",
      "point is decoded conditioned on the contents of its ancestor points. In addition, instead of complying\n",
      "with a static graph, we expect the need of having dynamic Graph-of-Thoughts , where the high-level\n",
      "thought structure is adjusted dynamically by LLMs themselves. This could potentially combine the\n",
      "efficiency and global thinking advantages of SoT with the logical reasoning and impromptu thinking\n",
      "strengths of methods like CoT (Kojima et al., 2022; Wei et al., 2022). Notably, a contemporary\n",
      "work (Besta et al., 2023) has attempted to design Graph-of-Thoughts to elicit reasoning.\n",
      "Furthermore, there exist self-improving training pipelines (Zelikman et al., 2022; Huang et al., 2022)\n",
      "that use rationales generated by CoT to fine-tune LLMs, thereby enhancing their reasoning abilities.\n",
      "9\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Likewise, it is interesting to investigate how the more structured answers from SoT can be used to\n",
      "fine-tune LLMs to enhance their ability to generate well-organized and comprehensive answers.\n",
      "Efficiency and overhead of SoT in different scenarios. Serving systems commonly adopt batch\n",
      "processing to handle concurrent queries. This raises a concern of whether SoT may hurt serving\n",
      "throughput due to parallel requests. (1) When there is an unsaturated number of concurrent queries,\n",
      "SoT can effectively reduce latency and enhance GPU utilization. Example scenarios include (a)\n",
      "Edge-side applications with a single user; (b) Centralized services during periods with unsaturated\n",
      "user requests and underutilized computing capacity. It is interesting to study the appropriate SoT\n",
      "triggering conditions based on system workloads. (2) When there is a saturated number of concur-\n",
      "rent queries, SoT is still useful for improving answer quality. However, in this case, it is important\n",
      "to consider the computation overhead from SoT. We delve into this concern in App. H.\n",
      "For API-based models, a notable concern arises regarding the increased number of prefilling tokens\n",
      "(App. H). Given that many APIs charge token usage, SoT may lead to higher costs. To address this,\n",
      "one can tune the number of parallel API requests (by expanding multiple points in a single API call),\n",
      "or use prompt tuning to design shorter SoT prompts (see App. H).\n",
      "Data-centric efficiency optimization. While data-centric engineering for improving answer qual-\n",
      "ity(Zha et al., 2023; HazyResearch, 2023) is gaining popularity, its potential for inference efficiency\n",
      "is not explored yet. SoT is the first attempt. As LLM capabilities and the amount of LLM-generated\n",
      "data are growing rapidly, data-centric techniques could become more useful in the future. We look\n",
      "forward to more explorations to unlock the full potential of data-centric efficiency optimization.\n",
      "ACKNOWLEDGEMENTS\n",
      "We thank Sergey Yekhanin (Microsoft Research), and Tianji Wu (Infinigence AI) for their support\n",
      "and suggestions on the work. We thank Tianyu Fu for many initial discussions on the idea. We\n",
      "thank Ke Hong and Genghan Zhang for their discussions about profiling. We thank Yue Wu for the\n",
      "help on the Claude scripts. We thank Da Yu, Chulin Xie, and Saiqian Zhang for their suggestions\n",
      "on revising the first version of the paper. We thank Rui Hu, Cheng Cheng, Jack Jin, Zhoutong Ye,\n",
      "Mingze Sun, Jun Yan, Zhi Zhang, Yuxuan Tong, and Nianhui Guo for their suggestions on revising\n",
      "the second version of the paper.\n",
      "REFERENCES\n",
      "Anthropic. Introducing claude, May 2023. URL https://www.anthropic.com/index/\n",
      "introducing-claude .\n",
      "Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna\n",
      "Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, et al.\n",
      "Graph of thoughts: Solving elaborate problems with large language models. arXiv preprint\n",
      "arXiv:2308.09687 , 2023.\n",
      "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\n",
      "Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\n",
      "few-shot learners. Advances in neural information processing systems , 33:1877–1901, 2020.\n",
      "Han Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang, and Song Han. Once-for-all: Train one\n",
      "network and specialize it for efficient deployment. arXiv preprint arXiv:1908.09791 , 2019.\n",
      "Harrison Chase. LangChain, October 2022. URL https://github.com/hwchase17/\n",
      "langchain .\n",
      "Charlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste Lespiau, Laurent Sifre, and John\n",
      "Jumper. Accelerating large language model decoding with speculative sampling. arXiv preprint\n",
      "arXiv:2302.01318 , 2023a.\n",
      "Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. Program of thoughts prompt-\n",
      "ing: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint\n",
      "arXiv:2211.12588 , 2022.\n",
      "10\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Zhaodong Chen, Zheng Qu, Yuying Quan, Liu Liu, Yufei Ding, and Yuan Xie. Dynamic n: M\n",
      "fine-grained structured sparse attention mechanism. In Proceedings of the 28th ACM SIGPLAN\n",
      "Annual Symposium on Principles and Practice of Parallel Programming , pp. 369–379, 2023b.\n",
      "Zhihong Chen, Junying Chen, Hongbo Zhang, Feng Jiang, Guiming Chen, Fei Yu, Tiannan Wang,\n",
      "Juhao Liang, Chen Zhang, Zhiyi Zhang, Jianquan Li, Xiang Wan, Haizhou Li, and Benyou Wang.\n",
      "Llm zoo: democratizing chatgpt. https://github.com/FreedomIntelligence/\n",
      "LLMZoo , 2023c.\n",
      "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,\n",
      "Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An\n",
      "open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https:\n",
      "//lmsys.org/blog/2023-03-30-vicuna/ .\n",
      "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\n",
      "Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language mod-\n",
      "els.arXiv preprint arXiv:2210.11416 , 2022.\n",
      "Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher R ´e. Flashattention: Fast and memory-\n",
      "efficient exact attention with io-awareness. Advances in Neural Information Processing Systems ,\n",
      "35:16344–16359, 2022.\n",
      "Emily L Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Exploiting linear\n",
      "structure within convolutional networks for efficient evaluation. Advances in neural information\n",
      "processing systems , 27, 2014.\n",
      "Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong\n",
      "Sun, and Bowen Zhou. Enhancing chat language models by scaling high-quality instructional\n",
      "conversations. arXiv preprint arXiv:2305.14233 , 2023.\n",
      "Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. Glm:\n",
      "General language model pretraining with autoregressive blank infilling. In Proceedings of the\n",
      "60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) ,\n",
      "pp. 320–335, 2022.\n",
      "Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter. Neural architecture search: A survey. The\n",
      "Journal of Machine Learning Research , 20(1):1997–2017, 2019.\n",
      "Jiarui Fang, Yang Yu, Chengduo Zhao, and Jie Zhou. Turbotransformers: an efficient gpu serv-\n",
      "ing system for transformer models. In Proceedings of the 26th ACM SIGPLAN Symposium on\n",
      "Principles and Practice of Parallel Programming , pp. 389–402, 2021.\n",
      "William Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: Scaling to trillion parameter\n",
      "models with simple and efficient sparsity. The Journal of Machine Learning Research , 23(1):\n",
      "5232–5270, 2022.\n",
      "Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. Gptq: Accurate post-training\n",
      "quantization for generative pre-trained transformers. arXiv preprint arXiv:2210.17323 , 2022.\n",
      "Prakhar Ganesh, Yao Chen, Xin Lou, Mohammad Ali Khan, Yin Yang, Hassan Sajjad, Preslav\n",
      "Nakov, Deming Chen, and Marianne Winslett. Compressing large-scale transformer-based mod-\n",
      "els: A case study on bert. Transactions of the Association for Computational Linguistics , 9:\n",
      "1061–1080, 2021.\n",
      "Joao Gante. Assisted generation: a new direction toward low-latency text generation. https:\n",
      "//huggingface.co/blog/assisted-generation , 2023. Accessed: 2023-06-23.\n",
      "Google. Tensorflow serving, 2021. URL https://github.com/tensorflow/serving .\n",
      "Jiatao Gu, James Bradbury, Caiming Xiong, Victor O.K. Li, and Richard Socher. Non-autoregressive\n",
      "neural machine translation. In International Conference on Learning Representations , 2018. URL\n",
      "https://openreview.net/forum?id=B1l8BtlCb .\n",
      "11\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks\n",
      "with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149 , 2015.\n",
      "HazyResearch. Data-centric ai. https://github.com/HazyResearch/\n",
      "data-centric-ai , 2023. Accessed: 2023-07-04.\n",
      "Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei\n",
      "Han. Large language models can self-improve. arXiv preprint arXiv:2210.11610 , 2022.\n",
      "Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Dehao Chen, Mia Chen, HyoukJoong\n",
      "Lee, Jiquan Ngiam, Quoc V Le, Yonghui Wu, et al. Gpipe: Efficient training of giant neural\n",
      "networks using pipeline parallelism. Advances in neural information processing systems , 32,\n",
      "2019.\n",
      "Andrei Ivanov, Nikoli Dryden, Tal Ben-Nun, Shigang Li, and Torsten Hoefler. Data movement is\n",
      "all you need: A case study on optimizing transformers. Proceedings of Machine Learning and\n",
      "Systems , 3:711–732, 2021.\n",
      "Nikita Kitaev, Łukasz Kaiser, and Anselm Levskaya. Reformer: The efficient transformer. arXiv\n",
      "preprint arXiv:2001.04451 , 2020.\n",
      "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\n",
      "language models are zero-shot reasoners. Advances in neural information processing systems ,\n",
      "35:22199–22213, 2022.\n",
      "Raghuraman Krishnamoorthi. Quantizing deep convolutional networks for efficient inference: A\n",
      "whitepaper. arXiv preprint arXiv:1806.08342 , 2018.\n",
      "Alex Krizhevsky. One weird trick for parallelizing convolutional neural networks. arXiv preprint\n",
      "arXiv:1404.5997 , 2014.\n",
      "Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E\n",
      "Gonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model\n",
      "serving with pagedattention. arXiv preprint arXiv:2309.06180 , 2023.\n",
      "Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang,\n",
      "Maxim Krikun, Noam Shazeer, and Zhifeng Chen. {GS}hard: Scaling giant models with condi-\n",
      "tional computation and automatic sharding. In International Conference on Learning Represen-\n",
      "tations , 2021. URL https://openreview.net/forum?id=qrwe7XHTmYb .\n",
      "Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt\n",
      "tuning. arXiv preprint arXiv:2104.08691 , 2021.\n",
      "Yaniv Leviathan, Matan Kalman, and Yossi Matias. Fast inference from transformers via speculative\n",
      "decoding. arXiv preprint arXiv:2211.17192 , 2022.\n",
      "Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
      "Camel: Communicative agents for ”mind” exploration of large scale language model society,\n",
      "2023a.\n",
      "Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv\n",
      "preprint arXiv:2101.00190 , 2021.\n",
      "Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy\n",
      "Liang, and Tatsunori B. Hashimoto. Alpacaeval: An automatic evaluator of instruction-following\n",
      "models. https://github.com/tatsu-lab/alpaca_eval , 2023b.\n",
      "Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and Weizhu Chen. Making\n",
      "language models better reasoners with step-aware verifier. In Proceedings of the 61st Annual\n",
      "Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 5315–\n",
      "5333, 2023c.\n",
      "Zhuohan Li, Siyuan Zhuang, Shiyuan Guo, Danyang Zhuo, Hao Zhang, Dawn Song, and Ion Stoica.\n",
      "Terapipe: Token-level pipeline parallelism for training large-scale language models. In Interna-\n",
      "tional Conference on Machine Learning , pp. 6543–6552. PMLR, 2021.\n",
      "12\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Xingyu Dang, and Song Han. Awq:\n",
      "Activation-aware weight quantization for llm compression and acceleration. arXiv preprint\n",
      "arXiv:2306.00978 , 2023.\n",
      "Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-\n",
      "train, prompt, and predict: A systematic survey of prompting methods in natural language pro-\n",
      "cessing. ACM Computing Surveys , 55(9):1–35, 2023.\n",
      "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike\n",
      "Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining\n",
      "approach, 2019.\n",
      "Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International Confer-\n",
      "ence on Learning Representations , 2019.\n",
      "Wenyan Lu, Guihai Yan, Jiajun Li, Shijun Gong, Yinhe Han, and Xiaowei Li. Flexflow: A flexible\n",
      "dataflow accelerator architecture for convolutional neural networks. In 2017 IEEE International\n",
      "Symposium on High Performance Computer Architecture (HPCA) , pp. 553–564. IEEE, 2017.\n",
      "Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Zeyu Wang, Rae Ying Yee Wong,\n",
      "Zhuoming Chen, Daiyaan Arfeen, Reyna Abhyankar, and Zhihao Jia. Specinfer: Accelerating\n",
      "generative llm serving with speculative inference and token tree verification. arXiv preprint\n",
      "arXiv:2305.09781 , 2023.\n",
      "Asit Mishra, Jorge Albericio Latorre, Jeff Pool, Darko Stosic, Dusan Stosic, Ganesh Venkatesh,\n",
      "Chong Yu, and Paulius Micikevicius. Accelerating sparse deep neural networks. arXiv preprint\n",
      "arXiv:2104.08378 , 2021.\n",
      "Deepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek Seshadri, Nikhil R Devanur, Gre-\n",
      "gory R Ganger, Phillip B Gibbons, and Matei Zaharia. Pipedream: Generalized pipeline par-\n",
      "allelism for dnn training. In Proceedings of the 27th ACM Symposium on Operating Systems\n",
      "Principles , pp. 1–15, 2019.\n",
      "Deepak Narayanan, Amar Phanishayee, Kaiyu Shi, Xie Chen, and Matei Zaharia. Memory-efficient\n",
      "pipeline-parallel dnn training. In International Conference on Machine Learning , pp. 7937–7947.\n",
      "PMLR, 2021.\n",
      "NVIDIA. Fastertransformer, 2019. URL https://github.com/NVIDIA/\n",
      "FasterTransformer .\n",
      "NVIDIA. Triton inference server, 2021. URL https://developer.nvidia.com/\n",
      "triton-inference-server .\n",
      "OpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 , 2023.\n",
      "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\n",
      "Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow\n",
      "instructions with human feedback. Advances in Neural Information Processing Systems , 35:\n",
      "27730–27744, 2022.\n",
      "Duy Phung. Stablevicuna-13b, May 2023. URL https://huggingface.co/CarperAI/\n",
      "stable-vicuna-13b-delta .\n",
      "Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis. Measuring\n",
      "and narrowing the compositionality gap in language models. arXiv preprint arXiv:2210.03350 ,\n",
      "2022.\n",
      "Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. Zero: Memory optimizations\n",
      "toward training trillion parameter models. In SC20: International Conference for High Perfor-\n",
      "mance Computing, Networking, Storage and Analysis , pp. 1–16. IEEE, 2020.\n",
      "Jie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Min-\n",
      "jia Zhang, Dong Li, and Yuxiong He. {ZeRO-Offload }: Democratizing {Billion-Scale }model\n",
      "training. In 2021 USENIX Annual Technical Conference (USENIX ATC 21) , pp. 551–564, 2021.\n",
      "13\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Andrea Santilli, Silvio Severino, Emilian Postolache, Valentino Maiorca, Michele Mancusi, Ric-\n",
      "cardo Marin, and Emanuele Rodol `a. Accelerating transformer inference for translation via paral-\n",
      "lel decoding. In acl, 2023.\n",
      "Timo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\n",
      "Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\n",
      "use tools. arXiv preprint arXiv:2302.04761 , 2023.\n",
      "SenseTime. Lightllm. https://github.com/ModelTC/lightllm , 2023a. Accessed:\n",
      "2023-09-26.\n",
      "SenseTime. Openppl. https://github.com/openppl-public/ppl.nn , 2023b. Ac-\n",
      "cessed: 2023-09-26.\n",
      "Noam Shazeer. Fast transformer decoding: One write-head is all you need. arXiv preprint\n",
      "arXiv:1911.02150 , 2019.\n",
      "Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang.\n",
      "Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint\n",
      "arXiv:2303.17580 , 2023.\n",
      "Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Daniel Y Fu, Zhiqiang\n",
      "Xie, Beidi Chen, Clark Barrett, Joseph E Gonzalez, et al. High-throughput generative inference\n",
      "of large language models with a single gpu. arXiv preprint arXiv:2303.06865 , 2023.\n",
      "Taylor Shin, Yasaman Razeghi, Robert L Logan IV , Eric Wallace, and Sameer Singh. Autoprompt:\n",
      "Eliciting knowledge from language models with automatically generated prompts. In Proceedings\n",
      "of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pp.\n",
      "4222–4235, 2020.\n",
      "Mitchell Stern, Noam Shazeer, and Jakob Uszkoreit. Blockwise parallel decoding for deep autore-\n",
      "gressive models. Advances in Neural Information Processing Systems , 31, 2018.\n",
      "Ziteng Sun, Ananda Theertha Suresh, Jae Hun Ro, Ahmad Beirami, Himanshu Jain, Felix Yu,\n",
      "Michael Riley, and Sanjiv Kumar. Spectr: Fast speculative decoding via optimal transport.\n",
      "InWorkshop on Efficient Systems for Foundation Models @ ICML2023 , 2023. URL https:\n",
      "//openreview.net/forum?id=d0mGsaheuT .\n",
      "Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethink-\n",
      "ing the inception architecture for computer vision. In Proceedings of the IEEE conference on\n",
      "computer vision and pattern recognition , pp. 2818–2826, 2016.\n",
      "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy\n",
      "Liang, and Tatsunori Hashimoto. Alpaca: A strong, replicable instruction-following model.\n",
      "https://crfm.stanford.edu/2023/03/13/alpaca.html , 2023. Accessed: 2023-\n",
      "06-23.\n",
      "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth ´ee\n",
      "Lacroix, Baptiste Rozi `ere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and\n",
      "efficient foundation language models. arXiv preprint arXiv:2302.13971 , 2023a.\n",
      "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-\n",
      "lay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher,\n",
      "Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy\n",
      "Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn,\n",
      "Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel\n",
      "Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee,\n",
      "Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,\n",
      "Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi,\n",
      "Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh\n",
      "Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen\n",
      "Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic,\n",
      "Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models,\n",
      "2023b.\n",
      "14\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Guan Wang, Sijie Cheng, Qiying Yu, and Changling Liu. Openllms: Less is more for open-source\n",
      "models, July 2023a. URL https://github.com/imoneoi/openchat .\n",
      "Hanrui Wang, Zhekai Zhang, and Song Han. Spatten: Efficient sparse attention architecture with\n",
      "cascade token and head pruning. In 2021 IEEE International Symposium on High-Performance\n",
      "Computer Architecture (HPCA) , pp. 97–110. IEEE, 2021.\n",
      "Sinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, and Hao Ma. Linformer: Self-attention\n",
      "with linear complexity. arXiv preprint arXiv:2006.04768 , 2020.\n",
      "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\n",
      "ery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models.\n",
      "arXiv preprint arXiv:2203.11171 , 2022.\n",
      "Zifu Wang, Teodora Popordanoska, Jeroen Bertels, Robin Lemmens, and Matthew B Blaschko. Dice\n",
      "semimetric losses: Optimizing the dice score with soft labels. In Medical Image Computing and\n",
      "Computer Assisted Intervention , 2023b.\n",
      "Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\n",
      "Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint\n",
      "arXiv:2109.01652 , 2021.\n",
      "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\n",
      "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in\n",
      "Neural Information Processing Systems , 35:24824–24837, 2022.\n",
      "Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in\n",
      "deep neural networks. Advances in neural information processing systems , 29, 2016.\n",
      "Guangxuan Xiao, Ji Lin, Mickael Seznec, Julien Demouth, and Song Han. Smoothquant:\n",
      "Accurate and efficient post-training quantization for large language models. arXiv preprint\n",
      "arXiv:2211.10438 , 2022.\n",
      "Yisheng Xiao, Lijun Wu, Junliang Guo, Juntao Li, Min Zhang, Tao Qin, and Tie-yan Liu. A survey\n",
      "on non-autoregressive generation for neural machine translation and beyond. IEEE Transactions\n",
      "on Pattern Analysis and Machine Intelligence , 2023.\n",
      "Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and\n",
      "Daxin Jiang. Wizardlm: Empowering large language models to follow complex instructions.\n",
      "arXiv preprint arXiv:2304.12244 , 2023.\n",
      "Yuanzhong Xu, HyoukJoong Lee, Dehao Chen, Blake Hechtman, Yanping Huang, Rahul Joshi,\n",
      "Maxim Krikun, Dmitry Lepikhin, Andy Ly, Marcello Maggioni, et al. Gspmd: general and\n",
      "scalable parallelization for ml computation graphs. arXiv preprint arXiv:2105.04663 , 2021.\n",
      "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\n",
      "React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629 ,\n",
      "2022.\n",
      "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik\n",
      "Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. arXiv\n",
      "preprint arXiv:2305.10601 , 2023.\n",
      "Gyeong-In Yu, Joo Seong Jeong, Geon-Woo Kim, Soojeong Kim, and Byung-Gon Chun. Orca: A\n",
      "distributed serving system for {Transformer-Based }generative models. In 16th USENIX Sympo-\n",
      "sium on Operating Systems Design and Implementation (OSDI 22) , pp. 521–538, 2022.\n",
      "Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago\n",
      "Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et al. Big bird: Transformers for\n",
      "longer sequences. Advances in neural information processing systems , 33:17283–17297, 2020.\n",
      "Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman. Star: Bootstrapping reasoning with\n",
      "reasoning. Advances in Neural Information Processing Systems , 35:15476–15488, 2022.\n",
      "15\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Daochen Zha, Zaid Pervaiz Bhat, Kwei-Herng Lai, Fan Yang, Zhimeng Jiang, Shaochen Zhong, and\n",
      "Xia Hu. Data-centric artificial intelligence: A survey. arXiv preprint arXiv:2303.10158 , 2023.\n",
      "Yujia Zhai, Chengquan Jiang, Leyuan Wang, Xiaoying Jia, Shang Zhang, Zizhong Chen, Xin Liu,\n",
      "and Yibo Zhu. Bytetransformer: A high-performance transformer boosted for variable-length\n",
      "inputs. arXiv preprint arXiv:2210.03052 , 2022.\n",
      "Yifan Zhang, Jingqin Yang, Yang Yuan, and Andrew Chi-Chih Yao. Cumulative reasoning with\n",
      "large language models. arXiv preprint arXiv:2308.04371 , 2023.\n",
      "Lianmin Zheng, Zhuohan Li, Hao Zhang, Yonghao Zhuang, Zhifeng Chen, Yanping Huang, Yida\n",
      "Wang, Yuanzhong Xu, Danyang Zhuo, Eric P Xing, et al. Alpa: Automating inter-and {Intra-\n",
      "Operator }parallelism for distributed deep learning. In 16th USENIX Symposium on Operating\n",
      "Systems Design and Implementation (OSDI 22) , pp. 559–578, 2022.\n",
      "Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,\n",
      "Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.\n",
      "Judging llm-as-a-judge with mt-bench and chatbot arena, 2023.\n",
      "Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat,\n",
      "Ping Yu, Lili Yu, et al. Lima: Less is more for alignment, 2023.\n",
      "Zhe Zhou, Xuechao Wei, Jiejing Zhang, and Guangyu Sun. {PetS}: A unified framework for\n",
      "{Parameter-Efficient }transformers serving. In 2022 USENIX Annual Technical Conference\n",
      "(USENIX ATC 22) , pp. 489–504, 2022.\n",
      "Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li,\n",
      "Lewei Lu, Xiaogang Wang, et al. Ghost in the minecraft: Generally capable agents for open-world\n",
      "enviroments via large language models with text-based knowledge and memory. arXiv preprint\n",
      "arXiv:2305.17144 , 2023.\n",
      "Barret Zoph and Quoc V . Le. Neural architecture search with reinforcement learning. In Interna-\n",
      "tional Conference on Learning Representations (ICLR) , 2017.\n",
      "16\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Appendix\n",
      "Table of Contents\n",
      "A Model Details 18\n",
      "B Implementation Details of Skeleton-of-Thought 18\n",
      "B.1 Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n",
      "B.2 Supporting Multi-Round Conversation . . . . . . . . . . . . . . . . . . . . . . 20\n",
      "C Implementation Details of Skeleton-of-Thought with Router 20\n",
      "C.1 Prompting Router . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n",
      "C.2 Trained Router . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n",
      "C.3 Router Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n",
      "C.4 Concurrent execution for SoT-R . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n",
      "D Related Work (Expanded) 22\n",
      "D.1 Efficient LLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n",
      "D.2 Prompting Methods for LLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n",
      "E Efficiency Analysis 24\n",
      "F Efficiency Profiling 25\n",
      "G Efficiency Evaluation 27\n",
      "G.1 Skeleton-of-Thought . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n",
      "G.2 Skeleton-of-Thought with Router . . . . . . . . . . . . . . . . . . . . . . . . . 29\n",
      "H Overhead of SoT in Different Scenarios 31\n",
      "I Answer Quality Evaluation 32\n",
      "I.1 Skeleton-of-Thought . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n",
      "I.2 Skeleton-of-Thought with Router . . . . . . . . . . . . . . . . . . . . . . . . . 44\n",
      "I.3 ChatGPT-3.5 as the Judge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n",
      "17\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "A M ODEL DETAILS\n",
      "Table 1 summarizes the models on which we evaluate SoT. We use GPT-4 in the main paper and\n",
      "ChatGPT-3.5 in App. I.3 as the judge in FastChat and LLMZoo evaluation.\n",
      "Table 1: Model evaluated with SoT. All the open-source models are fine-tuned from LLaMA models.\n",
      "Access Model Name Institution Released Date\n",
      "Open-SourceLLaMA2-Chat-7B (Touvron et al., 2023b) Meta & Microsoft 2023/07\n",
      "LLaMA2-Chat-13B (Touvron et al., 2023b) Meta & Microsoft 2023/07\n",
      "OpenChat-13B (Wang et al., 2023a) Tsinghua 2023/07\n",
      "Vicuna-7B V1.3 (Chiang et al., 2023) LMSYS 2023/06\n",
      "Vicuna-13B V1.3 (Chiang et al., 2023) LMSYS 2023/06\n",
      "Vicuna-33B V1.3 (Chiang et al., 2023) LMSYS 2023/06\n",
      "StableVicuna-13B (Phung, 2023) CarperAI 2023/05\n",
      "UltraLM-13B (Ding et al., 2023) OpenBMB & Tsinghua 2023/05\n",
      "Vicuna-7B V1.1 (Chiang et al., 2023) LMSYS 2023/03\n",
      "API-BasedClaude (Anthropic, 2023) Anthropic 2023/05\n",
      "ChatGPT-3.5 OpenAI 2022/11\n",
      "GPT-4 OpenAI 2023/03\n",
      "Table 2 shows sources of the models we use in the paper.\n",
      "Table 2: The Hugging Face or API endpoints of the models.\n",
      "Access Model Name Hugging Face or API Endpoints\n",
      "Open-SourceLLaMA2-Chat-7B (Touvron et al., 2023b) meta-llama/Llama-2-7b-chat-hf\n",
      "LLaMA2-Chat-13B (Touvron et al., 2023b) meta-llama/Llama-2-13b-chat-hf\n",
      "OpenChat-13B (Wang et al., 2023a) openchat/openchat\n",
      "Vicuna-7B V1.3 (Chiang et al., 2023) lmsys/vicuna-7b-v1.3\n",
      "Vicuna-13B V1.3 (Chiang et al., 2023) lmsys/vicuna-13b-v1.3\n",
      "Vicuna-33B V1.3 (Chiang et al., 2023) lmsys/vicuna-33b-v1.3\n",
      "StableVicuna-13B (Phung, 2023) CarperAI/stable-vicuna-13b-delta2\n",
      "UltraLM-13B (Ding et al., 2023) openbmb/UltraLM-13b2\n",
      "Vicuna-7B V1.1 (Chiang et al., 2023) lmsys/vicuna-7b-delta-v1.1\n",
      "API-BasedClaude (Anthropic, 2023) Claude extension on Slack3\n",
      "ChatGPT-3.5 Azure OpenAI, gpt-35-turbo 0301 version4\n",
      "GPT-4 OpenAI, gpt-4-0613 version\n",
      "B I MPLEMENTATION DETAILS OF SKELETON -OF-THOUGHT\n",
      "B.1 P ROMPT\n",
      "The skeleton prompt is shown in Prompts 1 and 3 and the point-expanding prompt is shown in\n",
      "Prompt 2.\n",
      "Skeleton prompt template. In order to make the output skeleton short and in a consistent format for\n",
      "the good of efficiency and ease of point extraction, the skeleton prompt template (1) describes the\n",
      "task precisely, and (2) provides a partial answer “1.” for the LLM to continue writing. The skeleton\n",
      "2For convenience, we use the non-official endpoint TheBloke/stable-vicuna-13B-HF and\n",
      "TheBloke/UltraLM-13B-fp16 to get merged weights.\n",
      "3https://www.anthropic.com/claude-in-slack\n",
      "4https://azure.microsoft.com/en-us/products/ai-services/openai-service\n",
      "18\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Prompt 3. Skeleton Prompt Template Ts(with Two-Shot Demonstrations)\n",
      "[User:] You’re an organizer responsible for only giving the skeleton (not the full content) for answering the question.\n",
      "Provide the skeleton in a list of points (numbered 1., 2., 3., etc.) to answer the question. Instead of writing a full\n",
      "sentence, each skeleton point should be very short with only 3 ∼5 words. Generally, the skeleton should have 3 ∼10\n",
      "points.\n",
      "Question:\n",
      "What are the typical types of Chinese dishes?\n",
      "Skeleton:\n",
      "1. Dumplings.\n",
      "2. Noodles.\n",
      "3. Dim Sum.\n",
      "4. Hot Pot.\n",
      "5. Wonton.\n",
      "6. Ma Po Tofu.\n",
      "7. Char Siu.\n",
      "8. Fried Rice.\n",
      "Question:\n",
      "What are some practical tips for individuals to reduce their carbon emissions?\n",
      "Skeleton:\n",
      "1. Energy conservation.\n",
      "2. Efficient transportation.\n",
      "3. Home energy efficiency.\n",
      "4. Reduce water consumption.\n",
      "5. Sustainable diet.\n",
      "6. Sustainable travel.\n",
      "Now, please provide the skeleton for the following question.\n",
      "{question }\n",
      "Skeleton:\n",
      "[Assistant:] 1.\n",
      "responses are in the desired format in most cases. Therefore, we can use a simple regular expression\n",
      "(\\d+)\\.\\s?([\\s\\S]+?)(?=\\n|\\n *$)to extract point indexes and point skeletons from the\n",
      "skeleton response.\n",
      "We find that GPT-4 can work well without the two demonstrations in the skeleton prompt. Therefore,\n",
      "we do not include the two demonstrations for GPT-4 (Prompt 1). For all other models, the two\n",
      "demonstrations are included, as shown in Prompt 3.\n",
      "Point-expanding prompt template. It describes the point-expanding task and provides a partial\n",
      "answer. We also provide instructions “Write it **very shortly** in 1 ∼2 sentence” so that the LLMs\n",
      "keep the answers concise. Unlike the skeleton prompt template, we find that demonstrations are not\n",
      "necessary to get reasonable results.\n",
      "We find that Claude and GPT-4 follows the instruction “Write it **very shortly** in 1 ∼2 sentence\n",
      "and do not continue with other points!” in Prompt 2 very well, so that the answers are very short.\n",
      "Therefore, we delete “**very shortly**” from the prompt template in Claude and GPT-4.\n",
      "Partial answer. In the Prompts 1 and 2, we provide partial answers so that LLMs can follow the\n",
      "desired response format better.\n",
      "We can put the partial answer at the end of the prompt for the open-source models to continue\n",
      "writing. An implementation detail is that different open-source models have different conversa-\n",
      "tion templates (i.e., different ways to combine user and assistant messages into one string). For\n",
      "example, Vicuna (Chiang et al., 2023) uses the string “USER:” and “ ASSISTANT:” for the place-\n",
      "holder “ [User:] ” and “ [Role] ” in the Prompts 1 and 2, respectively, while UltraLM (Ding et al.,\n",
      "2023) uses “User:” and “ 〈/s〉Assistant:”. We build our open-source model experiments with the\n",
      "help of the FastChat codebase (Zheng et al., 2023), in which the conversation templates of many\n",
      "models are already handled correctly. We implement the conversation templates of OpenChat-13B,\n",
      "StableVicuna-13B, and UltraLM-13B according to their official guides and codes.\n",
      "For ChatGPT-3.5, we provide partial answers as a last message in the chat history from the assistant.\n",
      "Note that it is not a documented approach. We find it works well in most cases, in that ChatGPT-3.5\n",
      "19\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Prompt 4. LLM Prompting as the Router\n",
      "[User:] Question: {question }\n",
      "How would you like to answer the question?\n",
      "A. Organize the answer as a list of points or perspectives (in the format of 1., 2., 3., etc.), and the points or perspectives\n",
      "can be answered independently without referring to the contents of the previous points.\n",
      "B. Organize the answer as a list of points or perspectives (in the format of 1., 2., 3., etc.), and the contents of later points\n",
      "or perspectives cannot be answered independently without referring to the contents of the previous ones.\n",
      "C. Do not organize the answer as a list of points or perspectives.\n",
      "Just say A, B, or C. Do not explain. Do not provide an answer to the question.\n",
      "[Assistant:]\n",
      "continues the texts from the provided partial answer. However, in some rare cases, ChatGPT-3.5\n",
      "repeats the provided partial answers.\n",
      "For Claude over Slack, there is no obvious way to give the API a partial answer. We resort to\n",
      "modifying the prompt template slightly by adding\n",
      "Please start your answer from “ {partial answer }” and do not output other things before that\n",
      "at the end. We find that Claude understands and obeys it well. For GPT-4, we also take this approach.\n",
      "System Message. We do not include the system message in the prompts for open-source models\n",
      "except LLaMA2.\n",
      "The partial answer, “**very shortly**”, and the 2-shot demonstrations discussed above are the only\n",
      "differences between the prompts we used across all models and all evaluations.\n",
      "B.2 S UPPORTING MULTI -ROUND CONVERSATION\n",
      "To use SoT in a multi-round conversation, we can just put the question and the final aggregated\n",
      "answer in the history, removing all the SoT prompts. In this way, using SoT in one conversation\n",
      "round will not introduce additional prefill cost in future rounds.\n",
      "C I MPLEMENTATION DETAILS OF SKELETON -OF-THOUGHT WITH ROUTER\n",
      "C.1 P ROMPTING ROUTER\n",
      "We use Prompt 4 for querying GPT-4 as the router. If the answer is “A” (i.e., the question can be\n",
      "answered in a list of independent points), we will use SoT. Otherwise, if the answer is “B” (i.e., the\n",
      "answer is in a list of points but they depend on each other) or “C” (i.e., the answer should notbe in\n",
      "a list of points), SoT is not suitable and we will fall back to normal decoding.\n",
      "C.2 T RAINED ROUTER\n",
      "We tackle the routing problem as a sequence classification task. We first annotate the LIMA training\n",
      "set (Zhou et al., 2023), and then fine-tune a RoBERTa model (Liu et al., 2019) using the labeled\n",
      "data. Finally, we apply the tuned RoBERTa as the router on Vicuna-80 and WizardLM. We detail\n",
      "the steps in the following.\n",
      "C.2.1 A NNOTATION PROCESS\n",
      "In the classification task, a label of 1 (positive) indicates that this question can be answered with\n",
      "SoT, while a label of 0 (negative) suggests that using the normal generation mode is more suitable.\n",
      "We annotate the LIMA training set, which consists of 1,030 Q&As sourced from three community\n",
      "webpages: Stack Exchange, wikiHow, and the Pushshift Reddit. We also annotate the Vicuna-80\n",
      "and WizardLM datasets for evaluation.\n",
      "20\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Table 3: Router confusion matrices on the Vicuna-80 dataset. Left: Rows are human annotations\n",
      "(H) and columns are the GPT-4 router (G). Middle: Rows are human annotations (H) and columns\n",
      "are the RoBERTa router (R). Right: Rows are the GPT-4 router (G) and columns are the RoBERTa\n",
      "router (R).\n",
      "G0 G1\n",
      "H0 38 5\n",
      "H1 0 37R0 R1\n",
      "H0 37 6\n",
      "H1 5 32R0 R1\n",
      "G0 34 4\n",
      "G1 8 34\n",
      "Table 4: Router confusion matrices on the WizardLM dataset. Left: Rows are human annotations\n",
      "(H) and columns are the GPT-4 router (G). Middle: Rows are human annotations (H) and columns\n",
      "are the RoBERTa router (R). Right: Rows are the GPT-4 router (G) and columns are the RoBERTa\n",
      "router (R).\n",
      "G0 G1\n",
      "H0 94 66\n",
      "H1 3 55R0 R1\n",
      "H0 135 25\n",
      "H1 31 27R0 R1\n",
      "G0 93 4\n",
      "G1 73 48\n",
      "We use GPT-4 to assist the annotation process. Specifically, we present each question to GPT-4 and\n",
      "analyze its answer to determine whether SoT can be triggered for this question. We assign a positive\n",
      "label to a question if GPT-4’s response meets two criteria: (1) it contains a list of points that can be\n",
      "expanded in parallel, (2) each point provides sufficient details (i.e., the point-expanding response is\n",
      "not too short), which will enable SoT to achieve a speed-up. Two of the paper’s authors conduct the\n",
      "annotation process independently, and discuss the inconsistent annotations to decide the final label.\n",
      "C.2.2 T RAINING DETAILS\n",
      "We use roberta-base with 120M parameters as the router model. The finetuning is conducted\n",
      "using the AdamW optimizer (Loshchilov & Hutter, 2019) with a weight decay of 0.01. The learning\n",
      "rate undergoes a warm-up phase during the first 1% of iterations to 5e-5 and then decays linearly.\n",
      "We train the model for 2 epochs using a batch size of 32. Input sequences are either padded or\n",
      "truncated to achieve a consistent length of 512 tokens.\n",
      "In the application of SoT, false positives (SoT is incorrectly triggered when it should not be, resulting\n",
      "in degraded answer quality) are of more significant concern than false negatives (the router misses a\n",
      "potential SoT trigger, resulting in a reduced speed-up). Thus, to mitigate false positives, we employ\n",
      "the Tversky loss (Wang et al., 2023b) with parameters α= 0.7andβ= 0.3, which penalizes false\n",
      "positives more heavily than false negatives. We also incorporate label smoothing (Szegedy et al.,\n",
      "2016) with a factor of ϵ= 0.2. Overall, the entire fine-tuning process is efficient, completing in 2\n",
      "minutes on an NVIDIA A100 GPU.\n",
      "C.3 R OUTER CONSISTENCY\n",
      "We present the confusion matrices for the three routers to illustrate their consistency. The results on\n",
      "Vicuna-80 and WizardLM are shown in Tables 3 and 4, respectively.\n",
      "On Vicuna-80, we can observe a notable level of agreement among the three routers. Compared with\n",
      "the GPT-4-prompting router, the trained router exhibits a slightly higher number of false negatives\n",
      "w.r.t. the human annotations. Conversely, on WizardLM, given the intricate answer structure and\n",
      "the presence of many ambiguous cases, the routers show significant discrepancies. Specifically, the\n",
      "GPT-4 router produces many false positives, which pose adverse affects on the answer quality (see\n",
      "App. I.2). The RoBERTa router aligns more closely with the human annotations.\n",
      "C.4 C ONCURRENT EXECUTION FOR SOT-R\n",
      "In SoT-R, the router serves as an additional stage that extends the two-stage SoT pipeline. The\n",
      "SoT-R pipeline is illustrated in Fig. 9. To push the limit of latency optimization, we can run the\n",
      "router, normal generation, and SoT generation concurrently. Once the router makes a decision, one\n",
      "of the normal and SoT generation processes can be aborted. However, this approach will increase\n",
      "21\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "RouterSkeleton Expandpositive\n",
      "negativeDecodeQuestion\n",
      "AnswerAnswer\n",
      "RouterSkeleton Expand\n",
      "DecodeQuestionAnswer\n",
      "Answerpositive\n",
      "negative\n",
      "Figure 9: Left: The SoT-R pipeline. Right: A possible approach to further reduce latency at the\n",
      "cost of token overhead.\n",
      "the token overhead. Therefore, we did not employ this approach in this work and leave it to future\n",
      "work.\n",
      "D R ELATED WORK (EXPANDED )\n",
      "D.1 E FFICIENT LLM S\n",
      "Extensive research has been dedicated to enhancing the throughput and latency of LLM infer-\n",
      "ence. We first discuss model-level architecture design or compression techniques. These techniques\n",
      "change the model and can benefit both the latency and throughput but require finetuning to retain the\n",
      "model quality. Then, we discuss system-level efforts that optimize the computational graph or the\n",
      "assignment and scheduling of the computational graph on computation and storage devices. Most\n",
      "system-level efforts accelerate the prefilling phase or focus on improving the throughput. Finally,\n",
      "we discuss some research efforts that share a similar motivation to ours, namely, addressing the\n",
      "efficiency issue of sequential decoding.\n",
      "Model-level optimization. Considerable architectural design efforts have emerged to (1) improve\n",
      "the scalability w.r.t. model size by introducing mixture-of-expert inference (Lepikhin et al., 2021;\n",
      "Fedus et al., 2022), (2) address the quadratic complexity w.r.t. input size of attention by designing\n",
      "new attention mechanisms (Kitaev et al., 2020; Wang et al., 2020), (3) reduce the memory access\n",
      "and footprint of attention by using multi-query attention (Shazeer, 2019), and so on. However, these\n",
      "methods usually require a substantial re-training cost. The model compression techniques require a\n",
      "smaller amount of fine-tuning by reducing the model complexity of a pre-trained LLM from certain\n",
      "aspects (Ganesh et al., 2021). Representative techniques include quantization (Xiao et al., 2022;\n",
      "Frantar et al., 2022; Lin et al., 2023), the static or dynamic pruning of weights, activation, and\n",
      "attention (Mishra et al., 2021; Zaheer et al., 2020; Wang et al., 2021; Chen et al., 2023b), and so on.\n",
      "Zooming out from LLM compression to the whole field of model compression, we can see that\n",
      "model co-design or compression for efficiency has received tremendous attention in the past few\n",
      "years and has grown into large research fields, such as pruning (Han et al., 2015; Wen et al., 2016),\n",
      "quantization (Krishnamoorthi, 2018), factorization (Denton et al., 2014), and neural architecture\n",
      "search (Zoph & Le, 2017; Elsken et al., 2019; Cai et al., 2019). Different from the model co-design\n",
      "paradigm, SoT is in a “ content co-organization for efficiency ” paradigm for improving the LLM\n",
      "efficiency . Along with the growth in the LLM capabilities and amount of LLM-generated data,\n",
      "data-level techniques could become important tools in the efficient LLM toolbox.\n",
      "System-level optimization. In the realm of lossless acceleration, considerable efforts have been\n",
      "devoted to addressing the I/O-bound nature of LLMs on modern hardware platforms (Dao et al.,\n",
      "2022). Numerous studies (Dao et al., 2022; Zhai et al., 2022; Ivanov et al., 2021; NVIDIA, 2019)\n",
      "have focused on adjusting the computational graph by fusing and implementing operations in an\n",
      "I/O-friendly way. As a representative method, FlashAttention (Dao et al., 2022) fuses all operations\n",
      "of one attention into one GPU kernel with spatially tiled computation to reduce the off-chip I/O of\n",
      "the attention map. While FlashAttention can effectively accelerate training and the prefilling phase\n",
      "of inference, it cannot accelerate the decoding phase much (when the batch size is small), as it is\n",
      "the I/O of weights rather than activation or attention map that bottlenecks the decoding phase. For\n",
      "example, when the context length is 64, decoding one token using LLaMA-7B needs to load each\n",
      "22\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "of the 7B parameters from the off-chip HBM onto the GPU chip at least once, but only transferring\n",
      "about 20M (0.02B) activation values between the off-chip HBM and GPU chip.\n",
      "In order to satisfy Service Level Objectives, serving systems focus on improving the serving\n",
      "throughput under latency constraints. To this end, serving systems (Fang et al., 2021; NVIDIA,\n",
      "2021; Google, 2021) pack multiple queries together into a batch to improve the hardware utiliza-\n",
      "tion. The batching technique has proven highly effective in enhancing throughput, leading to the\n",
      "development of various variants. For example, some work designs methods to decide which queries\n",
      "to batch together (Fang et al., 2021; Zhou et al., 2022), while others selectively batch parts of the\n",
      "model to enable fine-grained iteration-level batching (Yu et al., 2022) or multi-task batching (Zhou\n",
      "et al., 2022). Various model parallelism (Lu et al., 2017; Huang et al., 2019; Narayanan et al.,\n",
      "2019; Rajbhandari et al., 2020; Narayanan et al., 2021; Li et al., 2021; Zheng et al., 2022) and\n",
      "offloading (Ren et al., 2021; Sheng et al., 2023) techniques have been proposed to maximize the\n",
      "throughput of LLM training or inference. In a nutshell, given the computational graph and device\n",
      "configurations, these techniques optimize the split, assignment, and scheduling of computations,\n",
      "storage, and communications on devices. In addition to the model parallelism and batching tech-\n",
      "niques, an efficient memory management mechanism for LLM workloads is also an essential feature\n",
      "in the serving systems (Kwon et al., 2023; SenseTime, 2023a;b).\n",
      "To sum up, these system-level techniques mainly help with the throughput in training and batched\n",
      "inference. They can be used by SoT to improve the throughput of the batched decoding of multiple\n",
      "segments. This means that SoT can harness the power of these throughput-oriented techniques and\n",
      "make them help with the end-to-end latency , offering a new dimension for better trading off latency\n",
      "and throughput in future serving systems.\n",
      "Another parallelism perspective to position SoT is that SoT guides the LLM to adjust the sequen-\n",
      "tial workload to become “inter-content” parallelizable , which differs from the parallelism levels\n",
      "in existing serving systems, including inter-instance (Krizhevsky, 2014; Rajbhandari et al., 2020),\n",
      "inter-operation (Huang et al., 2019; Narayanan et al., 2019; 2021), intra-operation (Xu et al., 2021),\n",
      "and inter-token (Li et al., 2021). It may be worthwhile to explore the integration of SoT into serving\n",
      "systems to maximize the hardware utilization .\n",
      "Decoding optimization. One bottleneck for the end-to-end latency lies in the autoregressive de-\n",
      "coding phase, where tokens must be generated one by one. Due to the dependency between tokens,\n",
      "the computation of different tokens cannot be parallelized, causing severe under-utilization of GPU.\n",
      "In order to improve the end-to-end decoding latency of a given LLM, speculative decoding meth-\n",
      "ods (Stern et al., 2018; Leviathan et al., 2022; Chen et al., 2023a; Gante, 2023; Sun et al., 2023;\n",
      "Miao et al., 2023) propose to use cheaper approaches to generate short candidate token sequences,\n",
      "for example, by sequentially decoding with an assisting model much smaller than the given LLM.\n",
      "Then, they use the LLM to parallelly verify the candidates and keep the prefix sequence that matches\n",
      "the LLM’s verification results.\n",
      "Another line of work that shares the motivation of addressing the autoregressive efficiency issue is\n",
      "non-autoregressive generation (NAG) methods (Gu et al., 2018; Xiao et al., 2023). NAG methods\n",
      "sample consecutive tokens parallelly, often with the aid of a modified and tuned model. To maintain\n",
      "the answer quality, instead of sampling for one iteration, many NAG methods refine the output\n",
      "parallelly for multiple iterations (Xiao et al., 2023; Santilli et al., 2023).\n",
      "To summarize, the speculative decoding methods use assisting models for letting the LLM conduct\n",
      "parallel verification of consecutive tokens , and the NAG methods rely on specially designed models,\n",
      "training schemes, or sampling schemes for the parallel sampling and refinement of consecutive to-\n",
      "kens. In contrast, SoT prompts the LLM itself to plan the contents in a way that permits the parallel\n",
      "generation of multiple tokens in different segments . SoT exploits the emerging instruction-following\n",
      "and planning ability of SoTA LLMs rather than relying on specially designed modeling, sampling,\n",
      "and training schemes. This is different from all existing work that targets the autoregressive effi-\n",
      "ciency issue.\n",
      "D.2 P ROMPTING METHODS FOR LLM S\n",
      "In recent years, the “pre-train, prompt, and predict” paradigm has emerged (Liu et al., 2023), which\n",
      "designs prompts comprising task descriptions and (optionally) a few demonstrations to guide pre-\n",
      "23\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Table 5: The latency and average GPU performance of the prefilling and decoding phases when\n",
      "inferencing LLMs. The prefilling token length is 128, the decoding token length is 64, and the batch\n",
      "size is 1. The test is run on one NVIDIA A100 GPU.\n",
      "Model Prefill/Decode Latency (ms) Prefill/Decode GPU Perf. (TFLOPS)\n",
      "LLaMA-7B 40 / 2735 43 / 0.31\n",
      "LLaMA-13B 54 / 3725 62 / 0.44\n",
      "LLaMA-33B 100 / 5506 85 / 0.75\n",
      "trained LLMs in generating answers for a wide range of downstream tasks. Researchers found that\n",
      "instruction-tuned LLMs (Brown et al., 2020; Wei et al., 2021; Ouyang et al., 2022; Chung et al.,\n",
      "2022; Taori et al., 2023) possess a strong ability to (1) generalize to new tasks thanks to the diverse\n",
      "natural language descriptions encountered during instruction tuning, and (2) learn in-context using\n",
      "a few demonstrations without weight tuning.\n",
      "In virtue of these abilities, the field has been manually engineering (Brown et al., 2020; Kojima\n",
      "et al., 2022; Shen et al., 2023; Li et al., 2023a), automatic searching (Shin et al., 2020), or continu-\n",
      "ously tuning (Li & Liang, 2021; Lester et al., 2021) the prompts for uncovering the capabilities of\n",
      "LLMs on downstream tasks. There are a bunch of prompting methods that improves the reasoning\n",
      "performance of LLMs by designing thinking flows mimicking human reasoning: (1) mimicking the\n",
      "step-by-step or compositional thinking structure (Wei et al., 2022; Kojima et al., 2022; Press et al.,\n",
      "2022; Yao et al., 2023; Besta et al., 2023; Zhang et al., 2023), (2) designing multiple reasoning paths\n",
      "and their aggregation (Wang et al., 2022; Yao et al., 2023; Li et al., 2023c), and (3) using tools for\n",
      "calculation and information retrieval (Chen et al., 2022; Yao et al., 2022; Schick et al., 2023). As\n",
      "a representative example, the Chain-of-Thought prompts largely improve the performance on tasks\n",
      "that require logical reasoning by simply providing a “Let’s think step by step” (Kojima et al., 2022)\n",
      "instruction or a few demonstrations (Wei et al., 2022). Another topic that arises quite a surge of in-\n",
      "terests is to prompt LLMs to help finish complex multi-modality task (Shen et al., 2023; Zhu et al.,\n",
      "2023). For example, HuggingGPT (Shen et al., 2023) design prompts to guide the LLM to generate\n",
      "structural JSON for the orchestration of multi-model execution to finish complex tasks.\n",
      "To summarize, the large literature on prompting methods has been aiming at uncovering different\n",
      "capabilities of LLM and improving the answer quality on different downstream tasks. In contrast,\n",
      "SoT is a first attempt at exploiting the power of prompting to improve efficiency .\n",
      "E E FFICIENCY ANALYSIS\n",
      "This section gives a detailed explanation on why SoT can reduce the overall decoding latency with\n",
      "the same computational resource for local models.\n",
      "The vanilla approach processes only one question and decodes the answers sequentially, whereas\n",
      "SoT processes multiple point-expanding requests and the answers in a batch. We focus on the\n",
      "following question: “Compared to processing only one sequence, how much peak memory overhead\n",
      "and latency increase will be brought by processing a batch of sequences?”\n",
      "A typical LLM generative process consists of two phases: (1) the prefilling phase in which the\n",
      "prompt is parsed to generate the key-value cache for further use, and (2) the decoding phase in\n",
      "which tokens are generated one by one in a sequential manner. The decoding phase accounts for\n",
      "the majority of the end-to-end latency, especially when generating a long response. As shown in\n",
      "Table 5, when running Vicuna-7B on NVIDIA A100-80G, the actual computing performance is\n",
      "only 0.31 TFLOPS (0.1% utilization) in the decoding phase, compared to 43 TFLOPS (13.8% uti-\n",
      "lization) during prefilling. The utilization is calculated with respect to the FP165tensor core peak\n",
      "performance – 312 TFLOPS for NVIDIA-A100. As a result, the latency of decoding only one token\n",
      "is comparable to that of prefilling 128 tokens (40ms). This huge gap in actual computing perfor-\n",
      "mance and thereby the latency arises from the fact that all LLM weights need to be loaded onto the\n",
      "GPU chip at least once only for decoding one token, so the decoding is heavily bottlenecked by the\n",
      "I/O of weights and the GPU computation units cannot be well utilized.\n",
      "5All of our experiments are run with FP16 inference.\n",
      "24\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "1 2 3 4 5 6 7 8 9\n",
      "B300035004000450050005500\n",
      "LLaMA-7B\n",
      "LLaMA-13B\n",
      "LLaMA-33B\n",
      "(a) Latency (ms)\n",
      "1 2 3 4 5 6 7 8 9\n",
      "B0123456\n",
      "LLaMA-7B\n",
      "LLaMA-13B\n",
      "LLaMA-33B (b) Actual GPU Perf. (TFLOPS)\n",
      "1 2 3 4 5 6 7 8 9\n",
      "B203040506070\n",
      "LLaMA-7B\n",
      "LLaMA-13B\n",
      "LLaMA-33B (c) Peak Memory (GB)\n",
      "Figure 10: The trends of latency, average GPU performance of decoding one token, and peak mem-\n",
      "ory with respect to the batch size Bof sequences. The prefilling token length is 128, and the\n",
      "decoding token length is 64. The test is run on one NVIDIA A100 GPU.\n",
      "When conducting batched decoding, as the sequence batch size Bincreases, the latency of decoding\n",
      "one token for each sequence stays roughly the same (Fig. 10a), as the amount of LLM weights that\n",
      "needs to be loaded onto the chip does not change. As a result, the GPU computation utilization\n",
      "(Actual GPU Performance\n",
      "Peak GPU Performance) increases almost linearly as Bincreases (Fig. 10b). In other words, for gener-\n",
      "ating a final answer of length N, if we cut the answer into Bsegments of length N/B and decode\n",
      "them as a batch, we can get a B×decoding speed-up compared to sequential decoding. Never-\n",
      "theless, in practice, as prefilling longer requests brings some overhead, and the lengths of the B\n",
      "segments could be imbalanced, the actual speed-up of the batched point-expanding stage compared\n",
      "with the original prefilling and sequential decoding process is smaller than B.\n",
      "As for the peak memory overhead, the amount of LLM weights can be one to two orders of mag-\n",
      "nitude larger than that of all the intermediate activations as long as the prefilling token length is not\n",
      "too large, not to mention that most activations do not need to be saved for back-propagation during\n",
      "inference. Therefore, the LLM weights account for the majority of the memory footprint in our test\n",
      "cases. Consequently, as shown in Fig. 10c, the peak memory overhead due to the increasing size\n",
      "of the KV cache and activation grows at a slow pace as the batch size Bincreases. Thanks to the\n",
      "small peak memory overhead, in all of our experiments, we managed to use one GPU to run SoT\n",
      "without seeking help from other peak memory optimization techniques (e.g., quantization (Frantar\n",
      "et al., 2022; Lin et al., 2023), offloading (Sheng et al., 2023)).\n",
      "F E FFICIENCY PROFILING\n",
      "We run the profiling on the target GPU (NVIDIA A100-80G and NVIDIA RTX 3090) with CUDA\n",
      "11.7, using the Hugging Face transformer library 4.28.1 and PyTorch 2.0.1. The host of A100-80G\n",
      "has an Intel Xeon Platinum 8358P CPU and 1T memory. The host of RTX 3090 has an Intel Xeon\n",
      "Gold 6246R CPU and 512G memory.\n",
      "Latency profiling and estimation. For the decoding phase, we denote tD\n",
      "B(k)as the latency\n",
      "of batched decoding the k+ 1-th token with batch size B, where the superscript Dstands for\n",
      "“decode”. For each batch size B= 1,···,16and each context length k= 1,···,1024 , we\n",
      "usetorch.cuda.Event to record the latency of decoding one token. We run each decod-\n",
      "ing three times continuously and take their geometric mean as {tD\n",
      "B(k)}k=1,···,1024;B=1,···,16. For\n",
      "the prefilling phase, we profile the latency of batched prefilling the inputs with token length kin\n",
      "range (1,700,10)and batch size B= 1,···,16, and denote it as tP\n",
      "B(k), where the superscript P\n",
      "stands for “prefill”. We run each test seven times continuously, regard the first two times as the\n",
      "warmup tests, and take the geometric mean of the last five times as {tP\n",
      "B(k)}k=1,11,···,691;B=1,···,16.\n",
      "Once we get the latency profiling table, given a request with litokens and the decoding batch size\n",
      "B, the latency of generating lotokens can be estimated as:\n",
      "T(li, lo, B) =˜tP\n",
      "B(li) +li+lo−1X\n",
      "k=litD\n",
      "B(k), (1)\n",
      "where the subscripts iandostand for “input” and “output”. Note that we only test the prefill-\n",
      "ing latency every ten token lengths (i.e., 1,11,21,···) for fast profiling and estimate ˜tP\n",
      "B(li)by\n",
      "tP\n",
      "B(⌊li\n",
      "10⌋ ×10 + 1) .\n",
      "25\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "The SoT decoding process consists of two stages: the skeleton stage and the point-expanding stage.\n",
      "Denoting the token length of the skeleton request and skeleton response as ls\n",
      "iandls\n",
      "o, the token length\n",
      "of the longest point-expanding request and the longest point-expanding response as lpe\n",
      "iandlpe\n",
      "o, the\n",
      "number of the points as B, we can compute the latency of the skeleton and point-expanding stages\n",
      "as:\n",
      "Ls(ls\n",
      "i, ls\n",
      "o) =T(ls\n",
      "i, ls\n",
      "o,1), (2)\n",
      "Lpe(lpe\n",
      "i, lpe\n",
      "o, B) =T(lpe\n",
      "i, lpe\n",
      "o, B). (3)\n",
      "Using the latency profiling table, we can further estimate the average GPU computing performance\n",
      "in FLOPS (i.e., FLOPs per second) of decoding lotokens with prefilling length lias\n",
      "PD(li, lo, B) =Pli+lo−1\n",
      "k=lifD\n",
      "B(k)\n",
      "Pli+lo−1\n",
      "k=litD\n",
      "B(k), (4)\n",
      "where fD\n",
      "B(k)denotes the FLOPs of decoding one token with context length k, which is calculated\n",
      "by DeepSpeed’s FLOPs profiler6. Fig. 10b reports the average GPU computing performance during\n",
      "the process of decoding 64 tokens (prefilling length=128), i.e., PD(128,64, B).\n",
      "Memory profiling and evaluation. To evaluate the peak memory, we use\n",
      "torch.cuda.max_memory_allocated to record the memory consumption of prefill-\n",
      "ing sequences of different lengths and decoding with different context lengths and a batch size\n",
      "ranging from 1 to 16. Then, we calculate the peak memory of each stage as the maximum value of\n",
      "the prefilling and decoding phases, and calculate the overall peak memory of SoT as the maximum\n",
      "value of the skeleton and point-expanding stages.\n",
      "6https://deepspeed.readthedocs.io/en/latest/flops-profiler.html\n",
      "26\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "G E FFICIENCY EVALUATION\n",
      "G.1 S KELETON -OF-THOUGHT\n",
      "G.1.1 D ETAILED STATISTICS OF TOKEN LENGTHS AND POINT NUMBERS\n",
      "Avgerage\n",
      "LLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\n",
      "ChatGPT-3.5GPT-4coding\n",
      "math\n",
      "fermi\n",
      "roleplay\n",
      "writing\n",
      "knowledge\n",
      "generic\n",
      "counterfactual\n",
      "common-sense\n",
      "Average6.4 5.3 4.4 7.3 4.9 7.9 6.6 9.7 7.1 5.0 4.7 5.3 8.6\n",
      "4.4 3.7 3.3 5.7 5.0 4.0 3.7 5.7 5.0 3.3 3.7 4.7 5.3\n",
      "6.3 4.9 5.6 5.4 5.3 6.5 6.9 10.0 5.8 5.5 6.4 4.8 8.5\n",
      "7.4 6.7 6.3 6.7 6.0 7.0 7.3 9.9 9.1 5.3 8.6 6.3 9.9\n",
      "7.5 5.9 6.6 8.2 6.3 8.0 7.8 8.8 8.1 5.8 8.3 5.9 9.8\n",
      "7.4 7.5 5.9 5.9 6.3 7.5 8.6 9.4 8.1 6.4 7.9 6.1 9.4\n",
      "7.8 6.3 6.2 7.4 6.7 8.4 8.6 9.7 9.2 6.4 7.9 6.7 9.5\n",
      "6.8 5.0 6.1 6.1 4.9 9.1 7.7 8.4 8.3 4.4 7.3 4.9 9.5\n",
      "6.8 6.0 5.5 5.5 4.8 8.6 7.8 9.2 8.8 4.1 7.3 5.1 9.3\n",
      "6.8 5.7 5.6 6.5 5.6 7.4 7.2 9.0 7.7 5.1 6.9 5.5 8.9\n",
      "4.05.06.07.08.09.010.0\n",
      "(a) The number of points B.\n",
      "Avgerage\n",
      "LLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\n",
      "ChatGPT-3.5GPT-4coding\n",
      "math\n",
      "fermi\n",
      "roleplay\n",
      "writing\n",
      "knowledge\n",
      "generic\n",
      "counterfactual\n",
      "common-sense\n",
      "Average372.4 374.0 462.7 386.9 459.7 394.9 384.9 300.3 338.4 381.4 338.6 343.0 304.3\n",
      "173.5 177.3 208.0 95.0 254.7 159.7 255.0 83.0 273.7 156.7 137.0 139.7 142.7\n",
      "391.8 396.6 350.3 453.0 382.8 429.6 465.3 398.1 272.1 402.1 417.6 333.8 400.2\n",
      "311.4 368.5 356.4 273.4 338.2 285.4 431.7 155.7 361.0 254.3 304.7 235.3 372.5\n",
      "409.8 436.6 478.1 373.9 397.9 404.1 440.4 260.4 325.2 386.0 464.4 366.6 583.6\n",
      "401.0 470.6 488.6 468.9 377.1 369.8 497.8 266.7 376.8 341.1 352.9 320.2 481.8\n",
      "372.7 468.4 469.8 417.2 328.1 341.1 476.3 194.2 417.8 321.8 361.3 231.7 444.3\n",
      "319.0 285.4 419.5 303.3 245.5 332.1 501.9 198.2 399.7 252.3 404.9 173.4 311.3\n",
      "335.6 424.5 487.9 326.0 324.9 307.6 479.6 169.6 337.9 285.9 303.7 206.1 373.5\n",
      "343.0 378.0 413.5 344.2 345.4 336.0 437.0 225.1 344.7 309.1 342.8 261.1 379.4\n",
      "100.0200.0300.0400.0500.0 (b) The normal answer length.\n",
      "Avgerage\n",
      "LLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\n",
      "ChatGPT-3.5GPT-4coding\n",
      "math\n",
      "fermi\n",
      "roleplay\n",
      "writing\n",
      "knowledge\n",
      "generic\n",
      "counterfactual\n",
      "common-sense\n",
      "Average114.9 92.6 126.1 151.7 143.0 124.7 104.9 216.0 120.6 128.4 48.0 56.1 67.0\n",
      "95.0 104.3 94.3 27.3 162.0 189.0 101.7 79.3 98.7 108.0 64.7 45.3 65.7\n",
      "116.0 117.2 117.1 170.7 188.9 106.0 126.0 163.3 105.8 80.4 65.0 78.0 74.0\n",
      "89.0 93.1 108.2 63.4 102.0 100.3 118.7 123.4 76.9 71.8 59.4 66.1 84.6\n",
      "97.2 94.4 114.5 161.9 125.1 92.6 118.1 89.5 90.2 85.8 53.8 61.3 79.4\n",
      "94.1 99.9 101.0 98.1 110.5 108.9 114.0 117.8 90.9 81.1 61.2 62.9 83.0\n",
      "86.0 86.3 108.5 106.6 108.6 89.6 105.4 87.3 81.3 76.8 51.3 55.5 75.1\n",
      "93.5 106.2 103.2 101.9 88.9 118.3 113.0 129.2 79.6 75.3 66.6 56.7 83.1\n",
      "86.9 97.4 100.1 75.4 121.3 100.6 98.3 104.2 88.5 75.6 55.0 57.0 69.7\n",
      "97.0 99.0 108.1 106.3 127.8 114.4 111.1 123.3 92.5 87.0 58.3 59.9 75.7\n",
      "50.075.0100.0125.0150.0175.0200.0\n",
      "(c) The maximum point-expanding response length.\n",
      "Avgerage\n",
      "LLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\n",
      "ChatGPT-3.5GPT-4coding\n",
      "math\n",
      "fermi\n",
      "roleplay\n",
      "writing\n",
      "knowledge\n",
      "generic\n",
      "counterfactual\n",
      "common-sense\n",
      "Average0.4 0.3 0.4 0.4 0.3 0.3 0.3 0.9 0.5 0.3 0.1 0.2 0.2\n",
      "0.8 0.6 0.5 0.7 0.6 1.3 0.5 3.0 0.6 0.7 0.6 0.3 0.5\n",
      "0.3 0.3 0.4 0.4 0.5 0.3 0.3 0.4 0.5 0.2 0.2 0.2 0.2\n",
      "0.4 0.3 0.4 0.4 0.3 0.4 0.3 1.2 0.3 0.3 0.2 0.3 0.3\n",
      "0.3 0.2 0.2 0.7 0.3 0.2 0.6 0.4 0.6 0.2 0.1 0.2 0.1\n",
      "0.3 0.2 0.2 0.2 0.3 0.3 0.2 0.5 0.3 0.2 0.3 0.2 0.2\n",
      "0.3 0.2 0.2 0.3 0.4 0.3 0.2 0.5 0.3 0.2 0.1 0.2 0.2\n",
      "0.3 0.4 0.2 0.4 0.4 0.4 0.2 0.7 0.3 0.4 0.2 0.3 0.3\n",
      "0.3 0.2 0.2 0.4 0.4 0.3 0.2 0.7 0.4 0.3 0.4 0.3 0.2\n",
      "0.4 0.3 0.3 0.4 0.4 0.4 0.3 0.9 0.4 0.3 0.2 0.3 0.2\n",
      "0.51.01.52.02.5(d) The ratio of the maximum point-expanding re-\n",
      "sponse length to the normal answer length.\n",
      "Avgerage\n",
      "LLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\n",
      "ChatGPT-3.5GPT-4coding\n",
      "math\n",
      "fermi\n",
      "roleplay\n",
      "writing\n",
      "knowledge\n",
      "generic\n",
      "counterfactual\n",
      "common-sense\n",
      "Average30.8 13.5 27.6 50.0 42.1 36.2 24.1 64.7 36.6 43.2 10.3 11.8 9.1\n",
      "25.2 23.6 18.4 6.3 48.7 59.1 17.5 22.6 31.8 41.6 13.0 8.9 10.4\n",
      "25.0 21.6 18.9 47.4 49.2 21.8 22.2 35.8 29.8 23.0 12.9 8.7 8.4\n",
      "16.4 9.9 14.8 17.1 21.0 18.0 18.8 26.6 21.5 15.9 9.1 10.8 12.9\n",
      "17.9 10.9 14.3 39.1 27.1 17.1 19.8 17.1 22.1 18.0 9.4 8.4 12.2\n",
      "14.4 9.7 10.6 20.3 17.9 17.2 15.0 19.8 20.4 15.3 8.3 7.4 10.8\n",
      "15.4 9.0 15.9 27.0 24.1 18.4 16.8 16.2 18.0 15.7 7.6 7.6 8.3\n",
      "15.9 12.4 11.4 22.3 13.1 23.8 14.0 34.0 19.6 15.1 8.8 5.3 11.5\n",
      "14.7 10.5 12.1 19.7 27.7 17.6 14.2 19.6 19.0 15.1 7.0 7.4 6.5\n",
      "19.5 13.5 16.0 27.7 30.1 25.5 18.1 28.5 24.3 22.5 9.6 8.5 10.0\n",
      "10.020.030.040.050.060.0\n",
      "(e) The imbalance degree of point-expanding response\n",
      "lengths (standard deviation of point token lengths).\n",
      "Avgerage\n",
      "LLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\n",
      "ChatGPT-3.5GPT-4coding\n",
      "math\n",
      "fermi\n",
      "roleplay\n",
      "writing\n",
      "knowledge\n",
      "generic\n",
      "counterfactual\n",
      "common-sense\n",
      "Average1.5 1.2 1.1 1.1 0.8 1.1 1.1 6.8 1.5 0.7 0.5 0.6 1.4\n",
      "2.1 1.5 1.1 3.4 1.9 2.5 1.0 7.6 1.2 1.0 1.4 1.1 1.8\n",
      "1.3 1.2 1.7 1.2 1.5 1.2 1.3 1.9 1.9 0.6 0.7 0.9 1.3\n",
      "1.9 1.6 1.7 1.9 1.3 2.0 1.3 5.5 1.2 1.1 1.4 1.4 1.9\n",
      "1.7 1.1 1.3 2.8 1.4 1.3 3.5 2.2 3.3 1.0 0.7 0.8 1.0\n",
      "1.5 1.3 1.0 0.8 1.5 1.7 1.5 3.0 1.5 1.1 1.7 1.0 1.3\n",
      "1.4 1.0 1.1 1.0 1.7 1.7 1.3 3.5 1.6 1.1 0.9 1.3 1.3\n",
      "1.7 1.6 1.3 2.0 1.5 2.1 1.3 3.4 1.2 1.1 0.9 1.4 2.0\n",
      "1.7 1.2 0.9 2.0 1.2 2.0 1.2 4.5 1.7 0.9 2.1 1.2 1.5\n",
      "1.6 1.3 1.2 1.8 1.4 1.7 1.5 4.3 1.7 1.0 1.1 1.1 1.5\n",
      "1.02.03.04.05.06.07.0(f) The ratio of the final SoT answer length to the nor-\n",
      "mal answer length.\n",
      "Figure 11: The statistics of the token lengths and point numbers on the Vicuna-80 dataset. Each row\n",
      "corresponds to one question category, and each column corresponds to one model.\n",
      "G.1.2 L ATENCY BREAKDOWN : SOT S TAGES AND PHASES\n",
      "Fig. 12 presents the absolute latencies of normal and SoT generations on Vicuna-80. Again, the\n",
      "speed-ups of SoT compared with normal generation is evident. We can see that the decoding phases\n",
      "predominantly account for the end-to-end latency. Consequently, although SoT has higher prefilling\n",
      "latency in the skeleton stage than the normal generation and introduces additional point-expanding\n",
      "27\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "prefilling latency – which is expected – this has negligible impact on the overall latency and thereby\n",
      "the overall speed-up.\n",
      "0 5000 10000 15000 20000 25000 30000 35000 40000\n",
      "Latency (ms)ChatGPT-3.5StableVicuna-13BVicuna-7B V1.1Vicuna-7B V1.3LLaMA2-Chat-7BClaudeUltraLM-13BVicuna-13B V1.3OpenChat-13BLLaMA2-Chat-13BGPT-4Vicuna-33B V1.3\n",
      "Normal (prefill)\n",
      "Normal (decode)\n",
      "SoT skeleton (prefill)\n",
      "SoT skeleton (decode)\n",
      "SoT point-expanding (prefill)\n",
      "SoT point-expanding (decode)\n",
      "(a) Average latency across all question categories except\n",
      "math andcode on different models.\n",
      "0 5000 10000 15000 20000\n",
      "Latency (ms)mathroleplaycounterfactualcommon-sensecodingfermigenericknowledgewriting(b) Average latency across all models on different\n",
      "question categories.\n",
      "Figure 12: The latency breakdown of SoT and normal generations on the Vicuna-80 dataset. For\n",
      "open-source models, the latency breakdown of the prefilling and decoding phases is shown in dif-\n",
      "ferent colors. For API-based models, we do not record such latency breakdown information; the bar\n",
      "labeled as “(decode)” indicates the overall latency of prefilling and decoding phases.\n",
      "G.1.3 E FFICIENCY EVALUATION ON NVIDIA RTX 3090\n",
      "We present the SoT speed-ups and latency breakdown on RTX 3090 in Fig. 13. We test the three\n",
      "7B models, as their FP16-precision version can be run on an RTX 3090 GPU without further peak\n",
      "memory optimization techniques such as weight quantization (Frantar et al., 2022; Lin et al., 2023)\n",
      "or offloading (Sheng et al., 2023). On these three models, SoT can obtain 1.94 ×to 2.40 ×speed-up\n",
      "on average on Vicuna-80.\n",
      "For the five question categories that SoT can provide high-quality answers (i.e., knowledge ,common-\n",
      "sense ,generic ,roleplay ,counterfactual ), SoT can speed-up the overall answer generation process\n",
      "by 1.96 ×to 2.52 ×in the meantime. Note that for the math category, despite the average speed-up\n",
      "being 1.20 ×by calculating the speed-up across the three math questions, SoT does not reduce the\n",
      "absolute latency of processing the three questions.\n",
      "0 2000 4000 6000 8000 10000 12000 14000 16000\n",
      "Latency (ms)Vicuna-7B V1.3Vicuna-7B V1.1LLaMA2-Chat-7B\n",
      "1.94×2.26×2.40×\n",
      "0 2000 4000 6000 8000 10000 12000 14000 16000\n",
      "Latency (ms)mathfermicounterfactualcodingroleplayknowledgecommon-sensewritinggeneric\n",
      "1.20×1.70×1.96×2.10×2.12×2.37×2.39×2.43×2.52×Normal (prefill)\n",
      "Normal (decode)\n",
      "SoT skeleton (prefill)\n",
      "SoT skeleton (decode)\n",
      "SoT point-expanding (prefill)\n",
      "SoT point-expanding (decode)\n",
      "Figure 13: The latency breakdown of SoT and normal decoding on the Vicuna-80 dataset. The\n",
      "average speed-up across questions are also marked on the figure.\n",
      "G.1.4 A CTUAL LATENCY TESTING\n",
      "This section reports the actual SoT speed-up on the Vicuna-80 with batch testing (instead of analyz-\n",
      "ing with pre-made profiling tables), using a single NVIDIA A100 GPU. We test the actual end-to-end\n",
      "latency of the SoT and normal decoding with the 9 open-source models. For each model, we run the\n",
      "speed-up test for five times and plot the box in Fig. 14.\n",
      "28\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "As shown in Fig. 14a, the current SoT solution obtains a >2×speed-up on 6 out of the 9 open-\n",
      "source models (i.e., Vicuna-7B V1.1, Vicuna-7B V1.3, UltraLM-13B, LLaMA2-Chat-7B, Vicuna-\n",
      "13B V1.3, and LLaMA2-Chat-13B), and a >1.7speed-up on OpenChat-13B and Vicuna-33B V1.3.\n",
      "SoT achieves no speed-up on StableVicuna-13B. As shown in Fig. 14b, for the five question cate-\n",
      "gories that SoT can provide high-quality answers (i.e., knowledge ,common-sense ,generic ,roleplay ,\n",
      "counterfactual ), SoT can speed-up the overall answer generation process by 2.15 ×to 2.50 ×in the\n",
      "meantime.\n",
      "1.0 1.5 2.0 2.5 3.0 3.5StableVicuna-13BVicuna-33B V1.3OpenChat-13BLLaMA2-Chat-13BVicuna-13B V1.3LLaMA2-Chat-7BUltraLM-13BVicuna-7B V1.3Vicuna-7B V1.1\n",
      "0.97×1.75×1.97×2.14×2.19×2.20×2.75×2.82×2.88×\n",
      "(a) Average speed-up on different models.\n",
      "1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8 3.0fermimathroleplaywritingcounterfactualcodingknowledgecommon-sensegeneric\n",
      "1.63×1.67×2.15×2.16×2.18×2.29×2.34×2.45×2.50× (b) Average speed-up on different question categories.\n",
      "Figure 14: Speed-ups on 9 open-source models on the Vicuna-80 dataset with actual batch testing.\n",
      "G.2 S KELETON -OF-THOUGHT WITH ROUTER\n",
      "The overhead brought by the router inference is relatively small: On the Vicuna-80 dataset,\n",
      "the prompting and trained router have an average latency of 0.65s (0.39s ∼1.37s) and 0.04s\n",
      "(0.008s ∼1.55s), respectively. On the WizardLM dataset, the average latency of the prompting and\n",
      "trained router is 0.80s (0.36s ∼2.22s) and 0.03s (0.009s ∼2.52s), respectively.\n",
      "G.2.1 S PEED -UP BREAKDOWN :MODELS\n",
      "Fig. 15 shows the speed-ups of SoT-R on different models on the Vicuna-80 dataset. Fig. 16 and\n",
      "Fig. 17 show the speed-ups of SoT-R on different models on the WizardLM dataset. We can ob-\n",
      "serve that on Vicuna-80, the two methods yield similar speed-ups, whereas on WizardLM, GPT-4\n",
      "prompting router usually obtains higher speed-ups than the trained router, especially on GPT-4 itself.\n",
      "1.0 1.2 1.4 1.6 1.8 2.0 2.2StableVicuna-13BClaudeChatGPT-3.5Vicuna-13B V1.3Vicuna-7B V1.3UltraLM-13BGPT-4Vicuna-7B V1.1Vicuna-33B V1.3OpenChat-13BLLaMA2-Chat-7BLLaMA2-Chat-13B\n",
      "0.98×1.15×1.24×1.32×1.39×1.51×1.54×1.55×1.62×1.66×1.67×1.70×\n",
      "(a) Average speed-up across all question categories\n",
      "with prompting router.\n",
      "1.0 1.2 1.4 1.6 1.8 2.0 2.2StableVicuna-13BClaudeChatGPT-3.5Vicuna-13B V1.3Vicuna-7B V1.3GPT-4Vicuna-33B V1.3UltraLM-13BVicuna-7B V1.1LLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13B\n",
      "0.99×1.14×1.33×1.34×1.42×1.49×1.57×1.59×1.59×1.69×1.70×1.82×(b) Average speed-up across all question categories\n",
      "with trained router.\n",
      "Figure 15: Speed-ups of SoT-R on different models on Vicuna-80 dataset.\n",
      "29\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75StableVicuna-13BClaudeChatGPT-3.5Vicuna-7B V1.3LLaMA2-Chat-7BLLaMA2-Chat-13BVicuna-7B V1.1UltraLM-13BVicuna-13B V1.3OpenChat-13BVicuna-33B V1.3GPT-4\n",
      "1.13×1.13×1.40×1.49×1.51×1.52×1.56×1.57×1.59×1.66×1.68×2.41×\n",
      "(a) Average speed-up across all question categories\n",
      "with prompting router.\n",
      "1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75ClaudeStableVicuna-13BVicuna-13B V1.3UltraLM-13BVicuna-33B V1.3Vicuna-7B V1.3LLaMA2-Chat-13BVicuna-7B V1.1LLaMA2-Chat-7BChatGPT-3.5OpenChat-13BGPT-4\n",
      "1.09×1.09×1.31×1.33×1.33×1.34×1.35×1.36×1.37×1.37×1.42×1.74×(b) Average speed-up across all question categories\n",
      "with trained router.\n",
      "Figure 16: Speed-ups of SoT-R on different models on WizardLM dataset.\n",
      "1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75ClaudeStableVicuna-13BVicuna-7B V1.3LLaMA2-Chat-7BLLaMA2-Chat-13BChatGPT-3.5Vicuna-13B V1.3Vicuna-33B V1.3OpenChat-13BVicuna-7B V1.1UltraLM-13BGPT-4\n",
      "SoT (w/o router)\n",
      "SoT-R w/ prompting router\n",
      "SoT-R w/ trained router\n",
      "Figure 17: Speed-ups of SoT and SoT-R on different models on the WizardLM dataset.\n",
      "G.2.2 S PEED -UP BREAKDOWN :CATEGORIES\n",
      "Fig. 18 and Fig. 19 show the speed-ups of SoT-R on different question categories of Vicuna-80\n",
      "dataset. The trained router achieves slightly higher speed-up on most of the categories (except for\n",
      "knowledge ,writing , and fermi ). Fig. 20 and Fig. 21 show the speed-ups of SoT-R on different\n",
      "question categories of WizardLM dataset. We can observe that on 19 out of 29 categories, using the\n",
      "prompting router achieves higher speed-ups than using the trained router.\n",
      "1.001.251.501.752.002.252.502.75mathcodingfermiwritingroleplaycounterfactualknowledgecommon-sensegeneric\n",
      "0.90×0.96×1.01×1.10×1.17×1.75×1.95×2.05×2.11×\n",
      "(a) Speed-ups of SoT-R with prompting router on dif-\n",
      "ferent question categories.\n",
      "1.001.251.501.752.002.252.502.75mathwritingcodingfermiroleplaycounterfactualknowledgecommon-sensegeneric\n",
      "1.00×1.00×1.00×1.00×1.23×1.79×1.87×2.10×2.26×(b) Speed-ups of SoT-R with trained router on different\n",
      "question categories.\n",
      "Figure 18: Speed-ups of SoT-R on different question categories of Vicuna-80 dataset\n",
      "1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00mathfermicounterfactualroleplaycodingcommon-sensewritinggenericknowledge\n",
      "SoT (w/o router)\n",
      "SoT-R w/ prompting router\n",
      "SoT-R w/ trained router\n",
      "Figure 19: Speed-ups of SoT and SoT-R on different question categories of the Vicuna-80 dataset.\n",
      "30\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00MathPhysicsReasoningCode GenerationEntertainmentT oxicityComplex FormatMultilingualCommon-SenseCode DebugBiologyArtMusicComputer ScienceRoleplayChemistryEthicsAcademic WritingTruthfulQAWrittingLiteraturePhilosophyLawSportMedicineHistoryT echnologyEconomyCounterfactual\n",
      "0.85×0.94×1.02×1.02×1.03×1.12×1.14×1.22×1.24×1.25×1.34×1.47×1.54×1.54×1.58×1.62×1.67×1.69×1.74×1.77×1.85×1.90×1.90×1.93×2.08×2.10×2.14×2.18×2.23×\n",
      "(a) Speed-ups of SoT-R with prompting router on dif-\n",
      "ferent question categories.\n",
      "1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00Code GenerationEntertainmentArtComplex FormatMathLiteratureCode DebugLawAcademic WritingPhilosophyBiologyReasoningPhysicsHistoryComputer ScienceMultilingualMusicT oxicityRoleplayCommon-SenseTruthfulQAWrittingEconomyChemistryEthicsSportT echnologyMedicineCounterfactual\n",
      "0.99×1.00×1.00×1.00×1.00×1.00×1.00×1.00×1.00×1.00×1.07×1.09×1.14×1.16×1.17×1.17×1.20×1.22×1.36×1.37×1.41×1.49×1.65×1.73×1.82×2.01×2.17×2.26×2.41×(b) Speed-ups of SoT-R with trained router on different\n",
      "question categories.\n",
      "Figure 20: Speed-ups of SoT-R on different question categories of WizardLM dataset\n",
      "1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00EntertainmentPhysicsReasoningMultilingualMathCommon-SenseBiologyArtMusicT oxicityEthicsComputer ScienceCode DebugChemistryLiteratureAcademic WritingPhilosophyLawTruthfulQARoleplayCode GenerationComplex FormatSportWrittingMedicineHistoryT echnologyEconomyCounterfactual\n",
      "SoT (w/o router)\n",
      "SoT-R w/ prompting router\n",
      "SoT-R w/ trained router\n",
      "Figure 21: Speed-ups of SoT and SoT-R on different question categories of the WizardLM dataset.\n",
      "H O VERHEAD OF SOTINDIFFERENT SCENARIOS\n",
      "Despite the optimizations made to the decoding phase, SoT brings overhead to the prefilling phase as\n",
      "the model needs to handle additional SoT prompts. Table 6 reports SoT’s prefilling overhead for the\n",
      "API-based models. These statistics are averaged across the Vicuna-80 questions that are suitable for\n",
      "SoT (according to our manual annotation). We can see that SoT significantly increases the number\n",
      "of prefilling tokens. This is because that SoT issues an independent point-expanding request for\n",
      "each point, with the average number of points being 6.8 on Vicuna-80 dataset across all evaluated\n",
      "models. Consequently, the APIs need to prefill the point-expanding request multiple times.\n",
      "31\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Table 6: SoT’s prefilling token overhead for API-based models.\n",
      "ModelPrefill Phase\n",
      "Normal SoT Stage 1 SoT Stage 2 Ratio (SoT / Normal)\n",
      "Claude 12.52 171.41 808.91 78.30\n",
      "ChatGPT-3.5 12.52 171.41 591.31 60.92\n",
      "GPT-4 12.52 171.41 983.09 92.21\n",
      "When using SoT to serve the open-source models, a simple and small trick is to prefill the common\n",
      "prefix of point-expanding requests with a batch size of 1 during Stage 2 (i.e., the point-expanding\n",
      "stage). Table 7 shows the prefilling overhead after applying the trick. Although the ratio is consid-\n",
      "erably smaller compared to that of the API-based models, this computational overhead remains a\n",
      "concern, especially during periods of high system workload.\n",
      "There are some possibilities to further reduce the token and computational overhead that are worth\n",
      "exploring in future work. To name a few: (1) When using SoT in serving systems, we can simply\n",
      "reuse the key-value cache containing the question and skeleton from Stage 1 during Stage 2, rather\n",
      "than re-prefilling them as in a multi-round conversation. (2) Generally, as LLM capabilities continue\n",
      "to evolve and prompt tuning techniques advance (Shin et al., 2020; Li & Liang, 2021; Lester et al.,\n",
      "2021), the possibility of using much shorter prompts to activate the SoT mode in the future holds\n",
      "promise, which would significantly mitigate the token or computational overhead.\n",
      "Table 7: SoT’s computational overhead (in terms of the number of prefilling tokens) for open-source\n",
      "models.\n",
      "ModelPrefill Phase\n",
      "Naive SoT Stage 1 SoT Stage 2 Ratio (SoT / Normal)\n",
      "LLaMA2-Chat-7B 12.52 171.41 216.49 30.98\n",
      "LLaMA2-Chat-13B 12.52 171.41 216.41 30.98\n",
      "OpenChat-13B 12.52 171.41 234.38 32.41\n",
      "Vicuna-7B V1.3 12.52 171.41 211.61 30.59\n",
      "Vicuna-13B V1.3 12.52 171.41 273.39 35.53\n",
      "Vicuna-33B V1.3 12.52 171.41 258.88 34.37\n",
      "StableVicuna-13B 12.52 171.41 312.03 38.61\n",
      "UltraLM-13B 12.52 171.41 290.88 36.92\n",
      "Vicuna-7B V1.1 12.52 171.41 196.64 29.40\n",
      "I A NSWER QUALITY EVALUATION\n",
      "I.1 S KELETON -OF-THOUGHT\n",
      "I.1.1 A NSWER ANALYSIS : DIFFERENT MODELS\n",
      "Models on which SoT has low net win rates. We observe two types of reasons for the low net win\n",
      "rates.\n",
      "(1) OpenChat-13B, Vicuna-7B V1.1, and LLaMA2-Chat-13B. For the weak models such as\n",
      "OpenChat-13B and Vicuna-7B V1.1, they are not able to follow the SoT prompts precisely. For\n",
      "OpenChat-13B and LLaMA2-Chat-13B, sometimes the skeleton contains undesired contents (e.g.,\n",
      "completing the skeleton points as shown below).\n",
      "32\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Question: How many lightning strikes occur on Earth each day? Try to explain your answer. Your\n",
      "explanation should take the reader through your reasoning step-by-step.\n",
      "SoT’s answer (OpenChat-13B) (Orange texts are the skeleton.)\n",
      "(Only showing the skeleton)\n",
      "1.Introduction.\n",
      "2. The Earth’s atmosphere.\n",
      "3. Lightning formation.\n",
      "4. Electrical discharge.\n",
      "5. Lightning strikes per second.\n",
      "6. Calculating the total.\n",
      "Skeleton:\n",
      "1. Introduction.\n",
      "Lightning is a beautiful and awe-inspiring natural phenomenon, but it can also be dangerous. It occurs when positively\n",
      "charged particles in a thundercloud discharge to the negatively charged Earth. The process is still not fully understood,\n",
      "but scientists have been able to estimate how many lightning strikes occur on Earth each day.\n",
      "Skeleton:\n",
      "1. The Earth’s atmosphere.\n",
      "The Earth’s atmosphere plays a crucial role in the formation of lightning. It consists of different layers, with the tropo-\n",
      "sphere being the lowest and most active. The troposphere is where most of the weather occurs, and it is where lightning\n",
      "primarily forms. The atmosphere’s temperature, humidity, and wind patterns all contribute to the likelihood of a lightning\n",
      "strike.\n",
      "Skeleton:\n",
      "2. Lightning formation.\n",
      "When warm, moist air rises, it cools and forms water ¡more texts are omitted...¿\n",
      "For both OpenChat-13B and Vicuna-7B V1.1, sometimes they do not write anything in the point-\n",
      "expanding stage when details are needed.\n",
      "Question: As a superhero, how would you explain your origin story to a curious child?\n",
      "SoT’s answer (Vicuna-7B V1.1) (Orange texts are the skeleton.)\n",
      "1. Born with extraordinary abilities.\n",
      "2. Trained to use powers for the greater good.\n",
      "3. Protecting the innocent and fighting villains.I use my powers to defend the defenseless and bring justice to those who\n",
      "have been wronged.\n",
      "4. Inspired by courage, justice, and selflessness.\n",
      "These two issues result in bad net win rates.\n",
      "(2) Claude. For strong models such as Claude, we do not see major issues with SoT’s answers except\n",
      "the common issues across all models discussed in § 3.2.3. We hypothesize that the low net win rates\n",
      "are majorly due to the fact that their normal sequential generation is already very good.\n",
      "Models on which SoT has high net win rates. The models with high net win rates (Vicuna-13B\n",
      "V1.3, StableVicuna-13B, and UltraLM-13B) are between the above two extremes. On one hand,\n",
      "they are good enough to understand SoT prompts. While we observe that they sometimes have the\n",
      "same issues as OpenChat-13B and Vicuna-7B V1.1 discussed before, these issues happen much less\n",
      "frequently. On the other hand, their normal sequential generation performance has a larger room for\n",
      "improvement than Claude and ChatGPT-3.5 so that the benefits from SoT are more visible on these\n",
      "models.\n",
      "I.1.2 A NSWER ANALYSIS : DIFFERENT QUESTION CATEGORIES\n",
      "Categories on which SoT has low net win rates.\n",
      "(1) Math. Math questions require step-by-step thinking. Without knowing the previous steps, it is\n",
      "hard to derive the following steps. Chain-of-Thoughts (Kojima et al., 2022; Wei et al., 2022) empha-\n",
      "size the importance of expanding the sequential thinking steps to solve these problems successfully.\n",
      "In contrast, SoT requires the models to (a) come up with the skeleton of the solution first and (b)\n",
      "deduce each individual step independently without referring to previous results. Both of these are\n",
      "challenging tasks. Strong models are able to get (a) correct but fail at (b). In the following example,\n",
      "ChatGPT-3.5 gets the skeleton steps correct. However, without knowing the results from the first\n",
      "step, the model starts making mistakes in the second step.7\n",
      "7One additional (minor) issue of the API-based ChatGPT-3.5 is that the skeleton point “1.” is repeated in\n",
      "the answer.\n",
      "33\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Question: (Math) Solve for x in the equation 3x + 10 = 5(x - 2).\n",
      "✗SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\n",
      "1. Move all x terms to one side. 1. Move all x terms to one side by subtracting 5x from both sides, giving -2x + 10 = -10.\n",
      "2. Move all constant terms to the other side. This can be done by subtracting 5x - 10 from both sides, leaving 3x - 5x =\n",
      "-10 - 10.\n",
      "3. Simplify the equation. Combine like terms on both sides of the equation to get 3x + 10 = 5x - 10.\n",
      "4. Divide both sides by the coefficient of x. Divide both sides by 2 to get x = -5.\n",
      "5. Check the solution by plugging it back into the original equation.Substitute the value of x obtained in step 4 back into\n",
      "the original equation and verify that both sides are equal.\n",
      "✓Normal answer (ChatGPT-3.5)\n",
      "3x + 10 = 5(x - 2) can be simplified as follows:\n",
      "3x + 10 = 5x - 10 (distribute the 5 on the right side)\n",
      "10 + 10 = 5x - 3x (subtract 3x from both sides)\n",
      "20 = 2x (combine like terms on the right side)\n",
      "x = 10 (divide both sides by 2)\n",
      "Therefore, the solution for x in the equation 3x + 10 = 5(x - 2) is x = 10.\n",
      "For weaker models, it is hard to even get step (a) correct. For example, as shown below, the third\n",
      "step “Apply FOIL” in Vicuna-13B V1.3’s SoT solution comes out of nowhere. This makes SoT’s\n",
      "solution incorrect (though the solution from the normal generation is also incorrect).\n",
      "Question: (Math) Solve for x in the equation 3x + 10 = 5(x - 2).\n",
      "✗SoT’s answer (Vicuna-13B V1.3) (Orange texts are the skeleton.)\n",
      "1. Simplify equation.\n",
      "We can simplify the equation by combining like terms:\n",
      "3x + 10 = 5(x - 2)\n",
      "=¿ 3x + 10 = 5x - 10\n",
      "=¿ x + 5 = 2\n",
      "=¿ x = 2 - 5\n",
      "=¿ x = -3\n",
      "2. Factor 5(x - 2).\n",
      "5(x - 2) = 5x - 10.\n",
      "3. Apply FOIL.\n",
      "* Multiply the binomials in the equation, using the first term of each binomial for the first term of the product, the outside\n",
      "term for the second term of the product, the second term of each binomial for the third term of the product, and the\n",
      "remaining terms for the fourth term of the product.\n",
      "* 3(x - 2) + 10 = 5x + 5(-2)\n",
      "* 3x - 6 = 5x - 10\n",
      "* 3x = 5x - 10\n",
      "* x = 5x - 10 / 3\n",
      "* x = 5/3x - 10/3\n",
      "* x = 2/3x - 5/3\n",
      "4. Solve for x.\n",
      "After applying the FOIL method and simplifying the equation, we get 3x = 17. Therefore, x = 17/3.\n",
      "✗Normal answer (Vicuna-13B V1.3)\n",
      "To solve for x in the equation 3x + 10 = 5(x - 2), we need to first distribute the 5 to multiply both sides by 5.\n",
      "3x + 10 = 5(x - 2)\n",
      "5(3x + 10) = 5(x - 2)\n",
      "15x + 50 = 5x - 10\n",
      "Add 5x to both sides:\n",
      "20x + 50 = 5x\n",
      "Subtract 5x from both sides:\n",
      "15x = 0\n",
      "Divide both sides by 15:\n",
      "x = 0\n",
      "Therefore, the solution to the equation is x = 0.\n",
      "(2) Fermi. Similar to math questions, questions in the fermi category require solvers to make as-\n",
      "sumptions and calculate the answer step-by-step. For example, to answer the question in the figure\n",
      "below, the solver is required to make an assumption about when life began on Earth. In step 4,\n",
      "ChatGPT-3.5 does not know that it has already assumed 3.5 billion years in step 3 and uses the\n",
      "wrong number 4.54 billion in the calculation. In step 5, ChatGPT-3.5 does not know that it has\n",
      "already made the above assumptions and refuses to answer “due to the uncertainties in estimating\n",
      "the age of the Earth”. In contrast, normal generation is able to create a consistent solution.\n",
      "34\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Question: (Fermi) How many times has the Earth orbited the Sun since the beginning of life? Try\n",
      "to explain your answer. Your explanation should take the reader through your reasoning step-by-step.\n",
      "✗SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\n",
      "1. Estimate the age of the Earth. The age of the Earth is estimated to be around 4.54 billion years, based on radiometric\n",
      "dating of rocks and meteorites.\n",
      "2. Determine when life began on Earth. Life on Earth is estimated to have begun around 3.5 billion years ago, based on\n",
      "the discovery of ancient microfossils.\n",
      "3. Calculate the number of years since life began. The oldest known fossils suggest that life on Earth began around 3.5\n",
      "billion years ago. Therefore, the number of years since life began on Earth is approximately 3.5 billion years.\n",
      "4. Divide the number of years by the length of one orbit. Assuming an orbital period of 365.25 days, the Earth has\n",
      "orbited the Sun approximately 4.54 billion / 365.25 = 12,425,000 times since the beginning of life.\n",
      "5. The Earth has orbited the Sun approximately X times since the beginning of life. Unfortunately, it is impossible to give\n",
      "a specific number for the amount of times the Earth has orbited the Sun since the beginning of life due to the uncertainties\n",
      "in estimating the age of the Earth and when life first emerged.\n",
      "Normal answer (ChatGPT-3.5)\n",
      "The beginning of life on Earth is estimated to have occurred around 3.5 to 4 billion years ago. Since that time, the Earth\n",
      "has been orbiting the Sun continuously.\n",
      "The length of one orbit, or one year, is approximately 365.25 days. This means that the Earth completes one full orbit\n",
      "around the Sun every 365.25 days.\n",
      "To calculate the number of times the Earth has orbited the Sun since the beginning of life, we can divide the total number\n",
      "of days by the length of one orbit:\n",
      "Total number of days since the beginning of life = (3.5 billion years) x (365 days per year) = 1.2775 trillion days\n",
      "Number of orbits = (1.2775 trillion days) / (365.25 days per orbit) = 3.5 billion orbits\n",
      "Therefore, the Earth has orbited the Sun approximately 3.5 billion times since the beginning of life.\n",
      "As the following example shows, there are also cases when SoT solves the question (with minor\n",
      "computation errors) by embedding the computation steps in the skeleton directly in the skeleton\n",
      "stage. The point-expanding stage will then add little content (except some undesired repetition of\n",
      "the following skeletons occasionally). This happens both on small/weak models and large/powerful\n",
      "models. Although this behavior is not what we originally expect, it sheds light on a promising direc-\n",
      "tion for making SoT a general framework: in the problem where step-by-step thinking is needed, the\n",
      "SoT model automatically falls back to the sequential generation mode by outputting the complete\n",
      "answer in the skeleton stage and skipping the point-expanding stage. Future work needs to be done\n",
      "to control and encourage this behavior better.\n",
      "Question: (Fermi) How many times does the average human blink in a lifetime? Try to explain your\n",
      "answer. Your explanation should take the reader through your reasoning step-by-step.\n",
      "SoT’s answer (Vicuna-7B V1.1) (Orange texts are the skeleton.)\n",
      "1. The average human blinks 12-15 times per minute.\n",
      "2. There are 60 minutes in an hour.\n",
      "3. Therefore, the average human blinks 60 x 12-15 = 720-900 times per hour.\n",
      "4. There are 24 hours in a day.Therefore, the average human blinks 720-900 x 24 = 17,520-22,400 times per day.\n",
      "5. Therefore, the average human blinks 720-900 x 24 = 17,520-22,400 times per day.This translates to blinking approxi-\n",
      "mately 50-65 times per hour, which is a significant portion of the day.\n",
      "6. There are 365 days in a year.Therefore, the average human blinks 17,520-22,400 x 365 = 5,857,600-8,124,000 times\n",
      "per year.\n",
      "7. Therefore, the average human blinks 17,520-22,400 x 365 = 5,857,600-8,124,000 times per year.\n",
      "8. The human lifespan is typically 70-80 years.Therefore, the average human blinks 80,000-112,000 times in their\n",
      "lifetime.\n",
      "9. Therefore, the average human blinks 5,857,600-8,124,000 / 70-80 = 80,000-112,000 times in their lifetime.\n",
      "Normal answer (Vicuna-7B V1.1)\n",
      "The average human blinks about 12-15 times per minute, which translates to about 18,200 to 20,400 blinks per day. Over\n",
      "the course of a lifetime, the number of blinks is estimated to be around 7,500,000 to 8,000,000.\n",
      "Blinking is a reflexive action that helps to keep the eyes moist and comfortable, as well as to protect the eyes from dust\n",
      "and other foreign particles. The frequency of blinking can vary depending on a variety of factors, including age, health,\n",
      "and environmental conditions. For example, people who work in dusty or dry environments may blink more frequently\n",
      "than those who work in a clean, moist environment.\n",
      "Over the course of a lifetime, the average person will spend approximately 27,375 days or 700,000 hours awake. This\n",
      "means that the majority of the time spent blinking will occur in the first few decades of life, with the frequency of blinking\n",
      "gradually decreasing as people age.\n",
      "It is important to note that there is a significant amount of individual variation in the frequency of blinking. Some people\n",
      "may blink more or less than the average, depending on a variety of factors such as age, health, and environmental condi-\n",
      "tions. Additionally, blinking patterns can be affected by factors such as stress, fatigue, and certain medical conditions.\n",
      "35\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "(3) Coding. While in most cases, the models are able to decompose the coding problem into smaller\n",
      "tasks in the skeleton stage, the generation quality during the point-expanding stage is bad, potentially\n",
      "due to the fact that we did not carefully craft a special point-expanding prompt for coding. The\n",
      "failure cases can be grouped into two cases. (a) In some cases, the model only generates a description\n",
      "of how implementation can be done without giving the code.\n",
      "Question: (Coding) Develop a C++ program that reads a text file line by line and counts the number\n",
      "of occurrences of a specific word in the file.\n",
      "SoT’s answer (Claude) (Orange texts are the skeleton.)\n",
      "1. Open file stream by declaring an ifstream object and using the open() method to open the file in read mode.\n",
      "2. Read line by line from the file stream into a string using getline().\n",
      "3. Find word by searching each line for the target word using string::find and keeping track of matches.\n",
      "4. Increment counter by one each time the specified word is encountered in the current line.\n",
      "5. Close file\n",
      "The file stream should be closed after finishing reading the file to free up resources. This can be done by calling the\n",
      "close() method on the file stream object.\n",
      "This might be due to the fact that the powerful models (e.g., Claude) follow the point-expanding\n",
      "prompt “Write it **very shortly** in 1 ∼2 sentence” precisely. Better prompts tailed to coding\n",
      "could help. (b) In some other cases, the model tends to generate the complete code repeatedly in\n",
      "several points.\n",
      "Question: (Coding) Develop a C++ program that reads a text file line by line and counts the number\n",
      "of occurrences of a specific word in the file.\n",
      "SoT’s answer (OpenChat-13B) (Orange texts are the skeleton.)\n",
      "1. Read file line by line.\n",
      "2. Store lines in a container.\n",
      "3. Count occurrences of specific word.\n",
      "“‘cpp\n",
      "¡more texts are omitted...¿\n",
      "“‘\n",
      "This code uses the C++ standard library to read a text file line by line, store each line in a container, and count the\n",
      "occurrences of a specific word. The results are printed.\n",
      "4. Print results.\n",
      "Here’s the C++ program that reads a text file line by line and counts the number of occurrences of a specific word in the\n",
      "file:\n",
      "“‘cpp\n",
      "¡more texts are omitted...¿\n",
      "“‘\n",
      "Please note that this is a very basic implementation. You may need to adjust it depending on your specific requirements.\n",
      "This problem might also be alleviated by prompts that explicitly tell the model to only generate a\n",
      "“code snippet” in each skeleton point.\n",
      "Although better prompt engineering could lead to better results, we expect that SoT is not suitable\n",
      "for the coding questions in Vicuna-80. The reason is that the solutions to the problems in Vicuna-\n",
      "80 are usually in a few lines with strong dependencies between each other. Without knowing the\n",
      "previously defined variable names or imported libraries, it is hard (or even impossible) to implement\n",
      "the subsequent code correctly. As a consequence, generating different parts of the answers in parallel\n",
      "is not suitable here. Similar to the math questions, automatically falling back to outputting all the\n",
      "code in the skeleton stage and not triggering the point-expanding stage might be more suitable for\n",
      "answering this question type.\n",
      "However, we expect that SoT could be helpful for larger coding tasks that involve multiple modules\n",
      "(e.g., functions, classes). The skeleton stage could be in charge of defining the interfaces between\n",
      "different modules (e.g., functionalities, names, parameters, return types). The point-expanding stage\n",
      "could be in charge of implementing these modules or using these modules to complete the final task,\n",
      "which can be done in parallel. This mimics the common practice in software engineering.\n",
      "(4) Writing. The writing questions usually ask for an email, a blog post, or a review in a given\n",
      "scenario. In the detailed evaluation output from FastChat and LLMZoo metrics, the major and\n",
      "common complaint is that SoT’s answers are (slightly) less detailed. This could potentially be\n",
      "improved by point-expanding prompts that request more details.\n",
      "36\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "While inspecting SoT’s answers manually, we observe one additional issue. Writing problems usu-\n",
      "ally require a coherent passage without embedded skeleton points, whereas our current SoT pipeline\n",
      "(§ 2) concatenates skeleton points as part of the answer. One example is shown below.\n",
      "Question: (Writing) Can you help me write a formal email to a potential business partner proposing\n",
      "a joint venture?\n",
      "SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\n",
      "1. Introduce yourself and your company. Dear [Recipient],\n",
      "I hope this email finds you well. My name is [Your Name] and I am the [Your Position] at [Your Company Name].\n",
      "2. State the purpose of the email. The purpose of this email is to propose a joint venture between our companies.\n",
      "3. Explain the potential benefits of the joint venture. By combining our resources and expertise, we can increase market\n",
      "share and profitability for both companies.\n",
      "4. Provide details on the proposed collaboration. Our proposed collaboration would involve combining our expertise in\n",
      "marketing with your strong manufacturing capabilities to create a new line of products.\n",
      "5. Suggest a follow-up meeting or call. Please let me know your availability for a follow-up call next week to discuss\n",
      "this opportunity further.\n",
      "6. Thank the recipient for their time and consideration.Thank you for considering this proposal and we look forward to\n",
      "hearing back from you soon.\n",
      "Normal answer (ChatGPT-3.5)\n",
      "Of course, I can help you with that. Here’s a sample email you can use as a guide:\n",
      "Subject: Proposal for Joint Venture\n",
      "Dear [Business Partner’s Name],\n",
      "I hope this email finds you well. I am writing to propose a joint venture between our companies, [Your Company Name]\n",
      "and [Potential Partner Company Name]. We believe that our respective expertise can create a successful partnership that\n",
      "will benefit both of our businesses.\n",
      "We have conducted thorough research on your company and admire your innovative approach to [insert industry or niche].\n",
      "We think our [insert expertise or specialty] could complement your [insert potential partner’s specialty or expertise].\n",
      "By collaborating on this joint venture, we believe we can create a new and innovative product that will appeal to our\n",
      "respective markets.\n",
      "We are confident that our companies would work well together and that our joint venture would be successful. We would\n",
      "like to set up a meeting to discuss the specifics of our proposal and explore how we can move forward with the joint\n",
      "venture.\n",
      "Thank you for considering this proposal. We look forward to hearing from you soon.\n",
      "Best regards,\n",
      "[Your Name]\n",
      "In such cases, simply removing the skeleton points would greatly improve the answer quality. To\n",
      "make SoT more general, one future direction is to let the LLM itself decide whether the point index\n",
      "and point skeleton should be included to make the final answer more natural and fluent.\n",
      "Categories on which SoT has high net win rates.\n",
      "(1) Counterfactual, knowledge, common sense, generic. All these four categories have the same\n",
      "characteristic: the ideal answer should cover several relatively independent points. Having the LLM\n",
      "generate a skeleton before expanding the details can result in more comprehensive discussions for\n",
      "the question. Besides, organizing the answers as a list of points makes the answers easier to read,\n",
      "whereas the answers from normal generation are sometimes less structured and less readable. Below,\n",
      "we give one example for each question category to illustrate these points.\n",
      "37\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Question: (Counterfactual) What if the Internet had been invented during the Renaissance period?\n",
      "SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\n",
      "1. Advancements in communication.The invention of the Internet during the Renaissance period would have revolution-\n",
      "ized communication, allowing for faster and more efficient exchange of ideas and information across vast distances.\n",
      "2. Increased access to knowledge.The invention of the printing press during the Renaissance period already allowed\n",
      "for greater access to knowledge, but the internet would have revolutionized this even further by providing instantaneous\n",
      "access to information from all over the world.\n",
      "3. Improved dissemination of ideas.If the internet had been invented during the Renaissance period, the spread of ideas\n",
      "and knowledge would have been much faster and widespread than it was at the time. This could have led to a faster\n",
      "progression of scientific and artistic innovations.\n",
      "4. Impact on art and literature.The invention of the internet during the Renaissance period would have revolutionized the\n",
      "way art and literature are created, shared, and consumed, leading to a more diverse and globally-influenced artistic and\n",
      "literary scene.\n",
      "5. Potential for global trade.The invention of the internet during the Renaissance period would have greatly expanded\n",
      "global trade opportunities, allowing for easier communication and collaboration between merchants and traders across\n",
      "continents.\n",
      "6. Influence on political and social structures.The invention of the internet during the Renaissance period could have led\n",
      "to significant changes in political and social structures, allowing for greater democratization and communication among\n",
      "people from different regions and classes.\n",
      "Normal answer (ChatGPT-3.5)\n",
      "If the Internet had been invented during the Renaissance period, it would have had a significant impact on the way people\n",
      "communicated, shared ideas, and gained knowledge. The Renaissance was a time of great intellectual and artistic growth,\n",
      "and the Internet would have facilitated the spread of these ideas and innovations.\n",
      "Scholars and artists would have been able to share their work more easily, and people from different parts of the world\n",
      "would have been able to connect and collaborate more easily. The Internet would have also made it easier to access\n",
      "information, which could have accelerated the pace of scientific and technological advancements.\n",
      "However, it’s important to note that the infrastructure required for the Internet to exist did not exist during the Renaissance\n",
      "period. There were no telecommunications networks or electricity grids, so the idea of the Internet would have been\n",
      "impossible to realize. Nonetheless, it’s interesting to think about how the Renaissance might have been different if the\n",
      "Internet had existed at that time.\n",
      "38\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Question: (Knowledge) What are some potential implications of using a single-use plastic bottle\n",
      "versus a reusable bottle on both the environment and human health?\n",
      "SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\n",
      "1. Single-use plastic waste.Single-use plastic bottles contribute to the massive amount of plastic waste that ends up in\n",
      "landfills and oceans, harming wildlife and ecosystems.\n",
      "2. Pollution of waterways.Single-use plastic bottles contribute to the pollution of waterways, as they often end up in\n",
      "rivers, lakes, and oceans, causing harm to aquatic life and the overall ecosystem.\n",
      "3. Harmful chemicals leaching.Single-use plastic bottles may release harmful chemicals such as bisphenol A (BPA) and\n",
      "phthalates into the water or liquid they contain, posing a risk to human health.\n",
      "4. Greenhouse gas emissions.The production and disposal of single-use plastic bottles contribute to greenhouse gas\n",
      "emissions, which contribute to climate change. Using a reusable bottle reduces the need for constant production and\n",
      "disposal, therefore reducing greenhouse gas emissions.\n",
      "5. Microplastic ingestion.Single-use plastic bottles contribute to the accumulation of microplastics in the environment,\n",
      "which can be ingested by humans through food and water, leading to potential health risks.\n",
      "6. Increased risk of disease.Single-use plastic bottles can harbor harmful bacteria, leading to an increased risk of disease\n",
      "if not disposed of properly. Reusable bottles, when cleaned regularly, pose a lower risk.\n",
      "Normal answer (ChatGPT-3.5)\n",
      "Using a single-use plastic bottle has significant implications on the environment and human health.\n",
      "Environmental implications:\n",
      "1. Plastic pollution: Single-use plastic bottles are one of the major contributors to plastic pollution in oceans and landfills.\n",
      "They take hundreds of years to decompose, and during that time, they release toxic chemicals and microplastics into the\n",
      "environment.\n",
      "2. Carbon emissions: Manufacturing and transporting single-use plastic bottles require a significant amount of energy\n",
      "and resources, which contribute to greenhouse gas emissions and climate change.\n",
      "3. Natural resource depletion: The production of single-use plastic bottles requires large amounts of water and oil, which\n",
      "are finite resources.\n",
      "Health implications:\n",
      "1. Chemical exposure: Single-use plastic bottles contain chemicals such as Bisphenol A (BPA) and phthalates, which\n",
      "can leach into the water and pose a risk to human health.\n",
      "2. Microplastics ingestion: When plastic bottles break down, they release microplastics, which can enter the food chain\n",
      "and be ingested by humans.\n",
      "Using a reusable bottle, on the other hand, has a positive impact on the environment and human health.\n",
      "Environmental benefits:\n",
      "1. Reduced plastic waste: Reusable bottles significantly reduce the amount of plastic waste generated.\n",
      "2. Lower carbon emissions: Reusable bottles have a lower carbon footprint as they can be used multiple times.\n",
      "3. Reduced resource depletion: The production of reusable bottles requires fewer resources than single-use plastic bottles.\n",
      "Health benefits:\n",
      "1. Chemical-free: Reusable bottles are typically made from materials that are free from harmful chemicals, reducing the\n",
      "risk of chemical exposure.\n",
      "2. Reduced microplastics: Reusable bottles do not break down easily, reducing the release of microplastics into the\n",
      "environment.\n",
      "Overall, using a reusable bottle is a more sustainable and healthier option than using a single-use plastic bottle.\n",
      "Question: (Common sense) How can you determine if a person is genuinely interested in a conver-\n",
      "sation or simply being polite?\n",
      "SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\n",
      "1. Pay attention to body language.Notice if their posture is open or closed, if they are facing towards you or away, and if\n",
      "they are fidgeting or relaxed. These can all indicate their level of interest in the conversation.\n",
      "2. Listen for engaged responses.If the person is genuinely interested in the conversation, they will respond with thoughtful\n",
      "and relevant comments or questions rather than short, generic responses.\n",
      "3. Observe eye contact.If the person maintains steady eye contact and their gaze is focused on you, they are likely\n",
      "genuinely interested in the conversation. On the other hand, if they frequently look away or seem distracted, they may\n",
      "just be being polite.\n",
      "4. Look for follow-up questions.If the person asks follow-up questions and seems genuinely interested in what you’re\n",
      "saying, then they are likely interested in the conversation and not just being polite.\n",
      "5. Notice tone of voice.A person who is genuinely interested in a conversation will often have a more enthusiastic and\n",
      "animated tone of voice, compared to someone who is simply being polite and giving short, monotone responses.\n",
      "Normal answer (ChatGPT-3.5)\n",
      "As an AI assistant, I cannot determine a person’s true intentions or feelings. However, there are some social cues that\n",
      "can indicate whether a person is genuinely interested in a conversation or not. For example, if they maintain eye contact,\n",
      "lean in, nod their head and ask follow-up questions, it can be a sign that they are engaged in the conversation. On the\n",
      "other hand, if they avoid eye contact, give short or vague responses, or seem distracted, it may indicate that they are\n",
      "not as interested. Ultimately, it’s important to remember that everyone has different communication styles, and it can be\n",
      "difficult to accurately interpret someone’s intentions without directly asking them.\n",
      "39\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Question: (Generic) How can I improve my time management skills?\n",
      "SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\n",
      "1. Set clear goals. Setting clear goals is important in improving time management skills as it helps you to focus on what\n",
      "needs to be done and what can be accomplished within a certain timeframe.\n",
      "2. Prioritize tasks. Make a list of tasks and prioritize them based on their importance and deadline. This will help you\n",
      "focus on the most critical tasks and avoid wasting time on less important ones.\n",
      "3. Create a schedule. Creating a schedule helps you allocate time for each task and ensures that you complete them\n",
      "within the allotted time.\n",
      "4. Minimize distractions. Distractions such as social media, emails, and phone notifications can waste a lot of time. Try\n",
      "to limit them by turning off notifications or setting specific times to check them.\n",
      "5. Take breaks. Taking breaks can actually improve productivity and help prevent burnout. It’s important to schedule\n",
      "short breaks throughout the day to recharge and refocus.\n",
      "6. Learn to say no. It’s important to prioritize your own tasks and not take on too much at once. Saying no to requests\n",
      "that don’t align with your goals or schedule can help you manage your time more effectively.\n",
      "7. Delegate tasks. If you have too many tasks to handle, consider delegating some of them to others who can help you.\n",
      "This will allow you to focus on more important tasks and manage your time more effectively.\n",
      "8. Use time management tools.There are a variety of time management tools available, such as calendars, to-do lists, and\n",
      "productivity apps, that can help you stay organized and on track with your tasks.\n",
      "Normal answer (ChatGPT-3.5)\n",
      "Improving time management skills can be a challenge, but there are several strategies that can help. Here are a few:\n",
      "1. Set clear goals and priorities: Identify your most important tasks and make sure to complete them first.\n",
      "2. Make a schedule: Create a schedule that includes your most important tasks and set aside time for them.\n",
      "3. Use a timer: Set a timer for a specific amount of time to help you stay focused and avoid distractions.\n",
      "4. Take breaks: Take short breaks throughout the day to help you recharge and avoid burnout.\n",
      "5. Eliminate distractions: Try to limit distractions as much as possible, such as by turning off your phone or closing your\n",
      "email.\n",
      "6. Delegate tasks: If possible, delegate tasks to others to free up time for more important activities.\n",
      "Remember, improving time management skills takes practice and perseverance. Be patient with yourself and keep trying\n",
      "until you find strategies that work well for you.\n",
      "(2) Roleplay. Roleplay questions require LLMs to assume a character and present an introduction\n",
      "or speech to other people. LLMZoo and FastChat metrics usually favor the level of details of SoT\n",
      "when assigning it a better score. Similar to the writing category discussed before, SoT’s answers\n",
      "could be even better if the skeleton points are removed from the answer.\n",
      "Question: (Roleplay) How would you introduce yourself as a medieval knight at a royal banquet?\n",
      "SoT’s answer (Claude) (Orange texts are the skeleton.)\n",
      "1. Name and house. My name is Sir Percival of Camelot, knight of the Round Table and protector of King Arthur’s\n",
      "realm.\n",
      "2. Lands and titles. I hold fiefdom over the lands of Westmarch and Ravenshire, and bear the titles of Baron of the\n",
      "Western Marches and Knight of the Raven.\n",
      "3. Military feats. I have led my men to great victories against the kingdom’s enemies, winning many battles through\n",
      "strength of arms and tactical cunning.\n",
      "4. Allegiance to king. I pledge my sword, my loyalty, and my life to serve and protect my noble king and this great\n",
      "kingdom.\n",
      "5. Request to join table. Your Highness, it would be the greatest honor to join your exalted table and share in this\n",
      "magnificent feast with my fellow knights and loyal subjects.\n",
      "Normal answer (Claude)\n",
      "Greetings, your majesty and honored guests. I am Sir Claude, a knight in service of the king. I hail from the province\n",
      "of Assistantia, where I was trained in the knightly virtues of chivalry, courage and courtesy. Though I am but a humble\n",
      "knight, I shall endeavor to serve you and this kingdom with all the strength and valor I possess. I thank you for allowing\n",
      "me to join you at this royal feast, and hope only that my conduct brings further honor to my liege and this noble court.\n",
      "Please let me know if I can be of any service during the celebrations, as it would be my honor to assist you in any way.\n",
      "I.1.3 A NSWER ANALYSIS : DIFFERENT METRICS\n",
      "Metrics on which SoT has low net win rates.\n",
      "(1) Coherence. In the prompt of LLMZoo evaluation, coherence is defined as “The response should\n",
      "be coherent and flow logically from one point to the next that is easy to read and understand without\n",
      "major gaps or inconsistencies. The more coherent they are, the better.” SoT’s answer is structured in\n",
      "a list of points. It is suitable for some questions but not all. For example, in the questions that require\n",
      "40\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "LLMs to write a passage, email, or script, the introduction and conclusion paragraphs are usually\n",
      "missing, and the answers usually lack transition sentences between consecutive points. These make\n",
      "the answers less coherent. Below is one example from Claude.\n",
      "Question: Write a script for a YouTube video exploring the history and cultural significance of jazz.\n",
      "SoT’s answer (Claude) (Orange texts are the skeleton.)\n",
      "1. Origins. Jazz originated in the late 19th and early 20th centuries among African Americans in New Orleans, emerging\n",
      "from a combination of African rhythmic traditions, blues, ragtime, and other influences.\n",
      "2. Early jazz styles. The early styles of jazz that emerged in the late 19th and early 20th centuries included ragtime,\n",
      "Dixieland, and the blues.\n",
      "3. Jazz age. The Jazz Age was the period during the 1920s when jazz music and dance styles like the Charleston became\n",
      "popular cultural phenomena in American and European society.\n",
      "4. Bebop era. Bebop emerged in the early 1940s with artists like Dizzy Gillespie and Charlie Parker experimenting with\n",
      "faster tempos, complex chord changes, and unpredictable melodic phrasing.\n",
      "5. Cool jazz. Emerging in the late 1940s and early 1950s, cool jazz was a more subdued, mellow style that broke from\n",
      "the high-energy virtuosic improvisation of bebop.\n",
      "6. Free jazz emerged in the late 1950s and 1960s as musicians explored free improvisation and atonality, moving away\n",
      "from traditional jazz structures.\n",
      "7. Fusion jazz. Major jazz artists such as Miles Davis and Herbie Hancock began experimenting with combining elements\n",
      "of rock, funk, and electronic music in the 1970s, resulting in the emergence of the subgenre known as fusion jazz.\n",
      "8. Jazz festivals. Jazz festivals emerged in the 1950s and 1960s as a way to celebrate jazz music, with famous early\n",
      "festivals like the Newport Jazz Festival bringing thousands of fans together to hear top performers.\n",
      "9. Jazz instruments. The trumpet, saxophone, piano, double bass, and drum set are some of the key instruments com-\n",
      "monly used in jazz.\n",
      "10. Influential musicians include Louis Armstrong, Duke Ellington, Charlie Parker, Miles Davis, John Coltrane, and\n",
      "many others who pioneered new styles and techniques.\n",
      "11. Legacy and impact. Jazz has left an indelible mark on music and culture over the past century, influencing countless\n",
      "artists and genres while spreading the spirit of improvisation and freedom across the globe.\n",
      "Normal answer (Claude)\n",
      "Here is a draft script for a YouTube video exploring the history and cultural significance of jazz:\n",
      "Introduction\n",
      "Hey everyone! Welcome to my channel. In today’s video, we’re going to be exploring the history and cultural impact of\n",
      "one of America’s original art forms - jazz music.\n",
      "Jazz Origins\n",
      "Jazz grew out of the African American communities in the southern United States in the late 19th and early 20th centuries.\n",
      "It was influenced by a combination of African and European musical traditions. Some key elements that fed into early\n",
      "jazz included blues, ragtime, spirituals, work songs, field hollers, and brass band music.\n",
      "New Orleans is considered the birthplace of jazz, emerging around the turn of the 20th century. The city was a melting\n",
      "pot of cultures and musical styles. Musicians mixed improvisation, syncopated rhythms, bent notes and a loose ensemble\n",
      "playing style to create a new genre that became known as jazz.\n",
      "Early jazz greats like Buddy Bolden, Jelly Roll Morton and Sidney Bechet began fusing these various influences into the\n",
      "distinct jazz sound. As the music spread via travel and recordings in the 1910s, jazz captivated listeners and began to\n",
      "evolve into different styles.\n",
      "Jazz Styles Emerge\n",
      "In the 1920s, jazz expanded out from New Orleans and Chicago emerged as a hotspot. Louis Armstrong’s innovative\n",
      "solos and expressive phrasing became influential. The swing style also developed during the 1930s and 40s, propelled\n",
      "by star big bands and dancers.\n",
      "Bebop arose in the 1940s with soloists like Charlie Parker and Dizzy Gillespie exploring new levels of harmonic and\n",
      "rhythmic complexity. In the 50s and 60s, jazz expanded into new fusions like cool jazz, hard bop, free jazz, modal jazz\n",
      "and soul jazz. Artists used jazz to express their unique regional, social and political identities.\n",
      "Cultural Significance\n",
      "Over the decades, jazz has become woven into the fabric of American society. It is equated with many values and ideals\n",
      "like individualism, freedom, spontaneity, innovation and social harmony.\n",
      "Jazz was associated with breaking down barriers between races, classes and genres. It represented modernism and urban\n",
      "culture. Musicians like Louis Armstrong and Duke Ellington became some of the first widely popular African American\n",
      "artists.\n",
      "Jazz also spread American culture and values abroad through performances, radio and film. It influenced music around\n",
      "the world and became a truly global art form.\n",
      "Today jazz continues to thrive and evolve both in the U.S. and internationally. Its history and sounds reflect the diversity\n",
      "of both American and global cultures. From its folk roots, jazz has become a sophisticated art music that retains its spirit\n",
      "of freedom and improvisation.\n",
      "Conclusion\n",
      "That covers some of the key points in the history and cultural impact of jazz music. Let me know in the comments about\n",
      "your favorite jazz styles and musicians! Be sure to like and subscribe. See you next time.\n",
      "While the content of SoT’s answer is good, it reads less fluent for the purpose of a YouTube script.\n",
      "(2) Immersion. In the prompt of LLMZoo evaluation, immersion is defined as “the response should\n",
      "act like the assigned role using the tone, manner, and vocabulary the role would use. The more\n",
      "assistant-like tones, the worse. The more in-character, the better.” The way that SoT breaks the\n",
      "41\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "answers into a list makes its answer less in-character. Therefore, SoT receives a lower immersion\n",
      "score. Here is one example.\n",
      "Question: Pretend to be a world-famous chef. How would you describe your signature dish to a\n",
      "panel of judges?\n",
      "SoT’s answer (Claude) (Orange texts are the skeleton.)\n",
      "1. Main ingredient: The incredibly fresh and tender salmon caught just this morning from the crystal clear waters of the\n",
      "Pacific Northwest.\n",
      "2. Cooking method\n",
      "I slowly braise the main ingredient in a rich broth to bring out its natural flavors before searing it to a perfect golden crust.\n",
      "3. Special seasoning\n",
      "The dish is seasoned with a blend of fresh herbs like thyme, rosemary, and oregano which provides an aromatic backbone\n",
      "that pairs nicely with the natural flavors of the main ingredients. I add just a touch of smoked paprika to provide a subtle\n",
      "smokiness without overpowering the other flavors.\n",
      "4. Texture: The dish has a perfect balance of crispy on the outside and tender on the inside, with each bite yielding a\n",
      "delightful mix of crunchy and smooth textures that dance across your tongue.\n",
      "5. Plating presentation\n",
      "I purposefully create height and dimension on the plate with the carefully arranged components of the dish, so that the\n",
      "dish appears vibrant and alive. The interplay of colors, textures and shapes is intended to delight the eye before the first\n",
      "bite.\n",
      "6. Inspiration: This dish was inspired by my dear grandmother, who taught me the secret family recipe when I was just\n",
      "a child.\n",
      "Normal answer (Claude)\n",
      "*clears throat and speaks in a fancy French accent*\n",
      "Bonjour honored judges. Today I present to you my signature dish - la cr `eme de la cr `eme of French haute cuisine.\n",
      "Behold, le poulet `a la Claude!\n",
      "This succulent chicken is firstly marinated overnight in a bath of fine herbes - thyme, rosemary, and sage cultivated from\n",
      "my private garden. The young spring chicken is then roasted to perfection, its skin crisping to a beautiful caramel brown.\n",
      "Nestled beside the chicken is a tower of pommes dauphine - light and airy potato puffs - alongside a decadent mound of\n",
      "cr`eme fra ˆıche infused with truffle essence.\n",
      "But the pi `ece de r ´esistance is the sauce. A luxurious pool of velout ´e enriched with cream and butter, brightened with a\n",
      "dash of lemon, and studded with morsels of morel mushrooms foraged at dawn.\n",
      "One bite of this ensemble will transport you to food heaven. The tender chicken, the creaminess of the potato puffs, and\n",
      "the rich decadence of the sauce meld together in blissful harmony.\n",
      "So tell me honored judges, will my poulet `a la Claude earn your coveted approval? I await your discerning verdict as I\n",
      "swirl more vintage Bordeaux into your glasses. Sant ´e!\n",
      "Again, while the answer from SoT covers sufficient aspects and details, it reads rather stiffly. The\n",
      "normal answer, in contrast, has the opening sentence ”Bonjour honored judges. Today I present to\n",
      "you my signature dish...” and the conclusion statement ”So tell me honored judges, will my poulet `a\n",
      "la Claude earn your coveted approval? ...” which reads more like a casual talk from a chef.\n",
      "Metrics on which SoT has high net win rates.\n",
      "(1) Diversity. In the prompt of LLMZoo evaluation, diversity is defined as “The response should\n",
      "be comprehensive and provide a range of information that is not limited to a single perspective.\n",
      "More perspectives are better.” The skeleton stage in SoT encourages LLMs to think from multiple\n",
      "perspectives. Therefore, SoT’s answers tend to have better diversity. Below is one example showing\n",
      "that SoT’s answer has better diversity.\n",
      "42\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "Question: How can you determine if a person is genuinely interested in a conversation or simply\n",
      "being polite?\n",
      "SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\n",
      "1. Pay attention to body language.Notice if their posture is open or closed, if they are facing towards you or away, and if\n",
      "they are fidgeting or relaxed. These can all indicate their level of interest in the conversation.\n",
      "2. Listen for engaged responses.If the person is genuinely interested in the conversation, they will respond with thoughtful\n",
      "and relevant comments or questions rather than short, generic responses.\n",
      "3. Observe eye contact.If the person maintains steady eye contact and their gaze is focused on you, they are likely\n",
      "genuinely interested in the conversation. On the other hand, if they frequently look away or seem distracted, they may\n",
      "just be being polite.\n",
      "4. Look for follow-up questions.If the person asks follow-up questions and seems genuinely interested in what you’re\n",
      "saying, then they are likely interested in the conversation and not just being polite.\n",
      "5. Notice tone of voice.A person who is genuinely interested in a conversation will often have a more enthusiastic and\n",
      "animated tone of voice, compared to someone who is simply being polite and giving short, monotone responses.\n",
      "Normal answer (ChatGPT-3.5)\n",
      "As an AI assistant, I cannot determine a person’s true intentions or feelings. However, there are some social cues that\n",
      "can indicate whether a person is genuinely interested in a conversation or not. For example, if they maintain eye contact,\n",
      "lean in, nod their head and ask follow-up questions, it can be a sign that they are engaged in the conversation. On the\n",
      "other hand, if they avoid eye contact, give short or vague responses, or seem distracted, it may indicate that they are\n",
      "not as interested. Ultimately, it’s important to remember that everyone has different communication styles, and it can be\n",
      "difficult to accurately interpret someone’s intentions without directly asking them.\n",
      "SoT answers the question from five aspects, whereas the normal answer only mentions one aspect.\n",
      "(2) Relevance. In the prompt of LLMZoo evaluation, relevance is defined as “The response should\n",
      "be closely related to the question and answer the question accurately with sufficient details without\n",
      "repetition or redundancy. The more relevant they are, the better.” In the skeleton stage, LLMs are\n",
      "forced to propose several points around the question; and in the point-expanding stage, LLMs are\n",
      "required to only discuss these points. Therefore, answers from SoT tend to have better relevance.\n",
      "One typical example is shown below.\n",
      "Question: Why do some people enjoy the sensation of being scared, such as by watching horror\n",
      "movies or going on roller coasters, while others avoid these experiences?\n",
      "SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\n",
      "1. Neurological differences.Some people enjoy the sensation of being scared due to the release of adrenaline and\n",
      "dopamine in the brain, while others may have a lower threshold for fear due to differences in their amygdala and pre-\n",
      "frontal cortex.\n",
      "2. Psychological factors.Some people may enjoy the sensation of being scared because it can provide a sense of excite-\n",
      "ment, thrill, and a temporary escape from the mundane aspects of everyday life. On the other hand, others may avoid\n",
      "these experiences due to past trauma or anxiety.\n",
      "3. Developmental experiences.Individuals who had negative experiences with fear during childhood, such as trauma\n",
      "or abuse, may avoid scary situations as adults, while those who had positive experiences with fear may seek out these\n",
      "experiences.\n",
      "4. Cultural influences.Some cultures place a greater emphasis on seeking excitement and thrill, while others may priori-\n",
      "tize safety and security, which can impact whether individuals enjoy scary experiences or avoid them.\n",
      "5. Genetics.Research has suggested that some individuals may have a genetic predisposition towards seeking out thrilling\n",
      "or risky experiences, which may include enjoying the sensation of being scared.\n",
      "Normal answer (ChatGPT-3.5)\n",
      "The enjoyment of being scared is a complex psychological phenomenon. Some people may enjoy the adrenaline rush\n",
      "that comes with being scared, while others may enjoy the feeling of being able to conquer their fears. Additionally,\n",
      "some people may be more naturally inclined to seek out new experiences and sensations, including those that are scary\n",
      "or thrilling. On the other hand, some people may be more risk-averse or may have had negative experiences with fear or\n",
      "anxiety in the past, which could make them more likely to avoid scary experiences. Ultimately, the reasons why some\n",
      "people enjoy being scared while others do not are likely to be influenced by a range of factors, including personality, past\n",
      "experiences, and individual preferences.\n",
      "In the answer from the normal generation, the first two sentences provide little information in an-\n",
      "swering the question, and the last sentence only gives keywords such as “personality, past expe-\n",
      "riences, and individual preferences” without providing concrete explanations to each. In contrast,\n",
      "43\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "-20% 0% 20% 40% 60%counterfactualgenericcommon-senseknowledgeroleplayfermiwriting\n",
      "SoT (w/o router)\n",
      "SoT-R w/ prompting router\n",
      "SoT-R w/ trained router\n",
      "SoT-R w/ human router\n",
      "Figure 22: Net win rates of SoT and SoT-R on different question categories of Vicuna-80 dataset\n",
      "using the general quality metric from LLMZoo. Blue dots are from Fig. 5b. SoT-R correctly falls\n",
      "back to normal decoding on questions where SoT is not suitable.\n",
      "-60% -40% -20% 0% 20% 40%PhilosophyCounterfactualEthicsT echnologyLiteratureMusicSportRoleplayHistoryT oxicityPhysicsBiologyArtCommon-SenseLawTruthfulQAComputer ScienceAcademic WritingChemistryMathEconomyReasoningWrittingMedicineEntertainmentCode GenerationMultilingualComplex FormatCode Debug\n",
      "SoT (w/o router)\n",
      "SoT-R w/ prompting router\n",
      "SoT-R w/ trained router\n",
      "SoT-R w/ human router\n",
      "Figure 23: Net win rates of SoT and SoT-R on different question categories of WizardLM dataset\n",
      "using the general quality metric from FastChat. SoT-R correctly falls back to normal decoding on\n",
      "questions where SoT is not suitable.\n",
      "SoT’s answer is well-structured into five reasons with sufficient explanations and it does not waste\n",
      "space in irrelevant contents.\n",
      "I.2 S KELETON -OF-THOUGHT WITH ROUTER\n",
      "Fig. 22 shows net win rates of SoT on Vicuna-80 dataset with LLMZoo metrics, and Fig. 23 shows\n",
      "net win rates of SoT on WizardLM dataset with FastChat metrics. The key takeaways are: (1) In\n",
      "both cases, SoT-R achieves similar or better quality than SoT, and the net win rates of SoT-R are\n",
      "usually non-negative. This indicates that SoT-R falls back to normal decoding on the right question\n",
      "categories. (2) On the WizardLM dataset, we see that the trained router has better performance than\n",
      "the prompting router in most cases. This is reasonable, as the prompting router is limited by the\n",
      "capability of GPT-4, whereas the trained router is dedicated to this task. (3) Sometimes, our routers\n",
      "can even achieve better performance than humans.\n",
      "I.3 C HATGPT-3.5 AS THE JUDGE\n",
      "In this section, we provide quality evaluation results with ChatGPT-3.5 as the judge in FastChat and\n",
      "LLMZoo metrics. Note that as prior work (e.g., (Li et al., 2023b)) shows, GPT-4-based evaluation\n",
      "usually aligns with human better than ChatGPT-3.5. Therefore, readers should refer to the results\n",
      "in the main paper (with GPT-4 as the judge) for a more accurate view of the performance of SoT.\n",
      "However, the takeaway messages from ChatGPT-3.5 are similar to the ones from GPT-4.\n",
      "44\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "I.3.1 O VERALL QUALITY\n",
      "In Fig. 24, we show the win/tie/lose rates (the percentage of the cases when SoT wins/ties/loses\n",
      "compared to normal generation) across all models and questions using the two metrics from FastChat\n",
      "and LLMZoo that capture the general quality of the answers. We notice a discrepancy between the\n",
      "two metrics on when SoT is strictly better than the baseline (50.2% v.s. 12.4%). Despite that, the two\n",
      "metrics agree that SoT is not worse than the baseline in more than 76% of the cases. For FastChat\n",
      "metric, we also show the rates excluding math and coding questions that SoT is not suitable for (see\n",
      "§ 3.2.3); SoT is not worse than the baseline in more than 89% of the cases. This result suggests that\n",
      "the answers of SoT maintain good quality.\n",
      "0% 20% 40% 60% 80% 100%General quality (LLMZoo)General quality (FastChat)\n",
      "(excluding math & coding)General quality (FastChat)\n",
      "50.2%12.5%12.4%\n",
      "27.3%76.7%69.2%\n",
      "22.5%10.8%18.4%Win Tie Lose\n",
      "Figure 24: Win/tie/lose rates of SoT v.s. normal generation using “general” metrics from FastChat\n",
      "and LLMZoo. SoT performs better than or equal to normal generation in around 80% of cases.\n",
      "(Evaluated using ChatGPT-3.5 as the judge.)\n",
      "I.3.2 Q UALITY BREAKDOWN : QUESTION CATEGORIES\n",
      "Next, we investigate how SoT performs on different question categories. We compute net win rates\n",
      "(win rates minus lose rates) across all question categories in Fig. 25. Similar to Fig. 24, we see\n",
      "that LLMZoo tends to be more optimistic about the quality of SoT than FastChat. Nevertheless,\n",
      "the conclusions are consistent: SoT performs relatively well on generic, common-sense, knowledge,\n",
      "roleplay, and counterfactual. SoT performs relatively badly on writing, fermi, math, and coding.\n",
      "-60%-50%-40%-30%-20%-10%0%10%20%counterfactualroleplayknowledgegenericcommon-sensefermiwritingmathcoding\n",
      "(a) Metric: general quality (FastChat).\n",
      "0% 10% 20% 30% 40%counterfactualroleplayknowledgegenericcommon-sensefermiwriting (b) Metric: general quality (LLMZoo).\n",
      "Figure 25: Net win rates of SoT on different question categories. (Evaluated using ChatGPT-3.5 as\n",
      "the judge.)\n",
      "I.3.3 Q UALITY BREAKDOWN : M ODELS\n",
      "Next, we investigate how SoT performs on different models. We compute net win rates across all\n",
      "models in Fig. 26. Again, we see that the two general metrics from FastChat and LLMZoo have\n",
      "different absolute values but similar rankings. In particular, both metrics agree that OpenChat-\n",
      "13B, Vicuna-7B V1.1, Claude, ChatGPT-3.5 have lownet win rates, whereas Vicuna-13B V1.3,\n",
      "StableVicuna-13B, and UltraLM-13B have high net win rates.\n",
      "I.3.4 Q UALITY BREAKDOWN : QUESTION CATEGORIES AND MODELS\n",
      "In the main text, we analyze how question categories and models affect SoT’s answer quality inde-\n",
      "pendently . Here, we show their joint effect. For each model and question category, we compute the\n",
      "net win rates. The results are in Fig. 27.\n",
      "45\n",
      "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\n",
      "-15% -10% -5% 0% 5%Vicuna-13B V1.3StableVicuna-13BUltraLM-13BVicuna-33B V1.3GPT-4LLaMA2-Chat-7BLLaMA2-Chat-13BVicuna-7B V1.3ChatGPT-3.5ClaudeVicuna-7B V1.1OpenChat-13B\n",
      "(a) Metric: general quality (FastChat).\n",
      "-10% 0% 10% 20% 30% 40% 50% 60%Vicuna-13B V1.3StableVicuna-13BUltraLM-13BVicuna-33B V1.3GPT-4LLaMA2-Chat-7BLLaMA2-Chat-13BVicuna-7B V1.3ChatGPT-3.5ClaudeVicuna-7B V1.1OpenChat-13B (b) Metric: general quality (LLMZoo).\n",
      "Figure 26: Net win rates of SoT on different models. (Evaluated using ChatGPT-3.5 as the judge.)\n",
      "Avgerage\n",
      "LLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BStableVicuna-13BVicuna-7B V1.1 Vicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3UltraLM-13BClaude\n",
      "ChatGPT-3.5GPT-4coding\n",
      "math\n",
      "fermi\n",
      "roleplay\n",
      "writing\n",
      "knowledge\n",
      "generic\n",
      "counterfactual\n",
      "common-sense\n",
      "Average-63% -43% -71% 0% -100% -86% -71% -57% -86% 43% -86% -100% -100%\n",
      "-53% -33% -33% -67% -67% -100% -100% -67% 0% 33% -33% -100% -67%\n",
      "-8% 10% 20% 10% -40% -40% -30% 20% 50% 0% -30% -40% -30%\n",
      "6% 20% 0% -40% 10% 0% 10% 10% 0% 0% 20% 30% 10%\n",
      "-12% 0% 0% -30% 10% -10% 10% 10% 0% -10% -30% 0% -90%\n",
      "4% 0% 0% -10% 20% -10% 0% 10% 10% 0% 0% 0% 30%\n",
      "2% -10% 0% -50% 30% 0% 0% 0% 10% 0% 0% 0% 50%\n",
      "18% 0% 0% 20% 40% 20% 20% 40% 0% 0% -10% -10% 90%\n",
      "2% 0% -20% -20% 20% -10% 0% 10% 0% -20% 10% 10% 40%\n",
      "-12% -6% -12% -21% -9% -26% -18% -3% -2% 5% -18% -23% -7%\n",
      "-100%-75%-50%-25%0%25%50%75%100%\n",
      "(a) FastChat metric.\n",
      "Avgerage\n",
      "LLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BStableVicuna-13BVicuna-7B V1.1 Vicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3UltraLM-13BClaude\n",
      "ChatGPT-3.5GPT-4coding\n",
      "math\n",
      "fermi\n",
      "roleplay\n",
      "writing\n",
      "knowledge\n",
      "generic\n",
      "counterfactual\n",
      "common-sense\n",
      "Average10% 0% -57% 0% 17% 14% -14% 43% 57% 71% -29% 14% 0%\n",
      "14% 0% 67% 0% 67% -33% -100% 67% 33% 67% 33% -67% 33%\n",
      "20% 40% 60% -10% 20% -50% 30% 20% 50% 30% -10% 20% 40%\n",
      "28% 20% 0% -10% 90% -20% 40% 50% 40% 20% 10% 50% 50%\n",
      "8% 10% -10% 30% 60% 40% 30% 0% -10% 20% -60% -10% 0%\n",
      "41% 40% 10% -40% 70% 40% 50% 50% 90% 70% 40% 40% 30%\n",
      "26% -40% -30% -10% 90% 10% 60% 70% 30% 70% -40% 30% 70%\n",
      "47% 60% 30% 60% 10% 0% 70% 80% 40% 70% -10% 50% 100%\n",
      "24% 0% -30% -40% 90% -20% 20% 80% 50% 80% -20% 20% 60%\n",
      "24% 14% 4% -2% 57% -2% 21% 51% 42% 55% -9% 16% 43%\n",
      "-100%-75%-50%-25%0%25%50%75%100% (b) The “general” metric from LLMZoo.\n",
      "Figure 27: Net win rates of different models and question categories. Each row corresponds to one\n",
      "question category, and one column corresponds to one model. (Evaluated using ChatGPT-3.5 as the\n",
      "judge.)\n",
      "I.3.5 Q UALITY BREAKDOWN : M ETRICS\n",
      "All previous evaluations use metrics about the general quality of the answer. In Fig. 28, we show\n",
      "more detailed metrics from LLMZoo to reveal in which aspects SoT can improve or hurt the answer\n",
      "quality. On average, we can see that SoT improves the diversity and relevance while hurting the\n",
      "immersion and coherence.\n",
      "0% 20% 40% 60% 80% 100%CoherenceImmersionIntegrityRelevanceDiversity\n",
      "28.3%32.7%34.5%50.0%49.4%\n",
      "31.4%28.6%34.9%21.8%29.0%\n",
      "40.2%38.7%30.6%28.2%21.5%Win Tie Lose\n",
      "Figure 28: Win/tie/lose rates of SoT v.s. normal generations using metrics from LLMZoo. SoT per-\n",
      "forms well on diversity and relevance, and relatively worse on coherence and immersion. (Evaluated\n",
      "using ChatGPT-3.5 as the judge.)\n",
      "46\n",
      "Graph of Thoughts: Solving Elaborate Problems with Large Language Models\n",
      "Maciej Besta1*, Nils Blach1*, Ales Kubicek1, Robert Gerstenberger1,\n",
      "Michał Podstawski2, Lukas Gianinazzi1, Joanna Gajda3, Tomasz Lehmann3,\n",
      "Hubert Niewiadomski3, Piotr Nyczyk3, Torsten Hoefler1\n",
      "1ETH Zurich,2Warsaw University of Technology,3Cledar\n",
      "bestam@inf.ethz.ch, nils.blach@inf.ethz.ch, htor@inf.ethz.ch\n",
      "Abstract\n",
      "We introduce Graph of Thoughts (GoT): a framework that\n",
      "advances prompting capabilities in large language models\n",
      "(LLMs) beyond those offered by paradigms such as Chain-of-\n",
      "Thought or Tree of Thoughts (ToT). The key idea and primary\n",
      "advantage of GoT is the ability to model the information gen-\n",
      "erated by an LLM as an arbitrary graph , where units of infor-\n",
      "mation (“LLM thoughts”) are vertices, and edges correspond\n",
      "to dependencies between these vertices. This approach en-\n",
      "ables combining arbitrary LLM thoughts into synergistic out-\n",
      "comes, distilling the essence of whole networks of thoughts,\n",
      "or enhancing thoughts using feedback loops. We illustrate\n",
      "that GoT offers advantages over state of the art on different\n",
      "tasks, for example increasing the quality of sorting by 62%\n",
      "over ToT, while simultaneously reducing costs by >31%.\n",
      "We ensure that GoT is extensible with new thought transfor-\n",
      "mations and thus can be used to spearhead new prompting\n",
      "schemes. This work brings the LLM reasoning closer to hu-\n",
      "man thinking or brain mechanisms such as recurrence, both\n",
      "of which form complex networks.\n",
      "Website & code: https://github.com/spcl/graph-of-thoughts\n",
      "1 Introduction\n",
      "Large language models (LLMs) are taking over the world\n",
      "of AI. Recent years saw a rapid development of models pri-\n",
      "marily based on the decoder-only Transformer variant [65],\n",
      "such as GPT [13, 14, 53, 54], PaLM [19], or LLaMA [63].\n",
      "Prompt engineering is a resource-efficient approach for\n",
      "solving different LLM tasks. In brief, one includes the task\n",
      "description within the input sent to an LLM. If this descrip-\n",
      "tion is appropriately formulated, the LLM solves the task\n",
      "using its autoregressive token-based mechanism for gener-\n",
      "ating text. Such prompts may contain example tasks with\n",
      "solutions (few-shot prompting, also referred to as in-context\n",
      "learning (ICL)), or even no example tasks at all (zero-shot\n",
      "prompting). In recent years it was shown that this mecha-\n",
      "nism can be used to solve a broad set of tasks that involve\n",
      "mathematical, commonsense, or symbolic reasoning.\n",
      "Chain-of-Thought (CoT) [71] is an approach for prompt-\n",
      "ing, in which one includes the intermediate steps of rea-\n",
      "soning within the prompt (intermediate “thoughts”), besides\n",
      "the task input/output. CoT was shown to significantly im-\n",
      "prove the capability of LLMs to solve problems without re-\n",
      "sorting to any model updates. One major improvement over\n",
      "*Equal contributionCoT, Self-Consistency with CoT (CoT-SC) [67], is a scheme\n",
      "where multiple CoTs are generated, and then the best one is\n",
      "selected as the outcome. More recently, CoT and CoT-SC\n",
      "were extended with Tree of Thoughts (ToT) [43, 75, 77],\n",
      "which models the LLM reasoning process with a tree. This\n",
      "facilitates using different paths of thoughts, and offers novel\n",
      "capabilities such as backtracking from non-promising out-\n",
      "comes. Unfortunately, the ToT approaches still fundamen-\n",
      "tally limit the reasoning abilities within a prompt by impos-\n",
      "ing the rigid tree structure on the thought process.\n",
      "In this work, we argue that fundamentally more power-\n",
      "ful prompting can be achieved by enabling LLM thoughts to\n",
      "form an arbitrary graph structure. This is motivated by nu-\n",
      "merous phenomena such as human reasoning, brain struc-\n",
      "ture, or algorithmic execution. When working on a novel\n",
      "idea, a human would not only follow a chain of thoughts\n",
      "(as in CoT) or try different separate ones (as in ToT), but\n",
      "would actually form a more complex network of thoughts.\n",
      "For example, one could explore a certain chain of reason-\n",
      "ing, backtrack and start a new one, then realize that a cer-\n",
      "tain idea from the previous chain could be combined with\n",
      "the currently explored one, and merge them both into a new\n",
      "solution, taking advantage of their strengths and eliminat-\n",
      "ing their weaknesses. Similarly, brains form complex net-\n",
      "works, with graph-like patterns such as recurrence [28]. Ex-\n",
      "ecuting algorithms also expose networked patterns, often\n",
      "represented by Directed Acyclic Graphs. The correspond-\n",
      "inggraph-enabled transformations bring a promise of more\n",
      "powerful prompting when applied to LLM thoughts, but they\n",
      "are not naturally expressible with CoT or ToT.\n",
      "We observe that these (and many other) thought trans-\n",
      "formations can be naturally enabled when modeling the\n",
      "reasoning process of an LLM as a graph . For this, we\n",
      "propose Graph of Thoughts (GoT), an approach that en-\n",
      "hances LLMs’ capabilities through networked reasoning\n",
      "(contribution #1 ). In GoT, an LLM thought is modeled\n",
      "as a vertex, while an edge is a dependency between such\n",
      "thoughts. Using GoT, one can aggregate arbitrary thoughts\n",
      "by constructing vertices that have more than one incom-\n",
      "ing edge. Overall, the graph abstraction harnessed by GoT\n",
      "seamlessly generalizes CoT and ToT to more complex\n",
      "thought patterns, without resorting to any model updates .\n",
      "Yet, putting GoT to practice requires solving several de-\n",
      "sign challenges. For example, what is the best graph struc-\n",
      "ture for different tasks? How to best aggregate thoughts to\n",
      "maximize accuracy and minimize cost? To answer these andarXiv:2308.09687v4  [cs.CL]  6 Feb 2024\n",
      "many other questions, we carefully design a modular archi-\n",
      "tecture for implementing GoT ( contribution #2 ), coming\n",
      "with two design highlights. First, we enable a fine-grained\n",
      "control over individual thoughts . This enables us to fully\n",
      "control the ongoing conversation with the LLM, and apply\n",
      "advanced thought transformations, such as combining most\n",
      "promising thoughts from the ongoing reasoning into a new\n",
      "one. Second, we ensure that our architecture can be seam-\n",
      "lessly extended with novel thought transformations, patterns\n",
      "of reasoning (i.e., graphs of thoughts), and LLM models.\n",
      "This enables rapid prototyping of novel prompting ideas us-\n",
      "ing GoT, while experimenting with different models such as\n",
      "GPT-3.5, GPT-4, or Llama-2 [64].\n",
      "We illustrate several use cases for GoT (sorting, keyword\n",
      "counting for summaries, set operations, document merging)\n",
      "and we detail how to implement them using the graph-based\n",
      "paradigm ( contribution #3 ). We evaluate GoT and show its\n",
      "advantages over the state of the art ( contribution #4 ). Over-\n",
      "all, we observe that GoT is particularly well-suited for tasks\n",
      "that can be naturally decomposed into smaller subtasks that\n",
      "are solved individually and then merged for a final solution.\n",
      "Here, GoT outperforms other schemes, for example improv-\n",
      "ing upon CoT and ToT by, respectively, ≈70% and ≈62%,\n",
      "in terms of the quality of sorting, while simultaneously re-\n",
      "ducing costs by >31% over ToT.\n",
      "We qualitatively compare GoT to other prompting\n",
      "schemes1in Table 1. GoT is the only one to enable arbitrary\n",
      "graph-based thought transformations within a prompt, such\n",
      "as aggregation, embracing all previously proposed schemes.\n",
      "Scheme Sc? Mc? Tr? Ag?\n",
      "Chain-of-Thought (CoT) [71] /reve /reve /reve\n",
      "Self-Consistency with CoT [67] /reve /reve\n",
      "Thought decomposition [75] /reve\n",
      "Tree-of-Thought (ToT) [43] /reve\n",
      "Tree of Thoughts (ToT) [77] /reve\n",
      "Graph of Thoughts (GoT) \n",
      "Table 1: Comparison of prompting schemes, with re-\n",
      "spect to the supported transformations of thoughts. “Sc?” :\n",
      "single chain of thoughts? “Mc?” : multiple chains of\n",
      "thoughts? “Tr?” : tree of thoughts? “Ag?” : arbitrary graph\n",
      "of thoughts? “ ”: full support, “ ”: partial support, “ /reve”:\n",
      "no support.\n",
      "Finally, we propose a new metric for evaluating a prompt-\n",
      "ing strategy, the volume of a thought (contribution #5 ).\n",
      "With this metric, we aim to understand better the differences\n",
      "between prompting schemes. For a given thought v, the vol-\n",
      "ume of visthe number of LLM thoughts, from which one\n",
      "can reach vusing directed edges . Intuitively, these are all\n",
      "the LLM thoughts that have had the potential to contribute\n",
      "1Note that we do not include a recent scheme called Graph-of-\n",
      "Thought [79] because it is not a prompting scheme. While its\n",
      "name suggests close connections to ToT and CoT, as a fine-tuning\n",
      "scheme, it resorts to model updates, and is thus outside the focus\n",
      "of this work. Similarly, the graph-of-thoughts repository [52] does\n",
      "not enable general graph-based reasoning and harnesses instead\n",
      "ToT with BFS.tov. We show that GoT, by incorporating thought transfor-\n",
      "mations such as aggregation, enables thoughts to have fun-\n",
      "damentally larger volumes than other schemes.\n",
      "2 Background & Notation\n",
      "We first outline background concepts and notation.\n",
      "2.1 Language Models & In-Context Learning\n",
      "Theconversation with the LLM consists of user messages\n",
      "(prompts ) and LLM replies ( thoughts ). We follow the estab-\n",
      "lished notation [77] and we denote a pre-trained language\n",
      "model (LM) with parameters θaspθ. Lowercase letters such\n",
      "asx, y, z, ... indicate LLM thoughts. We purposefully do not\n",
      "prescribe what is a single “thought”, and instead make it use-\n",
      "case specific. Hence, a single thought can be a paragraph\n",
      "(e.g., in article summary), a document (e.g., in document\n",
      "generation), a block of code (e.g., in code debugging or op-\n",
      "timization), and so on.\n",
      "We next describe specific prompting approaches .\n",
      "Input-Output (IO) The Input-Output (IO) prompting is a\n",
      "straightforward approach, in which we use an LLM to turn\n",
      "an input sequence xinto the output ydirectly , without any\n",
      "intermediate thoughts.\n",
      "Chain-of-Thought (CoT) Second, in Chain-of-Thought\n",
      "(CoT), one introduces intermediate thoughts a1, a2, ...be-\n",
      "tween xandy. This strategy was shown to significantly en-\n",
      "hance various LM tasks over the plain IO baseline, such as\n",
      "mathematical puzzles [71] or general mathematical reason-\n",
      "ing [24].\n",
      "Multiple CoTs Third, one can generalize CoT into multi-\n",
      "ple CoTs by generating several (independent) kCoTs, and\n",
      "returning the one with the best output (according to some\n",
      "prescribed scoring metric). It was introduced by Wang et\n",
      "al. in the scheme called Self-Consistency with CoT (CoT-\n",
      "SC) [67]. This approach enhances CoT because it offers an\n",
      "opportunity to explore different reasoning paths. However,\n",
      "it does not offer “local exploration” within a path, such as\n",
      "backtracking.\n",
      "Tree of Thoughts (ToT) Finally, the Tree of Thoughts\n",
      "(ToT) scheme was introduced independently by Yao [77]\n",
      "and Long [43] (where it is referred to as Tree-of-Thought);\n",
      "it was used implicitly to a certain degree by other schemes\n",
      "such as thought decomposition [75]. It enhances CoT-SC by\n",
      "modeling the process or reasoning as a treeof thoughts. A\n",
      "single tree node represents a partial solution. Based on a\n",
      "given node, the thought generator constructs a given number\n",
      "kof new nodes. Then, the state evaluator generates scores\n",
      "for each such new node. Depending on the use case, the eval-\n",
      "uation could be conducted using an LLM itself, or it can har-\n",
      "ness human scores. Finally, the schedule of extending the\n",
      "tree is dictated by the utilized search algorithm (for example\n",
      "BFS or DFS).\n",
      "3 The GoT Framework\n",
      "We now detail the GoT framework. We present it in Figure 1,\n",
      "and compare it to other prompting strategies.\n",
      "2\n",
      "Input\n",
      "OutputInput\n",
      "Output OutputThoughts:\n",
      "Unscored\n",
      "Negative\n",
      "score OutputInput\n",
      "Output[This work]\n",
      "Input\n",
      "Positive\n",
      "score\n",
      "Dependencies\n",
      "between thoughts\n",
      "Abandon thought\n",
      "BacktrackBasic Input-\n",
      "Output (IO)\n",
      "LegendMultiple CoTs (CoT-SC) Chain-of-\n",
      "-Thought\n",
      "(CoT)Tree of Thoughts (ToT) Graph of Thoughts (GoT)\n",
      "Key novelty:\n",
      "Intermediate\n",
      "LLM thoughts\n",
      "within a chainBranching out\n",
      "from a chain\n",
      "Selecting\n",
      "a chain with\n",
      "the best scoreAbandon a chain\n",
      "Key novelty\n",
      "(beyond CoT):\n",
      "Harnessing multiple\n",
      "independent chains\n",
      "of thoughtsKey novelty\n",
      "(beyond CoT-SC):\n",
      "Generating several\n",
      "new thoughts based\n",
      "on a given arbitrary\n",
      "thought, exploring\n",
      "it further, and possibly\n",
      "backtracking from itKey novelty (beyond ToT):\n",
      "Arbitrary graph-based thought\n",
      "transformations (aggregating \n",
      "thoughts into a new one, \n",
      "looping over a thought to \n",
      "refine it)BacktrackingRefining\n",
      "Aggregating\n",
      "thoughtsBacktracking\n",
      "from a chain\n",
      "Intermediate\n",
      "thoughts are\n",
      "also scored\n",
      "Aggregating\n",
      "chainsInputFigure 1: Comparison of Graph of Thoughts (GoT) to other prompting strategies.\n",
      "Formally, GoT can be modeled as a tuple (G,T,E,R),\n",
      "where Gis the “LLM reasoning process” (i.e., all the LLM\n",
      "thoughts within the context, with their relationships), Tare\n",
      "the potential thought transformations, Eis an evaluator func-\n",
      "tion used to obtain scores of thoughts, and Ris a ranking\n",
      "function used to select most relevant thoughts.\n",
      "3.1 Reasoning Process\n",
      "We model the reasoning process as a directed graph G=\n",
      "(V, E);Vis a set of vertices and E⊆V×Vis a set of\n",
      "edges. Gis directed and thus the edges are a subset of or-\n",
      "dered vertex pairs E⊆V×V. A vertex contains a solution\n",
      "to a problem at hand (be it an initial, intermediate, or a fi-\n",
      "nal one). The concrete form of such a thought depends on\n",
      "the use case; it could be a paragraph (in writing tasks) or a\n",
      "sequence of numbers (in sorting). A directed edge (t1, t2)\n",
      "indicates that thought t2has been constructed using t1as\n",
      "“direct input”, i.e., by explicitly instructing the LLM to use\n",
      "t1for generating t2.\n",
      "In certain use cases, graph nodes belong to different\n",
      "classes . For example, in writing tasks, some vertices model\n",
      "plans of writing a paragraph , while other vertices model the\n",
      "actual paragraphs of text . In such cases, GoT embraces a\n",
      "heterogeneous graph G= (V, E, c )to model the LLM rea-\n",
      "soning, where cmaps vertices Vinto their respective classes\n",
      "C(in the above case, it would be C={plan, par }). Hence,\n",
      "any vertex vcan model different aspects of reasoning.\n",
      "We associate Gwith the LLM reasoning process. To ad-\n",
      "vance this process, one applies thought transformations to\n",
      "G. An example of such a transformation is to merge best-\n",
      "scoring (so far) thoughts into a new one. Another example\n",
      "is to loop over a thought, in order to enhance it. Note that\n",
      "these transformations strictly extend the set of transforma-\n",
      "tions available in the CoT, CoT-SC, or ToT.\n",
      "3.2 Transformations of Thoughts\n",
      "GoT enables novel transformations of thoughts thanks to\n",
      "the graph-based model for reasoning. We refer to them as\n",
      "...Graph theory view Example sorting task Example writing taskAggregation Generation...\n",
      "1 2 7 8 1 1 4 5 2 3 6 7\n",
      "1 1 1 2 2 3 4 5 6 7 7 8...\n",
      "Article\n",
      "1Article\n",
      "2Article\n",
      "3\n",
      "Keyword\n",
      "summary\n",
      "A vertex models\n",
      "a thought. An edge\n",
      "models dependency... ...Merging sorted subarrays\n",
      "into a sorted array of numbers\n",
      "Splitting an unsorted array into\n",
      "subarrays, for subsequent sortingCombining articles into\n",
      "a coherent summary...\n",
      "Keyword\n",
      "summary 1Keyword\n",
      "summary 21 4 6 2 4 2 4 9 8 7 5 4\n",
      "1 4 6 2    4 2 4 9    8 7 5 4Article\n",
      "1\n",
      "Generating summaries from\n",
      "an article, to maximize qualityFigure 2: Examples of aggregation and generation thought\n",
      "transformations.\n",
      "graph-enabled transformations . For example, in writing,\n",
      "one could combine several input articles into one coherent\n",
      "summary. In sorting, one could merge several sorted subar-\n",
      "rays of numbers into a final sorted array. We illustrate exam-\n",
      "ples of aggregation and generation in Figure 2.\n",
      "Formally, each such transformation can be modeled as\n",
      "T(G, pθ)where G= (V, E)is the graph reflecting the\n",
      "current state of the reasoning, and pθis the used LLM. T\n",
      "modifies Gusually by adding new vertices and their incom-\n",
      "ing edges. We have G′=T(G, pθ) = ( V′, E′), where\n",
      "V′= (V∪V+)\\V−andE′= (E∪E+)\\E−.V+\n",
      "andE+are new vertices and edges inserted into Gto model\n",
      "the new thoughts and their dependencies, respectively. To\n",
      "maximize the expressiveness of GoT – we also enable the\n",
      "user to explicitly remove thoughts, by specifying the corre-\n",
      "sponding vertices and edges to be removed ( V−andE−, re-\n",
      "spectively). Here, it is the user’s responsibility to ensure that\n",
      "the sets V+, E+, V−,andE−come with consistent trans-\n",
      "formations (i.e., for example, that the user does not attempt\n",
      "to remove a vertex that does not exist). This enables seam-\n",
      "3\n",
      "less incorporation of schemes where, in order to save space\n",
      "within the context, one can remove parts of reasoning that\n",
      "do not promise improvements.\n",
      "The specific form of Tand how it impacts Gdepends on\n",
      "a specific transformation. We first detail the primary graph-\n",
      "enabled thought transformations, and then proceed to de-\n",
      "scribe how GoT embraces the transformations from the ear-\n",
      "lier schemes. Unless stated otherwise, V−=E−=∅.\n",
      "Aggregation Transformations First, with GoT, one can\n",
      "aggregate arbitrary thoughts into new ones, to combine\n",
      "and reinforce the advantages of these thoughts, while elim-\n",
      "inating their disadvantages. In the basic form, in which\n",
      "only one new vertex is created, V+={v+}andE+=\n",
      "{(v1, v+), ...,(vk, v+)}, where v1, ..., v kare the merged k\n",
      "thoughts. More generally, this enables aggregating reason-\n",
      "ing paths , i.e., longer chains of thoughts, beyond just indi-\n",
      "vidual thoughts. With the graph model, it is simply achieved\n",
      "by adding outgoing edges from the vertices v1, ..., v k, mod-\n",
      "eling final thoughts in several chains, into a single thought\n",
      "v+combining these chains.\n",
      "Refining Transformations Another thought transforma-\n",
      "tion is the refining of a current thought vby modifying its\n",
      "content: V+={}andE+={(v, v)}. This loop in the\n",
      "graph indicates an iterated thought with the same connec-\n",
      "tions as the original thought.\n",
      "Generation Transformations Finally, one can generate\n",
      "one or more new thoughts based on an existing single\n",
      "thought v. This class embraces analogous reasoning steps\n",
      "from earlier schemes, such as ToT or CoT-SC. Formally, we\n",
      "haveV+={v+\n",
      "1, ..., v+\n",
      "k}andE+={(v, v+\n",
      "1), ...,(v, v+\n",
      "k)}.\n",
      "3.3 Scoring & Ranking Thoughts\n",
      "Thoughts are scored to understand whether the current solu-\n",
      "tion is good enough. A score is modeled as a general func-\n",
      "tionE(v, G, p θ), where vis a thought to be evaluated. We\n",
      "use the state of the whole reasoning process ( G) inEfor\n",
      "maximum generality, because – for example – in some eval-\n",
      "uation scenarios, scores may be relative to other thoughts.\n",
      "GoT can also rank thoughts. We model this with a func-\n",
      "tionR(G, pθ, h)where hspecifies the number of highest-\n",
      "ranking thoughts in Gto be returned by R. While the spe-\n",
      "cific form of Rdepends on the use case, we most often use a\n",
      "simple yet effective strategy where hthoughts with the high-\n",
      "est scores are returned, i.e., v1, ..., v h=R(G, pθ, h).\n",
      "Specific forms of EandRdepend on the use case. We dis-\n",
      "cuss the details in Section 5. For example, the score (or rank)\n",
      "for sorting corresponds to the count of elements correctly\n",
      "sorted (or incorrectly, when using the error as a score).\n",
      "4 System Architecture & Extensibility\n",
      "The GoT architecture consists of a set of interacting mod-\n",
      "ules, see Figure 3 (the blue part). These modules are the\n",
      "Prompter (prepares the messages for the LLM), the Parser\n",
      "(extracts information from LLM thoughts), the Scoring\n",
      "module (verifies and scores the LLM thoughts), and theController (coordinates the entire reasoning process, and de-\n",
      "cides on how to progress it). The Controller contains two fur-\n",
      "ther important elements: the Graph of Operations (GoO) and\n",
      "the Graph Reasoning State (GRS). GoO is a static structure\n",
      "that specifies the graph decomposition of a given task , i.e.,\n",
      "it prescribes transformations to be applied to LLM thoughts,\n",
      "together with their order & dependencies. GRS is a dynamic\n",
      "structure that maintains the state of the ongoing LLM rea-\n",
      "soning process (the history of its thoughts and their states).\n",
      "4.1 Prompter\n",
      "The Prompter prepares the prompts to be sent to the LLM.\n",
      "This module is responsible for the specifics of encoding the\n",
      "graph structure within the prompt. The GoT architecture en-\n",
      "ables the user to implement use case specific graph encod-\n",
      "ings by providing full access to the graph structure.\n",
      "4.2 Parser\n",
      "The Parser extracts information from LLM thoughts. For\n",
      "each such thought, the Parser constructs the thought state ,\n",
      "which contains this extracted information. The thought state\n",
      "is then used to update the GRS accordingly.\n",
      "4.3 Scoring & Validation\n",
      "Here, we verify whether a given LLM thought satisfies po-\n",
      "tential correctness conditions, and then we assign it a score.\n",
      "Depending on how the score is derived, the module may\n",
      "consult the LLM. Moreover, depending on the use case, the\n",
      "score may also be assigned by a human. Finally, use cases\n",
      "such as sorting use simple local scoring functions.\n",
      "4.4 Controller\n",
      "The Controller implements a specific strategy for select-\n",
      "ing thoughts from its GRS structure. It also selects what\n",
      "transformations should be applied to which thoughts, and\n",
      "then passes this information to the Prompter. It also decides\n",
      "whether the whole process should be finalized, or whether\n",
      "the next round of interaction with the LLM should be initi-\n",
      "ated. In our current design, this is dictated by the execution\n",
      "plan specified in the GoO.\n",
      "4.5 GoO & GRS\n",
      "The user constructs a GoO instance, which prescribes the\n",
      "execution plan of thought operations. The GoO is a static\n",
      "structure that is constructed once, before the execution starts.\n",
      "Each operation object knows its predecessor and successor\n",
      "operations. Then, during the execution, an instance of the\n",
      "GRS maintains the continually updated information about\n",
      "the LLM reasoning process. This includes which operation\n",
      "has been executed so far, the states of all the generated LLM\n",
      "thoughts, their validity and scores, and any other relevant\n",
      "information.\n",
      "The above elements offer extensible APIs , enabling\n",
      "straightforward implementations of different prompting\n",
      "schemes. The APIs are outlines in the green part of Fig-\n",
      "ure 3, and detailed in the documentation. We also provide\n",
      "examples of prompts used by these operations and a corre-\n",
      "sponding GRS in the red part of Figure 3.\n",
      "4\n",
      "Goal: Build a prompt\n",
      "to be sent to the LLMLegend Architecture overview\n",
      "Example prompts and the Graph Reasoning State for the sorting use case (some examples within each prompt are omitted due to space constraints)\n",
      "Parser\n",
      "Goal: Extract\n",
      "information from\n",
      "LLM thought Goal: Assess the\n",
      "quality of the\n",
      "LLM's solution\n",
      "ControllerGoal: Initiate, coordinate, manage,\n",
      "and progress the GoT executionExternal entity Prompt Thought\n",
      "Thought stateScore\n",
      "Operation\n",
      "Thought state + its\n",
      "associated operationsThought state\n",
      "+ thought's scoreDependencyModule of the\n",
      "GoT framework Graph of\n",
      "Operations\n",
      "Goal: Specify\n",
      "LLM thought\n",
      "transformations\n",
      "Graph Reasoning State\n",
      "Goal: Maintain\n",
      "the ongoing LLM\n",
      "reasoning process\n",
      "User\n",
      "Goal: Indicate the\n",
      "top-scoring thoughts\n",
      "Graph of Operations enables seamless specification of not only\n",
      "GoT, but also existing schemes such as CoT, CoT-SC, ToT\n",
      "API for Prompter (extensible)\n",
      "➡ Generate(t,k) //generate a prompt for k new thoughts, using thought t➡ //LLM params: model used, temperature, max tokens, api key, org, ...\n",
      "➡ //LLM cost features: prompt token cost, response token cost, ...\n",
      "➡ //Instances of Prompter + Parser + Graph of Operations,\n",
      "➡ //Any additional input parameters (e.g., numbers to be sorted).\n",
      "//Each of the above routines is responsible for parsing an LLM thought\n",
      "//to a corresponding Prompter routine (e.g., ParseScore parses Score).➡ Score(t) //score thought t\n",
      "➡ Validate(t) //generate a prompt to validate the correctness of thought t➡ ValidateAndImprove(t) //generate a prompt to enhance thought t,\n",
      "➡ Aggregate(t1,...,tk) //generate a prompt to combine thoughts t1, ..., tk API for Controller\n",
      "API for Parser (extensible)\n",
      "ParseGenerate, ParseImprove, ParseScore,\n",
      "ParseAggregate, ParseValidate, ...➡ Generate, Aggregate, Score, ... //see Prompter API\n",
      "➡ KeepBest(N) //preserves N best scoring thoughts\n",
      "➡ Repeat(k) //Repeat a given operation k times, generating k thoughts.\n",
      "    //For example, this enables \"Aggregate\" to generate multiple outcomes\n",
      "    //of the combination operation. Each such thought is maintained \n",
      "   //within the Graph Reasoning State and scored individually.Available operations when building the GoO (extensible)\n",
      "Specifying the Structure of the Graph of Operations (GoO)Ranking Scoring &\n",
      "validationPrompter\n",
      "LLM\n",
      "Human\n",
      "or LLM\n",
      "Gray block\n",
      "Blue block\n",
      "A prompt used by\n",
      "Aggregate(t1,t2)+Repeat(k=3)+KeepBest(N=1)\n",
      "<Instruction> Merge the following 2 sorted lists of length {length1} each, \n",
      "into one sorted list of length {length2} using a merge sort style approach.\n",
      "Only output the final merged list without any additional text or thoughts!\n",
      "</Instruction>\n",
      "<Approach>\n",
      "To merge the two lists in a merge-sort style approach, follow these steps:\n",
      "1. Compare the first element of both lists.\n",
      "2. Append the smaller element to the merged list and move to the next \n",
      "element in the list from which the smaller element came.\n",
      "3. Repeat steps 1 and 2 until one of the lists is empty.\n",
      "4. Append the remaining elements of the non-empty list to the merged list.\n",
      "</Approach>\n",
      "Merge the following two lists into one sorted list:\n",
      "1: {input1}\n",
      "2: {input2}\n",
      "Merged list:\n",
      "This prompt is used by an operation Aggregate where the aggregation factor is \n",
      "k = 2 (2 input thoughts, t1 and t2, are aggregated). This is repeated by GoT 3 times, \n",
      "to maximize quality. Finally, the best result is selected. Note that, in this example, \n",
      "the prompt explicitly requests the merge operation only. All the remaining opera-\n",
      "tions are specified in the GoO and are handled by the underlying GoT framework.\n",
      "The input\n",
      "thoughts t1, t2\n",
      "3Initial/system prompt (optional)\n",
      "Hello. I want to sort the following input sequence of numbers: {input}I\n",
      "1 2 3I\n",
      "4Improve(t)+Repeat(k=4)\n",
      "<Instruction> The following two lists represent an unsorted list of numbers \n",
      "and a sorted variant of that list. The sorted variant is not correct. Fix the \n",
      "sorted variant so that it is correct. Make sure that the output list is sorted in\n",
      "ascending order, has the same number of elements as the input list ({length}),\n",
      "and contains the same elements as the input list. </Instruction>\n",
      "<Approach>\n",
      "To fix the incorrectly sorted list follow these steps:\n",
      "1. For each number from 0 to 9, compare the frequency of that number in the\n",
      "incorrectly sorted list to the frequency of that number in the input list.\n",
      "2. Iterate through the incorrectly sorted list and add or remove numbers as\n",
      "needed to make the frequency of each number in the incorrectly sorted list\n",
      "match the frequency of that number in the input list.\n",
      "</Approach>\n",
      "<Examples>\n",
      "Input: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9]\n",
      "Incorrectly Sorted: [0, 0, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 7, 7, 8, 8, 9, 9, 9, 9]\n",
      "Reason: The incorrectly sorted list contains four extra 0s, two extra 4s and\n",
      "three extra 9s and is missing two 2s.\n",
      "Output: [0, 1, 2, 2, 2, 2, 3, 3, 4, 5, 5, 7, 7, 8, 8, 9] \n",
      "    \n",
      "Input: [6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9, 2, 4, 9, 0, 7, 6, 5, 6, 6, 2, 8,\n",
      "3, 9, 5, 6, 1]\n",
      "Incorrectly Sorted: [0, 1, 1, 2, 2, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7,\n",
      "7, 7, 8, 8, 9, 9, 9, 9, 9]\n",
      "Reason: The incorrectly sorted list contains two extra 4s and is missing two\n",
      "6s and one 9.\n",
      "Output: [0, 1, 1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9,\n",
      "9, 9, 9, 9, 9]\n",
      "</Examples>\n",
      "Input: {input}\n",
      "Incorrectly Sorted: {incorrectly_sorted}A prompt used by\n",
      "...\n",
      "...This prompt is used by an operation\n",
      "Improve(t), which enhances a given thought t\n",
      "using information provided in another thought.\n",
      "Depending on how the Improve + Repeat \n",
      "operation is implemented by the user within\n",
      "GoT, it can either generate a number of new \n",
      "thoughts in GRS (the upper graph on the right), \n",
      "similar to Generate + Repeat, or may refine \n",
      "the same thought in GRS (the lower graph on \n",
      "the right), chaining k=4 refinement iterations together.\n",
      "4\n",
      "The input\n",
      "thought tA prompt used by\n",
      "Generate(t,k=4)\n",
      "<Instruction> Split the following list of 64 numbers into 4 lists of 16\n",
      "numbers each, the first list should contain the first 16 numbers, the\n",
      "second list the second 16 numbers, the third list the third 16 numbers\n",
      "and the fourth list the fourth 16 numbers. Only output the final 4 lists\n",
      "in the following format without any additional text or thoughts!\n",
      "{{\n",
      "    \"List 1\": [3, 4, 3, 5, 7, 8, 1, ...],\n",
      "    \"List 2\": [2, 9, 2, 4, 7, 1, 5, ...],\n",
      "    \"List 3\": [6, 9, 8, 1, 9, 2, 4, ...],\n",
      "    \"List 4\": [9, 0, 7, 6, 5, 6, 6, ...]\n",
      "}} </Instruction>\n",
      "<Example>\n",
      "Input: [3, 1, 9, 3, 7, 5, 5, 4, 8, 1, 5, 3, 3, 2, 3, 0, 9, 7, 2, 2, 4, 4, 8, 5, 0, \n",
      "8, 7, 3, 3, 8, 7, 0, 9, 5, 1, 6, 7, 6, 8, 9, 0, 3, 0, 6, 3, 4, 8, 0, 6, 9, 8, 4, 1, \n",
      "2, 9, 0, 4, 8, 8, 9, 9, 8, 5, 9]\n",
      "Output:\n",
      "{{\n",
      "    \"List 1\": [3, 1, 9, 3, 7, 5, 5, 4, 8, 1, 5, 3, 3, 2, 3, 0],\n",
      "    \"List 2\": [9, 7, 2, 2, 4, 4, 8, 5, 0, 8, 7, 3, 3, 8, 7, 0],\n",
      "    \"List 3\": [9, 5, 1, 6, 7, 6, 8, 9, 0, 3, 0, 6, 3, 4, 8, 0],\n",
      "    \"List 4\": [6, 9, 8, 4, 1, 2, 9, 0, 4, 8, 8, 9, 9, 8, 5, 9]\n",
      "}}\n",
      "</Example>\n",
      "Input: {input}\n",
      "This prompt is used by an operation Generate where\n",
      "the branching factor is k = 4. Four new thoughts are\n",
      "constructed based on the LLM reply to this prompt.The input\n",
      "thought t1Generate(t,k=1)+Repeat(k=4) A prompt used by\n",
      "<Instruction> Sort the following list of numbers in ascending order.\n",
      "Output only the sorted list of numbers, no additional text. </Instruction>\n",
      "<Example>\n",
      "Input: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, 5, 6, 6, 4, 4, 5, \n",
      "2, 0, 9, 3, 3, 9, 2, 1]\n",
      "Output: [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, \n",
      "6, 6, 7, 7, 8, 8, 9, 9, 9]\n",
      "</Example>\n",
      "Input: {input}\n",
      "The input\n",
      "thought t\n",
      "This prompt is used by an operation Generate where the\n",
      "branching factor is k=1, which means, only one thought is\n",
      "generated. However, as we chain it with the operation Repeat\n",
      "with k=4, the underlying GoT framework ensures that Generate\n",
      "executes 4 times and results in 4 separate thoughts. Note that, from the graph\n",
      "theory perspective, the GRS is identical to that in the operation Generate(t, k=4).\n",
      "The difference between these two is that Generate(t, k=4) gives the user more \n",
      "control over how these multiple thoughts are constructed, while Generate(t, \n",
      "k=1)+Repeat(k=4) is less flexible but more easy to use. Moreover, with Repeat \n",
      "one has 4 context-isolated responses from the LLM for identical prompts, \n",
      "whereas without Repeat there is only one context where all 4 thoughts are\n",
      "generated and must be explicitly handled in a single prompt/session.\n",
      "2\n",
      "Figure 3: The system architecture of GoT, and the APIs of respective modules. The user can straightforwardly extend the design\n",
      "towards new prompting schemes, experiment with novel thought transformations, and plug in different LLMs. The blue part of\n",
      "the figure contains the architecture overview, the green part lists the API, and the red part contains example prompts together\n",
      "with a GRS and operations involved.\n",
      "5\n",
      "5 Example Use Cases\n",
      "We now describe several use cases of GoT. We detail one\n",
      "use case (sorting) and summarize the others.\n",
      "5.1 Sorting\n",
      "We focus on the decomposition of the sorting use case and\n",
      "Graph of Operations, which are central for implementing\n",
      "and executing any workload within GoT.\n",
      "We consider sorting numbers 0–9 with duplicates. The\n",
      "considered LLMs are unable to sort a sequence of such num-\n",
      "bers correctly beyond a certain length consistently because\n",
      "duplicate counts do not match.\n",
      "In GoT, we employ merge-based sorting: First, one de-\n",
      "composes the input sequence of numbers into subarrays.\n",
      "Then, one sorts these subarrays individually, and then re-\n",
      "spectively merges them into a final solution. Figure 4 illus-\n",
      "trates this use case together with its graph decomposition.\n",
      "Here, an LLM thought is a sequence of sorted numbers.\n",
      "To score an outcome, denote an input sequence with\n",
      "[a1, a2, ..., a n]and an output one with [b1, b2, ..., b m]. We\n",
      "use the following score that determines “the scope” of er-\n",
      "rors:\n",
      "error-scope =X+Y\n",
      "where p∈ {1, ..., m},q∈ {1, ..., n}, and\n",
      "X=m−1X\n",
      "i=1sgn(max( bi−bi+1,0)),\n",
      "Y=9X\n",
      "i=0| |{bp:bp=i}| − |{ aq:aq=i}| |\n",
      "Here, Xindicates how many consecutive pairs of num-\n",
      "bers are incorrectly sorted. If two numbers iandi+ 1\n",
      "are incorrectly sorted (i.e., bi> bi+1), then the expression\n",
      "within the summation returns 1, increasing the error score\n",
      "by one. For two numbers correctly sorted, this expression\n",
      "amounts to 0. Then, Ydetermines how well a given output\n",
      "sequence preserves the frequency of output numbers. Specif-\n",
      "ically, for each considered number x(x∈ {0, ...,9}), we\n",
      "obtain the difference between the count of input elements\n",
      "being equal to x, vs. the count of output elements equal\n",
      "tox. For an output sequence perfectly preserving the fre-\n",
      "quency of x, this would amount to 0. Any single “devia-\n",
      "tion” in this count, increases the “error scope” by 1. We\n",
      "then sum this over all considered values of x. When plot-\n",
      "ting this score, to improve the clarity of plots, we addition-\n",
      "ally apply clipping min( error-scope , n), as some baselines\n",
      "(IO, CoT) result in large numbers of outliers with high er-\n",
      "ror scope. Finally, to use a “positive score” describing “the\n",
      "scope of correctly sorted” elements, one can use the value\n",
      "max( n−error-scope ,0).\n",
      "5.2 Set Operations\n",
      "Moreover, we also consider set operations, focusing on set\n",
      "intersection. They have numerous applications (particularly\n",
      "set intersection) in problems ranging from genome or docu-\n",
      "ment comparisons to pattern matching [9–11, 20, 27, 38, 50,\n",
      ".....\n",
      ".......... .....1 4  ...  4 316 numbers\n",
      "8 2  ...  1 316 numbers\n",
      "1 1  ...  4 2 1 9  ...  5 416 numbers\n",
      "16 numbers\n",
      "Sort\n",
      "Partial solutionGraph of Operations (GoO) for sorting 64 numbers\n",
      "Partial solution Partial solution Partial solution\n",
      "k = 3Generate(k)\n",
      "ScoreSort\n",
      "Generate(k)\n",
      "Sort\n",
      "Generate(k)\n",
      "1 2  ...  7 816 numbers\n",
      "1 1  ...  5 716 numbers\n",
      "Partial solution Partial solution\n",
      "1 2  ...  4 816 numbers\n",
      "Partial solution\n",
      "1 2  ...  7 816 numbers\n",
      "1 1  ...  5 716 numbers\n",
      "Partial solution Partial solution\n",
      "1 2 ... 4 816 numbers\n",
      "Partial solution\n",
      "Score: 78% Score: 86%\n",
      "KeepBest(N)\n",
      "Keep the best\n",
      "scored thoughtsN = 1\n",
      "Merge into a 32\n",
      "element subarray\n",
      "Aggregate(k)\n",
      "k = 10k = 3 k = 3\n",
      "Assess how well each sequence is sorted\n",
      "How do we score?64 numbers\n",
      "1 4 6 2 4  ...  9 8 7 5 4\n",
      "Splitting into four\n",
      "16-element chunksGenerate(k) k = 1\n",
      "Input\n",
      "Sort\n",
      "Generate(k)\n",
      "k = 3\n",
      "Score: 100%\n",
      "1 2  ...  4 816 numbers\n",
      "Partial solution\n",
      "Score: 100%1 3  ...  4 616 numbers\n",
      "Partial solution\n",
      "Score: 97%..... .....\n",
      ".....1 1  ...  8 932 numbers\n",
      "Partial solution\n",
      "Score: 100%1 1  ...  6 832 numbers\n",
      "Partial solution\n",
      "Score: 97%\n",
      "Merge into a 64\n",
      "element array\n",
      "Aggregate(k)\n",
      "k = 10S\n",
      "ScoreS\n",
      "ScoreS\n",
      "ScoreS\n",
      "Score\n",
      "K\n",
      "G\n",
      "ScoreG\n",
      "ScoreScore ScoreK K K\n",
      "AG\n",
      "KA\n",
      "AScore\n",
      "Score\n",
      "K KK KKG\n",
      "S\n",
      "AKGLegend\n",
      "GenerateDetails of the highlighted\n",
      "part of GoO are below \n",
      "Details of the highlighted part of the GoO from above\n",
      "The first Generate\n",
      "splits the 64-element\n",
      "input array into four\n",
      "16-element chunks.\n",
      "Sorting is implemented within\n",
      "the Generate operation. Here,\n",
      "k=3 means that, for each 16\n",
      "element chunk, we generate\n",
      "three different sortings. \n",
      "Here, N=1 means that we\n",
      "maintain a single best\n",
      "sorting outcome out of\n",
      "the three input ones.\n",
      "Here, k=10 means that we try 10 different\n",
      "aggregations of the two input 16-element subarrays.To obtain the score, for every\n",
      "number 0 - 9, we get the\n",
      "difference between the input\n",
      "and the sorted list, and we sum\n",
      "all 10 values. Zero indicates\n",
      "correctly sorted. To show\n",
      "\"the higher the better\", we do\n",
      "max(input_length - score, 0)Note that this is an example graph decomposition. The structure\n",
      "of connections between all operations can be arbitrarily modified.\n",
      "Sort\n",
      "KeepBest\n",
      "AggregateFigure 4: An example graph decomposition of the sorting\n",
      "use case in GoT. All used operations (Generate, Aggregate,\n",
      "Score, KeepBest) are described in Figure 3.\n",
      "6\n",
      "58]. Set intersection of two sets is implemented similarly as\n",
      "the sorting. The second input set is split into subsets and the\n",
      "intersection of those subsets with the first input set is deter-\n",
      "mined with the help of the LLM. Afterwards the resulting\n",
      "intersection sets are aggregated for the final results. For the\n",
      "evaluation we use different set sizes of 32, 64 and 128 el-\n",
      "ements and we vary the number of elements found in both\n",
      "sets to be between 25% and 75%.\n",
      "Our score indicates the total number of missing or in-\n",
      "correctly included elements in the final intersection. Specif-\n",
      "ically, denote two input sets with A= [a1, a2, ..., a n]\n",
      "andB= [b1, b2, ..., b n], and the output set with C=\n",
      "[c1, c2, ..., c m]. Then,\n",
      "error-scope =X1+X2+Xd\n",
      "where X1=|C\\(A∩B)|are the number of elements in C\n",
      "that are not supposed to be there, X2=|(A∩B)\\C|are the\n",
      "number of elements missing from C, and Xdis the number\n",
      "of duplicates in C(because the LLM expresses the set as a\n",
      "list in natural language). Finally, to use a “positive score”\n",
      "describing “the scope of correctly computed” elements, one\n",
      "can use the value max( n−error-scope ,0).\n",
      "5.3 Keyword Counting\n",
      "Keyword counting finds the frequency of keywords in a\n",
      "given category (countries in our example implementation)\n",
      "within the input text. GoT splits the input text into multiple\n",
      "passages, counts the keywords in each passage and aggre-\n",
      "gates the subresults. The number of passages is configurable\n",
      "and can also be left to the LLM, making it possible to treat\n",
      "each sentence as a separate passage. Here, to score a thought,\n",
      "we first – for each keyword – derive the absolute difference\n",
      "between the computed count and the correct one. We then\n",
      "sum all these differences to get the final score.\n",
      "5.4 Document Merging\n",
      "Finally, we also provide document merging. Here, the goal\n",
      "is to generate a new Non-Disclosure Agreement (NDA) doc-\n",
      "ument based on several input ones that partially overlap\n",
      "in terms of their contents. The goal is to ensure minimal\n",
      "amount of duplication, while maximizing information reten-\n",
      "tion. Document merging is broadly applicable in, e.g., legal\n",
      "procedures, where multiple sources of information have to\n",
      "be combined into a single document or article. To score a\n",
      "solution, we query the LLM for two values (3 times for each\n",
      "value, and take the average). The first value corresponds to\n",
      "the solution redundancy (10 indicates no redundancy, 0 im-\n",
      "plies at least half the information is redundant), the second\n",
      "value stands for information retention (10 indicates all infor-\n",
      "mation is retained, 0 says that none is retained). We compute\n",
      "the harmonic mean of these values.\n",
      "6 The Latency-Volume Tradeoff\n",
      "We now show that GoT improves upon previous prompting\n",
      "schemes in terms of the tradeoff between latency (number of\n",
      "hops in the graph of thoughts to reach a given final thought)\n",
      "andvolume . We define volume – for a given thought t– asthe number of preceding LLM thoughts that could have im-\n",
      "pacted t. Formally, the volume of tis the number of thoughts\n",
      "from which there exists a path to tin the graph of thoughts.\n",
      "We assume that outputting a single thought costs O(1)time\n",
      "and fix the total cost to Θ(n)for each prompting scheme.\n",
      "The structure of the schemes is as follows. CoT-SC con-\n",
      "sists of kindependent chains originating from a single start-\n",
      "ing thought. ToT is a complete k-ary tree. Finally, in GoT, a\n",
      "complete k-ary tree is joined at its leaves with a “mirrored”\n",
      "k-ary tree of the same size but with its edges reversed.\n",
      "The analysis is detailed in Table 2. CoT offers a large vol-\n",
      "ume of up to N, but at the cost of a high latency of N. CoT-\n",
      "SC reduces the latency by a factor of k(which corresponds\n",
      "to its branching factor), but it simultaneously decreases the\n",
      "volume by kas well. ToT offers a latency of logkNbut\n",
      "also has low volume. GoT is the only scheme to come with\n",
      "both a low latency of logkNand a high volume N. This\n",
      "is enabled by the fact that GoT harnesses aggregations of\n",
      "thoughts, making it possible to reach the final thought from\n",
      "any other intermediate thought in the graph decomposition.\n",
      "Scheme Latency Volume\n",
      "Chain-of-Thought (CoT) N N\n",
      "Self-Consistency with CoT (CoT-SC) N/k N/k\n",
      "Tree of Thoughts (ToT) logkN O (logkN)\n",
      "Graph of Thoughts (GoT) logkN N\n",
      "Table 2: Comparison of prompting schemes, with respect\n",
      "to their fundamental tradeoff between latency and volume.\n",
      "GoT offers the best tradeoff.\n",
      "7 Evaluation\n",
      "We show the advantages of GoT over the state of the art. We\n",
      "focus on comparing GoT to ToT, as it was shown to consis-\n",
      "tently outperform other schemes. Still, for a broad compari-\n",
      "son, we also experiment with IO, CoT, and CoT-SC. As our\n",
      "analysis results in a large evaluation space, we present rep-\n",
      "resentative results and omit data that does not bring relevant\n",
      "insights (e.g., CoT-SC).\n",
      "7.1 Evaluation Methodology\n",
      "We use 100 input samples for each task and comparison\n",
      "baseline. We set the temperature to 1.0 and use a 4k con-\n",
      "text size unless stated otherwise. For each experiment, we\n",
      "fix the numbers of thoughts in respective schemes to achieve\n",
      "similar costs in each experiment.\n",
      "Parameters We experiment extensively with the branch-\n",
      "ing factor kand the number of levels Lto ensure that we\n",
      "compare GoT to cost-effective and advantageous configu-\n",
      "rations. We plot two variants of ToT: one with higher k\n",
      "and lower depth (ToT), the other with lower kbut higher L\n",
      "(ToT2). We usually aim to achieve a sweet spot in the trade-\n",
      "off between sparser generation rounds (lower k) vs. more\n",
      "rounds (larger L). Usually more responses per round is more\n",
      "expensive (e.g., 80 vs. 60 total responses for Figure 7 but $6\n",
      "vs. $3 costs). We also try different problem sizes P(e.g., in\n",
      "sorting, Pstates how many numbers are to be sorted).\n",
      "7\n",
      "IOCoT ToTToT2 GoT0246810121416#incorrectly sorted elements; the lower the better\n",
      "32 elements\n",
      "0.00.20.40.60.81.01.21.41.6\n",
      "IOCoT ToTToT2 GoT0481216202428323640444852566064\n",
      "64 elements\n",
      "0.00.30.60.91.21.51.82.12.42.73.03.33.63.94.24.54.8\n",
      "IOCoT ToTToT2 GoT081624324048566472808896104112120128\n",
      "128 elements\n",
      "012345678910111213141516\n",
      "Total Cost ($); the lower the betterL=2\n",
      "k=20\n",
      "L=3\n",
      "k=10GoT: Figure 4 & Appendix\n",
      "clipped\n",
      "L=4\n",
      "k=20L=7\n",
      "k=10GoT: Figure 4\n",
      "& Appendixclipped\n",
      "L=4\n",
      "k=20\n",
      "L=10\n",
      "k=10GoT:\n",
      "Figure 4\n",
      "&\n",
      "AppendixFigure 5: Number of errors and cost in sorting tasks with ChatGPT-3.5. Landkindicate the structure of ToT (see Sections 3.2\n",
      "and 6).\n",
      "Used LLMs Due to budget restrictions, we focus on GPT-\n",
      "3.5. We also experimented with Llama-2, but it was usually\n",
      "worse than GPT-3.5 and also much slower to run, making it\n",
      "infeasible to obtain enough samples.\n",
      "7.2 Analysis of GoT’s Advantages\n",
      "The results of the analysis are in Figure 5 (sorting), 6 (set\n",
      "intersection), 7 (keyword counting), and 8 (document merg-\n",
      "ing); see Section 5 for the description of specific use cases.\n",
      "Overall, GoT improves the quality of outcomes over all the\n",
      "considered baselines and it reduces inference costs com-\n",
      "pared to ToT .\n",
      "GoT vs. ToT GoT improves upon ToT and ToT2 by a\n",
      "large margin over all the considered problem instances. ToT\n",
      "usually comes with somewhat higher quality than ToT2, but\n",
      "simultaneously much higher costs. GoT’s costs are always\n",
      "lower than ToT, and comparable (in some cases lower, in\n",
      "others higher) to ToT2. For example, it reduces median er-\n",
      "ror by ≈62%, thereby achieving a higher quality of sorting,\n",
      "forP= 128 in comparison to ToT while ensuring >31%\n",
      "cost reductions. These advantages are due to GoT’s ability to\n",
      "decompose complex tasks into simpler subtasks, solve these\n",
      "subtasks independently, and then incrementally merge these\n",
      "outcomes into the final result.\n",
      "GoT vs. IO and CoT GoT consistently delivers much\n",
      "higher quality of outcomes than IO/CoT. For example, for\n",
      "sorting ( P= 64 ), GoT’s median error is ≈65% and ≈83%\n",
      "lower than, respectively, CoT and IO. Yet, the costs of GoT\n",
      "– and ToT – are much higher than in IO and CoT. This is\n",
      "mostly due to our configuration of CoT, where we do not ar-\n",
      "tificially inflate the lengths of the chains of reasoning if this\n",
      "does not improve the outcomes. The higher costs of GoT and\n",
      "ToT are driven by knew thoughts built for each Generate\n",
      "operation; these multiple thoughts are one of the reasons for\n",
      "GoT’s superiority in quality.\n",
      "Increasing Complexity of Tackled Problems Most im-\n",
      "portantly, the advantages of GoT in the quality increase for\n",
      "all the baselines with the growing size of the problem P. Forexample, in sorting, while for P= 32 GoT only negligibly\n",
      "improves upon ToT2, its median error count becomes lower\n",
      "by≈61% for P= 64 and≈69% for P= 128 . The quar-\n",
      "tiles also become respectively better. The results for other\n",
      "schemes also follow the intuition; for example, IO becomes\n",
      "consistently worse with the increasing P, which is expected\n",
      "as a single thought is unlikely to solve a large problem in-\n",
      "stance. Overall, this analysis illustrates that GoT is indeed\n",
      "well-suited for elaborate problem cases , as the execution\n",
      "schedules usually become more complex with the growing\n",
      "problem sizes.\n",
      "7.3 Discussion on Task Decomposition\n",
      "When splitting a task into subtasks and then solving these\n",
      "subtasks, the size of responses and the input (in tokens) are\n",
      "reduced proportionally to the degree of the task decomposi-\n",
      "tion. However, the “static” part of the prompt (i.e., few-shot\n",
      "examples) may become a significant overhead (see GoT4 to\n",
      "GoT8 in Figure 7). Here, we observe that these few-shot ex-\n",
      "amples can usually also be reduced in size (e.g., the passages\n",
      "used to demonstrate keyword counting can also be made\n",
      "smaller and still be indicative of the actual input size), thus\n",
      "actively working towards decreasing the cost (e.g., see the\n",
      "difference between GoT8 and GoTx in Figure 7).\n",
      "The overall goal when conducting graph decomposition is\n",
      "to break down a task to the point, where the LLM can solve\n",
      "it correctly for the majority of time using a single prompt\n",
      "(or with a few additional improvement steps). This signifi-\n",
      "cantly lowers the number of improvement/refinement steps\n",
      "needed during the later stages of the graph exploration. Fur-\n",
      "thermore, as indicated by our results, combining or concate-\n",
      "nating subresults is usually an easier task than solving large\n",
      "task instances from scratch. Hence, the LLM is often suc-\n",
      "cessful when aggregating the final solution.\n",
      "8 Related Work\n",
      "We summarize relations between GoT and related work.\n",
      "8\n",
      "IOCoT T oTT oT2GoT024681012141618#incorrect elements; the lower the better\n",
      "7 6 31 29 4332 elements\n",
      "0.00.20.40.60.81.01.21.41.61.8\n",
      "IOCoT ToTToT2 GoT048121620242832\n",
      "0 0 0 0 464 elements\n",
      "0.00.61.21.82.43.03.64.24.8\n",
      "IOCoT ToTToT2 GoT0816243240485664728088\n",
      "0 0 0 0 0128 elements\n",
      "01234567891011\n",
      "Total Cost ($); the lower the betterL=2\n",
      "k=20Solved \n",
      "correctly:\n",
      "L=7\n",
      "k=10\n",
      "L=4\n",
      "k=25\n",
      "L=9\n",
      "k=10L=3\n",
      "k=10L=4\n",
      "k=20GoT: Appendix GoT: Appendix GoT: AppendixFigure 6: Number of errors and cost in set intersection tasks with ChatGPT-3.5. Landkindicate the structure of ToT (see\n",
      "Sections 3.2 and 6).\n",
      "IO CoT ToT ToT2 GoT4 GoT8 GoTx05101520253035Number of errors; the lower the better\n",
      "0 0 1 0 8 7 25\n",
      "012345678\n",
      "Total Cost ($); the lower the betterSamples solved\n",
      "correctly\n",
      "Splits the input text into 4 passages, counts\n",
      "keywords in each one, aggregates the sub-\n",
      "results always 2 at a time\n",
      "L=4\n",
      "k=20\n",
      "L=6\n",
      "k=10Splits the\n",
      "input into\n",
      "sentences\n",
      "(each input\n",
      "has 12-19\n",
      "sentences)As GoT4, but splits the\n",
      "input text into 8 passages\n",
      "Figure 7: Number of errors and cost in keyword counting\n",
      "with ChatGPT-3.5. Landkindicate the structure of ToT (see\n",
      "Sections 3.2 and 6).\n",
      "8.1 Prompting Paradigms & Approaches\n",
      "We detail different prompting paradigms in Section 1 and\n",
      "Table 1. There are numerous other works related to prompt-\n",
      "ing. We now briefly summarize selected most related ones;\n",
      "more extensive descriptions can be found in dedicated sur-\n",
      "veys [34, 40, 69, 70]. Wang et al. proposed Plan-and-\n",
      "Solve, an approach to enhance CoT with an explicit plan-\n",
      "ning stage [66]. Using complexity-based criteria to enhance\n",
      "prompting within a CoT was designed by Fu et al. [29, 67].\n",
      "The self-taught reasoner (STaR) [80] generates several chain\n",
      "of thoughts, and selects the ones that are valid. Similarly, a\n",
      "scheme by Shum et al. [61] generates a pool of CoT candi-\n",
      "dates, and selects the best candidate based on whether the\n",
      "candidates match the ground truth and on a policy gradient-\n",
      "based method. Automatic prompt generation overcomes the\n",
      "IO CoT ToT GoT GoT202468Score (out of 10); the higher the better\n",
      "03691215\n",
      "Total Cost ($); the lower the betterL=3\n",
      "k=10Aggregation of fully\n",
      "merged NDAs\n",
      "Aggregation\n",
      "of partially\n",
      "merged\n",
      "NDAsFigure 8: Score and cost in document merging with\n",
      "ChatGPT-3.5. Landkindicate the structure of ToT (see Sec-\n",
      "tions 3.2 and 6). Number of samples: 50; context size: 16k\n",
      "tokens.\n",
      "issues of scaling in CoT [41, 42, 59]. Zhou et al. pro-\n",
      "pose to harness selecting the best prompt out of a candidate\n",
      "set [84]. Skeleon-of-Thought [47] generates at first a num-\n",
      "ber of skeleton answers (brief bullet points of 3 to 5 words)\n",
      "and expands on these points in parallel in a second step.\n",
      "Finally, in prompt chaining, one cascades different LLMs.\n",
      "This enables prompting different LLMs via different con-\n",
      "texts, enabling more powerful reasoning [21, 23, 48, 51, 72,\n",
      "73, 73]. GoT is orthogonal to this class of schemes, as it\n",
      "focuses on a single context capabilities.\n",
      "8.2 Self-Reflection & Self-Evaluation\n",
      "Self-reflection and self-evaluation were introduced re-\n",
      "cently [45, 49, 60, 75, 85]. They are used to enhance dif-\n",
      "ferent tasks, for example for code generation [17] or com-\n",
      "9\n",
      "puter operation tasks [39]. In GoT, we partially rely on\n",
      "self-evaluation when taking decisions on how to expand the\n",
      "graph of thoughts within a prompt.\n",
      "8.3 LLMs & Planning\n",
      "There are many works recently on how to plan complex\n",
      "tasks with LLMs [36, 37, 68, 76, 78, 81]. GoT could be seen\n",
      "as a generic framework that could potentially be used to en-\n",
      "hance such schemes, by offering a paradigm for generating\n",
      "complex graph-based plans.\n",
      "8.4 Graphs and Graph Computing\n",
      "Graphs have become an immensely popular and important\n",
      "part of the general computing landscape [31, 32, 44, 46, 56].\n",
      "Recently, there has been a growing interest in domains\n",
      "such as graph databases [2–4, 7, 55], graph pattern match-\n",
      "ing [8, 10, 11, 18, 25, 62], graph streaming [1, 22, 26],\n",
      "and graph machine learning as well as graph neural net-\n",
      "works [5, 6, 12, 16, 30, 33, 33, 57, 74, 82, 83]. The graph\n",
      "abstraction has been fruitful for many modern research do-\n",
      "mains, such as social sciences (e.g., studying human inter-\n",
      "actions), bioinformatics (e.g., analyzing protein structures),\n",
      "chemistry (e.g., designing chemical compounds), medicine\n",
      "(e.g., drug discovery), cybersecurity (e.g., identifying in-\n",
      "truder machines), healthcare (e.g., exposing groups of peo-\n",
      "ple who submit fraudulent claims), web graph analysis (e.g.,\n",
      "providing accurate search services), entertainment services\n",
      "(e.g., predicting movie popularity), linguistics (e.g., model-\n",
      "ing relationships between words), transportation (e.g., find-\n",
      "ing efficient routes), physics (e.g., understanding phase tran-\n",
      "sitions and critical phenomena), and many others [15, 20,\n",
      "35, 38, 44]. In this work, we harness the graph abstraction\n",
      "as a key mechanism that enhances prompting capabilities in\n",
      "LLMs.\n",
      "9 Conclusion\n",
      "Prompt engineering is one of the central new domains of\n",
      "the large language model (LLM) research. It enables using\n",
      "LLMs efficiently, without any model updates. However, de-\n",
      "signing effective prompts is a challenging task.\n",
      "In this work, we propose Graph of Thoughts (GoT), a new\n",
      "paradigm that enables the LLM to solve different tasks effec-\n",
      "tively without any model updates. The key idea is to model\n",
      "the LLM reasoning as an arbitrary graph, where thoughts\n",
      "are vertices and dependencies between thoughts are edges.\n",
      "This enables novel transformations of thoughts, such as ag-\n",
      "gregation. Human’s task solving is often non-linear, and it\n",
      "involves combining intermediate solutions into final ones,\n",
      "or changing the flow of reasoning upon discovering new in-\n",
      "sights. GoT reflects this with its graph structure.\n",
      "GoT outperforms other prompting schemes, for example\n",
      "ensuring 62% increase in the quality of sorting over ToT,\n",
      "while simultaneously reducing costs by >31%. We also pro-\n",
      "pose a novel metric for a prompting scheme, the volume of\n",
      "a thought, to indicate the scope of information that a given\n",
      "LLM output could carry with it, where GoT also excels. This\n",
      "provides a step towards more principled prompt engineering.The graph abstraction has been the foundation of several\n",
      "successful designs in computing and AI over last decades,\n",
      "for example AlphaFold for protein predictions. Our work\n",
      "harnesses it within the realm of prompt engineering.\n",
      "Acknowledgements\n",
      "We thank Hussein Harake, Colin McMurtrie, Mark Klein, An-\n",
      "gelo Mangili, and the whole CSCS team granting access to the\n",
      "Ault and Daint machines, and for their excellent technical sup-\n",
      "port. We thank Timo Schneider for help with infrastructure at\n",
      "SPCL. This project received funding from the European Re-\n",
      "search Council (Project PSAP, No. 101002047), and the European\n",
      "High-Performance Computing Joint Undertaking (JU) under grant\n",
      "agreement No. 955513 (MAELSTROM). This project was sup-\n",
      "ported by the ETH Future Computing Laboratory (EFCL), financed\n",
      "by a donation from Huawei Technologies. This project received\n",
      "funding from the European Union’s HE research and innovation\n",
      "programme under the grant agreement No. 101070141 (Project\n",
      "GLACIATION).\n",
      "References\n",
      "[1] Besta, M.; Fischer, M.; Kalavri, V .; Kapralov, M.; and\n",
      "Hoefler, T. 2023. Practice of Streaming Processing\n",
      "of Dynamic Graphs: Concepts, Models, and Systems.\n",
      "IEEE Transactions on Parallel and Distributed Sys-\n",
      "tems, 34(6): 1860–1876.\n",
      "[2] Besta, M.; Gerstenberger, R.; Blach, N.; Fischer, M.;\n",
      "and Hoefler, T. 2023. GDI: A Graph Database Inter-\n",
      "face Standard. https://github.com/spcl/GDI-RMA. Ac-\n",
      "cessed: 2023-09-05.\n",
      "[3] Besta, M.; Gerstenberger, R.; Fischer, M.; Podstawski,\n",
      "M.; Blach, N.; Egeli, B.; Mitenkov, G.; Chlapek, W.;\n",
      "Michalewicz, M.; Niewiadomski, H.; M ¨uller, J.; and\n",
      "Hoefler, T. 2023. The Graph Database Interface: Scal-\n",
      "ing Online Transactional and Analytical Graph Work-\n",
      "loads to Hundreds of Thousands of Cores. In Proceed-\n",
      "ings of the International Conference for High Perfor-\n",
      "mance Computing, Networking, Storage and Analysis ,\n",
      "SC ’23. ACM.\n",
      "[4] Besta, M.; Gerstenberger, R.; Peter, E.; Fischer, M.;\n",
      "Podstawski, M.; Barthels, C.; Alonso, G.; and Hoefler,\n",
      "T. 2023. Demystifying Graph Databases: Analysis and\n",
      "Taxonomy of Data Organization, System Designs, and\n",
      "Graph Queries. ACM Comput. Surv. , 56(2).\n",
      "[5] Besta, M.; Grob, R.; Miglioli, C.; Bernold, N.;\n",
      "Kwa ´sniewski, G.; Gjini, G.; Kanakagiri, R.; Ashkboos,\n",
      "S.; Gianinazzi, L.; Dryden, N.; and Hoefler, T. 2022.\n",
      "Motif Prediction with Graph Neural Networks. In\n",
      "Proceedings of the 28th ACM SIGKDD Conference\n",
      "on Knowledge Discovery and Data Mining , KDD ’22,\n",
      "35–45.\n",
      "[6] Besta, M.; and Hoefler, T. 2022. Parallel and Dis-\n",
      "tributed Graph Neural Networks: An In-Depth Concur-\n",
      "rency Analysis. arXiv:2205.09702.\n",
      "[7] Besta, M.; Iff, P.; Scheidl, F.; Osawa, K.; Dryden, N.;\n",
      "Podstawski, M.; Chen, T.; and Hoefler, T. 2022. Neural\n",
      "Graph Databases. In Proceedings of the First Learning\n",
      "on Graphs Conference , volume 198 of Proceedings of\n",
      "Machine Learning Research , 31:1–31:38. PMLR.\n",
      "10\n",
      "[8] Besta, M.; Kanakagiri, R.; Kwa ´sniewski, G.;\n",
      "Ausavarungnirun, R.; Ber ´anek, J.; Kanellopoulos,\n",
      "K.; Janda, K.; V onarburg-Shmaria, Z.; Gianinazzi,\n",
      "L.; Stefan, I.; Luna, J. G.; Golinowski, J.; Copik,\n",
      "M.; Kapp-Schwoerer, L.; Di Girolamo, S.; Blach,\n",
      "N.; Konieczny, M.; Mutlu, O.; and Hoefler, T. 2021.\n",
      "SISA: Set-Centric Instruction Set Architecture for\n",
      "Graph Mining on Processing-in-Memory Systems. In\n",
      "Proceedings of the 54th Annual IEEE/ACM Interna-\n",
      "tional Symposium on Microarchitecture , MICRO ’21,\n",
      "282–297.\n",
      "[9] Besta, M.; Kanakagiri, R.; Mustafa, H.; Karasikov,\n",
      "M.; R ¨atsch, G.; Hoefler, T.; and Solomonik, E. 2020.\n",
      "Communication-Efficient Jaccard Similarity for High-\n",
      "Performance Distributed Genome Comparisons. In\n",
      "Proceedings of the IEEE International Parallel and\n",
      "Distributed Processing Symposium , IPDPS ’20, 1122–\n",
      "1132.\n",
      "[10] Besta, M.; Miglioli, C.; Labini, P. S.; T ˇetek, J.; Iff, P.;\n",
      "Kanakagiri, R.; Ashkboos, S.; Janda, K.; Podstawski,\n",
      "M.; Kwa ´sniewski, G.; Gleinig, N.; Vella, F.; Mutlu, O.;\n",
      "and Hoefler, T. 2022. ProbGraph: High-Performance\n",
      "and High-Accuracy Graph Mining with Probabilistic\n",
      "Set Representations. In Proceedings of the Interna-\n",
      "tional Conference on High Performance Computing,\n",
      "Networking, Storage and Analysis , SC ’22. IEEE.\n",
      "[11] Besta, M.; V onarburg-Shmaria, Z.; Schaffner, Y .;\n",
      "Schwarz, L.; Kwa ´sniewski, G.; Gianinazzi, L.; Be-\n",
      "ranek, J.; Janda, K.; Holenstein, T.; Leisinger, S.;\n",
      "Tatkowski, P.; Ozdemir, E.; Balla, A.; Copik, M.; Lin-\n",
      "denberger, P.; Konieczny, M.; Mutlu, O.; and Hoe-\n",
      "fler, T. 2021. GraphMineSuite: Enabling High-\n",
      "Performance and Programmable Graph Mining Algo-\n",
      "rithms with Set Algebra. Proc. VLDB Endow. , 14(11):\n",
      "1922–1935.\n",
      "[12] Bronstein, M. M.; Bruna, J.; LeCun, Y .; Szlam, A.; and\n",
      "Vandergheynst, P. 2017. Geometric Deep Learning:\n",
      "Going beyond Euclidean data. IEEE Signal Process-\n",
      "ing Magazine , 34(4): 18–42.\n",
      "[13] Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Ka-\n",
      "plan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam,\n",
      "P.; Sastry, G.; Askell, A.; Agarwal, S.; Herbert-V oss,\n",
      "A.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.;\n",
      "Ziegler, D.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.;\n",
      "Sigler, E.; Litwin, M.; Gray, S.; Chess, B.; Clark, J.;\n",
      "Berner, C.; McCandlish, S.; Radford, A.; Sutskever, I.;\n",
      "and Amodei, D. 2020. Language Models are Few-Shot\n",
      "Learners. In Advances in Neural Information Process-\n",
      "ing Systems (NeurIPS ’20) , volume 33, 1877–1901.\n",
      "Curran Associates.\n",
      "[14] Bubeck, S.; Chandrasekaran, V .; Eldan, R.; Gehrke,\n",
      "J.; Horvitz, E.; Kamar, E.; Lee, P.; Lee, Y . T.; Li,\n",
      "Y .; Lundberg, S.; Nori, H.; Palangi, H.; Ribeiro,\n",
      "M. T.; and Zhang, Y . 2023. Sparks of Artificial\n",
      "General Intelligence: Early experiments with GPT-4.\n",
      "arXiv:2303.12712.\n",
      "[15] Chakrabarti, D.; and Faloutsos, C. 2006. Graph Min-ing: Laws, Generators, and Algorithms. ACM Comput.\n",
      "Surv. , 38(1).\n",
      "[16] Chami, I.; Abu-El-Haija, S.; Perozzi, B.; R ´e, C.;\n",
      "and Murphy, K. 2020. Machine Learning on\n",
      "Graphs: A Model and Comprehensive Taxonomy.\n",
      "arXiv:2005.03675.\n",
      "[17] Chen, X.; Lin, M.; Sch ¨arli, N.; and Zhou, D. 2023.\n",
      "Teaching Large Language Models to Self-Debug.\n",
      "arXiv:2304.05128.\n",
      "[18] Cheng, J.; Yu, J. X.; Ding, B.; Philip, S. Y .; and Wang,\n",
      "H. 2008. Fast Graph Pattern Matching. In Proceedings\n",
      "of the IEEE 24th International Conference on Data En-\n",
      "gineering , ICDE ’08, 913–922.\n",
      "[19] Chowdhery, A.; Narang, S.; Devlin, J.; Bosma,\n",
      "M.; Mishra, G.; Roberts, A.; Barham, P.; Chung,\n",
      "H. W.; Sutton, C.; Gehrmann, S.; Schuh, P.; Shi, K.;\n",
      "Tsvyashchenko, S.; Maynez, J.; Rao, A.; Barnes, P.;\n",
      "Tay, Y .; Shazeer, N.; Prabhakaran, V .; Reif, E.; Du,\n",
      "N.; Hutchinson, B.; Pope, R.; Bradbury, J.; Austin, J.;\n",
      "Isard, M.; Gur-Ari, G.; Yin, P.; Duke, T.; Levskaya,\n",
      "A.; Ghemawat, S.; Dev, S.; Michalewski, H.; Garcia,\n",
      "X.; Misra, V .; Robinson, K.; Fedus, L.; Zhou, D.; Ip-\n",
      "polito, D.; Luan, D.; Lim, H.; Zoph, B.; Spiridonov,\n",
      "A.; Sepassi, R.; Dohan, D.; Agrawal, S.; Omernick,\n",
      "M.; Dai, A. M.; Pillai, T. S.; Pellat, M.; Lewkowycz,\n",
      "A.; Moreira, E.; Child, R.; Polozov, O.; Lee, K.; Zhou,\n",
      "Z.; Wang, X.; Saeta, B.; Diaz, M.; Firat, O.; Catasta,\n",
      "M.; Wei, J.; Meier-Hellstern, K.; Eck, D.; Dean, J.;\n",
      "Petrov, S.; and Fiedel, N. 2022. PaLM: Scaling Lan-\n",
      "guage Modeling with Pathways. arXiv:2204.02311.\n",
      "[20] Cook, D. J.; and Holder, L. B., eds. 2006. Mining\n",
      "Graph Data . John Wiley & Sons.\n",
      "[21] Creswell, A.; Shanahan, M.; and Higgins, I. 2022.\n",
      "Selection-Inference: Exploiting Large Language\n",
      "Models for Interpretable Logical Reasoning.\n",
      "arXiv:2205.09712.\n",
      "[22] Dhulipala, L.; Blelloch, G. E.; and Shun, J. 2019. Low-\n",
      "Latency Graph Streaming Using Compressed Purely-\n",
      "Functional Trees. In Proceedings of the 40th ACM\n",
      "SIGPLAN Conference on Programming Language De-\n",
      "sign and Implementation , PLDI ’19, 918–934.\n",
      "[23] Dohan, D.; Xu, W.; Lewkowycz, A.; Austin, J.; Bieber,\n",
      "D.; Lopes, R. G.; Wu, Y .; Michalewski, H.; Saurous,\n",
      "R. A.; Sohl-Dickstein, J.; Murphy, K.; and Sutton, C.\n",
      "2022. Language Model Cascades. In Beyond Bayes:\n",
      "Paths Towards Universal Reasoning Systems , Work-\n",
      "shop at ICML ’22.\n",
      "[24] Drori, I.; Zhang, S.; Shuttleworth, R.; Tang, L.; Lu, A.;\n",
      "Ke, E.; Liu, K.; Chen, L.; Tran, S.; Cheng, N.; Wang,\n",
      "R.; Singh, N.; Patti, T. L.; Lynch, J.; Shporer, A.;\n",
      "Verma, N.; Wu, E.; and Strang, G. 2022. A neural net-\n",
      "work solves, explains, and generates university math\n",
      "problems by program synthesis and few-shot learning\n",
      "at human level. Proceedings of the National Academy\n",
      "of Sciences , 119(32): e2123433119.\n",
      "[25] Fan, W.; Li, J.; Ma, S.; Tang, N.; Wu, Y .; and Wu,\n",
      "Y . 2010. Graph Pattern Matching: From Intractable\n",
      "11\n",
      "to Polynomial Time. Proc. VLDB Endow. , 3(1–2):\n",
      "264–275.\n",
      "[26] Feng, G.; Meng, X.; and Ammar, K. 2015. DIS-\n",
      "TINGER: A distributed graph data structure for mas-\n",
      "sive dynamic graph processing. In Proccedings of the\n",
      "IEEE International Conference on Big Data , Big Data\n",
      "’15, 1814–1822.\n",
      "[27] Friggeri, A.; Chelius, G.; and Fleury, E. 2011. Trian-\n",
      "gles to Capture Social Cohesion. In Proceedings of\n",
      "the IEEE Third International Conference on Privacy,\n",
      "Security, Risk and Trust and IEEE Third International\n",
      "Conference on Social Computing , PASSAT/SocialCom\n",
      "’11, 258–265.\n",
      "[28] Friston, K. 2008. Hierarchical Models in the Brain.\n",
      "PLOS Computational Biology , 4(11): 1–24.\n",
      "[29] Fu, Y .; Peng, H.; Sabharwal, A.; Clark, P.; and Khot,\n",
      "T. 2022. Complexity-Based Prompting for Multi-Step\n",
      "Reasoning. arXiv:2210.00720.\n",
      "[30] Gianinazzi, L.; Fries, M.; Dryden, N.; Ben-Nun, T.;\n",
      "Besta, M.; and Hoefler, T. 2021. Learning Combina-\n",
      "torial Node Labeling Algorithms. arXiv:2106.03594.\n",
      "[31] Gregor, D.; and Lumsdaine, A. 2005. Lifting Sequen-\n",
      "tial Graph Algorithms for Distributed-Memory Parallel\n",
      "Computation. SIGPLAN Not. , 40(10): 423–437.\n",
      "[32] Gregor, D.; and Lumsdaine, A. 2005. The Parallel\n",
      "BGL: A generic library for distributed graph compu-\n",
      "tations. Parallel Object-Oriented Scientific Computing\n",
      "(POOSC) .\n",
      "[33] Hamilton, W. L.; Ying, R.; and Leskovec, J. 2017. Rep-\n",
      "resentation Learning on Graphs: Methods and Appli-\n",
      "cations. Bulletin of the Technical Committee on Data\n",
      "Engineering , 40(3): 52–74.\n",
      "[34] Hartmann, M.; and Sonntag, D. 2022. A survey on\n",
      "improving NLP models with human explanations. In\n",
      "Proceedings of the First Workshop on Learning with\n",
      "Natural Language Supervision , 40–47. Association for\n",
      "Computational Linguistics.\n",
      "[35] Horv ´ath, T.; G ¨artner, T.; and Wrobel, S. 2004. Cyclic\n",
      "Pattern Kernels for Predictive Graph Mining. In Pro-\n",
      "ceedings of the Tenth ACM SIGKDD International\n",
      "Conference on Knowledge Discovery and Data Min-\n",
      "ing, KDD ’04, 158–167.\n",
      "[36] Huang, W.; Abbeel, P.; Pathak, D.; and Mordatch, I.\n",
      "2022. Language Models as Zero-Shot Planners: Ex-\n",
      "tracting Actionable Knowledge for Embodied Agents.\n",
      "InProceedings of the 39th International Conference\n",
      "on Machine Learning , volume 162 of Proceedings of\n",
      "Machine Learning Research , 9118–9147. PMLR.\n",
      "[37] Huang, W.; Xia, F.; Xiao, T.; Chan, H.; Liang, J.; Flo-\n",
      "rence, P.; Zeng, A.; Tompson, J.; Mordatch, I.; Cheb-\n",
      "otar, Y .; Sermanet, P.; Brown, N.; Jackson, T.; Luu,\n",
      "L.; Levine, S.; Hausman, K.; and Ichter, B. 2022. In-\n",
      "ner Monologue: Embodied Reasoning through Plan-\n",
      "ning with Language Models. arXiv:2207.05608.\n",
      "[38] Jiang, C.; Coenen, F.; and Zito, M. 2013. A survey of\n",
      "frequent subgraph mining algorithms. The Knowledge\n",
      "Engineering Review , 28(1): 75–105.[39] Kim, G.; Baldi, P.; and McAleer, S. 2023. Language\n",
      "Models can Solve Computer Tasks. arXiv:2303.17491.\n",
      "[40] Lertvittayakumjorn, P.; and Toni, F. 2021.\n",
      "Explanation-Based Human Debugging of NLP\n",
      "Models: A Survey. Transactions of the Association for\n",
      "Computational Linguistics , 9: 1508–1528.\n",
      "[41] Lester, B.; Al-Rfou, R.; and Constant, N. 2021. The\n",
      "Power of Scale for Parameter-Efficient Prompt Tun-\n",
      "ing. In Proceedings of the Conference on Empiri-\n",
      "cal Methods in Natural Language Processing , EMNLP\n",
      "’21, 3045–3059. Association for Computational Lin-\n",
      "guistics.\n",
      "[42] Li, X. L.; and Liang, P. 2021. Prefix-Tuning:\n",
      "Optimizing Continuous Prompts for Generation.\n",
      "arXiv:2101.00190.\n",
      "[43] Long, J. 2023. Large Language Model Guided Tree-\n",
      "of-Thought. arXiv:2305.08291.\n",
      "[44] Lumsdaine, A.; Gregor, D.; Hendrickson, B.; and\n",
      "Berry, J. 2007. Challenges in Parallel Graph Process-\n",
      "ing. Parallel Processing Letters , 17(1): 5–20.\n",
      "[45] Madaan, A.; Tandon, N.; Gupta, P.; Hallinan, S.; Gao,\n",
      "L.; Wiegreffe, S.; Alon, U.; Dziri, N.; Prabhumoye, S.;\n",
      "Yang, Y .; Gupta, S.; Majumder, B. P.; Hermann, K.;\n",
      "Welleck, S.; Yazdanbakhsh, A.; and Clark, P. 2023.\n",
      "Self-Refine: Iterative Refinement with Self-Feedback.\n",
      "arXiv:2303.17651.\n",
      "[46] Malewicz, G.; Austern, M. H.; Bik, A. J.; Dehnert,\n",
      "J. C.; Horn, I.; Leiser, N.; and Czajkowski, G. 2010.\n",
      "Pregel: A System for Large-Scale Graph Processing. In\n",
      "Proceedings of the International Conference on Man-\n",
      "agement of Data , SIGMOD ’10, 135–146. ACM.\n",
      "[47] Ning, X.; Lin, Z.; Zhou, Z.; Wang, Z.; Yang, H.; and\n",
      "Wang, Y . 2023. Skeleton-of-Thought: Large Language\n",
      "Models Can Do Parallel Decoding. arXiv:2307.15337.\n",
      "[48] Nye, M.; Andreassen, A. J.; Gur-Ari, G.; Michalewski,\n",
      "H.; Austin, J.; Bieber, D.; Dohan, D.; Lewkowycz, A.;\n",
      "Bosma, M.; Luan, D.; Sutton, C.; and Odena, A. 2021.\n",
      "Show Your Work: Scratchpads for Intermediate Com-\n",
      "putation with Language Models. arXiv:2112.00114.\n",
      "[49] Paul, D.; Ismayilzada, M.; Peyrard, M.; Borges, B.;\n",
      "Bosselut, A.; West, R.; and Faltings, B. 2023. RE-\n",
      "FINER: Reasoning Feedback on Intermediate Repre-\n",
      "sentations. arXiv:2304.01904.\n",
      "[50] Prat-P ´erez, A.; Dominguez-Sal, D.; Brunat, J. M.; and\n",
      "Larriba-Pey, J.-L. 2012. Shaping Communities out\n",
      "of Triangles. In Proceedings of the 21st ACM Inter-\n",
      "national Conference on Information and Knowledge\n",
      "Management , CIKM ’12, 1677–1681.\n",
      "[51] Qiao, S.; Ou, Y .; Zhang, N.; Chen, X.; Yao, Y .; Deng,\n",
      "S.; Tan, C.; Huang, F.; and Chen, H. 2023. Reasoning\n",
      "with Language Model Prompting: A Survey. In Pro-\n",
      "ceedings of the 61st Annual Meeting of the Association\n",
      "for Computational Linguistics , ACL ’23, 5368–5393.\n",
      "Association for Computational Linguistics.\n",
      "[52] qrdlgit. 2023. graph-of-thoughts Repository. https:\n",
      "//github.com/qrdlgit/graph-of-thoughts. Accessed:\n",
      "2023-10-11.\n",
      "12\n",
      "[53] Radford, A.; Narasimhan, K.; Salimans, T.; and\n",
      "Sutskever, I. 2018. Improving Language Understand-\n",
      "ing by Generative Pre-Training. https://openai.com/\n",
      "research/language-unsupervised. Accessed: 2023-09-\n",
      "06.\n",
      "[54] Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.;\n",
      "and Sutskever, I. 2019. Language Models are Unsuper-\n",
      "vised Multitask Learners. https://openai.com/research/\n",
      "better-language-models. Accessed: 2023-09-06.\n",
      "[55] Robinson, I.; Webber, J.; and Eifrem, E. 2015. Graph\n",
      "Databases: New Opportunities for Connected Data .\n",
      "O’Reilly Media, 2nd edition.\n",
      "[56] Sakr, S.; Bonifati, A.; V oigt, H.; Iosup, A.; Ammar, K.;\n",
      "Angles, R.; Aref, W.; Arenas, M.; Besta, M.; Boncz,\n",
      "P. A.; Daudjee, K.; Valle, E. D.; Dumbrava, S.; Har-\n",
      "tig, O.; Haslhofer, B.; Hegeman, T.; Hidders, J.; Hose,\n",
      "K.; Iamnitchi, A.; Kalavri, V .; Kapp, H.; Martens, W.;\n",
      "¨Ozsu, M. T.; Peukert, E.; Plantikow, S.; Ragab, M.; Ri-\n",
      "peanu, M. R.; Salihoglu, S.; Schulz, C.; Selmer, P.; Se-\n",
      "queda, J. F.; Shinavier, J.; Sz ´arnyas, G.; Tommasini,\n",
      "R.; Tumeo, A.; Uta, A.; Varbanescu, A. L.; Wu, H.-\n",
      "Y .; Yakovets, N.; Yan, D.; and Yoneki, E. 2021. The\n",
      "Future is Big Graphs: A Community View on Graph\n",
      "Processing Systems. Commun. ACM , 64(9): 62–71.\n",
      "[57] Scarselli, F.; Gori, M.; Tsoi, A. C.; Hagenbuchner, M.;\n",
      "and Monfardini, G. 2008. The Graph Neural Network\n",
      "Model. IEEE Transactions on Neural Networks , 20(1):\n",
      "61–80.\n",
      "[58] Schaeffer, S. E. 2007. Graph clustering. Computer\n",
      "Science Review , 1(1): 27–64.\n",
      "[59] Shin, T.; Razeghi, Y .; Logan IV , R. L.; Wallace, E.;\n",
      "and Singh, S. 2020. AutoPrompt: Eliciting Knowledge\n",
      "from Language Models with Automatically Generated\n",
      "Prompts. arXiv:2010.15980.\n",
      "[60] Shinn, N.; Labash, B.; and Gopinath, A. 2023. Re-\n",
      "flexion: Language Agents with Verbal Reinforcement\n",
      "Learning. arXiv:2303.11366.\n",
      "[61] Shum, K.; Diao, S.; and Zhang, T. 2023. Automatic\n",
      "Prompt Augmentation and Selection with Chain-of-\n",
      "Thought from Labeled Data. arXiv:2302.12822.\n",
      "[62] Teixeira, C. H. C.; Fonseca, A. J.; Serafini, M.;\n",
      "Siganos, G.; Zaki, M. J.; and Aboulnaga, A. 2015.\n",
      "Arabesque: A System for Distributed Graph Mining.\n",
      "InProceedings of the 25th Symposium on Operating\n",
      "Systems Principles , SOSP ’15, 425–440. ACM.\n",
      "[63] Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.;\n",
      "Lachaux, M.-A.; Lacroix, T.; Rozi `ere, B.; Goyal,\n",
      "N.; Hambro, E.; Azhar, F.; Rodriguez, A.; Joulin,\n",
      "A.; Grave, E.; and Lample, G. 2023. LLaMA:\n",
      "Open and Efficient Foundation Language Models.\n",
      "arXiv:2302.13971.\n",
      "[64] Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Alma-\n",
      "hairi, A.; Babaei, Y .; Bashlykov, N.; Batra, S.; Bhar-\n",
      "gava, P.; Bhosale, S.; Bikel, D.; Blecher, L.; Ferrer,\n",
      "C. C.; Chen, M.; Cucurull, G.; Esiobu, D.; Fernandes,\n",
      "J.; Fu, J.; Fu, W.; Fuller, B.; Gao, C.; Goswami, V .;\n",
      "Goyal, N.; Hartshorn, A.; Hosseini, S.; Hou, R.; Inan,H.; Kardas, M.; Kerkez, V .; Khabsa, M.; Kloumann,\n",
      "I.; Korenev, A.; Koura, P. S.; Lachaux, M.-A.; Lavril,\n",
      "T.; Lee, J.; Liskovich, D.; Lu, Y .; Mao, Y .; Martinet,\n",
      "X.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y .;\n",
      "Poulton, A.; Reizenstein, J.; Rungta, R.; Saladi, K.;\n",
      "Schelten, A.; Silva, R.; Smith, E. M.; Subramanian,\n",
      "R.; Tan, X. E.; Tang, B.; Taylor, R.; Williams, A.;\n",
      "Kuan, J. X.; Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y .; Fan,\n",
      "A.; Kambadur, M.; Narang, S.; Rodriguez, A.; Sto-\n",
      "jnic, R.; Edunov, S.; and Scialom, T. 2023. Llama\n",
      "2: Open Foundation and Fine-Tuned Chat Models.\n",
      "arXiv:2307.09288.\n",
      "[65] Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.;\n",
      "Jones, L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I.\n",
      "2017. Attention is All you Need. In Advances in Neu-\n",
      "ral Information Processing Systems (NIPS ’17) , vol-\n",
      "ume 30. Curran Associates.\n",
      "[66] Wang, L.; Xu, W.; Lan, Y .; Hu, Z.; Lan, Y .; Lee, R.\n",
      "K.-W.; and Lim, E.-P. 2023. Plan-and-Solve Prompt-\n",
      "ing: Improving Zero-Shot Chain-of-Thought Reason-\n",
      "ing by Large Language Models. In Proceedings of the\n",
      "61st Annual Meeting of the Association for Computa-\n",
      "tional Linguistics , ACL ’23, 2609–2634. Association\n",
      "for Computational Linguistics.\n",
      "[67] Wang, X.; Wei, J.; Schuurmans, D.; Le, Q. V .; Chi,\n",
      "E. H.; Narang, S.; Chowdhery, A.; and Zhou, D. 2023.\n",
      "Self-Consistency Improves Chain of Thought Rea-\n",
      "soning in Language Models. In Proceedings of the\n",
      "Eleventh International Conference on Learning Rep-\n",
      "resentations , ICLR ’23.\n",
      "[68] Wang, Z.; Cai, S.; Chen, G.; Liu, A.; Ma, X.; and\n",
      "Liang, Y . 2023. Describe, Explain, Plan and Select:\n",
      "Interactive Planning with Large Language Models En-\n",
      "ables Open-World Multi-Task Agents. In Advances in\n",
      "Neural Information Processing Systems (NeurIPS ’23) ,\n",
      "volume 36. Curran Associates.\n",
      "[69] Wang, Z.; Zhang, G.; Yang, K.; Shi, N.; Zhou, W.;\n",
      "Hao, S.; Xiong, G.; Li, Y .; Sim, M. Y .; Chen, X.;\n",
      "Zhu, Q.; Yang, Z.; Nik, A.; Liu, Q.; Lin, C.; Wang,\n",
      "S.; Liu, R.; Chen, W.; Xu, K.; Liu, D.; Guo, Y .; and\n",
      "Fu, J. 2023. Interactive Natural Language Processing.\n",
      "arXiv:2305.13246.\n",
      "[70] Wang, Z. J.; Choi, D.; Xu, S.; and Yang, D. 2021.\n",
      "Putting Humans in the Natural Language Processing\n",
      "Loop: A Survey. In Proceedings of the First Work-\n",
      "shop on Bridging Human-Computer Interaction and\n",
      "Natural Language Processing , 47–52. Association for\n",
      "Computational Linguistics.\n",
      "[71] Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Chi,\n",
      "E.; Le, Q.; and Zhou, D. 2022. Chain-of-Thought\n",
      "Prompting Elicits Reasoning in Large Language Mod-\n",
      "els. arXiv:2201.11903.\n",
      "[72] Wu, T.; Jiang, E.; Donsbach, A.; Gray, J.; Molina, A.;\n",
      "Terry, M.; and Cai, C. J. 2022. PromptChainer: Chain-\n",
      "ing Large Language Model Prompts through Visual\n",
      "Programming. In Extended Abstracts of the Confer-\n",
      "ence on Human Factors in Computing Systems , CHI\n",
      "EA ’22. ACM.\n",
      "13\n",
      "[73] Wu, T.; Terry, M.; and Cai, C. J. 2022. AI Chains:\n",
      "Transparent and Controllable Human-AI Interaction\n",
      "by Chaining Large Language Model Prompts. In Pro-\n",
      "ceedings of the Conference on Human Factors in Com-\n",
      "puting Systems , CHI ’22. ACM.\n",
      "[74] Wu, Z.; Pan, S.; Chen, F.; Long, G.; Zhang, C.; and Yu,\n",
      "P. S. 2021. A Comprehensive Survey on Graph Neural\n",
      "Networks. IEEE Transactions on Neural Networks and\n",
      "Learning Systems , 32(1): 4–24.\n",
      "[75] Xie, Y .; Kawaguchi, K.; Zhao, Y .; Zhao, X.; Kan, M.-\n",
      "Y .; He, J.; and Xie, Q. 2023. Self-Evaluation Guided\n",
      "Beam Search for Reasoning. In Advances in Neural\n",
      "Information Processing Systems (NeurIPS ’23) , vol-\n",
      "ume 36. Curran Associates.\n",
      "[76] Yang, S.; Nachum, O.; Du, Y .; Wei, J.; Abbeel, P.; and\n",
      "Schuurmans, D. 2023. Foundation Models for Deci-\n",
      "sion Making: Problems, Methods, and Opportunities.\n",
      "arXiv:2303.04129.\n",
      "[77] Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.;\n",
      "Cao, Y .; and Narasimhan, K. R. 2023. Tree of\n",
      "Thoughts: Deliberate Problem Solving with Large\n",
      "Language Models. In Advances in Neural Information\n",
      "Processing Systems (NeurIPS ’23) , volume 36. Curran\n",
      "Associates.\n",
      "[78] Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.;\n",
      "Narasimhan, K. R.; and Cao, Y . 2023. ReAct: Syner-\n",
      "gizing Reasoning and Acting in Language Models. In\n",
      "Proceedings of the Eleventh International Conference\n",
      "on Learning Representations , ICLR ’23.\n",
      "[79] Yao, Y .; Li, Z.; and Zhao, H. 2023. Beyond Chain-\n",
      "of-Thought, Effective Graph-of-Thought Reasoning in\n",
      "Large Language Models. arXiv:2305.16582.\n",
      "[80] Zelikman, E.; Wu, Y .; Mu, J.; and Goodman, N. 2022.\n",
      "STaR: Bootstrapping Reasoning With Reasoning. In\n",
      "Advances in Neural Information Processing Systems\n",
      "(NeurIPS ’22) , volume 35, 15476–15488. Curran As-\n",
      "sociates.\n",
      "[81] Zhang, S.; Chen, Z.; Shen, Y .; Ding, M.; Tenenbaum,\n",
      "J. B.; and Gan, C. 2023. Planning with Large Lan-\n",
      "guage Models for Code Generation. In Proceedings\n",
      "of the Eleventh International Conference on Learning\n",
      "Representations , ICLR ’23.\n",
      "[82] Zhang, Z.; Cui, P.; and Zhu, W. 2022. Deep Learning\n",
      "on Graphs: A Survey. IEEE Transactions on Knowl-\n",
      "edge and Data Engineering , 34(1): 249–270.\n",
      "[83] Zhou, J.; Cui, G.; Hu, S.; Zhang, Z.; Yang, C.; Liu,\n",
      "Z.; Wang, L.; Li, C.; and Sun, M. 2020. Graph neural\n",
      "networks: A review of methods and applications. AI\n",
      "Open , 1: 57–81.\n",
      "[84] Zhou, Y .; Muresanu, A. I.; Han, Z.; Paster, K.;\n",
      "Pitis, S.; Chan, H.; and Ba, J. 2022. Large Lan-\n",
      "guage Models Are Human-Level Prompt Engineers.\n",
      "arXiv:2211.01910.\n",
      "[85] Zhu, X.; Wang, J.; Zhang, L.; Zhang, Y .; Huang, Y .;\n",
      "Gan, R.; Zhang, J.; and Yang, Y . 2023. Solving Math\n",
      "Word Problems via Cooperative Reasoning inducedLanguage Models. In Proceedings of the 61st Annual\n",
      "Meeting of the Association for Computational Linguis-\n",
      "tics, ACL ’23, 4471–4485. Association for Computa-\n",
      "tional Linguistics.\n",
      "14\n",
      "A Positive Score Evaluation\n",
      "The following figures plot the same data as Figures 5 and 6\n",
      "respectively, however use the ”positive score” described in\n",
      "Sections 5.1 and 5.2.\n",
      "IOCoT ToTToT2 GoT0481216202428323640444852566064\n",
      "64 elements\n",
      "0.00.30.60.91.21.51.82.12.42.73.03.33.63.94.24.54.8\n",
      "IOCoT ToTToT2 GoT081624324048566472808896104112120128\n",
      "128 elements\n",
      "012345678910111213141516\n",
      "Total Cost ($); the lower the better\n",
      "IOCoT ToTToT2 GoT161820222426283032#correct elements; the higher the better\n",
      "32 elements\n",
      "0.00.20.40.60.81.01.21.41.6L=2\n",
      "k=20\n",
      "L=3\n",
      "k=10GoT: Figure 4 GoT: Figure 4 GoT: Figure 4\n",
      "L=4\n",
      "k=20L=7\n",
      "k=10L=4\n",
      "k=20\n",
      "L=10\n",
      "k=10\n",
      "Figure 9: Accuracy and cost in sorting tasks with ChatGPT-\n",
      "3.5.Landkindicate the structure of ToT (see Sections 3.2\n",
      "and 6).\n",
      "IOCoT ToTToT2 GoT8101214161820222426283032#correct elements; the higher the better\n",
      "7 6 31 29 4332 elements\n",
      "0.00.20.40.60.81.01.21.41.61.82.02.22.4\n",
      "IOCoT ToTToT2 GoT16202428323640444852566064\n",
      "0 0 0 0 464 elements\n",
      "0.00.20.40.60.81.01.21.41.61.82.02.22.4\n",
      "IOCoT ToTToT2 GoT081624324048566472808896104112120128\n",
      "0 0 0 0 0128 elements\n",
      "0.00.51.01.52.02.53.03.54.04.55.05.56.06.57.07.58.0\n",
      "Total Cost ($); the lower the betterL=2\n",
      "k=20\n",
      "L=3\n",
      "k=10Samples\n",
      "solved\n",
      "correctly:\n",
      "L=4\n",
      "k=20L=7\n",
      "k=10L=4\n",
      "k=25L=9\n",
      "k=10\n",
      "Figure 10: Accuracy and cost in set intersection with\n",
      "ChatGPT-3.5. Landkindicate the structure of ToT (see Sec-\n",
      "tions 3.2 and 6).\n",
      "B Example Prompts - Sorting\n",
      "We present the prompts only for the sorting of 32-element\n",
      "lists, as those for 64-element and 128-element lists are iden-\n",
      "tical, except for the split prompt where the number of ele-\n",
      "ments in the one-shot example matches the problem size.\n",
      "For sorting, we employ three distinct types of operations\n",
      "that interact with the LLM, each with its corresponding\n",
      "prompts. First, there is the Generate operation, utilizing the\n",
      "sort prompt to guide the LLM in sorting a provided list of\n",
      "values, and the split prompt to direct the LLM to split a spec-\n",
      "ified list into a designated number of sublists. Next, the Im-\n",
      "prove operation employs the improve prompt to instruct the\n",
      "LLM to refine a sorted list if it detects mistakes. Finally, the\n",
      "Aggregate operation leverages the merge prompt to guide\n",
      "the LLM in merging two pre-sorted lists into a single sorted\n",
      "list.\n",
      "First, we present the prompt stubs (Table 3), serving as\n",
      "templates to dynamically generate appropriate prompts at\n",
      "runtime. For clarity, we display their corresponding few-shot\n",
      "examples separately in Table 4. Following this, we outlinethe LLM interactions throughout the process of solving the\n",
      "sorting use case (Table 5 - Table 9).\n",
      "15\n",
      "Table 3: Prompt stubs for the sorting tasks; parameters in single curly brackets will be substituted at runtime.\n",
      "sort prompt: <Instruction >Sort the following list of numbers in ascending order. Output only the sorted list of numbers,\n",
      "no additional text. </Instruction >\n",
      "<Examples >See Table 4 </Examples >\n",
      "Input:{input list}\n",
      "split prompt (32 elements): <Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first\n",
      "list should contain the first 16 numbers and the second list the second 16 numbers.\n",
      "Only output the final 2 lists in the following format without any additional text or thoughts!:\n",
      "{{\n",
      "\"List 1\": [3, 4, 3, 5, 7, 8, 1, ...],\n",
      "\"List 2\": [2, 9, 2, 4, 7, 1, 5, ...]\n",
      "}}\n",
      "</Instruction >\n",
      "<Examples >See Table 4 </Examples >\n",
      "Input:{input list}\n",
      "improve prompt: <Instruction >The following two lists represent an unsorted list of numbers and a sorted variant of that\n",
      "list. The sorted variant is not correct. Fix the sorted variant so that it is correct. Make sure that the output list is sorted in\n",
      "ascending order, has the same number of elements as the input list ( {length}), and contains the same elements as the input\n",
      "list.</Instruction >\n",
      "<Approach >\n",
      "To fix the incorrectly sorted list follow these steps:\n",
      "1. For each number from 0 to 9, compare the frequency of that number in the incorrectly sorted list to the frequency of that\n",
      "number in the input list.\n",
      "2. Iterate through the incorrectly sorted list and add or remove numbers as needed to make the frequency of each number in\n",
      "the incorrectly sorted list match the frequency of that number in the input list.\n",
      "</Approach >\n",
      "<Examples >See Table 4 </Examples >\n",
      "Input:{input list}\n",
      "Incorrectly Sorted: {sorted list}\n",
      "merge prompt: <Instruction >Merge the following 2 sorted lists of length {length}each, into one sorted list of length\n",
      "{length combined }using a merge sort style approach. Only output the final merged list without any additional text or\n",
      "thoughts!: </Instruction >\n",
      "<Approach >\n",
      "To merge the two lists in a merge-sort style approach, follow these steps:\n",
      "1. Compare the first element of both lists.\n",
      "2. Append the smaller element to the merged list and move to the next element in the list from which the smaller element\n",
      "came.\n",
      "3. Repeat steps 1 and 2 until one of the lists is empty.\n",
      "4. Append the remaining elements of the non-empty list to the merged list.\n",
      "</Approach >\n",
      "Merge the following two lists into one sorted list:\n",
      "1.{input list1}\n",
      "2.{input list2}\n",
      "Merged list:\n",
      "16\n",
      "Table 4: Few-shot examples for each prompt used for the sorting tasks; some lists are truncated for brevity.\n",
      "sort prompt:\n",
      "<Examples >\n",
      "Input: [5, 1, 0, 1, 2, 0, 4, 8, 1, 9, 5, 1, 3, 3, 9, 7]\n",
      "Output: [0, 0, 1, 1, 1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 9, 9]\n",
      "Input: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, . . .(Omitted 14/32 numbers) ]\n",
      "Output: [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, . . .(Omitted 14/32 numbers) ]\n",
      "Input: [4, 4, 9, 7, 9, 7, 0, 0, 4, 9, 1, 7, 9, 5, 8, 7, 5, 6, . . .(Omitted 46/64 numbers) ]\n",
      "Output: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, . . .(Omitted 46/64 numbers) ]\n",
      "</Examples >\n",
      "split prompt (32 elements):\n",
      "<Examples >\n",
      "Input: [9, 6, 7, 7, 2, 0, 2, 2, 3, 5, 0, 9, 2, 2, 4, 4, 5, 2, . . .(Omitted 14/32 numbers) ]\n",
      "Output:\n",
      "{{\n",
      "\"List 1\": [9, 6, 7, 7, 2, 0, 2, 2, 3, 5, 0, 9, 2, 2, 4, 4],\n",
      "\"List 2\": [5, 2, 5, 1, 2, 8, 3, 8, 3, 9, 6, 0, 4, 2, 2, 3]\n",
      "}}\n",
      "</Examples >\n",
      "improve prompt:\n",
      "<Examples >\n",
      "Input: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9]\n",
      "Incorrectly Sorted: [0, 0, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 7, 7, 8, 8, 9, 9, 9, 9]\n",
      "Reason: The incorrectly sorted list contains four extra 0s, two extra 4s and three extra 9s and is\n",
      "missing two 2s.\n",
      "Output: [0, 1, 2, 2, 2, 2, 3, 3, 4, 5, 5, 7, 7, 8, 8, 9]\n",
      "Input: [6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9, 2, 4, . . .(Omitted 14/32 numbers) ]\n",
      "Incorrectly Sorted: [0, 1, 1, 2, 2, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, . . .(Omitted 14/32 numbers) ]\n",
      "Reason: The incorrectly sorted list contains two extra 4s and is missing two 6s and one 9.\n",
      "Output: [0, 1, 1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, . . .(Omitted 14/32 numbers) ]\n",
      "Input: [4, 4, 9, 7, 9, 7, 0, 0, 4, 9, 1, 7, 9, 5, 8, 7, 5, 6, . . .(Omitted 46/64 numbers) ]\n",
      "Incorrectly Sorted: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, . . .(Omitted 46/64 numbers) ]\n",
      "Reason: The incorrectly sorted list contains one extra 8 and is missing two 2s, one 3, three 4s, two\n",
      "5s, one 6, six 7s and one 9.\n",
      "Output: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, . . .(Omitted 46/64 numbers) ]\n",
      "</Examples >\n",
      "merge prompt: -\n",
      "17\n",
      "Table 5: Sorting of a 32 element list: Execution plan ( GoO )\n",
      "GoO:\n",
      "1. Split the input list into two sub-lists of equal size (split prompt)\n",
      "2. For each sub-list: Sort the sub-list (sort prompt) five times; score each sort attempt; keep the best\n",
      "3. Merge the sorted sub-lists into one fully sorted list (merge prompt) 10 times; score each merge attempt; keep the best\n",
      "4. Fix any potential mistakes in the sorted list (improve prompt) 10 times; score each improvement attempt; keep the best\n",
      "Table 6: Sorting of a 32 element list: Step 1 (Prompt/Response)\n",
      "Step 1 – Prompt:\n",
      "<Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first list should contain the first 16\n",
      "numbers and the second list the second 16 numbers.\n",
      "Only output the final 2 lists in the following format without any additional text or thoughts!:\n",
      "{{\n",
      "\"List 1\": [3, 4, 3, 5, 7, 8, 1, ...],\n",
      "\"List 2\": [2, 9, 2, 4, 7, 1, 5, ...]\n",
      "}}\n",
      "</Instruction >\n",
      "<Examples >See Table 4 </Examples >\n",
      "Input: [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1, 0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\n",
      "Step 1 – Response (Fully Correct):\n",
      "{{\n",
      "\"List 1\": [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1],\n",
      "\"List 1\": [0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\n",
      "}}\n",
      "18\n",
      "Table 7: Sorting of a 32 element list: Step 2 (Prompts/Responses)\n",
      "Step 2a – Prompt:\n",
      "<Instruction >Sort the following list of numbers in ascending order. Output only the sorted list of numbers, no additional\n",
      "text.</Instruction >\n",
      "<Examples >See Table 4 </Examples >\n",
      "Input: [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1]\n",
      "Step 2a – 5 Responses:\n",
      "1.[0, 0, 1, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (Fully Correct)\n",
      "2.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\n",
      "3.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\n",
      "4.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\n",
      "5.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\n",
      "Step 2b – Prompt:\n",
      "<Instruction >Sort the following list of numbers in ascending order. Output only the sorted list of numbers, no additional\n",
      "text.</Instruction >\n",
      "<Examples >See Table 4 </Examples >\n",
      "Input: [0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\n",
      "Step 2b – 5 Responses:\n",
      "1.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\n",
      "2.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\n",
      "3.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\n",
      "4.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 8, 9] (Fully Correct)\n",
      "5.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\n",
      "19\n",
      "Table 8: Sorting of a 32 element list: Step 3 (Prompt/Responses)\n",
      "Step 3 – Prompt:\n",
      "<Instruction >Merge the following 2 sorted lists of length 16 each, into one sorted list of length 32 using a merge sort style\n",
      "approach. Only output the final merged list without any additional text or thoughts!: </Instruction >\n",
      "<Approach >\n",
      "To merge the two lists in a merge-sort style approach, follow these steps:\n",
      "1. Compare the first element of both lists.\n",
      "2. Append the smaller element to the merged list and move to the next element in the list from which the smaller element\n",
      "came.\n",
      "3. Repeat steps 1 and 2 until one of the lists is empty.\n",
      "4. Append the remaining elements of the non-empty list to the merged list.\n",
      "</Approach >\n",
      "Merge the following two lists into one sorted list:\n",
      "1.[0, 0, 1, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9]\n",
      "2.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 8, 9]\n",
      "Merged list:\n",
      "Step 3 – 10 Responses:\n",
      "1.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\n",
      "(2 Errors - Missing one 1 and one 5)\n",
      "2.[0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\n",
      "(2 Errors - Missing two 1s)\n",
      "3.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\n",
      "(2 Errors - Missing one 1 and got one extra 6)\n",
      "4.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9]\n",
      "(3 Errors - Missing one 1, one 9 and got one extra 6)\n",
      "5.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\n",
      "(2 Errors - Missing one 1 and got one extra 6)\n",
      "6.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\n",
      "(2 Errors - Missing one 1 and one 5)\n",
      "7.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\n",
      "(2 Errors - Missing one 1 and got one extra 6)\n",
      "8.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\n",
      "(1 Error - Missing one 1)\n",
      "9.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\n",
      "(1 Error - Missing one 1)\n",
      "10.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\n",
      "(2 Errors - Missing one 1 and one 5)\n",
      "20\n",
      "Table 9: Sorting of a 32 element list: Step 4 (Prompt/Responses)\n",
      "Step 4 – Prompt:\n",
      "<Instruction >The following two lists represent an unsorted list of numbers and a sorted variant of that list. The sorted\n",
      "variant is not correct. Fix the sorted variant so that it is correct. Make sure that the output list is sorted in ascending order,\n",
      "has the same number of elements as the input list (32), and contains the same elements as the input list. </Instruction >\n",
      "<Approach >\n",
      "To fix the incorrectly sorted list follow these steps:\n",
      "1. For each number from 0 to 9, compare the frequency of that number in the incorrectly sorted list to the frequency of that\n",
      "number in the input list.\n",
      "2. Iterate through the incorrectly sorted list and add or remove numbers as needed to make the frequency of each number in\n",
      "the incorrectly sorted list match the frequency of that number in the input list.\n",
      "</Approach >\n",
      "<Examples >See Table 4 </Examples >\n",
      "Input: [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1, 0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\n",
      "Incorrectly Sorted: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8,\n",
      "8, 9, 9]\n",
      "Step 4 – 10 Responses:\n",
      "1. Reason: The incorrectly sorted list is missing two 0s, one 3, one 4, one 6 and one\n",
      "9. The incorrectly sorted list also contains one extra 1, one extra 2, and one extra 5.\n",
      "Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 5, 5, 5,\n",
      "6, 6, 6, 6, 7, 7, 8, 8, 9, 9] 4 Errors - Missing one 1, two 4s and one 5\n",
      "Note: The output list has the same number of elements as the input list, is sorted in ascending order, and con-\n",
      "tains the same elements as the input list.\n",
      "2.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7,\n",
      "8, 8, 9, 9] 1 Error - One extra 6\n",
      "3.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6,\n",
      "7, 7, 7, 8, 8, 8, 9, 9, 9] 6 Errors - One extra 2, 5, 6, 7, 8 and 9\n",
      "4. Reason: The incorrectly sorted list is missing two 9s and one 0.\n",
      "Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7,\n",
      "7, 8, 8, 9, 9, 9, 9] 3 Errors - Missing one 1 and has two extra 9s\n",
      "5. Reason: The incorrectly sorted list is missing one 0, one 3, one 4, four 6s, and one 9.\n",
      "Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
      "6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 9] 10 Errors - Missing one 1, 2, has four extra 6s, one extra 7, 8 and two extra 9s\n",
      "6.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6,\n",
      "7, 7, 7, 7, 8, 8, 8, 9, 9, 9, 9] 8 Errors - Has one extra 2, 3, 6, two extra 7s, one extra 8 and two extra 9s\n",
      "7.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8,\n",
      "8, 9, 9] 2 Errors - Missing one 1 and has one extra 4\n",
      "8. Reason: The incorrectly sorted list is missing three 0s, two 3s, two 4s, one 5, two 6s, and one 9.\n",
      "Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6,\n",
      "6, 7, 7, 8, 8, 9] 5 Errors - Missing one 1, 9, has one extra 3 and two extra 6s\n",
      "9. Reason: The incorrectly sorted list is missing one 0, three 2s, two 3s, two 4s, three 5s, two 6s, one 7, and one 9.\n",
      "Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 5, 6,\n",
      "6, 6, 6, 6, 7, 8, 8, 9, 9] 8 Errors - Missing one 1, one 7, has two extra 2s, two extra 3s, one extra 5 and 6\n",
      "10.Reason: The incorrectly sorted list is missing three 1s, one 3, one 4, two 5s, one 6, one 7, one 8, and one 9.\n",
      "Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7,\n",
      "7, 8, 8, 9, 9] (Fully Correct)\n",
      "Final Result (Correctly Sorted):\n",
      "[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\n",
      "21\n",
      "C Example Prompts - Set Intersection\n",
      "We present the prompts only for the intersection of two 32-\n",
      "element sets, as those for 64-element and 128-element sets\n",
      "are identical, except for the split prompt where the size of\n",
      "the split is adjusted proportionally.\n",
      "For set intersection, we employ two distinct types of op-\n",
      "erations that interact with the LLM, each with its corre-\n",
      "sponding prompts. First, there is the Generate operation,\n",
      "utilizing the intersect prompt to guide the LLM in inter-\n",
      "secting two input sets, and the split prompt to direct the\n",
      "LLM to split a specified set into a designated number of dis-\n",
      "tinct subsets. Second, the Aggregate operation leverages the\n",
      "merge prompt to guide the LLM in combining two sets into\n",
      "one.\n",
      "First, we present the prompt stubs (Table 10), serving as\n",
      "templates to dynamically generate appropriate prompts at\n",
      "runtime. For clarity, we display their corresponding few-shot\n",
      "examples separately in Table 11. Following this, we outline\n",
      "the LLM interactions throughout a complete set intersection\n",
      "process (Table 12 - Table 15).\n",
      "22\n",
      "Table 10: Prompt stubs for the set intersection tasks; parameters in single curly brackets will be substituted at runtime.\n",
      "intersect prompt: <Instruction >Find the intersection of two sets of numbers. Output only the set of numbers that are\n",
      "present in both sets, no additional text. </Instruction >\n",
      "<Examples >See Table 11 </Examples >\n",
      "Input Set 1: {set1}\n",
      "Input Set 2: {set2}\n",
      "split prompt (32 elements): <Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first\n",
      "list should contain the first 16 numbers and the second list the second 16 numbers.\n",
      "Only output the 2 lists in the following format without any additional text or thoughts!\n",
      "{{\n",
      "\"List 1\": [13, 16, 30, 6, 21, 7, 31, ...],\n",
      "\"List 2\": [25, 24, 10, 4, 27, 0, 14, ...]\n",
      "}}\n",
      "</Instruction >\n",
      "<Examples >See Table 11 </Examples >\n",
      "Input:{input}\n",
      "merge prompt: <Instruction >Merge the following 2 lists into one list by appending the second list to the first list.\n",
      "Only output the final list without any additional text or thoughts! </Instruction >\n",
      "List 1: {input1}\n",
      "List 2: {input2}\n",
      "23\n",
      "Table 11: Few-shot examples for each prompt used for the set intersection tasks; some lists are truncated for brevity.\n",
      "intersect prompt:\n",
      "<Examples >\n",
      "Input Set 1: [13, 16, 30, 6, 21, 7, 31, 15, 11, 1, 24, 10, 9, 3, 20, 8]\n",
      "Input Set 2: [25, 24, 10, 4, 27, 0, 14, 12, 8, 2, 29, 20, 17, 19, 26, 23]\n",
      "Output: [24, 10, 20, 8]\n",
      "Input Set 1: [26, 40, 42, 57, 15, 31, 5, 32, 11, 4, 24, 28, 51, 54, . . .(Omitted 18/32 numbers) ]\n",
      "Input Set 2: [16, 60, 36, 48, 0, 15, 5, 19, 46, 24, 1, 6, 61, 10, . . .(Omitted 18/32 numbers) ]\n",
      "Output: [40, 15, 5, 24, 35, 59, 16, 63]\n",
      "Input Set 1: [115, 61, 35, 103, 90, 117, 86, 44, 63, 45, 40, 30, 74, 33, . . .(Omitted 50/64 numbers) ]\n",
      "Input Set 2: [13, 35, 20, 96, 34, 18, 47, 127, 126, 9, 21, 16, 77, 22, . . .(Omitted 50/64 numbers) ]\n",
      "Output: [115, 35, 90, 117, 63, 40, 30, 33, 15, 89, 50, 12, 2, 84, 7, 57, 96]\n",
      "</Examples >\n",
      "split prompt (32 elements):\n",
      "<Examples >\n",
      "Input: [26, 40, 42, 57, 15, 31, 5, 32, 11, 4, 24, 28, 51, 54, . . .(Omitted 18/32 numbers) ]\n",
      "Output:\n",
      "{{\n",
      "\"List 1\": [26, 40, 42, 57, 15, 31, 5, 32, 11, 4, 24, 28, 51, 54, 12, 22],\n",
      "\"List 2\": [33, 35, 7, 13, 2, 59, 8, 23, 43, 16, 29, 55, 25, 63, 21, 18]\n",
      "}}\n",
      "</Examples >\n",
      "merge prompt: -\n",
      "Table 12: Intersection of two 32-element sets: Execution plan ( GoO )\n",
      "GoO:\n",
      "1. Split the second input set into two sub-sets of equal size (split prompt)\n",
      "2. For each sub-set: Intersect the sub-set with the first input set (intersect prompt) five times; score each sort attempt; keep\n",
      "the best\n",
      "3. Merge the resulting intersections into one full intersection set (merge prompt) 10 times; score each merge attempt; keep\n",
      "the best\n",
      "24\n",
      "Table 13: Intersection of two 32-element sets: Step 1 (Prompt/Response)\n",
      "Step 1 – Prompt:\n",
      "<Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first list should contain the first 16\n",
      "numbers and the second list the second 16 numbers.\n",
      "Only output the 2 lists in the following format without any additional text or thoughts!\n",
      "{{\n",
      "\"List 1\": [13, 16, 30, 6, 21, 7, 31, ...],\n",
      "\"List 2\": [25, 24, 10, 4, 27, 0, 14, ...]\n",
      "}}\n",
      "</Instruction >\n",
      "<Examples >See Table 11 </Examples >\n",
      "Input: [31, 11, 4, 63, 38, 58, 59, 24, 61, 14, 32, 39, 27, 46, 48, 19, 52, 57, 50, 56, 3, 2, 53, 29,\n",
      "5, 37, 62, 41, 36, 12, 49, 16]\n",
      "Step 1 – Response (Fully Correct):\n",
      "{{\n",
      "\"List 1\": [31, 11, 4, 63, 38, 58, 59, 24, 61, 14, 32, 39, 27, 46, 48, 19],\n",
      "\"List 1\": [52, 57, 50, 56, 3, 2, 53, 29, 5, 37, 62, 41, 36, 12, 49, 16]\n",
      "}}\n",
      "25\n",
      "Table 14: Intersection of two 32-element sets: Step 2 (Prompts/Responses)\n",
      "Step 2a – Prompt:\n",
      "<Instruction >Find the intersection of two sets of numbers. Output only the set of numbers that are present in both sets, no\n",
      "additional text. </Instruction >\n",
      "<Examples >See Table 11 </Examples >\n",
      "Input Set 1: [11, 60, 1, 49, 21, 33, 14, 56, 54, 15, 23, 40, 45, 22, 7, 28, 20, 46, 51, 6, 34, 37, 3,\n",
      "50, 17, 8, 25, 0, 35, 47, 18, 19]\n",
      "Input Set 2: [31, 11, 4, 63, 38, 58, 59, 24, 61, 14, 32, 39, 27, 46, 48, 19]\n",
      "Step 2a – 5 Responses:\n",
      "1.[11, 14, 46, 14, 19] (1 Error - Duplicated 14)\n",
      "2.Output: [11, 14, 46, 19] (Fully Correct)\n",
      "3.[11, 14, 46, 14, 19] (1 Error - Duplicated 14)\n",
      "4.[11, 14, 46, 19] (Fully Correct)\n",
      "5.[11, 14, 46, 14, 19] (1 Error - Duplicated 14)\n",
      "Step 2b – Prompt:\n",
      "<Instruction >Find the intersection of two sets of numbers. Output only the set of numbers that are present in both sets, no\n",
      "additional text. </Instruction >\n",
      "<Examples >See Table 11 </Examples >\n",
      "Input Set 1: [11, 60, 1, 49, 21, 33, 14, 56, 54, 15, 23, 40, 45, 22, 7, 28, 20, 46, 51, 6, 34, 37, 3,\n",
      "50, 17, 8, 25, 0, 35, 47, 18, 19]\n",
      "Input Set 2: [52, 57, 50, 56, 3, 2, 53, 29, 5, 37, 62, 41, 36, 12, 49, 16]\n",
      "Step 2b – 5 Responses:\n",
      "1.[50, 56, 49] (2 Errors - Missing 3 and 37)\n",
      "2.[50, 56, 37, 49] (1 Error - Missing 3)\n",
      "3.[56, 49, 37, 3, 50] (Fully Correct)\n",
      "4.[50, 56, 37, 49] (1 Error - Missing 3)\n",
      "5.[50, 56, 37, 49] (1 Error - Missing 3)\n",
      "26\n",
      "Table 15: Intersection of two 32-element sets: Step 3 (Prompt/Responses)\n",
      "Step 3 – Prompt:\n",
      "<Instruction >Merge the following 2 lists into one list by appending the second list to the first list.\n",
      "Only output the final list without any additional text or thoughts! </Instruction >\n",
      "List 1: [11, 14, 46, 19]\n",
      "List 2: [56, 49, 37, 3, 50]\n",
      "Step 3 – 10 Responses:\n",
      "1.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\n",
      "2.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\n",
      "3.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\n",
      "4.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\n",
      "5.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\n",
      "6.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\n",
      "7.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\n",
      "8.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\n",
      "9.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\n",
      "10.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\n",
      "Final Result (Correct Intersection):\n",
      "[11, 14, 46, 19, 56, 49, 37, 3, 50]\n",
      "27\n",
      "D Example Prompts - Keyword Counting\n",
      "We present the prompts only for GoT4 of the keyword count-\n",
      "ing task, as those used for GoT8 andGoTx are identical, ex-\n",
      "cept for minor differences in the split prompt where the size\n",
      "of the split is adjusted.\n",
      "For keyword counting, we employ three distinct types of\n",
      "operations that interact with the LLM, each with its corre-\n",
      "sponding prompts. First, there is the Generate operation,\n",
      "utilizing the count prompt to guide the LLM in counting the\n",
      "keywords in a text, and the split prompt to direct the LLM\n",
      "to split a given text into a number of passages. Next, the Ag-\n",
      "gregate operation leverages the merge prompt to guide the\n",
      "LLM in merging two dictionaries of counted keywords into\n",
      "one. Finally, the ValidateAndImprove operation employs\n",
      "theimprove merge prompt to instruct the LLM to correct\n",
      "mistakes that were made in a previous Aggregate operation.\n",
      "We present the prompt stubs (Table 16 - Table 17), serving\n",
      "as templates to dynamically generate appropriate prompts at\n",
      "runtime. For clarity, we display their corresponding few-shot\n",
      "examples separately in Table 18 and Table 19. Following\n",
      "this, we outline the LLM interactions throughout a complete\n",
      "keyword counting process (Table 20 - Table 28).\n",
      "28\n",
      "Table 16: Prompt stubs for the keyword counting task; parameters in single curly brackets will be substituted at runtime.\n",
      "count prompt: <Instruction >Count the frequency of how many times each country is explicitly named in the input text.\n",
      "You can generate any intermedate lists and states, but the final output should only contain the frequency of each country that\n",
      "appears at least once in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each\n",
      "country in the output as in the input text):\n",
      "{{\n",
      "\"country1\": frequency1,\n",
      "\"country2\": frequency2,\n",
      ". . .\n",
      "}}\n",
      "</Instruction >\n",
      "<Approach >\n",
      "To count the frequency for each country follow these steps:\n",
      "1. Split the input passage into four paragraphs of similar length.\n",
      "2. Count the frequency of each country in each paragraph.\n",
      "3. Combine the frequencies of each country from each paragraph by adding them together.\n",
      "</Approach >\n",
      "<Examples >See Table 18 </Examples >\n",
      "Input:{input text}\n",
      "split prompt: <Instruction >Split the following input text into 4 paragraphs of approximately same length.\n",
      "Only output the final 4 paragraphs in the following format without any additional text or thoughts:\n",
      "{{\n",
      "\"Paragraph 1\": \"Some paragraph text . . .\",\n",
      "\"Paragraph 2\": \"Some paragraph text . . .\",\n",
      "\"Paragraph 3\": \"Some paragraph text . . .\",\n",
      "\"Paragraph 4\": \"Some paragraph text . . .\"\n",
      "}}\n",
      "</Instruction >\n",
      "<Example >See Table 19 </Example >\n",
      "Input:{input text}\n",
      "29\n",
      "Table 17: Prompt stubs for the keyword counting task continued ; parameters in single curly brackets will be substituted at\n",
      "runtime.\n",
      "merge prompt: <Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text,\n",
      "into a single dictionary. Simply add the frequencies together for each country and if a country is not present in one of the\n",
      "dictionaries, add it to the final dictionary with the frequency from the other dictionary.\n",
      "Only output the final merged dictionary without any additional text or thoughts! </Instruction >\n",
      "<Approach >\n",
      "To combine the 2 dictionaries into single one, follow these steps:\n",
      "1. Create a new dictionary to store the combined frequencies.\n",
      "2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\n",
      "3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\n",
      "already present, add the frequency to the existing value.\n",
      "</Approach >\n",
      "Combine the following 2 dictionaries into a single dictionary:\n",
      "{dictionary 1}\n",
      "{dictionary 2}\n",
      "Combined Output:\n",
      "improve merge prompt: <Instruction >The following 2 dictionaries were combined into the third dictionary below. How-\n",
      "ever, some mistakes occured and the third dictionary is incorrect. Please fix the third dictionary so that it contains the correct\n",
      "frequencies for each country. The correct frequencies are the sum of the frequencies from the first 2 dictionaries. If a country\n",
      "is not present in one of the dictionaries, add it to the final dictionary with the frequency from the other dictionary.\n",
      "</Instruction >\n",
      "<Example >See Table 19 </Example >\n",
      "Dictionary 1: {dictionary 1}\n",
      "Dictionary 2: {dictionary 2}\n",
      "Incorrectly Combined Dictionary: {dictionary incorrect }\n",
      "Output:\n",
      "30\n",
      "Table 18: Few-shot examples for count prompt used for the keyword counting task; some paragraphs and dictionaries are\n",
      "truncated and formatting is slightly adjusted for brevity.\n",
      "count prompt:\n",
      "<Examples >\n",
      "Input: Alexandra boarded the first flight of her grand journey, starting from Canada. With a globe-trotting ... (Omitted)\n",
      "Paragraphs:\n",
      "Alexandra boarded the first flight of her grand journey, starting from Canada. With a globe-trotting itinerary ... (Omitted)\n",
      "Her first stop was Mexico, where she marveled at the Mayan ruins. From there, she explored the rainforests ... (Omitted)\n",
      "Sublist frequencies:\n",
      "{{\"Canada\": 1 }}\n",
      "{{\"Mexico\": 1, \"Brazil\": 1, \"Argentina\": 1 }}\n",
      "Output: {{\"Canada\": 1, \"Mexico\": 1, \"Brazil\": 1, \"Argentina\": 1 }}\n",
      "Input: The adventure led him to the peaks of Peru where he trekked to see the mysteries of Machu Picchu ... (Omitted)\n",
      "Paragraphs:\n",
      "The adventure led him to the peaks of Peru where he trekked to see the mysteries of Machu Picchu. He then ... (Omitted)\n",
      "A quick detour to Uruguay and Paraguay allowed him to experience the vibrancy of the local cultures before ... (Omitted)\n",
      "Sublists:\n",
      "{{\"Peru\": 1, \"Chile\": 1 }}\n",
      "{{\"Uruguay\": 1, \"Paraguay\": 1, \"Canada\": 1, \"Peru\": 1, \"Brazil\": 1, \"Mexico\": 1 }}\n",
      "Output: {{\"Peru\": 2, \"Chile\": 1, \"Uruguay\": 1, \"Paraguay\": 1, \"Canada\": 1, \"Brazil\": 1, \"Mexico\": 1 }}\n",
      "Input: Journeying westward, she admired the art in Italy and sipped coffee in France. The music of ... (Omitted)\n",
      "Paragraphs:\n",
      "Journeying westward, she admired the art in Italy and sipped coffee in France.\n",
      "The music of Spain and the history of Greece deepened her love for Europe. The Nordic beauty of Norway, ... (Omitted)\n",
      "She danced in Ireland, explored castles in Scotland, and marveled at the architecture in Germany and Russia.\n",
      "Italy, Norway, Sweden and Germany will always stay her favourite destinations to visit.\n",
      "Sublists:\n",
      "{{\"Italy\": 1, \"France\": 1 }}\n",
      "{{\"Spain\": 1, \"Greece\": 1, \"Norway\": 1, \"Sweden\": 1, \"Finland\": 1, \"Denmark\": 1 }}\n",
      "{{\"Ireland\": 1, \"Scotland\": 1, \"Germany\": 1, \"Russia\": 1 }}\n",
      "{{\"Italy\": 1, \"Norway\": 1, \"Sweden\": 1, \"Germany\": 1 }}\n",
      "Output: {{\"Italy\": 2, \"France\": 1, \"Spain\": 1, \"Greece\": 1, \"Norway\": 2, \"Sweden\": 2, . . .(Omitted) }}\n",
      "</Examples >\n",
      "31\n",
      "Table 19: Few-shot examples for split,merge andimprove merge prompts used for the keyword counting task; some para-\n",
      "graphs and dictionaries are truncated and formatting is slightly adjusted for brevity.\n",
      "split prompt:\n",
      "<Examples >\n",
      "Input: Journeying westward, she admired the art in Italy and sipped coffee in France. The music of Spain and the history of\n",
      "Greece deepened her love for Europe. The Nordic beauty of Norway, Sweden, Finland, and Denmark took her breath away.\n",
      "She danced in Ireland, explored castles in Scotland, and marveled at the architecture in Germany and Russia. Italy, Norway,\n",
      "Sweden and Germany will always stay her favourite destinations to visit.\n",
      "Output:\n",
      "{{\n",
      "\"Paragraph 1\": \"Journeying westward, she admired the art in Italy and sipped coffee in France. \",\n",
      "\"Paragraph 2\": \"The music of Spain and the history of Greece deepened her love for . . .(Omitted)”,\n",
      "\"Paragraph 3\": \"She danced in Ireland, explored castles in Scotland, and marveled . . .(Omitted)”,\n",
      "\"Paragraph 4\": \"Italy, Norway, Sweden and Germany will always stay her favourite . . .(Omitted)”\n",
      "}}\n",
      "</Examples >\n",
      "merge prompt: -\n",
      "improve merge prompt:\n",
      "<Example >\n",
      "Dictionary 1: {{\"Peru\": 2, \"Chile\": 1, \"Uruguay\": 1, \"Paraguay\": 1 }}\n",
      "Dictionary 2: {{\"Peru\": 1, \"Argentina\": 1, \"Canada\": 1, \"Chile\": 3, \"Germany\": 2 }}\n",
      "Incorrectly Combined Dictionary:\n",
      "{{\"Peru\": 3, \"Chile\": 2, \"Uruguay\": 1, \"Paraguay\": 1, \"Argentina\": 1, \"Chile\": 3, \"Germany\": 2 }}\n",
      "Output:\n",
      "{{\"Peru\": 3, \"Chile\": 4, \"Uruguay\": 1, \"Paraguay\": 1, \"Argentina\": 1, \"Canada\": 1, \"Germany\": 2 }}\n",
      "</Example >\n",
      "Table 20: Keyword counting for an example 4-passage split (GoT4): Execution plan ( GoO )\n",
      "GoO:\n",
      "1. Split the input text into four paragraphs of roughly equal size (split prompt)\n",
      "2. For each paragraph: Count the occurrences of individual countries (count prompt) 10 times; score each counting attempt;\n",
      "keep the best\n",
      "3. Merge the country counts into one dictionary (merge prompt) 3 times; validate and improve invalid merge attempts\n",
      "(improve merge prompt) up to 3 attempts each; score; keep the best\n",
      "32\n",
      "Table 21: Keyword counting for an example 4-passage split (GoT4): Step 1 (Prompt/Response)\n",
      "Step 1 – Prompt:\n",
      "<Instruction >Split the following input text into 4 paragraphs of approximately same length.\n",
      "Only output the final 4 paragraphs in the following format without any additional text or thoughts:\n",
      "{{\n",
      "\"Paragraph 1\": \"Some paragraph text . . .\",\n",
      "\"Paragraph 2\": \"Some paragraph text . . .\",\n",
      "\"Paragraph 3\": \"Some paragraph text . . .\",\n",
      "\"Paragraph 4\": \"Some paragraph text . . .\"\n",
      "}}\n",
      "</Instruction >\n",
      "<Example >See Table 19 </Example >\n",
      "Input: My friend, Alex from Peru , once recounted his journey to Argentina where he learned about the strong cultural ties\n",
      "between Argentina and Brazil due to their shared history. He spoke fondly of his time in Argentina and Brazil, marveling at\n",
      "the similar music, dance, and culinary traditions that seamlessly bridged the borders of these countries. It reminded me\n",
      "of a documentary I’d watched about the ancient Silk Road that spanned across Iran and China. It touched upon the shared\n",
      "historical narratives of Iran and China, highlighting how goods, ideas, and culture flowed between these two countries for\n",
      "centuries. Intriguingly, the documentary also brought up some parallels between this eastern route and the vibrant exchange\n",
      "between Italy and France during the Renaissance. The cultural and intellectual bonds between Italy and France were indeed\n",
      "profound, just as the resilient trade relations that existed between the United States and Canada. The United States\n",
      "and Canada, apart from their geographical proximity, shared an economic bond that strongly influenced their policies\n",
      "and international standing. Similarly, the ties between Australia and New Zealand shed light on their gestalt identity in the\n",
      "Pacific region. Despite their unique characteristics, Australia and New Zealand were often viewed as a single entity due to\n",
      "their remarkably similar backgrounds in terms of culture, language, and colonial history. Inspired by these chronicles of\n",
      "interconnectedness, I decided to delve deeper into history and found a fascinating account of how Ukraine and Poland had\n",
      "influenced each other through years of coexistence. Despite their tumultuous past , Ukraine and Poland shared a cultural\n",
      "tapestry that was deeply woven into their histories. It was quite similar to the complex relationship between North Korea\n",
      "and South Korea, which, despite their political differences, shared common heritage and traditions. Thus, from Argentina to\n",
      "South Korea, the world was an intricate web of countries intertwined with each other through shared histories, cultures, and\n",
      "sometimes, shared destinies.\n",
      "Step 1 – Response (Fully Correct):\n",
      "{{\n",
      "\"Paragraph 1\": \"My friend, Alex from Peru ... (Omitted) ... bridged the borders of these countries.\",\n",
      "\"Paragraph 2\": \"It reminded me of a ... (Omitted) ... between the United States and Canada.\",\n",
      "\"Paragraph 3\": \"The United States and Canada, apart ... (Omitted) ... through years of coexistence.\",\n",
      "\"Paragraph 4\": \"Despite their tumultuous past ... (Omitted) ... and sometimes, shared destinies.\"\n",
      "}}\n",
      "33\n",
      "Table 22: Keyword counting for an example 4-passage split (GoT4): Step 2a (Prompt/Responses)\n",
      "Step 2a – Prompt:\n",
      "<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\n",
      "any intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\n",
      "once in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\n",
      "output as in the input text):\n",
      "{{\n",
      "\"country1\": frequency1,\n",
      "\"country2\": frequency2,\n",
      ". . .\n",
      "}}\n",
      "</Instruction >\n",
      "<Approach >\n",
      "To count the frequency for each country follow these steps:\n",
      "1. Split the input passage into four paragraphs of similar length.\n",
      "2. Count the frequency of each country in each paragraph.\n",
      "3. Combine the frequencies of each country from each paragraph by adding them together.\n",
      "</Approach >\n",
      "<Examples >See Table 18 </Examples >\n",
      "Input: My friend, Alex from Peru, once recounted his journey to Argentina where he learned about the strong cultural ties\n",
      "between Argentina and Brazil due to their shared history. He spoke fondly of his time in Argentina and Brazil, marveling at\n",
      "the similar music, dance, and culinary traditions that seamlessly bridged the borders of these countries.\n",
      "Step 2a – 10 Responses:\n",
      "1.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\n",
      "2.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\n",
      "3.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\n",
      "4.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\n",
      "5.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\n",
      "6.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\n",
      "7.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\n",
      "8.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\n",
      "9.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\n",
      "10.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\n",
      "34\n",
      "Table 23: Keyword counting for an example 4-passage split (GoT4): Step 2b (Prompt/Responses)\n",
      "Step 2b – Prompt:\n",
      "<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\n",
      "any intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\n",
      "once in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\n",
      "output as in the input text):\n",
      "{{\n",
      "\"country1\": frequency1,\n",
      "\"country2\": frequency2,\n",
      ". . .\n",
      "}}\n",
      "</Instruction >\n",
      "<Approach >\n",
      "To count the frequency for each country follow these steps:\n",
      "1. Split the input passage into four paragraphs of similar length.\n",
      "2. Count the frequency of each country in each paragraph.\n",
      "3. Combine the frequencies of each country from each paragraph by adding them together.\n",
      "</Approach >\n",
      "<Examples >See Table 18 </Examples >\n",
      "Input: It reminded me of a documentary I’d watched about the ancient Silk Road that spanned across Iran and China. It\n",
      "touched upon the shared historical narratives of Iran and China, highlighting how goods, ideas, and culture flowed between\n",
      "these two countries for centuries. Intriguingly, the documentary also brought up some parallels between this eastern route\n",
      "and the vibrant exchange between Italy and France during the Renaissance. The cultural and intellectual bonds between Italy\n",
      "and France were indeed profound, just as the resilient trade relations that existed between the United States and Canada.\n",
      "Step 2b – 10 Responses:\n",
      "1.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\n",
      "(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\n",
      "2.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\n",
      "(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\n",
      "3.{{\"Iran\": 3, \"China\": 2, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\n",
      "(3 Errors - Surplus of one ”Iran”, missing one ”Italy” and one ”France”)\n",
      "4.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\n",
      "(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\n",
      "5.{{\"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\n",
      "(2 Errors - Missing one ”Italy” and one ”France”)\n",
      "6.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\n",
      "(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\n",
      "7.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\n",
      "(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\n",
      "8.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\n",
      "(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\n",
      "9.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\n",
      "(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\n",
      "10.{{\"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United States\": 1, \"Canada\": 1 }}\n",
      "(1 Error - Missing one ”Italy”)\n",
      "35\n",
      "Table 24: Keyword counting for an example 4-passage split (GoT4): Step 2c (Prompt/Responses)\n",
      "Step 2c – Prompt:\n",
      "<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\n",
      "any intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\n",
      "once in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\n",
      "output as in the input text):\n",
      "{{\n",
      "\"country1\": frequency1,\n",
      "\"country2\": frequency2,\n",
      ". . .\n",
      "}}\n",
      "</Instruction >\n",
      "<Approach >\n",
      "To count the frequency for each country follow these steps:\n",
      "1. Split the input passage into four paragraphs of similar length.\n",
      "2. Count the frequency of each country in each paragraph.\n",
      "3. Combine the frequencies of each country from each paragraph by adding them together.\n",
      "</Approach >\n",
      "<Examples >See Table 18 </Examples >\n",
      "Input: The United States and Canada, apart from their geographical proximity, shared an economic bond that strongly\n",
      "influenced their policies and international standing. Similarly, the ties between Australia and New Zealand shed light on\n",
      "their gestalt identity in the Pacific region. Despite their unique characteristics, Australia and New Zealand were often viewed\n",
      "as a single entity due to their remarkably similar backgrounds in terms of culture, language, and colonial history. Inspired\n",
      "by these chronicles of interconnectedness, I decided to delve deeper into history and found a fascinating account of how\n",
      "Ukraine and Poland had influenced each other through years of coexistence.\n",
      "Step 2c – 10 Responses:\n",
      "1.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\n",
      "(Fully Correct)\n",
      "2.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\n",
      "(Fully Correct)\n",
      "3.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Australia and New Zealand\":\n",
      "1, \"Ukraine\": 1, \"Poland\": 1 }}\n",
      "(3 Errors - Missing one ”Australia, one ”New Zealand” and surplus of one ”Australia and New Zealand”)\n",
      "4.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\n",
      "(Fully Correct)\n",
      "5.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Australia and New Zealand\":\n",
      "1, \"Ukraine\": 1, \"Poland\": 1 }}\n",
      "(3 Errors - Missing one ”Australia, one ”New Zealand” and surplus of one ”Australia and New Zealand”)\n",
      "6.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Ukraine\": 1, \"Poland\": 1 }}\n",
      "(2 Errors - Missing one ”Australia” and one ”New Zealand”)\n",
      "7.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\n",
      "(Fully Correct)\n",
      "8.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Ukraine\": 1, \"Poland\": 1 }}\n",
      "(2 Errors - Missing one ”Australia” and one ”New Zealand”)\n",
      "9.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\n",
      "(Fully Correct)\n",
      "10.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\n",
      "(Fully Correct)\n",
      "36\n",
      "Table 25: Keyword counting for an example 4-passage split (GoT4): Step 2d (Prompt/Responses)\n",
      "Step 2d – Prompt:\n",
      "<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\n",
      "any intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\n",
      "once in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\n",
      "output as in the input text):\n",
      "{{\n",
      "\"country1\": frequency1,\n",
      "\"country2\": frequency2,\n",
      ". . .\n",
      "}}\n",
      "</Instruction >\n",
      "<Approach >\n",
      "To count the frequency for each country follow these steps:\n",
      "1. Split the input passage into four paragraphs of similar length.\n",
      "2. Count the frequency of each country in each paragraph.\n",
      "3. Combine the frequencies of each country from each paragraph by adding them together.\n",
      "</Approach >\n",
      "<Examples >See Table 18 </Examples >\n",
      "Input: Despite their tumultuous past, Ukraine and Poland shared a cultural tapestry that was deeply woven into their histo-\n",
      "ries. It was quite similar to the complex relationship between North Korea and South Korea, which, despite their political\n",
      "differences, shared common heritage and traditions. Thus, from Argentina to South Korea, the world was an intricate web of\n",
      "countries intertwined with each other through shared histories, cultures, and sometimes, shared destinies.\n",
      "Step 2d – 10 Responses:\n",
      "1.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\n",
      "2.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\n",
      "3.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\n",
      "4.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\n",
      "5.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\n",
      "6.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\n",
      "7.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\n",
      "8.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\n",
      "9.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\n",
      "10.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\n",
      "37\n",
      "Table 26: Keyword counting for an example 4-passage split (GoT4): Step 3a (Prompt/Responses)\n",
      "Step 3a – Prompt:\n",
      "<Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text, into a single\n",
      "dictionary. Simply add the frequencies together for each country and if a country is not present in one of the dictionaries,\n",
      "add it to the final dictionary with the frequency from the other dictionary.\n",
      "Only output the final merged dictionary without any additional text or thoughts! </Instruction >\n",
      "<Approach >\n",
      "To combine the 2 dictionaries into single one, follow these steps:\n",
      "1. Create a new dictionary to store the combined frequencies.\n",
      "2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\n",
      "3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\n",
      "already present, add the frequency to the existing value.\n",
      "</Approach >\n",
      "Combine the following 2 dictionaries into a single dictionary:\n",
      "{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}\n",
      "{{\"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United States\": 1, \"Canada\": 1 }}\n",
      "Combined Output:\n",
      "Step 3a – 3 Responses:\n",
      "1.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\n",
      "States\": 1, \"Canada\": 1 }}(Valid - No Improvement) (2 Errors - from counting)\n",
      "2.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\n",
      "States\": 1, \"Canada\": 1 }}(Valid - No Improvement) (2 Errors - from counting)\n",
      "3.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\n",
      "States\": 1, \"Canada\": 1 }}(Valid - No Improvement) (2 Errors - from counting)\n",
      "38\n",
      "Table 27: Keyword counting for an example 4-passage split (GoT4): Step 3b (Prompt/Responses)\n",
      "Step 3b – Prompt:\n",
      "<Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text, into a single\n",
      "dictionary. Simply add the frequencies together for each country and if a country is not present in one of the dictionaries,\n",
      "add it to the final dictionary with the frequency from the other dictionary.\n",
      "Only output the final merged dictionary without any additional text or thoughts! </Instruction >\n",
      "<Approach >\n",
      "To combine the 2 dictionaries into single one, follow these steps:\n",
      "1. Create a new dictionary to store the combined frequencies.\n",
      "2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\n",
      "3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\n",
      "already present, add the frequency to the existing value.\n",
      "</Approach >\n",
      "Combine the following 2 dictionaries into a single dictionary:\n",
      "{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\n",
      "{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}\n",
      "Combined Output:\n",
      "Step 3b – 3 Responses:\n",
      "1.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\n",
      "\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Valid - No Improvement) (Fully Correct)\n",
      "2.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\n",
      "\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Valid - No Improvement) (Fully Correct)\n",
      "3.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\n",
      "\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Valid - No Improvement) (Fully Correct)\n",
      "39\n",
      "Table 28: Keyword counting for an example 4-passage split (GoT4): Step 3c (Prompt/Responses)\n",
      "Step 3c – Prompt:\n",
      "<Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text, into a single\n",
      "dictionary. Simply add the frequencies together for each country and if a country is not present in one of the dictionaries,\n",
      "add it to the final dictionary with the frequency from the other dictionary.\n",
      "Only output the final merged dictionary without any additional text or thoughts! </Instruction >\n",
      "<Approach >\n",
      "To combine the 2 dictionaries into single one, follow these steps:\n",
      "1. Create a new dictionary to store the combined frequencies.\n",
      "2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\n",
      "3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\n",
      "already present, add the frequency to the existing value.\n",
      "</Approach >\n",
      "Combine the following 2 dictionaries into a single dictionary:\n",
      "{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\n",
      "States\": 1, \"Canada\": 1 }}\n",
      "{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\n",
      "\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}\n",
      "Combined Output:\n",
      "Step 3c – 3 Responses:\n",
      "1.{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\n",
      "States\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North\n",
      "Korea\": 1, \"South Korea\": 2 }}(Valid - No Improvement) (2 Errors - from counting)\n",
      "2.{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\n",
      "States\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North\n",
      "Korea\": 1, \"South Korea\": 2 }}(Valid - No Improvement) (2 Errors - from counting)\n",
      "3.{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\n",
      "States\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North\n",
      "Korea\": 1, \"South Korea\": 2 }}(Valid - No Improvement) (2 Errors - from counting)\n",
      "Final Result (2 Errors):\n",
      "{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\n",
      "States\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North Korea\":\n",
      "1, \"South Korea\": 2 }}\n",
      "40\n",
      "E Example Prompts - Document Merging\n",
      "We present the prompts only for GoTof the document merg-\n",
      "ing task, as GoT2 only differs in the fact that it merges the\n",
      "4 NDAs in 2 steps rather than 1. For document merging, we\n",
      "employ four distinct types of operations that interact with the\n",
      "LLM, each with its corresponding prompts. First, there is the\n",
      "Generate operation, utilizing the merge prompt to instruct\n",
      "the LLM to merge the 4 NDAs into 1. Second, the Score\n",
      "operations instructs the LLM to score a given merged NDA\n",
      "using the score prompt . Next, the Aggregate operation em-\n",
      "ploys the aggregate prompt to instruct the LLM to aggregate\n",
      "multiple merge attempts into a single, better one. Finally, the\n",
      "Improve operation leverages the improve prompt to instruct\n",
      "the LLM to improve a merged NDA.\n",
      "First, we present the prompt stubs (Table 29 - Table 30),\n",
      "serving as templates to dynamically generate appropriate\n",
      "prompts at runtime. Following this, we outline the LLM in-\n",
      "teractions throughout a complete merging process (Table 31\n",
      "- Table 49). However, instead of displaying each input/gen-\n",
      "erated NDA in every prompt/response, we present the 4 in-\n",
      "put NDAs in Table 31 - Table 33 and the final merged NDA\n",
      "in Table 49. Furthermore, as scoring is done using the LLM\n",
      "as well, we will present these interactions for the best per-\n",
      "forming merged NDAs (Tables 39 - 40 and Tables 47 - 48).\n",
      "Lastly, most responses are limited to a few lines only, as\n",
      "they don’t offer any further insights and would otherwise\n",
      "span multiple pages. However, we refer the interested reader\n",
      "to the results in the corresponding code repository2for full\n",
      "logs and further examples.\n",
      "2https://github.com/spcl/graph-of-thoughts\n",
      "41\n",
      "Table 29: Prompt stubs for the document merging task; parameters in single curly brackets will be substituted at runtime.\n",
      "merge prompt: Merge the following 4 NDA documents <Doc1>-<Doc4>into a single NDA, maximizing retained\n",
      "information and minimizing redundancy. Output only the created NDA between the tags <Merged >and</Merged >,\n",
      "without any additional text.\n",
      "Here are NDAs <Doc1>-<Doc4>:\n",
      "<Doc1>{doc1}</Doc1 >\n",
      "<Doc2>{doc2}</Doc2 >\n",
      "<Doc3>{doc3}</Doc3 >\n",
      "<Doc4>{doc4}</Doc4 >\n",
      "score prompt: The following NDA <S>merges NDAs <Doc1>-<Doc4>.\n",
      "Please score the merged NDA <S>in terms of how much redundant information is contained, independent of the original\n",
      "NDAs, as well as how much information is retained from the original NDAs.\n",
      "A score of 10 for redundancy implies that absolutely no information is redundant, while a score of 0 implies that at least half\n",
      "of the information is redundant (so everything is at least mentioned twice).\n",
      "A score of 10 for retained information implies that all information from the original NDAs is retained, while a score of 0\n",
      "implies that no information is retained.\n",
      "You may provide reasoning for your scoring, but the final score for redundancy should be between the tags <Redundancy >\n",
      "and</Redundancy >, and the final score for retained information should be between the tags <Retained >and</Retained >,\n",
      "without any additional text within any of those tags.\n",
      "Here are NDAs <Doc1>-<Doc4>:\n",
      "<Doc1>{doc1}</Doc1 >\n",
      "<Doc2>{doc2}</Doc2 >\n",
      "<Doc3>{doc3}</Doc3 >\n",
      "<Doc4>{doc4}</Doc4 >\n",
      "Here is the merged NDA <S>:\n",
      "<S>{s}</S>\n",
      "aggregate prompt: The following NDAs <S1>-<S{num ndas summaries }>each merge the initial NDAs <Doc1>-\n",
      "<Doc4>.\n",
      "Combine the merged NDAs <S1>-<S{num ndas summaries }>into a new one, maximizing their advantages and overall\n",
      "information retention, while minimizing redundancy.\n",
      "Output only the new NDA between the tags <Merged >and</Merged >, without any additional text.\n",
      "Here are the original NDAs <Doc1>-<Doc4>:\n",
      "<Doc1>{doc1}</Doc1 >\n",
      "<Doc2>{doc2}</Doc2 >\n",
      "<Doc3>{doc3}</Doc3 >\n",
      "<Doc4>{doc4}</Doc4 >\n",
      "Here are the merged NDAs <S1>-<S{num ndas summaries }>:\n",
      "<S1>{s1}</S1>\n",
      ". . .\n",
      "<S{num ndas summaries }>{s{num ndas summaries }}</S{num ndas summaries }>\n",
      "42\n",
      "Table 30: Prompt stubs for the document merging task continued ; parameters in single curly brackets will be substituted at\n",
      "runtime.\n",
      "improve prompt: The following NDA <S>merges initial NDAs <Doc1>-<Doc4>.\n",
      "Please improve the merged NDA <S>by adding more information and removing redundancy. Output only the improved\n",
      "NDA, placed between the tags <Merged >and</Merged >, without any additional text.\n",
      "Here are NDAs <Doc1>-<Doc4>:\n",
      "<Doc1>{doc1}</Doc1 >\n",
      "<Doc2>{doc2}</Doc2 >\n",
      "<Doc3>{doc3}</Doc3 >\n",
      "<Doc4>{doc4}</Doc4 >\n",
      "Here is the merged NDA <S>:\n",
      "<S>{s}</S>\n",
      "43\n",
      "Table 31: Input NDA 1 and 2\n",
      "<Doc1>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      "3. ”Confidential Information” includes all potentially commercially valuable information, specifically software development\n",
      "tactics, processes, and in-house research results.\n",
      "4. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\n",
      "disclose it without consent.\n",
      "5. Breach penalties include injunctive relief, other remedies, and a $200,000 fee per breach.\n",
      "6. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\n",
      "enforcement doesn’t imply waiver.\n",
      "7. The Agreement is under the laws of [State].\n",
      "8. Signed by [Your Company Name] and [Recipient Name] at the above date.\n",
      "</Doc1 >\n",
      "<Doc2>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "Effective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\n",
      "(”Receiving Party”).\n",
      "1. Purpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\n",
      "for [Purpose].\n",
      "2. Confidential Information: Defined as all non-public reports, data, designs, and other materials provided by the Disclosing\n",
      "Party to the Receiving Party.\n",
      "3. Receiving Party’s Obligations:\n",
      "a. Use, reproduce, or distribute the confidential information only for the agreed purpose.\n",
      "b. Restrict access to the information to necessary parties, ensuring they abide by strict confidentiality.\n",
      "c. Return or destroy all confidential information upon request or at the end of the agreement.\n",
      "4. Exclusions: Information will not be classified as confidential if it is already known to the Receiving Party, publicly known,\n",
      "or independently developed by the Receiving Party.\n",
      "5. Non-Competition: The Receiving Party will not engage in any competing business against the Disclosing Party during\n",
      "the agreement and one year after its termination.\n",
      "6. Term and Termination: The agreement is valid for [e.g., ”two years”], unless terminated earlier with [e.g., ”30 days”]\n",
      "written notice. The Receiving Party’s non-disclosure and non-competition obligations persist post-termination.\n",
      "7. General Provisions:\n",
      "a. Governing Law: [Your State]’s laws apply.\n",
      "b. Amendments: Only valid if written and signed by both parties.\n",
      "c. Entire Agreement: This contract overrules previous related agreements.\n",
      "Signed as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party.\n",
      "</Doc2 >\n",
      "44\n",
      "Table 32: Input NDA 3\n",
      "<Doc3>\n",
      "CONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\n",
      "Entities Involved:\n",
      "Effective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\n",
      "Objective:\n",
      "To safeguard classified data during talks of a potential technological alliance.\n",
      "Specification of Protected Information:\n",
      "Particularly:\n",
      "a. System designs and architectural schematics.\n",
      "b. Proprietary computational algorithms.\n",
      "Receiver’s Obligations:\n",
      "a. Maintain strict non-disclosure using best practices.\n",
      "b. Employ solely for the aforementioned aim.\n",
      "c. No unveiling without explicit authorization.\n",
      "Violation Ramifications:\n",
      "A charge of $280,000 for every infringement, plus possible legal proceedings.\n",
      "General Terms:\n",
      "Binding for both parties and any successors. This encapsulates the entire accord.\n",
      "Legal Reference:\n",
      "Governed as per [State]’s legal framework.\n",
      "Attestation:\n",
      "Duly signed on [Date].\n",
      "[AquaBlue Innovations] [PineTree Solutions]\n",
      "</Doc3 >\n",
      "45\n",
      "Table 33: Input NDA 4\n",
      "<Doc4>\n",
      "SECRECY & DISCLOSURE AGREEMENT\n",
      "Contracting Parties:\n",
      "Dated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\n",
      "organization.\n",
      "Aim:\n",
      "To protect exclusive insights amidst dialogues for a technological partnership.\n",
      "Categorization of Sensitive Data:\n",
      "Includes:\n",
      "a. Internal software blueprints.\n",
      "b. Intellectual property awaiting patents.\n",
      "Commitments of Recipient:\n",
      "a. Uphold confidentiality, ensuring data integrity.\n",
      "b. Utilize strictly for collaborative ventures.\n",
      "c. No exposure without prior consensus.\n",
      "Repercussions for Non-Compliance:\n",
      "$295,000 fine for each transgression, and the option for legal recourse.\n",
      "Overall Provisions:\n",
      "Legally enforceable for signatories and successors. Complete and sole agreement.\n",
      "Juridical Standpoint:\n",
      "Under the auspices of [State] laws.\n",
      "Ratification:\n",
      "Confirmed and endorsed on [Date].\n",
      "[AquaBlue Innovations] [PineTree Solutions]\n",
      "</Doc4 >\n",
      "Table 34: Merging 4 example NDAs: Execution plan ( GoO )\n",
      "GoO:\n",
      "1. Merge the 4 NDAs into a single one 5 times; Score each attempt and keep the best 3\n",
      "2. Aggregate the merge attempts into a single one 5 times; Score each aggregation attempt and keep the overall best attempt\n",
      "(including Step 1)\n",
      "3. Improve the merged NDA 10 times; Score each and keep the best\n",
      "46\n",
      "Table 35: Merging 4 example NDAs: Step 1 (Prompt)\n",
      "Merge the following 4 NDA documents <Doc1>-<Doc4>into a single NDA, maximizing retained information and\n",
      "minimizing redundancy. Output only the created NDA between the tags <Merged >and</Merged >, without any additional\n",
      "text.\n",
      "Here are NDAs <Doc1>-<Doc4>:\n",
      "<Doc1>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted, see Table 31)\n",
      "</Doc1 >\n",
      "<Doc2>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "Effective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\n",
      "(”Receiving Party”).\n",
      "1. Purpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\n",
      "for [Purpose].\n",
      ". . .(Omitted, see Table 31)\n",
      "</Doc2 >\n",
      "<Doc3>\n",
      "CONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\n",
      "Entities Involved:\n",
      "Effective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\n",
      "Objective:\n",
      "To safeguard classified data during talks of a potential . . .(Omitted, see Table 32)\n",
      "</Doc3 >\n",
      "<Doc4>\n",
      "SECRECY & DISCLOSURE AGREEMENT\n",
      "Contracting Parties:\n",
      "Dated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\n",
      "organization.\n",
      "Aim:\n",
      "To protect exclusive insights amidst . . .(Omitted, see Table 33)\n",
      "</Doc4 >\n",
      "47\n",
      "Table 36: Merging 4 example NDAs; we only present the highest scoring response fully in Tables 37-38: Step 1 (Responses)\n",
      "Note that due to the shortening of responses, the appear to be equal, but small differences can be found when observing\n",
      "the fully generated summaries. The only small differences are reflected in the very similar scores (see Table 39-40 for the\n",
      "scoring of the best response).\n",
      "Response (1/5):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.60\n",
      "Response (2/5):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted, see Tables 37 - 38)\n",
      "Score: 6.87\n",
      "Response (3/5):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.60\n",
      "Response (4/5):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 5.78\n",
      "Response (5/5):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.50\n",
      "48\n",
      "Table 37: Merging 4 example NDAs: Step 1 (Highest Scoring Response Part 1)\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      "3. ”Confidential Information” includes all potentially commercially valuable information, specifically software development\n",
      "tactics, processes, and in-house research results.\n",
      "4. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\n",
      "disclose it without consent.\n",
      "5. Breach penalties include injunctive relief, other remedies, and a $200,000 fee per breach.\n",
      "6. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\n",
      "enforcement doesn’t imply waiver.\n",
      "7. The Agreement is under the laws of [State].\n",
      "8. Signed by [Your Company Name] and [Recipient Name] at the above date.\n",
      "Effective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\n",
      "(”Receiving Party”).\n",
      "Purpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\n",
      "for [Purpose].\n",
      "Confidential Information: Defined as all non-public reports, data, designs, and other materials provided by the Disclosing\n",
      "Party to the Receiving Party.\n",
      "Receiving Party’s Obligations:\n",
      "a. Use, reproduce, or distribute the confidential information only for the agreed purpose.\n",
      "b. Restrict access to the information to necessary parties, ensuring they abide by strict confidentiality.\n",
      "c. Return or destroy all confidential information upon request or at the end of the agreement.\n",
      "Exclusions: Information will not be classified as confidential if it is already known to the Receiving Party, publicly known,\n",
      "or independently developed by the Receiving Party.\n",
      "Non-Competition: The Receiving Party will not engage in any competing business against the Disclosing Party during the\n",
      "agreement and one year after its termination.\n",
      "Term and Termination: The agreement is valid for [e.g., ”two years”], unless terminated earlier with [e.g., ”30 days”] written\n",
      "notice. The Receiving Party’s non-disclosure and non-competition obligations persist post-termination.\n",
      "General Provisions:\n",
      "a. Governing Law: [Your State]’s laws apply.\n",
      "b. Amendments: Only valid if written and signed by both parties.\n",
      "c. Entire Agreement: This contract overrules previous related agreements.\n",
      "Signed as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party.\n",
      "Entities Involved:\n",
      "Effective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\n",
      "Objective:\n",
      "To safeguard classified data during talks of a potential technological alliance.\n",
      "49\n",
      "Table 38: Merging 4 example NDAs: Step 1 (Highest Scoring Response Part 2)\n",
      "Specification of Protected Information:\n",
      "Particularly:\n",
      "a. System designs and architectural schematics.\n",
      "b. Proprietary computational algorithms.\n",
      "Receiver’s Obligations:\n",
      "a. Maintain strict non-disclosure using best practices.\n",
      "b. Employ solely for the aforementioned aim.\n",
      "c. No unveiling without explicit authorization.\n",
      "Violation Ramifications:\n",
      "A charge of $280,000 for every infringement, plus possible legal proceedings.\n",
      "General Terms:\n",
      "Binding for both parties and any successors. This encapsulates the entire accord.\n",
      "Legal Reference:\n",
      "Governed as per [State]’s legal framework.\n",
      "Attestation:\n",
      "Duly signed on [Date].\n",
      "Contracting Parties:\n",
      "Dated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\n",
      "organization.\n",
      "Aim:\n",
      "To protect exclusive insights amidst dialogues for a technological partnership.\n",
      "Categorization of Sensitive Data:\n",
      "Includes:\n",
      "a. Internal software blueprints.\n",
      "b. Intellectual property awaiting patents.\n",
      "Commitments of Recipient:\n",
      "a. Uphold confidentiality, ensuring data integrity.\n",
      "b. Utilize strictly for collaborative ventures.\n",
      "c. No exposure without prior consensus.\n",
      "Repercussions for Non-Compliance:\n",
      "$295,000 fine for each transgression, and the option for legal recourse.\n",
      "Overall Provisions:\n",
      "Legally enforceable for signatories and successors. Complete and sole agreement.\n",
      "Juridical Standpoint:\n",
      "Under the auspices of [State] laws.\n",
      "Ratification:\n",
      "Confirmed and endorsed on [Date].\n",
      "50\n",
      "Table 39: Merging 4 example NDAs: Step 1 (Scoring Example – Prompt)\n",
      "Please score the merged NDA <S>in terms of how much redundant information is contained, independent of the original\n",
      "NDAs, as well as how much information is retained from the original NDAs.\n",
      "A score of 10 for redundancy implies that absolutely no information is redundant, while a score of 0 implies that at least half\n",
      "of the information is redundant (so everything is at least mentioned twice).\n",
      "A score of 10 for retained information implies that all information from the original NDAs is retained, while a score of 0\n",
      "implies that no information is retained.\n",
      "You may provide reasoning for your scoring, but the final score for redundancy should be between the tags <Redundancy >\n",
      "and</Redundancy >, and the final score for retained information should be between the tags <Retained >and</Retained >,\n",
      "without any additional text within any of those tags.\n",
      "Here are NDAs <Doc1>-<Doc4>:\n",
      "<Doc1>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      ". . .(Omitted, see Table 31)\n",
      "</Doc1 >\n",
      "<Doc2>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "Effective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\n",
      "(”Receiving Party”).\n",
      ". . .(Omitted, see Table 31)\n",
      "</Doc2 >\n",
      "<Doc3>\n",
      "CONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\n",
      "Entities Involved:\n",
      "Effective [Date], between [AquaBlue Innovations], established in [State], and . . .(Omitted, see Table 32)\n",
      "</Doc3 >\n",
      "<Doc4>\n",
      "SECRECY & DISCLOSURE AGREEMENT\n",
      "Contracting Parties:\n",
      "Dated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and . . .(Omitted, see Table 33)\n",
      "</Doc4 >\n",
      "Here is the summary NDA <S>:\n",
      "<S>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted, see Tables 37-38)\n",
      "</S>\n",
      "51\n",
      "Table 40: Merging 4 example NDAs: Step 1 (Scoring Example – Responses)\n",
      "Response (1/3):\n",
      "<Redundancy >5</Redundancy >\n",
      "<Retained >10</Retained >\n",
      "Reasoning:\n",
      "In terms of redundancy, there is some overlap in the information contained in the NDAs, such as the definition of ”Confiden-\n",
      "tial Information” and the obligations of the receiving party. However, there are also some unique details in each NDA, such\n",
      "as the specific purpose of information sharing and the penalties for breach. Overall, there is a moderate level of redundancy\n",
      "in the merged NDA.\n",
      "In terms of retained information, all the key elements from the original NDAs are included in the merged NDA. This\n",
      "includes the agreement between the parties, the purpose of information sharing, the definition of confidential information,\n",
      "the obligations of the receiving party, the exclusions for confidential information, non-competition clauses, the term and\n",
      "termination of the agreement, and the general provisions. Therefore, the merged NDA retains all the important information\n",
      "from the original NDAs.\n",
      "Response (2/3):\n",
      "<Redundancy >8</Redundancy >\n",
      "<Retained >10</Retained >\n",
      "Reasoning:\n",
      "The merged NDA <S>contains multiple redundant sections from the original NDAs. For example, the introductory sections,\n",
      "such as the agreement between the parties and the purpose of information sharing, are repeated multiple times. Additionally,\n",
      "sections related to the definition of confidential information, the recipient’s obligations, exclusions, non-competition, term\n",
      "and termination, and general provisions are also redundantly included.\n",
      "However, in terms of retained information, the merged NDA retains all the key elements from the original NDAs, including\n",
      "the parties involved, the objective, specification of protected information, recipient’s obligations, violation ramifications,\n",
      "general terms, legal reference, and attestation. Overall, while there is redundancy in the merged NDA, it successfully retains\n",
      "all the necessary information from the original NDAs.\n",
      "Response (3/3):\n",
      "<Redundancy >3</Redundancy >\n",
      "The merged NDA contains some redundancy. There are three sections that have overlapping information between the original\n",
      "NDAs. These sections include:\n",
      "1. The agreement between the parties (Section 1 in Doc1 and the beginning of Doc2)\n",
      "2. Information sharing and the purpose of the NDA (Section 2 in both Doc1 and Doc2)\n",
      "3. General provisions such as governing law and amendments (Section 7 in Doc1 and Doc2)\n",
      "<Retained >9</Retained >\n",
      "The merged NDA retains a significant amount of information from the original NDAs. It includes all key clauses and provi-\n",
      "sions, such as the definition of confidential information, the obligations of the receiving party, exclusions, non-competition,\n",
      "and general provisions. Only a few minor details, such as specific penalties and fine amounts, are not retained in the merged\n",
      "NDA. Overall, the merged NDA effectively combines the essential elements from the original NDAs.\n",
      "Note: Remember to remove the reasoning from between the tags when providing the final scores.\n",
      "Final Overall Score (Harmonic Mean of Averages):\n",
      "6.87\n",
      "52\n",
      "Table 41: Merging 4 example NDAs; Note that S1-S3 are the three best scoring merge attemps from the previous step: Step 2\n",
      "(Prompt)\n",
      "The following NDAs <S1>-<S3>each merge the initial NDAs <Doc1>-<Doc4>.\n",
      "Combine the merged NDAs <S1>-<S3>into a new one, maximizing their advantages and overall information retention,\n",
      "while minimizing redundancy.\n",
      "Output only the new NDA between the tags <Merged >and</Merged >, without any additional text.\n",
      "Here are the original NDAs <Doc1>-<Doc4>:\n",
      "<Doc1>\n",
      ". . .(Omitted, see Table 31)\n",
      "</Doc1 >\n",
      "<Doc2>\n",
      ". . .(Omitted, see Table 31)\n",
      "</Doc2 >\n",
      "<Doc3>\n",
      ". . .(Omitted, see Table 32)\n",
      "</Doc3 >\n",
      "<Doc4>\n",
      ". . .(Omitted, see Table 33)\n",
      "</Doc4 >\n",
      "Here are the merged NDAs <S1>-<S3>:\n",
      "<S1>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      ". . .(Omitted)\n",
      "</S1>\n",
      "<S2>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      ". . .(Omitted, see Tables 37-38)\n",
      "</S2>\n",
      "<S3>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      ". . .(Omitted)\n",
      "</S3>\n",
      "53\n",
      "Table 42: Merging 4 example NDAs: Step 2 (Responses)\n",
      "For this run, none of the responses improve upon the previous best and thus will all be discarded by the next step. For that\n",
      "reason and due to their long length, we do not present them fully and exclude their scoring.\n",
      "Response (1/5):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.50\n",
      "Response (2/5):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "Effective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\n",
      "(”Receiving Party”).\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      ". . .(Omitted)\n",
      "Score: 5.62\n",
      "Response (3/5):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.60\n",
      "Response (4/5):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.15\n",
      "Response (5/5):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.22\n",
      "54\n",
      "Table 43: Merging 4 example NDAs: Step 3 (Prompt)\n",
      "The following NDA <S>merges initial NDAs <Doc1>-<Doc4>.\n",
      "Please improve the merged NDA <S>by adding more information and removing redundancy. Output only the improved\n",
      "NDA, placed between the tags <Merged >and</Merged >, without any additional text.\n",
      "Here are NDAs <Doc1>-<Doc4>:\n",
      "<Doc1>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted, see Table 31)\n",
      "</Doc1 >\n",
      "<Doc2>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "Effective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\n",
      "(”Receiving Party”).\n",
      "1. Purpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\n",
      "for [Purpose].\n",
      ". . .(Omitted, see Table 31)\n",
      "</Doc2 >\n",
      "<Doc3>\n",
      "CONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\n",
      "Entities Involved:\n",
      "Effective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\n",
      "Objective:\n",
      "To safeguard classified data during talks of a potential . . .(Omitted, see Table 32)\n",
      "</Doc3 >\n",
      "<Doc4>\n",
      "SECRECY & DISCLOSURE AGREEMENT\n",
      "Contracting Parties:\n",
      "Dated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\n",
      "organization.\n",
      "Aim:\n",
      "To protect exclusive insights amidst . . .(Omitted, see Table 33)\n",
      "</Doc4 >\n",
      "Here is the summary NDA <S>:\n",
      "<S>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted, see Tables 37-38)\n",
      "</S>\n",
      "55\n",
      "Table 44: Merging 4 example NDAs; we only present the highest scoring response fully in Table 46: Step 3 (Responses Part\n",
      "1)\n",
      "Response (1/10):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.35\n",
      "Response (2/10):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.35\n",
      "Response (3/10):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date], for the purpose of [specific project or\n",
      "purpose].\n",
      "2. ”Confidential Information” includes all potentially commercially valuable information, specifically software develop-\n",
      "ment tactics, processes, in-house research results, system designs, architectural schematics, proprietary computational\n",
      "algorithms, internal software blueprints, and intellectual property awaiting patents.\n",
      ". . .(Omitted)\n",
      "Score: 6.87\n",
      "Response (4/10):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\n",
      "purpose].\n",
      "2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\n",
      "tactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\n",
      "rithms, internal software blueprints, and intellectual property awaiting patents.\n",
      ". . .(Omitted, see Table 46))\n",
      "Score: 7.78\n",
      "Response (5/10):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.43\n",
      "56\n",
      "Table 45: Merging 4 example NDAs; we only present the highest scoring response fully in Table 46: Step 3 (Responses Part\n",
      "2)\n",
      "Response (6/10):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.35\n",
      "Response (7/10):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\n",
      "purpose].\n",
      "2. ”Confidential Information” includes all potentially commercially valuable information, specifically software develop-\n",
      "ment tactics, processes, in-house research results, system designs, architectural schematics, proprietary computational\n",
      "algorithms, internal software blueprints, and intellectual property awaiting patents.\n",
      ". . .(Omitted)\n",
      "Score: 6.70\n",
      "Response (8/10):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\n",
      "purpose].\n",
      "2. ”Confidential Information” includes potentially commercially valuable information, such as software development tac-\n",
      "tics, processes, in-house research results, non-public reports, data, designs, and other materials provided by the Disclosing\n",
      "Party.\n",
      ". . .(Omitted)\n",
      "Score: 5.33\n",
      "Response (9/10):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "2. Information sharing for the purpose of [specific project or purpose], including [Topic of Research].\n",
      ". . .(Omitted)\n",
      "Score: 7.30\n",
      "Response (10/10):\n",
      "<Merged >\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      "Information sharing for the purpose of [specific project or purpose].\n",
      ". . .(Omitted)\n",
      "Score: 6.40\n",
      "57\n",
      "Table 46: Merging 4 example NDAs: Step 3 (Highest Scoring Response)\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\n",
      "purpose].\n",
      "2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\n",
      "tactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\n",
      "rithms, internal software blueprints, and intellectual property awaiting patents.\n",
      "3. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\n",
      "disclose it without consent.\n",
      "4. Breach penalties include injunctive relief, other remedies, and a fine per breach (e.g., $200,000 or $280,000 for each\n",
      "infringement, depending on the agreement).\n",
      "5. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\n",
      "enforcement doesn’t imply waiver.\n",
      "6. The Agreement is under the laws of [State] and is valid for a specified period (e.g., two years) unless terminated earlier\n",
      "with written notice (e.g., 30 days).\n",
      "7. The Receiving Party agrees not to engage in any competing business against the Disclosing Party during the agreement\n",
      "and a specified period after its termination (e.g., one year).\n",
      "8. The Agreement can only be amended if written and signed by both parties, and overrules previous related agreements.\n",
      "9. The Agreement is legally enforceable and binding for signatories and successors.\n",
      "10. The Agreement is governed by the laws of [State].\n",
      "Signed as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party, along\n",
      "with the other parties involved.\n",
      "58\n",
      "Table 47: Merging 4 example NDAs: Step 3 (Scoring Example – Prompt)\n",
      "Please score the merged NDA <S>in terms of how much redundant information is contained, independent of the original\n",
      "NDAs, as well as how much information is retained from the original NDAs.\n",
      "A score of 10 for redundancy implies that absolutely no information is redundant, while a score of 0 implies that at least half\n",
      "of the information is redundant (so everything is at least mentioned twice).\n",
      "A score of 10 for retained information implies that all information from the original NDAs is retained, while a score of 0\n",
      "implies that no information is retained.\n",
      "You may provide reasoning for your scoring, but the final score for redundancy should be between the tags <Redundancy >\n",
      "and</Redundancy >, and the final score for retained information should be between the tags <Retained >and</Retained >,\n",
      "without any additional text within any of those tags.\n",
      "Here are NDAs <Doc1>-<Doc4>:\n",
      "<Doc1>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\n",
      ". . .(Omitted, see Table 31)\n",
      "</Doc1 >\n",
      "<Doc2>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "Effective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\n",
      "(”Receiving Party”).\n",
      ". . .(Omitted, see Table 31)\n",
      "</Doc2 >\n",
      "<Doc3>\n",
      "CONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\n",
      "Entities Involved:\n",
      "Effective [Date], between [AquaBlue Innovations], established in [State], and . . .(Omitted, see Table 32)\n",
      "</Doc3 >\n",
      "<Doc4>\n",
      "SECRECY & DISCLOSURE AGREEMENT\n",
      "Contracting Parties:\n",
      "Dated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and . . .(Omitted, see Table 33)\n",
      "</Doc4 >\n",
      "Here is the summary NDA <S>:\n",
      "<S>\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\n",
      "purpose].\n",
      "2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\n",
      "tactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\n",
      "rithms, internal software blueprints, and intellectual property awaiting patents.\n",
      ". . .(Omitted, see Table 46)\n",
      "</S>\n",
      "59\n",
      "Table 48: Merging 4 example NDAs: Step 3 (Scoring Example – Responses)\n",
      "Response (1/3):\n",
      "<Redundancy >5</Redundancy >\n",
      "<Retained >8</Retained >\n",
      "Reasoning:\n",
      "The merged NDA <S>retains most of the information from the original NDAs, combining relevant clauses and terms\n",
      "into a single comprehensive agreement. However, some redundancy is present as similar information is mentioned multiple\n",
      "times, such as the definition of ”Confidential Information” and the obligations of the receiving party. Additionally, some\n",
      "specific details from the original NDAs are not included in the merged NDA, such as the exclusion criteria in Doc2 and the\n",
      "provisions for non-competition in Doc3 and Doc4. Nonetheless, the merged NDA captures the essence of the original NDAs\n",
      "and includes all key information necessary for a non-disclosure agreement.\n",
      "Response (2/3):\n",
      "<Redundancy >8</Redundancy >\n",
      "<Retained >10</Retained >\n",
      "Reasoning:\n",
      "The merged NDA <S>retains all the key information from the original NDAs, including the purpose of the agreement,\n",
      "the definition of confidential information, the obligations of the receiving party, breach penalties, applicability to parties and\n",
      "successors, governing law, and signature requirements.\n",
      "There is some redundant information, such as the inclusion of system designs, architectural schematics, proprietary com-\n",
      "putational algorithms, internal software blueprints, and intellectual property awaiting patents from both Doc3 and Doc4.\n",
      "However, this redundancy is minor and does not significantly impact the overall usefulness of the NDA.\n",
      "Overall, the merged NDA <S>retains all important information while minimizing redundancy, making it highly effective\n",
      "in conveying the necessary terms and obligations of the agreement. Therefore, it receives a score of 8 for redundancy and a\n",
      "score of 10 for retained information.\n",
      "Response (3/3):\n",
      "<Redundancy >7</Redundancy >\n",
      "<Retained >10</Retained >\n",
      "Reasoning:\n",
      "The merged NDA <S>contains some redundant information, such as the definition of ”Confidential Information” and the\n",
      "obligations of the receiving party. However, it retains all the important information from the original NDAs, including the\n",
      "purpose of the agreement, the specific types of confidential information, the breach penalties, the applicability to parties and\n",
      "successors, the governing law, and the provisions regarding non-competition, amendment, and termination. Additionally, it\n",
      "incorporates the additional information about the agreement’s validity period and the option for legal recourse in case of\n",
      "non-compliance. Therefore, the merged NDA <S>scores a 7 for redundancy and a 10 for retained information.\n",
      "Final Overall Score (Harmonic Mean of Averages):\n",
      "7.78\n",
      "60\n",
      "Table 49: Merging 4 example NDAs: Final Merged NDA\n",
      "NON-DISCLOSURE AGREEMENT (NDA)\n",
      "1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\n",
      "purpose].\n",
      "2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\n",
      "tactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\n",
      "rithms, internal software blueprints, and intellectual property awaiting patents.\n",
      "3. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\n",
      "disclose it without consent.\n",
      "4. Breach penalties include injunctive relief, other remedies, and a fine per breach (e.g., $200,000 or $280,000 for each\n",
      "infringement, depending on the agreement).\n",
      "5. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\n",
      "enforcement doesn’t imply waiver.\n",
      "6. The Agreement is under the laws of [State] and is valid for a specified period (e.g., two years) unless terminated earlier\n",
      "with written notice (e.g., 30 days).\n",
      "7. The Receiving Party agrees not to engage in any competing business against the Disclosing Party during the agreement\n",
      "and a specified period after its termination (e.g., one year).\n",
      "8. The Agreement can only be amended if written and signed by both parties, and overrules previous related agreements.\n",
      "9. The Agreement is legally enforceable and binding for signatories and successors.\n",
      "10. The Agreement is governed by the laws of [State].\n",
      "Signed as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party, along\n",
      "with the other parties involved.\n",
      "61\n",
      "F Evaluation - GoT Configurations\n",
      "We detail the concrete operations that GoT was configured\n",
      "with to solve the set intersection and sorting use cases.\n",
      "Listing 1: GoT configuration for the set intersection use case\n",
      "with 32 elements\n",
      "1Generate (k =1) # Split second set into two halves of 16 elements\n",
      "2foreach subset :\n",
      "3 Generate (k =5) # Determine intersected subset of subset and\n",
      "first input set\n",
      "4 Score (k =1) # Score locally the intersected subsets\n",
      "5 KeepBestN (1) # Keep the best intersected subset\n",
      "6Aggregate (10) # Merge both intersected subsets\n",
      "7Score (k =1) # Score locally the intersected result sets\n",
      "8KeepBestN (1) # Keep the best result\n",
      "9GroundTruth () # Compare to precomputed result\n",
      "Listing 2: GoT configuration for the set intersection use case\n",
      "with 64 elements\n",
      "1Generate (k =1) # Split second set into four parts of 16 elements\n",
      "2foreach subset :\n",
      "3 Generate (k =5) # Determine intersected subset of subset and\n",
      "first input set\n",
      "4 Score (k =1) # Score locally the intersected subsets\n",
      "5 KeepBestN (1) # Keep the best intersected subset\n",
      "6merge step 1:\n",
      "7 Aggregate (10) # Merge intersected subsets 1 and 2\n",
      "8 Score (k =1) # Score locally the intersected result sets\n",
      "9 KeepBestN (1) # Keep the best result\n",
      "10merge step 2:\n",
      "11 Aggregate (10) # Merge intersected subsets 3 and 4\n",
      "12 Score (k =1) # Score locally the intersected result sets\n",
      "13 KeepBestN (1) # Keep the best result\n",
      "14final merge :\n",
      "15 Aggregate (10) # Merge intermediate intersected subsets from\n",
      "merge step 1 and 2\n",
      "16 Score (k =1) # Score locally the intersected result sets\n",
      "17 KeepBestN (1) # Keep the best result\n",
      "18GroundTruth () # Compare to precomputed result\n",
      "Listing 3: GoT configuration for the set intersection use case\n",
      "with 128 elements\n",
      "1Generate (k =1) # Split second set into eight parts of 16\n",
      "elements\n",
      "2foreach subset :\n",
      "3 Generate (k =5) # Determine intersected subset of subset and\n",
      "first input set\n",
      "4 Score (k =1) # Score locally the intersected subsets\n",
      "5 KeepBestN (1) # Keep the best intersected subset\n",
      "6merge step 1:\n",
      "7 Aggregate (5) # Merge intersected subsets 1 and 2\n",
      "8 Score (k =1) # Score locally the intersected result sets\n",
      "9 KeepBestN (1) # Keep the best result\n",
      "10merge step 2:\n",
      "11 Aggregate (5) # Merge intersected subsets 3 and 4\n",
      "12 Score (k =1) # Score locally the intersected result sets\n",
      "13 KeepBestN (1) # Keep the best result\n",
      "14merge step 3:\n",
      "15 Aggregate (5) # Merge intersected subsets 5 and 6\n",
      "16 Score (k =1) # Score locally the intersected result sets\n",
      "17 KeepBestN (1) # Keep the best result\n",
      "18merge step 4:\n",
      "19 Aggregate (5) # Merge intersected subsets 7 and 8\n",
      "20 Score (k =1) # Score locally the intersected result setsListing 4: GoT configuration for the set intersection use case\n",
      "with 128 elements (cont.)\n",
      "21 KeepBestN (1) # Keep the best result\n",
      "22merge step 5:\n",
      "23 Aggregate (5) # Merge intermediate intersected subsets from\n",
      "merge step 1 and 2\n",
      "24 Score (k =1) # Score locally the intersected result sets\n",
      "25 KeepBestN (1) # Keep the best result\n",
      "26merge step 6:\n",
      "27 Aggregate (5) # Merge intermediate intersected subsets from\n",
      "merge step 3 and 4\n",
      "28 Score (k =1) # Score locally the intersected result sets\n",
      "29 KeepBestN (1) # Keep the best result\n",
      "30final merge :\n",
      "31 Aggregate (5) # Merge intermediate intersected subsets from\n",
      "merge step 5 and 6\n",
      "32 Score (k =1) # Score locally the intersected result sets\n",
      "33 KeepBestN (1) # Keep the best result\n",
      "34GroundTruth () # Compare to precomputed result\n",
      "Listing 5: GoT configuration for the sorting use case with 32\n",
      "elements\n",
      "1Generate (k =1) # Split list into two halves of 16 elements\n",
      "2foreach list part :\n",
      "3 Generate (k =5) # Sort list part\n",
      "4 Score (k =1) : # Score partially sorted list\n",
      "5 KeepBestN (1) : # Keep the best partially sorted list\n",
      "6Aggregate (10) # Merge both partially sorted lists\n",
      "7Score (k =1) # Score locally the sorted result lists\n",
      "8KeepBestN (1) # Keep the best result\n",
      "9Generate (k =10) # Try to improve solution\n",
      "10Score (k =1) # Score locally the sorted result lists\n",
      "11KeepBestN (1) # Keep the best result\n",
      "12GroundTruth () # Compare to precomputed result\n",
      "Listing 6: GoT configuration for the sorting use case with 64\n",
      "elements\n",
      "1Generate (k =1) # Split list into four parts of 16 elements\n",
      "2foreach list part :\n",
      "3 Generate (k =5) # Sort list part\n",
      "4 Score (k =1) # Score partially sorted list\n",
      "5 KeepBestN (1) # Keep the best partially sorted list\n",
      "6merge step 1:\n",
      "7 Aggregate (10) # Merge partially sorted lists 1 and 2\n",
      "8 Score (k =1) # Score locally the partially sorted result lists\n",
      "9 KeepBestN (1) # Keep the best result\n",
      "10 Generate (k =5) # Try to improve the partial solution\n",
      "11 Score (k =1) # Score locally the partially sorted result lists\n",
      "12 KeepBestN (1) # Keep the best result\n",
      "13merge step 2:\n",
      "14 Aggregate (10) # Merge partially sorted lists 3 and 4\n",
      "15 Score (k =1) # Score locally the partially sorted result lists\n",
      "16 KeepBestN (1) # Keep the best result\n",
      "17 Generate (k =5) # Try to improve the partial solution\n",
      "18 Score (k =1) # Score locally the partially sorted result lists\n",
      "19 KeepBestN (1) # Keep the best result\n",
      "20final merge :\n",
      "21 Aggegrate (10) # Merge partially sorted lists from merge step\n",
      "1 and 2\n",
      "22 Score (k =1) # Score locally the sorted result lists\n",
      "23 KeepBestN (1) # Keep the best result\n",
      "24 Generate (k =10) # Try to improve solution\n",
      "25 Score (k =1) # Score locally the sorted result lists\n",
      "26 KeepBestN (1) # Keep the best result\n",
      "27GroundTruth () # Compare to precomputed result\n",
      "62\n",
      "Listing 7: GoT configuration for the sorting use case with\n",
      "128 elements\n",
      "1Generate (k =1) # Split list into eight parts of 16 elements\n",
      "2foreach list part :\n",
      "3 Generate (k =5) # Sort list part\n",
      "4 Score (k =1) # Score partially sorted list\n",
      "5 KeepBestN (1) # Keep the best partially sorted list\n",
      "6merge step 1:\n",
      "7 Aggregate (10) # Merge partially sorted lists 1 and 2\n",
      "8 Score (k =1) # Score locally the partially sorted result lists\n",
      "9 KeepBestN (1) # Keep the best result\n",
      "10 Generate (k =5) # Try to improve the partial solution\n",
      "11 Score (k =1) # Score locally the partially sorted result lists\n",
      "12 KeepBestN (1) # Keep the best result\n",
      "13merge step 2:\n",
      "14 Aggregate (10) # Merge partially sorted lists 3 and 4\n",
      "15 Score (k =1) # Score locally the partially sorted result lists\n",
      "16 KeepBestN (1) # Keep the best result\n",
      "17 Generate (k =5) # Try to improve the partial solution\n",
      "18 Score (k =1) # Score locally the partially sorted result lists\n",
      "19 KeepBestN (1) # Keep the best result\n",
      "20merge step 3:\n",
      "21 Aggregate (10) # Merge partially sorted lists 5 and 6\n",
      "22 Score (k =1) # Score locally the partially sorted result lists\n",
      "23 KeepBestN (1) # Keep the best result\n",
      "24 Generate (k =5) # Try to improve the partial solution\n",
      "25 Score (k =1) # Score locally the partially sorted result lists\n",
      "26 KeepBestN (1) # Keep the best result\n",
      "27merge step 4:\n",
      "28 Aggregate (10) # Merge partially sorted lists 7 and 8\n",
      "29 Score (k =1) # Score locally the partially sorted result lists\n",
      "30 KeepBestN (1) # Keep the best result\n",
      "31 Generate (k =5) # Try to improve the partial solution\n",
      "32 Score (k =1) # Score locally the partially sorted result lists\n",
      "33 KeepBestN (1) # Keep the best result\n",
      "34merge step 5:\n",
      "35 Aggregate (10) # Merge partially sorted lists from merge step\n",
      "1 and 2\n",
      "36 Score (k =1) # Score locally the partially sorted result lists\n",
      "37 KeepBestN (1) # Keep the best result\n",
      "38 Generate (k =5) # Try to improve the partial solution\n",
      "39 Score (k =1) # Score locally the partially sorted result lists\n",
      "40 KeepBestN (1) # Keep the best result\n",
      "41merge step 6:\n",
      "42 Aggregate (10) # Merge partially sorted lists from merge step\n",
      "3 and 4\n",
      "43 Score (k =1) # Score locally the partially sorted result lists\n",
      "44 KeepBestN (1) # Keep the best result\n",
      "45 Generate (k =5) # Try to improve the partial solution\n",
      "46 Score (k =1) # Score locally the partially sorted result lists\n",
      "47 KeepBestN (1 # Keep the best result\n",
      "48final merge :\n",
      "49 Aggregate (10) # Merge partially sorted lists from merge step\n",
      "5 and 6\n",
      "50 Score (k =1) # Score locally the partially sorted result lists\n",
      "51 KeepBestN (1) # Keep the best result\n",
      "52 Generate (k =10) # Try to improve solution\n",
      "53 Score (k =1) # Score locally the sorted result lists\n",
      "54 KeepBestN (1) # Keep the best result\n",
      "55GroundTruth () # Compare to precomputed result\n",
      "63\n",
      "Tree of Thoughts: Deliberate Problem Solving\n",
      "with Large Language Models\n",
      "Shunyu Yao\n",
      "Princeton UniversityDian Yu\n",
      "Google DeepMindJeffrey Zhao\n",
      "Google DeepMindIzhak Shafran\n",
      "Google DeepMind\n",
      "Thomas L. Grifﬁths\n",
      "Princeton UniversityYuan Cao\n",
      "Google DeepMindKarthik Narasimhan\n",
      "Princeton University\n",
      "Abstract\n",
      "Language models are increasingly being deployed for general problem solving\n",
      "across a wide range of tasks, but are still conﬁned to token-level, left-to-right\n",
      "decision-making processes during inference. This means they can fall short in\n",
      "tasks that require exploration, strategic lookahead, or where initial decisions play\n",
      "a pivotal role. To surmount these challenges, we introduce a new framework for\n",
      "language model inference, “Tree of Thoughts” (ToT), which generalizes over the\n",
      "popular “Chain of Thought” approach to prompting language models, and enables\n",
      "exploration over coherent units of text (“thoughts”) that serve as intermediate steps\n",
      "toward problem solving. ToT allows LMs to perform deliberate decision making\n",
      "by considering multiple different reasoning paths and self-evaluating choices to\n",
      "decide the next course of action, as well as looking ahead or backtracking when\n",
      "necessary to make global choices. Our experiments show that ToT signiﬁcantly\n",
      "enhances language models’ problem-solving abilities on three novel tasks requiring\n",
      "non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.\n",
      "For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only\n",
      "solved 4% of tasks, our method achieved a success rate of 74%. Code repo with all\n",
      "prompts: https://github.com/ysymyth/tree-of-thought-llm .\n",
      "1 Introduction\n",
      "Originally designed to generate text, scaled-up versions of language models (LMs) such as GPT [ 22,\n",
      "23,1,20] and PaLM [ 5] have been shown to be increasingly capable of performing an ever wider\n",
      "range of tasks requiring mathematical, symbolic, commonsense, and knowledge reasoning. It is\n",
      "perhaps surprising that underlying all this progress is still the original autoregressive mechanism for\n",
      "generating text, which makes token-level decisions one by one and in a left-to-right fashion. Is such\n",
      "a simple mechanism sufﬁcient for a LM to be built toward a general problem solver? If not, what\n",
      "problems would challenge the current paradigm, and what should be alternative mechanisms?\n",
      "The literature on human cognition provides some clues to answer these questions. Research on “dual\n",
      "process” models suggests that people have two modes in which they engage with decisions – a fast,\n",
      "automatic, unconscious mode (“System 1”) and a slow, deliberate, conscious mode (“System 2”)\n",
      "[27,28,13,12]. These two modes have previously been connected to a variety of mathematical\n",
      "models used in machine learning. For example, research on reinforcement learning in humans and\n",
      "other animals has explored the circumstances under which they engage in associative “model free”\n",
      "learning or more deliberative “model based” planning [ 6]. The simple associative token-level choices\n",
      "of LMs are also reminiscent of “System 1”, and thus might beneﬁt from augmentation by a more\n",
      "deliberate “System 2” planning process that (1) maintains and explores diverse alternatives for current\n",
      "Preprint. Under review.arXiv:2305.10601v1  [cs.CL]  17 May 2023\n",
      "GĮŔũƜ\n",
      "jũƜŔũƜGĮŔũƜ\n",
      "jũƜŔũƜʱÊʲˤGjʱæʲˤ\u001dĵÉGĮŔũƜ\n",
      "ˤjũƜŔũƜʱçʲˤ\u001dĵÉˁ\u001dʟʟʟʟaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\n",
      "ˤjũƜŔũƜʱíʲˤÉĵÉˤʱĵũŗŝʲʟʟʟʟʟʟˤˤʝˤƛĎĵũĈĎƜ)L[\u0003FRORU\u0003\u000bE\\\u0003<XTLDQ\f0DUN\u0003GLIIHUHQFH\u0003E\\\u0003FRORU\n",
      "GĮŔũƜ\n",
      "jũƜŔũƜGĮŔũƜ\n",
      "jũƜŔũƜGĮŔũƜ\n",
      "ˤjũƜŔũƜʱçʲˤòĦƙˤ\u001dĵĮŝƓŝŤòĮçƆˤƀƓƜĎˤ\u001dĵÉˤʱ\u001dĵÉˁ\u001dʲaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\n",
      "ˤjũƜŔũƜʱíʲˤÉŗòòˤĵƙˤĎĵũĈĎŤŝˤʱÉĵÉʲʟʟʟʟʟʟʟʟʟʟˤˤƛĎĵũĈĎƜ\n",
      "ʱçʲˤ\u001dĎÊđĮˤĵƙˤĎĵũĈĎƜˤŗĵĭŔƜđĮĈˤʱ\u001dĵÉʲʱÊʲˤGĮŔũƜˁjũƜŔũƜˤŗĵĭŔƜđĮĈˤʱGjʲFigure 1: Schematic illustrating various approaches to problem solving with LLMs. Each rectangle\n",
      "box represents a thought , which is a coherent language sequence that serves as an intermediate\n",
      "step toward problem solving. See concrete examples of how thoughts are generated, evaluated, and\n",
      "searched in Figures 2,4,6.\n",
      "choices instead of just picking one, and (2) evaluates its current status and actively looks ahead or\n",
      "backtracks to make more global decisions.\n",
      "To design such a planning process, we return to the origins of artiﬁcial intelligence (and cognitive\n",
      "science), drawing inspiration from the planning processes explored by Newell, Shaw, and Simon\n",
      "starting in the 1950s [ 18,19]. Newell and colleagues characterized problem solving [ 18] as search\n",
      "through a combinatorial problem space, represented as a tree. We thus propose the Tree of Thoughts\n",
      "(ToT) framework for general problem solving with language models. As Figure 1 illustrates, while\n",
      "existing methods (detailed below) sample continuous language sequences for problem solving, ToT\n",
      "actively maintains a tree of thoughts, where each thought is a coherent language sequence that serves\n",
      "as an intermediate step toward problem solving (Table 1). Such a high-level semantic unit allows the\n",
      "LM to self-evaluate the progress different intermediate thoughts make towards solving the problem\n",
      "through a deliberate reasoning process that is also instantiated in language (Figures 2,4,6). This\n",
      "implementation of search heuristics via LM self-evaluation and deliberation is novel, as previous\n",
      "search heuristics are either programmed or learned. Finally, we combine this language-based\n",
      "capability to generate and evaluate diverse thoughts with search algorithms, such as breadth-ﬁrst\n",
      "search (BFS) or depth-ﬁrst search (DFS), which allow systematic exploration of the tree of thoughts\n",
      "with lookahead and backtracking.\n",
      "Empirically, we propose three new problems that challenge existing LM inference methods even with\n",
      "the state-of-the-art language model, GPT-4 [ 20]: Game of 24, Creative Writing, and Crosswords\n",
      "(Table 1). These tasks require deductive, mathematical, commonsense, lexical reasoning abilities,\n",
      "and a way to incorporate systematic planning or search. We show ToT obtains superior results on\n",
      "all three tasks by being general and ﬂexible enough to support different levels of thoughts, different\n",
      "ways to generate and evaluate thoughts, and different search algorithms that adapt to the nature of\n",
      "different problems. We also analyze how such choices affect model performances via systematic\n",
      "ablations and discuss future directions to better train and use LMs.\n",
      "2 Background\n",
      "We ﬁrst formalize some existing methods that use large language models for problem-solving,\n",
      "which our approach is inspired by and later compared with. We use pθto denote a pre-trained LM\n",
      "with parameters θ, and lowercase letters x,y,z,s,···to denote a language sequence , i.e.x=\n",
      "(x[1],···,x[n])where eachx[i]is a token, so that pθ(x) =∏n\n",
      "i=1pθ(x[i]|x[1...i]). We use uppercase\n",
      "lettersS,···to denote a collection of language sequences.\n",
      "Input-output (IO) prompting is the most common way to turn a problem input xinto outputywith\n",
      "LM:y∼pθ(y|promptIO(x)), where promptIO(x)wraps inputxwith task instructions and/or few-\n",
      "shot input-output examples. For simplicity, let us denote pprompt\n",
      "θ(output|input ) =pθ(output|\n",
      "prompt (input )), so that IO prompting can be formulated as y∼pIO\n",
      "θ(y|x).\n",
      "2\n",
      "Chain-of-thought (CoT) prompting [35] was proposed to address cases where the mapping of\n",
      "inputxto outputyis non-trivial (e.g. when xis a math question and yis the ﬁnal numerical answer).\n",
      "The key idea is to introduce a chain of thoughtsz1,···,znto bridgexandy, where each ziis a\n",
      "coherent language sequence that serves as a meaningful intermediate step toward problem solving\n",
      "(e.g.zicould be an intermediate equation for math QA). To solve problems with CoT, each thought\n",
      "zi∼pCoT\n",
      "θ(zi|x,z1···i−1)is sampled sequentially, then the output y∼pCoT\n",
      "θ(y|x,z1···n). In\n",
      "practice, [z1···n,y]∼pCoT\n",
      "θ(z1···n,y|x)is sampled as a continuous language sequence, and the\n",
      "decomposition of thoughts (e.g. is each zia phrase, a sentence, or a paragraph) is left ambiguous.\n",
      "Self-consistency with CoT (CoT-SC) [33] is an ensemble approach that samples ki.i.d. chains\n",
      "of thought: [z(i)\n",
      "1···n,y(i)]∼pCoT\n",
      "θ(z1···n,y|x) (i= 1···k), then returns the most frequent output:\n",
      "arg maxy#{i|y(i)=y}. CoT-SC improves upon CoT, because there are generally different\n",
      "thought processes for the same problem (e.g. different ways to prove the same theorem), and the\n",
      "output decision can be more faithful by exploring a richer set of thoughts. However, within each\n",
      "chain there is no local exploration of different thought steps, and the “most frequent” heuristic only\n",
      "applies when the output space is limited (e.g. multi-choice QA).\n",
      "3 Tree of Thoughts: Deliberate Problem Solving with LM\n",
      "A genuine problem-solving process involves the repeated use of available informa-\n",
      "tion to initiate exploration, which discloses, in turn, more information until a way\n",
      "to attain the solution is ﬁnally discovered.—— Newell et al. [18]\n",
      "Research on human problem-solving suggests that people search through a combinatorial problem-\n",
      "space – a tree where the nodes represent partial solutions, and the branches correspond to operators\n",
      "that modify them [ 18,19]. Which branch to take is determined by heuristics that help to navigate the\n",
      "problem-space and guide the problem-solver towards a solution. This perspective highlights two key\n",
      "shortcomings of existing approaches that use LMs to solve general problems: 1) Locally, they do not\n",
      "explore different continuations within a thought process – the branches of the tree. 2) Globally, they\n",
      "do not incorporate any type of planning, lookahead, or backtracking to help evaluate these different\n",
      "options – the kind of heuristic-guided search that seems characteristic of human problem-solving.\n",
      "To address these shortcomings, we introduce Tree of Thoughts (ToT) , a paradigm that allows LMs to\n",
      "explore multiple reasoning paths over thoughts (Figure 1(c)). ToT frames any problem as a search\n",
      "over a tree, where each node is a states= [x,z1···i]representing a partial solution with the input and\n",
      "the sequence of thoughts so far. A speciﬁc instantiation of ToT involves answering four questions:\n",
      "1. How to decompose the intermediate process into thought steps; 2. How to generate potential\n",
      "thoughts from each state; 3. How to heuristically evaluate states; 4. What search algorithm to use.\n",
      "1. Thought decomposition. While CoT samples thoughts coherently without explicit decomposition,\n",
      "ToT leverages problem properties to design and decompose intermediate thought steps. As Table 1\n",
      "shows, depending on different problems, a thought could be a couple of words (Crosswords), a line of\n",
      "equation (Game of 24), or a whole paragraph of writing plan (Creative Writing). In general, a thought\n",
      "should be “small” enough so that LMs can generate promising and diverse samples (e.g. generating\n",
      "a whole book is usually too “big” to be coherent), yet “big” enough so that LMs can evaluate its\n",
      "prospect toward problem solving (e.g. generating one token is usually too “small” to evaluate).\n",
      "2. Thought generator G(pθ,s,k).Given a tree state s= [x,z1···i], we consider two strategies to\n",
      "generatekcandidates for the next thought step:\n",
      "(a)Sample i.i.d. thoughts from a CoT prompt (Creative Writing, Figure 4): z(j)∼\n",
      "pCoT\n",
      "θ(zi+1|s) =pCoT\n",
      "θ(zi+1|x,z1···i) (j= 1···k). This works better when the thought\n",
      "space is rich (e.g. each thought is a paragraph), and i.i.d. samples lead to diversity;\n",
      "(b)Propose thoughts sequentially using a “propose prompt” (Game of 24, Figure 2; Crosswords,\n",
      "Figure 6): [z(1),···,z(k)]∼ppropose\n",
      "θ(z(1···k)\n",
      "i+1|s). This works better when the thought\n",
      "space is more constrained (e.g. each thought is just a word or a line), so proposing different\n",
      "thoughts in the same context avoids duplication.\n",
      "3. State evaluator V(pθ,S).Given a frontier of different states, the state evaluator evaluates the\n",
      "progress they make towards solving the problem, serving as a heuristic for the search algorithm\n",
      "to determine which states to keep exploring and in which order. While heuristics are a standard\n",
      "approach to solving search problems, they are typically either programmed (e.g. DeepBlue [ 3]) or\n",
      "3\n",
      "learned (e.g. AlphaGo [ 26]). We propose a third alternative, by using the LM to deliberately reason\n",
      "about states. When applicable, such a deliberate heuristic can be more ﬂexible than programmed\n",
      "rules, and more sample-efﬁcient than learned models. Similar to the thought generator, we consider\n",
      "two strategies to evaluate states either independently or together:\n",
      "(a)Value each state independently: V(pθ,S)(s)∼pvalue\n",
      "θ(v|s)∀s∈S, where a value\n",
      "prompt reasons about the state sto generate a scalar value v(e.g. 1-10) or a classiﬁca-\n",
      "tion (e.g. sure/likely/impossible) that could be heuristically turned into a value. The basis\n",
      "of such evaluative reasoning can vary across problems and thought steps. In this work, we\n",
      "explore evaluation via few lookahead simulations (e.g. quickly conﬁrm that 5, 5, 14 can\n",
      "reach 24 via 5 + 5 + 14, or “hot l” can mean “inn” via ﬁlling “e” in “ ”) plus commonsense\n",
      "(e.g. 1 2 3 are too small to reach 24, or no word can start with “tzxc”). While the former\n",
      "might promote “good” states, the latter could help eliminate “bad” states. Such valuations\n",
      "do not need to be perfect, and only need to be approximately\n",
      "(b)Vote across states: V(pθ,S)(s) =1[s=s∗], where a “good” state s∗∼pvote\n",
      "θ(s∗|S)is\n",
      "voted out based on deliberately comparing different states in Sin a vote prompt. When\n",
      "problem success is harder to directly value (e.g. passage coherency), it is natural to to instead\n",
      "compare different partial solutions and vote for the most promising one. This is similar\n",
      "in spirit to a “step-wise” self-consistency strategy, i.e. cast “which state to explore” as a\n",
      "multi-choice QA, and use LM samples to vote for it.\n",
      "For both strategies, we could prompt the LM multiple times to aggregate the value or vote results to\n",
      "trade time/resource/cost for more faithful/robust heuristics.\n",
      "Algorithm 1 ToT-BFS(x,pθ,G,k,V,T,b )\n",
      "Require: Inputx, LMpθ, thought generator G()\n",
      "& size limitk, states evaluator V(), step limitT,\n",
      "breadth limit b.\n",
      "S0←{x}\n",
      "fort= 1,···,Tdo\n",
      "S′\n",
      "t←{[s,z]|s∈St−1,zt∈G(pθ,s,k)}\n",
      "Vt←V(pθ,S′\n",
      "t)\n",
      "St←arg maxS⊂S′\n",
      "t,|S|=b∑\n",
      "s∈SVt(s)\n",
      "end for\n",
      "returnG(pθ,arg maxs∈STVT(s),1)Algorithm 2 ToT-DFS(s,t,pθ,G,k,V,T,v th)\n",
      "Require: Current state s, stept, LMpθ, thought\n",
      "generatorG()and size limit k, states evaluator\n",
      "V(), step limitT, thresholdvth\n",
      "ift>T then record output G(pθ,s,1)\n",
      "end if\n",
      "fors′∈G(pθ,s,k)do⊿sorted candidates\n",
      "ifV(pθ,{s′})(s)>vthres then⊿pruning\n",
      "DFS(s′,t+ 1)\n",
      "end if\n",
      "end for\n",
      "4. Search algorithm. Finally, within the ToT framework, one can plug and play different search\n",
      "algorithms depending on the tree structure. We explore two relatively simple search algorithms and\n",
      "leave more advanced ones (e.g. A* [9], MCTS [2]) for future work:\n",
      "(a)Breadth-ﬁrst search (BFS) (Algorithm 1) maintains a set of the bmost promising states\n",
      "per step. This is used for Game of 24 and Creative Writing where the tree depth is limit\n",
      "(T≤3), and initial thought steps can be evaluated and pruned to a small set ( b≤5).\n",
      "(b)Depth-ﬁrst search (DFS) (Algorithm 2) explores the most promising state ﬁrst, until the\n",
      "ﬁnal output is reached ( t > T ), or the state evaluator deems it impossible to solve the\n",
      "problem from the current s(V(pθ,{s})(s)≤vthfor a value threshold vth). In the latter\n",
      "case, the subtree from sispruned to trade exploration for exploitation. In both cases, DFS\n",
      "backtracks to the parent state of sto continue exploration.\n",
      "Conceptually, ToT has several beneﬁts as a method for general problem-solving with LMs: (1) Gener-\n",
      "ality. IO, CoT, CoT-SC, and self-reﬁnement can be seen as special cases of ToT (i.e. trees of limited\n",
      "depth and breadth; Figure 1). (2) Modularity. The base LM, as well as the thought decomposition,\n",
      "generation, evaluation, and search procedures can all be varied independently. (3) Adaptability .\n",
      "Different problem properties, LM capabilities, and resource constraints can be accommodated. (4)\n",
      "Convenience. No extra training is needed, just a pre-trained LM is sufﬁcient. The next section will\n",
      "show how these conceptual beneﬁts translate to strong empirical performance in different problems.\n",
      "4 Experiments\n",
      "We propose three tasks that are hard even when sampling from the state-of-the-art language model,\n",
      "GPT-4 [ 20], using standard IO prompting or chain-of-thought (CoT) prompting. We show how\n",
      "4\n",
      "Game of 24 Creative Writing 5x5 Crosswords\n",
      "Input 4 numbers (4 9 10 13) 4 random sentences 10 clues (h1. presented;..)\n",
      "Output An equation to reach 24\n",
      "(13-9)*(10-4)=24A passage of 4 paragraphs\n",
      "ending in the 4 sentences5x5 letters: SHOWN;\n",
      "WIRRA; A V AIL; ...\n",
      "Thoughts 3 intermediate equations\n",
      "(13-9=4 (left 4,4,10); 10-\n",
      "4=6 (left 4,6); 4*6=24)A short writing plan\n",
      "(1. Introduce a book that\n",
      "connects...)Words to ﬁll in for clues:\n",
      "(h1. shown; v5. naled; ...)\n",
      "#ToT steps 3 1 5-10 (variable)\n",
      "Table 1: Task overview. Input, output, thought examples are in blue.\n",
      "deliberate search in trees of thoughts (ToT) produces better results, and more importantly, interesting\n",
      "and promising new ways to use language models to solve problems requiring search or planning.\n",
      "Unless otherwise stated, we perform experiments using a Chat Completion mode GPT-41with a\n",
      "sampling temperature of 0.7.\n",
      "4.1 Game of 24\n",
      "Game of 24 is a mathematical reasoning challenge, where the goal is to use 4 numbers and basic\n",
      "arithmetic operations (+-*/) to obtain 24. For example, given input “4 9 10 13”, a solution output\n",
      "could be “(10 - 4) * (13 - 9) = 24”.\n",
      "ʳĵĮòˤòƅÊĭŔĦòʴˤGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀĵŝŝđæĦòˤĮòƅƜˤŝŤòŔŝʝˤˤˤ3URSRVH\u00033URPSWʁˤ̌ˤʆˤ̐ˤɾʀˤʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˤˊˤʁˤ̐ˤʃˤʱĦòƙƜʝˤʃˤʆˤɾʀʲʳʛʛʛĭĵŗòˤĦđĮòŝʟʴ7KRXJKW\u0003*HQHUDWLRQ/0)ſÊĦũÊŤòˤđƙˤĈƓſòĮˤĮũĭæòŗŝˤçÊĮˤŗòÊçĎˤɿʁˤʱŝũŗòʫĦđģòĦƆʫđĭŔĵŝŝđæĦòʲɾɽˤɾʁʝˤɾɽˤ̌ˤɾʁˤ̐ˤɿʁʛˤŝũŗòʳĭĵŗòˤòƅÊĭŔĦòŝʴɾɽˤɾʀˤɾʀ9DOXH\u00033URPSWʱɾʀˤˊˤɾɽʲˤʦˤɾʀˤ̐ˤʀˤʦˤɾʀˤ̐ˤʀʆɾɽˤ̌ˤɾʀˤ̌ˤɾʀˤ̐ˤʀʃĎòŗòˤƓŝˤĮĵˤƀÊƆˤƘĵˤĵæŤÊđĮˤɿʁˤƀƓƜĎˤƛĎòŝòˤĮũĭæòŗŝʛˤđĭŔĵŝŝđæĦò7KRXJKW\u0003(YDOXDWLRQʱæʲʱçʲ/0GĮŔũƜʝˤʁˤʆˤɾɽˤɾʀʁ̌ʆ̐ɾʀʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˁʁ̐ʃʱĦòƙƜʝˤʃˤʆˤɾʀʲʟʟɾʀˁʃ̐ʄʱĦòƙƜʝˤʄˤʆʲɾʀˁʆ̐ʁʱĦòƙƜʝˤʁˤʃʲʟʟʁʦʃ̐ɿʁʱĦòƙƜʝˤɿʁʲʁ̌ʃ̐ɾɽʱĦòƙƜʝˤɾɽʲʟʟʱÊʲ\n",
      "ʳĵĮòˤòƅÊĭŔĦòʴˤGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀĵŝŝđæĦòˤĮòƅƜˤŝŤòŔŝʝˤˤˤ\u000bD\f\u00033URSRVH\u00033URPSWʁˤ̌ˤʆˤ̐ˤɾʀˤʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˤˊˤʁˤ̐ˤʃˤʱĦòƙƜʝˤʃˤʆˤɾʀʲʳʛʛʛĭĵŗòˤĦđĮòŝʟʴ7KRXJKW\u0003*HQHUDWLRQ/0)ſÊĦũÊŤòˤđƙˤĈƓſòĮˤĮũĭæòŗŝˤçÊĮˤŗòÊçĎˤɿʁˤʱŝũŗòʫĦđģòĦƆʫđĭŔĵŝŝđæĦòʲɾɽˤɾʁʝˤɾɽˤ̌ˤɾʁˤ̐ˤɿʁʛˤŝũŗòʳĭĵŗòˤòƅÊĭŔĦòŝʴɾɽˤɾʀˤɾʀ\u000bE\f\u00039DOXH\u00033URPSWʱɾʀˤˊˤɾɽʲˤʦˤɾʀˤ̐ˤʀˤʦˤɾʀˤ̐ˤʀʆɾɽˤ̌ˤɾʀˤ̌ˤɾʀˤ̐ˤʀʃˤĎòŗòˤƓŝˤĮĵˤƀÊƆˤƘĵˤĵæŤÊđĮˤɿʁˤƀƓƜĎˤƛĎòŝòˤæƓĈˤĮũĭæòŗŝʛˤđĭŔĵŝŝđæĦò7KRXJKW\u0003(YDOXDWLRQ/0GĮŔũƜʝˤʁˤʆˤɾɽˤɾʀʁ̌ʆ̐ɾʀʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˁʁ̐ʃʱĦòƙƜʝˤʃˤʆˤɾʀʲʟʟɾʀˁʃ̐ʄʱĦòƙƜʝˤʄˤʆʲɾʀˁʆ̐ʁʱĦòƙƜʝˤʁˤʃʲʟʟʁʦʃ̐ɿʁʱĦòƙƜʝˤɿʁʲʁ̌ʃ̐ɾɽʱĦòƙƜʝˤɾɽʲʟʟ)L[\u0003FRORU\u0003\u000bE\\\u0003<XTLDQ\f0DUN\u0003GLII\u0003SURPSW\u0003ZLWK\u0003FRORU\n",
      "Figure 2: ToT in a game of 24. The LM is prompted for (a) thought generation and (b) valuation.\n",
      "Task Setup. We scrape data from 4nums.com, which has 1,362 games that are sorted from easy to\n",
      "hard by human solving time, and use a subset of relatively hard games indexed 901-1,000 for testing.\n",
      "For each task, we consider the output as success if it is a valid equation that equals 24 and uses the\n",
      "input numbers each exactly once. We report the success rate across 100 games as the metric.\n",
      "Baselines. We use a standard input-output (IO) prompt with 5 in-context examples. For chain-of-\n",
      "thought (CoT) prompting, we augment each input-output pair with 3 intermediate equations, each\n",
      "operating on two remaining numbers. For example, given input “4 9 10 13”, the thoughts could be\n",
      "“13 - 9 = 4 (left: 4 4 10); 10 - 4 = 6 (left: 4 6); 4 * 6 = 24 (left: 24)”. For each game, we sample IO\n",
      "and CoT prompting for 100 times for average performance. We also consider a CoT self-consistency\n",
      "baseline, which takes the majority output from 100 CoT samples, and an iterative-reﬁne approach on\n",
      "top of an IO sample for at most 10iterations. At each iteration, the LM is conditioned on all previous\n",
      "history to “reﬂect on your mistakes and generate a reﬁned answer” if the output is incorrect. Note\n",
      "that it uses groundtruth feedback signals about equation correctness.\n",
      "ToT Setup. To frame Game of 24 into ToT, it is natural to decompose the thoughts into 3 steps,\n",
      "each an intermediate equation. As shown in Figure 2(a), at each tree node, we exact the “left”\n",
      "numbers and prompt the LM to propose some possible next steps. The same “propose prompt” is\n",
      "used for all 3 thought steps, though it only has one example with 4 input numbers. We perform a\n",
      "breadth-ﬁrst search (BFS) in ToT, where at each step we keep the best b= 5candidates. To perform\n",
      "deliberate BFS in ToT, as shown in Figure 2(b), we prompt LM to evaluate each thought candidate as\n",
      "“sure/maybe/impossible” with regard to reaching 24. The aim is to promote correct partial solutions\n",
      "that can be verdicted within few lookahead trials, and eliminate impossible partial solutions based on\n",
      "“too big/small” commonsense, and keep the rest “maybe”. We sample values 3times for each thought.\n",
      "1Experiments were done between May 5-16, 2023.\n",
      "5\n",
      "Method Success\n",
      "IO prompt 7.3%\n",
      "CoT prompt 4.0%\n",
      "CoT-SC (k=100) 9.0%\n",
      "ToT (ours) (b=1) 45%\n",
      "ToT (ours) (b=5) 74%\n",
      "IO + Reﬁne (k=10) 27%\n",
      "IO(best of 100) 33%\n",
      "CoT (best of 100) 49%\n",
      "Table 2: Game of 24 Results.\n",
      "0 25 50 75 1000.20.40.6(a) Success rate with nodes visited\n",
      "IO (best of k)\n",
      "CoT (best of k)\n",
      "ToT (b=1...5)\n",
      "1 2 3 4Correct0.00.20.40.6(b) Samples failed at each step\n",
      "CoT\n",
      "ToT (b=5) Figure 3: Game of 24 (a) scale analysis & (b) error analysis.\n",
      "Results. As shown in Table 2, IO, CoT, and CoT-SC prompting methods perform badly on the task,\n",
      "achieving only 7.3%, 4.0%, and 9.0% success rates. In contrast, ToT with a breadth of b= 1already\n",
      "achieves a success rate of 45%, whileb= 5 achieves 74%. We also consider an oracle setup for\n",
      "IO/CoT, by calculating the success rate using best of ksamples (1≤k≤100) . To compare IO/CoT\n",
      "(best of k) with ToT, we consider calculating the tree nodes visited per task in ToT across b= 1···5,\n",
      "and map the 5 success rates in Figure 3(a), treating IO/CoT (best of k) as visitingknodes in a bandit.\n",
      "Not surprisingly, CoT scales better than IO, and best of 100 CoT samples achieve a success rate of\n",
      "49%, but still much worse than exploring more nodes in ToT ( b>1).\n",
      "Error Analysis. Figure 3(b) breaks down at which step CoT and ToT samples fail the task, i.e. the\n",
      "thought (in CoT) or all bthoughts (in ToT) are invalid or impossible to reach 24. Notably, around\n",
      "60% of CoT samples already failed the task after generating the ﬁrst step, or equivalently, the ﬁrst\n",
      "three words (e.g. “ 4 + 9 ”). This highlights the issues with direct left-to-right decoding.\n",
      "4.2 Creative writing\n",
      "Next, we invent a creative writing task where the input is 4 random sentences and the output should\n",
      "be a coherent passage with 4 paragraphs that end in the 4 input sentences respectively. Such a task is\n",
      "open-ended and exploratory, and challenges creative thinking as well as high-level planning.\n",
      "Task setup. We sample random sentences from randomwordgenerator.com to form 100 inputs, and\n",
      "there is no groundtruth passage for each input constraint. As we ﬁnd that GPT-4 can follow the\n",
      "input constraints most of the time, we focus on evaluating passage coherency in two ways: using a\n",
      "GPT-4 zero-shot prompt to provide a 1-10 scalar score, or using human judgments to compare pairs\n",
      "of outputs from different methods. For the former, we sample 5 scores and average them for each task\n",
      "output, and we ﬁnd these 5 scores usually consistent, with a standard deviation of around 0.56on\n",
      "average across outputs. For the latter, we employ a subset of the authors in a blind study to compare\n",
      "the coherency of CoT vs. ToT generated passage pairs, where the order of passages is random ﬂipped\n",
      "over 100 inputs.\n",
      "Baselines. Given the creative nature of the task, both IO and CoT prompts are zero-shot. While the\n",
      "former prompts the LM to directly generate a coherent passage given input constraints, the latter\n",
      "prompts the LM to ﬁrst make a brief plan then write the passage, i.e. the plan serves as the intermediate\n",
      "thought step. We generate 10 IO and CoT samples per task. We also consider an iterative-reﬁne\n",
      "(k≤5) method on top of a random IO sample for each task, where the LM is conditioned on input\n",
      "constraints and the last generated passage to decide if the passage is already “perfectly coherent”,\n",
      "and if not generate a reﬁned one.\n",
      "ToT setup. We build a ToT with depth 2 (and only 1 intermediate thought step) — the LM ﬁrst\n",
      "generatesk= 5plans and votes for the best one (Figure 4), then similarly generate k= 5passages\n",
      "based on the best plan then vote for the best one. Here the breadth limit b= 1, as only one choice is\n",
      "kept per step. A simple zero-shot vote prompt (“analyze choices below, then conclude which is most\n",
      "promising for the instruction”) is used to sample 5 votes at both steps.\n",
      "Results. Figure 5(a) shows average GPT-4 scores across 100 tasks, where ToT (7.56) is deemed to\n",
      "generate more coherent passages than IO (6.19) and CoT (6.93) on average. While such an automatic\n",
      "metric might be noisy, Figure 5(b) conﬁrms the ﬁnding by showing that humans prefer ToT over\n",
      "CoT in 41 out of 100 passage pairs, while only prefer CoT over ToT in 21 (other 38 pairs are found\n",
      "“similarly coherent”). Lastly, iterative-reﬁne is more effective on this natural language task, where\n",
      "6\n",
      "µŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\u001dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤĦÊĮŝʱʀˤĭĵŗòˤĵĭƓƜŤòíʲʱçʲˤ´ĵŤòŝ\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱɽʫʂˤſĵŤòŝʲ\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱʀʫʂˤſĵŤòŝʲʟɾɿGĮŔũƜĦÊĮˤɾĦÊĮˤɿʟʟÊŝŝÊĈòɾÊŝŝÊĈòɿʟʟ)L[\u0003FRORU\u0003\u000bE\\\u0003<XTLDQ\fµŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\u001dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤĦÊĮŝʱçʲˤ´ĵŤòŝ\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛGĮŔũƜĦÊĮˤɾˤĦÊĮˤɿˤˤʟʟÊŝŝÊĈòɾÊŝŝÊĈòɿʟʟɽʫʂˤſĵŤòŝĦÊĮˤɾˤˤˤʟʛʟʛɾʟʛɿʟʟʀʫʂˤſĵŤòŝĦÊĮˤʀˁʂˤˤˤ8VH\u0003UHG\u0012JUHHQ\u0003WR\u0003VKRZ\u0003ILQDO\u0003FKRLFH\n",
      "ĮʫʂˤſĵŤòŝĦÊĮˤɿˤˤˤ\n",
      "\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\u0001ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\u001dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\u001dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛFigure 4: A step of deliberate search in a randomly picked Creative Writing task. Given the input, the\n",
      "LM samples 5 different plans, then votes 5 times to decide which plan is best. The majority choice is\n",
      "used to consequently write the output passage with the same sample-vote procedure.\n",
      "IO CoT ToT IO\n",
      "+refineToT\n",
      "+refine468\n",
      "(a) GPT-4 coherency scores\n",
      "CoT > ToT Similar ToT > CoT010203040\n",
      "213841(b) Human coherency comparison\n",
      "Figure 5: Creative Writing results.Method Success Rate (%)\n",
      "Letter Word Game\n",
      "IO 38.7 14 0\n",
      "CoT 40.6 15.6 1\n",
      "ToT (ours) 78 60 20\n",
      "+best state 82.4 67.5 35\n",
      "-prune 65.4 41.5 5\n",
      "-backtrack 54.6 20 5\n",
      "Table 3: Mini Crosswords results.\n",
      "it improves IO coherency score from 6.19 to 7.67, and ToT coherency score from 7.56 to 7.91. We\n",
      "believe it could be thought of as a third approach to thought generation in the ToT framework, where\n",
      "new thoughts can arise from reﬁning old thoughts instead of i.i.d. or sequentially generated.\n",
      "4.3 Mini Crosswords\n",
      "In Game of 24 and Creative Writing, ToT is relatively shallow — at most 3 thought steps are needed\n",
      "to reach the ﬁnal output. Here we explore 5×5mini crosswords as a harder search problem involving\n",
      "natural language. Again, the goal is not just to solve the task, as more general crosswords can be\n",
      "readily solved with specialized NLP pipelines [ 31] that leverages large-scale retrieval instead of LM.\n",
      "Rather, we aim to explore the limit of LM as a general problem solver that explores its own thoughts\n",
      "and guides its own exploration with deliberate reasoning as heuristics.\n",
      "Task Setup. We scrape data from GooBix, which contains 156 games of 5×5mini crosswords. As\n",
      "we observe adjacent games contain similar clues, we use 20 games with indices 1,6,···,91,96for\n",
      "testing, and games 136,141,146,151,156for prompting. For each task, the input describes the 5\n",
      "horizontal clues and 5 vertical clues, and the output should be a board of 5×5 = 25 letters to solve\n",
      "the crosswords. For evaluation, we consider three levels of success: the portion of correct letters (25\n",
      "per game), words (10 per game), and games.\n",
      "Baselines. We provide 5 example input-output pairs in the IO prompt, and in the CoT prompt\n",
      "additionally include intermediate words in the order h1..5 then v1..5. We run each prompt for 10\n",
      "samples and average the results.\n",
      "ToT Setup. We leverage a depth-ﬁrst search (Algorithm 2) that keeps exploring the most promising\n",
      "subsequent word clue until the state is no longer promising, then backtrack to the parent state to\n",
      "explore alternative thoughts. To make search tractable, subsequent thoughts are constrained not to\n",
      "change any ﬁlled words or letters, so that the ToT has at most 10 intermediate steps. For thought\n",
      "generation, at each state we translate all existing thoughts (e.g. “h2.motor; h1.tasks” for the state\n",
      "in Figure 6(a)) into letter constraints for remaining clues (e.g. “v1.To heap: tm ;...”) and prompt\n",
      "a proposal prompt 5times to come up with candidates for where and what to ﬁll in the next word.\n",
      "Importantly, we also prompt the LM to give a conﬁdence level for different thoughts, and aggregate\n",
      "7\n",
      ">\u000b\n",
      "Y\u0016\u0011\u0003HORSH\n",
      "\u000f\u0003\u0016\u0011\u0015\f\u000f\u0003\u000b\n",
      "K\u0015\u0011\u0003YDOXH\n",
      "\u000f\u0003\u0015\u0011\u0013\f\u000f\u0003\u000b\n",
      "K\u0014\u0011\u0003SDUFK\n",
      "\u000f\u0003\u0014\u0011\u001c\f\u000f\u0003\u000b\n",
      "Y\u0018\u0011\u0003FRYHW\n",
      "\u000f\u0003\u0013\u0011\u0019\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0014\f\u000f\u0003\u000b\n",
      "K\u0015\u0011\u0003PHULW\n",
      "\u000f\u0003\u0013\u0011\u0017\f\u000f\u0003\u000b\n",
      "Y\u0014\u0011\u0003DOORZ\n",
      "\u000f\u0003\u0013\u0011\u0015\f\u000f\u0003\u000b\n",
      "Y\u0015\u0011\u0003JULQG\n",
      "\u000f\u0003\u0013\u0011\u0014\f\u000f\u0003\u000b\n",
      "K\u0017\u0011\u0003OHSHU\n",
      "\u000f\u0003\u0013\u0011\u0014\f@\n",
      "Y\u0016\u0011\u0003HORSH\n",
      "0XOWLSOH\u0003UXQV3DUVH\u000f\u0003ILOWHU\u0003RXW\u0003QRQ\u0010ILYH\u0010OHWWHU\u000f\u0003VFRUH\u000f\u0003DJJUHJDWH\n",
      "&KRRVH\u0003\u000bVRIW\u0003VHOI\u0010FRQVLVWHQF\\\"\f\u0014\u00110D[\u0015\u00110D[\u0003ZLWKRXW\u0003YLRODWH\u0016\u0011')6\n",
      "GĮŔũƜˤ\u001dĦũòŝĎɿʛĭĵŤĵŗĎɾʛƘÊŝģŝĎʁʛŝÊĦĵĮƘÊŝģŝƘÊŝģŝ\n",
      "ĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\u00033URSRVDOVÊĈĈŗòĈÊŤòſʀʛˤŗòŤòĮƜƓĵũŝʞˤƚĦĵƀòŗƆʝˤˈˈˈˈˈˤŝũŗò6WDWH\u0003(YDOXDWRU\u0003\u000bRYHU\u0003HDFK\u0003FOXH\fſɾʛˤÉĵˤĎòÊŔʝˤƛĭˈŝˈˤʳʛʛʛʴˤđĭŔĵŝŝđæĦòſʂʛˤ#òŝƓççÊŤĵŗʞˤĭĵŗòˤíŗƆʝˤŝŗˈĮˈˤʳʛʛʛʴˤĭÊƆæòʟʟʱæÊçģƜŗÊçģʲĎʀʛĈŗÊĮíʟʟʱŝũæƜŗòòˤŔŗũĮòíʲĎʁʛˤŝÊĦĵĮĎʀʛˤĈŗÊĮíſʀʛˤŝƜŗđĮĈʟʟ')6\u00032UGHUĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\u00033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\u00033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\u00033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\u00033URSRVDOVʱÊʲʱæʲƛˤÊˤŝˤģˤŝĭˤĵˤƛˤĵˤŗˈˤˈˤˈˤˈˤˈŝˤÊˤĦˤĵˤĮˈˤˈˤˈˤˈˤˈFigure 6: In Mini Crosswords, (a) how thoughts are proposed and aggregated in a priority queue\n",
      "for depth-ﬁrst search (DFS), and (b) how a state is evaluated based on the possibility of ﬁlling in\n",
      "each remaining word clue, and pruned if any remaining clue is deemed not possible to ﬁll by the LM.\n",
      "Then DFS backtracks to the parent state and explore the next promising thought for clue.\n",
      "these across proposals to obtain a sorted list of next thoughts to explore (Figure 6(a)). For state\n",
      "evaluations, we similarly translate each state into letter constraints for remaining clues, then evaluate\n",
      "for each clue if it is possible to ﬁll given the constraints. If any remaining clue is deemed “impossible”\n",
      "to ﬁll in (e.g. “v1. To heap: tm s”), then the exploration of the state’s subtree is pruned and DFS\n",
      "backtracks to its parent to explore the next promising thought. We limit DFS search steps to 100, and\n",
      "simply render the deepest explored state (the ﬁrst explored one if multiple) into the ﬁnal output.\n",
      "Results. As shown in Table 3, IO and CoT prompting methods perform poorly with a word-level\n",
      "success rate less than 16%, while ToT signiﬁcantly improves all metrics, achieving a word-level\n",
      "success rate of 60% and solving 4 out of 20 games. Such an improvement is not surprising, given IO\n",
      "and CoT lack mechanisms to try different clues, make changes to decisions, or backtrack.\n",
      "Oracle and ablation studies. When outputting from the oracle best DFS state (instead of the\n",
      "heuristically determined best state) per task, ToT performance is even higher and actually solves\n",
      "7/20 games (Table 3, “+best state”), indicating our simple output heuristics can be readily improved.\n",
      "Interestingly, sometimes when the crosswords game is actually solved, the state evaluator might still\n",
      "deem some words as “impossible” and prune — possibly because 5×5crosswords by design have\n",
      "some rare or obselete words that GPT-4 cannot recognize2. Given the state evaluation as a pruning\n",
      "heuristic is imperfect, we also explore ablating the pruning, and ﬁnd the performance generally worse\n",
      "(Table 3, “-prune”). However, it could actually ﬁnd the correct solution for 4/20 games (though only\n",
      "outputting 1 via heuristic), 3 of which are games ToT+pruning cannot solve within 100 steps. Thus,\n",
      "better heuristics for DFS pruning are critical for problem solving in this case. Lastly, we conﬁrm the\n",
      "importance of backtracking by running an ablation that keeps ﬁlling the most promising clue for at\n",
      "most 20 steps, allowing overwrites. This is similar to a “greedy” BFS search with breadth limit of\n",
      "b= 1, and performs poorly with a word level success of only 20% (Table 3, “-backtrack”).\n",
      "5 Related Work\n",
      "Planning and decision making. Smart planning and decision making are critical to achieving\n",
      "predeﬁned goals. As they are trained on vast amount of world knowledge and human examples, LMs\n",
      "are known to have already absorbed rich commonsense that makes it possible to propose reasonable\n",
      "plans conditioned on problem setting and environmental states [ 10,39,34,11,32,38,37]. Our\n",
      "proposed Tree-of-Thought approach extends existing planning formulations by considering multiple\n",
      "potentially feasible plans simultaneously at each problem-solving step, and proceeding with the most\n",
      "promising ones. The integration between thought sampling and value feedback organically integrates\n",
      "planning and decision-making mechanisms, enabling effective search inside a solution tree. On the\n",
      "other hand, traditional decision-making procedures usually require training dedicated reward and\n",
      "policy models as in reinforcement learning (for example CHAI [ 30]), whereas we use the LM itself\n",
      "to provide the value estimates for decision making.\n",
      "2For example, “agend” is an obsolete form of “agendum”, but GPT-4 deems it a typo for “agenda”. External\n",
      "retrieval or web interaction could augment LM for problem solving under knowledge uncertainty.\n",
      "8\n",
      "Self-reﬂection. Using LLMs to assess the viability of their own predictions is becoming an in-\n",
      "creasingly important procedure in problem solving. [ 25,17,21] introduced the “self-reﬂection”\n",
      "mechanism, in which LMs provide feedback to their generation candidates. [ 4] improves LMs code\n",
      "generation accuracy by injecting feedback messages generated by the LM itself based on its code\n",
      "execution results. Similarly, [ 14] also introduces “critic” or review steps over the actions and states,\n",
      "deciding the next action to take in solving computer operation tasks. Another recent work very\n",
      "relevant to ours is “self-eval guided decoding” [ 36]. Similar to our method, self-eval decoding\n",
      "also follows a tree-search procedure with leaves sampled from stochastic beam search decoding,\n",
      "which are then evaluated by LLM itself with carefully prepared self-eval prompts. Their approach\n",
      "however, uses the PAL formulation [ 7] which represents thoughts as codes, which makes it difﬁcult\n",
      "to tackle challenging tasks like creative writing which we consider in this paper. Our Tree-of-Thought\n",
      "formulation is thus more versatile and handles challenging tasks on which GPT-4 only achieves very\n",
      "low accuracy with standard prompts.\n",
      "Program-guided LLM generation. Our proposal is also related to recent advancements that or-\n",
      "ganize LM’s behavior with symbolic program guidance. For example [ 24] embeds LMs in an\n",
      "algorithmic search procedure to help solve problems like question answering step-by-step, in which\n",
      "the search trees are expanded by relevant paragraphs that might provide answers. This approach\n",
      "however differs from ours in that trees are expanded by sampling external paragraphs instead of the\n",
      "LM’s own thoughts, and there is no reﬂection or voting steps. Another approach, LLM+P [ 15], goes\n",
      "one step further and delegates the actual planning process to a classical planner.\n",
      "Classical search methods. Last but not least, our approach can be treated as a modern rendition\n",
      "of classical search methods for problem solving. For example it can be considered as a heuristic\n",
      "search algorithm like A* [ 8], in which the heuristic at each search node is provided by the LM’s\n",
      "self-assessment. From this perspective, our method is also related to NeuroLogic A*esque decoding\n",
      "proposed in [ 16], which is inspired by A* search but introduces look-ahead heuristics that are\n",
      "efﬁcient for LMs to improve the beam-search or top-k sampling decoding. This method however is\n",
      "constrained to sentence generation tasks, whereas our framework are designed for complex, multi-step\n",
      "problem solving guarded by value feedback.\n",
      "6 Discussion\n",
      "Limitations and future directions. Deliberate search such as ToT might not be necessary for\n",
      "many existing tasks that GPT-4 already excels at, and as an initial step this work only explores\n",
      "three relatively simple tasks that challenges GPT-4 and calls of better search and planning abilities\n",
      "incorporated with LMs. However, as we begin to deploy LMs for more real-world decision making\n",
      "applications (e.g. coding, data analysis, robotics, etc.), more complex tasks could emerge and present\n",
      "new opportunities to study these research questions. Also, search methods like ToT requires more\n",
      "resources (e.g. GPT-4 API cost) than sampling methods in order to improve task performances,\n",
      "but the modular ﬂexibility of ToT allows users to customize such performance-cost tradeoffs, and\n",
      "ongoing open-source efforts [ 29] should readily reduce such costs in the near future. Lastly, this work\n",
      "focuses on using an off-the-shelf LM, and ﬁne-tuning LMs using a ToT-style high-level counterfactual\n",
      "decision making (e.g. deliberating over potential choices for the next paragraph, instead of predicting\n",
      "the next token) might present opportunities to enhance the problem-solving capabilities of LMs.\n",
      "Broader impact. ToT is a framework that empowers LMs to more autonomously and intelligently\n",
      "make decisions and solve problems. While current tasks are limited to reasoning and search problems,\n",
      "future applications involving interaction with external environments or humans could bring potential\n",
      "danger, e.g. facilitating harmful uses of LMs. On the other hand, ToT also improves the interpretability\n",
      "of model decisions and the opportunity for human alignment, as the resulting representations are\n",
      "readable, high-level language reasoning instead of implicit, low-level token values.\n",
      "Conclusion. The associative “System 1” of LMs can be beneﬁcially augmented by a “System 2”\n",
      "based on searching a tree of possible paths to the solution to a problem. The Tree of Thoughts\n",
      "framework provides a way to translate classical insights about problem-solving into actionable\n",
      "methods for contemporary LMs. At the same time, LMs address a weakness of these classical\n",
      "methods, providing a way to solve complex problems that are not easily formalized, such as creative\n",
      "writing. We see this intersection of LMs with classical approaches to AI as an exciting direction for\n",
      "future work.\n",
      "9\n",
      "References\n",
      "[1]T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,\n",
      "G. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural\n",
      "information processing systems , 33:1877–1901, 2020.\n",
      "[2]C. Browne, E. J. Powley, D. Whitehouse, S. M. M. Lucas, P. I. Cowling, P. Rohlfshagen,\n",
      "S. Tavener, D. P. Liebana, S. Samothrakis, and S. Colton. A survey of monte carlo tree search\n",
      "methods. IEEE Transactions on Computational Intelligence and AI in Games , 4:1–43, 2012.\n",
      "[3]M. Campbell, A. J. Hoane Jr, and F.-h. Hsu. Deep blue. Artiﬁcial intelligence , 134(1-2):57–83,\n",
      "2002.\n",
      "[4]X. Chen, M. Lin, N. Sch ¨arli, and D. Zhou. Teaching large language models to self-debug, 2023.\n",
      "[5]A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W.\n",
      "Chung, C. Sutton, S. Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv\n",
      "preprint arXiv:2204.02311 , 2022.\n",
      "[6]N. D. Daw, Y . Niv, and P. Dayan. Uncertainty-based competition between prefrontal and\n",
      "dorsolateral striatal systems for behavioral control. Nature neuroscience , 8(12):1704–1711,\n",
      "2005.\n",
      "[7]L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y . Yang, J. Callan, and G. Neubig. Pal: Program-\n",
      "aided language models, 2023.\n",
      "[8]P. E. Hart, N. J. Nilsson, and B. Raphael. A formal basis for the heuristic determination of\n",
      "minimum cost paths. IEEE Transactions on Systems Science and Cybernetics , 4(2):100–107,\n",
      "1968. doi: 10.1109/TSSC.1968.300136.\n",
      "[9]P. E. Hart, N. J. Nilsson, and B. Raphael. A formal basis for the heuristic determination of\n",
      "minimum cost paths. IEEE transactions on Systems Science and Cybernetics , 4(2):100–107,\n",
      "1968.\n",
      "[10] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch. Language models as zero-shot planners:\n",
      "Extracting actionable knowledge for embodied agents, 2022.\n",
      "[11] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch,\n",
      "Y . Chebotar, et al. Inner monologue: Embodied reasoning through planning with language\n",
      "models. arXiv preprint arXiv:2207.05608 , 2022.\n",
      "[12] D. Kahneman. Thinking, fast and slow . Macmillan, 2011.\n",
      "[13] D. Kahneman, S. Frederick, et al. Representativeness revisited: Attribute substitution in intuitive\n",
      "judgment. Heuristics and biases: The psychology of intuitive judgment , 49(49-81):74, 2002.\n",
      "[14] G. Kim, P. Baldi, and S. McAleer. Language models can solve computer tasks, 2023.\n",
      "[15] B. Liu, Y . Jiang, X. Zhang, Q. Liu, S. Zhang, J. Biswas, and P. Stone. Llm+p: Empowering\n",
      "large language models with optimal planning proﬁciency, 2023.\n",
      "[16] X. Lu, S. Welleck, P. West, L. Jiang, J. Kasai, D. Khashabi, R. L. Bras, L. Qin, Y . Yu,\n",
      "R. Zellers, N. A. Smith, and Y . Choi. Neurologic a*esque decoding: Constrained text generation\n",
      "with lookahead heuristics. In North American Chapter of the Association for Computational\n",
      "Linguistics , 2021.\n",
      "[17] A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe, U. Alon, N. Dziri,\n",
      "S. Prabhumoye, Y . Yang, S. Welleck, B. P. Majumder, S. Gupta, A. Yazdanbakhsh, and P. Clark.\n",
      "Self-reﬁne: Iterative reﬁnement with self-feedback, 2023.\n",
      "[18] A. Newell, J. C. Shaw, and H. A. Simon. Report on a general problem solving program. In IFIP\n",
      "congress , volume 256, page 64. Pittsburgh, PA, 1959.\n",
      "[19] A. Newell, H. A. Simon, et al. Human problem solving . Prentice-Hall, 1972.\n",
      "10\n",
      "[20] OpenAI. Gpt-4 technical report. ArXiv , abs/2303.08774, 2023.\n",
      "[21] D. Paul, M. Ismayilzada, M. Peyrard, B. Borges, A. Bosselut, R. West, and B. Faltings. Reﬁner:\n",
      "Reasoning feedback on intermediate representations, 2023.\n",
      "[22] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al. Improving language understanding\n",
      "by generative pre-training. OpenAI blog , 2018.\n",
      "[23] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are\n",
      "unsupervised multitask learners. OpenAI blog , 1(8):9, 2019.\n",
      "[24] I. Schlag, S. Sukhbaatar, A. Celikyilmaz, W. tau Yih, J. Weston, J. Schmidhuber, and X. Li.\n",
      "Large language model programs, 2023.\n",
      "[25] N. Shinn, B. Labash, and A. Gopinath. Reﬂexion: an autonomous agent with dynamic memory\n",
      "and self-reﬂection, 2023.\n",
      "[26] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker,\n",
      "M. Lai, A. Bolton, et al. Mastering the game of go without human knowledge. nature , 550\n",
      "(7676):354–359, 2017.\n",
      "[27] S. A. Sloman. The empirical case for two systems of reasoning. Psychological bulletin , 119(1):\n",
      "3, 1996.\n",
      "[28] K. E. Stanovich. Who is rational? Studies of individual differences in reasoning . Psychology\n",
      "Press, 1999.\n",
      "[29] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozi `ere, N. Goyal,\n",
      "E. Hambro, F. Azhar, et al. Llama: Open and efﬁcient foundation language models. arXiv\n",
      "preprint arXiv:2302.13971 , 2023.\n",
      "[30] S. Verma, J. Fu, S. Yang, and S. Levine. Chai: A chatbot ai for task-oriented dialogue with\n",
      "ofﬂine reinforcement learning. In Proceedings of the 2022 Conference of the North American\n",
      "Chapter of the Association for Computational Linguistics: Human Language Technologies ,\n",
      "pages 4471–4491, 2022.\n",
      "[31] E. Wallace, N. Tomlin, A. Xu, K. Yang, E. Pathak, M. Ginsberg, and D. Klein. Automated\n",
      "crossword solving. arXiv preprint arXiv:2205.09665 , 2022.\n",
      "[32] L. Wang, W. Xu, Y . Lan, Z. Hu, Y . Lan, R. K.-W. Lee, and E.-P. Lim. Plan-and-solve prompting:\n",
      "Improving zero-shot chain-of-thought reasoning by large language models, 2023.\n",
      "[33] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, and D. Zhou. Self-consistency improves chain\n",
      "of thought reasoning in language models. arXiv preprint arXiv:2203.11171 , 2022.\n",
      "[34] Z. Wang, S. Cai, A. Liu, X. Ma, and Y . Liang. Describe, explain, plan and select: Interactive\n",
      "planning with large language models enables open-world multi-task agents, 2023.\n",
      "[35] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D. Zhou. Chain of thought\n",
      "prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903 , 2022.\n",
      "[36] Y . Xie, K. Kawaguchi, Y . Zhao, X. Zhao, M.-Y . Kan, J. He, and Q. Xie. Decomposition\n",
      "enhances reasoning via self-evaluation guided decoding, 2023.\n",
      "[37] S. Yang, O. Nachum, Y . Du, J. Wei, P. Abbeel, and D. Schuurmans. Foundation models for\n",
      "decision making: Problems, methods, and opportunities, 2023.\n",
      "[38] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y . Cao. ReAct: Synergizing\n",
      "reasoning and acting in language models. arXiv preprint arXiv:2210.03629 , 2022.\n",
      "[39] S. Zhang, Z. Chen, Y . Shen, M. Ding, J. B. Tenenbaum, and C. Gan. Planning with large\n",
      "language models for code generation. In The Eleventh International Conference on Learning\n",
      "Representations , 2023. URL https://openreview.net/forum?id=Lr8cOOtYbfL .\n",
      "11\n",
      "Published as a conference paper at ICLR 2023\n",
      "SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT\n",
      "REASONING IN LANGUAGE MODELS\n",
      "Xuezhi Wang†‡Jason Wei†Dale Schuurmans†Quoc Le†Ed H. Chi†\n",
      "Sharan Narang†Aakanksha Chowdhery†Denny Zhou†§\n",
      "†Google Research, Brain Team\n",
      "‡xuezhiw@google.com ,§dennyzhou@google.com\n",
      "ABSTRACT\n",
      "Chain-of-thought prompting combined with pre-trained large language models has\n",
      "achieved encouraging results on complex reasoning tasks. In this paper, we propose\n",
      "a new decoding strategy, self-consistency , to replace the naive greedy decoding\n",
      "used in chain-of-thought prompting. It ﬁrst samples a diverse set of reasoning paths\n",
      "instead of only taking the greedy one, and then selects the most consistent answer\n",
      "by marginalizing out the sampled reasoning paths. Self-consistency leverages the\n",
      "intuition that a complex reasoning problem typically admits multiple different ways\n",
      "of thinking leading to its unique correct answer. Our extensive empirical evaluation\n",
      "shows that self-consistency boosts the performance of chain-of-thought prompting\n",
      "with a striking margin on a range of popular arithmetic and commonsense reasoning\n",
      "benchmarks, including GSM8K (+17.9%), SV AMP (+11.0%), AQuA (+12.2%),\n",
      "StrategyQA (+6.4%) and ARC-challenge (+3.9%).\n",
      "1 I NTRODUCTION\n",
      "Although language models have demonstrated remarkable success across a range of NLP tasks, their\n",
      "ability to demonstrate reasoning is often seen as a limitation, which cannot be overcome solely by\n",
      "increasing model scale (Rae et al., 2021; BIG-bench collaboration, 2021, inter alia ). In an effort\n",
      "to address this shortcoming, Wei et al. (2022) have proposed chain-of-thought prompting , where\n",
      "a language model is prompted to generate a series of short sentences that mimic the reasoning\n",
      "process a person might employ in solving a task. For example, given the question “If there are 3\n",
      "cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?” , instead\n",
      "of directly responding with “5”, a language model would be prompted to respond with the entire\n",
      "chain-of-thought: “There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 +\n",
      "2 = 5 cars. The answer is 5. ” . It has been observed that chain-of-thought prompting signiﬁcantly\n",
      "improves model performance across a variety of multi-step reasoning tasks (Wei et al., 2022).\n",
      "In this paper, we introduce a novel decoding strategy called self-consistency to replace the greedy\n",
      "decoding strategy used in chain-of-thought prompting (Wei et al., 2022), that further improves\n",
      "language models’ reasoning performance by a signiﬁcant margin. Self-consistency leverages the\n",
      "intuition that complex reasoning tasks typically admit multiple reasoning paths that reach a correct\n",
      "answer (Stanovich & West, 2000). The more that deliberate thinking and analysis is required for a\n",
      "problem (Evans, 2010), the greater the diversity of reasoning paths that can recover the answer.\n",
      "Figure 1 illustrates the self-consistency method with an example. We ﬁrst prompt the language model\n",
      "with chain-of-thought prompting, then instead of greedily decoding the optimal reasoning path, we\n",
      "propose a “sample-and-marginalize” decoding procedure: we ﬁrst sample from the language model’s\n",
      "decoder to generate a diverse set of reasoning paths; each reasoning path might lead to a different\n",
      "ﬁnal answer, so we determine the optimal answer by marginalizing out the sampled reasoning paths\n",
      "to ﬁnd the most consistent answer in the ﬁnal answer set. Such an approach is analogous to the\n",
      "human experience that if multiple different ways of thinking lead to the same answer, one has greater\n",
      "conﬁdence that the ﬁnal answer is correct. Compared to other decoding methods, self-consistency\n",
      "avoids the repetitiveness and local-optimality that plague greedy decoding, while mitigating the\n",
      "stochasticity of a single sampled generation.\n",
      "1arXiv:2203.11171v4  [cs.CL]  7 Mar 2023\n",
      "Published as a conference paper at ICLR 2023\n",
      "Language \n",
      "model Q: If there are 3 cars in the parking \n",
      "lot and 2 more cars arrive, how many \n",
      "cars are in the parking lot?\n",
      "A: There are 3 cars in the parking lot \n",
      "already. 2 more arrive. Now there are \n",
      "3 + 2 = 5 cars. The answer is 5. \n",
      "…\n",
      "Q: Janet’s ducks lay 16 eggs per day. \n",
      "She eats three for breakfast every \n",
      "morning and bakes muffins for her \n",
      "friends every day with four. She sells \n",
      "the remainder for $2 per egg. How \n",
      "much does she make every day? \n",
      "A:She has 16 - 3 - 4 = 9 eggs \n",
      "left. So she makes $2 * 9 = \n",
      "$18 per day. Sample a diverse set of \n",
      "reasoning paths\n",
      "She eats 3 for breakfast, so \n",
      "she has 16 - 3 = 13 left. Then \n",
      "she bakes muffins, so she \n",
      "has 13 - 4 = 9 eggs left. So \n",
      "she has 9 eggs * $2 = $18. This means she she sells the \n",
      "remainder for $2 * (16 - 4 - 3) \n",
      "= $26 per day. The answer is $18. \n",
      "The answer is $26. \n",
      "The answer is $18. The answer is $18.Marginalize out reasoning paths \n",
      "to aggregate final answers Language \n",
      "model This means she uses 3 + 4 = 7 eggs every day.  \n",
      "She sells the remainder for $2 per egg, so in \n",
      "total she sells 7 * $2 = $14 per day. \n",
      "The answer is $14. The answer is $14. Greedy decode\n",
      "Figure 1: The self-consistency method contains three steps: (1) prompt a language model using\n",
      "chain-of-thought (CoT) prompting; (2) replace the “greedy decode” in CoT prompting by sampling\n",
      "from the language model’s decoder to generate a diverse set of reasoning paths; and (3) marginalize\n",
      "out the reasoning paths and aggregate by choosing the most consistent answer in the ﬁnal answer set.\n",
      "Self-consistency is far simpler than prior approaches that either train an additional veriﬁer (Cobbe\n",
      "et al., 2021) or train a re-ranker given additional human annotations to improve generation quality\n",
      "(Thoppilan et al., 2022). Instead, self-consistency is entirely unsupervised , works off-the-shelf with\n",
      "pre-trained language models, requires no additional human annotation, and avoids any additional\n",
      "training, auxiliary models or ﬁne-tuning. Self-consistency also differs from a typical ensemble\n",
      "approach where multiple models are trained and the outputs from each model are aggregated, it acts\n",
      "more like a “self-ensemble” that works on top of a single language model.\n",
      "We evaluate self-consistency on a wide range of arithmetic and commonsense reasoning tasks over\n",
      "four language models with varying scales: the public UL2-20B (Tay et al., 2022) and GPT-3-175B\n",
      "(Brown et al., 2020), and two densely-activated decoder-only language models: LaMDA-137B\n",
      "(Thoppilan et al., 2022) and PaLM-540B (Chowdhery et al., 2022). On all four language models,\n",
      "self-consistency improves over chain-of-thought prompting by a striking margin across all tasks. In\n",
      "particular, when used with PaLM-540B or GPT-3, self-consistency achieves new state-of-the-art levels\n",
      "of performance across arithmetic reasoning tasks, including GSM8K (Cobbe et al., 2021) (+17.9%\n",
      "absolute accuracy gains), SV AMP (Patel et al., 2021) (+11.0%), AQuA (Ling et al., 2017) (+12.2%),\n",
      "and across commonsense reasoning tasks such as StrategyQA (Geva et al., 2021) (+6.4%) and ARC-\n",
      "challenge (Clark et al., 2018) (+3.9%). In additional experiments, we show self-consistency can\n",
      "robustly boost performance on NLP tasks where adding a chain-of-thought might hurt performance\n",
      "compared to standard prompting (Ye & Durrett, 2022). We also show self-consistency signiﬁcantly\n",
      "outperforms sample-and-rank, beam search, ensemble-based approaches, and is robust to sampling\n",
      "strategies and imperfect prompts.\n",
      "2 S ELF-CONSISTENCY OVER DIVERSE REASONING PATHS\n",
      "A salient aspect of humanity is that people think differently. It is natural to suppose that in tasks\n",
      "requiring deliberate thinking, there are likely several ways to attack the problem. We propose that\n",
      "such a process can be simulated in language models via sampling from the language model’s decoder.\n",
      "For instance, as shown in Figure 1, a model can generate several plausible responses to a math\n",
      "question that all arrive at the same correct answer (Outputs 1 and 3). Since language models are not\n",
      "perfect reasoners, the model might also produce an incorrect reasoning path or make a mistake in\n",
      "one of the reasoning steps (e.g., in Output 2), but such solutions are less likely to arrive at the same\n",
      "answer. That is, we hypothesize that correct reasoning processes, even if they are diverse, tend to\n",
      "have greater agreement in their ﬁnal answer than incorrect processes.\n",
      "We leverage this intuition by proposing the following self-consistency method. First, a language\n",
      "model is prompted with a set of manually written chain-of-thought exemplars (Wei et al., 2022). Next,\n",
      "2\n",
      "Published as a conference paper at ICLR 2023\n",
      "GSM8K MultiArith AQuA SV AMP CSQA ARC-c\n",
      "Greedy decode 56.5 94.7 35.8 79.0 79.0 85.2\n",
      "Weighted avg (unnormalized) 56.3 ±0.0 90.5±0.0 35.8±0.073.0±0.074.8±0.082.3±0.0\n",
      "Weighted avg (normalized) 22.1 ±0.0 59.7±0.0 15.7±0.040.5±0.052.1±0.051.7±0.0\n",
      "Weighted sum (unnormalized) 59.9 ±0.0 92.2±0.0 38.2±0.076.2±0.076.2±0.083.5±0.0\n",
      "Weighted sum (normalized) 74.1 ±0.0 99.3±0.0 48.0±0.086.8±0.080.7±0.088.7±0.0\n",
      "Unweighted sum (majority vote) 74.4 ±0.1 99.3±0.0 48.3±0.586.6±0.180.7±0.188.7±0.1\n",
      "Table 1: Accuracy comparison of different answer aggregation strategies on PaLM-540B.\n",
      "we sample a set of candidate outputs from the language model’s decoder, generating a diverse set of\n",
      "candidate reasoning paths. Self-consistency is compatible with most existing sampling algorithms,\n",
      "including temperature sampling (Ackley et al., 1985; Ficler & Goldberg, 2017), top- ksampling (Fan\n",
      "et al., 2018; Holtzman et al., 2018; Radford et al., 2019), and nucleus sampling (Holtzman et al.,\n",
      "2020). Finally, we aggregate the answers by marginalizing out the sampled reasoning paths and\n",
      "choosing the answer that is the most consistent among the generated answers.\n",
      "In more detail, assume the generated answers aiare from a ﬁxed answer set, ai∈A, where\n",
      "i= 1, . . . , m indexes the mcandidate outputs sampled from the decoder. Given a prompt and a\n",
      "question, self-consistency introduces an additional latent variable ri, which is a sequence of tokens\n",
      "representing the reasoning path in the i-th output, then couples the generation of (ri,ai)where\n",
      "ri→ai, i.e., generating a reasoning path riis optional and only used to reach the ﬁnal answer ai. As\n",
      "an example, consider Output 3 from Figure 1: the ﬁrst few sentences “ She eats 3 for breakfast ... So\n",
      "she has 9 eggs * $2 = $18. ” constitutes ri, while the answer 18from the last sentence, “ The answer\n",
      "is $18 ”, is parsed as ai.1After sampling multiple (ri,ai)from the model’s decoder, self-consistency\n",
      "applies a marginalization over riby taking a majority vote over ai, i.e., arg maxa∑m\n",
      "i=11(ai=a),\n",
      "or as we deﬁned as the most “consistent” answer among the ﬁnal answer set.\n",
      "In Table 1, we show the test accuracy over a set of reasoning tasks by using different answer\n",
      "aggregation strategies. In addition to majority vote, one can also weight each (ri,ai)byP(ri,ai|\n",
      "prompt ,question )when aggregating the answers. Note to compute P(ri,ai|prompt ,question ), we\n",
      "can either take the unnormalized probability of the model generating (ri,ai)given (prompt ,question ),\n",
      "or we can normalize the conditional probability by the output length (Brown et al., 2020), i.e.,\n",
      "P(ri,ai|prompt ,question ) = exp1\n",
      "K∑K\n",
      "k=1logP(tk|prompt ,question ,t1,...,tk−1), (1)\n",
      "where logP(tk|prompt ,question , t1, . . . , t k−1)is the log probability of generating the k-th token\n",
      "tkin(ri,ai)conditioned on the previous tokens, and Kis the total number of tokens in (ri,ai).\n",
      "In Table 1, we show that taking the “unweighted sum”, i.e., taking a majority vote directly over ai\n",
      "yields a very similar accuracy as aggregating using the “normalized weighted sum”. We took a closer\n",
      "look at the model’s output probabilities and found this is because for each (ri,ai), the normalized\n",
      "conditional probabilities P(ri,ai|prompt ,question )are quite close to each other, i.e., the language\n",
      "model regards those generations as “similarly likely”.2Additionally, when aggregating the answers,\n",
      "the results in Table 1 show that the “normalized” weighted sum (i.e., Equation 1) yields a much\n",
      "higher accuracy compared to its unnormalized counterpart. For completeness, in Table 1 we also\n",
      "report the results by taking a “weighted average”, i.e., each agets a score of its weighted sum divided\n",
      "by∑m\n",
      "i=11(ai=a), which results in a much worse performance.\n",
      "Self-consistency explores an interesting space between open-ended text generation and optimal\n",
      "text generation with a ﬁxed answer. Reasoning tasks typically have ﬁxed answers, which is why\n",
      "researchers have generally considered greedy decoding approaches (Radford et al., 2019; Wei et al.,\n",
      "2022; Chowdhery et al., 2022). However, we have found that even when the desired answer is ﬁxed,\n",
      "introducing diversity in the reasoning processes can be highly beneﬁcial; therefore we leverage\n",
      "1The parser is task dependent. For arithmetic reasoning, we parse the ﬁrst numerical part as the ﬁnal answer\n",
      "after the model generates “The answer is ”. For commonsense reasoning, we parse the full string answer as the\n",
      "ﬁnal answer after the model generates “The answer is ”. Most generated outputs have a consistent format of\n",
      "“{Reasoning paths}. The answer is X.” if we prompt the language model in this format.\n",
      "2This also means that the language model is not well calibrated and thus cannot distinguish well between\n",
      "correct solutions and wrong solutions, which also explains why additional re-rankers were trained to better judge\n",
      "the quality of the solutions in previous work (Cobbe et al., 2021; Thoppilan et al., 2022).\n",
      "3\n",
      "Published as a conference paper at ICLR 2023\n",
      "sampling, as commonly used for open-ended text generation (Radford et al., 2019; Brown et al., 2020;\n",
      "Thoppilan et al., 2022), to achieve this goal. One should note that self-consistency can be applied\n",
      "only to problems where the ﬁnal answer is from a ﬁxed answer set, but in principle this approach can\n",
      "be extended to open-text generation problems if a good metric of consistency can be deﬁned between\n",
      "multiple generations, e.g., whether two answers agree or contradict each other.\n",
      "3 E XPERIMENTS\n",
      "We conducted a series of experiments to compare the proposed self-consistency method with existing\n",
      "approaches on a range of reasoning benchmarks. We ﬁnd that self-consistency robustly improves\n",
      "reasoning accuracy for every language model considered, spanning a wide range of model scales.\n",
      "3.1 E XPERIMENT SETUP\n",
      "Tasks and datasets. We evaluate self-consistency on the following reasoning benchmarks.3\n",
      "•Arithmetic reasoning . For these tasks, we used the Math Word Problem Repository (Koncel-\n",
      "Kedziorski et al., 2016), including AddSub (Hosseini et al., 2014), MultiArith (Roy & Roth,\n",
      "2015), and ASDiv (Miao et al., 2020). We also included AQUA-RAT (Ling et al., 2017), a\n",
      "recently published benchmark of grade-school-math problems (GSM8K; Cobbe et al., 2021),\n",
      "and a challenge dataset over math word problems (SV AMP; Patel et al., 2021).\n",
      "•Commonsense reasoning . For these tasks, we used CommonsenseQA (Talmor et al., 2019),\n",
      "StrategyQA (Geva et al., 2021), and the AI2 Reasoning Challenge (ARC) (Clark et al., 2018).\n",
      "•Symbolic Reasoning . We evaluate two symbolic reasoning tasks: last letter concatenation (e.g.,\n",
      "the input is “Elon Musk” and the output should be “nk”), and Coinﬂip (e.g., a coin is heads-up,\n",
      "after a few ﬂips is the coin still heads-up?) from Wei et al. (2022).\n",
      "Language models and prompts. We evaluate self-consistency over four transformer-based lan-\n",
      "guage models with varying scales:\n",
      "•UL2 (Tay et al., 2022) is an encoder-decoder model trained on a mixture of denoisers with 20-\n",
      "billion parameters. UL2 is completely open-sourced4and has similar or better performance than\n",
      "GPT-3 on zero-shot SuperGLUE, with only 20B parameters and thus is more compute-friendly;\n",
      "•GPT-3 (Brown et al., 2020) with 175-billion parameters. We use two public engines code-davinci-\n",
      "001andcode-davinci-002 from the Codex series (Chen et al., 2021) to aid reproducibility;5\n",
      "•LaMDA-137B (Thoppilan et al., 2022) is a dense left-to-right, decoder-only language model with\n",
      "137-billion parameters, pre-trained on a mixture of web documents, dialog data and Wikipedia;\n",
      "•PaLM-540B (Chowdhery et al., 2022) is a dense left-to-right, decoder-only language model with\n",
      "540-billion parameters, pre-trained on a high quality corpus of 780 billion tokens with ﬁltered\n",
      "webpages, books, Wikipedia, news articles, source code, and social media conversations.\n",
      "We perform all experiments in the few-shot setting, without training or ﬁne-tuning the language\n",
      "models. For a fair comparison we use the same prompts as in Wei et al. (2022): for all arithmetic\n",
      "reasoning tasks we use the same set of 8 manually written exemplars; for each commonsense\n",
      "reasoning task, 4-7 exemplars are randomly chosen from the training set with manually composed\n",
      "chain-of-thought prompts.6Full details on the prompts used are given in Appendix A.3.\n",
      "Sampling scheme. To sample diverse reasoning paths, we followed similar settings to those\n",
      "suggested in Radford et al. (2019); Holtzman et al. (2020) for open-text generation. In particular, for\n",
      "UL2-20B and LaMDA-137B we applied temperature sampling with T= 0.5and truncated at the\n",
      "top-k(k= 40 ) tokens with the highest probability, for PaLM-540B we applied T= 0.7, k= 40 , and\n",
      "for GPT-3 we use T= 0.7without top- ktruncation. We provide an ablation study in Section 3.5 to\n",
      "show that self-consistency is generally robust to sampling strategies and parameters.\n",
      "3By default we use the test split for all datasets if the labels are available for evaluation. For CommonsenseQA\n",
      "we use the dev split; for StrategyQA we use the question-only set from BIG-bench collaboration (2021):\n",
      "https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/strategyqa .\n",
      "4Model checkpoints at https://github.com/google-research/google-research/tree/master/ul2 .\n",
      "5Public API available at https://openai.com/api/ .\n",
      "6Self-consistency is robust to different sets of prompts and we provide a study in Appendix A.1.2.\n",
      "4\n",
      "Published as a conference paper at ICLR 2023\n",
      "3.2 M AINRESULTS\n",
      "We report the results of self-consistency averaged over 10 runs, where we sampled 40 outputs\n",
      "independently from the decoder in each run. The baseline we compare to is chain-of-thought\n",
      "prompting with greedy decoding (Wei et al., 2022), referred to as CoT-prompting , which has been\n",
      "previously used for decoding in large language models (Chowdhery et al., 2022).\n",
      "Arithmetic Reasoning The results are shown in Table 2.7Self-consistency improves the arithmetic\n",
      "reasoning performance over all four language models signiﬁcantly over chain-of-thought prompting.\n",
      "More surprisingly, the gains become more signiﬁcant when the language model’s scale increases,\n",
      "e.g., we see +3%-6% absolute accuracy improvement over UL2-20B but +9%-23% for LaMDA-\n",
      "137B and GPT-3. For larger models that already achieve high accuracy on most tasks (e.g., GPT-3\n",
      "and PaLM-540B), self-consistency still contributes signiﬁcant additional gains with +12%-18%\n",
      "absolute accuracy on tasks like AQuA and GSM8K, and +7%-11% on SV AMP and ASDiv. With\n",
      "self-consistency, we achieve new state-of-the-art results on almost all tasks: despite the fact that self-\n",
      "consistency is unsupervised and task-agnostic, these results compare favorably to existing approaches\n",
      "that require task-speciﬁc training, or ﬁne-tuning with thousands of examples (e.g., on GSM8K).\n",
      "Method AddSub MultiArith ASDiv AQuA SV AMP GSM8K\n",
      "Previous SoTA 94.9a60.5a75.3b37.9c57.4d35e/ 55g\n",
      "UL2-20BCoT-prompting 18.2 10.7 16.9 23.6 12.6 4.1\n",
      "Self-consistency 24.8 (+6.6) 15.0 (+4.3) 21.5 (+4.6) 26.9 (+3.3) 19.4 (+6.8) 7.3 (+3.2)\n",
      "LaMDA-137BCoT-prompting 52.9 51.8 49.0 17.7 38.9 17.1\n",
      "Self-consistency 63.5 (+10.6) 75.7 (+23.9) 58.2 (+9.2) 26.8 (+9.1) 53.3 (+14.4) 27.7 (+10.6)\n",
      "PaLM-540BCoT-prompting 91.9 94.7 74.0 35.8 79.0 56.5\n",
      "Self-consistency 93.7 (+1.8) 99.3 (+4.6) 81.9 (+7.9) 48.3 (+12.5) 86.6 (+7.6) 74.4 (+17.9)\n",
      "GPT-3\n",
      "Code-davinci-001CoT-prompting 57.2 59.5 52.7 18.9 39.8 14.6\n",
      "Self-consistency 67.8 (+10.6) 82.7 (+23.2) 61.9 (+9.2) 25.6 (+6.7) 54.5 (+14.7) 23.4 (+8.8)\n",
      "GPT-3\n",
      "Code-davinci-002CoT-prompting 89.4 96.2 80.1 39.8 75.8 60.1\n",
      "Self-consistency 91.6 (+2.2) 100.0 (+3.8) 87.8 (+7.6) 52.0 (+12.2) 86.8 (+11.0) 78.0 (+17.9)\n",
      "Table 2: Arithmetic reasoning accuracy by self-consistency compared to chain-of-thought prompting\n",
      "(Wei et al., 2022). The previous SoTA baselines are obtained from: a: Relevance and LCA operation\n",
      "classiﬁer (Roy & Roth, 2015), b: Lan et al. (2021), c: Amini et al. (2019), d: Pi et al. (2022), e:\n",
      "GPT-3 175B ﬁnetuned with 7.5k examples (Cobbe et al., 2021), g: GPT-3 175B ﬁnetuned plus an\n",
      "additional 175B veriﬁer (Cobbe et al., 2021). The best performance for each task is shown in bold.\n",
      "Method CSQA StrategyQA ARC-e ARC-c Letter (4) Coinﬂip (4)\n",
      "Previous SoTA 91.2a73.9b86.4c75.0cN/A N/A\n",
      "UL2-20BCoT-prompting 51.4 53.3 61.6 42.9 0.0 50.4\n",
      "Self-consistency 55.7 (+4.3) 54.9 (+1.6) 69.8 (+8.2) 49.5 (+6.8) 0.0 (+0.0) 50.5 (+0.1)\n",
      "LaMDA-137BCoT-prompting 57.9 65.4 75.3 55.1 8.2 72.4\n",
      "Self-consistency 63.1 (+5.2) 67.8 (+2.4) 79.3 (+4.0) 59.8 (+4.7) 8.2 (+0.0) 73.5 (+1.1)\n",
      "PaLM-540BCoT-prompting 79.0 75.3 95.3 85.2 65.8 88.2\n",
      "Self-consistency 80.7 (+1.7) 81.6 (+6.3) 96.4 (+1.1) 88.7 (+3.5) 70.8 (+5.0) 91.2 (+3.0)\n",
      "GPT-3\n",
      "Code-davinci-001CoT-prompting 46.6 56.7 63.1 43.1 7.8 71.4\n",
      "Self-consistency 54.9 (+8.3) 61.7 (+5.0) 72.1 (+9.0) 53.7 (+10.6) 10.0 (+2.2) 75.9 (+4.5)\n",
      "GPT-3\n",
      "Code-davinci-002CoT-prompting 79.0 73.4 94.0 83.6 70.4 99.0\n",
      "Self-consistency 81.5 (+2.5) 79.8 (+6.4) 96.0 (+2.0) 87.5 (+3.9) 73.4 (+3.0) 99.5 (+0.5)\n",
      "Table 3: Commonsense and symbolic reasoning accuracy by self-consistency compared to chain-\n",
      "of-thought prompting (Wei et al., 2022). The previous SoTA baselines are obtained from: a:\n",
      "DeBERTaV3-large + KEAR (Xu et al., 2021b), b: Chowdhery et al. (2022), c: UniﬁedQA-FT\n",
      "(Khashabi et al., 2020). The best performance for each task is shown in bold.\n",
      "7The standard deviation of self-consistency is ≤0.5for all tasks and is thus omitted in the table. Please refer\n",
      "to Figure 2, Figure 7 and 8 for the standard deviations under varying numbers of sampled paths.\n",
      "5\n",
      "Published as a conference paper at ICLR 2023\n",
      "Commonsense and Symbolic Reasoning Table 3 shows the results on commonsense and symbolic\n",
      "reasoning tasks. Similarly, self-consistency yields large gains across all four language models, and\n",
      "obtained SoTA results on 5 out of 6 tasks. For symbolic reasoning, we test the out-of-distribution\n",
      "(OOD) setting where the input prompt contains examples of 2-letters or 2-ﬂips but we test examples\n",
      "of 4-letters and 4-ﬂips (this setting is more challenging as PaLM-540B or GPT-3 can already achieve\n",
      "perfect in-distribution accuracy). In this challenging OOD setting, the gain of self-consistency is still\n",
      "quite signiﬁcant compared to CoT-prompting with sufﬁcient model sizes.\n",
      "To show the effect of the number of sampled reasoning paths, we plot the accuracy (mean and\n",
      "standard deviation over 10 runs) with respect to varying numbers of sampled paths (1, 5, 10, 20, 40)\n",
      "in Figure 2. The results show that sampling a higher number (e.g., 40) of reasoning paths leads to a\n",
      "consistently better performance, further emphasizing the importance of introducing diversity in the\n",
      "reasoning paths. In Table 4, we show self-consistency yields a richer set of reasoning paths compared\n",
      "to greedy decoding with a few example questions from two tasks.\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths505560657075Accuracy (%)\n",
      "MultiArith\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths3336394245485154\n",
      "SVAMP\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths56586062\n",
      "Commonsense QA\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths505254565860\n",
      "ARC (Challenge)\n",
      "Greedy Decode (Single-path)\n",
      "Self Consistency (Multi-path)\n",
      "Figure 2: Self-consistency (blue) signiﬁcantly improves accuracy over CoT-prompting with greedy\n",
      "decoding (orange) across arithmetic and commonsense reasoning tasks, over LaMDA-137B. Sampling\n",
      "a higher number of diverse reasoning paths consistently improves reasoning accuracy.\n",
      "GSM8K StrategyQA\n",
      "Question Henry made two stops during his 60-mile bike trip. He ﬁrst stopped after 20\n",
      "miles. His second stop was 15 miles before the end of the trip. How many miles\n",
      "did he travel between his ﬁrst and second stops?Yes or no: Is Albany, Georgia the most populous\n",
      "US Albany?\n",
      "Greedy\n",
      "DecodeHe traveled 60 miles in total. He stopped after 20 miles, so he traveled 60 - 20\n",
      "= 40 miles between the ﬁrst and second stops. The answer is 40.Albany, Georgia is the most populous US Al-\n",
      "bany. Thus, the answer is yes.\n",
      "Sampled\n",
      "Path 1Henry travelled a total of 60 miles. His ﬁrst stop was 20 miles in, and his\n",
      "second stop was 15 miles before the end. So between his ﬁrst and second stops\n",
      "he travelled 60 - 20 -15 = 25 miles. The answer is 25.The most populous US Albany is Albany, New\n",
      "York. Thus, Albany, Georgia is not the most\n",
      "populous US Albany. So the answer is no.\n",
      "Sampled\n",
      "Path 2He made two stops during a 60-mile trip. The ﬁrst was 20 miles into the trip.\n",
      "The second was 15 miles before the end of the trip. This means the second stop\n",
      "was 60 - 15 = 45 miles into the trip. Since he made the stops in order, the second\n",
      "stop must have been 45 - 20 = 25 miles after the ﬁrst stop. The answer is 25.Albany, Georgia has a population of about\n",
      "88,000. Albany, New York has a population of\n",
      "about 95,000. Thus, Albany, Georgia is not the\n",
      "most populous US Albany. So the answer is no.\n",
      "Table 4: Examples where self-consistency helps repair the errors over greedy decode, on PaLM-540B.\n",
      "Two sampled reasoning paths that are consistent with the ground truth are shown.\n",
      "3.3 S ELF-CONSISTENCY HELPS WHEN CHAIN -OF-THOUGHT HURTS PERFORMANCE\n",
      "Ye & Durrett (2022) show that sometimes chain-of-thought prompting could hurt performance\n",
      "compared to standard prompting in few-shot in-context learning. Here we perform a study using\n",
      "self-consistency to see if it can help ﬁll in the gap, over a set of common NLP tasks, including (1)\n",
      "Closed-Book Question Answering: BoolQ (Clark et al., 2019), HotpotQA (Yang et al., 2018), and\n",
      "(2) Natural Language Inference: e-SNLI (Camburu et al., 2018), ANLI (Nie et al., 2020) and RTE\n",
      "(Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009).\n",
      "The results over PaLM-540B are shown in Table 5. For some tasks (e.g., ANLI-R1, e-SNLI, RTE),\n",
      "adding chain-of-thought does hurt performance compared to standard prompting (Brown et al., 2020),\n",
      "but self-consistency is able to robustly boost the performance and outperform standard prompting,\n",
      "making it a reliable way to add rationales in few-shot in-context learning for common NLP tasks.\n",
      "ANLI R1 / R2 / R3 e-SNLI RTE BoolQ HotpotQA (EM/F1)\n",
      "Standard-prompting (no-rationale) 69.1 / 55.8 / 55.8 85.8 84.8 71.3 27.1 / 36.8\n",
      "CoT-prompting (Wei et al., 2022) 68.8 / 58.9 / 60.6 81.0 79.1 74.2 28.9 / 39.8\n",
      "Self-consistency 78.5 /64.5 /63.4 88.4 86.3 78.4 33.8 / 44.6\n",
      "Table 5: Compare Standard/CoT prompting with self-consistency on common NLP tasks.\n",
      "6\n",
      "Published as a conference paper at ICLR 2023\n",
      "3.4 C OMPARE TO OTHER EXISTING APPROACHES\n",
      "We conduct a set of additional studies and show that self-consistency signiﬁcantly outperforms\n",
      "existing methods including sample-and-rank, beam search, and ensemble-based approaches.\n",
      "Comparison to Sample-and-Rank One commonly used approach to improve generation quality is\n",
      "sample-and-rank, where multiple sequences are sampled from the decoder and then ranked according\n",
      "to each sequence’s log probability (Adiwardana et al., 2020). We compare self-consistency with\n",
      "sample-and-rank on GPT-3 code-davinci-001 , by sampling the same number of sequences from the\n",
      "decoder as self-consistency and taking the ﬁnal answer from the top-ranked sequence. The results are\n",
      "shown in Figure 3. While sample-and-rank does improve the accuracy with additionally sampled\n",
      "sequences and ranking, the gain is much smaller compared to self-consistency.\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths12141618202224Accuracy (%)\n",
      "GSM8K\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths50556065707580Accuracy (%)\n",
      "MultiArith\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths303540455055Accuracy (%)\n",
      "ARC (Challenge)\n",
      "Self Consistency (Multi-path)\n",
      "Sample & Rank (Multi-path)\n",
      "Greedy Decode (Single-path)\n",
      "Figure 3: Self-consistency signiﬁcantly outperforms sample-and-rank with the same # of samples.\n",
      "Comparison to Beam Search In Table 6, we compare self-consistency with beam search decoding\n",
      "on the UL2-20B model. For a fair comparison we report the accuracy under the same number of\n",
      "beams and reasoning paths. On both tasks self-consistency outperforms beam search signiﬁcantly.\n",
      "Note self-consistency can also adopt beam search to decode each reasoning path (results are shown\n",
      "as “Self-consistency using beam search”), but its performance is worse compared to self-consistency\n",
      "with sampling. The reason is that beam search yields a lower diversity in the outputs (Li & Jurafsky,\n",
      "2016), while in self-consistency the diversity of the reasoning paths is the key to a better performance.\n",
      "Beam size / Self-consistency paths 1 5 10 20 40\n",
      "AQuABeam search decoding (top beam) 23.6 19.3 16.1 15.0 10.2\n",
      "Self-consistency using beam search 23.6 19.8 ±0.321.2±0.724.6±0.424.2±0.5\n",
      "Self-consistency using sampling 19.7 ±2.524.9±2.625.3±1.826.7±1.026.9±0.5\n",
      "MultiArithBeam search decoding (top beam) 10.7 12.0 11.3 11.0 10.5\n",
      "Self-consistency using beam search 10.7 11.8 ±0.011.4±0.112.3±0.110.8±0.1\n",
      "Self-consistency using sampling 9.5 ±1.2 11.3±1.212.3±0.813.7±0.914.7±0.3\n",
      "Table 6: Compare self-consistency with beam search decoding on the UL2-20B model.\n",
      "Comparison to Ensemble-based Approaches We further compare self-consistency to ensemble-\n",
      "based methods for few-shot learning. In particular, we consider ensembling by: (1) prompt order\n",
      "permutation: we randomly permute the exemplars in the prompt 40 times to mitigate model’s\n",
      "sensitivity to prompt order (Zhao et al., 2021; Lu et al., 2021); and (2) multiple sets of prompts\n",
      "(Gao et al., 2021): we manually write 3different sets of prompts. We took majority vote of the\n",
      "answers from greedy decoding in both approaches as an ensemble. Table 7 shows that compared to\n",
      "self-consistency, existing ensemble-based approaches achieve a much smaller gain.8In addition, note\n",
      "that self-consistency is different from a typical model-ensemble approach, where multiple models\n",
      "are trained and their outputs are aggregated. Self-consistency acts more like a “self-ensemble” on\n",
      "top of a single language model. We additionally show the results of ensembling multiple models in\n",
      "Appendix A.1.3 where the model-ensembles perform much worse compared to self-consistency.\n",
      "GSM8K MultiArith SV AMP ARC-e ARC-c\n",
      "CoT (Wei et al., 2022) 17.1 51.8 38.9 75.3 55.1\n",
      "Ensemble (3 sets of prompts) 18.6 ±0.5 57.1±0.7 42.1±0.6 76.6±0.1 57.0±0.2\n",
      "Ensemble (40 prompt permutations) 19.2 ±0.1 60.9±0.2 42.7±0.1 76.9±0.1 57.0±0.1\n",
      "Self-Consistency (40 sampled paths) 27.7±0.2 75.7±0.3 53.3±0.2 79.3±0.3 59.8±0.2\n",
      "Table 7: Self-consistency outperforms prompt-order and multi-prompt ensembles on LaMDA-137B.\n",
      "8Self-consistency is compatible with both ensemble approaches and we show the results in Appendix A.1.4.\n",
      "7\n",
      "Published as a conference paper at ICLR 2023\n",
      "3.5 A DDITIONAL STUDIES\n",
      "We conducted a number of additional experiments to analyze different aspects of the self-consistency\n",
      "method, including its robustness to sampling strategies and parameters, and how it works with\n",
      "imperfect prompts and non-natural-language reasoning paths.\n",
      "Self-Consistency is Robust to Sampling Strategies and Scaling We show self-consistency is\n",
      "robust to sampling strategies and parameters, by varying Tin temperature sampling (Ackley et al.,\n",
      "1985; Ficler & Goldberg, 2017), kin top- ksampling (Fan et al., 2018; Holtzman et al., 2018; Radford\n",
      "et al., 2019), and pin nucleus sampling (Holtzman et al., 2020), over PaLM-540B in Figure 4 (left).\n",
      "Figure 4 (right) shows that self-consistency robustly improves performance across all scales for the\n",
      "LaMDA-137B model series. The gain is relatively lower for smaller models due to certain abilities\n",
      "(e.g., arithmetic) only emerge when the model reaches a sufﬁcient scale (Brown et al., 2020).\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths444852566064687276Accuracy (%)\n",
      "T=0.7, k=40\n",
      "T=0.5, k=40\n",
      "T=0.3, k=40\n",
      "T=0.7, k=20\n",
      "T=0.7, no top k\n",
      "p=0.95\n",
      "p=0.9\n",
      "Greedy Decode\n",
      "12 51020 50100200\n",
      "Model size (#param in billions)510152025Accuracy (%)\n",
      "Self Consistency\n",
      "Greedy Decode\n",
      "Figure 4: GSM8K accuracy. (Left) Self-consistency is robust to various sampling strategies and\n",
      "parameters. (Right) Self-consistency improves performance across language model scales.\n",
      "Self-Consistency Improves Robustness to Imperfect Prompts For few-shot learning with man-\n",
      "ually constructed prompts, human annotators sometimes make minor mistakes when creating the\n",
      "prompts. We further study if self-consistency can help improve a language model’s robustness to\n",
      "imperfect prompts.9We show the results in Table 8: while imperfect prompts decrease accuracy with\n",
      "greedy decoding (17.1 →14.9), self-consistency can ﬁll in the gaps and robustly improve the results.\n",
      "Additionally, we found that the consistency (in terms of % of decodes agreeing with the ﬁnal\n",
      "aggregated answer) is highly correlated with accuracy (Figure 5, over GSM8K). This suggests that\n",
      "one can use self-consistency to provide an uncertainty estimate of the model in its generated solutions.\n",
      "In other words, one can use low consistency as an indicator that the model has low conﬁdence; i.e.,\n",
      "self-consistency confers some ability for the model to “know when it doesn’t know”.\n",
      "LaMDA-137BPrompt with correct chain-of-thought 17.1\n",
      "Prompt with imperfect chain-of-thought 14.9\n",
      "+ Self-consistency (40 paths) 23.4\n",
      "Prompt with equations 5.0\n",
      "+ Self-consistency (40 paths) 6.5\n",
      "PaLM-540BZero-shot CoT (Kojima et al., 2022) 43.0\n",
      "+ Self-consistency (40 paths) 69.2\n",
      "Table 8: Self-consistency works under imperfect prompts, equa-\n",
      "tion prompts and zero-shot chain-of-thought for GSM8K.\n",
      "0 20 40 60 80 100\n",
      "Consistency (%)020406080100Accuracy (%)\n",
      "Figure 5: The consistency is cor-\n",
      "related with model’s accuracy.\n",
      "Self-Consistency Works for Non-Natural-Language Reasoning Paths and Zero-shot CoT We\n",
      "also tested the generality of the self-consistency concept to alternative forms of intermediate reasoning\n",
      "like equations (e.g., from “ There are 3 cars in the parking lot already. 2 more arrive. Now there\n",
      "are 3 + 2 = 5 cars. ” to “ 3 + 2 = 5 ”). The results are shown in Table 8 (“Prompt with equations”):\n",
      "self-consistency still improves accuracy by generating intermediate equations; however, compared to\n",
      "generating natural language reasoning paths, the gain is smaller since the equations are much shorter\n",
      "and less opportunity remains for generating diversity in the decoding process. In addition, we tested\n",
      "self-consistency with zero-shot chain-of-thought (Kojima et al., 2022) and show that self-consistency\n",
      "works for zero-shot CoT as well and improves the results signiﬁcantly (+26.2%) in Table 8.\n",
      "9We use the same prompts as before, but swap all the numbers in the reasoning paths with random numbers\n",
      "except the ﬁnal answer, e.g., from “ There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 +\n",
      "2 = 5 cars. ” to “ There are 7 cars in the parking lot already. 6 more arrive. Now there are 7 + 6 = 5 cars. ”.\n",
      "8\n",
      "Published as a conference paper at ICLR 2023\n",
      "4 R ELATED WORK\n",
      "Reasoning in language models. Language models are known to struggle in Type 2 tasks, such as\n",
      "arithmetic, logical and commonsense reasoning (Evans, 2010). Previous work has primarily focused\n",
      "onspecialized approaches for improving reasoning (Andor et al., 2019; Ran et al., 2019; Geva et al.,\n",
      "2020; Pi˛ ekos et al., 2021). Compared to prior work, self-consistency is applicable to a wide range of\n",
      "reasoning tasks without any additional supervision or ﬁne-tuning, while still substantially improving\n",
      "the performance of the chain-of-thought prompting approach proposed in Wei et al. (2022).\n",
      "Sampling and re-ranking in language models. Multiple decoding strategies for language models\n",
      "have been proposed in the literature, e.g., temperature sampling (Ackley et al., 1985; Ficler &\n",
      "Goldberg, 2017), top- ksampling (Fan et al., 2018; Holtzman et al., 2018; Radford et al., 2019),\n",
      "nucleus sampling (Holtzman et al., 2020), minimum Bayes risk decoding (Eikema & Aziz, 2020; Shi\n",
      "et al., 2022), and typical decoding (Meister et al., 2022). Other work has sought to explicitly promote\n",
      "diversity in the decoding process (Batra et al., 2012; Li et al., 2016; Vijayakumar et al., 2018).\n",
      "Re-ranking is another common approach to improve generation quality in language models (Adiwar-\n",
      "dana et al., 2020; Shen et al., 2021). Thoppilan et al. (2022) collect additional human annotations\n",
      "to train a re-ranker for response ﬁltering. Cobbe et al. (2021) train a “veriﬁer” to re-rank generated\n",
      "solutions, which substantially improves the solve rate on math tasks compared to just ﬁne-tuning the\n",
      "language model. Elazar et al. (2021) improve the consistency of factual knowledge extraction by\n",
      "extending pre-training with an additional consistency loss. All these methods require either training\n",
      "an additional re-ranker or collecting additional human annotation, while self-consistency requires no\n",
      "additional training, ﬁne-tuning, nor extra data collection.\n",
      "Extract reasoning paths. Some previous work has considered task-speciﬁc approaches for iden-\n",
      "tifying reasoning paths, such as constructing semantic graphs (Xu et al., 2021a), learning an RNN\n",
      "to retrieve reasoning paths over the Wikipedia graph (Asai et al., 2020), ﬁne-tuning with human\n",
      "annotated reasoning paths on math problems (Cobbe et al., 2021), or training an extractor with\n",
      "heuristic-based pseudo reasoning paths (Chen et al., 2019). More recently, the importance of di-\n",
      "versity in the reasoning processes has been noticed, but only leveraged via task-speciﬁc training,\n",
      "either through an additional QA model over extracted reasoning paths (Chen et al., 2019), or by the\n",
      "introduction of latent variables in a commonsense knowledge graph (Yu et al., 2022). Compared to\n",
      "these approaches, self-consistency is far simpler and requires no additional training. The approach\n",
      "we propose simply couples the generation of reasoning paths and a ﬁnal answer by sampling from\n",
      "the decoder, using aggregation to recover the most consistent answer without additional modules.\n",
      "Consistency in language models. Some prior work has shown that language models can suffer\n",
      "from inconsistency in conversation (Adiwardana et al., 2020), explanation generation (Camburu et al.,\n",
      "2020), and factual knowledge extraction (Elazar et al., 2021). Welleck et al. (2020) use “consistency”\n",
      "to refer to generating an inﬁnite-length sequence in recurrent language models. Nye et al. (2021)\n",
      "improve the logical consistency of samples from a System 1 model by adding a System 2-inspired\n",
      "logical reasoning module. In this paper we focus on a slightly different notion of “consistency”, i.e.,\n",
      "utilizing answer consistency among diverse reasoning paths to improve accuracy.\n",
      "5 C ONCLUSION AND DISCUSSION\n",
      "We introduced a simple yet effective method called self-consistency, and observed that it signiﬁcantly\n",
      "improves accuracy in a range of arithmetic and commonsense reasoning tasks, across four large\n",
      "language models with varying scales. Beyond accuracy gains, self-consistency is also useful for\n",
      "collecting rationales when performing reasoning tasks with language models, and for providing\n",
      "uncertainty estimates and improved calibration of language model outputs.\n",
      "One limitation of self-consistency is that it incurs more computation cost. In practice people can try a\n",
      "small number of paths (e.g., 5 or 10) as a starting point to realize most of the gains while not incurring\n",
      "too much cost, as in most cases the performance saturates quickly (Figure 2). As part of future work,\n",
      "one could use self-consistency to generate better supervised data to ﬁne-tune the model, such that the\n",
      "model can give more accurate predictions in a single inference run after ﬁne-tuning. In addition, we\n",
      "observed that language models can sometimes generate incorrect or nonsensical reasoning paths (e.g.,\n",
      "the StrategyQA example in Table 4, the two population numbers are not exactly correct), and further\n",
      "work is needed to better ground models’ rationale generations.\n",
      "9\n",
      "Published as a conference paper at ICLR 2023\n",
      "REPRODUCIBILITY STATEMENT\n",
      "In experiments, we included four different language models with varying scales. Two of them are pub-\n",
      "lic models: UL2 is a completely open-sourced model with model checkpoints available at https://\n",
      "github.com/google-research/google-research/tree/master/ul2 ; GPT-3 is\n",
      "also a public model with public API available at https://openai.com/api/ . For GPT-3,\n",
      "we have included two public engines (“code-davinci-001” and “code-davinci-002”) to further aid\n",
      "reproducibility, as Codex is currently free so anyone can reproduce the results. In addition, as our\n",
      "results make use of LaMDA-137B and PaLM-540B that are not publicly available, we provide the\n",
      "exact input prompts for all tasks in Appendix A.3 (and note that we do not perform any ﬁnetuning\n",
      "and only apply prompting to off-the-shelf language models).\n",
      "ETHICS STATEMENT\n",
      "As we stated in the discussion, language models can sometimes generate nonsensical or non-factual\n",
      "reasoning paths, so one should use language models’ outputs with extra caution. We deal with\n",
      "reasoning tasks mostly and the generated rationales are only used for inspecting how a model reaches\n",
      "its answer. One could potentially use the generated rationales to further check why the model makes\n",
      "certain mistakes or whether the model contains any biases when performing a certain task. For\n",
      "language model in real-world use, further work is needed to better ground models’ predictions and\n",
      "improve model’s factuality and safety, to ensure the models do not cause harms to users.\n",
      "REFERENCES\n",
      "David H. Ackley, Geoffrey E. Hinton, and Terrence J. Sejnowski. A learning algorithm for boltzmann\n",
      "machines. Cognitive Science , 9(1):147–169, 1985. ISSN 0364-0213. URL https://www.\n",
      "sciencedirect.com/science/article/pii/S0364021385800124 .\n",
      "Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel, Romal Thoppilan,\n",
      "Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, and Quoc V . Le. Towards a human-like\n",
      "open-domain chatbot, 2020.\n",
      "Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh\n",
      "Hajishirzi. MathQA: Towards interpretable math word problem solving with operation-based\n",
      "formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the\n",
      "Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long\n",
      "and Short Papers) , pp. 2357–2367. Association for Computational Linguistics, June 2019. URL\n",
      "https://aclanthology.org/N19-1245 .\n",
      "Daniel Andor, Luheng He, Kenton Lee, and Emily Pitler. Giving BERT a calculator: Finding\n",
      "operations and arguments with reading comprehension. In Proceedings of the 2019 Conference on\n",
      "Empirical Methods in Natural Language Processing and the 9th International Joint Conference\n",
      "on Natural Language Processing (EMNLP-IJCNLP) , 2019. URL https://aclanthology.\n",
      "org/D19-1609 .\n",
      "Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, and Caiming Xiong. Learn-\n",
      "ing to retrieve reasoning paths over wikipedia graph for question answering. In International\n",
      "Conference on Learning Representations , 2020. URL https://openreview.net/forum?\n",
      "id=SJgVHkrYDH .\n",
      "Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and\n",
      "Idan Szpektor. The second pascal recognising textual entailment challenge. In Proceedings of the\n",
      "second PASCAL challenges workshop on recognising textual entailment , 2006.\n",
      "Dhruv Batra, Payman Yadollahpour, Abner Guzman-Rivera, and Gregory Shakhnarovich. Diverse\n",
      "m-best solutions in markov random ﬁelds. In Proceedings of the 12th European Conference on\n",
      "Computer Vision - Volume Part V , ECCV’12, pp. 1–16, Berlin, Heidelberg, 2012. Springer-Verlag.\n",
      "ISBN 9783642337147. URL https://doi.org/10.1007/978-3-642-33715-4_1 .\n",
      "10\n",
      "Published as a conference paper at ICLR 2023\n",
      "Luisa Bentivogli, Peter Clark, Ido Dagan, and Danilo Giampiccolo. The ﬁfth pascal recognizing\n",
      "textual entailment challenge. In TAC, 2009.\n",
      "BIG-bench collaboration. Beyond the imitation game: Measuring and extrapolating the capabil-\n",
      "ities of language models. In preparation , 2021. URL https://github.com/google/\n",
      "BIG-bench/ .\n",
      "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\n",
      "Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\n",
      "Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,\n",
      "Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\n",
      "Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\n",
      "and Dario Amodei. Language models are few-shot learners. In Advances in Neural Information\n",
      "Processing Systems , 2020. URL https://proceedings.neurips.cc/paper/2020/\n",
      "file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf .\n",
      "Oana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom. e-\n",
      "snli: Natural language inference with natural language explanations. In S. Ben-\n",
      "gio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett\n",
      "(eds.), Advances in Neural Information Processing Systems 31 , pp. 9539–9549.\n",
      "Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/\n",
      "8163-e-snli-natural-language-inference-with-natural-language-explanations.\n",
      "pdf.\n",
      "Oana-Maria Camburu, Brendan Shillingford, Pasquale Minervini, Thomas Lukasiewicz, and Phil\n",
      "Blunsom. Make up your mind! adversarial generation of inconsistent natural language explanations.\n",
      "InProceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pp.\n",
      "4157–4165, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.\n",
      "acl-main.382. URL https://aclanthology.org/2020.acl-main.382 .\n",
      "Jifan Chen, Shih-Ting Lin, and Greg Durrett. Multi-hop question answering via reasoning chains.\n",
      "CoRR , abs/1910.02610, 2019. URL http://arxiv.org/abs/1910.02610 .\n",
      "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\n",
      "Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large\n",
      "language models trained on code. arXiv preprint arXiv:2107.03374 , 2021.\n",
      "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\n",
      "Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\n",
      "Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\n",
      "Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\n",
      "Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\n",
      "skaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\n",
      "Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph,\n",
      "Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M.\n",
      "Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon\n",
      "Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\n",
      "Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean,\n",
      "Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways, 2022. URL\n",
      "https://arxiv.org/abs/2204.02311 .\n",
      "Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina\n",
      "Toutanova. Boolq: Exploring the surprising difﬁculty of natural yes/no questions. In NAACL ,\n",
      "2019.\n",
      "Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and\n",
      "Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge.\n",
      "ArXiv , abs/1803.05457, 2018.\n",
      "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\n",
      "Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John\n",
      "Schulman. Training veriﬁers to solve math word problems, 2021.\n",
      "11\n",
      "Published as a conference paper at ICLR 2023\n",
      "Ido Dagan, Oren Glickman, and Bernardo Magnini. The pascal recognising textual entailment\n",
      "challenge. In Machine Learning Challenges Workshop , pp. 177–190. Springer, 2005.\n",
      "Bryan Eikema and Wilker Aziz. Is MAP decoding all you need? the inadequacy of the mode in neural\n",
      "machine translation. In Proceedings of the 28th International Conference on Computational Lin-\n",
      "guistics , pp. 4506–4520, Barcelona, Spain (Online), December 2020. International Committee on\n",
      "Computational Linguistics. URL https://aclanthology.org/2020.coling-main.\n",
      "398.\n",
      "Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich\n",
      "Schütze, and Yoav Goldberg. Measuring and improving consistency in pretrained language\n",
      "models. Transactions of the Association for Computational Linguistics , 9:1012–1031, 2021. doi:\n",
      "10.1162/tacl_a_00410. URL https://aclanthology.org/2021.tacl-1.60 .\n",
      "Jonathan St BT Evans. Intuition and reasoning: A dual-process perspective. Psychological Inquiry ,\n",
      "21(4):313–326, 2010.\n",
      "Angela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. In Proceedings\n",
      "of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long\n",
      "Papers) , pp. 889–898, Melbourne, Australia, July 2018. Association for Computational Linguistics.\n",
      "doi: 10.18653/v1/P18-1082. URL https://aclanthology.org/P18-1082 .\n",
      "Jessica Ficler and Yoav Goldberg. Controlling linguistic style aspects in neural language generation. In\n",
      "Proceedings of the Workshop on Stylistic Variation , pp. 94–104, Copenhagen, Denmark, September\n",
      "2017. Association for Computational Linguistics. doi: 10.18653/v1/W17-4912. URL https:\n",
      "//aclanthology.org/W17-4912 .\n",
      "Tianyu Gao, Adam Fisch, and Danqi Chen. Making pre-trained language models better few-shot\n",
      "learners. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguis-\n",
      "tics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long\n",
      "Papers) , pp. 3816–3830, Online, August 2021. Association for Computational Linguistics. doi:\n",
      "10.18653/v1/2021.acl-long.295. URL https://aclanthology.org/2021.acl-long.\n",
      "295.\n",
      "Mor Geva, Ankit Gupta, and Jonathan Berant. Injecting numerical reasoning skills into language\n",
      "models. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguis-\n",
      "tics, 2020. doi: 10.18653/v1/2020.acl-main.89. URL https://aclanthology.org/2020.\n",
      "acl-main.89 .\n",
      "Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle\n",
      "use a laptop? A question answering benchmark with implicit reasoning strategies. Transactions of\n",
      "the Association for Computational Linguistics , 2021. URL https://aclanthology.org/\n",
      "2021.tacl-1.21 .\n",
      "Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. The third pascal recognizing\n",
      "textual entailment challenge. In Proceedings of the ACL-PASCAL workshop on textual entailment\n",
      "and paraphrasing , pp. 1–9. Association for Computational Linguistics, 2007.\n",
      "Ari Holtzman, Jan Buys, Maxwell Forbes, Antoine Bosselut, David Golub, and Yejin Choi. Learning\n",
      "to write with cooperative discriminators. In Proceedings of the 56th Annual Meeting of the\n",
      "Association for Computational Linguistics (Volume 1: Long Papers) , pp. 1638–1649, Melbourne,\n",
      "Australia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1152.\n",
      "URLhttps://aclanthology.org/P18-1152 .\n",
      "Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. The curious case of neural text\n",
      "degeneration. In International Conference on Learning Representations , 2020. URL https:\n",
      "//openreview.net/forum?id=rygGQyrFvH .\n",
      "Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. Learning to\n",
      "solve arithmetic word problems with verb categorization. In Proceedings of the 2014 Conference on\n",
      "Empirical Methods in Natural Language Processing (EMNLP) , 2014. doi: 10.3115/v1/D14-1058.\n",
      "URLhttps://aclanthology.org/D14-1058 .\n",
      "12\n",
      "Published as a conference paper at ICLR 2023\n",
      "Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, and Han-\n",
      "naneh Hajishirzi. UNIFIEDQA: Crossing format boundaries with a single QA system. In Findings\n",
      "of the Association for Computational Linguistics: EMNLP 2020 , pp. 1896–1907, Online, Novem-\n",
      "ber 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.ﬁndings-emnlp.171.\n",
      "URLhttps://aclanthology.org/2020.findings-emnlp.171 .\n",
      "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\n",
      "language models are zero-shot reasoners. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave,\n",
      "and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems , 2022. URL\n",
      "https://openreview.net/forum?id=e2TBb5y0yFf .\n",
      "Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. MAWPS:\n",
      "A math word problem repository. In Proceedings of the 2016 Conference of the North American\n",
      "Chapter of the Association for Computational Linguistics: Human Language Technologies , 2016.\n",
      "doi: 10.18653/v1/N16-1136. URL https://aclanthology.org/N16-1136 .\n",
      "Yihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,\n",
      "and Ee-Peng Lim. MWPToolkit: An open-source framework for deep learning-based math word\n",
      "problem solvers. arXiv preprint arXiv:2109.00799 , 2021. URL https://arxiv.org/abs/\n",
      "2109.00799 .\n",
      "Jiwei Li and Dan Jurafsky. Mutual information and diverse decoding improve neural machine\n",
      "translation, 2016. URL https://arxiv.org/abs/1601.00372 .\n",
      "Jiwei Li, Will Monroe, and Dan Jurafsky. A simple, fast diverse decoding algorithm for neural\n",
      "generation. CoRR , abs/1611.08562, 2016. URL http://arxiv.org/abs/1611.08562 .\n",
      "Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale genera-\n",
      "tion: Learning to solve and explain algebraic word problems. In Proceedings of the 55th Annual\n",
      "Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , 2017. doi:\n",
      "10.18653/v1/P17-1015. URL https://aclanthology.org/P17-1015 .\n",
      "Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. Fantastically\n",
      "ordered prompts and where to ﬁnd them: Overcoming few-shot prompt order sensitivity. ArXiv ,\n",
      "abs/2104.08786, 2021.\n",
      "Clara Meister, Tiago Pimentel, Gian Wiher, and Ryan Cotterell. Typical decoding for natural language\n",
      "generation. arXiv preprint arXiv:2202.00666 , 2022.\n",
      "Shen Yun Miao, Chao Chun Liang, and Keh Yih Su. A diverse corpus for evaluating and developing\n",
      "English math word problem solvers. In Proceedings of the 58th Annual Meeting of the Asso-\n",
      "ciation for Computational Linguistics , 2020. URL https://aclanthology.org/2020.\n",
      "acl-main.92 .\n",
      "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. Adver-\n",
      "sarial NLI: A new benchmark for natural language understanding. In Proceedings of the 58th\n",
      "Annual Meeting of the Association for Computational Linguistics . Association for Computational\n",
      "Linguistics, 2020.\n",
      "Maxwell Nye, Michael Henry Tessler, Joshua B. Tenenbaum, and Brenden M. Lake. Improving\n",
      "coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning.\n",
      "In A. Beygelzimer, Y . Dauphin, P. Liang, and J. Wortman Vaughan (eds.), Advances in Neural\n",
      "Information Processing Systems , 2021. URL https://openreview.net/forum?id=\n",
      "uyKk_avJ-p4 .\n",
      "Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve simple\n",
      "math word problems? In Proceedings of the 2021 Conference of the North American Chapter of\n",
      "the Association for Computational Linguistics: Human Language Technologies , pp. 2080–2094,\n",
      "Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.\n",
      "168. URL https://aclanthology.org/2021.naacl-main.168 .\n",
      "Xinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and\n",
      "Weizhu Chen. Reasoning like program executors, 2022.\n",
      "13\n",
      "Published as a conference paper at ICLR 2023\n",
      "Piotr Pi˛ ekos, Mateusz Malinowski, and Henryk Michalewski. Measuring and improving BERT’s\n",
      "mathematical abilities by predicting the order of reasoning. In Proceedings of the 59th Annual Meet-\n",
      "ing of the Association for Computational Linguistics and the 11th International Joint Conference on\n",
      "Natural Language Processing (Volume 2: Short Papers) , 2021. doi: 10.18653/v1/2021.acl-short.49.\n",
      "URLhttps://aclanthology.org/2021.acl-short.49 .\n",
      "Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language\n",
      "models are unsupervised multitask learners. 2019.\n",
      "Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John\n",
      "Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. Scaling language models:\n",
      "Methods, analysis & insights from training gopher. arXiv preprint arXiv:2112.11446 , 2021.\n",
      "Qiu Ran, Yankai Lin, Peng Li, Jie Zhou, and Zhiyuan Liu. NumNet: Machine reading comprehension\n",
      "with numerical reasoning. In Proceedings of the 2019 Conference on Empirical Methods in Natural\n",
      "Language Processing and the 9th International Joint Conference on Natural Language Processing\n",
      "(EMNLP-IJCNLP) , 2019. doi: 10.18653/v1/D19-1251. URL https://aclanthology.\n",
      "org/D19-1251 .\n",
      "Subhro Roy and Dan Roth. Solving general arithmetic word problems. In Proceedings of the 2015\n",
      "Conference on Empirical Methods in Natural Language Processing , 2015. doi: 10.18653/v1/\n",
      "D15-1202. URL https://aclanthology.org/D15-1202 .\n",
      "Jianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, and Qun Liu. Generate\n",
      "& rank: A multi-task framework for math word problems. In Findings of the Association for\n",
      "Computational Linguistics: EMNLP 2021 , pp. 2269–2279, Punta Cana, Dominican Republic,\n",
      "November 2021. Association for Computational Linguistics. URL https://aclanthology.\n",
      "org/2021.findings-emnlp.195 .\n",
      "Freda Shi, Daniel Fried, Marjan Ghazvininejad, Luke Zettlemoyer, and Sida I. Wang. Natural\n",
      "language to code translation with execution. In Proceedings of the 2022 Conference on Empirical\n",
      "Methods in Natural Language Processing , pp. 3533–3546, Abu Dhabi, United Arab Emirates,\n",
      "December 2022. Association for Computational Linguistics. URL https://aclanthology.\n",
      "org/2022.emnlp-main.231 .\n",
      "Keith E Stanovich and Richard F West. Individual differences in reasoning: Implications for\n",
      "the rationality debate? Behavioral and brain sciences , 23(5):645–665, 2000. URL https:\n",
      "//pubmed.ncbi.nlm.nih.gov/11301544/ .\n",
      "Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. CommonsenseQA: A question\n",
      "answering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference of\n",
      "the North American Chapter of the Association for Computational Linguistics: Human Language\n",
      "Technologies, Volume 1 (Long and Short Papers) , 2019. URL https://aclanthology.\n",
      "org/N19-1421 .\n",
      "Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung,\n",
      "Dara Bahri, Tal Schuster, Steven Zheng, Denny Zhou, Neil Houlsby, and Donald Metzler. Unifying\n",
      "language learning paradigms, 2022. URL https://arxiv.org/abs/2205.05131 .\n",
      "Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze\n",
      "Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. Lamda: Language models for dialog\n",
      "applications. arXiv preprint arXiv:2201.08239 , 2022. URL https://arxiv.org/abs/\n",
      "2201.08239 .\n",
      "Ashwin Vijayakumar, Michael Cogswell, Ramprasaath Selvaraju, Qing Sun, Stefan Lee, David\n",
      "Crandall, and Dhruv Batra. Diverse beam search for improved description of complex scenes.\n",
      "Proceedings of the AAAI Conference on Artiﬁcial Intelligence , 32, Apr. 2018. URL https:\n",
      "//ojs.aaai.org/index.php/AAAI/article/view/12340 .\n",
      "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc\n",
      "Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models.\n",
      "Conference on Neural Information Processing Systems (NeurIPS) , 2022. URL https://arxiv.\n",
      "org/pdf/2201.11903 .\n",
      "14\n",
      "Published as a conference paper at ICLR 2023\n",
      "Sean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang, and Kyunghyun Cho. Consistency\n",
      "of a recurrent language model with respect to incomplete decoding. In Proceedings of the 2020\n",
      "Conference on Empirical Methods in Natural Language Processing (EMNLP) , pp. 5553–5568,\n",
      "Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.\n",
      "emnlp-main.448. URL https://aclanthology.org/2020.emnlp-main.448 .\n",
      "Weiwen Xu, Yang Deng, Huihui Zhang, Deng Cai, and Wai Lam. Exploiting reasoning chains\n",
      "for multi-hop science question answering. In Findings of the Association for Computational\n",
      "Linguistics: EMNLP 2021 , pp. 1143–1156, Punta Cana, Dominican Republic, November 2021a.\n",
      "Association for Computational Linguistics. URL https://aclanthology.org/2021.\n",
      "findings-emnlp.99 .\n",
      "Yichong Xu, Chenguang Zhu, Shuohang Wang, Siqi Sun, Hao Cheng, Xiaodong Liu, Jianfeng\n",
      "Gao, Pengcheng He, Michael Zeng, and Xuedong Huang. Human parity on commonsenseqa:\n",
      "Augmenting self-attention with external attention, 2021b. URL https://arxiv.org/abs/\n",
      "2112.03254 .\n",
      "Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and\n",
      "Christopher D. Manning. HotpotQA: A dataset for diverse, explainable multi-hop question answer-\n",
      "ing. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing ,\n",
      "pp. 2369–2380, Brussels, Belgium, October-November 2018. Association for Computational Lin-\n",
      "guistics. doi: 10.18653/v1/D18-1259. URL https://aclanthology.org/D18-1259 .\n",
      "Xi Ye and Greg Durrett. The unreliability of explanations in few-shot prompting for textual reasoning.\n",
      "In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in\n",
      "Neural Information Processing Systems , 2022. URL https://openreview.net/forum?\n",
      "id=Bct2f8fRd8S .\n",
      "Wenhao Yu, Chenguang Zhu, Lianhui Qin, Zhihan Zhang, Tong Zhao, and Meng Jiang. Diversifying\n",
      "content generation for commonsense reasoning with mixture of knowledge graph experts. In\n",
      "Findings of Annual Meeting of the Association for Computational Linguistics (ACL) , 2022.\n",
      "Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving\n",
      "few-shot performance of language models. In Marina Meila and Tong Zhang (eds.), Proceed-\n",
      "ings of the 38th International Conference on Machine Learning , volume 139 of Proceedings of\n",
      "Machine Learning Research . PMLR, 2021. URL https://proceedings.mlr.press/\n",
      "v139/zhao21c.html .\n",
      "15\n",
      "Published as a conference paper at ICLR 2023\n",
      "A A PPENDIX\n",
      "A.1 A DDITIONAL EXPERIMENT RESULTS\n",
      "A.1.1 R OBUSTNESS TO SAMPLING STRATEGIES AND PARAMETERS\n",
      "In Figure 6 we ablate the results with respect to different sampling strategies and parameters by\n",
      "varying Tin temperature sampling and kin Top- ksampling, on LaMDA-137B. We show that\n",
      "self-consistency is robust to various sampling strategies and parameters.\n",
      "481216202428323640\n",
      "#Sampled Reasoning Paths182022242628Accuracy (%)\n",
      "T=0.7, k=40\n",
      "T=0.5, k=40\n",
      "T=0.3, k=40\n",
      "T=0.5, k=20\n",
      "T=0.5, no top k\n",
      "Greedy Decode\n",
      "Figure 6: GSM8K accuracy over LaMDA-137B. Self-consistency works under various sampling\n",
      "strategies and sampling parameters.\n",
      "In Figure 7 and Figure 8, we show the results of self-consistency compared with greedy decoding a\n",
      "single path over LaMDA-137B and PaLM-540B, respectively. Self-consistency improves over greedy\n",
      "decode by a quite signiﬁcant margin on both models, on top of high accuracy already achieved by\n",
      "scaling up model sizes.\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths505560657075Accuracy (%)\n",
      "MultiArith\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths4446485052545658\n",
      "ASDiv\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths3336394245485154\n",
      "SVAMP\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths1416182022242628\n",
      "GSM8K\n",
      "Greedy Decode (Single-path)\n",
      "Self Consistency (Multi-path)\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths56586062Accuracy (%)\n",
      "Commonsense QA\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths62636465666768\n",
      "Strategy QA\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths687072747678\n",
      "ARC (Easy)\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths505254565860\n",
      "ARC (Challenge)\n",
      "Greedy Decode (Single-path)\n",
      "Self Consistency (Multi-path)\n",
      "Figure 7: Self-consistency (blue) signiﬁcantly improves accuracy across various arithmetic and\n",
      "commonsense reasoning tasks, over LaMDA-137B. Sampling a higher number of diverse reasoning\n",
      "paths consistently improves reasoning accuracy.\n",
      "We further show additional sampled reasoning paths from the LaMDA-137B model in Table 12, and\n",
      "sampled reasoning paths from the PaLM-540B model in Table 13. We see that the diversity in the\n",
      "additionally sampled reasoning paths indeed helps the model arrive at a more correct ﬁnal answer\n",
      "after aggregation.\n",
      "A.1.2 R OBUSTNESS TO DIFFERENT SETS OF PROMPTS\n",
      "In Table 9, we further show that self-consistency is quite robust to different sets of input prompts.\n",
      "We manually wrote 3 different sets of chain-of-thought as prompts to the model. Across all sets of\n",
      "prompts, self-consistency yields consistent gains over the original CoT approach.\n",
      "A.1.3 C OMPARED TO MODEL ENSEMBLES\n",
      "Additionally, we provide results of directly ensembling the outputs from multiple language models .\n",
      "The results are shown in Table 10, by greedily decoding sequences from 3 language models and\n",
      "16\n",
      "Published as a conference paper at ICLR 2023\n",
      "0510152025303540\n",
      "#Sampled Reasoning Chains8688909294Accuracy (%)\n",
      "AddSub\n",
      "0510152025303540\n",
      "#Sampled Reasoning Chains727476788082Accuracy (%)\n",
      "ASDiv\n",
      "0510152025303540\n",
      "#Sampled Reasoning Chains30333639424548Accuracy (%)\n",
      "AQuA\n",
      "Greedy Decode (Single-path)\n",
      "Self Consistency (Multi-path)\n",
      "0510152025303540\n",
      "#Sampled Reasoning Chains889092949698Accuracy (%)\n",
      "MultiArith\n",
      "0510152025303540\n",
      "#Sampled Reasoning Chains70.072.575.077.580.082.585.087.5Accuracy (%)\n",
      "SVAMP\n",
      "0510152025303540\n",
      "#Sampled Reasoning Chains505560657075Accuracy (%)\n",
      "GSM8K\n",
      "Greedy Decode (Single-path)\n",
      "Self Consistency (Multi-path)\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths7475767778798081Accuracy (%)\n",
      "Commonsense QA\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths7476788082\n",
      "Strategy QA\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths8890929496\n",
      "ARC (Easy)\n",
      "0510152025303540\n",
      "#Sampled Reasoning Paths788082848688\n",
      "ARC (Challenge)\n",
      "Greedy Decode (Single-path)\n",
      "Self Consistency (Multi-path)\n",
      "Figure 8: Self-consistency (blue) signiﬁcantly improves accuracy across various arithmetic and\n",
      "commonsense reasoning tasks, over PaLM-540B. Sampling a higher number of diverse reasoning\n",
      "paths consistently helps reasoning accuracy.\n",
      "Prompt set 1 (used in the main text) Prompt set 2 Prompt set 3\n",
      "CoT (Wei et al., 2022) 56.5 54.6 54.0\n",
      "Self-consistency 74.4 (+17.9) 72.1 (+17.5) 70.4 (+16.4)\n",
      "Table 9: GSM8K accuracy over PaLM-540B. The results show robustness of self-consistency with\n",
      "respect to different prompts in the input.\n",
      "taking the majority vote (averaged over 10 runs). Note this is a typical ensemble approach (averaging\n",
      "over the predictions over multiple models) and it achieves a performance signiﬁcantly worse than\n",
      "self-consistency (self-consistency over PaLM-540B gets an accuracy of 74.4%), as lower-capacity\n",
      "models drag down the performance of higher-capacity models. In addition, this approach is limited in\n",
      "two ways: 1) It requires multiple models for an ensemble which might not always be available, while\n",
      "self-consistency only requires one single model to “self-ensemble”; 2) If one of the models is much\n",
      "weaker, it can actually hurt the ﬁnal performance.\n",
      "Method GSM8K accuracy\n",
      "Single model PaLM-540B, greedy / self-consistency 56.5 / 74.4\n",
      "Ensemble of modelsLaMDA-137B + PaLM-540B 36.9 ±0.5\n",
      "PaLM-540B + GPT-3 (code-davinci-001, 175B) 36.6 ±0.4\n",
      "LaMDA-137B + GPT-3 (code-davinci-001, 175B) 16.0 ±0.8\n",
      "LaMDA-137B + PaLM-540B + GPT-3 (code-davinci-001, 175B) 33.3 ±0.7\n",
      "Table 10: Comparison of GSM8K accuracy over multiple-model ensembles.\n",
      "A.1.4 C OMBINING SELF -CONSISTENCY WITH OTHER ENSEMBLING STRATEGIES\n",
      "Self-consistency is completely compatible with other ensemble strategies, although the gains achieved\n",
      "by self-consistency are signiﬁcantly higher than other ensemble strategies (and can “override” the\n",
      "performance gains achieved by other ensemble strategies). We further performed experiments and\n",
      "include the results in Table 11 (for a fair comparison, we use 40 sets of prompts, or 40 prompt\n",
      "permutations to compare with self-consistency with 40 paths, all experiments are based on PaLM-\n",
      "540B).\n",
      "17\n",
      "Published as a conference paper at ICLR 2023\n",
      "GSM8K accuracy\n",
      "Different sets of prompts (x40) 58.9\n",
      "Prompt-permutation (x40) 59.6\n",
      "Self-consistency (x40) 74.4\n",
      "Self-consistency + different sets of prompts (x40) 75.4\n",
      "Self-consistency + prompt-permutation (x40) 73.8\n",
      "Table 11: Combining self-consistency with other ensembling strategies.\n",
      "A.2 D ETAILS ON RESOURCES AND INFERENCE\n",
      "For all four language models we perform prompting-based inference only. For UL2 we use TPU v3\n",
      "(2x2 conﬁguration, 4 chips, 8 cores). For GPT-3 models the experiments are done though the public\n",
      "API.10For LaMDA-137B we use TPU v3 (8x8 conﬁguration, 64 chips, 128 cores). For PaLM-540B\n",
      "we use TPU v4 (4x4x12 conﬁguration, 192 chips, 384 cores). Most inference jobs take 1 to 4 hours\n",
      "(over about 1,000 examples) for each task on UL2 and LaMDA-137B, and about 2 to 12 hours on\n",
      "PaLM-540B. Some tasks (e.g., commonsense reasoning) take longer but do not exceed 2 days for\n",
      "each task.\n",
      "For GPT-3 models, we use 128 max tokens for all methods, without frequency penalty or presence\n",
      "penalty. For all models, we take the generated outputs until the start of the next “Q:\" to parse the ﬁnal\n",
      "answers, consistent with our prompting format.\n",
      "Question Greedy Decode Sampled Path 1 Sampled Path 2\n",
      "[MultiArith] Sam had 10 socks.\n",
      "If he threw away 3 old ones\n",
      "that didn’t ﬁt and bought 36 new\n",
      "ones, how many socks would he\n",
      "have?Sam had 10 socks. He threw\n",
      "away 3 old ones that didn’t ﬁt.\n",
      "He bought 36 new ones. That\n",
      "means he has 10 + 36 - 3 = 41\n",
      "socks. The answer is 41.Sam had 10 socks. He\n",
      "threw away 3 old ones. So\n",
      "now he has 7 left. Then he\n",
      "bought 36 new ones. So\n",
      "now he has 7 + 36 = 43\n",
      "socks. The answer is 43.He had 10 socks. He threw away\n",
      "3 old ones that didn’t ﬁt. He\n",
      "bought 36 new ones. So in total\n",
      "he has 10 - 3 + 36 = 43 socks. The\n",
      "answer is 43.\n",
      "[SVAMP] In a school there are\n",
      "697 girls and the rest are boys.\n",
      "If there are 228 more girls than\n",
      "boys. How many boys are there\n",
      "in that school?There are 697 girls and the rest\n",
      "are boys. That means there are\n",
      "697 + 228 = 925 girls. The\n",
      "rest are boys. So the number of\n",
      "boys is 925 - 697 = 228. The\n",
      "answer is 228.The number of boys is the\n",
      "difference between 697\n",
      "and 228. This is 697 - 228\n",
      "= 469. The answer is 469.In the beginning there are 697\n",
      "girls and the rest are boys. So, the\n",
      "number of boys must be 697 - 228\n",
      "= 469 boys. The answer is 469.\n",
      "[AQuA] There are 10 oranges in\n",
      "a basket. Find the no. of ways in\n",
      "which 2 oranges are chosen from\n",
      "the basket? (a) 45 (b) 90 (c) 120\n",
      "(d) 150 (e) 180There are 10 oranges in a bas-\n",
      "ket. So there are 10 ways\n",
      "in which 2 oranges are chosen\n",
      "from the basket.There are 10 oranges in a\n",
      "basket. We need to choose\n",
      "2 oranges from the basket.\n",
      "So the number of ways are\n",
      "10C2. So the answer is (a).There are 10 oranges in the bas-\n",
      "ket. If you choose 2 oranges, you\n",
      "have 10C2 = 45 ways of choosing\n",
      "2 oranges. So the answer is (a).\n",
      "[CommonsenseQA] The man\n",
      "laid on the soft moss and looked\n",
      "up at the trees, where was the\n",
      "man? (a) niagra falls (b) forest\n",
      "(c) waterfall (d) ground (e) treeThe answer must be something\n",
      "that is soft and mossy. Of the\n",
      "above choices, only ground is\n",
      "soft and mossy. So the answer\n",
      "is (d).The answer must be\n",
      "somewhere where moss\n",
      "is found. Of the above\n",
      "choices, only forests are\n",
      "known for having moss.\n",
      "So the answer is (b).The answer must be a place where\n",
      "the man is laying down and look-\n",
      "ing up at trees. Of the above\n",
      "choices, only forest is a place\n",
      "where people lay down and look\n",
      "at trees. So the answer is (b).\n",
      "[ARC] Which of these will most\n",
      "likely harm a habitat? (a) plant-\n",
      "ing trees. (b) water pollution. (c)\n",
      "rainfall. (d) sunlight.Planting trees will not harm a\n",
      "habitat. So the answer is (a).The answer is (b), water\n",
      "pollution, because it will\n",
      "most likely harm the habi-\n",
      "tat. The other answers are\n",
      "not likely to harm the habi-\n",
      "tat.The answer is (b), water pollution.\n",
      "Trees are good for a habitat, rain-\n",
      "fall is necessary for a habitat, and\n",
      "sunlight is necessary for a habitat.\n",
      "So the answer is (b).\n",
      "[ARC-challenge] Which pro-\n",
      "cess in the carbon cycle takes the\n",
      "longest to complete? (a) emis-\n",
      "sion of waste. (b) respiration in\n",
      "animals. (c) photosynthesis in\n",
      "plants. (d) formation of fossil fu-\n",
      "els.The process of photosynthesis\n",
      "in plants takes the longest to\n",
      "complete. So the answer is (c).The formation of fossil fu-\n",
      "els takes the longest time\n",
      "to complete. So the an-\n",
      "swer is (d).The process that takes the longest\n",
      "time to complete is the forma-\n",
      "tion of fossil fuels, which hap-\n",
      "pens over millions of years. So\n",
      "the answer is (d).\n",
      "Table 12: Additional examples where self-consistency helps repair the errors over greedy decode on\n",
      "LaMDA-137B. Two sampled reasoning paths that are consistent with the ground truth are shown.\n",
      "10https://beta.openai.com/docs/api-reference/making-requests\n",
      "18\n",
      "Published as a conference paper at ICLR 2023\n",
      "Question Greedy Decode Sampled Path 1 Sampled Path 2\n",
      "[GSM8K] Kyle bought last\n",
      "year’s best-selling book for\n",
      "$19.50. This is with a 25% dis-\n",
      "count from the original price.\n",
      "What was the original price of\n",
      "the book?The book was sold for $19.50.\n",
      "This is 25% less than the origi-\n",
      "nal price. This means the original\n",
      "price was 100%. 25% of 100%\n",
      "is 25%. So the original price\n",
      "was 100% - 25% = 75%. The\n",
      "original price was 75% of $19.50.\n",
      "75% of $19.50 is 75% * $19.50 =\n",
      "$14.625. The answer is $14.625.The original price of the book\n",
      "is $19.50. Since it was dis-\n",
      "counted by 25%, the original\n",
      "price was 19.50 / 0.75 = 26.\n",
      "The answer is 26.Kyle bought a book that is sold\n",
      "for $19.50. With a 25% discount,\n",
      "the original price must be higher.\n",
      "If we call the original price x,\n",
      "then the discounted price is 0.75x.\n",
      "Since this is $19.50, we can write\n",
      "0.75x = 19.50. Solving this, we\n",
      "ﬁnd that the original price is x =\n",
      "19.50 / 0.75 = $26. The answer is\n",
      "$26.\n",
      "[AQuA] The capacity of a\n",
      "tank of dimensions (8 m x 6\n",
      "m x 2.5 m) is (a) 120 litres (b)\n",
      "1200 litres (c) 12000 litres (d)\n",
      "120000 litres (e) None of theseThe volume of the tank is 8 m *\n",
      "6 m * 2.5 m = 120 m3. So the\n",
      "capacity of the tank is 120 m3. So\n",
      "the answer is (c).The volume of the tank is 8m\n",
      "* 6m* 2.5m = 120m3. This is\n",
      "equal to 120000 litres. So the\n",
      "answer is (d)The volume of the tank is 8 m *\n",
      "6 m * 2.5 m = 120 m3. One cu-\n",
      "bic meter contains 1000 litres, so\n",
      "the tank contains 120 m3 * 1000\n",
      "liters/m3 = 120,000 liters. So the\n",
      "answer is (d).\n",
      "[StrategyQA] Yes or no:\n",
      "Can the Great Depression be\n",
      "treated with Prozac?The Great Depression was an\n",
      "economic depression. Prozac is\n",
      "a drug used to treat depression.\n",
      "Thus, the Great Depression could\n",
      "be treated with Prozac. So the an-\n",
      "swer is yes.Prozac is an anti-depressant\n",
      "medication. The Great Depres-\n",
      "sion is not a disease. Thus,\n",
      "Prozac cannot treat the Great\n",
      "Depression. So the answer is\n",
      "no.The Great Depression is a time pe-\n",
      "riod. Prozac is used to treat de-\n",
      "pression (the mental illness). Thus,\n",
      "the Great Depression can not be\n",
      "treated with Prozac. So the answer\n",
      "is no.\n",
      "[ARC-easy] Which source of\n",
      "energy is nonrenewable? (a)\n",
      "coal. (b) sunlight. (c) water.\n",
      "(d) wood.Coal, sunlight, and water are\n",
      "all renewable sources of energy.\n",
      "Wood is a nonrenewable source of\n",
      "energy. So the answer is (d).A nonrenewable source of en-\n",
      "ergy is one in which the source\n",
      "is not replenished in a short\n",
      "amount of time. Thus, the only\n",
      "option that is nonrenewable is\n",
      "coal. So the answer is (a).Coal is a fossil fuel and is formed\n",
      "from dead organisms from the past.\n",
      "Coal cannot be produced in a short\n",
      "period of time, so it is considered\n",
      "a nonrenewable source of energy.\n",
      "So the answer is (a).\n",
      "[ARC-challenge] Students\n",
      "studied the revolution of Earth\n",
      "around the Sun. During which\n",
      "month will Florida have the\n",
      "most sunlight energy avail-\n",
      "able? (a) March. (b) June. (c)\n",
      "September. (d) December.The Earth is closest to the Sun\n",
      "in December, hence Florida will\n",
      "have the most sunlight energy\n",
      "available in December. So the an-\n",
      "swer is (d).Earth is closest to the Sun on\n",
      "June 21, the summer solstice.\n",
      "So the answer is (b).Florida is closer to the sun during\n",
      "June, so it will have the most sun-\n",
      "light energy during that month. So\n",
      "the answer is (b).\n",
      "Table 13: Additional examples where self-consistency helps repair the errors over greedy decode on\n",
      "PaLM-540B. Two sampled reasoning paths that are consistent with the ground truth are shown.\n",
      "A.3 F ULL SETS OF PROMPTS\n",
      "We list the full details of the prompts used for two newly-introduced datasets, AQUA-RAT (Ling\n",
      "et al., 2017) and AI2 Reasoning Challenge (ARC) (Clark et al., 2018), where we manually composed\n",
      "the example chain-of-thought in this paper, in Table 14 and Table 15, respectively.\n",
      "Table 14: Few-shot exemplars for AQUA-RAT.\n",
      "Q:John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the\n",
      "numbers is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\n",
      "A:If 10 is added to each number, then the mean of the numbers also increases by 10. So the new mean\n",
      "would be 50. The answer is (a).\n",
      "Q:If a / b = 3/4 and 8a + 5b = 22,then ﬁnd the value of a. Answer Choices: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e)\n",
      "7/2\n",
      "A:If a / b = 3/4, then b = 4a / 3. So 8a + 5(4a / 3) = 22. This simpliﬁes to 8a + 20a / 3 = 22, which means\n",
      "44a / 3 = 22. So a is equal to 3/2. The answer is (b).\n",
      "Q:A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then ﬁnd the distance? Answer Choices:\n",
      "(a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km\n",
      "A:The distance that the person traveled would have been 20 km/hr * 2.5 hrs = 50 km. The answer is (e).\n",
      "Q:How many keystrokes are needed to type the numbers from 1 to 500? Answer Choices: (a) 1156 (b) 1392\n",
      "(c) 1480 (d) 1562 (e) 1788\n",
      "A:There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401\n",
      "three-digit numbers from 100 to 500. 9 + 90(2) + 401(3) = 1392. The answer is (b).\n",
      "19\n",
      "Published as a conference paper at ICLR 2023\n",
      "Table 15: Few-shot exemplars for ARC easy/challenge.\n",
      "Q:George wants to warm his hands quickly by rubbing them. Which skin surface will produce the most\n",
      "heat? (a) dry palms. (b) wet palms. (c) palms covered with oil. (d) palms covered with lotion.\n",
      "A:Dry surfaces will more likely cause more friction via rubbing than other smoother surfaces, hence dry\n",
      "palms will produce the most heat. The answer is (a).\n",
      "Q:Which factor will most likely cause a person to develop a fever? (a) a leg muscle relaxing after exercise.\n",
      "(b) a bacterial population in the bloodstream. (c) several viral particles on the skin. (d) carbohydrates being\n",
      "digested in the stomach.\n",
      "A:Option (b), bacterial population is the most likely cause for a person developing fever. The answer is (b).\n",
      "Q:Which change in the state of water particles causes the particles to become arranged in a ﬁxed position?\n",
      "(a) boiling. (b) melting. (c) freezing. (d) evaporating.\n",
      "A:When water is freezed, the particles are arranged in a ﬁxed position; the particles are still moving for all\n",
      "other options. The answer is (c).\n",
      "Q:When a switch is used in an electrical circuit, the switch can (a) cause the charge to build. (b) increase\n",
      "and decrease the voltage. (c) cause the current to change direction. (d) stop and start the ﬂow of current.\n",
      "A:The function of a switch is to start and stop the ﬂow of a current. The answer is (d).\n",
      "Table 16: Few-shot exemplars for HotpotQA (closed-book setting).\n",
      "Q:Which magazine was started ﬁrst Arthur’s Magazine or First for Women?\n",
      "A:Arthur’s Magazine started in 1844. First for Women started in 1989. So Arthur’s Magazine was started ﬁrst.\n",
      "The answer is Arthur’s Magazine.\n",
      "Q:The Oberoi family is part of a hotel company that has a head ofﬁce in what city?\n",
      "A:The Oberoi family is part of the hotel company called The Oberoi Group. The Oberoi Group has its head\n",
      "ofﬁce in Delhi. The answer is Delhi.\n",
      "Q:What nationality was James Henry Miller’s wife?\n",
      "A:James Henry Miller’s wife is June Miller. June Miller is an American. The answer is American.\n",
      "Q:The Dutch-Belgian television series that \"House of Anubis\" was based on ﬁrst aired in what year?\n",
      "A:\"House of Anubis\" is based on the Dutch–Belgian television series Het Huis Anubis. Het Huis Anubis is ﬁrst\n",
      "aired in September 2006. The answer is 2006.\n",
      "As additional information, we also list the exact set of prompts used for all arithmetic reasoning tasks\n",
      "in Table 17, since there are multiple sets of prompts introduced in Wei et al. (2022). The prompts for\n",
      "CommonsenseQA and StrategyQA are the same as used in Wei et al. (2022).\n",
      "We provide the exact prompts used for common NLP tasks in the following tables as well, including\n",
      "NLI (Table 18, Table 19, Table 20) and Closed-Book Question-Answering tasks (Table 16, Table 21).\n",
      "20\n",
      "Published as a conference paper at ICLR 2023\n",
      "Table 17: Few-shot exemplars for all arithmetic reasoning tasks, from Wei et al. (2022).\n",
      "Q:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
      "there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A:We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
      "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
      "Q:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A:There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
      "Q:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
      "A:Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\n",
      "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
      "Q:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
      "did Jason give to Denny?\n",
      "A:Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
      "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
      "Q:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does\n",
      "he have now?\n",
      "A:He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\n",
      "in total he has 7 + 2 = 9 toys. The answer is 9.\n",
      "Q:There were nine computers in the server room. Five more computers were installed each day, from\n",
      "monday to thursday. How many computers are now in the server room?\n",
      "A:There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\n",
      "20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\n",
      "The answer is 29.\n",
      "Q:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\n",
      "golf balls did he have at the end of wednesday?\n",
      "A:Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\n",
      "Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
      "Q:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\n",
      "A:She bought 5 bagels for $3 each. This means she spent 5 * $3 = $15 on the bagels. She had $23 in\n",
      "beginning, so now she has $23 - $15 = $8. The answer is 8.\n",
      "21\n",
      "Published as a conference paper at ICLR 2023\n",
      "Table 18: Few-shot exemplars for ANLI.\n",
      "Premise:\n",
      "\"Conceptually cream skimming has two basic dimensions - product and geography.\"\n",
      "Based on this premise, can we conclude the hypothesis \"Product and geography are what make cream skimming\n",
      "work.\" is true?\n",
      "OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:Based on \"cream skimming has two basic dimensions\" we can’t infer that these two dimensions are what\n",
      "make cream skimming work. The answer is it is not possible to tell.\n",
      "Premise:\n",
      "\"One of our member will carry out your instructions minutely.\"\n",
      "Based on this premise, can we conclude the hypothesis \"A member of my team will execute your orders with\n",
      "immense precision.\" is true?\n",
      "OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:\"one of\" means the same as \"a member of\", \"carry out\" means the same as \"execute\", and \"minutely\" means\n",
      "the same as \"immense precision\". The answer is yes.\n",
      "Premise:\n",
      "\"Fun for adults and children.\"\n",
      "Based on this premise, can we conclude the hypothesis \"Fun for only children.\" is true?\n",
      "OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:\"adults and children\" contradicts \"only children\". The answer is no.\n",
      "Premise:\n",
      "\"He turned and smiled at Vrenna.\"\n",
      "Based on this premise, can we conclude the hypothesis \"He smiled at Vrenna who was walking slowly behind\n",
      "him with her mother.\" is true?\n",
      "OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:the premise does not say anything about \"Vrenna was walking\". The answer is it is not possible to tell.\n",
      "Premise:\n",
      "\"well you see that on television also\"\n",
      "Based on this premise, can we conclude the hypothesis \"You can see that on television, as well.\" is true?\n",
      "OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:\"also\" and \"as well\" mean the same thing. The answer is yes.\n",
      "Premise:\n",
      "\"Vrenna and I both fought him and he nearly took us.\"\n",
      "Based on this premise, can we conclude the hypothesis \"Neither Vrenna nor myself have ever fought him.\" is\n",
      "true?\n",
      "OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:\"Vrenna and I both\" contradicts \"neither Vrenna nor myself\". The answer is no.\n",
      "22\n",
      "Published as a conference paper at ICLR 2023\n",
      "Table 19: Few-shot exemplars for e-SNLI (the rationales are crowd-sourced annotations from the\n",
      "original dataset).\n",
      "Premise:\n",
      "\"A person on a horse jumps over a broken down airplane.\"\n",
      "Based on this premise, can we conclude the hypothesis \"A person is training his horse for a competition.\" is true?\n",
      "OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:The person is not necessarily training his horse. The answer is it is not possible to tell.\n",
      "Premise:\n",
      "\"A person on a horse jumps over a broken down airplane.\"\n",
      "Based on this premise, can we conclude the hypothesis \"A person is at a diner, ordering an omelette.\" is true?\n",
      "OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:One jumping horse cannot be in a diner ordering food. The answer is no.\n",
      "Premise:\n",
      "\"A person on a horse jumps over a broken down airplane.\"\n",
      "Based on this premise, can we conclude the hypothesis \"A person is outdoors, on a horse.\" is true?\n",
      "OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:A broken down airplane is outdoors. The answer is yes.\n",
      "Premise:\n",
      "\"Children smiling and waving at camera.\"\n",
      "Based on this premise, can we conclude the hypothesis \"They are smiling at their parents.\" is true?\n",
      "OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:Just because they are smiling and waving at a camera does not imply their parents or anyone is anyone behind\n",
      "it. The answer is it is not possible to tell.\n",
      "Premise:\n",
      "\"Children smiling and waving at camera.\"\n",
      "Based on this premise, can we conclude the hypothesis \"The kids are frowning.\" is true? OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:One cannot be smiling and frowning at the same time. The answer is no.\n",
      "Premise:\n",
      "\"Children smiling and waving at camera.\"\n",
      "Based on this premise, can we conclude the hypothesis \"There are children present.\" is true?\n",
      "OPTIONS:\n",
      "- yes\n",
      "- no\n",
      "- it is not possible to tell\n",
      "A:The children must be present to see them smiling and waving. The answer is yes.\n",
      "23\n",
      "Published as a conference paper at ICLR 2023\n",
      "Table 20: Few-shot exemplars for RTE.\n",
      "Premise:\n",
      "\"No Weapons of Mass Destruction Found in Iraq Yet.\"\n",
      "Based on this premise, can we conclude the hypothesis \"Weapons of Mass Destruction Found in Iraq.\" is true?\n",
      "A:\"No Weapons of Mass Destruction Found\" contradicts \"Weapons of Mass Destruction Found\". The answer is\n",
      "no.\n",
      "Premise:\n",
      "\"A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful\n",
      "gathered in downtown Chicago to mark the installation of new Pope Benedict XVI.\"\n",
      "Based on this premise, can we conclude the hypothesis \"Pope Benedict XVI is the new leader of the Roman\n",
      "Catholic Church.\" is true?’\n",
      "A:\"installation of new Pope Benedict XVI.\" means \"Pope Benedict XVI is the new leader\". The answer is yes.\n",
      "Premise:\n",
      "\"A man is due in court later charged with the murder 26 years ago of a teenager whose case was the ﬁrst to\n",
      "be featured on BBC One’s Crimewatch. Colette Aram, 16, was walking to her boyfriend’s house in Keyworth,\n",
      "Nottinghamshire, on 30 October 1983 when she disappeared. Her body was later found in a ﬁeld close to her\n",
      "home. Paul Stewart Hutchinson, 50, has been charged with murder and is due before Nottingham magistrates\n",
      "later.\"\n",
      "Based on this premise, can we conclude the hypothesis \"Paul Stewart Hutchinson is accused of having stabbed a\n",
      "girl.\" is true?\n",
      "A:The premise does not say Paul Stewart Hutchinson \"stabbed\" this girl. The answer is no.\n",
      "Premise:\n",
      "\"Herceptin was already approved to treat the sickest breast cancer patients, and the company said, Monday, it\n",
      "will discuss with federal regulators the possibility of prescribing the drug for more breast cancer patients.\"\n",
      "Based on this premise, can we conclude the hypothesis \"Herceptin can be used to treat breast cancer.\" is true?\n",
      "A:\"Herceptin was approved to treat breast cancer\" implies that \"Herceptin can be used to treat breast cancer\".\n",
      "The answer is yes.\n",
      "Table 21: Few-shot exemplars for BoolQ (closed-book setting).\n",
      "Q:does system of a down have 2 singers?\n",
      "A:System of a Down currently consists of Serj Tankian, Daron Malakian, Shavo Odadjian and John Dolmayan.\n",
      "Serj and Daron do vocals, so the band does have two singers. The answer is yes.\n",
      "Q:do iran and afghanistan speak the same language?\n",
      "A:Iran and Afghanistan both speak the Indo-European language Persian. The answer is yes.\n",
      "Q:is a cello and a bass the same thing?\n",
      "A:The cello is played sitting down with the instrument between the knees, whereas the double bass is played\n",
      "standing or sitting on a stool. The answer is no.\n",
      "Q:can you use oyster card at epsom station?\n",
      "A:Epsom railway station serves the town of Epsom in Surrey and is not in the London Oyster card zone. The\n",
      "answer is no.\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# Percorso della cartella contenente i PDF\n",
    "folder_path = 'pdfs'\n",
    "\n",
    "# Lista per memorizzare tutti i documenti caricati\n",
    "all_documents = []\n",
    "\n",
    "# Iterare su tutti i file nella cartella\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(folder_path, filename)\n",
    "        loader = PyPDFLoader(file_path=pdf_path)\n",
    "        documents = loader.load()\n",
    "        all_documents.extend(documents)\n",
    "\n",
    "# Verifica e stampa il contenuto delle pagine\n",
    "for doc in all_documents:\n",
    "    if hasattr(doc, 'page_content'):\n",
    "        print(doc.page_content)\n",
    "\n",
    "# Funzione per formattare i documenti\n",
    "def format_documents(documents):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in documents if hasattr(doc, 'page_content'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents[16].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stampare i nomi dei file PDF caricati\n",
    "print(\"PDF caricati:\")\n",
    "for pdf in all_documents:\n",
    "    print(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_documents[0].page_content[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents=testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumi che pdfd sia già definita e carica i documenti una volta\n",
    "\n",
    "# Carica il PDF una volta\n",
    "loader = PyPDFLoader(all_documents)\n",
    "documents = loader.load()\n",
    "\n",
    "# Assicurati che ogni documento abbia l'attributo 'page_content'\n",
    "for doc in documents:\n",
    "    print(doc.page_content)\n",
    "\n",
    "# Funzione per formattare i documenti\n",
    "def format_documents(documents):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size =500,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "splits =text_splitter.split_documents(all_documents)\n",
    "for sp in splits:\n",
    "    if (len(sp.page_content) <100):\n",
    "        splits.remove(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di chunks: 2584\n"
     ]
    }
   ],
   "source": [
    "print (\"Numero di chunks:\",len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metadata :\", splits[0].metadata)\n",
    "print(\"Dimenzione del chunk:\", len(splits[1].page_content), \"caratteri\")\n",
    "print(\"Contenuto del chunk: \\n\" )\n",
    "print(splits[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Embeddings model questo funziona\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartella=\"algoritmo3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "if os.path.exists(cartella):\n",
    "    #Carica indice FAISS cartella corrente attuale\n",
    "    faiss_index=FAISS.load_local(\n",
    "        cartella,\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "else:\n",
    "    #crea indice FAISS dei chunk nella cartella attuale\n",
    "    faiss_index = FAISS.from_documents(\n",
    "        splits,\n",
    "        embeddings\n",
    "    )\n",
    "    faiss_index.save_local(cartella)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = faiss_index.as_retriever(\n",
    "\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt =hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "prompt = ChatPromptTemplate.from_template(\"Sei un assistente preciso e attento ; Rispondi a questa domanda in italiano: {question}, considra il seguente contesto {context}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def format_documents(all_documents):\n",
    "  #  return \"\\n\\n\".join(doc.page_contente for doc in all_documents)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_documents,\n",
    "        \"question\": RunnablePassthrough()\n",
    "        \n",
    "    } \n",
    "    |prompt\n",
    "    |model\n",
    "    |StrOutputParser()\n",
    "    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query):\n",
    "    answer = rag_chain.invoke(query)\n",
    "    return answer\n",
    "\n",
    "def queryStream(query):\n",
    "    for chunk in rag_chain.stream(query):\n",
    "        print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In questo contesto, un prompt è una frase o un insieme di parole che vengono fornite a un'intelligenza artificiale (LLM) per ottenere risultati ragionevoli. In particolare, i prompt sono utilizzati per guidare la risposta dell'LLM e influire sulla sua capacità di comprendere il contesto e di generare testi coerenti.\\n\\nNel caso specifico menzionato nel testo, i prompt 1 e 2 sono stati utilizzati per ottenere risposte brevi e concise. Il prompt 2, in particolare, è stato formulato in modo tale da richiedere alla LLM di fornire una risposta molto breve (di solito 1-2 frasi) e non proseguire con ulteriori punti.\\n\\nIn generale, i prompt possono essere utilizzati per vari scopi, come ad esempio:\\n\\n* Guidare la risposta dell'LLM verso un certo tipo di contenuto o stile\\n* Fornire informazioni specifiche che l'LLM deve considerare nella sua risposta\\n* Influenzare il tono e lo stile della risposta\\n* Aiutare l'LLM a comprendere il contesto e a generare testi coerenti\\n\\nIn questo senso, i prompt sono un importante strumento per gli sviluppatori di LLMs per ottenere risultati ragionevoli e per migliorare la qualità delle risposte generate dalle loro intelligenze artificiali.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(\"che cosa è un prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryStream(\"Dammi esempi di prompt efficaci\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
