{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerie necessarie\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough, RunnableParallel, RunnableLambda\n",
    "from IPython.display import JSON\n",
    "import json\n",
    "from unstructured_client import UnstructuredClient\n",
    "from unstructured_client.models import shared\n",
    "from unstructured_client.models.errors import SDKError\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import dict_to_elements, elements_to_json\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carica le variabili di ambiente dal file .env\n",
    "load_dotenv()\n",
    "\n",
    "# Ora puoi accedere alle variabili di ambiente\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm studio\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url = \"http://172.17.0.1:1234/v1\",\n",
    "    temperature = 0,\n",
    "    api_key = \"not-needed\",\n",
    "    model_name =\"llama3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollama\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url = \"http://localhost:11434/v1\",\n",
    "    temperature = 0,\n",
    "    api_key = \"not-need\",\n",
    "    model_name =\"llama3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    emperature = 0,\n",
    "     model_name =\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfd=\"/home/nugh75/git-repository/env1/Algorithm_of_Thoughts-_Enhancing_Exploration_of_Ideas_in_Large_Language_Models.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "filename = pdfd\n",
    "\n",
    "# Call the partition_pdf function\n",
    "# Returns a List[Element] present in the pages of the parsed pdf document\n",
    "elements = partition_pdf(filename)\n",
    "\n",
    "# Now, elements is a list of all elements present in the pages of the parsed pdf document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "filename = pdfd\n",
    "\n",
    "# Call the partition_pdf function\n",
    "# Returns a List[Element] present in the pages of the parsed pdf document\n",
    "all_documents = partition_pdf(filename)\n",
    "\n",
    "# Now, elements is a list of all elements present in the pages of the parsed pdf document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Text at 0x7fd92820ddb0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92820de70>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92820e890>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820e950>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92820de10>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92820dbd0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92820dcc0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92820e9e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92820f790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92820eec0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92820efb0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92820eb60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92820ec20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92820ec80>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92820ee30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92820f0d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92820f160>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92820f250>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9285108e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd928510130>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285102e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285103d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd928510400>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285105e0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9285106d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285107c0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925c58eb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925c58130>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925c584c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925c58670>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925c58a60>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925c58c40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925c58d30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925c58850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925c58f40>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c6980>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283c6fe0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c74c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c6830>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c6b30>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c5fc0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c70d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c6d10>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c7580>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283c5e70>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c7760>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c6bf0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c7700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9283c5840>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9283c5480>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9283c5660>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9283c5cf0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9283c5d80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9283c7430>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9283c6200>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9283c5ed0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9283c5e40>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9283c5f90>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9283c65f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925b482b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925b48700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925b488b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925b489d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925b489a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925b48ee0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925b48fd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925b492a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925b493c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925b49660>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925b49840>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925b49900>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9285c8220>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9285c8130>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9285c8700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285c8880>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285c88b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285c8a00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285c8bb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285c8ca0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285c8e50>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9285c8f10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285c85e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9285c9030>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9285c9120>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285c9210>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285c9300>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9285c93f0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925d78460>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d78340>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925d78220>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925d78f10>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d7af20>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925d7bbb0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d7a320>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925d78e20>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d79c90>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925d7ae60>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d7abc0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d7a560>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d7b670>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d7a6b0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925d7bdc0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d79cc0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d7b3a0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d7a8c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925d798a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925d79b10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925d79ea0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925d790f0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d791b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925d79360>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925d79690>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925f8bf70>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925f8b250>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d7b280>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925884520>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925884670>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d7be20>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925884280>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d78d00>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925f8bdf0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925884070>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925f8b4c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d782e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d7b9d0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925f8bca0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92548bf10>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925884430>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925d782b0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9258844f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925d79a80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925d7a080>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925d7a590>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925657dc0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9255174f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925517520>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925c59cc0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925c5bdf0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92547c2e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547c2b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925bdbd30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547c910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547c6a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547c5b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547c7f0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92547c160>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547c0d0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92547c400>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547c070>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925bd8d90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925bdbdc0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925bd9150>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925bd9180>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925bda2c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925bd9930>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925bd8b50>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925bd9300>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925bd9990>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925bd95a0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925bd87c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925bd8fa0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925bd8f70>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925bd9420>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925bd9330>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925bd92a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925bd8790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925bd9630>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925bd9a50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925bd99c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7790>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e69e0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283e7a30>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283e7e80>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e6770>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7d30>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7640>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7a60>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7c70>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e40a0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7d90>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e6b30>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7e50>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e6650>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4940>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e75b0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925b480d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7dc0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4910>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e6ce0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283e5db0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283e6f20>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7fd0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e5930>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e5870>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925b48370>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e6860>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e78e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7eb0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e73a0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e67d0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283e73d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7820>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925b48bb0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283e53c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7250>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e6680>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4e50>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4100>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e5480>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4340>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e5600>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4250>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e5510>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4a90>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283e49d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4700>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e5180>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e6b60>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4580>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4670>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e72b0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283e4e80>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e6ec0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4790>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e51b0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4be0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283e5f00>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4a00>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e6e90>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283e56f0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4490>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e5030>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7070>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e6bc0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e7100>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283e4ca0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925b48a90>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925b48880>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925b484f0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925b483a0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925b483d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a56920>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a56fe0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258549d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a57fa0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925854850>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a56b30>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925856c50>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925857d90>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a561d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a55a50>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925854970>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a576d0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925854e80>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a54e20>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a556c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925854b20>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925857e50>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925855c60>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a572e0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925a54640>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925854ca0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a57af0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925856d70>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a57d60>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a57940>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925857eb0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a55ea0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a55f90>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a57760>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a55f30>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925856da0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a55f00>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a54b80>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a54820>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92820f550>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925a55240>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925a555a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925a55660>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925a55ab0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a559c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a55630>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a541c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925a55c90>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925a56200>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a54ca0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a56530>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925a565c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a56a40>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820c730>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820cdc0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820cc70>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92820cbb0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820c970>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820c8b0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820c8e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820d270>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92820d210>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820c6d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820d1e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820cf40>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92820cee0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925855510>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925855780>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925855570>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925855840>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9258558a0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925855a20>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c5b40>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925855c00>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925f8bd90>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925f88c10>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283c5c30>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c5570>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c7d30>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c5240>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c7b50>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283c7a00>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c7850>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c7670>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9283c6e30>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9285101c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd928512890>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9285100a0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9285109d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547cd90>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547ce50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547cf40>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258b2200>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258b1bd0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258b2350>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9258b23b0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925b48be0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258b25c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258b2500>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258b2770>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9258b27d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258b2950>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258b27a0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9258b2920>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92547d030>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547d1b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547d2d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547d4b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547d690>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547d780>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547d870>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547d930>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547dbd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547dc90>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92547dd80>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92547de70>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547d570>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92547d450>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547e0b0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547d420>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547dff0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92547e560>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9289c2290>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9289c12d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9289c1450>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9289c14e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9289c1480>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9289c1750>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9289c1150>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925944af0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925944df0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925944f10>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925944a90>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9259444c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925944940>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925e84880>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925e87a00>,\n",
       " <unstructured.documents.elements.Text at 0x7fd928404d00>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9284041c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd928404460>,\n",
       " <unstructured.documents.elements.Text at 0x7fd928404610>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9284047f0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9284045e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820d6c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92561ae30>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925618eb0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925618e20>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925618730>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92837bc10>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925f9e1d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925f9e020>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925f9df90>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92837a740>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92837a9e0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92837aad0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92837ae30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92837af20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92837b790>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92837af50>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92837b370>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92837ac20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92837afb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd928379930>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92837b040>,\n",
       " <unstructured.documents.elements.Text at 0x7fd928379780>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92837a680>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92837b4f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92837a290>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92837a2c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92837b6d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925488b50>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92548ba90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925856170>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925856140>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258561a0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258562f0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925856560>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925856590>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9258565c0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925856710>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9258567a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9258553c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9258568c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925856d40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925856e30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925854130>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925856230>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925857c40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925856b00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925856b90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925855480>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925855990>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9258540a0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925856bf0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925856cb0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925855ff0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925f9d330>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925f9d450>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925f9cfd0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925f9d4e0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925b47850>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925b479d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925b44520>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92561ab60>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92561b5e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925618be0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92561b550>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92561b3a0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547c5e0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92561aef0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92561ae00>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9256188e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92837add0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547f5b0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547d1e0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92547dfc0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547ed40>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547ef50>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547efe0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547ed70>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547f130>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547c0a0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547df60>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92561bb20>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92561aec0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92561b070>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9256190c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925618d30>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9256187f0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925618700>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925618d00>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92561a3b0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92561bdc0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925618790>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820c3d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820d750>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820d660>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820c520>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9256199c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925619270>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925619990>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92549df90>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92549f1c0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92549d330>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549c550>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92549c5e0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925bdb970>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925bdab00>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925bd89d0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820ca60>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92820c640>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92820d600>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92820c430>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92820c0a0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92548ae90>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92548be80>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92548b370>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92548b400>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92548b9d0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925489f90>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547eb60>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547f640>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547ef80>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547fe50>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547fe80>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547fc10>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547fbe0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547f970>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92547fbb0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547d5a0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92547f850>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9283799f0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd928379840>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92837a3b0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92837a3e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92837a110>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283794e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd928379180>,\n",
       " <unstructured.documents.elements.Text at 0x7fd928378250>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92837bd60>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd928379750>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9283784f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92837b7c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a558a0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925a55480>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a57160>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925a56800>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a57f70>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a565f0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925a579a0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925a57f10>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925a569e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a56ad0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a57820>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925a54610>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925a55960>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925a575e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925a57010>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92549f820>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92549eb60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92549eb90>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549ecb0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549ed40>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549ee00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92549e380>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92549eef0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92549f040>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549e5f0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92549f100>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549e650>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549f1f0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549cf40>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92549fee0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549cee0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549ead0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549f220>,\n",
       " <unstructured.documents.elements.Title at 0x7fd92549fd00>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549fc70>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549f910>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925657b20>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925656ef0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9256545e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925657df0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925655390>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9256574f0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925656080>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925656890>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925656a40>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925655b70>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925655240>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925657fd0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925657f70>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9256550c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925657310>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925a570a0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a54730>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a56a70>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925a566e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925a544f0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c66e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c67d0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283c6380>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c6b90>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c60e0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c6f80>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9283c6140>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9283c53c0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92561bc10>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925655a80>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925656fb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925657e50>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925656950>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925655960>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925657bb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925657250>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9256559f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9256552d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925655ba0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925655630>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925657b80>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92549df30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92549f520>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92549f6a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92549cbb0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92549c430>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd92549d870>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92549d9c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92549c310>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549dba0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd92549dab0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd92549c0d0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd928406d40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd928406fb0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd928406f20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd928407130>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9284073d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd928406d10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9284075e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd928406560>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9284077c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd9284077f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd928407850>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd928405b70>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9255cb130>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9255ca440>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9255c8610>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9255c9e40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9255c81c0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9255caef0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9255c8b80>,\n",
       " <unstructured.documents.elements.Title at 0x7fd9255c96f0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925e87640>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925e85810>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925e85c60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925e871c0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925e86e30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925e85ea0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925e86d10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925e87df0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925e87b50>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925e86dd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925e87790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925e872b0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925e86b60>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925654820>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd9256577f0>,\n",
       " <unstructured.documents.elements.ListItem at 0x7fd925654e80>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925657130>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925656470>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9256562f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925656a70>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925655ab0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925655120>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925656440>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9256556c0>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925654b20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925654280>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd9256542b0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925f9ead0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925f9eb90>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925f9d360>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925855f90>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925f9dab0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925f9e500>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925f9d960>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925f9c070>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925f9d540>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925f9f940>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925f9e6b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925f9f5e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925f9e5f0>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925f9f400>,\n",
       " <unstructured.documents.elements.Title at 0x7fd925f9fb80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925f9d060>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925f9fb50>,\n",
       " <unstructured.documents.elements.Text at 0x7fd925f9de40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925f9c700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925f9c940>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7fd925f9f310>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titolo = elements[0]\n",
    "print(titolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autore = elements[2]\n",
    "print(autore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"3 2 0 2\",\n",
      "  \"p e S 8 2\",\n",
      "  \"] L C . s c [\",\n",
      "  \"2 v 9 7 3 0 1 . 8 0 3 2 : v i X r a\",\n",
      "  \"Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models\",\n",
      "  \"Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Ruoxi Jia, and Ming Jin\",\n",
      "  \"Virginia Tech\",\n",
      "  \"Abstract\",\n",
      "  \"Current literature, aiming to surpass the \\u201cChain-of-Thought\\u201d approach, often resorts to an external modus operandi in- volving halting, modifying, and then resuming the genera- tion process to boost Large Language Models\\u2019 (LLMs) rea- soning capacities. This mode escalates the number of query requests, leading to increased costs, memory, and computa- tional overheads. Addressing this, we propose the Algorithm of Thoughts\\u2014a novel strategy that propels LLMs through algorithmic reasoning pathways, pioneering a new mode of in-context learning. By employing algorithmic examples, we exploit the innate recurrence dynamics of LLMs, expand- ing their idea exploration with merely one or a few queries. Our technique outperforms earlier single-query methods and stands on par with a recent multi-query strategy that employs an extensive tree search algorithm. Intriguingly, our results suggest that instructing an LLM using an algorithm can lead to performance surpassing that of the algorithm itself, hinting at LLM\\u2019s inherent ability to weave its intuition into optimized searches. We probe into the underpinnings of our method\\u2019s efficacy and its nuances in application.\",\n",
      "  \"reflect the introspective nature of System 2. Notably, inte- grating intermediary reasoning steps has yielded improve- ments in arithmetic reasoning tasks (Srivastava et al. 2022; Liang et al. 2022).\",\n",
      "  \"However, as tasks shift towards deeper planning and ex- tensive thought exploration, these methods appear restric- tive. Although CoT integrated with Self-Consistency (CoT- SC) (Wang et al. 2022) enlists multiple LLM outputs for a consensus, the lack of meticulous evaluation can result in model misdirection. The \\u201cTree of Thoughts\\u201d (Yao et al. 2023; Long 2023) emerges as a notable solution. While one LLM is dedicated to idea generation, another steps in to as- sess the merit of these ideas, following a halting-assessment- resuming cycle. This iterative process, anchored by tree search, has shown marked effectiveness, especially in tasks with a breadth of continuations. We see this progression as akin to humans employing tools to circumvent working memory limitations, serving as an external augmentation for LLMs (Mialon et al. 2023).\",\n",
      "  \"Introduction\",\n",
      "  \"Recent developments in large language models (Chowdhery et al. 2022; Thoppilan et al. 2022; Liu et al. 2023, inter alia) have spotlighted their efficacy in general problem solving (Huang and Chang 2022; Suzgun et al. 2022), code gen- eration (Chen et al. 2021; Austin et al. 2021), and instruc- tion following (Ouyang et al. 2022; Bai et al. 2022). While early models relied on direct answer strategies (Brown et al. 2020), contemporary research veers towards linear reason- ing paths (Wei et al. 2022b; Kojima et al. 2022; Zhang et al. 2022) by breaking problems into sub-tasks for solution dis- covery, or harnesses external mechanisms to alter token gen- eration by changing the context (Zhou et al. 2022; Drozdov et al. 2022; Yao et al. 2023).\",\n",
      "  \"Analogous to human cognition (Sloman 1996; Kahneman 2011), early LLM strategies seemed to emulate the instan- taneous System 1, characterized by its impulsive decision- making. In contrast, more recent methodologies like chain- of-thought (CoT) (Wei et al. 2022b) and least-to-most prompting (L2M) (Zhou et al. 2022; Drozdov et al. 2022)\",\n",
      "  \"Preprint. Under review.\",\n",
      "  \"On the flip side, this enhanced LLM approach is not without pitfalls. A prominent downside is the substantial surge in the number of queries and computational demands. Each query to online LLM APIs such as GPT-4\\u2014a focal point of our study\\u2014incurs a monetary expense (Chen, Za- haria, and Zou 2023) but also contributes to latency, a sig- nificant limitation especially critical in real-time applica- tions. Cumulative delays from these queries can compro- mise solution efficiency. Infrastructure-wise, continuous in- teractions can stress systems, leading to potential bandwidth constraints and reduced model availability (Aminabadi et al. 2022). Moreover, the environmental implications cannot be ignored; incessant querying escalates the energy consump- tion of already power-hungry data centers, exacerbating the carbon footprint (Wu et al. 2022; Dhar 2020).\",\n",
      "  \"With this in mind, our goal is to dramatically reduce the query counts employed by contemporary multi-query rea- soning methods while maintaining performance for tasks ne- cessitating adept use of world knowledge, thereby steering a more responsible and proficient use of AI resources.\",\n",
      "  \"Reflecting on the evolution of LLMs from System 1 to System 2, an essential ingredient comes to light: algorithms. Characterized by its methodical nature, the algorithmic per- spective offers a path to keenly explore problem spaces, en- act strategies, and formulate solutions (Helie and Pizlo 2022;\",\n",
      "  \"Chain-of-ThoughtModel InputModel OutputUser: 8 6 4 4Assistant: 8 - 6 = 2 (left: 4, 4, 2)4 + 2 = 6 (left: 6, 4)6 * 4 = 24Answer: (4 + (8 - 6)) * 4 = 24. User: 11 10 5 1Assistant:11 - 10 = 1 (left: 1, 1, 5)1 * 1 = 1 (left: 1, 5)5 * 1 = 5 (left: 5)Answer: ((11 - 10) * 1) * 5 - 1 = 24.Algorithm of ThoughtsModel InputModel OutputUser: 8 6 4 4Assistant:1. 4 - 4: (left: 8, 6, 0)...3. 8 - 6: (left: 4, 4, 2)- 4 + 4: (left: 8, 2) 10, 6, 16, 4- 4 - 4: (left: 2, 0) 2, 2, 0, undefined- 4 * 4: (left: 16, 2) 18, 14, 32, 8- 4 / 4: (left: 2, 1) 3, 1, 2, 2- 4 + 2: (left: 6, 4) 10, 2, 24 = 6 * 4 -> found it!Answer: (4 + (8 - 6)) * 4 = 24. User: 11 10 5 1Assistant:1. 11 - 1: (left: 10, 10, 5)...5. 11 + 1: (left: 12, 10, 5)- 12 + 10: (left: 22, 5) 27, 17, 110, 4.4- 12 - 10: (left: 5, 2) 7, 3, 10, 2.5- 12 * 10: (left: 120, 5) 24 = 120 / 5 -> found it!Answer: ((11 + 1) * 10) / 5 = 24.Standard PromptingModel InputModel OutputUser: 8 6 4 4Assistant: Answer: (4 + (8 - 6)) * 4 = 24. User: 11 10 5 1Assistant:Answer: (11 - 1) * (10 - 5) = 24\",\n",
      "  \"Figure 1: Comparison between standard prompting, CoT, and AoT in the game of 24. While standard prompting aims for a direct answer, CoT sketches out the successive steps to the final solution. AoT\\u2019s in-context example, distinct from CoT, integrates the search process, highlighted by markers \\u20181\\u2019,..., \\u20183\\u2019 as \\u201cfirst operations\\u201d guiding subtree exploration for the problem set \\u20188 6 4 4\\u2019. For clarity, only a single in-context example is displayed, with a focus on the third subtree exploration. AoT produces prospective search steps (e.g., the subtree exploration \\u20185. 11 + 1\\u2019) and evaluates potential subsequent steps to either progress towards a solution or retrace to another viable subtree.\",\n",
      "  \"Banerjee et al. 2022). While much of the prevailing literature treats algorithms as external to LLMs, given LLMs\\u2019 inher- ent generative recurrence, can we channel this iterative logic to internalize an algorithm?\",\n",
      "  \"Drawing upon both the intricate nuances of human rea- soning and the disciplined precision of algorithmic method- ologies, our work aims to fuse these dual facets to aug- ment reasoning capabilities within LLMs. Existing research underscores that humans, when navigating complex prob- lems, instinctively draw upon past efforts, ensuring a com- prehensive contemplation rather than a narrow focus (Mon- sell 2003; Holyoak and Morrison 2005; Baddeley 2003). LLMs, with their generative span bounded only by token limits, appear poised to break through the barriers of human working memory. Spurred by this observation, we investi- gated if LLMs could mirror a similar layered exploration of ideas, referencing prior intermediate steps to sieve out infeasible options, all within their iterative generation cy- cle. And while humans excel with their intuitive acumen, al- gorithms stand out with organized, systematic exploration. Current techniques, like CoT, often sidestep this synergistic potential, imposing undue pressure on LLMs for on-the-spot precision. By capitalizing on LLMs\\u2019 recursive capabilities, we emulate a hybrid human-algorithmic approach. This is achieved through our use of algorithmic examples that cap- ture the essence of exploration, from initial candidates to validated solutions. Thus emerges our concept of the Algo- rithm of Thoughts (AoT), as illustrated in Figs. 1 and 2.\",\n",
      "  \"More broadly, our approach signifies a new paradigm of in-context learning. Instead of the traditional \\u201csupervised- learning\\u201d mold of [PROBLEM, SOLUTION] or [PROBLEM, SUCCESSIVE STEPS TO SOLUTION], we present a new structure that covers [PROBLEM, SEARCH PROCESS, SO- LUTION]. Naturally, when instructing an LLM using an al- gorithm, the anticipation leans towards the LLM simply imitating the algorithm\\u2019s iterative thinking. However, what emerges as intriguing is the LLM\\u2019s ability to infuse its own \\u201cintuition\\u201d to achieve a search efficiency that even surpasses the algorithm itself (see Fig. 5).\",\n",
      "  \"In the subsequent sections, we first situate our work within the existing literature, followed by a discussion of our principal idea. We then present our experimental results and probe a series of hypotheses related to this emerging ca- pability of LLM before rounding off with a conclusion.\",\n",
      "  \"Related Work\",\n",
      "  \"Standard Prompting. Also known as input-output prompting, it provides a few input-output examples of the task before getting an answer for the test sample from the language model (Brown et al. 2020). Although this method is very general and does not need any special prompting strategy, the performance is also worse compared to more advanced methods (Shao et al. 2023; Wei et al. 2022a; Lyu et al. 2023).\",\n",
      "  \"InputOutputInputOutputInputOutputInputOutputStandard PromptingChain of ThoughtsTree of ThoughtsAlgorithm of Thoughts\",\n",
      "  \"Figure 2: Illustration outlining various strategies for tackling reasoning problems with LLMs. Each box signifies a distinct thought, functioning as a unified string of words that forms an incremental pathway to reasoning. Green boxes indicate ideas deemed promising by the LLM, while red boxes represent less promising concepts.\",\n",
      "  \"Chain-of-Thought. In CoT, LLMs are presented with ex- amples where a given question x unfolds through a chain of intermediate reasoning pieces c1, . . . , cn to reach an an- swer y, represented as x \\u2192 c1 \\u2192 . . . \\u2192 cn \\u2192 y (Wei et al. 2022b; Lyu et al. 2023). By mimicking the examples in the context, the LLM automatically divides the solution into simpler linear steps to arrive at the answer, improv- ing performance across numerous reasoning benchmarks. Self-consistency (Wang et al. 2022) is a widely used de- coding strategy aimed at generating a variety of reason- ing paths by choosing the final answer through a majority vote, though this necessitates additional generations. Con- trary to CoT\\u2019s linear, direct progression, our approach pivots towards the explorative aspect of LLMs. We reconceptual- ize the c1, . . . , cn sequence, not merely as successive steps towards a solution, but as a dynamic, potentially mutable path that resembles an algorithmic search, allowing for ex- ploration, recalibration, and non-linear progression.\",\n",
      "  \"Least-to-Most prompting (L2M). Taking cues from ed- ucational psychology (Libby et al. 2008), L2M prompting directs the LLM to decompose the central problem into smaller subproblems. Each subproblem is tackled in se- quence, with the outcome appended before progressing to the next (Zhou et al. 2022; Drozdov et al. 2022). While this structured delineation is beneficial for broader generaliza- tion, it operates on the premise of finding a nearly perfect de- composition in a single attempt\\u2014ideal for problems with a clear-cut structure. Yet, when tasks intertwine with their de- composition complexities (like games of 24), this method\\u2019s inflexibility becomes apparent. Contrastingly, AoT not only underscores the active subproblem (as shown in Fig. 1), but also permits a more contemplative approach by entertaining various options for each subproblem, while maintaining ef- ficacy even with minimal prompts.\",\n",
      "  \"2023). Evaluation capabilities of LLMs can also be used to direct the search by pruning nodes that are hopeless to in- crease efficiency. However, ToT\\u2019s Achilles\\u2019 heel is its ex- cessive reliance on LLM queries, at times necessitating hun- dreds for just one problem. We tackle this limitation by gen- erating the whole thought process within a single context.\",\n",
      "  \"Algorithm of Thoughts\",\n",
      "  \"Our strategy pivots on recognizing a core shortcoming of current in-context learning paradigms. CoT, while enhanc- ing the coherency of thought linkages leading to solutions, occasionally falters, presenting incorrect intermediate steps (Zelikman et al. 2022; Turpin et al. 2023; Lanham et al. 2023). Faithful CoT (Lyu et al. 2023) ought to amend this by eliciting symbolic chains of reasoning where the LLM\\u2019s output resembles task-specific pseudo-code, primed for de- terministic execution like Python. The intention is only to use the thought processes but not the outputs and inputs of each link since they have a tendency to be unreliable. But, the occasional missteps of CoT may not necessarily due to the LLM\\u2019s inability to compute correctly. The LLM, when confronted with questions that closely match conditions of previous in-context examples, may favor echoing those out- puts over generating the appropriate questions. To shed light on this phenomenon, we designed an experiment. Querying text-davinci-003 for arithmetic tasks (e.g., \\u201811 \\u2212 2 =\\u2019), we prefixed them with multiple in-context equations converging to an identical output (e.g. \\u201815 \\u2212 5 = 10, 8 + 2 = 10\\u2019). Our results, presented in Fig. 3, reveal a steep decline in accu- racy, suggesting that the mere presence of correct reasoning in the context might inadvertently compromise even basic arithmetic skills.\",\n",
      "  \"Tree of Thoughts (ToT). In the cases where each sub- problem has multiple viable options to explore, linear rea- soning paths from CoT or L2M substantially limit the cov- erage of the thought space. Considering possible options for each subproblem, the decision tree can be explored by ex- ternal tree-search mechanisms (e.g., BFS, DFS) (Yao et al.\",\n",
      "  \"To offset this bias, diversifying the outputs of examples might seem like a viable solution, but this could subtly skew the distribution of outputs. Merely adding unsuccessful tri- als, much like a random search, might inadvertently encour- age the model to retry rather than truly solve. Capturing the true essence of algorithmic behavior, where both failed searches and subsequent recovering and learning from such attempts play a role, we incorporate in-context examples pat-\",\n",
      "  \"0.0\",\n",
      "  \"2\",\n",
      "  \"8\",\n",
      "  \"12# of Equations\",\n",
      "  \"10\",\n",
      "  \"1.0Probability of Correct Token\",\n",
      "  \"0\",\n",
      "  \"0.2\",\n",
      "  \"0.8\",\n",
      "  \"4\",\n",
      "  \"6\",\n",
      "  \"0.4\",\n",
      "  \"0.6\",\n",
      "  \"Figure 3: The probability of generating the correct token as we add more in-context examples that are correct but possess identical outputs.\",\n",
      "  \"terned after search algorithms, notably depth-first search (DFS) and breadth-first search (BFS). See Fig. 1 for an ex- ample.\",\n",
      "  \"This paper focuses on a broad class of tasks reminiscent of tree-search problems. These tasks necessitate breaking down the main problem, crafting feasible solutions for each seg- ment, and making decisions on the paths to either pursue or forsake, with the option of reevaluating more promising segmentations. Rather than posing separate queries for ev- ery subset, we leverage the iterative capabilities of the LLM to address them in one unified generation sweep. By confin- ing ourselves to one or two LLM interactions, this approach naturally incorporates insights from antecedent context can- didates and tackles intricate issues requiring an in-depth ex- ploration of the solution domain. In alignment with our goal, we also give insights into how small or big those thoughts should be and what type of in-context examples should be given to the LLM to promote token efficiency. Subsequently, we outline key components of tree-search algorithms and their manifestation in our framework.\",\n",
      "  \"1. Decomposition into Subproblems. Given a problem, constructing a search tree that delineates feasible reasoning pathways is already a demanding task, excluding the actual problem-solving aspect. Any decomposition must consider not just the interrelations between subtasks, but also the ease of addressing each individually. Consider a simple multi- digit addition: while converting numbers to binary might be efficient for a computer, humans typically find base 10 arithmetic more intuitive. Furthermore, even if the subprob- lems remain constant, their execution might vary. Intuition can lead to shortcuts between solution steps, while its ab- sence might necessitate more detailed steps. Crafting the right prompt (i.e., in-context algorithmic examples) hinges on these nuances, determining the minimal tokens an LLM would need for dependable performance. This is not only essential to fit within the LLM\\u2019s context constraints but also vital for efficacy, as we\\u2019d expect LLMs to address problems resonant with its context using a similar token volume.\",\n",
      "  \"2. Proposing Solutions to Subproblems. A dominant ap- proach in existing works involves direct sampling from LLM token output probabilities (Wang et al. 2022; Yao\",\n",
      "  \"The first five prime numbers:Text Completion2 = 87.6%1 = 12.3%......2, 3, 5, 7, 11probabilities for the first token\",\n",
      "  \"Figure 4: An example highlighting the drawback of isolated sampling of sequenced ideas. Input is denoted in blue, with the text-davinci-003 providing the green completions.\",\n",
      "  \"et al. 2023). Though effective for one-off answers (Kadavath et al. 2022) (with certain constraints (Robinson and Wingate 2022)), this method falls short in scenarios demanding a se- quence of samples to be integrated or evaluated within sub- sequent prompts (Robinson and Wingate 2022). To mini- mize model queries, we adopt an uninterrupted solution cre- ation process. Here, we directly and continuously generate solutions for the prevailing subproblem without any genera- tion pauses.\",\n",
      "  \"The benefits are three-fold. First, with all generated solu- tions existing within a shared context, there\\u2019s no need for in- dividual model queries for each solution evaluation. Second, while it may seem counterintuitive initially, isolated token or token group probabilities might not always yield meaning- ful choices. A simple illustration is found in Fig. 4. When evaluated independently, the second-most probable token for our inaugural number is \\u20181\\u2019\\u2014not qualifying as prime. But, when generation remains unbroken, the derived sequence is correct. This incongruence points towards the restrictive na- ture of the Markov property in sequence modeling. Core to our perspective is the premise that for sequential tasks like algorithmic search, LLMs are more adept at generating en- tire sequences than intermittently pausing and re-initiating the token sampling process.\",\n",
      "  \"3. Gauging the Promise of a Subproblem. As above, existing techniques lean on additional prompting to dis- cern the potential of tree nodes, aiding decisions regard- ing exploration direction. Our observations suggest that if the most promising routes are encapsulated within the in- context examples, LLMs inherently gravitate towards prior- itizing those promising candidates. This diminishes the need for intricate prompt engineering and allows the incorpora- tion of intricate heuristics, whether intuitive or knowledge- driven. Again, the absence of disjoint prompts in our ap- proach allows for an immediate assessment of candidate vi- ability in the same generation.\",\n",
      "  \"4. Backtracking to a Preferable Juncture. The decision of which node to explore next (including retracing to a prior node) inherently depends on the selected tree-search algo- rithm. While previous studies (Yao et al. 2023) have em- ployed external means such as coded mechanisms for the search process, this restricts its broader appeal and entails additional customization. Our designs predominantly adopt a DFS approach supplemented by pruning. The aim is to\",\n",
      "  \"maintain proximity between nodes sharing the same par- ent, thereby encouraging the LLM to prioritize local over distant features. Additionally, we present performance met- rics for the AoT approach grounded in BFS. Our reliance on the model\\u2019s inherent capacity to glean insights from in- context examples obviates the necessity for additional, be- spoke mechanisms.\",\n",
      "  \"Experiments We show that AoT surpasses the performance of other single-prompt methods (e.g. standard, CoT/-SC prompting) while remaining competitive even when compared to meth- ods that utilize external mechanisms, such as ToT, in bench- marks like the game of 24 and 5x5 mini crosswords.\",\n",
      "  \"Game of 24 The game of 24 is a mathematical card game in which play- ers are given four numbers and must use addition, subtrac- tion, multiplication, and division (each operation can be used more than once) to manipulate those numbers to total 24. For instance, for the numbers \\u20188 8 5 4\\u2019, one solution would be \\u20188 \\u2217 (5 \\u2212 (8/4)) = 24\\u2019. At first glance, the game might appear straightforward. However, a cursory calculation sug- gests there are nearly 13,000 distinct expressions possible for any set of four numbers (without accounting for the com- mutative properties of addition and multiplication), making it a formidable challenge for present-day LLMs.\",\n",
      "  \"Task Setup. Adhering to the setup detailed in (Yao et al. 2023), we use games from indices 901-1000, sourced from the 1362 games ranked by relative difficulty at 4nums.com. For an attempt to be considered successful, it must derive a total of 24 using the exact numbers provided and only the allowed operations.\",\n",
      "  \"Baselines. Standard prompting and CoT are used in the 5- shot setting, with CoT integrating 3 steps for the operations. These methods are sampled 100 times, and the averaged suc- cess rates from these samples are reported. CoT-SC is also tested with 100 votes in our setup. For ToT, we use a breadth of 5. The performance metrics from their study are directly cited to obviate the need for needless carbon emissions.\",\n",
      "  \"AoT Setup. We employ the same 5-shot setting as in stan- dard prompting and CoT baseline setup. Our in-context sam- ples leverage a DFS-style search algorithm, which, for clar- ity, is the same version used when contrasting with tra- ditional DFS in Fig. 5. During each subtree exploration, dubbed either the \\u2018first step\\u2019 or \\u2018first operation\\u2019, we choose two numbers\\u2014illustrated by the selection of 8 and 6 in the third \\u2019first step\\u2019 (i.e., subtree labeled \\u20183\\u2019) of Fig. 1\\u2014and a corresponding operation (e.g., 8 \\u2212 6). This operation results in a new number, 2, leaving us with three numbers in total. A thorough combing of these three numbers culminates in 19 leaf nodes, all visible under the \\u20183\\u2019 subtree in Fig. 1. We aim to assess two aspects: the ability of the LLM to pin- point promising first operations, which directly impacts the number of resolved leaf nodes, and its performance against a conventional DFS. Details on the prompts we employed are provided in the Appendix. As our method emphasizes\",\n",
      "  \"sequential generation over trajectory sampling, we operate with a temperature setting of 0.\",\n",
      "  \"Results. From Table 1, it\\u2019s evident that standard prompt- ing combined with CoT/-SC significantly lags behind tree search methods when used with LLMs. The \\u201cStandard + Re- fine\\u201d result, showing a 27% success rate, is referenced from (Yao et al. 2023). This method involves iteratively asking the LLM (up to 10 iterations) to refine its answer if the initial one is incorrect. Meanwhile, ToT is limited to a maximum of 100 node visits, translating to several hundred LLM queries for each example. Remarkably, AoT achieves its results with just a single query. Despite reducing the number of requests by more than a factor of 100, AoT still outperforms ToT in this task.\",\n",
      "  \"Method Standard Prompting CoT CoT-SC (k = 100) Standard + Refine ToT (b = 5) AoT (ours)\",\n",
      "  \"Success Avg. Queries 7.3% 1 4.0% 1 100 9.0% 10 27% 109.1 69% 1 71%\",\n",
      "  \"Table 1: Game of 24: success rates and the average number of LLM queries for each example.\",\n",
      "  \"Error Analysis. Using a strictly LLM-centric approach\\u2014 eschewing any external tooling or edits\\u2014we sought to cat- egorize mistakes observed during the game of 24. This aids in highlighting areas for refinement when solely deploying LLMs. We\\u2019ve classified these errors into four distinct, ex- haustive categories: 1) Out-of-token error: The LLM reaches its maximum token threshold without identifying a solution. 2) Expression misstep: The LLM has the correct logic or steps but fails when trying to express or formulate them into a coherent answer. 3) Non-finalization error: The LLM dis- covers the solution but continues its search without consol- idating the finding. 4) Other errors: This umbrella term en- compasses other mistakes like computational errors that re- sult in overlooking the solution or furnishing incorrect an- swers. To exclusively showcase the AoT\\u2019s search capabil- ities, we also present the AoT + Manual Resolution ver- sion. Here, once the LLM pinpoints a solution, its final ar- ticulation is manually processed\\u2014a strategy also employed by the ToT method. As evidenced in Table 2, a notable 7% of mistakes stem from non-algorithmic factors like non- finalization and expression missteps. In fact, with manual resolution, AoT attains a 78% success rate, surpassing ToT. This underlines the potential for refining our prompt, espe- cially in areas concerning recognizing and expressing suc- cessful problem resolutions. Additionally, the token limi- tation underscores the appeal of expanding the generative context window, which may further bolster LLMs\\u2019 recursive reasoning when engaged with algorithmic examples.\",\n",
      "  \"Error Type Out-of-token error Expression misstep Non-finalization error Others Method ToT AoT AoT + Manual Resolution\",\n",
      "  \"Error 9% 4% 3% 13% Success 69% 71% 78%\",\n",
      "  \"Table 2: Game of 24: AoT error analysis.\",\n",
      "  \"Mini Crosswords The 5 \\u00d7 5 mini crossword is a compact word puzzle featur- ing a grid of 25 squares arranged in a 5-by-5 configuration. Players are tasked with filling the grid based on provided clues for each word. Clues are given for words that run both across (horizontally) and down (vertically). Words intersect at certain letters, offering additional hints to complete the puzzle.\",\n",
      "  \"Task Setup. Adhering to the setup outlined in (Yao et al. 2023), we draw our prompts from games 136, 141, 146, 151, and 156 out of the 156 games available on goobix.com. Our testing focuses on a set of 20 games, specifically games 1, 6, . . ., 91, and 96.\",\n",
      "  \"Baselines. Mirroring our approach for the game of 24, we benchmark our method against established techniques: stan- dard prompting, CoT, and ToT. For standard prompting, we provide both the crosswords and their respective solutions as in-context examples. CoT augments this by prompting the retrieval of words for each of the ten clues\\u2014equally split between horizontal and vertical orientations. We directly ex- tract the success rates of ToT from their original publication for comparison.\",\n",
      "  \"AoT Setup. We divide the process into two steps, each in- volving a query. Initially, we task the LLM with suggesting five potential words for each row and column. We then pin- point the starting word candidates that have the highest com- patibility with other words within the crossword framework. This preliminary phase mirrors a \\u2019warm-up\\u2019 sequence in al- gorithm initialization. In the subsequent step, we exclusively leverage the LLM\\u2019s algorithmic reasoning prowess, starting with the pre-selected word. The method involves cyclically choosing a likely option (specifically, a row or column) for insertion, generating candidate words, and assessing their compatibility with the words already on the board. If no match is found, the process shifts focus to another promising candidate. Otherwise, the word is added to the crossword, and the search continues. The cycle concludes either when the board is fully populated or no more suitable words can be found, which may be due to either incorrect existing words or the absence of matching words. Notably, this entire pro- cess unfolds within a single generation window. The algo- rithmic examples in our prompt (detailed in the Appendix)\",\n",
      "  \"include three that achieve game completion and two that pre- dominantly populate the crossword, filling 8 or 9 slots.\",\n",
      "  \"Results. Table 3 underscores AoT\\u2019s proficiency in the mini crosswords task, showcasing a word success rate\\u2014a measure used in existing studies to represent the percent- age of words correctly completed out of the total\\u2014that sur- passes earlier methods reliant on various prompting tech- niques. However, it trails behind ToT. An important observa- tion is the sheer volume of queries ToT employs, exceeding AoT\\u2019s by over a factor of 100. One factor hindering AoT from surpassing ToT is that the backtracking capability in- herent in the algorithmic example isn\\u2019t fully activated. Fully unlocking this capability would lead to a significant elonga- tion in the generation phase. In contrast, ToT has the advan- tage of leveraging external memory for its backtracking.\",\n",
      "  \"Method Standard Prompting CoT ToT AoT (ours)\",\n",
      "  \"Word Success Avg. Queries 14% 15.6% 60% 52%\",\n",
      "  \"1 1 >200 2\",\n",
      "  \"Table 3: 5 \\u00d7 5 mini crosswords word: word success rates and the average number of LLM queries for each example.\",\n",
      "  \"Error Analysis. To understand the prevalent mistakes made by AoT, we\\u2019ve categorized the errors into four dis- tinct categories. In our analysis for each game, we focus on the initial error the LLM produces while charting its rea- soning path, given that an early error typically cascades into subsequent failures. 1) No preselections: LLM fails to gen- erate compatible words essential for the warm-start phase. Given a correctly preselected word, the second phase for re- cursive reasoning can exhibit errors including: 2) Expres- sion misstep: The LLM mistakenly believes it has exhausted all choices and jumps to an answer prematurely. 3) Incor- rect pattern extraction: The LLM wrongly extracts a pattern based on the current board layout. 4) Erroneous word place- ment: Despite recognizing the correct pattern, the LLM se- lects a mismatched word or misses better-fitting alternatives. Navigating the crossword complexity arises from outdated terms, esoteric references, and typographical mishaps. Pre- dominantly, the errors observed are due to misguided word placements followed by pattern misinterpretations. Also, the LLM seems challenged in aligning letters at precise indices to create word structures\\u2014 an obstracle circumvented by an external mechanism in the ToT framework.\",\n",
      "  \"Discussion In this section, we delve into crucial aspects to consider when crafting prompts for AoT, using the game of 24 as our primary case study.\",\n",
      "  \"Can AoT surpass the DFS it\\u2019s patterned after? A core query of ours is to ascertain if the LLM has the capability to not only mirror but also outdo the efficiency of the al- gorithm introduced in-context. As evidenced in Fig. 5, AoT\",\n",
      "  \"Error Type No preselections Expression misstep Incorrect pattern extraction Erroneous word placement\",\n",
      "  \"Error 15.8% 5.3% 26.3% 52.6%\",\n",
      "  \"Table 4: Breakdown of errors in 5 \\u00d7 5 mini crosswords with AoT. Numbers indicate the relative percentage of each error type among all errors.\",\n",
      "  \"systematically navigates fewer nodes than its DFS counter- part. While DFS employs a uniform strategy when choosing the subsequent subtree to investigate, AoT\\u2019s LLM integrates its inherent heuristic. This amplification over the base algo- rithm exemplifies the advantages of LLM\\u2019s recursive reason- ing capability.\",\n",
      "  \"0\",\n",
      "  \"800\",\n",
      "  \"8\",\n",
      "  \"12\",\n",
      "  \"200\",\n",
      "  \"AoT\",\n",
      "  \"20# of Games\",\n",
      "  \"0\",\n",
      "  \"400\",\n",
      "  \"1000# of Visited Nodes\",\n",
      "  \"600\",\n",
      "  \"4\",\n",
      "  \"DFS\",\n",
      "  \"16\",\n",
      "  \"Figure 5: Histogram showing the number of visited nodes for AoT and DFS in the Game of 24.\",\n",
      "  \"How does algorithm selection influence AoT\\u2019s efficacy? To explore the impact of algorithm choice on AoT\\u2019s per- formance, we implemented both BFS and random search within the AoT framework. Our findings, presented in Ta- ble 5, reveal that all three AoT variations outperform the single-query CoT. This outcome was anticipated as AoT, ir- respective of the algorithm, undertakes a search and revis- its potential mistakes\\u2014either by random retry in the ran- dom search variant or through backtracking in the DFS and BFS configurations. Notably, the structured search versions, AoT (DFS) and AoT (BFS), displayed better efficiency than AoT (Random), underscoring the advantage of algorithmic insights in solution discovery. However, AoT (BFS) lagged behind AoT (DFS). Closer inspection of errors made by AoT (BFS) revealed the LLM faced greater challenges in identi- fying optimal operations than its DFS counterpart.\",\n",
      "  \"How does the search step count within the algorithmic example modulate AoT\\u2019s behavior? We begin with the standard AoT prompt and modify the subtree explorations. In AoT (Short), each in-context example uses one or two steps to reach a solution, while AoT (Long) incorporates three to five extra subtree explorations. The impact on total search steps is illustrated in Fig. 6. Our observations high- light longer generations for AoT (Long) and shorter ones\",\n",
      "  \"Method CoT CoT-SC (k=100) ToT AoT (DFS) AoT (BFS) AoT (Random)\",\n",
      "  \"Success Avg. Queries 1 4% 100 9% 109.1 69% 1 71% 1 48% 1 20%\",\n",
      "  \"Table 5: Comparative success rates and average LLM query counts for AoT variations templated by distinct algorithms.\",\n",
      "  \"for AoT (Short) relative to the original AoT. This suggests that the search step count introduces an implicit bias on the LLM\\u2019s search velocity. Notably, even when navigating in- correct steps, it\\u2019s essential to emphasize the exploration of promising directions.\",\n",
      "  \"0\",\n",
      "  \"20\",\n",
      "  \"200\",\n",
      "  \"AoT (Long)\",\n",
      "  \"400# of Visited Nodes\",\n",
      "  \"60\",\n",
      "  \"50\",\n",
      "  \"0\",\n",
      "  \"100\",\n",
      "  \"250\",\n",
      "  \"AoT\",\n",
      "  \"100# of Games\",\n",
      "  \"150\",\n",
      "  \"80\",\n",
      "  \"40\",\n",
      "  \"350\",\n",
      "  \"300\",\n",
      "  \"AoT (Short)\",\n",
      "  \"Figure 6: Comparison of AoT with shorter and longer in- context examples prompted AoT versions: cumulative num- ber of games for the number of visited nodes.\",\n",
      "  \"Limitations. While AoT substantially cuts down on the number of queries relative to ToT, its resource demands ex- ceed those of standard prompting and CoT, a consequence of its extensive exploration of ideas via token generation. Crafting token-efficient algorithmic examples is one avenue, but there\\u2019s also potential in judiciously tapping into or un- locking the LLM\\u2019s \\u201ctunnel-vision\\u201d. Our research primarily spotlighted certain algorithms, with a keen focus on tree- search tasks. It\\u2019s pertinent to highlight that we conducted our tests exclusively with GPT-4. Though more costly than other LLMs, GPT-4\\u2019s advanced capabilities appear pivotal for AoT\\u2019s optimal functioning; models of lesser caliber might not yield comparable performance boosts from AoT.\",\n",
      "  \"Conclusion This paper presents the Algorithm of Thoughts, a pioneer- ing prompting strategy to navigate reasoning pathways in LLMs using minimal queries. Our findings reveal that this method not only substantially surpasses prior single-query techniques but also rivals external tree-search implementa- tions. Such an approach augments the potential to stream- line idea discovery in LLMs, balancing both cost and com- putational demands. Future work includes designing token-\",\n",
      "  \"efficient algorithmic examples, developing adaptive mecha- nisms for \\u201ctunnel-vision\\u201d activation to expedite the search, and deepening the understanding of this fresh mode of in- context learning from theoretical angles.\",\n",
      "  \"References Aminabadi, R. Y.; Rajbhandari, S.; Awan, A. A.; Li, C.; Li, D.; Zheng, E.; Ruwase, O.; Smith, S.; Zhang, M.; Rasley, J.; et al. 2022. DeepSpeed-inference: enabling efficient infer- ence of transformer models at unprecedented scale. In SC22: International Conference for High Performance Computing, Networking, Storage and Analysis, 1\\u201315. IEEE. Austin, J.; Odena, A.; Nye, M.; Bosma, M.; Michalewski, H.; Dohan, D.; Jiang, E.; Cai, C.; Terry, M.; Le, Q.; et al. 2021. Program synthesis with large language models. arXiv preprint arXiv:2108.07732. Baddeley, A. 2003. Working memory: looking back and looking forward. Nature reviews neuroscience, 4(10): 829\\u2013 839. Bai, Y.; Kadavath, S.; Kundu, S.; Askell, A.; Kernion, J.; Jones, A.; Chen, A.; Goldie, A.; Mirhoseini, A.; McKinnon, C.; Chen, C.; Olsson, C.; Olah, C.; Hernandez, D.; Drain, D.; Ganguli, D.; Li, D.; Tran-Johnson, E.; Perez, E.; Kerr, J.; Mueller, J.; Ladish, J.; Landau, J.; Ndousse, K.; Lukosuite, K.; Lovitt, L.; Sellitto, M.; Elhage, N.; Schiefer, N.; Mer- cado, N.; DasSarma, N.; Lasenby, R.; Larson, R.; Ringer, S.; Johnston, S.; Kravec, S.; Showk, S. E.; Fort, S.; Lanham, T.; Telleen-Lawton, T.; Conerly, T.; Henighan, T.; Hume, T.; Bowman, S. R.; Hatfield-Dodds, Z.; Mann, B.; Amodei, D.; Joseph, N.; McCandlish, S.; Brown, T.; and Kaplan, J. 2022. Constitutional AI: Harmlessness from AI Feedback. ArXiv:2212.08073 [cs]. Banerjee, S.; Bringsjord, S.; Giancola, M.; and Govindara- julu, N. S. 2022. Qualitative Mechanical Problem-Solving by Artificial Agents:: Further Progress, Under Psychometric AI. In The International FLAIRS Conference Proceedings, volume 35. Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; Agarwal, S.; Herbert-Voss, A.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.; Ziegler, D.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.; Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford, A.; Sutskever, I.; and Amodei, D. 2020. Language Mod- els are Few-Shot Learners. Advances in Neural Information Processing Systems, 33: 1877\\u20131901. Chen, L.; Zaharia, M.; and Zou, J. 2023. FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance. arXiv preprint arXiv:2305.05176. Chen, M.; Tworek, J.; Jun, H.; Yuan, Q.; Pinto, H. P. d. O.; Kaplan, J.; Edwards, H.; Burda, Y.; Joseph, N.; Brockman, G.; et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374. Chowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra, G.; Roberts, A.; Barham, P.; Chung, H. W.; Sutton, C.; Gehrmann, S.; et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311.\",\n",
      "  \"Dhar, P. 2020. The carbon impact of artificial intelligence. Nat. Mach. Intell., 2(8): 423\\u2013425. Drozdov, A.; Sch\\u00a8arli, N.; Aky\\u00a8urek, E.; Scales, N.; Song, X.; Chen, X.; Bousquet, O.; and Zhou, D. 2022. Compositional Semantic Parsing with Large Language Models. Helie, S.; and Pizlo, Z. 2022. When is psychology research useful in artificial intelligence? A case for reducing compu- tational complexity in problem solving. Topics in Cognitive Science, 14(4): 687\\u2013701. Holyoak, K. J.; and Morrison, R. G. 2005. The Cambridge handbook of thinking and reasoning. Cambridge University Press. Huang, J.; and Chang, K. C.-C. 2022. Towards reason- ing in large language models: A survey. arXiv preprint arXiv:2212.10403. Kadavath, S.; Conerly, T.; Askell, A.; Henighan, T.; Drain, D.; Perez, E.; Schiefer, N.; Hatfield-Dodds, Z.; DasSarma, N.; Tran-Johnson, E.; et al. 2022. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221. Kahneman, D. 2011. Thinking, fast and slow. macmillan. Kojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y.; and Iwasawa, Y. 2022. Large Language Models are Zero-Shot Reason- ers. Advances in Neural Information Processing Systems, 35: 22199\\u201322213. Lanham, T.; Chen, A.; Radhakrishnan, A.; Steiner, B.; Deni- son, C.; Hernandez, D.; Li, D.; Durmus, E.; Hubinger, E.; Kernion, J.; et al. 2023. Measuring Faithfulness in Chain- of-Thought Reasoning. arXiv preprint arXiv:2307.13702. Liang, P.; Bommasani, R.; Lee, T.; Tsipras, D.; Soylu, D.; Yasunaga, M.; Zhang, Y.; Narayanan, D.; Wu, Y.; Kumar, A.; et al. 2022. Holistic evaluation of language models. arXiv preprint arXiv:2211.09110. Libby, M. E.; Weiss, J. S.; Bancroft, S.; and Ahearn, W. H. 2008. A comparison of most-to-least and least-to-most prompting on the acquisition of solitary play skills. Behav- ior analysis in practice, 1: 37\\u201343. Liu, Y.; Han, T.; Ma, S.; Zhang, J.; Yang, Y.; Tian, J.; He, H.; Li, A.; He, M.; Liu, Z.; et al. 2023. Summary of chatgpt/gpt- 4 research and perspective towards the future of large lan- guage models. arXiv preprint arXiv:2304.01852. Long, J. 2023. Large Language Model Guided Tree-of- Thought. arXiv preprint arXiv:2305.08291. Lyu, Q.; Havaldar, S.; Stein, A.; Zhang, L.; Rao, D.; Wong, E.; Apidianaki, M.; and Callison-Burch, C. 2023. Faithful Chain-of-Thought Reasoning. ArXiv:2301.13379 [cs]. Mialon, G.; Dess`\\u0131, R.; Lomeli, M.; Nalmpantis, C.; Pa- sunuru, R.; Raileanu, R.; Rozi`ere, B.; Schick, T.; Dwivedi- Yu, J.; Celikyilmaz, A.; et al. 2023. Augmented language models: a survey. arXiv preprint arXiv:2302.07842. Monsell, S. 2003. Task switching. Trends in cognitive sci- ences, 7(3): 134\\u2013140. Ouyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright, C.; Mishkin, P.; Zhang, C.; Agarwal, S.; Slama, K.; Ray, A.; et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Pro- cessing Systems, 35: 27730\\u201327744.\",\n",
      "  \"Robinson, J.; and Wingate, D. 2022. Leveraging Large Lan- guage Models for Multiple Choice Question Answering. Shao, Z.; Gong, Y.; Shen, Y.; Huang, M.; Duan, N.; and Chen, W. 2023. Synthetic Prompting: Generating Chain- of-Thought Demonstrations for Large Language Models. Sloman, S. A. 1996. The empirical case for two systems of reasoning. Psychological bulletin, 119(1): 3. Srivastava, A.; Rastogi, A.; Rao, A.; Shoeb, A. A. M.; Abid, A.; Fisch, A.; Brown, A. R.; Santoro, A.; Gupta, A.; Garriga- Alonso, A.; et al. 2022. Beyond the imitation game: Quanti- fying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615. Suzgun, M.; Scales, N.; Sch\\u00a8arli, N.; Gehrmann, S.; Tay, Y.; Chung, H. W.; Chowdhery, A.; Le, Q. V.; Chi, E. H.; Zhou, D.; and Wei, J. 2022. Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them. ArXiv:2210.09261 [cs]. Thoppilan, R.; De Freitas, D.; Hall, J.; Shazeer, N.; Kul- shreshtha, A.; Cheng, H.-T.; Jin, A.; Bos, T.; Baker, L.; Du, Y.; et al. 2022. Lamda: Language models for dialog appli- cations. arXiv preprint arXiv:2201.08239. Turpin, M.; Michael, J.; Perez, E.; and Bowman, S. R. 2023. Language Models Don\\u2019t Always Say What They Think: Un- faithful Explanations in Chain-of-Thought Prompting. arXiv preprint arXiv:2305.04388. Wang, X.; Wei, J.; Schuurmans, D.; Le, Q. V.; Chi, E. H.; Narang, S.; Chowdhery, A.; and Zhou, D. 2022. Self- Consistency Improves Chain of Thought Reasoning in Lan- guage Models. Wei, J.; Tay, Y.; Bommasani, R.; Raffel, C.; Zoph, B.; Borgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler, D.; Chi, E. H.; Hashimoto, T.; Vinyals, O.; Liang, P.; Dean, J.; and Fedus, W. 2022a. Emergent Abilities of Large Lan- guage Models. ArXiv:2206.07682 [cs]. Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Ichter, B.; Xia, F.; Chi, E.; Le, Q. V.; and Zhou, D. 2022b. Chain- of-Thought Prompting Elicits Reasoning in Large Language Models. Advances in Neural Information Processing Sys- tems, 35: 24824\\u201324837. Wu, C.-J.; Raghavendra, R.; Gupta, U.; Acun, B.; Ardalani, N.; Maeng, K.; Chang, G.; Aga, F.; Huang, J.; Bai, C.; et al. 2022. Sustainable ai: Environmental implications, chal- lenges and opportunities. Proceedings of Machine Learning and Systems, 4: 795\\u2013813. Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.; Cao, Y.; and Narasimhan, K. 2023. Tree of Thoughts: Deliberate Problem Solving with Large Language Models. ArXiv:2305.10601 [cs]. Zelikman, E.; Wu, Y.; Mu, J.; and Goodman, N. 2022. Star: Bootstrapping reasoning with reasoning. Advances in Neu- ral Information Processing Systems, 35: 15476\\u201315488. Zhang, Z.; Zhang, A.; Li, M.; and Smola, A. 2022. Auto- matic Chain of Thought Prompting in Large Language Mod- els. Zhou, D.; Sch\\u00a8arli, N.; Hou, L.; Wei, J.; Scales, N.; Wang, X.; Schuurmans, D.; Cui, C.; Bousquet, O.; Le, Q. V.; and\",\n",
      "  \"Chi, E. H. 2022. Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.\",\n",
      "  \"Game of 24 - Additional Details\",\n",
      "  \"In order to avoid confusion in our analysis of AoT in the game of 24, we give additional details in terms of terminologies we use as well as their direct implications in the performance figures. An Illustration of these are given in Fig. 7.\",\n",
      "  \"4 - 4 = 8(left: 8, 6, 0)4 + 2 = 6(left: 6, 4)4 / 4 = 1(left: 2, 1)6 * 4 = 24(left: 24)6 + 4 = 10(left: 10)...Input: 8 6 4 4First OperationsSecond OperationsThird OperationsVisited Nodes8 - 6 = 2(left: 4, 4, 2)...Subtree Exploration\",\n",
      "  \"Figure 7: An illustration of terminologies we use for the game of 24. The yellow nodes represent the first operations and the states they lead to; the green node represents the node where we find the solution; all other nodes are represented by pink.\",\n",
      "  \"First operations / First iterations. This represents the scenario that after we choose the first two number in the game of 24, the case of either adding, subtracting, multiplying or dividing them.\",\n",
      "  \"Subtree Exploration. This denotes searching all or most of the nodes coming from the same state, typically states with less than four numbers left.\",\n",
      "  \"Number of nodes visited. This is the number of states that the method has been on the game of 24. Each state is the set of number we are left with, after our operations in the numbers. For example, after the first operation we might be left with the numbers \\u20188 3 1\\u2019. This set of numbers represent a state, as well as the state of \\u20188 3\\u2019 that we will be left with after another operation of \\u20188 \\u2217 1 = 8\\u2019.\",\n",
      "  \"Creative Writing\",\n",
      "  \"We use the creative writing task, also used by (Yao et al. 2023), where the LLM is provided with four arbitrary sentences. The objective is to craft a cohesive narrative divided into four paragraphs, with each paragraph culminating in one of the given sentences. This exercise not only fosters creativity but also emphasizes strategic deliberation.\",\n",
      "  \"Task Setup\",\n",
      "  \"Sentences are randomly sourced from randomwordgenerator.com, resulting in 100 distinct sets of inputs. Given the absence of predetermined correct answers, the primary focus lies in evaluating the coherence of the responses. We have noted that GPT-4 consistently aligns with these input guidelines. Evaluation is centered around assessing passage coherence using a GPT-4 zero- shot prompt, where each output is rated on a scale of 1 to 10. Each task response undergoes five such evaluations, with their scores being averaged subsequently.\",\n",
      "  \"Baselines\",\n",
      "  \"For this task, both standard and CoT prompts are employed without preliminary training. While the standard prompt directly guides the LLM to fashion a cohesive narrative based on stipulated parameters, the CoT prompt obliges the model to initially outline a succinct plan prior to drafting the narrative, serving as an intermediate cognitive bridge. For each task iteration, ten samples are generated using both the standard and CoT methods. Results of the ToT approach are presented without modification.\",\n",
      "  \"AoT Setup Mirroring ToT\\u2019s methodology, the task is tackled in a zero-shot setting. Our prompt instructs the model to first formulate five distinct plans. Subsequent to this, the model selects the most promising among them to shape a narrative and then refines it for optimal coherence. The exact prompts used for this zero-shot approach will be provided in the subsequent section.\",\n",
      "  \"Results As depicted in Fig. 8, AoT outpaces other singular query prompting techniques such as standard prompting and CoT in terms of performance. It also exhibits a marked improvement over ToT, although the difference is not statistically significant. Com- prehensive scores, along with the average query count needed for each method, are consolidated in Table 6. Notably, AoT necessitates fewer queries compared to ToT.\",\n",
      "  \"2\",\n",
      "  \"4\",\n",
      "  \"6\",\n",
      "  \"0\",\n",
      "  \"10\",\n",
      "  \"8\",\n",
      "  \"StandardCoTToTAoT\",\n",
      "  \"Figure 8: Comparison of the standard prompting, CoT, ToT and AoT on the creative writing task.\",\n",
      "  \"Method Standard Prompting CoT ToT AoT\",\n",
      "  \"Score Avg. Queries 6.19 6.93 7.56 7.58\",\n",
      "  \"1 1 20 1\",\n",
      "  \"Table 6: Performance of the methods determined by GPT-4.\",\n",
      "  \"CoT vs. Single Iteration AoT in the Game of 24 To demonstrate that the tree search mechanism is fundamentally distinct from the CoT prompting, even in scenarios where AoT\\u2019s in-context examples include only a single initial operation in the game of 24, we draw a comparison between AoT (Short) and CoT. In this setup, AoT (Short) determines the first operation and subsequently conducts a tree search on the remaining three numbers. Interestingly, AoT (Short) achieves a success rate of 48%, while CoT lags significantly, securing only 4%. These results underscore the notion that even a rudimentary search mechanism can lead to significant performance enhancements.\",\n",
      "  \"Detailed Analysis on the Effect of the Length of the Prompts In this section, we delve deeper into Fig. 6 by presenting histograms for the successful, unsuccessful, and total games of \\u201824\\u2019, considering the number of initial steps in methods AoT (Short), AoT, and AoT (Long). These are displayed in Figs. 9-11.\",\n",
      "  \"From these figures, it becomes evident that the length of the prompts, measured by the number of initial steps included in in-context examples, correlates with the length of their solutions to test examples. This trend is consistent across all three cases, suggesting that AoT\\u2019s strategy in determining the number of initial steps is influenced by its in-context examples.\",\n",
      "  \"Interestingly, when AoT is provided a well-balanced set of initial steps that emphasize the most promising operations, it excels in solving the majority of games in earlier iterations. This indicates AoT\\u2019s capacity to prioritize swift problem-solving without sacrificing performance. This tendency is also observed in AoT (Long), albeit with a somewhat reduced success rate, as illustrated in Fig. 9.\",\n",
      "  \"8\",\n",
      "  \"8\",\n",
      "  \"12# of First Steps\",\n",
      "  \"0\",\n",
      "  \"2\",\n",
      "  \"0\",\n",
      "  \"40# of Successful Games\",\n",
      "  \"AoT (Short)\",\n",
      "  \"40\",\n",
      "  \"10\",\n",
      "  \"8\",\n",
      "  \"12\",\n",
      "  \"2\",\n",
      "  \"20\",\n",
      "  \"20\",\n",
      "  \"0\",\n",
      "  \"4\",\n",
      "  \"20\",\n",
      "  \"2\",\n",
      "  \"6\",\n",
      "  \"AoT\",\n",
      "  \"6\",\n",
      "  \"4\",\n",
      "  \"0\",\n",
      "  \"40\",\n",
      "  \"0\",\n",
      "  \"6\",\n",
      "  \"10\",\n",
      "  \"0\",\n",
      "  \"12\",\n",
      "  \"10\",\n",
      "  \"AoT (Long)\",\n",
      "  \"4\",\n",
      "  \"Figure 9: Histogram of the number of successful games with respect to the number of first steps for AoT (Short), AoT and AoT (Long).\",\n",
      "  \"0\",\n",
      "  \"2\",\n",
      "  \"12\",\n",
      "  \"0\",\n",
      "  \"20\",\n",
      "  \"6\",\n",
      "  \"4\",\n",
      "  \"20\",\n",
      "  \"6\",\n",
      "  \"8\",\n",
      "  \"0\",\n",
      "  \"AoT\",\n",
      "  \"6\",\n",
      "  \"AoT (Long)\",\n",
      "  \"8\",\n",
      "  \"12\",\n",
      "  \"4\",\n",
      "  \"4\",\n",
      "  \"40# of Unsuccessful Games\",\n",
      "  \"2\",\n",
      "  \"AoT (Short)\",\n",
      "  \"20\",\n",
      "  \"10\",\n",
      "  \"40\",\n",
      "  \"0\",\n",
      "  \"10\",\n",
      "  \"10\",\n",
      "  \"8\",\n",
      "  \"0\",\n",
      "  \"2\",\n",
      "  \"0\",\n",
      "  \"12# of First Steps\",\n",
      "  \"40\",\n",
      "  \"Figure 10: Histogram of the number of unsuccessful games with respect to the number of first steps for AoT (Short), AoT and AoT (Long).\",\n",
      "  \"Prompts\",\n",
      "  \"Game of 24 Below, we represent the specific prompts employed for the various methods detailed in the experiments section. It\\u2019s important to note that the terms \\u201cSystem\\u201d,\\u201cUser\\u201d, and \\u201cAssistant\\u201d are utilized to denote the roles within the OpenAI API when operating in chat completion mode. The line breaks serve to show the transitions between the user and assistant interactions within the API.\",\n",
      "  \"AoT (DFS)\",\n",
      "  \"System:\",\n",
      "  \"2\",\n",
      "  \"8\",\n",
      "  \"12# of First Steps\",\n",
      "  \"0\",\n",
      "  \"10\",\n",
      "  \"50\",\n",
      "  \"4\",\n",
      "  \"50\",\n",
      "  \"50\",\n",
      "  \"AoT (Long)\",\n",
      "  \"0\",\n",
      "  \"100# of All Games\",\n",
      "  \"0\",\n",
      "  \"0\",\n",
      "  \"0\",\n",
      "  \"100\",\n",
      "  \"2\",\n",
      "  \"2\",\n",
      "  \"12\",\n",
      "  \"10\",\n",
      "  \"AoT (Short)\",\n",
      "  \"8\",\n",
      "  \"6\",\n",
      "  \"100\",\n",
      "  \"4\",\n",
      "  \"12\",\n",
      "  \"4\",\n",
      "  \"8\",\n",
      "  \"AoT\",\n",
      "  \"0\",\n",
      "  \"10\",\n",
      "  \"6\",\n",
      "  \"6\",\n",
      "  \"Figure 11: Histogram of the number of all games with respect to the number of first steps for AoT (Short), AoT and AoT (Long).\",\n",
      "  \"Use numbers and basic arithmetic operations (+ - * /) to obtain 24. When\",\n",
      "  \"considering the next steps, do not choose operations that will result in a negative or fractional number. In order to help with the calculations, the numbers in the parenthesis represent the numbers that are left after the operations and they are in descending order.\",\n",
      "  \"Another thing we do is when there are only two numbers left in the parenthesis, we\",\n",
      "  \"check whether we can arrive at 24 only by using basic arithmetic operations\",\n",
      "  \"(+ - * /). Some examples regarding this idea:\",\n",
      "  \"(21 2) no since 21 + 2 = 23, 21 - 2 = 19, 21 * 2 = 42, 21 / 2 = 10.5, none of which is equal\",\n",
      "  \"to 24.\",\n",
      "  \"(30 6) 30 - 6 = 24 yes (8 3) 8 * 3 = 24 yes (12 8) no (48 2) 48 / 2 = 24 yes\",\n",
      "  \"Most importantly, do not give up, all the numbers that will be given has indeed a\",\n",
      "  \"solution.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"14 8 8 2\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 8 + 2: (14, 10, 8) - 14 + 10: (24, 8) 32, 16, 192, 3 - 14 - 10: (8, 4) 12, 8, 32, 2 - 14 * 10: (140, 8) 148, 132, 1120, fractional - 14 / 10: (8, 1.4) fractional - 14 + 8: (22, 10) 32, 12, 220, fractional - 14 - 8: (10, 6) 16, 4, 60, fractional - 14 * 8: (112, 10) 122, 102, 1120, fractional - 14 / 8: fractional - 10 + 8: (18, 14) 32, 4, 252, fractional - 10 - 8: (14, 2) 16, 12, 28, 7 - 10 * 8: (80, 14) 94, 66, big, fractional - 10 / 8: fractional\",\n",
      "  \"Trying another promising first operation: 2. 8 / 2: (14, 8, 4) - 14 + 8: (22, 4) 26, 18, 88, fractional - 14 - 8: (6, 4) 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 8 / 2 = 4 Step 2: 14 - 8 = 6 Step 3: 6 * 4 = 24 Considering these steps: 24 = 6 * 4 = (14 - 8) * 4 = (14 - 8) * (8 / 2) = 24. answer: (14 - 8) * (8 / 2) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"9 5 5 5\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 9 - 5: (5, 5, 4) - 5 + 5: (10, 4) 14, 6, 40, fractional - 5 - 5: (4, 0) 4, 4, 0, undefined - 5 * 5: (25, 4) 29, 21, 100, fractional - 5 / 5: (4, 1) 5, 3, 4, 4 - 5 + 4: (9, 5) 14, 4, 45, fractional - 5 - 4: (5, 1) 6, 4, 5, 0.2 - 5 * 4: (20, 5) 25, 15, 100, fractional - 5 / 4: fractional\",\n",
      "  \"Trying another promising first operation: 2. 5 + 5: (10, 9, 5) - 10 + 9: (19, 5) 24 = 19 + 5 -> found it! Backtracking the solution: Step 1: 5 + 5 = 10 Step 2: 10 + 9 = 19 Step 3: 19 + 5 = 24 Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24. answer: ((5 + 5) + 9) + 5 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"8 6 4 4\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 8 - 6: (4, 4, 2) - 4 + 4: (8, 2) 10, 6, 16, 4 - 4 - 4: (2, 0) 2, 2, 0, undefined - 4 * 4: (16, 2) 18, 14, 32, 8 - 4 / 4: (2, 1) 3, 1, 2, 2 - 4 + 2: (6, 4) 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 8 - 6 = 2 Step 2: 4 + 2 = 6 Step 3: 6 * 4 = 24 Considering these steps: 24 = 6 * 4 = (4 + 2) * 4 = (4 + (8 - 6)) * 4 = 24. answer: (4 + (8 - 6)) * 4 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"13 10 9 4\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 13 - 4: (10, 9, 9) - 10 + 9: (19, 9) 28, 10, 171, fractional - 10 - 9: (9, 1) 10, 8, 9, 9 - 10 * 9: (90, 9) 99, 81, 810, fractional - 10 / 9: fractional - 9 + 9: (18, 10) 28, 8, 180, fractional - 9 - 9: (10, 0) 10, 10, 0, undefined - 9 * 9: (81, 10) 91, 71, 810, fractional - 9 / 9: (10, 1) 11, 9, 10, 10\",\n",
      "  \"Trying another promising first operation: 2. 10 - 4: (13, 9, 6) - 13 + 9: (22, 6) 28, 16, 132, fractional - 13 - 9: (6, 4) 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 10 - 4 = 6 Step 2: 13 - 9 = 4 Step 3: 6 * 4 = 24 Considering these steps: 24 = 6 * 4 = 6 * (13 - 9) = (10 - 4) * (13 - 9) = 24. answer: (10 - 4) * (13 - 9) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"8 8 5 4\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 8 - 4: (8, 5, 4) - 8 + 5: (13, 4) 17, 9, 52, fractional - 8 - 5: (4, 3) 7, 1, 12, fractional - 8 * 5: (40, 4) 44, 36, 160, fractional - 8 / 5: fractional - 8 + 4: (12, 5) 17, 7, 60, fractional - 8 - 4: (5, 4) 9, 1, 20, fractional - 8 * 4: (32, 5) 37, 27, 160, fractional - 8 / 4: (5, 2) 7, 3, 10, 2.5 - 5 + 4: (9, 8) 17, 1, 72, fractional - 5 - 4: (8, 1) 9, 7, 8, 8 - 5 * 4: (20, 8) 28, 12, 160, fractional - 5 / 4: fractional\",\n",
      "  \"Trying another promising first operation: 2. 8 / 4: (8, 5, 2) - 8 + 5: (13, 2) 15, 11, 26, fractional - 8 - 5: (3, 2) 5, 1, 6, 1.5 - 8 * 5: (40, 2) 42, 38, 80, 20 - 8 / 5: fractional - 8 + 2: (10, 5) 15, 5, 50, 2 - 8 - 2: (6, 5) 11, 1, 30, fractional - 8 * 2: (16, 5) 21, 11, 80, fractional - 8 / 2: (5, 4) 9, 1, 20, fractional - 5 + 2: (7, 8) 15, 1, 56, fractional - 5 - 2: (8, 3) 11, 5, 24 = 8 * 3 -> found it! Backtracking the solution: Step 1: 8 / 4 = 2 Step 2: 5 - 2 = 3 Step 3: 8 * 3 = 24 Considering these steps: 24 = 8 * 3 = 8 * (5 - 2) = 8 * (5 - (8 / 4)) = 24. answer: 8 * (5 - (8 / 4)) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\",\n",
      "  \"User:\",\n",
      "  \"11 11 1 1\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 11 - 1: (11, 10, 1) - 11 + 10: (21, 1) 22, 20, 21, 21 - 11 - 10: (1, 1) 2, 0, 1, 1 - 11 * 10: (110, 1) 111, 109, 110, 110 - 11 / 10: fractional - 11 + 1: (12, 10) 22, 2, 120, 1.2 - 11 - 1: (10, 10) 20, 0, 100, 1 - 11 * 1: (11, 10) 21, 1, 110, 1.1 - 11 / 1: (11, 10) 21, 1, 110, fractional - 10 + 1: (11, 11) 22, 0, 121, 1 - 10 - 1: (11, 9) 20, 2, 99, 1.1 - 10 * 1: (11, 10) 21, 1, 110, 1.1 - 10 / 1: (11, 10) 21, 1, 110, 1.1\",\n",
      "  \"Trying another promising first operation: 2. 11 + 1: (12, 11, 1) - 12 + 11: (23, 1) 24 = 23 + 1 -> found it! Backtracking the solution: Step 1: 11 + 1 = 12 Step 2: 12 + 11 = 23 Step 3: 23 + 1 Considering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24. answer: ((11 + 1) + 11) + 1 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"11 7 4 1\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 7 * 4: (28, 11, 1) - 28 + 11: (39, 1) 40, 38, 39, 39 - 28 - 11: (17, 1) 18, 16, 17, 17 - 28 * 11: (308, 1) 309, 307, 308, 308 - 28 / 11: fractional - 28 + 1: (29, 11) 40, 18, 319, fractional - 28 - 1: (27, 11) 38, 16, 297, fractional - 28 * 1: (28, 11) 39, 17, 308, fractional - 28 / 1: (28, 11) 39, 17, 308, fractional - 11 + 1: (29, 28) 57, 1, 812, fractional - 11 - 1: (28, 10) 38, 18, 280, fractional - 11 * 1: (28, 11) 39, 17, 308, fractional - 11 / 1: (28, 11) 39, 17, 308, fractional\",\n",
      "  \"Trying another promising first operation: 2. 7 + 1: (11 8 4) - 11 + 8: (19, 4) 23, 15, 76, fractional - 11 - 8: (4, 3) 7, 1, 12, fractional - 11 * 8: (88, 4) 92, 84, 352, fractional - 11 / 8: fractional - 11 + 4: (15, 8) 23, 7, 120, fractional - 11 - 4: (7, 8) 15, -1, 56, fractional - 11 * 4: (44, 8) 52, 36, 352, fractional - 11 / 4: fractional - 8 + 4: (12, 11) 23, -1, 132, fractional - 8 - 4: (11, 4) 15, 7, 44, fractional - 8 * 4: (32, 11) 43, 21, 352, fractional - 8 / 4: (11, 2) 13, 9, 22, fractional\",\n",
      "  \"Trying another promising first operation:\",\n",
      "  \"3. 4 + 1: (11 7 5) - 11 + 7: (18, 5) 23, 13, 90, fractional - 11 - 7: (5, 4) 9, 1, 20, fractional - 11 * 7: (77, 5) 82, 72, 385, fractional - 11 / 7: fractional - 11 + 5: (16, 7) 23, 9, 112, fractional - 11 - 5: (7, 6) 13, 1, 42, fractional - 11 * 5: (55, 7) 62, 48, 385, fractional - 11 / 5: fractional - 7 + 5: (12, 11) 23, 1, 132, fractional - 7 - 5: (11, 2) 13, 9, 22, fractional - 7 * 5: (35, 11) 46, 24 = 35 - 11 -> found it! Step 1: 4 + 1 = 5 Step 2: 7 * 5 = 35 Step 3: 35 - 11 = 24 Considering these steps: Backtracking the solution: 24 = 35 - 11 = (7 * 5) - 11 = (7 * (4 + 1)) - 11 = 24. answer: (7 * (4 + 1)) - 11 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"11 5 4 3\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 5 * 4: (20, 11, 3) - 20 + 11: (31, 3) 34, 28, 93, fractional - 20 - 11: (9, 3) 12, 6, 27, 3 - 20 * 11: (220, 3) 223, 217, 660, fractional - 20 / 11: fractional - 20 + 3: (23, 11) 34, 12, 253, fractional - 20 - 3: (17, 11) 28, 6, 187, fractional - 20 * 3: (60, 11) 71, 49, 660, fractional - 20 / 3: fractional - 11 + 3: (14, 20) 34, -6, 280, fractional - 11 - 3: (8, 20) 28, -12, 160, fractional - 11 * 3: (33, 20) 53, 13, 660, fractional - 11 / 3: fractional\",\n",
      "  \"Trying another promising first operation: 2. 11 - 3: (8, 5, 4) - 8 + 5: (13, 4) 17, 9, 52, fractional - 8 - 5: (4, 3) 7, 1, 12, fractional - 8 * 5: (40, 4) 44, 36, 160, fractional - 8 / 5: fractional - 8 + 4: (12, 5) 17, 7, 60, fractional - 8 - 4: (5, 4) 9, 1, 20, fractional - 8 * 4: (32, 5) 37, 27, 160, fractional - 8 / 4: (5, 2) 7, 3, 10, 2.5 - 5 + 4: (9, 8) 17, 1, 72, fractional - 5 - 4: (8, 1) 9, 7, 8, 8 - 5 * 4: (20, 8) 28, 12, 160, fractional - 5 / 4: fractional\",\n",
      "  \"Trying another promising first operation: 3. 11 * 3: (33, 5, 4) - 33 + 5: (38, 4) 42, 34, 152, fractional - 33 - 5: (28, 4) 32, 24 = 28 - 4 -> found it! Backtracking the solution: Step 1: 11 * 3 = 33 Step 2: 33 - 5 = 28 Step 3:\",\n",
      "  \"28 - 4 = 24 Considering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 * 3) - 5) - 4 = 24. answer: ((11 * 3) - 5) - 4 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"13 12 5 2\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 12 + 2: (14, 13, 5) - 14 + 13: (27, 5) 32, 22, 135, fractional - 14 - 13: (5, 1) 6, 4, 5, 5 - 14 * 13: (182, 5) 187, 177, 910, fractional - 14 / 13: fractional - 14 + 5: (19, 13) 32, 6, 247, fractional - 14 - 5: (13, 9) 22, 4, 117, fractional - 14 * 5: (70, 13) 83, 57, 910, fractional - 14 / 5: fractional - 13 + 5: (18, 14) 32, 4, 252, fractional - 13 - 5: (14, 8) 22, 6, 112, fractional - 13 * 5: (65, 14) 79, 51, 910, fractional - 13 / 5: fractional\",\n",
      "  \"Trying another promising first operation: 2. 13 + 5: (18, 12, 2) - 18 + 12: (30, 2) 32, 28, 60, fractional - 18 - 12: (6, 2) 8, 4, 12, 3 - 18 * 12: (216, 2) 218, 214, 432, fractional - 18 / 12: fractional - 18 + 2: (20, 12) 32, 8, 240, fractional - 18 - 2: (16, 12) 28, 4, 192, fractional - 18 * 2: (36, 12) 48, 24 = 36 - 12 -> found it! Backtracking the solution: Step 1: 13 + 5 = 18 Step 2: 18 * 2 = 36 Step 3: 36 - 12 = 24 Considering these steps: 24 = 36 - 12 = (18 * 2) - 12 = ((13 + 5) * 2) - 12 = 24. answer: ((13 + 5) * 2) - 12 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"9 8 2 1\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 9 - 1: (8, 8, 2) - 8 + 8: (16, 2) 18, 14, 32, 8 - 8 - 8: (2, 0) 2, 2, 0, undefined - 8 * 8: (64, 2) 66, 62, 128, 32 - 8 / 8: (2, 1) 3, 1, 2, 2 - 8 + 2: (10, 8) 18, 2, 80, 4 - 8 - 2: (6, 8) 14, -2, 48, fractional - 8 * 2: (16, 8) 24 = 16 + 8 -> found it! Backtracking the solution: Step 1: 9 - 1 = 8 Step 2: 8 * 2 = 16 Step 3: 16 + 8 = 24 Considering these steps: 24 = 16 + 8 = (8 * 2) + 8 = ((9 - 1) * 2) + 8 = 24. answer: ((9 - 1) * 2) + 8 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\",\n",
      "  \"AoT (Long)\",\n",
      "  \"System:\",\n",
      "  \"Use numbers and basic arithmetic operations (+ - * /) to obtain 24. When\",\n",
      "  \"considering the next steps, do not choose operations that will result in a negative or fractional number. In order to help with the calculations, the numbers in the parenthesis represent the numbers that are left after the operations and they are in descending order.\",\n",
      "  \"Another thing we do is when there are only two numbers left in the parenthesis, we\",\n",
      "  \"check whether we can arrive at 24 only by using basic arithmetic operations\",\n",
      "  \"(+ - * /). Some examples regarding this idea:\",\n",
      "  \"(21 2) no since 21 + 2 = 23, 21 - 2 = 19, 21 * 2 = 42, 21 / 2 = 10.5, none of which is equal\",\n",
      "  \"to 24.\",\n",
      "  \"(30 6) 30 - 6 = 24 yes (8 3) 8 * 3 = 24 yes (12 8) no (48 2) 48 / 2 = 24 yes\",\n",
      "  \"Most importantly, do not give up, all the numbers that will be given has indeed a\",\n",
      "  \"solution.\",\n",
      "  \"User:\",\n",
      "  \"14 8 8 2\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 8 + 2: (14, 10, 8) - 14 + 10: (24, 8) 32, 16, 192, 3 - 14 - 10: (8, 4) 12, 8, 32, 2 - 14 * 10: (140, 8) 148, 132, 1120, fractional - 14 / 10: (8, 1.4) fractional - 14 + 8: (22, 10) 32, 12, 220, fractional - 14 - 8: (10, 6) 16, 4, 60, fractional - 14 * 8: (112, 10) 122, 102, 1120, fractional - 14 / 8: fractional - 10 + 8: (18, 14) 32, 4, 252, fractional - 10 - 8: (14, 2) 16, 12, 28, 7 - 10 * 8: (80, 14) 94, 66, big, fractional - 10 / 8: fractional\",\n",
      "  \"Trying another promising first operation: 2. 14 + 8: (22, 8, 2) - 22 + 8: (30, 2) 32, 28, 60, 15 - 22 - 8: (14, 2) 16, 12, 28, 7 - 22 * 8: (176, 2) 178, 174, 88 - 22 / 8: (2.75, 2) fractional - 22 + 2: (24, 8) 32, 16, 192, 3 - 22 - 2: (20, 8) 28, 12, 160, fractional - 22 * 2: (44, 8) 52, 36, 352, fractional - 22 / 2: (11, 8) 19, 3, 88, fractional - 8 + 2: (22, 10) 32, 12, 220, fractional - 8 - 2: (22, 6) 28, 16, 132, fractional - 8 * 2: (22, 16) 38, 6, 352, fractional - 8 / 2: (22, 4) 26, 18, 88, fractional\",\n",
      "  \"Trying another promising first operation: 3. 14 + 2: (16, 8, 8) - 16 + 8: (24, 8) 32, 16, 192, 3 - 16 - 8: (8, 8) 16, 0, 64, 1 - 16 * 8: (128, 8) 136, 120, 1024, 16 - 16 / 8: (8, 2) 10, 6, 16, 4 - 8 + 8: (16, 16 32, 0, 256, 1 - 8 - 8: (16, 0) 16, 16, 0, undefined - 8 * 8: (64, 16) 80, 48, 1024, 4 - 8 / 8: (16, 1) 17, 15, 16, 16\",\n",
      "  \"Trying another promising first operation:\",\n",
      "  \"4. 8 - 2: (14, 8, 6) - 14 + 8: (22, 14) 36, 8, 308, fractional - 14 - 8: (6, 6) 12, 0, 36, 1 - 14 * 8: (112, 6) 118, 106, 672, fractional - 14 / 8: (6, 1.75) fractional - 14 + 6: (20, 8) 22, 12, 160, fractional - 14 - 6: (8, 8) 16, 0, 64, 1 - 14 * 6: (84, 8) 92, 76, 672, fractional - 14 / 6: (8, 2.3) fractional - 8 + 6: (14, 14) 28, 0, 196, 1 - 8 - 6: (14, 2) 16, 12, 28, 7 - 8 * 6: (48, 14) 62, 34, 672, fractional - 8 / 6: (14, 1.3) fractional Trying another promising first operation: 5. 8 * 2: (16, 14, 8) - 16 + 14: (30, 8) 38, 22, 240, fractional - 16 - 14: (8, 2) 10, 6, 16, 4 - 16 * 14: (224, 8) 232, 216, 1792, 28 - 16 / 14: (8, 1.1) fractional - 16 + 8: (24, 14) 38, 10, 336, fractional - 16 - 8: (14, 8) 22, 6, 112, fractional - 16 * 8: (128, 14) 142, 112, 1792, fractional - 16 / 8: (14, 2) 16, 12, 28, 7 - 14 + 8: (22, 16) 38, 6, 352, fractional - 14 - 8: (16, 6) 22, 10, 96, fractional - 14 * 8: (112, 16) 128, 96, 1792, 7 - 14 / 8: (16, 1.7) fractional\",\n",
      "  \"Trying another promising first operation: 6. 14 * 2: (28, 8, 8) - 28 + 8: (36, 8) 44, 28, 288, fractional - 28 - 8: (20, 8) 28, 12, 160, fractional - 28 * 8: (224, 8) 232, 216, 1792, 28 - 28 / 8: (8, 3.5) fractional, fractional, 28, fractional - 8 + 8: (16, 16 32, 0, 256, 1 - 8 - 8: (16, 0) 16, 16, 0, undefined - 8 * 8: (64, 16) 80, 48, 1024, 4 - 8 / 8: (16, 1) 17, 15, 16, 16\",\n",
      "  \"Trying another promising first operation: 7. 8 / 2: (14, 8, 4) - 14 + 8: (22, 4) 26, 18, 88, fractional - 14 - 8: (6, 4) 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 8 / 2 = 4 Step 2: 14 - 8 = 6 Step 3: 6 * 4 = 24 Considering these steps: 24 = 6 * 4 = (14 - 8) * 4 = (14 - 8) * (8 / 2) = 24. answer: (14 - 8) * (8 / 2) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"9 5 5 5\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 9 - 5: (5, 5, 4) - 5 + 5: (10, 4) 14, 6, 40, fractional - 5 - 5: (4, 0) 4, 4, 0, undefined - 5 * 5: (25, 4) 29, 21, 100, fractional - 5 / 5: (4, 1) 5, 3, 4, 4 - 5 + 4: (9, 5) 14, 4, 45, fractional - 5 - 4: (5, 1) 6, 4, 5, 0.2\",\n",
      "  \"5 * 4: (20, 5) 25, 15, 100, fractional - 5 / 4: fractional\",\n",
      "  \"Trying another promising first operation: 2. 5 * 5: (25, 9, 5) - 25 + 9: (34, 5) 39, 29, 170, fractional - 25 - 9: (16, 5) 21, 11, 80, fractional - 25 * 9: (225, 5) 230, 220, 1125, 45 - 25 / 9: (5, 2.7) fractional - 25 + 5: (30, 9) 39, 21, 270, fractional - 25 - 5: (20, 9) 29, 11, 180, fractional - 25 * 5: (75, 9) 84, 66, 675, fractional - 25 / 5: (9, 5) 14, 4, 45, fractional - 9 + 5: (25, 14) 39, 11, 350, fractional - 9 - 5: (25, 4) 29, 21, 100, fractional - 9 * 5: (45, 25) 70, 20, 1125, fractional - 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\",\n",
      "  \"Trying another promising first operation: 3. 5 - 5: (9, 5, 0) - 9 + 5: (25, 14) 39, 11, 350, fractional - 9 - 5: (25, 4) 29, 21, 100, fractional - 9 * 5: (45, 25) 70, 20, 1125, fractional - 9 / 5: (25, 1.8) fractional, fractional, 45, fractional - 9 + 0: (9, 5) 14, 4, 45, fractional - 9 - 0: (9, 5) 14, 4, 45, fractional - 9 * 0: (5, 0) 5, 5, 0, undefined - 9 / 0: undefined - 5 + 0: (9, 5) 14, 4, 45, fractional - 5 - 0: (9, 5) 14, 4, 45, fractional - 5 * 0: (9, 0) 9, 9, 0, undefined - 5 / 0: undefined\",\n",
      "  \"Trying another promising first operation: 4. 5 / 5: (9, 5, 1) - 9 + 5: (25, 14) 39, 11, 350, fractional - 9 - 5: (25, 4) 29, 21, 100, fractional - 9 * 5: (45, 25) 70, 20, 1125, fractional - 9 / 5: (25, 1.8) fractional, fractional, 45, fractional - 9 + 1: (10, 5) 15, 5, 50, 2 - 9 - 1: (8, 5) 13, 3, 40, fractional - 9 * 1: (9, 5) 14, 4, 45, fractional - 9 / 1: (9, 5) 14, 4, 45, fractional - 5 + 1: (9, 6) 15, 3, 54, fractional - 5 - 1: (9, 4) 13, 5, 36, fractional - 5 * 1: (9, 5) 14, 4, 45, fractional - 5 / 1: (9, 5) 14, 4, 45, fractional\",\n",
      "  \"Trying another promising first operation: 5. 9 * 5: (45, 5, 5) - 45 + 5: (50, 5) 55, 45, 250, 10 - 45 - 5: (40, 5) 45, 35, 200, 8 - 45 * 5: (225, 5) 230, 220, 1125, 45 - 45 / 5: (9, 5) 14, 4, 45, fractional - 5 + 5: (10, 4) 14, 6, 40, fractional - 5 - 5: (4, 0) 4, 4, 0, undefined - 5 * 5: (25, 4) 29, 21, 100, fractional - 5 / 5: (4, 1) 5, 3, 4, 4\",\n",
      "  \"Trying another promising first operation: 6. 5 + 5: (10, 9, 5) - 10 + 9: (19, 5) 24 = 19 + 5 -> found it! Backtracking the solution: Step 1: 5 + 5 = 10\",\n",
      "  \"Step 2: 10 + 9 = 19 Step 3: 19 + 5 = 24 Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24. answer: ((5 + 5) + 9) + 5 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"8 6 4 4\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 8 * 6: (48, 4, 4) - 48 + 4: (52, 4) 56, 48, 208, 13 - 48 - 4: (44, 4) 48, 40, 176, 11 - 48 * 4: (192, 4) 196, 188, 768, 48 - 48 / 4: (12, 4) 16, 8, 48, 3 - 4 + 4: (48, 8) 56, 40, 384, 6 - 4 - 4: (48, 0) 48, 48, 0, undefined - 4 * 4: (48, 16) 64, 32, 768, 3 - 4 / 4: (48, 1) 49, 47, 48, 48\",\n",
      "  \"Trying another promising first operation: 2. 4 - 4: (8, 6, 0) - 8 + 6: (14, 0) 14, 14, 0, undefined - 8 - 6: (2, 0) 2, 2, 0, undefined - 8 * 6: (48, 0) 48, 48, 0, undefined - 8 / 6: (1.3, 0) fractional - 8 + 0: (8, 6) 14, 2, 48, fractional - 8 - 0: (8, 6) 14, 2, 48, fractional - 8 * 0: (6, 0) 6, 6, 0, undefined - 8 / 0: undefined - 6 + 0: (8, 6) 14, 2, 48, fractional - 6 - 0: (8, 6) 14, 2, 48, fractional - 6 * 0: (8, 0) 8, 8, 0, undefined - 6 / 0: undefined\",\n",
      "  \"Trying another promising first operation: 3. 4 / 4: (8, 6, 1) - 8 + 6: (14, 1) 15, 13, 14, 14 - 8 - 6: (2, 1) 3, 1, 2, 2 - 8 * 6: (48, 1) 49, 47, 48, 48 - 8 / 6: (1.3, 1) fractional - 8 + 1: (9, 6) 15, 3, 54, fractional - 8 - 1: (7, 6) 13, 1, 42, fractional - 8 * 1: (8, 6) 14, 2, 48, fractional - 8 / 1: (8, 6) 14, 2, 48, fractional - 6 + 1: (8, 7) 15, 1, 56, fractional - 6 - 1: (8, 5) 13, 3, 40, fractional - 6 * 1: (8, 6) 14, 2, 48, fractional - 6 / 1: (8, 1) 9, 7, 8, 8\",\n",
      "  \"Trying another promising first operation: 4. 8 - 6: (4, 4, 2) - 4 + 4: (8, 2) 10, 6, 16, 4 - 4 - 4: (2, 0) 2, 2, 0, undefined - 4 * 4: (16, 2) 18, 14, 32, 8 - 4 / 4: (2, 1) 3, 1, 2, 2 - 4 + 2: (6, 4) 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 8 - 6 = 2 Step 2: 4 + 2 = 6 Step 3: 6 * 4 = 24\",\n",
      "  \"Considering these steps: 24 = 6 * 4 = (4 + 2) * 4 = (4 + (8 - 6)) * 4 = 24. answer: (4 + (8 - 6)) * 4 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"13 10 9 4\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 13 - 4: (10, 9, 9) - 10 + 9: (19, 9) 28, 10, 171, fractional - 10 - 9: (9, 1) 10, 8, 9, 9 - 10 * 9: (90, 9) 99, 81, 810, fractional - 10 / 9: fractional - 9 + 9: (18, 10) 28, 8, 180, fractional - 9 - 9: (10, 0) 10, 10, 0, undefined - 9 * 9: (81, 10) 91, 71, 810, fractional - 9 / 9: (10, 1) 11, 9, 10, 10 Trying another promising first operation: 2. 13 / 10: (9, 4, 1.3) - 9 + 4: (13, 1.3) fractional, fractional, fractional, 10 - 9 - 4: (5, 1.3) fractional - 9 * 4: (36, 1.3) fractional - 9 / 4: (2.3, 1.3) fractional, 1, fractional, fractional - 9 + 1.3: (10.3, 4) fractional - 9 - 1.3: (7.7, 4) fractional - 9 * 1.3: (11.7, 4) fractional - 9 / 1.3: (6.9, 4) fractional - 4 + 1.3: (9, 5.3) fractional - 4 - 1.3: (9, 2.7) fractional - 4 * 1.3: (9, 5.2) fractional - 4 / 1.3: (9, 3.1) fractional Trying another promising first operation: 3. 9 / 4: (13, 10, 2.3) - 13 + 10: (23, 2.3) fractional, fractional, fractional, 10 - 13 - 10: (3, 2.3) fractional - 13 * 10: (130, 2.3) fractional - 13 / 10: (2.3, 1.3) fractional, 1, fractional, fractional - 13 + 2.3: (15.3, 10) fractional, fractional, 153, fractional - 13 - 2.3: (11.7, 10) fractional, fractional, 117, fractional - 13 * 2.3: (29.9, 10) fractional, fractional, 299, fractional - 13 / 2.3: (10, 5.6) fractional, fractional, 560, fractional - 10 + 2.3: (13, 12.3) fractional - 10 - 2.3: (13, 7.7) fractional - 10 * 2.3: (23, 13) 36, 10, 299, fractional - 10 / 2.3: (13, 4.3) fractional Trying another promising first operation: 4. 13 / 4: (10, 9, 3.3) - 10 + 9: (19, 3.3) fractional - 10 - 9: (3.3, 1) fractional - 10 * 9: (90, 3.3) fractional - 10 / 9: (3.3, 1.1) fractional, fractional, fractional, 3 - 10 + 3.3: (13.3, 9) fractional - 10 - 3.3: (9, 6.7) fractional - 10 * 3.3: (33, 9) 42, 24, 297, fractional - 10 / 3.3: (3.1, 9) fractional - 9 + 3.3: (12.3, 10) fractional, fractional, 123, fractional - 9 - 3.3: (10, 5.7) fractional, fractional, 57, fractional - 9 * 3.3: (29.7, 10) fractional, fractional, 297, fractional - 9 / 3.3: (10, 2.7) fractional, fractional, 27, fractional Trying another promising first operation: 5. 13 / 9: (10, 9, 1.4) - 10 + 9: (19, 1.4) fractional - 10 - 9: (1.4, 1) fractional - 10 * 9: (90, 1.4) fractional, fractional, 130, fractional - 10 / 9: (1.1, 1.4) fractional - 10 + 1.4: (11.4, 9) fractional\",\n",
      "  \"10 - 1.4: (9, 8.6) fractional - 10 * 1.4: (140, 9) 149, 131, 1260, fractional - 10 / 1.4: (9, 7.1) fractional - 9 + 1.4: (10.4, 10) fractional, fractional, 104, fractional - 9 - 1.4: (10, 7.6) fractional, fractional, 76, fractional - 9 * 1.4: (12.6, 10) fractional, fractional, 126, fractional - 9 / 1.4: (10, 6.4) fractional, fractional, 64, fractional Trying another promising first operation: 6. 10 - 4: (13, 9, 6) - 13 + 9: (22, 6) 28, 16, 132, fractional - 13 - 9: (6, 4) 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 10 - 4 = 6 Step 2: 13 - 9 = 4 Step 3: 6 * 4 = 24 Considering these steps: 24 = 6 * 4 = 6 * (13 - 9) = (10 - 4) * (13 - 9) = 24. answer: (10 - 4) * (13 - 9) = 24. number.\",\n",
      "  \"10 - 1.4: (9, 8.6) fractional - 10 * 1.4: (140, 9) 149, 131, 1260, fractional - 10 / 1.4: (9, 7.1) fractional - 9 + 1.4: (10.4, 10) fractional, fractional, 104, fractional - 9 - 1.4: (10, 7.6) fractional, fractional, 76, fractional - 9 * 1.4: (12.6, 10) fractional, fractional, 126, fractional - 9 / 1.4: (10, 6.4) fractional, fractional, 64, fractional Trying another promising first operation: 6. 10 - 4: (13, 9, 6) - 13 + 9: (22, 6) 28, 16, 132, fractional - 13 - 9: (6, 4) 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 10 - 4 = 6 Step 2: 13 - 9 = 4 Step 3: 6 * 4 = 24 Considering these steps: 24 = 6 * 4 = 6 * (13 - 9) = (10 - 4) * (13 - 9) = 24. answer: (10 - 4) * (13 - 9) = 24. number.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\",\n",
      "  \"AoT (Random) System:\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"4 4 6 8.\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: (4 + 4) * 6 - 8 = 40.\",\n",
      "  \"Trying another promising first operation: (8 - 6) * 4 + 4 = 12.\",\n",
      "  \"Trying another promising first operation: (6 - 4) * (4 + 8) = 24. answer: (6 - 4) * (4 + 8) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"2 9 10 12.\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: ((12 - 10) / 2) + 9 = 10.\",\n",
      "  \"Trying another promising first operation: (10 + 9) + (12 / 2) = 25.\",\n",
      "  \"Trying another promising first operation: (12 * 2) * (10 - 9) = 24. answer: (12 * 2) * (10 - 9) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"4 9 10 13.\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: ((13 - 10) / 4) + 9 = 10.\",\n",
      "  \"Trying another promising first operation: 4 * (9 - (13 - 10)) = 24. answer: 4 * (9 - (13 - 10)) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"1 4 8 8.\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: (8 + 1) + 4 * 8 + 32.\",\n",
      "  \"Trying another promising first operation: (1 + 8 / 4) * 8 = 24. answer: (1 + 8 / 4) * 8 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"5 5 5 9.\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: ((5 + 5) + 5) + 9 = 24. answer: ((5 + 5) + 5) + 9 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\",\n",
      "  \"AoT (BFS)\",\n",
      "  \"System:\",\n",
      "  \"Use numbers and basic arithmetic operations (+ - * /) to obtain 24. When\",\n",
      "  \"considering the next steps, do not choose operations that will result in a negative or fractional number. In order to help with the calculations, the numbers in the parenthesis represent the numbers that are left after the operations and they are in descending order.\",\n",
      "  \"Another thing we do is when there are only two numbers left in the parenthesis, we\",\n",
      "  \"check whether we can arrive at 24 only by using basic arithmetic operations\",\n",
      "  \"(+ - * /). Some examples regarding this idea:\",\n",
      "  \"(21, 2): 23, 19, 42, fractional (30, 6): 36, 24 = 30 - 6 -> found it! (8, 3): 11, 5, 24 = 8 * 3 yes (12, 8): 20, 4, 72, fractional\",\n",
      "  \"In the second steps, when there are three numbers left, we choose the most\",\n",
      "  \"promising operations so that when we are left with two numbers, we will be able to get to 24.\",\n",
      "  \"So, when we reach 24 in the third steps, that means we found the solution, we\",\n",
      "  \"directly backtrack to write the answer.\",\n",
      "  \"In each step, we want to choose the best operations so that the numbers left, will\",\n",
      "  \"have a good chance to reach 24.\",\n",
      "  \"User:\",\n",
      "  \"14 8 8 2\",\n",
      "  \"Assistant:\",\n",
      "  \"Let\\u2019s consider the most promising possible first steps: 1. 8 + 8: (16, 14, 2) 2. 14 - 8: (8, 6, 2) 3. 14 + 2: (16, 8, 8) 4. 8 / 2: (14, 8, 4)\",\n",
      "  \"Let\\u2019s consider the most promising second steps: 1. (16, 14, 2) - 16 - 14: (2, 2) - 16 / 2: (8, 14) - 14 * 2: (28, 16) - 14 / 2: (7, 16)\",\n",
      "  \"2. (8, 6, 2) - 8 - 6: (2, 2) - 8 / 2: (4, 6) - 6 * 2: (12, 8) - 6 / 2: (3, 8)\",\n",
      "  \"3. (16, 8, 8)\",\n",
      "  \"16 - 8: (8, 8) - 16 / 8: (2, 8) - 8 * 8: (64, 16) - 8 / 8: (1, 16)\",\n",
      "  \"4. (14, 8, 4) - 14 - 8: (6, 4) - 14 / 4: (3.5, 8) - 8 * 4: (32, 14) - 8 / 4: (2, 14)\",\n",
      "  \"Let\\u2019s consider the most promising third steps: 1. 8 + 8 = 16 - 16 - 14: (2, 2): 4, 0, 4, 1 - 16 / 2: (8, 14): 22, 6, 112, fractional - 14 * 2: (28, 16): 44, 12, 448, fractional - 14 / 2: (7, 16): 23, 9, 112, fractional\",\n",
      "  \"2. 14 - 8 = 6 - 8 - 6: (2, 2): 4, 0, 4, 1 - 8 / 2: (6, 4): 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 14 - 8 = 6 Step 2: 8 / 2 = 4 Step 3: 6 * 4 = 24 Considering these steps: 24 = 6 * 4 = (14 - 8) * (8 / 2) = 24. answer: (14 - 8) * (8 / 2) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"9 5 5 5\",\n",
      "  \"Assistant:\",\n",
      "  \"Let\\u2019s consider the most promising first steps: 1. 9 - 5: (5, 5, 4) 2. 5 + 5: (9, 10, 5) 3. 9 + 5: (14, 5, 5) 4. 5 - 5: (9, 5, 0)\",\n",
      "  \"Let\\u2019s consider the most promising second steps: 1. (5, 5, 4) - 5 + 5: (10, 4) - 5 * 4: (20, 5) - 5 - 4: (5, 1) - 5 / 4: (5, 1.25)\",\n",
      "  \"2. (9, 10, 5) - 10 + 9: (19, 5) - 10 - 5: (9, 5) - 10 * 5: (50, 9) - 10 / 5: (9, 2)\",\n",
      "  \"3. (14, 5, 5) - 14 - 5: (9, 5) - 14 + 5: (19, 5) - 5 * 5: (25, 14) - 5 / 5: (14, 1)\",\n",
      "  \"4. (9, 5, 0) - 9 + 5: (14, 0) - 9 - 5: (4, 0) - 5 * 0: (9, 0) - 5 / 0: (9, infinity)\",\n",
      "  \"Let\\u2019s consider the most promising third steps: 1. 9 - 5 = 4 - 5 + 5: (10, 4): 14, 6, 40, fractional - 5 * 4: (20, 5): 25, 15, 100, 4 - 5 - 4: (5, 1): 6, 4, 5, 5 - 5 / 4: (5, 1.25): 6.25, 3.75, 6.25, 4\",\n",
      "  \"2. 5 + 5 = 10 - 10 + 9: (19, 5): 24 = 19 + 5 -> found it! Backtracking the solution: Step 1: 5 + 5 = 10 Step 2: 10 + 9 = 19 Step 3: 19 + 5 = 24 Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24. answer: ((5 + 5) + 9) + 5 = 24. 8 6 4 4\",\n",
      "  \"2. 5 + 5 = 10 - 10 + 9: (19, 5): 24 = 19 + 5 -> found it! Backtracking the solution: Step 1: 5 + 5 = 10 Step 2: 10 + 9 = 19 Step 3: 19 + 5 = 24 Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24. answer: ((5 + 5) + 9) + 5 = 24. 8 6 4 4\",\n",
      "  \"Assistant:\",\n",
      "  \"Let\\u2019s consider the most promising first steps: 1. 8 * 6: (48, 4, 4) 2. 8 + 4: (12, 6, 4) 3. 8 - 6: (4, 4, 2) 4. 6 - 4: (8, 4, 2)\",\n",
      "  \"Let\\u2019s consider the most promising second steps: 1. (48, 4, 4) - 4 * 4: (48, 16) - 48 / 4: (12, 4) - 4 + 4: (48, 8) - 48 - 4: (44, 4)\",\n",
      "  \"2. (12, 6, 4) - 12 + 6: (18, 4) - 6 * 4: (24, 12) - 6 + 4: (12, 10) - 12 / 4: (6, 3)\",\n",
      "  \"3. (4, 4, 2) - 4 * 4: (16, 2) - 4 + 2: (6, 4) - 4 + 4: (8, 2) - 4 * 2: (8, 4)\",\n",
      "  \"4. (8, 4, 2) - 8 * 4: (32, 2) - 4 * 2: (8, 8) - 8 + 4: (12, 2) - 8 / 4: (4, 2)\",\n",
      "  \"Let\\u2019s consider the most promising third steps: 1. 8 * 6 = 48 - 4 * 4: (48, 16): 64, 32, big, 3 - 48 / 4: (12, 4): 16, 8, 48, 3 - 4 + 4: (48, 8): 56, 40, big, 6 - 48 - 4: (44, 4): 48, 40, big, 11\",\n",
      "  \"2. 8 + 4 = 12 - 12 + 6: (18, 4): 22, 14, 72, fractional - 6 * 4: (24, 12): 36, 12, 288, 2 - 6 + 4: (12, 10): 22, 2, 120, fractional - 12 / 4: (6, 3): 9, 3, 18, 2\",\n",
      "  \"3. 8 - 6 = 2 - 4 * 4: (16, 2): 19, 14, 32, 8 - 4 + 2: (6, 4): 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 8 - 6 = 2 Step 2: 4 + 2 = 6 Step 3: 6 * 4 = 24 Considering these steps: 24 = 6 * 4 = (4 + 2) * 4 = (4 + (8 - 6)) * 4 = 24. answer: (4 + (8 - 6)) * 4 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"13 10 9 4\",\n",
      "  \"Assistant:\",\n",
      "  \"Let\\u2019s consider the most promising first steps: 1. 13 - 4: (10, 9, 9) 2. 10 - 4: (13, 9, 6) 3. 13 + 9: (22, 10, 4) 4. 10 - 9: (13, 4, 1)\",\n",
      "  \"Let\\u2019s consider the most promising second steps: 1. (10, 9, 9) - 10 + 9: (19, 9) - 10 - 9: (9, 1) - 9 + 9: (18, 10) - 9 / 9: (9, 1)\",\n",
      "  \"2. (13, 9, 6) - 9 + 6: (15, 13) - 9 * 6: (54, 13) - 13 - 9: (6, 4) - 13 - 6: (9, 7)\",\n",
      "  \"3. (22, 10, 4) - 22 - 10: (12, 4) - 22 - 4: (18, 10) - 10 * 4: (40, 22) - 10 / 4: (22, 5.5)\",\n",
      "  \"4. (13, 4, 1) - 13 - 4: (9, 1) - 13 * 4: (52, 1) - 4 - 1: (13, 3) - 13 - 1: (12, 4)\",\n",
      "  \"Let\\u2019s consider the most promising third steps: 1. 13 - 4 = 9 - 10 + 9: (19, 9): 28, 10, 171, fractional - 10 - 9: (9, 1): 10, 8, 9, 9 - 9 + 9: (18, 10): 28, 8, 180, fractional - 9 / 9: (9, 1): 10, 8, 9, 9\",\n",
      "  \"2. 10 - 4 = 6 - 9 + 6: (15, 13): 28, 2, 195, fractional - 9 * 6: (54, 13): 67, 41, 702, fractional - 13 - 9: (6, 4): 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 13 - 9 = 4 Step 2: 10 - 4 = 6 Step 3:\",\n",
      "  \"6 * 4 = 24 Considering these steps: 24 = 6 * 4 = (10 - 4) * (13 - 9) = 24. answer:\",\n",
      "  \"(10 - 4) * (13 - 9) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"8 8 5 4\",\n",
      "  \"Assistant:\",\n",
      "  \"Let\\u2019s consider the most promising first steps: 1. 5 + 4: (9, 8, 8) 2. 8 / 4: (8, 5, 2) 3. 8 - 5: (8, 4, 3) 4. 8 / 8: (5, 4, 1)\",\n",
      "  \"Let\\u2019s consider the most promising second steps: 1. (9, 8, 8) - 9 + 8: (17, 8) - 8 + 8: (16, 9) - 9 * 8: (72, 8) - 8 / 8: (9, 1)\",\n",
      "  \"2. (8, 5, 2) - 5 - 2: (8, 3) - 8 - 2: (6, 5) - 8 + 5: (13, 2) - 5 * 2: (10, 8)\",\n",
      "  \"3. (8, 4, 3) - 8 - 4: (4, 3) - 8 - 3: (5, 4) - 4 * 3: (12, 8) - 4 + 3: (8, 7)\",\n",
      "  \"4. (5, 4, 1) - 5 + 4: (9, 1) - 5 - 4: (1, 1) - 4 - 1: (5, 3) - 5 + 1: (6, 4)\",\n",
      "  \"Let\\u2019s consider the most promising third steps: 1. 5 + 4 = 9 - 9 + 8: (17, 8): 25, 9, 136, fractional - 8 + 8: (16, 9): 25, 7, 144, fractional - 9 * 8: (72, 8): 80, 64, 576, 9 - 8 / 8: (9, 1): 10, 8, 9, 9\",\n",
      "  \"2. 8 / 4 = 2 - 5 - 2: (8, 3): 11, 5, 24 = 8 * 3 -> found it! Backtracking the solution: Step 1: 8 / 4 = 2 Step 2: 5 - 2 = 3 Step 3: 8 * 3 = 24 Considering these steps: 24 = 8 * 3 = 8 * (5 - 2) = 8 * (5 - (8 / 4)) = 24. answer: 8 * (5 - (8 / 4)) = 24. 11 11 1 1\",\n",
      "  \"2. 8 / 4 = 2 - 5 - 2: (8, 3): 11, 5, 24 = 8 * 3 -> found it! Backtracking the solution: Step 1: 8 / 4 = 2 Step 2: 5 - 2 = 3 Step 3: 8 * 3 = 24 Considering these steps: 24 = 8 * 3 = 8 * (5 - 2) = 8 * (5 - (8 / 4)) = 24. answer: 8 * (5 - (8 / 4)) = 24. 11 11 1 1\",\n",
      "  \"Assistant:\",\n",
      "  \"Let\\u2019s consider the most promising first steps: 1. 11 - 1: (11, 10, 1) 2. 11 + 1: (12, 11, 1) 3. 11 + 11: (22, 1, 1) 4. 1 + 1: (11, 11, 2)\",\n",
      "  \"Let\\u2019s consider the most promising second steps: 1. (11, 10, 1) - 11 + 10: (21, 1) - 10 + 1: (11, 11) - 10 / 1: (11, 10) - 11 / 1: (11, 10)\",\n",
      "  \"2. (12, 11, 1) - 12 + 11: (23, 1) - 11 + 1: (12, 11) - 11 - 1: (12, 10) - 12 + 1: (13, 11)\",\n",
      "  \"3. (22, 1, 1) - 22 + 1: (23, 1) - 1 + 1: (22, 2) - 22 / 1: (22, 1) - 1 / 1: (22, 1)\",\n",
      "  \"4. (11, 11, 2) - 11 + 11: (22, 2) - 11 * 2: (22, 11) - 11 + 2: (13, 11) - 2 * 11: (22, 11)\",\n",
      "  \"Let\\u2019s consider the most promising third steps: 1. 11 - 1 = 10 - 11 + 10: (21, 1): 22, 20, 21, 20 - 10 + 1: (11, 11): 22, 10, 121, 0 - 10 / 1: (11, 10): 21, 1, 110, 0 - 11 / 1: (11, 10): 21, 1, 110, 0\",\n",
      "  \"2. 11 + 1 = 12 - 12 + 11: (23, 1): 24 = 23 + 1 -> found it! Backtracking the solution: Step 1: 11 + 1 = 12 Step 2: 12 + 11 = 23 Step 3: 23 + 1 = 24 Considering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24. answer: ((11 + 1) + 11) + 1 = 24. 11 7 4 1\",\n",
      "  \"2. 11 + 1 = 12 - 12 + 11: (23, 1): 24 = 23 + 1 -> found it! Backtracking the solution: Step 1: 11 + 1 = 12 Step 2: 12 + 11 = 23 Step 3: 23 + 1 = 24 Considering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24. answer: ((11 + 1) + 11) + 1 = 24. 11 7 4 1\",\n",
      "  \"Assistant:\",\n",
      "  \"Let\\u2019s consider the most promising first steps: 1. 7 * 4: (28, 11, 1) 2. 7 + 1: (11, 8, 4) 3. 4 + 1: (11, 7, 5) 4. 11 - 4: (7, 3, 1)\",\n",
      "  \"Let\\u2019s consider the most promising second steps: 1. (28, 11, 1) - 28 - 11: (17, 1) - 28 - 1: (27, 11) - 11 + 1: (29, 28) - 11 - 1: (28, 10)\",\n",
      "  \"2. (11, 8, 4) - 11 + 8: (19, 4) - 8 + 4: (12, 11) - 11 - 8: (4, 3)\",\n",
      "  \"8 - 4: (7, 11)\",\n",
      "  \"3. (11, 7, 5) - 11 - 5: (7, 6) - 7 - 5: (11, 2) - 7 * 5: (35, 11) - 11 + 5: (16, 7)\",\n",
      "  \"4. (7, 3, 1) - 7 - 3: (4, 1) - 7 * 3: (21, 1) - 3 + 1: (7, 4) - 7 - 1: (6, 3)\",\n",
      "  \"Let\\u2019s consider the most promising third steps: 1. 7 * 4 = 28 - 28 - 11: (17, 1): 18, 16, 17, 17 - 28 - 1: (27, 11): 38, 16, 297, 2.45 - 11 + 1: (29, 28): 57, 1, 812, 1.03 - 11 - 1: (28, 10): 38, 18, 280, 2.8\",\n",
      "  \"2. 7 + 1 = 8 - 11 + 8: (19, 4): 23, 15, 76, 4.75 - 8 + 4: (12, 11): 23, 7, 132, 3 - 11 - 8: (4, 3): 7, 1, 12, 1.33 - 8 - 4: (7, 11): 18, 4, 77, 1.75\",\n",
      "  \"3. 4 + 1 = 5 - 11 - 5: (7, 6): 13, 1, 42, 1.17 - 7 - 5: (11, 2): 13, 9, 22, 5.5 - 7 * 5: (35, 11): 46, 24 = 35 - 11 -> found it! Backtracking the solution: Step 1: 4 + 1 = 5 Step 2: 7 * 5 = 35 Step 3: 35 - 11 = 24 Considering these steps: 24 = 35 - 11 = (7 * 5) - 11 = (7 * (4 + 1)) - 11 = 24. answer: (7 * (4 + 1)) - 11 = 24. \\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc 11 5 4 3\",\n",
      "  \"3. 4 + 1 = 5 - 11 - 5: (7, 6): 13, 1, 42, 1.17 - 7 - 5: (11, 2): 13, 9, 22, 5.5 - 7 * 5: (35, 11): 46, 24 = 35 - 11 -> found it! Backtracking the solution: Step 1: 4 + 1 = 5 Step 2: 7 * 5 = 35 Step 3: 35 - 11 = 24 Considering these steps: 24 = 35 - 11 = (7 * 5) - 11 = (7 * (4 + 1)) - 11 = 24. answer: (7 * (4 + 1)) - 11 = 24. \\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc Let\\u2019s consider the most promising first steps to reach 24: 1. 11 * 3: (33, 5, 4) 2. 5 + 4: (11, 9, 3) 3. 11 - 4: (7, 5, 3) 4. 4 + 3: (11, 7, 5)\",\n",
      "  \"3. 4 + 1 = 5 - 11 - 5: (7, 6): 13, 1, 42, 1.17 - 7 - 5: (11, 2): 13, 9, 22, 5.5 - 7 * 5: (35, 11): 46, 24 = 35 - 11 -> found it! Backtracking the solution: Step 1: 4 + 1 = 5 Step 2: 7 * 5 = 35 Step 3: 35 - 11 = 24 Considering these steps: 24 = 35 - 11 = (7 * 5) - 11 = (7 * (4 + 1)) - 11 = 24. answer: (7 * (4 + 1)) - 11 = 24. \\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc Let\\u2019s consider the most promising first steps to reach 24: 1. 11 * 3: (33, 5, 4) 2. 5 + 4: (11, 9, 3) 3. 11 - 4: (7, 5, 3) 4. 4 + 3: (11, 7, 5)\",\n",
      "  \"Let\\u2019s consider the most promising second steps to reach 24: 1. (33, 5, 4) - 33 - 5: (28, 4) - 33 - 4: (29, 5) - 5 + 4: (33, 9) - 5 * 4: (20, 33)\",\n",
      "  \"2. (11, 9, 3) - 11 * 3: (33, 9) - 11 + 3: (14, 9) - 9 + 3: (12, 11) - 9 / 3: (11, 3)\",\n",
      "  \"3. (7, 5, 3)\",\n",
      "  \"7 - 3: (4, 5) - 7 + 5: (12, 3) - 5 + 3: (8, 7) - 5 * 3: (7, 6)\",\n",
      "  \"4. (11, 7, 5) - 11 + 7: (18, 5) - 11 - 5: (6, 7) - 7 + 5: (12, 11) - 7 - 5: (2, 11)\",\n",
      "  \"Let\\u2019s consider the most promising third steps to reach 24: 1. 11 * 3 = 33 - 33 - 5: (28, 4): 32, 24 = 28 - 4 -> found it! Backtracking the solution: Step 1: 11 * 3 = 33 Step 2: 33 - 5 = 28 Step 3: 28 - 4 = 24 Considering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 * 3) - 5) - 4 = 24. answer: ((11 * 3) - 5) - 4 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"13 12 5 2\",\n",
      "  \"Assistant:\",\n",
      "  \"Let\\u2019s consider the most promising first steps to reach 24: 1. 12 / 2: (13, 6, 5) 2. 13 + 5: (18, 12, 2) 3. 12 - 5: (13, 7, 2) 4. 5 - 2: (13, 12, 3)\",\n",
      "  \"Let\\u2019s consider the most promising second steps to reach 24: 1. (13, 6, 5) - 13 + 6: (19, 5) - 13 - 5: (8, 6) - 6 * 5: (30, 13) - 6 - 5: (13, 1)\",\n",
      "  \"2. (18, 12, 2) - 18 * 2: (36, 12) - 12 / 2: (18, 6) - 18 - 2: (16, 12) - 12 * 2: (24, 18)\",\n",
      "  \"3. (13, 7, 2) - 13 + 7: (20, 2) - 13 - 2: (11, 7) - 7 * 2: (14, 13) - 7 - 2: (13, 5)\",\n",
      "  \"4. (13, 12, 3) - 13 * 3: (39, 12) - 13 - 3: (10, 12) - 12 * 3: (36, 13) - 12 / 3: (13, 4)\",\n",
      "  \"Let\\u2019s consider the most promising third steps to reach 24: 1. 12 / 2 = 6 - 13 + 6: (19, 5): 24 = 19 + 5 -> found it! Backtracking the solution: Step 1: 12 / 2 = 6 Step 2:\",\n",
      "  \"13 + 6 = 19 Step 3: 19 + 5 = 24 Considering these steps: 24 = 19 + 5 = (13 + 6) + 5 = (13 + (12 / 2)) + 5 = 24. answer: (13 + (12 / 2)) + 5 = 24. \\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\",\n",
      "  \"User:\",\n",
      "  \"9 8 2 1\",\n",
      "  \"Assistant:\",\n",
      "  \"Let\\u2019s consider the most promising first steps to reach 24: 1. 9 - 1: (8, 8, 2) 2. 8 + 2: (10, 9, 1) 3. 9 + 1: (10, 8, 2) 4. 2 + 1: (9, 8, 3)\",\n",
      "  \"Let\\u2019s consider the most promising second steps to reach 24: 1. (8, 8, 2) - 8 + 8: (16, 2) - 8 * 2: (16, 8) - 8 - 2: (6, 8) - 8 + 8: (16, 2)\",\n",
      "  \"2. (10, 9, 1) - 10 + 9: (19, 1) - 10 - 1: (9, 9) - 9 + 1: (10, 10) - 9 / 1: (8, 10)\",\n",
      "  \"3. (10, 8, 2) - 10 + 8: (18, 2) - 10 * 2: (8, 8) - 8 + 2: (10, 10) - 8 / 2: (6, 10)\",\n",
      "  \"4. (9, 8, 3) - 9 + 8: (17, 3) - 9 / 3: (6, 8) - 8 + 3: (11, 9) - 8 * 3: (24, 9)\",\n",
      "  \"Let\\u2019s consider the most promising third steps to reach 24: 1. 9 - 1 = 8 - 8 + 8: (16, 2): 18, 14, 32, 8 - 8 * 2: (16, 8): 24 = 16 + 8 -> found it! Backtracking the solution: Step 1: 9 - 1 = 8 Step 2: 8 * 2 = 16 Step 3: 16 + 8 = 24 Considering these steps: 24 = 16 + 8 = (8 * 2) + 8 = ((9 - 1) * 2) + 8 = 24. answer: ((9 - 1) * 2) + 8 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\",\n",
      "  \"AoT (Short)\",\n",
      "  \"System:\",\n",
      "  \"Use numbers and basic arithmetic operations (+ - * /) to obtain 24. When\",\n",
      "  \"considering the next steps, do not choose operations that will result in a negative or fractional number. In order to help with the calculations, the numbers in the parenthesis represent the numbers that are left after the operations and they are in descending order.\",\n",
      "  \"Another thing we do is when there are only two numbers left in the parenthesis, we\",\n",
      "  \"check whether we can arrive at 24 only by using basic arithmetic operations\",\n",
      "  \"(+ - * /). Some examples regarding this idea:\",\n",
      "  \"(21 2) no since 21 + 2 = 23, 21 - 2 = 19, 21 * 2 = 42, 21 / 2 = 10.5, none of which is equal\",\n",
      "  \"to 24.\",\n",
      "  \"(30 6) 30 - 6 = 24 yes (8 3) 8 * 3 = 24 yes (12 8) no (48 2) 48 / 2 = 24 yes\",\n",
      "  \"Most importantly, do not give up, all the numbers that will be given has indeed a\",\n",
      "  \"solution.\",\n",
      "  \"User:\",\n",
      "  \"14 8 8 2\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 8 / 2: (14, 8, 4) - 14 + 8: (22, 4) 26, 18, 88, fractional - 14 - 8: (6, 4) 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 8 / 2 = 4 Step 2: 14 - 8 = 6 Step 3: 6 * 4 = 24 Considering these steps: 24 = 6 * 4 = (14 - 8) * 4 = (14 - 8) * (8 / 2) = 24. answer: (14 - 8) * (8 / 2) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"9 5 5 5\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 5 + 5: (10, 9, 5) - 10 + 9: (19, 5) 24 = 19 + 5 -> found it! Backtracking the solution: Step 1: 5 + 5 = 10 Step 2: 10 + 9 = 19 Step 3: 19 + 5 = 24 Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24. answer: ((5 + 5) + 9) + 5 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"8 6 4 4\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 8 - 6: (4, 4, 2) - 4 + 4: (8, 2) 10, 6, 16, 4 - 4 - 4: (2, 0) 2, 2, 0, undefined - 4 * 4: (16, 2) 18, 14, 32, 8 - 4 / 4: (2, 1) 3, 1, 2, 2 - 4 + 2: (6, 4) 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 8 - 6 = 2 Step 2: 4 + 2 = 6 Step 3: 6 * 4 = 24 Considering these steps: 24 = 6 * 4 = (4 + 2) * 4 = (4 + (8 - 6)) * 4 = 24. answer: (4 + (8 - 6)) * 4 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"13 10 9 4\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 10 - 4: (13, 9, 6) - 13 + 9: (22, 6) 28, 16, 132, fractional - 13 - 9: (6, 4) 10, 2, 24 = 6 * 4 -> found it! Backtracking the solution: Step 1: 10 - 4 = 6 Step 2: 13 - 9 = 4 Step 3: 6 * 4 = 24 Considering these steps: 24 = 6 * 4 = 6 * (13 - 9) = (10 - 4) * (13 - 9) = 24. answer: (10 - 4) * (13 - 9) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"8 8 5 4\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 8 / 4: (8, 5, 2) - 8 + 5: (13, 2) 15, 11, 26, fractional - 8 - 5: (3, 2) 5, 1, 6, 1.5 - 8 * 5: (40, 2) 42, 38, 80, 20 - 8 / 5: fractional - 8 + 2: (10, 5) 15, 5, 50, 2 - 8 - 2: (6, 5) 11, 1, 30, fractional - 8 * 2: (16, 5) 21, 11, 80, fractional - 8 / 2: (5, 4) 9, 1, 20, fractional - 5 + 2: (7, 8) 15, 1, 56, fractional - 5 - 2: (8, 3) 11, 5, 24 = 8 * 3 -> found it! Backtracking the solution: Step 1: 8 / 4 = 2 Step 2: 5 - 2 = 3 Step 3: 8 * 3 = 24 Considering these steps: 24 = 8 * 3 = 8 * (5 - 2) = 8 * (5 - (8 / 4)) = 24. answer: 8 * (5 - (8 / 4)) = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"11 11 1 1\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 11 + 1: (12, 11, 1) - 12 + 11: (23, 1) 24 = 23 + 1 -> found it! Backtracking the solution: Step 1: 11 + 1 = 12 Step 2: 12 + 11 = 23 Step 3: 23 + 1 Considering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24. answer: ((11 + 1) + 11) + 1 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"11 7 4 1\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 4 + 1: (11 7 5) - 11 + 7: (18, 5) 23, 13, 90, fractional\",\n",
      "  \"11 - 7: (5, 4) 9, 1, 20, fractional - 11 * 7: (77, 5) 82, 72, 385, fractional - 11 / 7: fractional - 11 + 5: (16, 7) 23, 9, 112, fractional - 11 - 5: (7, 6) 13, 1, 42, fractional - 11 * 5: (55, 7) 62, 48, 385, fractional - 11 / 5: fractional - 7 + 5: (12, 11) 23, 1, 132, fractional - 7 - 5: (11, 2) 13, 9, 22, fractional - 7 * 5: (35, 11) 46, 24 = 35 - 11 -> found it! Step 1: 4 + 1 = 5 Step 2: 7 * 5 = 35 Step 3: 35 - 11 = 24 Considering these steps: Backtracking the solution: 24 = 35 - 11 = (7 * 5) - 11 = (7 * (4 + 1)) - 11 = 24. answer: (7 * (4 + 1)) - 11 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"11 5 4 3\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 11 * 3: (33, 5, 4) - 33 + 5: (38, 4) 42, 34, 152, fractional - 33 - 5: (28, 4) 32, 24 = 28 - 4 -> found it! Backtracking the solution: Step 1: 11 * 3 = 33 Step 2: 33 - 5 = 28 Step 3: 28 - 4 = 24 Considering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 * 3) - 5) - 4 = 24. answer: ((11 * 3) - 5) - 4 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"13 12 5 2\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 13 + 5: (18, 12, 2) - 18 + 12: (30, 2) 32, 28, 60, fractional - 18 - 12: (6, 2) 8, 4, 12, 3 - 18 * 12: (216, 2) 218, 214, 432, fractional - 18 / 12: fractional - 18 + 2: (20, 12) 32, 8, 240, fractional - 18 - 2: (16, 12) 28, 4, 192, fractional - 18 * 2: (36, 12) 48, 24 = 36 - 12 -> found it! Backtracking the solution: Step 1: 13 + 5 = 18 Step 2: 18 * 2 = 36 Step 3: 36 - 12 = 24 Considering these steps: 24 = 36 - 12 = (18 * 2) - 12 = ((13 + 5) * 2) - 12 = 24. answer: ((13 + 5) * 2) - 12 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"9 8 2 1\",\n",
      "  \"Assistant:\",\n",
      "  \"Trying a promising first operation: 1. 9 - 1: (8, 8, 2) - 8 + 8: (16, 2) 18, 14, 32, 8\",\n",
      "  \"8 - 8: (2, 0) 2, 2, 0, undefined - 8 * 8: (64, 2) 66, 62, 128, 32 - 8 / 8: (2, 1) 3, 1, 2, 2 - 8 + 2: (10, 8) 18, 2, 80, 4 - 8 - 2: (6, 8) 14, -2, 48, fractional - 8 * 2: (16, 8) 24 = 16 + 8 -> found it! Backtracking the solution: Step 1: 9 - 1 = 8 Step 2: 8 * 2 = 16 Step 3: 16 + 8 = 24 Considering these steps: 24 = 16 + 8 = (8 * 2) + 8 = ((9 - 1) * 2) + 8 = 24. answer: ((9 - 1) * 2) + 8 = 24.\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\",\n",
      "  \"5 \\u00d7 5 Mini Crosswords Prompts\",\n",
      "  \"In the following we give all the exact prompts we used for the methods given in the experiments section and some selection of the generations from the LLM. In the prompts the keywords \\u201cSystem\\u201d, \\u201cUser\\u201d and \\u201cAssistant\\u201d used are the roles in the OpenAI API in chat completion mode. The line breaks are to show the turns between the user and assistant in the API.\",\n",
      "  \"AoT\",\n",
      "  \"User:\",\n",
      "  \"h1. A lunar valley h2. A fatty oil h3. To entice h4. To lower; to reduce h5. A solitary person v1. According to the roster v2. Another name for Port-Francqui v3. An illicit lover; a European lake v4. To lisp v5. To come in\",\n",
      "  \"The words I already found are: h1. rille h3. tempt v2. ilebo v5. enter\",\n",
      "  \"Assistant:\",\n",
      "  \"There are two horizontal and two vertical words. Since they are the amount, let\\u2019s\",\n",
      "  \"consider the next unfound horizontal word, which is h2. Since we are considering the second horizontal word, we need to look at the second letters of the vertical words we found: - What is the second letter of ilebo: e - What is the second letter of enter: n The word we are looking fits the clue \\\"A fatty oil\\\" and needs to have the letters\",\n",
      "  \"e and n in its (v2, two) second and (v5, five) fifth letters: _ e _ _ n. The candidates are: oleic, olein, olive. - oleic (o l e i c, _ e _ _ n) doesn\\u2019t fit - olein (o l e i n, _ e _ _ n) fits - olive (o l i v e, _ e _ _ n) doesn\\u2019t fit We add the word olein for h2. The current words are: h1. rille h2. olein h3. tempt v2. ilebo v5. enter Now, let\\u2019s consider the next unfound vertical word, which is v1. Since we are\",\n",
      "  \"considering the first vertical word, we need to look at the first letters of the horizontal words we found: - What is the first letter of rille: r - What is the first letter of olein: o\",\n",
      "  \"What is the first letter of tempt: t The word we are looking fits the clue \\\"According to the roster\\\" and needs to have the letters r, o, and t in its (h1, one) first, (h2, two) second, and (h3, three) third letters: r o t _ _. The candidates are: none considering the third vertical word, we need to look at the third letters of the horizontal words we found: - What is the third letter of rille: l - What is the third letter of olein: e - What is the third letter of tempt: m The word we are looking fits the clue \\\"An illicit lover; a European lake\\\" and\",\n",
      "  \"needs to have the letters l, e, and m in its (h1, one) first, (h2, two) second , and (h3, three) third letters: l e m _ _. The candidates are: leman.\",\n",
      "  \"leman (l e m a n, l e m _ _) fits We add the word leman for v3. The current words are: h1. rille h2. olein h3. tempt v2. ilebo v3. leman v5. enter Now, let\\u2019s consider the next unfound horizontal word, which is h4. Since we are considering the fourth horizontal word, we need to look at the fourth letters of the vertical words we found: - What is the fourth letter of ilebo: b - What is the fourth letter of leman: a - What is the fourth letter of enter: e The word we are looking fits the clue \\\"To lower; to reduce\\\" and needs to have the letters b, a, and e in its (v2, two) second, (v3, three) third, and (v5, five)\",\n",
      "  \"fifth letters: _ b a _ e. The candidates are: abase, abate.\",\n",
      "  \"abase (a b a s e, _ b a _ e) fits - abate (a b a t e, _ b a _ e) fits Since both fits, let\\u2019s consider another word. Now, let\\u2019s consider the last unfound vertical word, which is v4. Since we are the horizontal words we found: - What is the fourth letter of rille: l - What is the fourth letter of olein: i - What is the fourth letter of tempt: p The word we are looking fits the clue \\\"To lisp\\\" and needs to have the letters l, i , p, and s in its (h1, one) first, (h2, two) second, (h3, three) third letters : l i p _ _. The candidates are: The candidate is \\\"lisps\\\".\",\n",
      "  \"lisps (l i s p s, l i p _ _) doesn\\u2019t fit\",\n",
      "  \"We have considered all of the words for the horizontal words, we have two options:\",\n",
      "  \"abase and abate, let\\u2019s choose one of them.\",\n",
      "  \"answer: h1. rille h2. olein h3. tempt h4. abase v2. ilebo v3. leman v5. enter\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc User:\",\n",
      "  \"h1. One who saws h2. A fungus genus h3. An assessor h4. Pasture land h5. Receiving by the ear v1. To swell; to increase v2. The Brazilian macaw; an Australian bird v3. A Timorese island v4. Excessive fluid accumulation\",\n",
      "  \"v5. Dewy; roscid\",\n",
      "  \"The words I already found are: h1. sawer h3. rater v1. surge v4. edema\",\n",
      "  \"Assistant:\",\n",
      "  \"There are two horizontal and two vertical words. Since they are the amount, let\\u2019s\",\n",
      "  \"consider the next unfound horizontal word, which is h2. Since we are considering the second horizontal word, we need to look at the second letters of the vertical words we found: - What is the second letter of surge: u - What is the second letter of edema: d The word we are looking fits the clue \\\"A fungus genus\\\" and needs to have the\",\n",
      "  \"letters u and d in its (v1, one) first and (v4, four) fourth letters: u _ _ d _. The candidates are: uredo. - uredo (u r e d o, u _ _ d _) fits We add the word uredo for h2. The current words are: h1. sawer h2. uredo h3. rater v1. surge v4. edema Now, let\\u2019s consider the next unfound vertical word, which is v2. Since we are\",\n",
      "  \"considering the second vertical word, we need to look at the second letters of\",\n",
      "  \"the horizontal words we found: - What is the second letter of sawer: a - What is the second letter of uredo: r - What is the second letter of rater: a The word we are looking fits the clue \\\"The Brazilian macaw; an Australian bird\\\" and needs to have the letters a, r, and a in its (h1, one) first, (h2, two) second, and (h3, third) third letters: a r a _ _. The candidates are: arara.\",\n",
      "  \"arara (a r a r a, a r a _ _) fits We add the word arara for v2. The current words are: h1. sawer h2. uredo h3. rater v1. surge v2. arara v4. edema Now, let\\u2019s consider the next unfound horizontal word, which is h4. Since we are considering the fourth horizontal word, we need to look at the fourth letters of the vertical words we found: - What is the fourth letter of surge: g - What is the fourth letter of arara: r - What is the fourth letter of edema: m the word we are looking fits the clue \\\"Pasture land\\\" and needs to have the letters\",\n",
      "  \"g, r, and m in its (v1, one) first, (v2, two) second, and (v4, four) fourth\",\n",
      "  \"letters: g r _ m _. The candidates are: grama.\",\n",
      "  \"grama (g r a m a, g r a _ _) fits We add the word grama for h4. The current words are: h1. Sawer h2. Uredos h3. Rater h4. Grama v1. surge v2. arara v4. edema Now, let\\u2019s consider the next unfound vertical word, which is v3. Since we are considering the third vertical word, we need to look at the third letters of the horizontal words we found: - What is the third letter of sawer: w - What is the third letter of uredo: e - What is the third letter of rater: t\",\n",
      "  \"What is the third letter of grama: a The word we are looking fits the clue \\\"A Timorese island\\\" and needs to have the letters w, e, t, and a in its (h1, one) first, (h2, two) second, (h3, three) third, and (h4, four) fourth letters: w e t a _. The candidates are: The candidate is \\\"wetar\\\".\",\n",
      "  \"wetar (w e t a r, w e t a _) fits We add the word wetar for v3. The current words are: h1. sawer h2. uredo h3. rater h4. grama v1. surge v2. arara v3. wetar v4. edema Now, let\\u2019s consider the last unfound horizontal word, which is h5. Since we are considering the fifth horizontal word, we need to look at the fifth letters of\",\n",
      "  \"the vertical words we found: - What is the fifth letter of surge: e - What is the fifth letter of arara: a - What is the fifth letter of wetar: r - What is the fifth letter of edema: a The word we are looking fits the clue \\\"Receiving by the ear\\\" and needs to have the\",\n",
      "  \"letters e, a, r, and a in its (v1, one) first, (v2, two) second, (v3, three)\",\n",
      "  \"third, and (v4, four) fourth letters: e a r a _. The candidates are: The candidate is \\\"earal\\\".\",\n",
      "  \"earal (e a r a l, e a r a _) fits We add the word earal for h5. The current words are: h1. sawer h2. uredo h3. rater h4. grama h5. earal v1. surge v2. arara v3. wetar v4. edema Since we found all horizontal words: answer: h1. sawer h2. uredo h3. rater h4. grama h5. earal v1. surge v2. arara v3. wetar v4. edema h1. Dandruff; scum; the bull-trout h2. One who greets; to vacillate; a British river h3. A Turkish written decree h4. Mignon; petty; little h5. A bishop\\u2019s permission for a priest to leave a diocese v1. To steal; to brush across v2. A sedge (a primitive three-sided grass) v3. Grape jam v4. A flatworm larva v5. Ore refuse; to prepare material for glass by heat\",\n",
      "  \"earal (e a r a l, e a r a _) fits We add the word earal for h5. The current words are: h1. sawer h2. uredo h3. rater h4. grama h5. earal v1. surge v2. arara v3. wetar v4. edema Since we found all horizontal words: answer: h1. sawer h2. uredo h3. rater h4. grama h5. earal v1. surge v2. arara v3. wetar v4. edema h1. Dandruff; scum; the bull-trout h2. One who greets; to vacillate; a British river h3. A Turkish written decree h4. Mignon; petty; little h5. A bishop\\u2019s permission for a priest to leave a diocese v1. To steal; to brush across v2. A sedge (a primitive three-sided grass) v3. Grape jam v4. A flatworm larva v5. Ore refuse; to prepare material for glass by heat\",\n",
      "  \"h2. waver h5. exeat v1. swipe v2. carex\",\n",
      "  \"Assistant:\",\n",
      "  \"Let\\u2019s consider the next unfound horizontal word, which is h1. Since we are\",\n",
      "  \"considering the first horizontal word, we need to look at the first letters of\",\n",
      "  \"the vertical words we found: - What is the first letter of swipe: s - What is the first letter of carex: c The word we are looking fits the clue \\\"Dandruff; scum; the bull-trout\\\" and needs to have the letters s and c in its (v1, one) first and (v2, two) second letters: s c _ _ _. The candidates are: scurf.\",\n",
      "  \"scurf (s c u r f, s c _ _ _) fits We add the word scurf for h1. The current words are: h1. scurf h2. waver h5. exeat v1. swipe v2. carex Now, let\\u2019s consider the next unfound vertical word, which is v3. Since we are considering the third vertical word, we need to look at the third letters of the horizontal words we found: - What is the third letter of scurf: u - What is the third letter of waver: v - What is the third letter of exeat: e The word we are looking fits the clue \\\"Grape jam\\\" and needs to have the letters u, v, and e in its (h1, one) first, (h2, two) second, and (h5, five) fifth\",\n",
      "  \"letters: u v _ _ e. The candidates are: The candidate is \\\"uvetta\\\".\",\n",
      "  \"uvetta (u v e t t a, u v _ _ e) doesn\\u2019t fit Let\\u2019s consider the next unfound vertical word, which is v4. Since we are considering the fourth vertical word, we need to look at the fourth letters of\",\n",
      "  \"the horizontal words we found: - What is the fourth letter of scurf: r - What is the fourth letter of waver: e - What is the fourth letter of exeat: a The word we are looking fits the clue \\\"A flatworm larva\\\" and needs to have the\",\n",
      "  \"letters r, e, and a in its (h1, one) first, (h2, two) second, and (h5, five) fifth letters: r e _ _ a. The candidates are: redia.\",\n",
      "  \"redia (r e d i a, r e _ _ a) fits We add the word redia for v4. The current words are: h1. scurf h2. waver h5. exeat v1. swipe v2. carex v4. redia Now, let\\u2019s consider the next unfound horizontal word, which is h3. Since we are considering the third horizontal word, we need to look at the third letters of\",\n",
      "  \"the vertical words we found: - What is the third letter of swipe: i - What is the third letter of carex: r - What is the third letter of redia: d The word we are looking fits the clue \\\"A Turkish written decree\\\" and needs to have the letters i, r, and d in its (v1, one) first, (v2, two) second, and (v4,\",\n",
      "  \"four) fourth letters: i r _ d _. The candidates are: irade.\",\n",
      "  \"irade (i r a d e, i r _ d _) fits We add the word irade for h3. The current words are: h1. scurf h2. waver h3. irade h5. exeat v1. swipe v2. carex v4. redia Now, let\\u2019s consider the last unfound vertical word, which is v5. Since we are considering the fifth vertical word, we need to look at the fifth letters of the horizontal words we found: - What is the fifth letter of scurf: f\",\n",
      "  \"What is the fifth letter of waver: r - What is the fifth letter of irade: e - What is the fifth letter of exeat: t The word we are looking fits the clue \\\"Ore refuse; to prepare material for glass by heat\\\" and needs to have the letters f, r, e, and t in its (h1, one) first, (h2, two) second, (h3, three) third, and (h5, five) fifth letters: f r e _ t. The candidates are: The candidate is \\\"frett\\\".\",\n",
      "  \"frett (f r e t t, f r e _ t) fits We add the word frett for v5. The current words are: h1. scurf h2. waver h3. irade h5. exeat v1. swipe v2. carex v4. redia v5. frett Since we found all horizontal words: answer: h1. scurf h2. waver h3. irade h5. exeat v1. swipe v2. carex v4. redia v5. frett h1. A lunar valley h2. A fatty oil h3. To entice h4. To lower; to reduce h5. A solitary person v1. According to the roster v2. Another name for Port-Francqui v3. An illicit lover; a European lake v4. To lisp v5. To come in\",\n",
      "  \"frett (f r e t t, f r e _ t) fits We add the word frett for v5. The current words are: h1. scurf h2. waver h3. irade h5. exeat v1. swipe v2. carex v4. redia v5. frett Since we found all horizontal words: answer: h1. scurf h2. waver h3. irade h5. exeat v1. swipe v2. carex v4. redia v5. frett h1. A lunar valley h2. A fatty oil h3. To entice h4. To lower; to reduce h5. A solitary person v1. According to the roster v2. Another name for Port-Francqui v3. An illicit lover; a European lake v4. To lisp v5. To come in\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\",\n",
      "  \"Assistant:\",\n",
      "  \"All possible 5-letters words for each clue, for each clue we give 10 options: h1. RILLE, VALLIS, CRATER, BASINS, PLAINS h2. OLEIC, OLEIN, GREASE, BUTTER, ANIMAL h3. LURE, TEMPT, SEDUCE, ENTICE, DRAWIN h4. ABASE, LOWER, REDUCE, LESSEN, DEBASE h5. HERMIT, ALONE, LONER, SINGLE, SOLITARY\",\n",
      "  \"v1. ONTAP, LISTED, ROSTER, SCHEDULE, PLANNED v2. ILEBO, PORTF, CONGO, AFRICA, COLONY v3. LOVER, AMOUR, GENEVA, LEMAN, ZURICH v4. SLUR, LISPS, STUTTER, MUMBLE, STAMMER v5. ENTER, ARRIVE, COMEIN, APPEAR, SHOWUP\",\n",
      "  \"\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\\u02dc\",\n",
      "  \"Creative Writing AoT\",\n",
      "  \"\\\"Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph\",\n",
      "  \"must be:\",\n",
      "  \"{0}\",\n",
      "  \"Firstly, make five different plans for a coherent passage, then write. Your output\",\n",
      "  \"should be of the following format:\",\n",
      "  \"Plan 1: Your plan here.\",\n",
      "  \"Plan 2: Your plan here.\",\n",
      "  \"Plan 3: Your plan here.\",\n",
      "  \"Plan 4: Your plan here.\",\n",
      "  \"Plan 5: Your plan here.\",\n",
      "  \"Secondly, given an instruction and several plans, decide which choice is most\",\n",
      "  \"promising. Analyze each choice in detail, then conclude in the last line \\\"The best\",\n",
      "  \"choice is {{s}}\\\", where s the integer id of the choice.\",\n",
      "  \"Thirdly, write the passage according to that chosen plan in the most coherent way. Add\",\n",
      "  \"\\\"Passage:\\\" before writing the passage under it.\",\n",
      "  \"Passage: Your passage here.\",\n",
      "  \"Finally, refine the passage in the most coherent way, but you still have to end each\",\n",
      "  \"paragraph with the given sentences as before.\",\n",
      "  \"Final Passage: Final passage here.\",\n",
      "  \"Score Prompt\",\n",
      "  \"Analyze the following passage, then at the last line conclude \\\"Thus the coherency\",\n",
      "  \"score is {{s}}\\\", where s is an integer from 1 to 10.\",\n",
      "  \"{0}\",\n",
      "  \"Acknowledgment: We appreciate the discussions and assistance provided by L. Wang.\",\n",
      "  \"Contributions: B. Sel played a pivotal role in shaping the primary concept, spearheading the experimental design and eval- uation, and leading the paper\\u2019s writing process. A. Tawaha actively engaged in discussions and conducted experiments. V. Khattar collaborated through discussions and played a role in conducting the experiments. R. Jia and M. Jin both engaged in constructive discussions, with M. Jin also offering advisory guidance.\",\n",
      "  \"Additional info about the changes from the first version (dated 8/20/2023) can be found in this link (https://tinyurl.com/ 2vnjxw93).\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Supponiamo che `elements` sia gi definito e contenga una lista di oggetti con il metodo `to_dict()`\n",
    "\n",
    "# Converte ogni elemento in un dizionario usando il metodo `to_dict()`\n",
    "element_dicts = [el.to_dict() for el in elements]\n",
    "\n",
    "# Estrae solo il campo \"text\" di ogni dizionario\n",
    "texts = [element[\"text\"] for element in element_dicts]\n",
    "\n",
    "# Converte la lista di testi in una stringa JSON ben formattata\n",
    "testo= json.dumps(texts, indent=2)\n",
    "\n",
    "# Stampa la stringa JSON formattata\n",
    "print(testo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supponiamo che `elements` sia gi definito e contenga una lista di oggetti con il metodo `to_dict()`\n",
    "\n",
    "# Converte ogni elemento in un dizionario usando il metodo `to_dict()`\n",
    "element_dicts = [el.to_dict() for el in elements]\n",
    "\n",
    "# Filtra solo gli elementi di tipo \"Title\" ed estrae il campo \"text\"\n",
    "titles = [element[\"text\"] for element in element_dicts if element[\"type\"] == \"Title\"]\n",
    "\n",
    "# Converte la lista di testi dei titoli in una stringa JSON ben formattata\n",
    "indice = json.dumps(titles, indent=2)\n",
    "\n",
    "# Stampa la stringa JSON formattata\n",
    "print(indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testo_da_riassumere=testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esempio di template prompt\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Riassumi questo testo{testou} ; {argomento}, Rispondi in italiano.\")\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "answer = chain.invoke({\"argomento\": \"La linguistica\"})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esempio di template prompt\n",
    "\n",
    "# Definisci il prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Riassumi questo testo {testou} il cui titolo  {titolou}, il cui autore  {autoreu}, il cui indice  {indice}. Dividi il riassunto i queste ssezioni: quadro teorico, obiettivi, metodologia, risultati e conclusioni. Queste sezionio saranno i paragrafi del riassunto. Il riassunto deve essere discorsivo e ogni parte deve avere almeno cinque capoversi. Inserisci esempi, definizioni e loro spigazione.  All'inizio del riassunto fai una piccola scheda con titolo, autore e concetti pi importanti. Non fare un elenco puntato. Agisci come un ricercatore. Rispondi in italiano. dopo aver fatto il riassunto e cerca di migliorarlo ulteriormente. Alla fine metti i riferimenti bibliografici che si trovano nella sezione bibliografia in formato APA. Se parole sono tecniche e centrarli nel testo lasciale in inlgese\"\"\"\n",
    ")\n",
    "\n",
    "# Crea l'output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Crea la catena di trasformazione\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# Definisci i parametri di input\n",
    "params = {\n",
    "    \"testou\": testo,\n",
    "    \"titolou\": titolo,\n",
    "    \"autoreu\": autore,\n",
    "    \"indice\": indice\n",
    "}\n",
    "\n",
    "# Esegui la catena e ottieni la risposta\n",
    "answer = chain.invoke(params)\n",
    "\n",
    "# Stampa la risposta\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caricamento file da cartella\n",
    "\n",
    "#percorso della cartella contenente i PDF\n",
    "folder_path = 'pdfs'\n",
    "\n",
    "# Lista per memorizzare tutti i documenti caricati\n",
    "all_documents = []\n",
    "\n",
    "# Iterare su tutti i file nella cartella\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(folder_path, filename)\n",
    "        loader = PyPDFLoader(file_path=pdf_path)\n",
    "        documents = loader.load()\n",
    "        all_documents.extend(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents[16].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stampare i nomi dei file PDF caricati\n",
    "print(\"PDF caricati:\")\n",
    "for pdf in all_documents:\n",
    "    print(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_documents[0].page_content[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents=testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm of Thoughts: Enhancing Exploration of Ideas\n",
      "in Large Language Models\n",
      "Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Ruoxi Jia, and Ming Jin\n",
      "Virginia Tech\n",
      "Abstract\n",
      "Current literature, aiming to surpass the Chain-of-Thought\n",
      "approach, often resorts to an external modus operandi in-\n",
      "volving halting, modifying, and then resuming the genera-\n",
      "tion process to boost Large Language Models (LLMs) rea-\n",
      "soning capacities. This mode escalates the number of query\n",
      "requests, leading to increased costs, memory, and computa-\n",
      "tional overheads. Addressing this, we propose the Algorithm\n",
      "of Thoughts a novel strategy that propels LLMs through\n",
      "algorithmic reasoning pathways, pioneering a new mode of\n",
      "in-context learning. By employing algorithmic examples, we\n",
      "exploit the innate recurrence dynamics of LLMs, expand-\n",
      "ing their idea exploration with merely one or a few queries.\n",
      "Our technique outperforms earlier single-query methods and\n",
      "stands on par with a recent multi-query strategy that employs\n",
      "an extensive tree search algorithm. Intriguingly, our results\n",
      "suggest that instructing an LLM using an algorithm can lead\n",
      "to performance surpassing that of the algorithm itself, hinting\n",
      "at LLMs inherent ability to weave its intuition into optimized\n",
      "searches. We probe into the underpinnings of our methods\n",
      "efficacy and its nuances in application.\n",
      "Introduction\n",
      "Recent developments in large language models (Chowdhery\n",
      "et al. 2022; Thoppilan et al. 2022; Liu et al. 2023, inter alia )\n",
      "have spotlighted their efficacy in general problem solving\n",
      "(Huang and Chang 2022; Suzgun et al. 2022), code gen-\n",
      "eration (Chen et al. 2021; Austin et al. 2021), and instruc-\n",
      "tion following (Ouyang et al. 2022; Bai et al. 2022). While\n",
      "early models relied on direct answer strategies (Brown et al.\n",
      "2020), contemporary research veers towards linear reason-\n",
      "ing paths (Wei et al. 2022b; Kojima et al. 2022; Zhang et al.\n",
      "2022) by breaking problems into sub-tasks for solution dis-\n",
      "covery, or harnesses external mechanisms to alter token gen-\n",
      "eration by changing the context (Zhou et al. 2022; Drozdov\n",
      "et al. 2022; Yao et al. 2023).\n",
      "Analogous to human cognition (Sloman 1996; Kahneman\n",
      "2011), early LLM strategies seemed to emulate the instan-\n",
      "taneous System 1 , characterized by its impulsive decision-\n",
      "making. In contrast, more recent methodologies like chain-\n",
      "of-thought (CoT) (Wei et al. 2022b) and least-to-most\n",
      "prompting (L2M) (Zhou et al. 2022; Drozdov et al. 2022)\n",
      "Preprint. Under review.reflect the introspective nature of System 2 . Notably, inte-\n",
      "grating intermediary reasoning steps has yielded improve-\n",
      "ments in arithmetic reasoning tasks (Srivastava et al. 2022;\n",
      "Liang et al. 2022).\n",
      "However, as tasks shift towards deeper planning and ex-\n",
      "tensive thought exploration, these methods appear restric-\n",
      "tive. Although CoT integrated with Self-Consistency (CoT-\n",
      "SC) (Wang et al. 2022) enlists multiple LLM outputs for\n",
      "a consensus, the lack of meticulous evaluation can result\n",
      "in model misdirection. The Tree of Thoughts (Yao et al.\n",
      "2023; Long 2023) emerges as a notable solution. While one\n",
      "LLM is dedicated to idea generation, another steps in to as-\n",
      "sess the merit of these ideas, following a halting-assessment-\n",
      "resuming cycle. This iterative process, anchored by tree\n",
      "search, has shown marked effectiveness, especially in tasks\n",
      "with a breadth of continuations. We see this progression\n",
      "as akin to humans employing tools to circumvent working\n",
      "memory limitations, serving as an external augmentation for\n",
      "LLMs (Mialon et al. 2023).\n",
      "On the flip side, this enhanced LLM approach is not\n",
      "without pitfalls. A prominent downside is the substantial\n",
      "surge in the number of queries and computational demands.\n",
      "Each query to online LLM APIs such as GPT-4a focal\n",
      "point of our studyincurs a monetary expense (Chen, Za-\n",
      "haria, and Zou 2023) but also contributes to latency, a sig-\n",
      "nificant limitation especially critical in real-time applica-\n",
      "tions. Cumulative delays from these queries can compro-\n",
      "mise solution efficiency. Infrastructure-wise, continuous in-\n",
      "teractions can stress systems, leading to potential bandwidth\n",
      "constraints and reduced model availability (Aminabadi et al.\n",
      "2022). Moreover, the environmental implications cannot be\n",
      "ignored; incessant querying escalates the energy consump-\n",
      "tion of already power-hungry data centers, exacerbating the\n",
      "carbon footprint (Wu et al. 2022; Dhar 2020).\n",
      "With this in mind, our goal is to dramatically reduce the\n",
      "query counts employed by contemporary multi-query rea-\n",
      "soning methods while maintaining performance for tasks ne-\n",
      "cessitating adept use of world knowledge , thereby steering a\n",
      "more responsible and proficient use of AI resources.\n",
      "Reflecting on the evolution of LLMs from System 1 to\n",
      "System 2, an essential ingredient comes to light: algorithms.\n",
      "Characterized by its methodical nature, the algorithmic per-\n",
      "spective offers a path to keenly explore problem spaces, en-\n",
      "act strategies, and formulate solutions (Helie and Pizlo 2022;arXiv:2308.10379v2  [cs.CL]  28 Sep 2023\n",
      "Chain-of-Thought\n",
      "Model \n",
      "Input\n",
      "Model \n",
      "Output\n",
      "User: \n",
      "8 \n",
      "6 \n",
      "4 \n",
      "4\n",
      "Assistant: \n",
      "8 \n",
      "- \n",
      "6 \n",
      "= \n",
      "2 \n",
      "(left: \n",
      "4, \n",
      "4, \n",
      "2)\n",
      "4 \n",
      "+ \n",
      "2 \n",
      "= \n",
      "6 \n",
      "(left: \n",
      "6, \n",
      "4)\n",
      "6 \n",
      "* \n",
      "4 \n",
      "= \n",
      "24\n",
      "Answer: \n",
      "(4 \n",
      "+ \n",
      "(8 \n",
      "- \n",
      "6)) \n",
      "* \n",
      "4 \n",
      "= \n",
      "24.\n",
      " \n",
      "User: \n",
      "11 \n",
      "10 \n",
      "5 \n",
      "1\n",
      "Assistant:\n",
      "11 \n",
      "- \n",
      "10 \n",
      "= \n",
      "1 \n",
      "(left: \n",
      "1, \n",
      "1, \n",
      "5)\n",
      "1 \n",
      "* \n",
      "1 \n",
      "= \n",
      "1 \n",
      "(left: \n",
      "1, \n",
      "5)\n",
      "5 \n",
      "* \n",
      "1 \n",
      "= \n",
      "5 \n",
      "(left: \n",
      "5)\n",
      "Answer: \n",
      "((11 \n",
      "- \n",
      "10) \n",
      "* \n",
      "1) \n",
      "* \n",
      "5 \n",
      "- \n",
      "1 \n",
      "= \n",
      "24.\n",
      "Algorithm \n",
      "of \n",
      "Thoughts\n",
      "Model \n",
      "Input\n",
      "Model \n",
      "Output\n",
      "User: \n",
      "8 \n",
      "6 \n",
      "4 \n",
      "4\n",
      "Assistant:\n",
      "1. \n",
      "4 \n",
      "- \n",
      "4: \n",
      "(left: \n",
      "8, \n",
      "6, \n",
      "0)\n",
      ".\n",
      ".\n",
      ".\n",
      "3. \n",
      "8 \n",
      "- \n",
      "6: \n",
      "(left: \n",
      "4, \n",
      "4, \n",
      "2)\n",
      "- \n",
      "4 \n",
      "+ \n",
      "4: \n",
      "(left: \n",
      "8, \n",
      "2) \n",
      "10, \n",
      "6, \n",
      "16, \n",
      "4\n",
      "- \n",
      "4 \n",
      "- \n",
      "4: \n",
      "(left: \n",
      "2, \n",
      "0) \n",
      "2, \n",
      "2, \n",
      "0, \n",
      "undefined\n",
      "- \n",
      "4 \n",
      "* \n",
      "4: \n",
      "(left: \n",
      "16, \n",
      "2) \n",
      "18, \n",
      "14, \n",
      "32, \n",
      "8\n",
      "- \n",
      "4 \n",
      "/ \n",
      "4: \n",
      "(left: \n",
      "2, \n",
      "1) \n",
      "3, \n",
      "1, \n",
      "2, \n",
      "2\n",
      "- \n",
      "4 \n",
      "+ \n",
      "2: \n",
      "(left: \n",
      "6, \n",
      "4) \n",
      "10, \n",
      "2, \n",
      "24 \n",
      "= \n",
      "6 \n",
      "* \n",
      "4 \n",
      "-> \n",
      "found \n",
      "it!\n",
      "Answer: \n",
      "(4 \n",
      "+ \n",
      "(8 \n",
      "- \n",
      "6)) \n",
      "* \n",
      "4 \n",
      "= \n",
      "24.\n",
      " \n",
      "User: \n",
      "11 \n",
      "10 \n",
      "5 \n",
      "1\n",
      "Assistant:\n",
      "1. \n",
      "11 \n",
      "- \n",
      "1: \n",
      "(left: \n",
      "10, \n",
      "10, \n",
      "5)\n",
      ".\n",
      ".\n",
      ".\n",
      "5. \n",
      "11 \n",
      "+ \n",
      "1: \n",
      "(left: \n",
      "12, \n",
      "10, \n",
      "5)\n",
      "- \n",
      "12 \n",
      "+ \n",
      "10: \n",
      "(left: \n",
      "22, \n",
      "5) \n",
      "27, \n",
      "17, \n",
      "110, \n",
      "4.4\n",
      "- \n",
      "12 \n",
      "- \n",
      "10: \n",
      "(left: \n",
      "5, \n",
      "2) \n",
      "7, \n",
      "3, \n",
      "10, \n",
      "2.5\n",
      "- \n",
      "12 \n",
      "* \n",
      "10: \n",
      "(left: \n",
      "120, \n",
      "5) \n",
      "24 \n",
      "= \n",
      "120 \n",
      "/ \n",
      "5 \n",
      "-> \n",
      "found \n",
      "it!\n",
      "Answer: \n",
      "((11 \n",
      "+ \n",
      "1) \n",
      "* \n",
      "10) \n",
      "/ \n",
      "5 \n",
      "= \n",
      "24.\n",
      "Standard \n",
      "Prompting\n",
      "Model \n",
      "Input\n",
      "Model \n",
      "Output\n",
      "User: \n",
      "8 \n",
      "6 \n",
      "4 \n",
      "4\n",
      "Assistant: \n",
      "Answer: \n",
      "(4 \n",
      "+ \n",
      "(8 \n",
      "- \n",
      "6)) \n",
      "* \n",
      "4 \n",
      "= \n",
      "24.\n",
      " \n",
      "User: \n",
      "11 \n",
      "10 \n",
      "5 \n",
      "1\n",
      "Assistant:\n",
      "Answer: \n",
      "(11 \n",
      "- \n",
      "1) \n",
      "* \n",
      "(10 \n",
      "- \n",
      "5) \n",
      "= \n",
      "24Figure 1: Comparison between standard prompting, CoT, and AoT in the game of 24. While standard prompting aims for a direct\n",
      "answer, CoT sketches out the successive steps to the final solution. AoTs in-context example, distinct from CoT, integrates the\n",
      "search process, highlighted by markers 1,..., 3 as first operations guiding subtree exploration for the problem set 8 6\n",
      "4 4. For clarity, only a single in-context example is displayed, with a focus on the third subtree exploration. AoT produces\n",
      "prospective search steps (e.g., the subtree exploration 5. 11 + 1 ) and evaluates potential subsequent steps to either progress\n",
      "towards a solution or retrace to another viable subtree.\n",
      "Banerjee et al. 2022). While much of the prevailing literature\n",
      "treats algorithms as external to LLMs, given LLMs inher-\n",
      "ent generative recurrence, can we channel this iterative logic\n",
      "tointernalize an algorithm?\n",
      "Drawing upon both the intricate nuances of human rea-\n",
      "soning and the disciplined precision of algorithmic method-\n",
      "ologies, our work aims to fuse these dual facets to aug-\n",
      "ment reasoning capabilities within LLMs. Existing research\n",
      "underscores that humans, when navigating complex prob-\n",
      "lems, instinctively draw upon past efforts, ensuring a com-\n",
      "prehensive contemplation rather than a narrow focus (Mon-\n",
      "sell 2003; Holyoak and Morrison 2005; Baddeley 2003).\n",
      "LLMs, with their generative span bounded only by token\n",
      "limits, appear poised to break through the barriers of human\n",
      "working memory. Spurred by this observation, we investi-\n",
      "gated if LLMs could mirror a similar layered exploration\n",
      "of ideas, referencing prior intermediate steps to sieve out\n",
      "infeasible options, all within their iterative generation cy-\n",
      "cle. And while humans excel with their intuitive acumen, al-\n",
      "gorithms stand out with organized, systematic exploration.\n",
      "Current techniques, like CoT, often sidestep this synergistic\n",
      "potential, imposing undue pressure on LLMs for on-the-spot\n",
      "precision. By capitalizing on LLMs recursive capabilities,\n",
      "we emulate a hybrid human-algorithmic approach. This is\n",
      "achieved through our use of algorithmic examples that cap-\n",
      "ture the essence of exploration, from initial candidates to\n",
      "validated solutions. Thus emerges our concept of the Algo-\n",
      "rithm of Thoughts (AoT), as illustrated in Figs. 1 and 2.More broadly, our approach signifies a new paradigm of\n",
      "in-context learning. Instead of the traditional supervised-\n",
      "learning mold of [ PROBLEM ,SOLUTION ] or [ PROBLEM ,\n",
      "SUCCESSIVE STEPS TO SOLUTION ], we present a new\n",
      "structure that covers [ PROBLEM ,SEARCH PROCESS ,SO-\n",
      "LUTION ]. Naturally, when instructing an LLM using an al-\n",
      "gorithm, the anticipation leans towards the LLM simply\n",
      "imitating the algorithms iterative thinking. However, what\n",
      "emerges as intriguing is the LLMs ability to infuse its own\n",
      "intuition to achieve a search efficiency that even surpasses\n",
      "the algorithm itself (see Fig. 5).\n",
      "In the subsequent sections, we first situate our work\n",
      "within the existing literature, followed by a discussion of\n",
      "our principal idea. We then present our experimental results\n",
      "and probe a series of hypotheses related to this emerging ca-\n",
      "pability of LLM before rounding off with a conclusion.\n",
      "Related Work\n",
      "Standard Prompting. Also known as input-output\n",
      "prompting, it provides a few input-output examples of the\n",
      "task before getting an answer for the test sample from the\n",
      "language model (Brown et al. 2020). Although this method\n",
      "is very general and does not need any special prompting\n",
      "strategy, the performance is also worse compared to more\n",
      "advanced methods (Shao et al. 2023; Wei et al. 2022a; Lyu\n",
      "et al. 2023).\n",
      "Input\n",
      "Output\n",
      "Input\n",
      "Output\n",
      "Input\n",
      "Output\n",
      "Input\n",
      "Output\n",
      "Standard \n",
      "Prompting\n",
      "Chain \n",
      "of \n",
      "Thoughts\n",
      "Tree \n",
      "of \n",
      "Thoughts\n",
      "Algorithm \n",
      "of \n",
      "ThoughtsFigure 2: Illustration outlining various strategies for tackling reasoning problems with LLMs. Each box signifies a distinct\n",
      "thought, functioning as a unified string of words that forms an incremental pathway to reasoning. Green boxes indicate ideas\n",
      "deemed promising by the LLM, while red boxes represent less promising concepts.\n",
      "Chain-of-Thought. In CoT, LLMs are presented with ex-\n",
      "amples where a given question xunfolds through a chain\n",
      "of intermediate reasoning pieces c1, . . . , c nto reach an an-\n",
      "swery, represented as xc1. . .cny(Wei\n",
      "et al. 2022b; Lyu et al. 2023). By mimicking the examples\n",
      "in the context, the LLM automatically divides the solution\n",
      "into simpler linear steps to arrive at the answer, improv-\n",
      "ing performance across numerous reasoning benchmarks.\n",
      "Self-consistency (Wang et al. 2022) is a widely used de-\n",
      "coding strategy aimed at generating a variety of reason-\n",
      "ing paths by choosing the final answer through a majority\n",
      "vote, though this necessitates additional generations. Con-\n",
      "trary to CoTs linear, direct progression, our approach pivots\n",
      "towards the explorative aspect of LLMs. We reconceptual-\n",
      "ize the c1, . . . , c nsequence, not merely as successive steps\n",
      "towards a solution, but as a dynamic, potentially mutable\n",
      "path that resembles an algorithmic search, allowing for ex-\n",
      "ploration, recalibration, and non-linear progression.\n",
      "Least-to-Most prompting (L2M). Taking cues from ed-\n",
      "ucational psychology (Libby et al. 2008), L2M prompting\n",
      "directs the LLM to decompose the central problem into\n",
      "smaller subproblems. Each subproblem is tackled in se-\n",
      "quence, with the outcome appended before progressing to\n",
      "the next (Zhou et al. 2022; Drozdov et al. 2022). While this\n",
      "structured delineation is beneficial for broader generaliza-\n",
      "tion, it operates on the premise of finding a nearly perfect de-\n",
      "composition in a single attemptideal for problems with a\n",
      "clear-cut structure. Yet, when tasks intertwine with their de-\n",
      "composition complexities (like games of 24), this methods\n",
      "inflexibility becomes apparent. Contrastingly, AoT not only\n",
      "underscores the active subproblem (as shown in Fig. 1), but\n",
      "also permits a more contemplative approach by entertaining\n",
      "various options for each subproblem, while maintaining ef-\n",
      "ficacy even with minimal prompts.\n",
      "Tree of Thoughts (ToT). In the cases where each sub-\n",
      "problem has multiple viable options to explore, linear rea-\n",
      "soning paths from CoT or L2M substantially limit the cov-\n",
      "erage of the thought space. Considering possible options for\n",
      "each subproblem, the decision tree can be explored by ex-\n",
      "ternal tree-search mechanisms (e.g., BFS, DFS) (Yao et al.2023). Evaluation capabilities of LLMs can also be used to\n",
      "direct the search by pruning nodes that are hopeless to in-\n",
      "crease efficiency. However, ToTs Achilles heel is its ex-\n",
      "cessive reliance on LLM queries, at times necessitating hun-\n",
      "dreds for just one problem. We tackle this limitation by gen-\n",
      "erating the whole thought process within a single context.\n",
      "Algorithm of Thoughts\n",
      "Our strategy pivots on recognizing a core shortcoming of\n",
      "current in-context learning paradigms. CoT, while enhanc-\n",
      "ing the coherency of thought linkages leading to solutions,\n",
      "occasionally falters, presenting incorrect intermediate steps\n",
      "(Zelikman et al. 2022; Turpin et al. 2023; Lanham et al.\n",
      "2023). Faithful CoT (Lyu et al. 2023) ought to amend this\n",
      "by eliciting symbolic chains of reasoning where the LLMs\n",
      "output resembles task-specific pseudo-code, primed for de-\n",
      "terministic execution like Python. The intention is only to\n",
      "use the thought processes but not the outputs and inputs of\n",
      "each link since they have a tendency to be unreliable. But,\n",
      "the occasional missteps of CoT may not necessarily due to\n",
      "the LLMs inability to compute correctly . The LLM, when\n",
      "confronted with questions that closely match conditions of\n",
      "previous in-context examples, may favor echoing those out-\n",
      "puts over generating the appropriate questions. To shed light\n",
      "on this phenomenon, we designed an experiment. Querying\n",
      "text-davinci-003 for arithmetic tasks (e.g.,  112 =), we\n",
      "prefixed them with multiple in-context equations converging\n",
      "to an identical output (e.g.  155 = 10 ,8 + 2 = 10 ). Our\n",
      "results, presented in Fig. 3, reveal a steep decline in accu-\n",
      "racy, suggesting that the mere presence of correct reasoning\n",
      "in the context might inadvertently compromise even basic\n",
      "arithmetic skills.\n",
      "To offset this bias, diversifying the outputs of examples\n",
      "might seem like a viable solution, but this could subtly skew\n",
      "the distribution of outputs. Merely adding unsuccessful tri-\n",
      "als, much like a random search, might inadvertently encour-\n",
      "age the model to retry rather than truly solve. Capturing\n",
      "the true essence of algorithmic behavior, where both failed\n",
      "searches and subsequent recovering and learning from such\n",
      "attempts play a role, we incorporate in-context examples pat-\n",
      "0 2 4 6 8 10 12\n",
      "# of Equations0.00.20.40.60.81.0Probability of Correct T okenFigure 3: The probability of generating the correct token as\n",
      "we add more in-context examples that are correct but possess\n",
      "identical outputs.\n",
      "terned after search algorithms , notably depth-first search\n",
      "(DFS) and breadth-first search (BFS). See Fig. 1 for an ex-\n",
      "ample.\n",
      "This paper focuses on a broad class of tasks reminiscent of\n",
      "tree-search problems. These tasks necessitate breaking down\n",
      "the main problem, crafting feasible solutions for each seg-\n",
      "ment, and making decisions on the paths to either pursue\n",
      "or forsake, with the option of reevaluating more promising\n",
      "segmentations. Rather than posing separate queries for ev-\n",
      "ery subset, we leverage the iterative capabilities of the LLM\n",
      "to address them in one unified generation sweep. By confin-\n",
      "ing ourselves to one or two LLM interactions, this approach\n",
      "naturally incorporates insights from antecedent context can-\n",
      "didates and tackles intricate issues requiring an in-depth ex-\n",
      "ploration of the solution domain. In alignment with our goal,\n",
      "we also give insights into how small or big those thoughts\n",
      "should be and what type of in-context examples should be\n",
      "given to the LLM to promote token efficiency. Subsequently,\n",
      "we outline key components of tree-search algorithms and\n",
      "their manifestation in our framework.\n",
      "1. Decomposition into Subproblems. Given a problem,\n",
      "constructing a search tree that delineates feasible reasoning\n",
      "pathways is already a demanding task, excluding the actual\n",
      "problem-solving aspect. Any decomposition must consider\n",
      "not just the interrelations between subtasks, but also the ease\n",
      "of addressing each individually. Consider a simple multi-\n",
      "digit addition: while converting numbers to binary might\n",
      "be efficient for a computer, humans typically find base 10\n",
      "arithmetic more intuitive. Furthermore, even if the subprob-\n",
      "lems remain constant, their execution might vary. Intuition\n",
      "can lead to shortcuts between solution steps, while its ab-\n",
      "sence might necessitate more detailed steps. Crafting the\n",
      "right prompt (i.e., in-context algorithmic examples) hinges\n",
      "on these nuances, determining the minimal tokens an LLM\n",
      "would need for dependable performance. This is not only\n",
      "essential to fit within the LLMs context constraints but also\n",
      "vital for efficacy, as wed expect LLMs to address problems\n",
      "resonant with its context using a similar token volume.\n",
      "2. Proposing Solutions to Subproblems. A dominant ap-\n",
      "proach in existing works involves direct sampling from\n",
      "LLM token output probabilities (Wang et al. 2022; Yao\n",
      "The \n",
      "first \n",
      "five \n",
      "prime \n",
      "numbers:\n",
      "Text \n",
      "Completion\n",
      "2 \n",
      "= \n",
      "87.6%\n",
      "1 \n",
      "= \n",
      "12.3%\n",
      "...\n",
      "...\n",
      "2, \n",
      "3, \n",
      "5, \n",
      "7, \n",
      "11\n",
      "probabilities \n",
      "for \n",
      "the \n",
      "first \n",
      "tokenFigure 4: An example highlighting the drawback of isolated\n",
      "sampling of sequenced ideas. Input is denoted in blue, with\n",
      "thetext-davinci-003 providing the green completions.\n",
      "et al. 2023). Though effective for one-off answers (Kadavath\n",
      "et al. 2022) (with certain constraints (Robinson and Wingate\n",
      "2022)), this method falls short in scenarios demanding a se-\n",
      "quence of samples to be integrated or evaluated within sub-\n",
      "sequent prompts (Robinson and Wingate 2022). To mini-\n",
      "mize model queries, we adopt an uninterrupted solution cre-\n",
      "ation process. Here, we directly and continuously generate\n",
      "solutions for the prevailing subproblem without any genera-\n",
      "tion pauses.\n",
      "The benefits are three-fold. First, with all generated solu-\n",
      "tions existing within a shared context, theres no need for in-\n",
      "dividual model queries for each solution evaluation. Second,\n",
      "while it may seem counterintuitive initially, isolated token or\n",
      "token group probabilities might not always yield meaning-\n",
      "ful choices. A simple illustration is found in Fig. 4. When\n",
      "evaluated independently, the second-most probable token for\n",
      "our inaugural number is  1not qualifying as prime. But,\n",
      "when generation remains unbroken, the derived sequence is\n",
      "correct. This incongruence points towards the restrictive na-\n",
      "ture of the Markov property in sequence modeling. Core to\n",
      "our perspective is the premise that for sequential tasks like\n",
      "algorithmic search, LLMs are more adept at generating en-\n",
      "tire sequences than intermittently pausing and re-initiating\n",
      "the token sampling process.\n",
      "3. Gauging the Promise of a Subproblem. As above,\n",
      "existing techniques lean on additional prompting to dis-\n",
      "cern the potential of tree nodes, aiding decisions regard-\n",
      "ing exploration direction. Our observations suggest that if\n",
      "the most promising routes are encapsulated within the in-\n",
      "context examples, LLMs inherently gravitate towards prior-\n",
      "itizing those promising candidates. This diminishes the need\n",
      "for intricate prompt engineering and allows the incorpora-\n",
      "tion of intricate heuristics, whether intuitive or knowledge-\n",
      "driven. Again, the absence of disjoint prompts in our ap-\n",
      "proach allows for an immediate assessment of candidate vi-\n",
      "ability in the same generation.\n",
      "4. Backtracking to a Preferable Juncture. The decision\n",
      "of which node to explore next (including retracing to a prior\n",
      "node) inherently depends on the selected tree-search algo-\n",
      "rithm. While previous studies (Yao et al. 2023) have em-\n",
      "ployed external means such as coded mechanisms for the\n",
      "search process, this restricts its broader appeal and entails\n",
      "additional customization. Our designs predominantly adopt\n",
      "a DFS approach supplemented by pruning. The aim is to\n",
      "maintain proximity between nodes sharing the same par-\n",
      "ent, thereby encouraging the LLM to prioritize local over\n",
      "distant features. Additionally, we present performance met-\n",
      "rics for the AoT approach grounded in BFS. Our reliance\n",
      "on the models inherent capacity to glean insights from in-\n",
      "context examples obviates the necessity for additional, be-\n",
      "spoke mechanisms.\n",
      "Experiments\n",
      "We show that AoT surpasses the performance of other\n",
      "single-prompt methods (e.g. standard, CoT/-SC prompting)\n",
      "while remaining competitive even when compared to meth-\n",
      "ods that utilize external mechanisms, such as ToT, in bench-\n",
      "marks like the game of 24 and 5x5 mini crosswords.\n",
      "Game of 24\n",
      "The game of 24 is a mathematical card game in which play-\n",
      "ers are given four numbers and must use addition, subtrac-\n",
      "tion, multiplication, and division (each operation can be used\n",
      "more than once) to manipulate those numbers to total 24.\n",
      "For instance, for the numbers  8 8 5 4 , one solution would\n",
      "be 8(5(8/4)) = 24 . At first glance, the game might\n",
      "appear straightforward. However, a cursory calculation sug-\n",
      "gests there are nearly 13,000 distinct expressions possible\n",
      "for any set of four numbers (without accounting for the com-\n",
      "mutative properties of addition and multiplication), making\n",
      "it a formidable challenge for present-day LLMs.\n",
      "Task Setup. Adhering to the setup detailed in (Yao et al.\n",
      "2023), we use games from indices 901-1000, sourced from\n",
      "the 1362 games ranked by relative difficulty at 4nums.com .\n",
      "For an attempt to be considered successful, it must derive a\n",
      "total of 24 using the exact numbers provided and only the\n",
      "allowed operations.\n",
      "Baselines. Standard prompting and CoT are used in the 5-\n",
      "shot setting, with CoT integrating 3 steps for the operations.\n",
      "These methods are sampled 100 times, and the averaged suc-\n",
      "cess rates from these samples are reported. CoT-SC is also\n",
      "tested with 100 votes in our setup. For ToT, we use a breadth\n",
      "of 5. The performance metrics from their study are directly\n",
      "cited to obviate the need for needless carbon emissions.\n",
      "AoT Setup. We employ the same 5-shot setting as in stan-\n",
      "dard prompting and CoT baseline setup. Our in-context sam-\n",
      "ples leverage a DFS-style search algorithm, which, for clar-\n",
      "ity, is the same version used when contrasting with tra-\n",
      "ditional DFS in Fig. 5. During each subtree exploration,\n",
      "dubbed either the first step or first operation, we choose\n",
      "two numbersillustrated by the selection of 8 and 6 in the\n",
      "third first step (i.e., subtree labeled 3) of Fig. 1and a\n",
      "corresponding operation (e.g., 86). This operation results\n",
      "in a new number, 2, leaving us with three numbers in total.\n",
      "A thorough combing of these three numbers culminates in\n",
      "19 leaf nodes, all visible under the 3 subtree in Fig. 1. We\n",
      "aim to assess two aspects: the ability of the LLM to pin-\n",
      "point promising first operations, which directly impacts the\n",
      "number of resolved leaf nodes, and its performance against\n",
      "a conventional DFS. Details on the prompts we employed\n",
      "are provided in the Appendix. As our method emphasizessequential generation over trajectory sampling, we operate\n",
      "with a temperature setting of 0.\n",
      "Results. From Table 1, its evident that standard prompt-\n",
      "ing combined with CoT/-SC significantly lags behind tree\n",
      "search methods when used with LLMs. The Standard + Re-\n",
      "fine result, showing a 27% success rate, is referenced from\n",
      "(Yao et al. 2023). This method involves iteratively asking\n",
      "the LLM (up to 10 iterations) to refine its answer if the initial\n",
      "one is incorrect. Meanwhile, ToT is limited to a maximum of\n",
      "100 node visits, translating to several hundred LLM queries\n",
      "for each example. Remarkably, AoT achieves its results with\n",
      "just a single query . Despite reducing the number of requests\n",
      "by more than a factor of 100, AoT still outperforms ToT in\n",
      "this task.\n",
      "Method Success Avg. Queries\n",
      "Standard Prompting 7.3% 1\n",
      "CoT 4.0% 1\n",
      "CoT-SC (k= 100) 9 .0% 100\n",
      "Standard + Refine 27% 10\n",
      "ToT (b= 5) 69% 109 .1\n",
      "AoT (ours) 71% 1\n",
      "Table 1: Game of 24: success rates and the average number\n",
      "of LLM queries for each example.\n",
      "Error Analysis. Using a strictly LLM-centric approach\n",
      "eschewing any external tooling or editswe sought to cat-\n",
      "egorize mistakes observed during the game of 24. This aids\n",
      "in highlighting areas for refinement when solely deploying\n",
      "LLMs. Weve classified these errors into four distinct, ex-\n",
      "haustive categories: 1)Out-of-token error: The LLM reaches\n",
      "its maximum token threshold without identifying a solution.\n",
      "2)Expression misstep: The LLM has the correct logic or\n",
      "steps but fails when trying to express or formulate them into\n",
      "a coherent answer. 3)Non-finalization error: The LLM dis-\n",
      "covers the solution but continues its search without consol-\n",
      "idating the finding. 4)Other errors: This umbrella term en-\n",
      "compasses other mistakes like computational errors that re-\n",
      "sult in overlooking the solution or furnishing incorrect an-\n",
      "swers. To exclusively showcase the AoTs search capabil-\n",
      "ities, we also present the AoT + Manual Resolution ver-\n",
      "sion. Here, once the LLM pinpoints a solution, its final ar-\n",
      "ticulation is manually processeda strategy also employed\n",
      "by the ToT method. As evidenced in Table 2, a notable\n",
      "7% of mistakes stem from non-algorithmic factors like non-\n",
      "finalization and expression missteps. In fact, with manual\n",
      "resolution, AoT attains a 78% success rate, surpassing ToT.\n",
      "This underlines the potential for refining our prompt, espe-\n",
      "cially in areas concerning recognizing and expressing suc-\n",
      "cessful problem resolutions. Additionally, the token limi-\n",
      "tation underscores the appeal of expanding the generative\n",
      "context window, which may further bolster LLMs recursive\n",
      "reasoning when engaged with algorithmic examples.\n",
      "Error Type Error\n",
      "Out-of-token error 9%\n",
      "Expression misstep 4%\n",
      "Non-finalization error 3%\n",
      "Others 13%\n",
      "Method Success\n",
      "ToT 69%\n",
      "AoT 71%\n",
      "AoT + Manual Resolution 78%\n",
      "Table 2: Game of 24: AoT error analysis.\n",
      "Mini Crosswords\n",
      "The 55mini crossword is a compact word puzzle featur-\n",
      "ing a grid of 25 squares arranged in a 5-by-5configuration.\n",
      "Players are tasked with filling the grid based on provided\n",
      "clues for each word. Clues are given for words that run both\n",
      "across (horizontally) and down (vertically). Words intersect\n",
      "at certain letters, offering additional hints to complete the\n",
      "puzzle.\n",
      "Task Setup. Adhering to the setup outlined in (Yao et al.\n",
      "2023), we draw our prompts from games 136, 141, 146, 151,\n",
      "and 156 out of the 156 games available on goobix.com . Our\n",
      "testing focuses on a set of 20 games, specifically games 1, 6,\n",
      ". . ., 91, and 96.\n",
      "Baselines. Mirroring our approach for the game of 24, we\n",
      "benchmark our method against established techniques: stan-\n",
      "dard prompting, CoT, and ToT. For standard prompting, we\n",
      "provide both the crosswords and their respective solutions\n",
      "as in-context examples. CoT augments this by prompting\n",
      "the retrieval of words for each of the ten cluesequally split\n",
      "between horizontal and vertical orientations. We directly ex-\n",
      "tract the success rates of ToT from their original publication\n",
      "for comparison.\n",
      "AoT Setup. We divide the process into two steps, each in-\n",
      "volving a query. Initially, we task the LLM with suggesting\n",
      "five potential words for each row and column. We then pin-\n",
      "point the starting word candidates that have the highest com-\n",
      "patibility with other words within the crossword framework.\n",
      "This preliminary phase mirrors a warm-up sequence in al-\n",
      "gorithm initialization. In the subsequent step, we exclusively\n",
      "leverage the LLMs algorithmic reasoning prowess, starting\n",
      "with the pre-selected word. The method involves cyclically\n",
      "choosing a likely option (specifically, a row or column) for\n",
      "insertion, generating candidate words, and assessing their\n",
      "compatibility with the words already on the board. If no\n",
      "match is found, the process shifts focus to another promising\n",
      "candidate. Otherwise, the word is added to the crossword,\n",
      "and the search continues. The cycle concludes either when\n",
      "the board is fully populated or no more suitable words can be\n",
      "found, which may be due to either incorrect existing words\n",
      "or the absence of matching words. Notably, this entire pro-\n",
      "cess unfolds within a single generation window. The algo-\n",
      "rithmic examples in our prompt (detailed in the Appendix)include three that achieve game completion and two that pre-\n",
      "dominantly populate the crossword, filling 8 or 9 slots.\n",
      "Results. Table 3 underscores AoTs proficiency in the\n",
      "mini crosswords task, showcasing a word success ratea\n",
      "measure used in existing studies to represent the percent-\n",
      "age of words correctly completed out of the totalthat sur-\n",
      "passes earlier methods reliant on various prompting tech-\n",
      "niques. However, it trails behind ToT. An important observa-\n",
      "tion is the sheer volume of queries ToT employs, exceeding\n",
      "AoTs by over a factor of 100. One factor hindering AoT\n",
      "from surpassing ToT is that the backtracking capability in-\n",
      "herent in the algorithmic example isnt fully activated. Fully\n",
      "unlocking this capability would lead to a significant elonga-\n",
      "tion in the generation phase. In contrast, ToT has the advan-\n",
      "tage of leveraging external memory for its backtracking.\n",
      "Method Word Success Avg. Queries\n",
      "Standard Prompting 14% 1\n",
      "CoT 15.6% 1\n",
      "ToT 60% >200\n",
      "AoT (ours) 52% 2\n",
      "Table 3: 55mini crosswords word: word success rates and\n",
      "the average number of LLM queries for each example.\n",
      "Error Analysis. To understand the prevalent mistakes\n",
      "made by AoT, weve categorized the errors into four dis-\n",
      "tinct categories. In our analysis for each game, we focus on\n",
      "the initial error the LLM produces while charting its rea-\n",
      "soning path, given that an early error typically cascades into\n",
      "subsequent failures. 1)No preselections: LLM fails to gen-\n",
      "erate compatible words essential for the warm-start phase.\n",
      "Given a correctly preselected word, the second phase for re-\n",
      "cursive reasoning can exhibit errors including: 2)Expres-\n",
      "sion misstep: The LLM mistakenly believes it has exhausted\n",
      "all choices and jumps to an answer prematurely. 3)Incor-\n",
      "rect pattern extraction: The LLM wrongly extracts a pattern\n",
      "based on the current board layout. 4)Erroneous word place-\n",
      "ment: Despite recognizing the correct pattern, the LLM se-\n",
      "lects a mismatched word or misses better-fitting alternatives.\n",
      "Navigating the crossword complexity arises from outdated\n",
      "terms, esoteric references, and typographical mishaps. Pre-\n",
      "dominantly, the errors observed are due to misguided word\n",
      "placements followed by pattern misinterpretations. Also, the\n",
      "LLM seems challenged in aligning letters at precise indices\n",
      "to create word structures an obstracle circumvented by an\n",
      "external mechanism in the ToT framework.\n",
      "Discussion\n",
      "In this section, we delve into crucial aspects to consider\n",
      "when crafting prompts for AoT, using the game of 24 as our\n",
      "primary case study.\n",
      "Can AoT surpass the DFS its patterned after? A core\n",
      "query of ours is to ascertain if the LLM has the capability\n",
      "to not only mirror but also outdo the efficiency of the al-\n",
      "gorithm introduced in-context. As evidenced in Fig. 5, AoT\n",
      "Error Type Error\n",
      "No preselections 15.8%\n",
      "Expression misstep 5.3%\n",
      "Incorrect pattern extraction 26.3%\n",
      "Erroneous word placement 52.6%\n",
      "Table 4: Breakdown of errors in 55mini crosswords with\n",
      "AoT. Numbers indicate the relative percentage of each error\n",
      "type among all errors.\n",
      "systematically navigates fewer nodes than its DFS counter-\n",
      "part. While DFS employs a uniform strategy when choosing\n",
      "the subsequent subtree to investigate, AoTs LLM integrates\n",
      "its inherent heuristic. This amplification over the base algo-\n",
      "rithm exemplifies the advantages of LLMs recursive reason-\n",
      "ing capability.\n",
      "0 200 400 600 800 1000\n",
      "# of Visited Nodes048121620# of Games\n",
      "DFS\n",
      "AoT\n",
      "Figure 5: Histogram showing the number of visited nodes\n",
      "for AoT and DFS in the Game of 24.\n",
      "How does algorithm selection influence AoTs efficacy?\n",
      "To explore the impact of algorithm choice on AoTs per-\n",
      "formance, we implemented both BFS and random search\n",
      "within the AoT framework. Our findings, presented in Ta-\n",
      "ble 5, reveal that all three AoT variations outperform the\n",
      "single-query CoT. This outcome was anticipated as AoT, ir-\n",
      "respective of the algorithm, undertakes a search and revis-\n",
      "its potential mistakeseither by random retry in the ran-\n",
      "dom search variant or through backtracking in the DFS and\n",
      "BFS configurations. Notably, the structured search versions,\n",
      "AoT (DFS) and AoT (BFS), displayed better efficiency than\n",
      "AoT (Random), underscoring the advantage of algorithmic\n",
      "insights in solution discovery. However, AoT (BFS) lagged\n",
      "behind AoT (DFS). Closer inspection of errors made by AoT\n",
      "(BFS) revealed the LLM faced greater challenges in identi-\n",
      "fying optimal operations than its DFS counterpart.\n",
      "How does the search step count within the algorithmic\n",
      "example modulate AoTs behavior? We begin with the\n",
      "standard AoT prompt and modify the subtree explorations.\n",
      "In AoT (Short), each in-context example uses one or two\n",
      "steps to reach a solution, while AoT (Long) incorporates\n",
      "three to five extra subtree explorations. The impact on total\n",
      "search steps is illustrated in Fig. 6. Our observations high-\n",
      "light longer generations for AoT (Long) and shorter onesMethod Success Avg. Queries\n",
      "CoT 4% 1\n",
      "CoT-SC (k=100) 9% 100\n",
      "ToT 69% 109 .1\n",
      "AoT (DFS) 71% 1\n",
      "AoT (BFS) 48% 1\n",
      "AoT (Random) 20% 1\n",
      "Table 5: Comparative success rates and average LLM query\n",
      "counts for AoT variations templated by distinct algorithms.\n",
      "for AoT (Short) relative to the original AoT. This suggests\n",
      "that the search step count introduces an implicit bias on the\n",
      "LLMs search velocity. Notably, even when navigating in-\n",
      "correct steps, its essential to emphasize the exploration of\n",
      "promising directions.\n",
      "0 50 100 150 200 250 300 350 400\n",
      "# of Visited Nodes020406080100# of Games\n",
      "AoT (Short)\n",
      "AoT\n",
      "AoT (Long)\n",
      "Figure 6: Comparison of AoT with shorter and longer in-\n",
      "context examples prompted AoT versions: cumulative num-\n",
      "ber of games for the number of visited nodes.\n",
      "Limitations. While AoT substantially cuts down on the\n",
      "number of queries relative to ToT, its resource demands ex-\n",
      "ceed those of standard prompting and CoT, a consequence\n",
      "of its extensive exploration of ideas via token generation.\n",
      "Crafting token-efficient algorithmic examples is one avenue,\n",
      "but theres also potential in judiciously tapping into or un-\n",
      "locking the LLMs tunnel-vision. Our research primarily\n",
      "spotlighted certain algorithms, with a keen focus on tree-\n",
      "search tasks. Its pertinent to highlight that we conducted our\n",
      "tests exclusively with GPT-4. Though more costly than other\n",
      "LLMs, GPT-4s advanced capabilities appear pivotal for\n",
      "AoTs optimal functioning; models of lesser caliber might\n",
      "not yield comparable performance boosts from AoT.\n",
      "Conclusion\n",
      "This paper presents the Algorithm of Thoughts , a pioneer-\n",
      "ing prompting strategy to navigate reasoning pathways in\n",
      "LLMs using minimal queries. Our findings reveal that this\n",
      "method not only substantially surpasses prior single-query\n",
      "techniques but also rivals external tree-search implementa-\n",
      "tions. Such an approach augments the potential to stream-\n",
      "line idea discovery in LLMs, balancing both cost and com-\n",
      "putational demands. Future work includes designing token-\n",
      "efficient algorithmic examples, developing adaptive mecha-\n",
      "nisms for tunnel-vision activation to expedite the search,\n",
      "and deepening the understanding of this fresh mode of in-\n",
      "context learning from theoretical angles.\n",
      "References\n",
      "Aminabadi, R. Y .; Rajbhandari, S.; Awan, A. A.; Li, C.; Li,\n",
      "D.; Zheng, E.; Ruwase, O.; Smith, S.; Zhang, M.; Rasley, J.;\n",
      "et al. 2022. DeepSpeed-inference: enabling efficient infer-\n",
      "ence of transformer models at unprecedented scale. In SC22:\n",
      "International Conference for High Performance Computing,\n",
      "Networking, Storage and Analysis , 115. IEEE.\n",
      "Austin, J.; Odena, A.; Nye, M.; Bosma, M.; Michalewski,\n",
      "H.; Dohan, D.; Jiang, E.; Cai, C.; Terry, M.; Le, Q.; et al.\n",
      "2021. Program synthesis with large language models. arXiv\n",
      "preprint arXiv:2108.07732 .\n",
      "Baddeley, A. 2003. Working memory: looking back and\n",
      "looking forward. Nature reviews neuroscience , 4(10): 829\n",
      "839.\n",
      "Bai, Y .; Kadavath, S.; Kundu, S.; Askell, A.; Kernion, J.;\n",
      "Jones, A.; Chen, A.; Goldie, A.; Mirhoseini, A.; McKinnon,\n",
      "C.; Chen, C.; Olsson, C.; Olah, C.; Hernandez, D.; Drain,\n",
      "D.; Ganguli, D.; Li, D.; Tran-Johnson, E.; Perez, E.; Kerr, J.;\n",
      "Mueller, J.; Ladish, J.; Landau, J.; Ndousse, K.; Lukosuite,\n",
      "K.; Lovitt, L.; Sellitto, M.; Elhage, N.; Schiefer, N.; Mer-\n",
      "cado, N.; DasSarma, N.; Lasenby, R.; Larson, R.; Ringer,\n",
      "S.; Johnston, S.; Kravec, S.; Showk, S. E.; Fort, S.; Lanham,\n",
      "T.; Telleen-Lawton, T.; Conerly, T.; Henighan, T.; Hume,\n",
      "T.; Bowman, S. R.; Hatfield-Dodds, Z.; Mann, B.; Amodei,\n",
      "D.; Joseph, N.; McCandlish, S.; Brown, T.; and Kaplan, J.\n",
      "2022. Constitutional AI: Harmlessness from AI Feedback.\n",
      "ArXiv:2212.08073 [cs].\n",
      "Banerjee, S.; Bringsjord, S.; Giancola, M.; and Govindara-\n",
      "julu, N. S. 2022. Qualitative Mechanical Problem-Solving\n",
      "by Artificial Agents:: Further Progress, Under Psychometric\n",
      "AI. In The International FLAIRS Conference Proceedings ,\n",
      "volume 35.\n",
      "Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;\n",
      "Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,\n",
      "A.; Agarwal, S.; Herbert-V oss, A.; Krueger, G.; Henighan,\n",
      "T.; Child, R.; Ramesh, A.; Ziegler, D.; Wu, J.; Winter,\n",
      "C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.;\n",
      "Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford,\n",
      "A.; Sutskever, I.; and Amodei, D. 2020. Language Mod-\n",
      "els are Few-Shot Learners. Advances in Neural Information\n",
      "Processing Systems , 33: 18771901.\n",
      "Chen, L.; Zaharia, M.; and Zou, J. 2023. FrugalGPT: How\n",
      "to Use Large Language Models While Reducing Cost and\n",
      "Improving Performance. arXiv preprint arXiv:2305.05176 .\n",
      "Chen, M.; Tworek, J.; Jun, H.; Yuan, Q.; Pinto, H. P. d. O.;\n",
      "Kaplan, J.; Edwards, H.; Burda, Y .; Joseph, N.; Brockman,\n",
      "G.; et al. 2021. Evaluating large language models trained on\n",
      "code. arXiv preprint arXiv:2107.03374 .\n",
      "Chowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra,\n",
      "G.; Roberts, A.; Barham, P.; Chung, H. W.; Sutton, C.;\n",
      "Gehrmann, S.; et al. 2022. Palm: Scaling language modeling\n",
      "with pathways. arXiv preprint arXiv:2204.02311 .Dhar, P. 2020. The carbon impact of artificial intelligence.\n",
      "Nat. Mach. Intell. , 2(8): 423425.\n",
      "Drozdov, A.; Sch arli, N.; Aky urek, E.; Scales, N.; Song, X.;\n",
      "Chen, X.; Bousquet, O.; and Zhou, D. 2022. Compositional\n",
      "Semantic Parsing with Large Language Models.\n",
      "Helie, S.; and Pizlo, Z. 2022. When is psychology research\n",
      "useful in artificial intelligence? A case for reducing compu-\n",
      "tational complexity in problem solving. Topics in Cognitive\n",
      "Science , 14(4): 687701.\n",
      "Holyoak, K. J.; and Morrison, R. G. 2005. The Cambridge\n",
      "handbook of thinking and reasoning . Cambridge University\n",
      "Press.\n",
      "Huang, J.; and Chang, K. C.-C. 2022. Towards reason-\n",
      "ing in large language models: A survey. arXiv preprint\n",
      "arXiv:2212.10403 .\n",
      "Kadavath, S.; Conerly, T.; Askell, A.; Henighan, T.; Drain,\n",
      "D.; Perez, E.; Schiefer, N.; Hatfield-Dodds, Z.; DasSarma,\n",
      "N.; Tran-Johnson, E.; et al. 2022. Language models (mostly)\n",
      "know what they know. arXiv preprint arXiv:2207.05221 .\n",
      "Kahneman, D. 2011. Thinking, fast and slow . macmillan.\n",
      "Kojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y .; and Iwasawa,\n",
      "Y . 2022. Large Language Models are Zero-Shot Reason-\n",
      "ers. Advances in Neural Information Processing Systems ,\n",
      "35: 2219922213.\n",
      "Lanham, T.; Chen, A.; Radhakrishnan, A.; Steiner, B.; Deni-\n",
      "son, C.; Hernandez, D.; Li, D.; Durmus, E.; Hubinger, E.;\n",
      "Kernion, J.; et al. 2023. Measuring Faithfulness in Chain-\n",
      "of-Thought Reasoning. arXiv preprint arXiv:2307.13702 .\n",
      "Liang, P.; Bommasani, R.; Lee, T.; Tsipras, D.; Soylu, D.;\n",
      "Yasunaga, M.; Zhang, Y .; Narayanan, D.; Wu, Y .; Kumar,\n",
      "A.; et al. 2022. Holistic evaluation of language models.\n",
      "arXiv preprint arXiv:2211.09110 .\n",
      "Libby, M. E.; Weiss, J. S.; Bancroft, S.; and Ahearn, W. H.\n",
      "2008. A comparison of most-to-least and least-to-most\n",
      "prompting on the acquisition of solitary play skills. Behav-\n",
      "ior analysis in practice , 1: 3743.\n",
      "Liu, Y .; Han, T.; Ma, S.; Zhang, J.; Yang, Y .; Tian, J.; He, H.;\n",
      "Li, A.; He, M.; Liu, Z.; et al. 2023. Summary of chatgpt/gpt-\n",
      "4 research and perspective towards the future of large lan-\n",
      "guage models. arXiv preprint arXiv:2304.01852 .\n",
      "Long, J. 2023. Large Language Model Guided Tree-of-\n",
      "Thought. arXiv preprint arXiv:2305.08291 .\n",
      "Lyu, Q.; Havaldar, S.; Stein, A.; Zhang, L.; Rao, D.; Wong,\n",
      "E.; Apidianaki, M.; and Callison-Burch, C. 2023. Faithful\n",
      "Chain-of-Thought Reasoning. ArXiv:2301.13379 [cs].\n",
      "Mialon, G.; Dess `, R.; Lomeli, M.; Nalmpantis, C.; Pa-\n",
      "sunuru, R.; Raileanu, R.; Rozi `ere, B.; Schick, T.; Dwivedi-\n",
      "Yu, J.; Celikyilmaz, A.; et al. 2023. Augmented language\n",
      "models: a survey. arXiv preprint arXiv:2302.07842 .\n",
      "Monsell, S. 2003. Task switching. Trends in cognitive sci-\n",
      "ences , 7(3): 134140.\n",
      "Ouyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright, C.;\n",
      "Mishkin, P.; Zhang, C.; Agarwal, S.; Slama, K.; Ray, A.;\n",
      "et al. 2022. Training language models to follow instructions\n",
      "with human feedback. Advances in Neural Information Pro-\n",
      "cessing Systems , 35: 2773027744.\n",
      "Robinson, J.; and Wingate, D. 2022. Leveraging Large Lan-\n",
      "guage Models for Multiple Choice Question Answering.\n",
      "Shao, Z.; Gong, Y .; Shen, Y .; Huang, M.; Duan, N.; and\n",
      "Chen, W. 2023. Synthetic Prompting: Generating Chain-\n",
      "of-Thought Demonstrations for Large Language Models.\n",
      "Sloman, S. A. 1996. The empirical case for two systems of\n",
      "reasoning. Psychological bulletin , 119(1): 3.\n",
      "Srivastava, A.; Rastogi, A.; Rao, A.; Shoeb, A. A. M.; Abid,\n",
      "A.; Fisch, A.; Brown, A. R.; Santoro, A.; Gupta, A.; Garriga-\n",
      "Alonso, A.; et al. 2022. Beyond the imitation game: Quanti-\n",
      "fying and extrapolating the capabilities of language models.\n",
      "arXiv preprint arXiv:2206.04615 .\n",
      "Suzgun, M.; Scales, N.; Sch arli, N.; Gehrmann, S.; Tay,\n",
      "Y .; Chung, H. W.; Chowdhery, A.; Le, Q. V .; Chi, E. H.;\n",
      "Zhou, D.; and Wei, J. 2022. Challenging BIG-Bench\n",
      "Tasks and Whether Chain-of-Thought Can Solve Them.\n",
      "ArXiv:2210.09261 [cs].\n",
      "Thoppilan, R.; De Freitas, D.; Hall, J.; Shazeer, N.; Kul-\n",
      "shreshtha, A.; Cheng, H.-T.; Jin, A.; Bos, T.; Baker, L.; Du,\n",
      "Y .; et al. 2022. Lamda: Language models for dialog appli-\n",
      "cations. arXiv preprint arXiv:2201.08239 .\n",
      "Turpin, M.; Michael, J.; Perez, E.; and Bowman, S. R. 2023.\n",
      "Language Models Dont Always Say What They Think: Un-\n",
      "faithful Explanations in Chain-of-Thought Prompting. arXiv\n",
      "preprint arXiv:2305.04388 .\n",
      "Wang, X.; Wei, J.; Schuurmans, D.; Le, Q. V .; Chi, E. H.;\n",
      "Narang, S.; Chowdhery, A.; and Zhou, D. 2022. Self-\n",
      "Consistency Improves Chain of Thought Reasoning in Lan-\n",
      "guage Models.\n",
      "Wei, J.; Tay, Y .; Bommasani, R.; Raffel, C.; Zoph, B.;\n",
      "Borgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler,\n",
      "D.; Chi, E. H.; Hashimoto, T.; Vinyals, O.; Liang, P.; Dean,\n",
      "J.; and Fedus, W. 2022a. Emergent Abilities of Large Lan-\n",
      "guage Models. ArXiv:2206.07682 [cs].\n",
      "Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Ichter, B.;\n",
      "Xia, F.; Chi, E.; Le, Q. V .; and Zhou, D. 2022b. Chain-\n",
      "of-Thought Prompting Elicits Reasoning in Large Language\n",
      "Models. Advances in Neural Information Processing Sys-\n",
      "tems, 35: 2482424837.\n",
      "Wu, C.-J.; Raghavendra, R.; Gupta, U.; Acun, B.; Ardalani,\n",
      "N.; Maeng, K.; Chang, G.; Aga, F.; Huang, J.; Bai, C.; et al.\n",
      "2022. Sustainable ai: Environmental implications, chal-\n",
      "lenges and opportunities. Proceedings of Machine Learning\n",
      "and Systems , 4: 795813.\n",
      "Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.;\n",
      "Cao, Y .; and Narasimhan, K. 2023. Tree of Thoughts:\n",
      "Deliberate Problem Solving with Large Language Models.\n",
      "ArXiv:2305.10601 [cs].\n",
      "Zelikman, E.; Wu, Y .; Mu, J.; and Goodman, N. 2022. Star:\n",
      "Bootstrapping reasoning with reasoning. Advances in Neu-\n",
      "ral Information Processing Systems , 35: 1547615488.\n",
      "Zhang, Z.; Zhang, A.; Li, M.; and Smola, A. 2022. Auto-\n",
      "matic Chain of Thought Prompting in Large Language Mod-\n",
      "els.\n",
      "Zhou, D.; Sch arli, N.; Hou, L.; Wei, J.; Scales, N.; Wang,\n",
      "X.; Schuurmans, D.; Cui, C.; Bousquet, O.; Le, Q. V .; andChi, E. H. 2022. Least-to-Most Prompting Enables Complex\n",
      "Reasoning in Large Language Models.\n",
      "Game of 24 - Additional Details\n",
      "In order to avoid confusion in our analysis of AoT in the game of 24, we give additional details in terms of terminologies we\n",
      "use as well as their direct implications in the performance figures. An Illustration of these are given in Fig. 7.\n",
      "4 \n",
      "- \n",
      "4 \n",
      "= \n",
      "8\n",
      "(left: \n",
      "8, \n",
      "6, \n",
      "0)\n",
      "4 \n",
      "+ \n",
      "2 \n",
      "= \n",
      "6\n",
      "(left: \n",
      "6, \n",
      "4)\n",
      "4 \n",
      "/ \n",
      "4 \n",
      "= \n",
      "1\n",
      "(left: \n",
      "2, \n",
      "1)\n",
      "6 \n",
      "* \n",
      "4 \n",
      "= \n",
      "24\n",
      "(left: \n",
      "24)\n",
      "6 \n",
      "+ \n",
      "4 \n",
      "= \n",
      "10\n",
      "(left: \n",
      "10)\n",
      "...\n",
      "Input: \n",
      "8 \n",
      "6 \n",
      "4 \n",
      "4\n",
      "First \n",
      "Operations\n",
      "Second \n",
      "Operations\n",
      "Third \n",
      "Operations\n",
      "Visited \n",
      "Nodes\n",
      "8 \n",
      "- \n",
      "6 \n",
      "= \n",
      "2\n",
      "(left: \n",
      "4, \n",
      "4, \n",
      "2)\n",
      "...\n",
      "Subtree \n",
      "Exploration\n",
      "Figure 7: An illustration of terminologies we use for the game of 24. The yellow nodes represent the first operations and the\n",
      "states they lead to; the green node represents the node where we find the solution; all other nodes are represented by pink.\n",
      "First operations / First iterations. This represents the scenario that after we choose the first two number in the game of 24,\n",
      "the case of either adding, subtracting, multiplying or dividing them.\n",
      "Subtree Exploration. This denotes searching all or most of the nodes coming from the same state, typically states with less\n",
      "than four numbers left.\n",
      "Number of nodes visited. This is the number of states that the method has been on the game of 24. Each state is the set of\n",
      "number we are left with, after our operations in the numbers. For example, after the first operation we might be left with the\n",
      "numbers  831. This set of numbers represent a state, as well as the state of  83 that we will be left with after another operation\n",
      "of 81 = 8 .\n",
      "Creative Writing\n",
      "We use the creative writing task, also used by (Yao et al. 2023), where the LLM is provided with four arbitrary sentences.\n",
      "The objective is to craft a cohesive narrative divided into four paragraphs, with each paragraph culminating in one of the given\n",
      "sentences. This exercise not only fosters creativity but also emphasizes strategic deliberation.\n",
      "Task Setup\n",
      "Sentences are randomly sourced from randomwordgenerator.com , resulting in 100 distinct sets of inputs. Given the absence of\n",
      "predetermined correct answers, the primary focus lies in evaluating the coherence of the responses. We have noted that GPT-4\n",
      "consistently aligns with these input guidelines. Evaluation is centered around assessing passage coherence using a GPT-4 zero-\n",
      "shot prompt, where each output is rated on a scale of 1 to 10. Each task response undergoes five such evaluations, with their\n",
      "scores being averaged subsequently.\n",
      "Baselines\n",
      "For this task, both standard and CoT prompts are employed without preliminary training. While the standard prompt directly\n",
      "guides the LLM to fashion a cohesive narrative based on stipulated parameters, the CoT prompt obliges the model to initially\n",
      "outline a succinct plan prior to drafting the narrative, serving as an intermediate cognitive bridge. For each task iteration,\n",
      "ten samples are generated using both the standard and CoT methods. Results of the ToT approach are presented without\n",
      "modification.\n",
      "AoT Setup\n",
      "Mirroring ToTs methodology, the task is tackled in a zero-shot setting. Our prompt instructs the model to first formulate five\n",
      "distinct plans. Subsequent to this, the model selects the most promising among them to shape a narrative and then refines it for\n",
      "optimal coherence. The exact prompts used for this zero-shot approach will be provided in the subsequent section.\n",
      "Results\n",
      "As depicted in Fig. 8, AoT outpaces other singular query prompting techniques such as standard prompting and CoT in terms\n",
      "of performance. It also exhibits a marked improvement over ToT, although the difference is not statistically significant. Com-\n",
      "prehensive scores, along with the average query count needed for each method, are consolidated in Table 6. Notably, AoT\n",
      "necessitates fewer queries compared to ToT.\n",
      "Standard CoT T oT AoT0246810\n",
      "Figure 8: Comparison of the standard prompting, CoT, ToT and AoT on the creative writing task.\n",
      "Method Score Avg. Queries\n",
      "Standard Prompting 6.19 1\n",
      "CoT 6.93 1\n",
      "ToT 7.56 20\n",
      "AoT 7.58 1\n",
      "Table 6: Performance of the methods determined by GPT-4.\n",
      "CoT vs. Single Iteration AoT in the Game of 24\n",
      "To demonstrate that the tree search mechanism is fundamentally distinct from the CoT prompting, even in scenarios where\n",
      "AoTs in-context examples include only a single initial operation in the game of 24, we draw a comparison between AoT\n",
      "(Short) and CoT. In this setup, AoT (Short) determines the first operation and subsequently conducts a tree search on the\n",
      "remaining three numbers. Interestingly, AoT (Short) achieves a success rate of 48%, while CoT lags significantly, securing\n",
      "only 4%. These results underscore the notion that even a rudimentary search mechanism can lead to significant performance\n",
      "enhancements.\n",
      "Detailed Analysis on the Effect of the Length of the Prompts\n",
      "In this section, we delve deeper into Fig. 6 by presenting histograms for the successful, unsuccessful, and total games of 24,\n",
      "considering the number of initial steps in methods AoT (Short), AoT, and AoT (Long). These are displayed in Figs. 9-11.\n",
      "From these figures, it becomes evident that the length of the prompts, measured by the number of initial steps included in\n",
      "in-context examples, correlates with the length of their solutions to test examples. This trend is consistent across all three cases,\n",
      "suggesting that AoTs strategy in determining the number of initial steps is influenced by its in-context examples.\n",
      "Interestingly, when AoT is provided a well-balanced set of initial steps that emphasize the most promising operations, it\n",
      "excels in solving the majority of games in earlier iterations. This indicates AoTs capacity to prioritize swift problem-solving\n",
      "without sacrificing performance. This tendency is also observed in AoT (Long), albeit with a somewhat reduced success rate,\n",
      "as illustrated in Fig. 9.\n",
      "0 2 4 6 8 10 1202040\n",
      "0 2 4 6 8 10 1202040# of Successful Games\n",
      "0 2 4 6 8 10 12\n",
      "# of First Steps02040\n",
      "AoT (Short)\n",
      "AoT\n",
      "AoT (Long)Figure 9: Histogram of the number of successful games with respect to the number of first steps for AoT (Short), AoT and AoT\n",
      "(Long).\n",
      "0 2 4 6 8 10 1202040\n",
      "0 2 4 6 8 10 1202040# of Unsuccessful Games\n",
      "0 2 4 6 8 10 12\n",
      "# of First Steps02040AoT (Short)\n",
      "AoT\n",
      "AoT (Long)\n",
      "Figure 10: Histogram of the number of unsuccessful games with respect to the number of first steps for AoT (Short), AoT and\n",
      "AoT (Long).\n",
      "Prompts\n",
      "Game of 24\n",
      "Below, we represent the specific prompts employed for the various methods detailed in the experiments section. Its important\n",
      "to note that the terms System,User, and Assistant are utilized to denote the roles within the OpenAI API when operating\n",
      "in chat completion mode. The line breaks serve to show the transitions between the user and assistant interactions within the\n",
      "API.\n",
      "AoT (DFS)\n",
      "System:\n",
      "0 2 4 6 8 10 12050100\n",
      "0 2 4 6 8 10 12050100# of All Games\n",
      "0 2 4 6 8 10 12\n",
      "# of First Steps050100\n",
      "AoT (Short)\n",
      "AoT\n",
      "AoT (Long)Figure 11: Histogram of the number of all games with respect to the number of first steps for AoT (Short), AoT and AoT\n",
      "(Long).\n",
      "Use numbers and basic arithmetic operations (+ - */) to obtain 24. When\n",
      "considering the next steps, do not choose operations that will result in a\n",
      "negative or fractional number. In order to help with the calculations, the\n",
      "numbers in the parenthesis represent the numbers that are left after the\n",
      "operations and they are in descending order.\n",
      "Another thing we do is when there are only two numbers left in the parenthesis, we\n",
      "check whether we can arrive at 24 only by using basic arithmetic operations\n",
      "(+ - */). Some examples regarding this idea:\n",
      "(21 2) no\n",
      "since 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\n",
      "to 24.\n",
      "(30 6) 30 - 6 = 24 yes\n",
      "(8 3) 8 *3 = 24 yes\n",
      "(12 8) no\n",
      "(48 2) 48 / 2 = 24 yes\n",
      "Most importantly, do not give up, all the numbers that will be given has indeed a\n",
      "solution.\n",
      "\n",
      "User:\n",
      "14 8 8 2\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 + 2: (14, 10, 8)\n",
      "- 14 + 10: (24, 8) 32, 16, 192, 3\n",
      "- 14 - 10: (8, 4) 12, 8, 32, 2\n",
      "- 14 *10: (140, 8) 148, 132, 1120, fractional\n",
      "- 14 / 10: (8, 1.4) fractional\n",
      "- 14 + 8: (22, 10) 32, 12, 220, fractional\n",
      "- 14 - 8: (10, 6) 16, 4, 60, fractional\n",
      "- 14 *8: (112, 10) 122, 102, 1120, fractional\n",
      "- 14 / 8: fractional\n",
      "- 10 + 8: (18, 14) 32, 4, 252, fractional\n",
      "- 10 - 8: (14, 2) 16, 12, 28, 7\n",
      "- 10 *8: (80, 14) 94, 66, big, fractional\n",
      "- 10 / 8: fractional\n",
      "Trying another promising first operation:\n",
      "2. 8 / 2: (14, 8, 4)\n",
      "- 14 + 8: (22, 4) 26, 18, 88, fractional\n",
      "- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 2 = 4\n",
      "Step 2:\n",
      "14 - 8 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\n",
      "answer: (14 - 8) *(8 / 2) = 24.\n",
      "\n",
      "User:\n",
      "9 5 5 5\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 9 - 5: (5, 5, 4)\n",
      "- 5 + 5: (10, 4) 14, 6, 40, fractional\n",
      "- 5 - 5: (4, 0) 4, 4, 0, undefined\n",
      "- 5 *5: (25, 4) 29, 21, 100, fractional\n",
      "- 5 / 5: (4, 1) 5, 3, 4, 4\n",
      "- 5 + 4: (9, 5) 14, 4, 45, fractional\n",
      "- 5 - 4: (5, 1) 6, 4, 5, 0.2\n",
      "- 5 *4: (20, 5) 25, 15, 100, fractional\n",
      "- 5 / 4: fractional\n",
      "Trying another promising first operation:\n",
      "2. 5 + 5: (10, 9, 5)\n",
      "- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "5 + 5 = 10\n",
      "Step 2:\n",
      "10 + 9 = 19\n",
      "Step 3:\n",
      "19 + 5 = 24\n",
      "Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\n",
      "answer: ((5 + 5) + 9) + 5 = 24.\n",
      "\n",
      "User:\n",
      "8 6 4 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 - 6: (4, 4, 2)\n",
      "- 4 + 4: (8, 2) 10, 6, 16, 4\n",
      "- 4 - 4: (2, 0) 2, 2, 0, undefined\n",
      "- 4 *4: (16, 2) 18, 14, 32, 8\n",
      "- 4 / 4: (2, 1) 3, 1, 2, 2\n",
      "- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 - 6 = 2\n",
      "Step 2:\n",
      "4 + 2 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\n",
      "answer: (4 + (8 - 6)) *4 = 24.\n",
      "\n",
      "User:\n",
      "13 10 9 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 13 - 4: (10, 9, 9)\n",
      "- 10 + 9: (19, 9) 28, 10, 171, fractional\n",
      "- 10 - 9: (9, 1) 10, 8, 9, 9\n",
      "- 10 *9: (90, 9) 99, 81, 810, fractional\n",
      "- 10 / 9: fractional\n",
      "- 9 + 9: (18, 10) 28, 8, 180, fractional\n",
      "- 9 - 9: (10, 0) 10, 10, 0, undefined\n",
      "- 9 *9: (81, 10) 91, 71, 810, fractional\n",
      "- 9 / 9: (10, 1) 11, 9, 10, 10\n",
      "Trying another promising first operation:\n",
      "2. 10 - 4: (13, 9, 6)\n",
      "- 13 + 9: (22, 6) 28, 16, 132, fractional\n",
      "- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "10 - 4 = 6\n",
      "Step 2:\n",
      "13 - 9 = 4\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\n",
      "answer: (10 - 4) *(13 - 9) = 24.\n",
      "\n",
      "User:\n",
      "8 8 5 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 - 4: (8, 5, 4)\n",
      "- 8 + 5: (13, 4) 17, 9, 52, fractional\n",
      "- 8 - 5: (4, 3) 7, 1, 12, fractional\n",
      "- 8 *5: (40, 4) 44, 36, 160, fractional\n",
      "- 8 / 5: fractional\n",
      "- 8 + 4: (12, 5) 17, 7, 60, fractional\n",
      "- 8 - 4: (5, 4) 9, 1, 20, fractional\n",
      "- 8 *4: (32, 5) 37, 27, 160, fractional\n",
      "- 8 / 4: (5, 2) 7, 3, 10, 2.5\n",
      "- 5 + 4: (9, 8) 17, 1, 72, fractional\n",
      "- 5 - 4: (8, 1) 9, 7, 8, 8\n",
      "- 5 *4: (20, 8) 28, 12, 160, fractional\n",
      "- 5 / 4: fractional\n",
      "Trying another promising first operation:\n",
      "2. 8 / 4: (8, 5, 2)\n",
      "- 8 + 5: (13, 2) 15, 11, 26, fractional\n",
      "- 8 - 5: (3, 2) 5, 1, 6, 1.5\n",
      "- 8 *5: (40, 2) 42, 38, 80, 20\n",
      "- 8 / 5: fractional\n",
      "- 8 + 2: (10, 5) 15, 5, 50, 2\n",
      "- 8 - 2: (6, 5) 11, 1, 30, fractional\n",
      "- 8 *2: (16, 5) 21, 11, 80, fractional\n",
      "- 8 / 2: (5, 4) 9, 1, 20, fractional\n",
      "- 5 + 2: (7, 8) 15, 1, 56, fractional\n",
      "- 5 - 2: (8, 3) 11, 5, 24 = 8 *3 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 4 = 2\n",
      "Step 2:\n",
      "5 - 2 = 3\n",
      "Step 3:\n",
      "8*3 = 24\n",
      "Considering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\n",
      "answer: 8 *(5 - (8 / 4)) = 24.\n",
      "\n",
      "User:\n",
      "11 11 1 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 11 - 1: (11, 10, 1)\n",
      "- 11 + 10: (21, 1) 22, 20, 21, 21\n",
      "- 11 - 10: (1, 1) 2, 0, 1, 1\n",
      "- 11 *10: (110, 1) 111, 109, 110, 110\n",
      "- 11 / 10: fractional\n",
      "- 11 + 1: (12, 10) 22, 2, 120, 1.2\n",
      "- 11 - 1: (10, 10) 20, 0, 100, 1\n",
      "- 11 *1: (11, 10) 21, 1, 110, 1.1\n",
      "- 11 / 1: (11, 10) 21, 1, 110, fractional\n",
      "- 10 + 1: (11, 11) 22, 0, 121, 1\n",
      "- 10 - 1: (11, 9) 20, 2, 99, 1.1\n",
      "- 10 *1: (11, 10) 21, 1, 110, 1.1\n",
      "- 10 / 1: (11, 10) 21, 1, 110, 1.1\n",
      "Trying another promising first operation:\n",
      "2. 11 + 1: (12, 11, 1)\n",
      "- 12 + 11: (23, 1) 24 = 23 + 1 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11 + 1 = 12\n",
      "Step 2:\n",
      "12 + 11 = 23\n",
      "Step 3:\n",
      "23 + 1\n",
      "Considering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\n",
      "answer: ((11 + 1) + 11) + 1 = 24.\n",
      "\n",
      "User:\n",
      "11 7 4 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 7 *4: (28, 11, 1)\n",
      "- 28 + 11: (39, 1) 40, 38, 39, 39\n",
      "- 28 - 11: (17, 1) 18, 16, 17, 17\n",
      "- 28 *11: (308, 1) 309, 307, 308, 308\n",
      "- 28 / 11: fractional\n",
      "- 28 + 1: (29, 11) 40, 18, 319, fractional\n",
      "- 28 - 1: (27, 11) 38, 16, 297, fractional\n",
      "- 28 *1: (28, 11) 39, 17, 308, fractional\n",
      "- 28 / 1: (28, 11) 39, 17, 308, fractional\n",
      "- 11 + 1: (29, 28) 57, 1, 812, fractional\n",
      "- 11 - 1: (28, 10) 38, 18, 280, fractional\n",
      "- 11 *1: (28, 11) 39, 17, 308, fractional\n",
      "- 11 / 1: (28, 11) 39, 17, 308, fractional\n",
      "Trying another promising first operation:\n",
      "2. 7 + 1: (11 8 4)\n",
      "- 11 + 8: (19, 4) 23, 15, 76, fractional\n",
      "- 11 - 8: (4, 3) 7, 1, 12, fractional\n",
      "- 11 *8: (88, 4) 92, 84, 352, fractional\n",
      "- 11 / 8: fractional\n",
      "- 11 + 4: (15, 8) 23, 7, 120, fractional\n",
      "- 11 - 4: (7, 8) 15, -1, 56, fractional\n",
      "- 11 *4: (44, 8) 52, 36, 352, fractional\n",
      "- 11 / 4: fractional\n",
      "- 8 + 4: (12, 11) 23, -1, 132, fractional\n",
      "- 8 - 4: (11, 4) 15, 7, 44, fractional\n",
      "- 8 *4: (32, 11) 43, 21, 352, fractional\n",
      "- 8 / 4: (11, 2) 13, 9, 22, fractional\n",
      "Trying another promising first operation:\n",
      "3. 4 + 1: (11 7 5)\n",
      "- 11 + 7: (18, 5) 23, 13, 90, fractional\n",
      "- 11 - 7: (5, 4) 9, 1, 20, fractional\n",
      "- 11 *7: (77, 5) 82, 72, 385, fractional\n",
      "- 11 / 7: fractional\n",
      "- 11 + 5: (16, 7) 23, 9, 112, fractional\n",
      "- 11 - 5: (7, 6) 13, 1, 42, fractional\n",
      "- 11 *5: (55, 7) 62, 48, 385, fractional\n",
      "- 11 / 5: fractional\n",
      "- 7 + 5: (12, 11) 23, 1, 132, fractional\n",
      "- 7 - 5: (11, 2) 13, 9, 22, fractional\n",
      "- 7 *5: (35, 11) 46, 24 = 35 - 11 -> found it!\n",
      "Step 1:\n",
      "4 + 1 = 5\n",
      "Step 2:\n",
      "7*5 = 35\n",
      "Step 3:\n",
      "35 - 11 = 24\n",
      "Considering these steps: Backtracking the solution:\n",
      "24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\n",
      "answer: (7 *(4 + 1)) - 11 = 24.\n",
      "\n",
      "User:\n",
      "11 5 4 3\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 5 *4: (20, 11, 3)\n",
      "- 20 + 11: (31, 3) 34, 28, 93, fractional\n",
      "- 20 - 11: (9, 3) 12, 6, 27, 3\n",
      "- 20 *11: (220, 3) 223, 217, 660, fractional\n",
      "- 20 / 11: fractional\n",
      "- 20 + 3: (23, 11) 34, 12, 253, fractional\n",
      "- 20 - 3: (17, 11) 28, 6, 187, fractional\n",
      "- 20 *3: (60, 11) 71, 49, 660, fractional\n",
      "- 20 / 3: fractional\n",
      "- 11 + 3: (14, 20) 34, -6, 280, fractional\n",
      "- 11 - 3: (8, 20) 28, -12, 160, fractional\n",
      "- 11 *3: (33, 20) 53, 13, 660, fractional\n",
      "- 11 / 3: fractional\n",
      "Trying another promising first operation:\n",
      "2. 11 - 3: (8, 5, 4)\n",
      "- 8 + 5: (13, 4) 17, 9, 52, fractional\n",
      "- 8 - 5: (4, 3) 7, 1, 12, fractional\n",
      "- 8 *5: (40, 4) 44, 36, 160, fractional\n",
      "- 8 / 5: fractional\n",
      "- 8 + 4: (12, 5) 17, 7, 60, fractional\n",
      "- 8 - 4: (5, 4) 9, 1, 20, fractional\n",
      "- 8 *4: (32, 5) 37, 27, 160, fractional\n",
      "- 8 / 4: (5, 2) 7, 3, 10, 2.5\n",
      "- 5 + 4: (9, 8) 17, 1, 72, fractional\n",
      "- 5 - 4: (8, 1) 9, 7, 8, 8\n",
      "- 5 *4: (20, 8) 28, 12, 160, fractional\n",
      "- 5 / 4: fractional\n",
      "Trying another promising first operation:\n",
      "3. 11 *3: (33, 5, 4)\n",
      "- 33 + 5: (38, 4) 42, 34, 152, fractional\n",
      "- 33 - 5: (28, 4) 32, 24 = 28 - 4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11*3 = 33\n",
      "Step 2:\n",
      "33 - 5 = 28\n",
      "Step 3:\n",
      "28 - 4 = 24\n",
      "Considering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\n",
      "answer: ((11 *3) - 5) - 4 = 24.\n",
      "\n",
      "User:\n",
      "13 12 5 2\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 12 + 2: (14, 13, 5)\n",
      "- 14 + 13: (27, 5) 32, 22, 135, fractional\n",
      "- 14 - 13: (5, 1) 6, 4, 5, 5\n",
      "- 14 *13: (182, 5) 187, 177, 910, fractional\n",
      "- 14 / 13: fractional\n",
      "- 14 + 5: (19, 13) 32, 6, 247, fractional\n",
      "- 14 - 5: (13, 9) 22, 4, 117, fractional\n",
      "- 14 *5: (70, 13) 83, 57, 910, fractional\n",
      "- 14 / 5: fractional\n",
      "- 13 + 5: (18, 14) 32, 4, 252, fractional\n",
      "- 13 - 5: (14, 8) 22, 6, 112, fractional\n",
      "- 13 *5: (65, 14) 79, 51, 910, fractional\n",
      "- 13 / 5: fractional\n",
      "Trying another promising first operation:\n",
      "2. 13 + 5: (18, 12, 2)\n",
      "- 18 + 12: (30, 2) 32, 28, 60, fractional\n",
      "- 18 - 12: (6, 2) 8, 4, 12, 3\n",
      "- 18 *12: (216, 2) 218, 214, 432, fractional\n",
      "- 18 / 12: fractional\n",
      "- 18 + 2: (20, 12) 32, 8, 240, fractional\n",
      "- 18 - 2: (16, 12) 28, 4, 192, fractional\n",
      "- 18 *2: (36, 12) 48, 24 = 36 - 12 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "13 + 5 = 18\n",
      "Step 2:\n",
      "18*2 = 36\n",
      "Step 3:\n",
      "36 - 12 = 24\n",
      "Considering these steps: 24 = 36 - 12 = (18 *2) - 12 = ((13 + 5) *2) - 12 = 24.\n",
      "answer: ((13 + 5) *2) - 12 = 24.\n",
      "\n",
      "User:\n",
      "9 8 2 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 9 - 1: (8, 8, 2)\n",
      "- 8 + 8: (16, 2) 18, 14, 32, 8\n",
      "- 8 - 8: (2, 0) 2, 2, 0, undefined\n",
      "- 8 *8: (64, 2) 66, 62, 128, 32\n",
      "- 8 / 8: (2, 1) 3, 1, 2, 2\n",
      "- 8 + 2: (10, 8) 18, 2, 80, 4\n",
      "- 8 - 2: (6, 8) 14, -2, 48, fractional\n",
      "- 8 *2: (16, 8) 24 = 16 + 8 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "9 - 1 = 8\n",
      "Step 2:\n",
      "8*2 = 16\n",
      "Step 3:\n",
      "16 + 8 = 24\n",
      "Considering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\n",
      "answer: ((9 - 1) *2) + 8 = 24.\n",
      "\n",
      "AoT (Long)\n",
      "System:\n",
      "Use numbers and basic arithmetic operations (+ - */) to obtain 24. When\n",
      "considering the next steps, do not choose operations that will result in a\n",
      "negative or fractional number. In order to help with the calculations, the\n",
      "numbers in the parenthesis represent the numbers that are left after the\n",
      "operations and they are in descending order.\n",
      "Another thing we do is when there are only two numbers left in the parenthesis, we\n",
      "check whether we can arrive at 24 only by using basic arithmetic operations\n",
      "(+ - */). Some examples regarding this idea:\n",
      "(21 2) no\n",
      "since 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\n",
      "to 24.\n",
      "(30 6) 30 - 6 = 24 yes\n",
      "(8 3) 8 *3 = 24 yes\n",
      "(12 8) no\n",
      "(48 2) 48 / 2 = 24 yes\n",
      "Most importantly, do not give up, all the numbers that will be given has indeed a\n",
      "solution.\n",
      "User:\n",
      "14 8 8 2\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 + 2: (14, 10, 8)\n",
      "- 14 + 10: (24, 8) 32, 16, 192, 3\n",
      "- 14 - 10: (8, 4) 12, 8, 32, 2\n",
      "- 14 *10: (140, 8) 148, 132, 1120, fractional\n",
      "- 14 / 10: (8, 1.4) fractional\n",
      "- 14 + 8: (22, 10) 32, 12, 220, fractional\n",
      "- 14 - 8: (10, 6) 16, 4, 60, fractional\n",
      "- 14 *8: (112, 10) 122, 102, 1120, fractional\n",
      "- 14 / 8: fractional\n",
      "- 10 + 8: (18, 14) 32, 4, 252, fractional\n",
      "- 10 - 8: (14, 2) 16, 12, 28, 7\n",
      "- 10 *8: (80, 14) 94, 66, big, fractional\n",
      "- 10 / 8: fractional\n",
      "Trying another promising first operation:\n",
      "2. 14 + 8: (22, 8, 2)\n",
      "- 22 + 8: (30, 2) 32, 28, 60, 15\n",
      "- 22 - 8: (14, 2) 16, 12, 28, 7\n",
      "- 22 *8: (176, 2) 178, 174, 88\n",
      "- 22 / 8: (2.75, 2) fractional\n",
      "- 22 + 2: (24, 8) 32, 16, 192, 3\n",
      "- 22 - 2: (20, 8) 28, 12, 160, fractional\n",
      "- 22 *2: (44, 8) 52, 36, 352, fractional\n",
      "- 22 / 2: (11, 8) 19, 3, 88, fractional\n",
      "- 8 + 2: (22, 10) 32, 12, 220, fractional\n",
      "- 8 - 2: (22, 6) 28, 16, 132, fractional\n",
      "- 8 *2: (22, 16) 38, 6, 352, fractional\n",
      "- 8 / 2: (22, 4) 26, 18, 88, fractional\n",
      "Trying another promising first operation:\n",
      "3. 14 + 2: (16, 8, 8)\n",
      "- 16 + 8: (24, 8) 32, 16, 192, 3\n",
      "- 16 - 8: (8, 8) 16, 0, 64, 1\n",
      "- 16 *8: (128, 8) 136, 120, 1024, 16\n",
      "- 16 / 8: (8, 2) 10, 6, 16, 4\n",
      "- 8 + 8: (16, 16 32, 0, 256, 1\n",
      "- 8 - 8: (16, 0) 16, 16, 0, undefined\n",
      "- 8 *8: (64, 16) 80, 48, 1024, 4\n",
      "- 8 / 8: (16, 1) 17, 15, 16, 16\n",
      "Trying another promising first operation:\n",
      "4. 8 - 2: (14, 8, 6)\n",
      "- 14 + 8: (22, 14) 36, 8, 308, fractional\n",
      "- 14 - 8: (6, 6) 12, 0, 36, 1\n",
      "- 14 *8: (112, 6) 118, 106, 672, fractional\n",
      "- 14 / 8: (6, 1.75) fractional\n",
      "- 14 + 6: (20, 8) 22, 12, 160, fractional\n",
      "- 14 - 6: (8, 8) 16, 0, 64, 1\n",
      "- 14 *6: (84, 8) 92, 76, 672, fractional\n",
      "- 14 / 6: (8, 2.3) fractional\n",
      "- 8 + 6: (14, 14) 28, 0, 196, 1\n",
      "- 8 - 6: (14, 2) 16, 12, 28, 7\n",
      "- 8 *6: (48, 14) 62, 34, 672, fractional\n",
      "- 8 / 6: (14, 1.3) fractional\n",
      "Trying another promising first operation:\n",
      "5. 8 *2: (16, 14, 8)\n",
      "- 16 + 14: (30, 8) 38, 22, 240, fractional\n",
      "- 16 - 14: (8, 2) 10, 6, 16, 4\n",
      "- 16 *14: (224, 8) 232, 216, 1792, 28\n",
      "- 16 / 14: (8, 1.1) fractional\n",
      "- 16 + 8: (24, 14) 38, 10, 336, fractional\n",
      "- 16 - 8: (14, 8) 22, 6, 112, fractional\n",
      "- 16 *8: (128, 14) 142, 112, 1792, fractional\n",
      "- 16 / 8: (14, 2) 16, 12, 28, 7\n",
      "- 14 + 8: (22, 16) 38, 6, 352, fractional\n",
      "- 14 - 8: (16, 6) 22, 10, 96, fractional\n",
      "- 14 *8: (112, 16) 128, 96, 1792, 7\n",
      "- 14 / 8: (16, 1.7) fractional\n",
      "Trying another promising first operation:\n",
      "6. 14 *2: (28, 8, 8)\n",
      "- 28 + 8: (36, 8) 44, 28, 288, fractional\n",
      "- 28 - 8: (20, 8) 28, 12, 160, fractional\n",
      "- 28 *8: (224, 8) 232, 216, 1792, 28\n",
      "- 28 / 8: (8, 3.5) fractional, fractional, 28, fractional\n",
      "- 8 + 8: (16, 16 32, 0, 256, 1\n",
      "- 8 - 8: (16, 0) 16, 16, 0, undefined\n",
      "- 8 *8: (64, 16) 80, 48, 1024, 4\n",
      "- 8 / 8: (16, 1) 17, 15, 16, 16\n",
      "Trying another promising first operation:\n",
      "7. 8 / 2: (14, 8, 4)\n",
      "- 14 + 8: (22, 4) 26, 18, 88, fractional\n",
      "- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 2 = 4\n",
      "Step 2:\n",
      "14 - 8 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\n",
      "answer: (14 - 8) *(8 / 2) = 24.\n",
      "\n",
      "User:\n",
      "9 5 5 5\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 9 - 5: (5, 5, 4)\n",
      "- 5 + 5: (10, 4) 14, 6, 40, fractional\n",
      "- 5 - 5: (4, 0) 4, 4, 0, undefined\n",
      "- 5 *5: (25, 4) 29, 21, 100, fractional\n",
      "- 5 / 5: (4, 1) 5, 3, 4, 4\n",
      "- 5 + 4: (9, 5) 14, 4, 45, fractional\n",
      "- 5 - 4: (5, 1) 6, 4, 5, 0.2\n",
      "- 5 *4: (20, 5) 25, 15, 100, fractional\n",
      "- 5 / 4: fractional\n",
      "Trying another promising first operation:\n",
      "2. 5 *5: (25, 9, 5)\n",
      "- 25 + 9: (34, 5) 39, 29, 170, fractional\n",
      "- 25 - 9: (16, 5) 21, 11, 80, fractional\n",
      "- 25 *9: (225, 5) 230, 220, 1125, 45\n",
      "- 25 / 9: (5, 2.7) fractional\n",
      "- 25 + 5: (30, 9) 39, 21, 270, fractional\n",
      "- 25 - 5: (20, 9) 29, 11, 180, fractional\n",
      "- 25 *5: (75, 9) 84, 66, 675, fractional\n",
      "- 25 / 5: (9, 5) 14, 4, 45, fractional\n",
      "- 9 + 5: (25, 14) 39, 11, 350, fractional\n",
      "- 9 - 5: (25, 4) 29, 21, 100, fractional\n",
      "- 9 *5: (45, 25) 70, 20, 1125, fractional\n",
      "- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\n",
      "Trying another promising first operation:\n",
      "3. 5 - 5: (9, 5, 0)\n",
      "- 9 + 5: (25, 14) 39, 11, 350, fractional\n",
      "- 9 - 5: (25, 4) 29, 21, 100, fractional\n",
      "- 9 *5: (45, 25) 70, 20, 1125, fractional\n",
      "- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\n",
      "- 9 + 0: (9, 5) 14, 4, 45, fractional\n",
      "- 9 - 0: (9, 5) 14, 4, 45, fractional\n",
      "- 9 *0: (5, 0) 5, 5, 0, undefined\n",
      "- 9 / 0: undefined\n",
      "- 5 + 0: (9, 5) 14, 4, 45, fractional\n",
      "- 5 - 0: (9, 5) 14, 4, 45, fractional\n",
      "- 5 *0: (9, 0) 9, 9, 0, undefined\n",
      "- 5 / 0: undefined\n",
      "Trying another promising first operation:\n",
      "4. 5 / 5: (9, 5, 1)\n",
      "- 9 + 5: (25, 14) 39, 11, 350, fractional\n",
      "- 9 - 5: (25, 4) 29, 21, 100, fractional\n",
      "- 9 *5: (45, 25) 70, 20, 1125, fractional\n",
      "- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\n",
      "- 9 + 1: (10, 5) 15, 5, 50, 2\n",
      "- 9 - 1: (8, 5) 13, 3, 40, fractional\n",
      "- 9 *1: (9, 5) 14, 4, 45, fractional\n",
      "- 9 / 1: (9, 5) 14, 4, 45, fractional\n",
      "- 5 + 1: (9, 6) 15, 3, 54, fractional\n",
      "- 5 - 1: (9, 4) 13, 5, 36, fractional\n",
      "- 5 *1: (9, 5) 14, 4, 45, fractional\n",
      "- 5 / 1: (9, 5) 14, 4, 45, fractional\n",
      "Trying another promising first operation:\n",
      "5. 9 *5: (45, 5, 5)\n",
      "- 45 + 5: (50, 5) 55, 45, 250, 10\n",
      "- 45 - 5: (40, 5) 45, 35, 200, 8\n",
      "- 45 *5: (225, 5) 230, 220, 1125, 45\n",
      "- 45 / 5: (9, 5) 14, 4, 45, fractional\n",
      "- 5 + 5: (10, 4) 14, 6, 40, fractional\n",
      "- 5 - 5: (4, 0) 4, 4, 0, undefined\n",
      "- 5 *5: (25, 4) 29, 21, 100, fractional\n",
      "- 5 / 5: (4, 1) 5, 3, 4, 4\n",
      "Trying another promising first operation:\n",
      "6. 5 + 5: (10, 9, 5)\n",
      "- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "5 + 5 = 10\n",
      "Step 2:\n",
      "10 + 9 = 19\n",
      "Step 3:\n",
      "19 + 5 = 24\n",
      "Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\n",
      "answer: ((5 + 5) + 9) + 5 = 24.\n",
      "\n",
      "User:\n",
      "8 6 4 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 *6: (48, 4, 4)\n",
      "- 48 + 4: (52, 4) 56, 48, 208, 13\n",
      "- 48 - 4: (44, 4) 48, 40, 176, 11\n",
      "- 48 *4: (192, 4) 196, 188, 768, 48\n",
      "- 48 / 4: (12, 4) 16, 8, 48, 3\n",
      "- 4 + 4: (48, 8) 56, 40, 384, 6\n",
      "- 4 - 4: (48, 0) 48, 48, 0, undefined\n",
      "- 4 *4: (48, 16) 64, 32, 768, 3\n",
      "- 4 / 4: (48, 1) 49, 47, 48, 48\n",
      "Trying another promising first operation:\n",
      "2. 4 - 4: (8, 6, 0)\n",
      "- 8 + 6: (14, 0) 14, 14, 0, undefined\n",
      "- 8 - 6: (2, 0) 2, 2, 0, undefined\n",
      "- 8 *6: (48, 0) 48, 48, 0, undefined\n",
      "- 8 / 6: (1.3, 0) fractional\n",
      "- 8 + 0: (8, 6) 14, 2, 48, fractional\n",
      "- 8 - 0: (8, 6) 14, 2, 48, fractional\n",
      "- 8 *0: (6, 0) 6, 6, 0, undefined\n",
      "- 8 / 0: undefined\n",
      "- 6 + 0: (8, 6) 14, 2, 48, fractional\n",
      "- 6 - 0: (8, 6) 14, 2, 48, fractional\n",
      "- 6 *0: (8, 0) 8, 8, 0, undefined\n",
      "- 6 / 0: undefined\n",
      "Trying another promising first operation:\n",
      "3. 4 / 4: (8, 6, 1)\n",
      "- 8 + 6: (14, 1) 15, 13, 14, 14\n",
      "- 8 - 6: (2, 1) 3, 1, 2, 2\n",
      "- 8 *6: (48, 1) 49, 47, 48, 48\n",
      "- 8 / 6: (1.3, 1) fractional\n",
      "- 8 + 1: (9, 6) 15, 3, 54, fractional\n",
      "- 8 - 1: (7, 6) 13, 1, 42, fractional\n",
      "- 8 *1: (8, 6) 14, 2, 48, fractional\n",
      "- 8 / 1: (8, 6) 14, 2, 48, fractional\n",
      "- 6 + 1: (8, 7) 15, 1, 56, fractional\n",
      "- 6 - 1: (8, 5) 13, 3, 40, fractional\n",
      "- 6 *1: (8, 6) 14, 2, 48, fractional\n",
      "- 6 / 1: (8, 1) 9, 7, 8, 8\n",
      "Trying another promising first operation:\n",
      "4. 8 - 6: (4, 4, 2)\n",
      "- 4 + 4: (8, 2) 10, 6, 16, 4\n",
      "- 4 - 4: (2, 0) 2, 2, 0, undefined\n",
      "- 4 *4: (16, 2) 18, 14, 32, 8\n",
      "- 4 / 4: (2, 1) 3, 1, 2, 2\n",
      "- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 - 6 = 2\n",
      "Step 2:\n",
      "4 + 2 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\n",
      "answer: (4 + (8 - 6)) *4 = 24.\n",
      "\n",
      "User:\n",
      "13 10 9 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 13 - 4: (10, 9, 9)\n",
      "- 10 + 9: (19, 9) 28, 10, 171, fractional\n",
      "- 10 - 9: (9, 1) 10, 8, 9, 9\n",
      "- 10 *9: (90, 9) 99, 81, 810, fractional\n",
      "- 10 / 9: fractional\n",
      "- 9 + 9: (18, 10) 28, 8, 180, fractional\n",
      "- 9 - 9: (10, 0) 10, 10, 0, undefined\n",
      "- 9 *9: (81, 10) 91, 71, 810, fractional\n",
      "- 9 / 9: (10, 1) 11, 9, 10, 10\n",
      "Trying another promising first operation:\n",
      "2. 13 / 10: (9, 4, 1.3)\n",
      "- 9 + 4: (13, 1.3) fractional, fractional, fractional, 10\n",
      "- 9 - 4: (5, 1.3) fractional\n",
      "- 9 *4: (36, 1.3) fractional\n",
      "- 9 / 4: (2.3, 1.3) fractional, 1, fractional, fractional\n",
      "- 9 + 1.3: (10.3, 4) fractional\n",
      "- 9 - 1.3: (7.7, 4) fractional\n",
      "- 9 *1.3: (11.7, 4) fractional\n",
      "- 9 / 1.3: (6.9, 4) fractional\n",
      "- 4 + 1.3: (9, 5.3) fractional\n",
      "- 4 - 1.3: (9, 2.7) fractional\n",
      "- 4 *1.3: (9, 5.2) fractional\n",
      "- 4 / 1.3: (9, 3.1) fractional\n",
      "Trying another promising first operation:\n",
      "3. 9 / 4: (13, 10, 2.3)\n",
      "- 13 + 10: (23, 2.3) fractional, fractional, fractional, 10\n",
      "- 13 - 10: (3, 2.3) fractional\n",
      "- 13 *10: (130, 2.3) fractional\n",
      "- 13 / 10: (2.3, 1.3) fractional, 1, fractional, fractional\n",
      "- 13 + 2.3: (15.3, 10) fractional, fractional, 153, fractional\n",
      "- 13 - 2.3: (11.7, 10) fractional, fractional, 117, fractional\n",
      "- 13 *2.3: (29.9, 10) fractional, fractional, 299, fractional\n",
      "- 13 / 2.3: (10, 5.6) fractional, fractional, 560, fractional\n",
      "- 10 + 2.3: (13, 12.3) fractional\n",
      "- 10 - 2.3: (13, 7.7) fractional\n",
      "- 10 *2.3: (23, 13) 36, 10, 299, fractional\n",
      "- 10 / 2.3: (13, 4.3) fractional\n",
      "Trying another promising first operation:\n",
      "4. 13 / 4: (10, 9, 3.3)\n",
      "- 10 + 9: (19, 3.3) fractional\n",
      "- 10 - 9: (3.3, 1) fractional\n",
      "- 10 *9: (90, 3.3) fractional\n",
      "- 10 / 9: (3.3, 1.1) fractional, fractional, fractional, 3\n",
      "- 10 + 3.3: (13.3, 9) fractional\n",
      "- 10 - 3.3: (9, 6.7) fractional\n",
      "- 10 *3.3: (33, 9) 42, 24, 297, fractional\n",
      "- 10 / 3.3: (3.1, 9) fractional\n",
      "- 9 + 3.3: (12.3, 10) fractional, fractional, 123, fractional\n",
      "- 9 - 3.3: (10, 5.7) fractional, fractional, 57, fractional\n",
      "- 9 *3.3: (29.7, 10) fractional, fractional, 297, fractional\n",
      "- 9 / 3.3: (10, 2.7) fractional, fractional, 27, fractional\n",
      "Trying another promising first operation:\n",
      "5. 13 / 9: (10, 9, 1.4)\n",
      "- 10 + 9: (19, 1.4) fractional\n",
      "- 10 - 9: (1.4, 1) fractional\n",
      "- 10 *9: (90, 1.4) fractional, fractional, 130, fractional\n",
      "- 10 / 9: (1.1, 1.4) fractional\n",
      "- 10 + 1.4: (11.4, 9) fractional\n",
      "- 10 - 1.4: (9, 8.6) fractional\n",
      "- 10 *1.4: (140, 9) 149, 131, 1260, fractional\n",
      "- 10 / 1.4: (9, 7.1) fractional\n",
      "- 9 + 1.4: (10.4, 10) fractional, fractional, 104, fractional\n",
      "- 9 - 1.4: (10, 7.6) fractional, fractional, 76, fractional\n",
      "- 9 *1.4: (12.6, 10) fractional, fractional, 126, fractional\n",
      "- 9 / 1.4: (10, 6.4) fractional, fractional, 64, fractional\n",
      "Trying another promising first operation:\n",
      "6. 10 - 4: (13, 9, 6)\n",
      "- 13 + 9: (22, 6) 28, 16, 132, fractional\n",
      "- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "10 - 4 = 6\n",
      "Step 2:\n",
      "13 - 9 = 4\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\n",
      "answer: (10 - 4) *(13 - 9) = 24.\n",
      "\n",
      "AoT (Random)\n",
      "System:\n",
      "Use numbers and basic arithmetic operations (+ - */) to obtain 24. Each step, you\n",
      "are only allowed to choose two of the remaining numbers to obtain a new\n",
      "number.\n",
      "\n",
      "User:\n",
      "4 4 6 8.\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "(4 + 4) *6 - 8 = 40.\n",
      "Trying another promising first operation:\n",
      "(8 - 6) *4 + 4 = 12.\n",
      "Trying another promising first operation:\n",
      "(6 - 4) *(4 + 8) = 24.\n",
      "answer: (6 - 4) *(4 + 8) = 24.\n",
      "\n",
      "User:\n",
      "2 9 10 12.\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "((12 - 10) / 2) + 9 = 10.\n",
      "Trying another promising first operation:\n",
      "(10 + 9) + (12 / 2) = 25.\n",
      "Trying another promising first operation:\n",
      "(12 *2)*(10 - 9) = 24.\n",
      "answer: (12 *2)*(10 - 9) = 24.\n",
      "\n",
      "User:\n",
      "4 9 10 13.\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "((13 - 10) / 4) + 9 = 10.\n",
      "Trying another promising first operation:\n",
      "4*(9 - (13 - 10)) = 24.\n",
      "answer: 4 *(9 - (13 - 10)) = 24.\n",
      "\n",
      "User:\n",
      "1 4 8 8.\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "(8 + 1) + 4 *8 + 32.\n",
      "Trying another promising first operation:\n",
      "(1 + 8 / 4) *8 = 24.\n",
      "answer: (1 + 8 / 4) *8 = 24.\n",
      "\n",
      "User:\n",
      "5 5 5 9.\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "((5 + 5) + 5) + 9 = 24.\n",
      "answer: ((5 + 5) + 5) + 9 = 24.\n",
      "\n",
      "AoT (BFS)\n",
      "System:\n",
      "Use numbers and basic arithmetic operations (+ - */) to obtain 24. When\n",
      "considering the next steps, do not choose operations that will result in a\n",
      "negative or fractional number. In order to help with the calculations, the\n",
      "numbers in the parenthesis represent the numbers that are left after the\n",
      "operations and they are in descending order.\n",
      "Another thing we do is when there are only two numbers left in the parenthesis, we\n",
      "check whether we can arrive at 24 only by using basic arithmetic operations\n",
      "(+ - */). Some examples regarding this idea:\n",
      "(21, 2): 23, 19, 42, fractional\n",
      "(30, 6): 36, 24 = 30 - 6 -> found it!\n",
      "(8, 3): 11, 5, 24 = 8 *3 yes\n",
      "(12, 8): 20, 4, 72, fractional\n",
      "In the second steps, when there are three numbers left, we choose the most\n",
      "promising operations so that when we are left with two numbers, we will be\n",
      "able to get to 24.\n",
      "So, when we reach 24 in the third steps, that means we found the solution, we\n",
      "directly backtrack to write the answer.\n",
      "In each step, we want to choose the best operations so that the numbers left, will\n",
      "have a good chance to reach 24.\n",
      "User:\n",
      "14 8 8 2\n",
      "Assistant:\n",
      "Lets consider the most promising possible first steps:\n",
      "1. 8 + 8: (16, 14, 2)\n",
      "2. 14 - 8: (8, 6, 2)\n",
      "3. 14 + 2: (16, 8, 8)\n",
      "4. 8 / 2: (14, 8, 4)\n",
      "Lets consider the most promising second steps:\n",
      "1. (16, 14, 2)\n",
      "- 16 - 14: (2, 2)\n",
      "- 16 / 2: (8, 14)\n",
      "- 14 *2: (28, 16)\n",
      "- 14 / 2: (7, 16)\n",
      "2. (8, 6, 2)\n",
      "- 8 - 6: (2, 2)\n",
      "- 8 / 2: (4, 6)\n",
      "- 6 *2: (12, 8)\n",
      "- 6 / 2: (3, 8)\n",
      "3. (16, 8, 8)\n",
      "- 16 - 8: (8, 8)\n",
      "- 16 / 8: (2, 8)\n",
      "- 8 *8: (64, 16)\n",
      "- 8 / 8: (1, 16)\n",
      "4. (14, 8, 4)\n",
      "- 14 - 8: (6, 4)\n",
      "- 14 / 4: (3.5, 8)\n",
      "- 8 *4: (32, 14)\n",
      "- 8 / 4: (2, 14)\n",
      "Lets consider the most promising third steps:\n",
      "1. 8 + 8 = 16\n",
      "- 16 - 14: (2, 2): 4, 0, 4, 1\n",
      "- 16 / 2: (8, 14): 22, 6, 112, fractional\n",
      "- 14 *2: (28, 16): 44, 12, 448, fractional\n",
      "- 14 / 2: (7, 16): 23, 9, 112, fractional\n",
      "2. 14 - 8 = 6\n",
      "- 8 - 6: (2, 2): 4, 0, 4, 1\n",
      "- 8 / 2: (6, 4): 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "14 - 8 = 6\n",
      "Step 2:\n",
      "8 / 2 = 4\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (14 - 8) *(8 / 2) = 24.\n",
      "answer: (14 - 8) *(8 / 2) = 24.\n",
      "\n",
      "User:\n",
      "9 5 5 5\n",
      "Assistant:\n",
      "Lets consider the most promising first steps:\n",
      "1. 9 - 5: (5, 5, 4)\n",
      "2. 5 + 5: (9, 10, 5)\n",
      "3. 9 + 5: (14, 5, 5)\n",
      "4. 5 - 5: (9, 5, 0)\n",
      "Lets consider the most promising second steps:\n",
      "1. (5, 5, 4)\n",
      "- 5 + 5: (10, 4)\n",
      "- 5 *4: (20, 5)\n",
      "- 5 - 4: (5, 1)\n",
      "- 5 / 4: (5, 1.25)\n",
      "2. (9, 10, 5)\n",
      "- 10 + 9: (19, 5)\n",
      "- 10 - 5: (9, 5)\n",
      "- 10 *5: (50, 9)\n",
      "- 10 / 5: (9, 2)\n",
      "3. (14, 5, 5)\n",
      "- 14 - 5: (9, 5)\n",
      "- 14 + 5: (19, 5)\n",
      "- 5 *5: (25, 14)\n",
      "- 5 / 5: (14, 1)\n",
      "4. (9, 5, 0)\n",
      "- 9 + 5: (14, 0)\n",
      "- 9 - 5: (4, 0)\n",
      "- 5 *0: (9, 0)\n",
      "- 5 / 0: (9, infinity)\n",
      "Lets consider the most promising third steps:\n",
      "1. 9 - 5 = 4\n",
      "- 5 + 5: (10, 4): 14, 6, 40, fractional\n",
      "- 5 *4: (20, 5): 25, 15, 100, 4\n",
      "- 5 - 4: (5, 1): 6, 4, 5, 5\n",
      "- 5 / 4: (5, 1.25): 6.25, 3.75, 6.25, 4\n",
      "2. 5 + 5 = 10\n",
      "- 10 + 9: (19, 5): 24 = 19 + 5 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "5 + 5 = 10\n",
      "Step 2:\n",
      "10 + 9 = 19\n",
      "Step 3:\n",
      "19 + 5 = 24\n",
      "Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\n",
      "answer: ((5 + 5) + 9) + 5 = 24.\n",
      "\n",
      "User:\n",
      "8 6 4 4\n",
      "Assistant:\n",
      "Lets consider the most promising first steps:\n",
      "1. 8 *6: (48, 4, 4)\n",
      "2. 8 + 4: (12, 6, 4)\n",
      "3. 8 - 6: (4, 4, 2)\n",
      "4. 6 - 4: (8, 4, 2)\n",
      "Lets consider the most promising second steps:\n",
      "1. (48, 4, 4)\n",
      "- 4 *4: (48, 16)\n",
      "- 48 / 4: (12, 4)\n",
      "- 4 + 4: (48, 8)\n",
      "- 48 - 4: (44, 4)\n",
      "2. (12, 6, 4)\n",
      "- 12 + 6: (18, 4)\n",
      "- 6 *4: (24, 12)\n",
      "- 6 + 4: (12, 10)\n",
      "- 12 / 4: (6, 3)\n",
      "3. (4, 4, 2)\n",
      "- 4 *4: (16, 2)\n",
      "- 4 + 2: (6, 4)\n",
      "- 4 + 4: (8, 2)\n",
      "- 4 *2: (8, 4)\n",
      "4. (8, 4, 2)\n",
      "- 8 *4: (32, 2)\n",
      "- 4 *2: (8, 8)\n",
      "- 8 + 4: (12, 2)\n",
      "- 8 / 4: (4, 2)\n",
      "Lets consider the most promising third steps:\n",
      "1. 8 *6 = 48\n",
      "- 4 *4: (48, 16): 64, 32, big, 3\n",
      "- 48 / 4: (12, 4): 16, 8, 48, 3\n",
      "- 4 + 4: (48, 8): 56, 40, big, 6\n",
      "- 48 - 4: (44, 4): 48, 40, big, 11\n",
      "2. 8 + 4 = 12\n",
      "- 12 + 6: (18, 4): 22, 14, 72, fractional\n",
      "- 6 *4: (24, 12): 36, 12, 288, 2\n",
      "- 6 + 4: (12, 10): 22, 2, 120, fractional\n",
      "- 12 / 4: (6, 3): 9, 3, 18, 2\n",
      "3. 8 - 6 = 2\n",
      "- 4 *4: (16, 2): 19, 14, 32, 8\n",
      "- 4 + 2: (6, 4): 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 - 6 = 2\n",
      "Step 2:\n",
      "4 + 2 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\n",
      "answer: (4 + (8 - 6)) *4 = 24.\n",
      "\n",
      "User:\n",
      "13 10 9 4\n",
      "Assistant:\n",
      "Lets consider the most promising first steps:\n",
      "1. 13 - 4: (10, 9, 9)\n",
      "2. 10 - 4: (13, 9, 6)\n",
      "3. 13 + 9: (22, 10, 4)\n",
      "4. 10 - 9: (13, 4, 1)\n",
      "Lets consider the most promising second steps:\n",
      "1. (10, 9, 9)\n",
      "- 10 + 9: (19, 9)\n",
      "- 10 - 9: (9, 1)\n",
      "- 9 + 9: (18, 10)\n",
      "- 9 / 9: (9, 1)\n",
      "2. (13, 9, 6)\n",
      "- 9 + 6: (15, 13)\n",
      "- 9 *6: (54, 13)\n",
      "- 13 - 9: (6, 4)\n",
      "- 13 - 6: (9, 7)\n",
      "3. (22, 10, 4)\n",
      "- 22 - 10: (12, 4)\n",
      "- 22 - 4: (18, 10)\n",
      "- 10 *4: (40, 22)\n",
      "- 10 / 4: (22, 5.5)\n",
      "4. (13, 4, 1)\n",
      "- 13 - 4: (9, 1)\n",
      "- 13 *4: (52, 1)\n",
      "- 4 - 1: (13, 3)\n",
      "- 13 - 1: (12, 4)\n",
      "Lets consider the most promising third steps:\n",
      "1. 13 - 4 = 9\n",
      "- 10 + 9: (19, 9): 28, 10, 171, fractional\n",
      "- 10 - 9: (9, 1): 10, 8, 9, 9\n",
      "- 9 + 9: (18, 10): 28, 8, 180, fractional\n",
      "- 9 / 9: (9, 1): 10, 8, 9, 9\n",
      "2. 10 - 4 = 6\n",
      "- 9 + 6: (15, 13): 28, 2, 195, fractional\n",
      "- 9 *6: (54, 13): 67, 41, 702, fractional\n",
      "- 13 - 9: (6, 4): 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "13 - 9 = 4\n",
      "Step 2:\n",
      "10 - 4 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (10 - 4) *(13 - 9) = 24.\n",
      "answer: (10 - 4) *(13 - 9) = 24.\n",
      "\n",
      "User:\n",
      "8 8 5 4\n",
      "Assistant:\n",
      "Lets consider the most promising first steps:\n",
      "1. 5 + 4: (9, 8, 8)\n",
      "2. 8 / 4: (8, 5, 2)\n",
      "3. 8 - 5: (8, 4, 3)\n",
      "4. 8 / 8: (5, 4, 1)\n",
      "Lets consider the most promising second steps:\n",
      "1. (9, 8, 8)\n",
      "- 9 + 8: (17, 8)\n",
      "- 8 + 8: (16, 9)\n",
      "- 9 *8: (72, 8)\n",
      "- 8 / 8: (9, 1)\n",
      "2. (8, 5, 2)\n",
      "- 5 - 2: (8, 3)\n",
      "- 8 - 2: (6, 5)\n",
      "- 8 + 5: (13, 2)\n",
      "- 5 *2: (10, 8)\n",
      "3. (8, 4, 3)\n",
      "- 8 - 4: (4, 3)\n",
      "- 8 - 3: (5, 4)\n",
      "- 4 *3: (12, 8)\n",
      "- 4 + 3: (8, 7)\n",
      "4. (5, 4, 1)\n",
      "- 5 + 4: (9, 1)\n",
      "- 5 - 4: (1, 1)\n",
      "- 4 - 1: (5, 3)\n",
      "- 5 + 1: (6, 4)\n",
      "Lets consider the most promising third steps:\n",
      "1. 5 + 4 = 9\n",
      "- 9 + 8: (17, 8): 25, 9, 136, fractional\n",
      "- 8 + 8: (16, 9): 25, 7, 144, fractional\n",
      "- 9 *8: (72, 8): 80, 64, 576, 9\n",
      "- 8 / 8: (9, 1): 10, 8, 9, 9\n",
      "2. 8 / 4 = 2\n",
      "- 5 - 2: (8, 3): 11, 5, 24 = 8 *3 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 4 = 2\n",
      "Step 2:\n",
      "5 - 2 = 3\n",
      "Step 3:\n",
      "8*3 = 24\n",
      "Considering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\n",
      "answer: 8 *(5 - (8 / 4)) = 24.\n",
      "\n",
      "User:\n",
      "11 11 1 1\n",
      "Assistant:\n",
      "Lets consider the most promising first steps:\n",
      "1. 11 - 1: (11, 10, 1)\n",
      "2. 11 + 1: (12, 11, 1)\n",
      "3. 11 + 11: (22, 1, 1)\n",
      "4. 1 + 1: (11, 11, 2)\n",
      "Lets consider the most promising second steps:\n",
      "1. (11, 10, 1)\n",
      "- 11 + 10: (21, 1)\n",
      "- 10 + 1: (11, 11)\n",
      "- 10 / 1: (11, 10)\n",
      "- 11 / 1: (11, 10)\n",
      "2. (12, 11, 1)\n",
      "- 12 + 11: (23, 1)\n",
      "- 11 + 1: (12, 11)\n",
      "- 11 - 1: (12, 10)\n",
      "- 12 + 1: (13, 11)\n",
      "3. (22, 1, 1)\n",
      "- 22 + 1: (23, 1)\n",
      "- 1 + 1: (22, 2)\n",
      "- 22 / 1: (22, 1)\n",
      "- 1 / 1: (22, 1)\n",
      "4. (11, 11, 2)\n",
      "- 11 + 11: (22, 2)\n",
      "- 11 *2: (22, 11)\n",
      "- 11 + 2: (13, 11)\n",
      "- 2 *11: (22, 11)\n",
      "Lets consider the most promising third steps:\n",
      "1. 11 - 1 = 10\n",
      "- 11 + 10: (21, 1): 22, 20, 21, 20\n",
      "- 10 + 1: (11, 11): 22, 10, 121, 0\n",
      "- 10 / 1: (11, 10): 21, 1, 110, 0\n",
      "- 11 / 1: (11, 10): 21, 1, 110, 0\n",
      "2. 11 + 1 = 12\n",
      "- 12 + 11: (23, 1): 24 = 23 + 1 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11 + 1 = 12\n",
      "Step 2:\n",
      "12 + 11 = 23\n",
      "Step 3:\n",
      "23 + 1 = 24\n",
      "Considering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\n",
      "answer: ((11 + 1) + 11) + 1 = 24.\n",
      "\n",
      "User:\n",
      "11 7 4 1\n",
      "Assistant:\n",
      "Lets consider the most promising first steps:\n",
      "1. 7 *4: (28, 11, 1)\n",
      "2. 7 + 1: (11, 8, 4)\n",
      "3. 4 + 1: (11, 7, 5)\n",
      "4. 11 - 4: (7, 3, 1)\n",
      "Lets consider the most promising second steps:\n",
      "1. (28, 11, 1)\n",
      "- 28 - 11: (17, 1)\n",
      "- 28 - 1: (27, 11)\n",
      "- 11 + 1: (29, 28)\n",
      "- 11 - 1: (28, 10)\n",
      "2. (11, 8, 4)\n",
      "- 11 + 8: (19, 4)\n",
      "- 8 + 4: (12, 11)\n",
      "- 11 - 8: (4, 3)\n",
      "- 8 - 4: (7, 11)\n",
      "3. (11, 7, 5)\n",
      "- 11 - 5: (7, 6)\n",
      "- 7 - 5: (11, 2)\n",
      "- 7 *5: (35, 11)\n",
      "- 11 + 5: (16, 7)\n",
      "4. (7, 3, 1)\n",
      "- 7 - 3: (4, 1)\n",
      "- 7 *3: (21, 1)\n",
      "- 3 + 1: (7, 4)\n",
      "- 7 - 1: (6, 3)\n",
      "Lets consider the most promising third steps:\n",
      "1. 7 *4 = 28\n",
      "- 28 - 11: (17, 1): 18, 16, 17, 17\n",
      "- 28 - 1: (27, 11): 38, 16, 297, 2.45\n",
      "- 11 + 1: (29, 28): 57, 1, 812, 1.03\n",
      "- 11 - 1: (28, 10): 38, 18, 280, 2.8\n",
      "2. 7 + 1 = 8\n",
      "- 11 + 8: (19, 4): 23, 15, 76, 4.75\n",
      "- 8 + 4: (12, 11): 23, 7, 132, 3\n",
      "- 11 - 8: (4, 3): 7, 1, 12, 1.33\n",
      "- 8 - 4: (7, 11): 18, 4, 77, 1.75\n",
      "3. 4 + 1 = 5\n",
      "- 11 - 5: (7, 6): 13, 1, 42, 1.17\n",
      "- 7 - 5: (11, 2): 13, 9, 22, 5.5\n",
      "- 7 *5: (35, 11): 46, 24 = 35 - 11 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "4 + 1 = 5\n",
      "Step 2:\n",
      "7*5 = 35\n",
      "Step 3:\n",
      "35 - 11 = 24\n",
      "Considering these steps: 24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\n",
      "answer: (7 *(4 + 1)) - 11 = 24.\n",
      "\n",
      "User:\n",
      "11 5 4 3\n",
      "Assistant:\n",
      "Lets consider the most promising first steps to reach 24:\n",
      "1. 11 *3: (33, 5, 4)\n",
      "2. 5 + 4: (11, 9, 3)\n",
      "3. 11 - 4: (7, 5, 3)\n",
      "4. 4 + 3: (11, 7, 5)\n",
      "Lets consider the most promising second steps to reach 24:\n",
      "1. (33, 5, 4)\n",
      "- 33 - 5: (28, 4)\n",
      "- 33 - 4: (29, 5)\n",
      "- 5 + 4: (33, 9)\n",
      "- 5 *4: (20, 33)\n",
      "2. (11, 9, 3)\n",
      "- 11 *3: (33, 9)\n",
      "- 11 + 3: (14, 9)\n",
      "- 9 + 3: (12, 11)\n",
      "- 9 / 3: (11, 3)\n",
      "3. (7, 5, 3)\n",
      "- 7 - 3: (4, 5)\n",
      "- 7 + 5: (12, 3)\n",
      "- 5 + 3: (8, 7)\n",
      "- 5 *3: (7, 6)\n",
      "4. (11, 7, 5)\n",
      "- 11 + 7: (18, 5)\n",
      "- 11 - 5: (6, 7)\n",
      "- 7 + 5: (12, 11)\n",
      "- 7 - 5: (2, 11)\n",
      "Lets consider the most promising third steps to reach 24:\n",
      "1. 11 *3 = 33\n",
      "- 33 - 5: (28, 4): 32, 24 = 28 - 4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11*3 = 33\n",
      "Step 2:\n",
      "33 - 5 = 28\n",
      "Step 3:\n",
      "28 - 4 = 24\n",
      "Considering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\n",
      "answer: ((11 *3) - 5) - 4 = 24.\n",
      "\n",
      "User:\n",
      "13 12 5 2\n",
      "Assistant:\n",
      "Lets consider the most promising first steps to reach 24:\n",
      "1. 12 / 2: (13, 6, 5)\n",
      "2. 13 + 5: (18, 12, 2)\n",
      "3. 12 - 5: (13, 7, 2)\n",
      "4. 5 - 2: (13, 12, 3)\n",
      "Lets consider the most promising second steps to reach 24:\n",
      "1. (13, 6, 5)\n",
      "- 13 + 6: (19, 5)\n",
      "- 13 - 5: (8, 6)\n",
      "- 6 *5: (30, 13)\n",
      "- 6 - 5: (13, 1)\n",
      "2. (18, 12, 2)\n",
      "- 18 *2: (36, 12)\n",
      "- 12 / 2: (18, 6)\n",
      "- 18 - 2: (16, 12)\n",
      "- 12 *2: (24, 18)\n",
      "3. (13, 7, 2)\n",
      "- 13 + 7: (20, 2)\n",
      "- 13 - 2: (11, 7)\n",
      "- 7 *2: (14, 13)\n",
      "- 7 - 2: (13, 5)\n",
      "4. (13, 12, 3)\n",
      "- 13 *3: (39, 12)\n",
      "- 13 - 3: (10, 12)\n",
      "- 12 *3: (36, 13)\n",
      "- 12 / 3: (13, 4)\n",
      "Lets consider the most promising third steps to reach 24:\n",
      "1. 12 / 2 = 6\n",
      "- 13 + 6: (19, 5): 24 = 19 + 5 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "12 / 2 = 6\n",
      "Step 2:\n",
      "13 + 6 = 19\n",
      "Step 3:\n",
      "19 + 5 = 24\n",
      "Considering these steps: 24 = 19 + 5 = (13 + 6) + 5 = (13 + (12 / 2)) + 5 = 24.\n",
      "answer: (13 + (12 / 2)) + 5 = 24.\n",
      "\n",
      "User:\n",
      "9 8 2 1\n",
      "Assistant:\n",
      "Lets consider the most promising first steps to reach 24:\n",
      "1. 9 - 1: (8, 8, 2)\n",
      "2. 8 + 2: (10, 9, 1)\n",
      "3. 9 + 1: (10, 8, 2)\n",
      "4. 2 + 1: (9, 8, 3)\n",
      "Lets consider the most promising second steps to reach 24:\n",
      "1. (8, 8, 2)\n",
      "- 8 + 8: (16, 2)\n",
      "- 8 *2: (16, 8)\n",
      "- 8 - 2: (6, 8)\n",
      "- 8 + 8: (16, 2)\n",
      "2. (10, 9, 1)\n",
      "- 10 + 9: (19, 1)\n",
      "- 10 - 1: (9, 9)\n",
      "- 9 + 1: (10, 10)\n",
      "- 9 / 1: (8, 10)\n",
      "3. (10, 8, 2)\n",
      "- 10 + 8: (18, 2)\n",
      "- 10 *2: (8, 8)\n",
      "- 8 + 2: (10, 10)\n",
      "- 8 / 2: (6, 10)\n",
      "4. (9, 8, 3)\n",
      "- 9 + 8: (17, 3)\n",
      "- 9 / 3: (6, 8)\n",
      "- 8 + 3: (11, 9)\n",
      "- 8 *3: (24, 9)\n",
      "Lets consider the most promising third steps to reach 24:\n",
      "1. 9 - 1 = 8\n",
      "- 8 + 8: (16, 2): 18, 14, 32, 8\n",
      "- 8 *2: (16, 8): 24 = 16 + 8 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "9 - 1 = 8\n",
      "Step 2:\n",
      "8*2 = 16\n",
      "Step 3:\n",
      "16 + 8 = 24\n",
      "Considering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\n",
      "answer: ((9 - 1) *2) + 8 = 24.\n",
      "\n",
      "AoT (Short)\n",
      "System:\n",
      "Use numbers and basic arithmetic operations (+ - */) to obtain 24. When\n",
      "considering the next steps, do not choose operations that will result in a\n",
      "negative or fractional number. In order to help with the calculations, the\n",
      "numbers in the parenthesis represent the numbers that are left after the\n",
      "operations and they are in descending order.\n",
      "Another thing we do is when there are only two numbers left in the parenthesis, we\n",
      "check whether we can arrive at 24 only by using basic arithmetic operations\n",
      "(+ - */). Some examples regarding this idea:\n",
      "(21 2) no\n",
      "since 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\n",
      "to 24.\n",
      "(30 6) 30 - 6 = 24 yes\n",
      "(8 3) 8 *3 = 24 yes\n",
      "(12 8) no\n",
      "(48 2) 48 / 2 = 24 yes\n",
      "Most importantly, do not give up, all the numbers that will be given has indeed a\n",
      "solution.\n",
      "User:\n",
      "14 8 8 2\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 / 2: (14, 8, 4)\n",
      "- 14 + 8: (22, 4) 26, 18, 88, fractional\n",
      "- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 2 = 4\n",
      "Step 2:\n",
      "14 - 8 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\n",
      "answer: (14 - 8) *(8 / 2) = 24.\n",
      "\n",
      "User:\n",
      "9 5 5 5\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 5 + 5: (10, 9, 5)\n",
      "- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "5 + 5 = 10\n",
      "Step 2:\n",
      "10 + 9 = 19\n",
      "Step 3:\n",
      "19 + 5 = 24\n",
      "Considering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\n",
      "answer: ((5 + 5) + 9) + 5 = 24.\n",
      "\n",
      "User:\n",
      "8 6 4 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 - 6: (4, 4, 2)\n",
      "- 4 + 4: (8, 2) 10, 6, 16, 4\n",
      "- 4 - 4: (2, 0) 2, 2, 0, undefined\n",
      "- 4 *4: (16, 2) 18, 14, 32, 8\n",
      "- 4 / 4: (2, 1) 3, 1, 2, 2\n",
      "- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 - 6 = 2\n",
      "Step 2:\n",
      "4 + 2 = 6\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\n",
      "answer: (4 + (8 - 6)) *4 = 24.\n",
      "\n",
      "User:\n",
      "13 10 9 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 10 - 4: (13, 9, 6)\n",
      "- 13 + 9: (22, 6) 28, 16, 132, fractional\n",
      "- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "10 - 4 = 6\n",
      "Step 2:\n",
      "13 - 9 = 4\n",
      "Step 3:\n",
      "6*4 = 24\n",
      "Considering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\n",
      "answer: (10 - 4) *(13 - 9) = 24.\n",
      "\n",
      "User:\n",
      "8 8 5 4\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 8 / 4: (8, 5, 2)\n",
      "- 8 + 5: (13, 2) 15, 11, 26, fractional\n",
      "- 8 - 5: (3, 2) 5, 1, 6, 1.5\n",
      "- 8 *5: (40, 2) 42, 38, 80, 20\n",
      "- 8 / 5: fractional\n",
      "- 8 + 2: (10, 5) 15, 5, 50, 2\n",
      "- 8 - 2: (6, 5) 11, 1, 30, fractional\n",
      "- 8 *2: (16, 5) 21, 11, 80, fractional\n",
      "- 8 / 2: (5, 4) 9, 1, 20, fractional\n",
      "- 5 + 2: (7, 8) 15, 1, 56, fractional\n",
      "- 5 - 2: (8, 3) 11, 5, 24 = 8 *3 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "8 / 4 = 2\n",
      "Step 2:\n",
      "5 - 2 = 3\n",
      "Step 3:\n",
      "8*3 = 24\n",
      "Considering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\n",
      "answer: 8 *(5 - (8 / 4)) = 24.\n",
      "\n",
      "User:\n",
      "11 11 1 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 11 + 1: (12, 11, 1)\n",
      "- 12 + 11: (23, 1) 24 = 23 + 1 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11 + 1 = 12\n",
      "Step 2:\n",
      "12 + 11 = 23\n",
      "Step 3:\n",
      "23 + 1\n",
      "Considering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\n",
      "answer: ((11 + 1) + 11) + 1 = 24.\n",
      "\n",
      "User:\n",
      "11 7 4 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 4 + 1: (11 7 5)\n",
      "- 11 + 7: (18, 5) 23, 13, 90, fractional\n",
      "- 11 - 7: (5, 4) 9, 1, 20, fractional\n",
      "- 11 *7: (77, 5) 82, 72, 385, fractional\n",
      "- 11 / 7: fractional\n",
      "- 11 + 5: (16, 7) 23, 9, 112, fractional\n",
      "- 11 - 5: (7, 6) 13, 1, 42, fractional\n",
      "- 11 *5: (55, 7) 62, 48, 385, fractional\n",
      "- 11 / 5: fractional\n",
      "- 7 + 5: (12, 11) 23, 1, 132, fractional\n",
      "- 7 - 5: (11, 2) 13, 9, 22, fractional\n",
      "- 7 *5: (35, 11) 46, 24 = 35 - 11 -> found it!\n",
      "Step 1:\n",
      "4 + 1 = 5\n",
      "Step 2:\n",
      "7*5 = 35\n",
      "Step 3:\n",
      "35 - 11 = 24\n",
      "Considering these steps: Backtracking the solution:\n",
      "24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\n",
      "answer: (7 *(4 + 1)) - 11 = 24.\n",
      "\n",
      "User:\n",
      "11 5 4 3\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 11 *3: (33, 5, 4)\n",
      "- 33 + 5: (38, 4) 42, 34, 152, fractional\n",
      "- 33 - 5: (28, 4) 32, 24 = 28 - 4 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "11*3 = 33\n",
      "Step 2:\n",
      "33 - 5 = 28\n",
      "Step 3:\n",
      "28 - 4 = 24\n",
      "Considering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\n",
      "answer: ((11 *3) - 5) - 4 = 24.\n",
      "\n",
      "User:\n",
      "13 12 5 2\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 13 + 5: (18, 12, 2)\n",
      "- 18 + 12: (30, 2) 32, 28, 60, fractional\n",
      "- 18 - 12: (6, 2) 8, 4, 12, 3\n",
      "- 18 *12: (216, 2) 218, 214, 432, fractional\n",
      "- 18 / 12: fractional\n",
      "- 18 + 2: (20, 12) 32, 8, 240, fractional\n",
      "- 18 - 2: (16, 12) 28, 4, 192, fractional\n",
      "- 18 *2: (36, 12) 48, 24 = 36 - 12 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "13 + 5 = 18\n",
      "Step 2:\n",
      "18*2 = 36\n",
      "Step 3:\n",
      "36 - 12 = 24\n",
      "Considering these steps: 24 = 36 - 12 = (18 *2) - 12 = ((13 + 5) *2) - 12 = 24.\n",
      "answer: ((13 + 5) *2) - 12 = 24.\n",
      "\n",
      "User:\n",
      "9 8 2 1\n",
      "Assistant:\n",
      "Trying a promising first operation:\n",
      "1. 9 - 1: (8, 8, 2)\n",
      "- 8 + 8: (16, 2) 18, 14, 32, 8\n",
      "- 8 - 8: (2, 0) 2, 2, 0, undefined\n",
      "- 8 *8: (64, 2) 66, 62, 128, 32\n",
      "- 8 / 8: (2, 1) 3, 1, 2, 2\n",
      "- 8 + 2: (10, 8) 18, 2, 80, 4\n",
      "- 8 - 2: (6, 8) 14, -2, 48, fractional\n",
      "- 8 *2: (16, 8) 24 = 16 + 8 -> found it!\n",
      "Backtracking the solution:\n",
      "Step 1:\n",
      "9 - 1 = 8\n",
      "Step 2:\n",
      "8*2 = 16\n",
      "Step 3:\n",
      "16 + 8 = 24\n",
      "Considering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\n",
      "answer: ((9 - 1) *2) + 8 = 24.\n",
      "\n",
      "55Mini Crosswords Prompts\n",
      "In the following we give all the exact prompts we used for the methods given in the experiments section and some selection of\n",
      "the generations from the LLM. In the prompts the keywords System, User and Assistant used are the roles in the OpenAI\n",
      "API in chat completion mode. The line breaks are to show the turns between the user and assistant in the API.\n",
      "AoT\n",
      "User:\n",
      "h1. A lunar valley\n",
      "h2. A fatty oil\n",
      "h3. To entice\n",
      "h4. To lower; to reduce\n",
      "h5. A solitary person\n",
      "v1. According to the roster\n",
      "v2. Another name for Port-Francqui\n",
      "v3. An illicit lover; a European lake\n",
      "v4. To lisp\n",
      "v5. To come in\n",
      "The words I already found are:\n",
      "h1. rille\n",
      "h3. tempt\n",
      "v2. ilebo\n",
      "v5. enter\n",
      "Assistant:\n",
      "There are two horizontal and two vertical words. Since they are the amount, lets\n",
      "consider the next unfound horizontal word, which is h2. Since we are\n",
      "considering the second horizontal word, we need to look at the second letters\n",
      "of the vertical words we found:\n",
      "- What is the second letter of ilebo: e\n",
      "- What is the second letter of enter: n\n",
      "The word we are looking fits the clue \"A fatty oil\" and needs to have the letters\n",
      "e and n in its (v2, two) second and (v5, five) fifth letters: _ e _ _ n. The\n",
      "candidates are: oleic, olein, olive.\n",
      "- oleic (o l e i c, _ e _ _ n) doesnt fit\n",
      "- olein (o l e i n, _ e _ _ n) fits\n",
      "- olive (o l i v e, _ e _ _ n) doesnt fit\n",
      "We add the word olein for h2. The current words are:\n",
      "h1. rille\n",
      "h2. olein\n",
      "h3. tempt\n",
      "v2. ilebo\n",
      "v5. enter\n",
      "Now, lets consider the next unfound vertical word, which is v1. Since we are\n",
      "considering the first vertical word, we need to look at the first letters of\n",
      "the horizontal words we found:\n",
      "- What is the first letter of rille: r\n",
      "- What is the first letter of olein: o\n",
      "- What is the first letter of tempt: t\n",
      "The word we are looking fits the clue \"According to the roster\" and needs to have\n",
      "the letters r, o, and t in its (h1, one) first, (h2, two) second, and (h3,\n",
      "three) third letters: r o t _ _. The candidates are: none\n",
      "Now, lets consider the next unfound vertical word, which is v3. Since we are\n",
      "considering the third vertical word, we need to look at the third letters of\n",
      "the horizontal words we found:\n",
      "- What is the third letter of rille: l\n",
      "- What is the third letter of olein: e\n",
      "- What is the third letter of tempt: m\n",
      "The word we are looking fits the clue \"An illicit lover; a European lake\" and\n",
      "needs to have the letters l, e, and m in its (h1, one) first, (h2, two) second\n",
      ", and (h3, three) third letters: l e m _ _. The candidates are: leman.\n",
      "- leman (l e m a n, l e m _ _) fits\n",
      "We add the word leman for v3. The current words are:\n",
      "h1. rille\n",
      "h2. olein\n",
      "h3. tempt\n",
      "v2. ilebo\n",
      "v3. leman\n",
      "v5. enter\n",
      "Now, lets consider the next unfound horizontal word, which is h4. Since we are\n",
      "considering the fourth horizontal word, we need to look at the fourth letters\n",
      "of the vertical words we found:\n",
      "- What is the fourth letter of ilebo: b\n",
      "- What is the fourth letter of leman: a\n",
      "- What is the fourth letter of enter: e\n",
      "The word we are looking fits the clue \"To lower; to reduce\" and needs to have the\n",
      "letters b, a, and e in its (v2, two) second, (v3, three) third, and (v5, five)\n",
      "fifth letters: _ b a _ e. The candidates are: abase, abate.\n",
      "- abase (a b a s e, _ b a _ e) fits\n",
      "- abate (a b a t e, _ b a _ e) fits\n",
      "Since both fits, lets consider another word.\n",
      "Now, lets consider the last unfound vertical word, which is v4. Since we are\n",
      "considering the fourth vertical word, we need to look at the fourth letters of\n",
      "the horizontal words we found:\n",
      "- What is the fourth letter of rille: l\n",
      "- What is the fourth letter of olein: i\n",
      "- What is the fourth letter of tempt: p\n",
      "The word we are looking fits the clue \"To lisp\" and needs to have the letters l, i\n",
      ", p, and s in its (h1, one) first, (h2, two) second, (h3, three) third letters\n",
      ": l i p _ _. The candidates are: The candidate is \"lisps\".\n",
      "- lisps (l i s p s, l i p _ _) doesnt fit\n",
      "We have considered all of the words for the horizontal words, we have two options:\n",
      "abase and abate, lets choose one of them.\n",
      "answer:\n",
      "h1. rille\n",
      "h2. olein\n",
      "h3. tempt\n",
      "h4. abase\n",
      "v2. ilebo\n",
      "v3. leman\n",
      "v5. enter\n",
      "\n",
      "User:\n",
      "h1. One who saws\n",
      "h2. A fungus genus\n",
      "h3. An assessor\n",
      "h4. Pasture land\n",
      "h5. Receiving by the ear\n",
      "v1. To swell; to increase\n",
      "v2. The Brazilian macaw; an Australian bird\n",
      "v3. A Timorese island\n",
      "v4. Excessive fluid accumulation\n",
      "v5. Dewy; roscid\n",
      "The words I already found are:\n",
      "h1. sawer\n",
      "h3. rater\n",
      "v1. surge\n",
      "v4. edema\n",
      "Assistant:\n",
      "There are two horizontal and two vertical words. Since they are the amount, lets\n",
      "consider the next unfound horizontal word, which is h2. Since we are\n",
      "considering the second horizontal word, we need to look at the second letters\n",
      "of the vertical words we found:\n",
      "- What is the second letter of surge: u\n",
      "- What is the second letter of edema: d\n",
      "The word we are looking fits the clue \"A fungus genus\" and needs to have the\n",
      "letters u and d in its (v1, one) first and (v4, four) fourth letters: u _ _ d\n",
      "_. The candidates are: uredo.\n",
      "- uredo (u r e d o, u _ _ d _) fits\n",
      "We add the word uredo for h2. The current words are:\n",
      "h1. sawer\n",
      "h2. uredo\n",
      "h3. rater\n",
      "v1. surge\n",
      "v4. edema\n",
      "Now, lets consider the next unfound vertical word, which is v2. Since we are\n",
      "considering the second vertical word, we need to look at the second letters of\n",
      "the horizontal words we found:\n",
      "- What is the second letter of sawer: a\n",
      "- What is the second letter of uredo: r\n",
      "- What is the second letter of rater: a\n",
      "The word we are looking fits the clue \"The Brazilian macaw; an Australian bird\"\n",
      "and needs to have the letters a, r, and a in its (h1, one) first, (h2, two)\n",
      "second, and (h3, third) third letters: a r a _ _. The candidates are: arara.\n",
      "- arara (a r a r a, a r a _ _) fits\n",
      "We add the word arara for v2. The current words are:\n",
      "h1. sawer\n",
      "h2. uredo\n",
      "h3. rater\n",
      "v1. surge\n",
      "v2. arara\n",
      "v4. edema\n",
      "Now, lets consider the next unfound horizontal word, which is h4. Since we are\n",
      "considering the fourth horizontal word, we need to look at the fourth letters\n",
      "of the vertical words we found:\n",
      "- What is the fourth letter of surge: g\n",
      "- What is the fourth letter of arara: r\n",
      "- What is the fourth letter of edema: m\n",
      "the word we are looking fits the clue \"Pasture land\" and needs to have the letters\n",
      "g, r, and m in its (v1, one) first, (v2, two) second, and (v4, four) fourth\n",
      "letters: g r _ m _. The candidates are: grama.\n",
      "- grama (g r a m a, g r a _ _) fits\n",
      "We add the word grama for h4. The current words are:\n",
      "h1. Sawer\n",
      "h2. Uredos\n",
      "h3. Rater\n",
      "h4. Grama\n",
      "v1. surge\n",
      "v2. arara\n",
      "v4. edema\n",
      "Now, lets consider the next unfound vertical word, which is v3. Since we are\n",
      "considering the third vertical word, we need to look at the third letters of\n",
      "the horizontal words we found:\n",
      "- What is the third letter of sawer: w\n",
      "- What is the third letter of uredo: e\n",
      "- What is the third letter of rater: t\n",
      "- What is the third letter of grama: a\n",
      "The word we are looking fits the clue \"A Timorese island\" and needs to have the\n",
      "letters w, e, t, and a in its (h1, one) first, (h2, two) second, (h3, three)\n",
      "third, and (h4, four) fourth letters: w e t a _. The candidates are: The\n",
      "candidate is \"wetar\".\n",
      "- wetar (w e t a r, w e t a _) fits\n",
      "We add the word wetar for v3. The current words are:\n",
      "h1. sawer\n",
      "h2. uredo\n",
      "h3. rater\n",
      "h4. grama\n",
      "v1. surge\n",
      "v2. arara\n",
      "v3. wetar\n",
      "v4. edema\n",
      "Now, lets consider the last unfound horizontal word, which is h5. Since we are\n",
      "considering the fifth horizontal word, we need to look at the fifth letters of\n",
      "the vertical words we found:\n",
      "- What is the fifth letter of surge: e\n",
      "- What is the fifth letter of arara: a\n",
      "- What is the fifth letter of wetar: r\n",
      "- What is the fifth letter of edema: a\n",
      "The word we are looking fits the clue \"Receiving by the ear\" and needs to have the\n",
      "letters e, a, r, and a in its (v1, one) first, (v2, two) second, (v3, three)\n",
      "third, and (v4, four) fourth letters: e a r a _. The candidates are: The\n",
      "candidate is \"earal\".\n",
      "- earal (e a r a l, e a r a _) fits\n",
      "We add the word earal for h5. The current words are:\n",
      "h1. sawer\n",
      "h2. uredo\n",
      "h3. rater\n",
      "h4. grama\n",
      "h5. earal\n",
      "v1. surge\n",
      "v2. arara\n",
      "v3. wetar\n",
      "v4. edema\n",
      "Since we found all horizontal words:\n",
      "answer:\n",
      "h1. sawer\n",
      "h2. uredo\n",
      "h3. rater\n",
      "h4. grama\n",
      "h5. earal\n",
      "v1. surge\n",
      "v2. arara\n",
      "v3. wetar\n",
      "v4. edema\n",
      "\n",
      "User:\n",
      "h1. Dandruff; scum; the bull-trout\n",
      "h2. One who greets; to vacillate; a British river\n",
      "h3. A Turkish written decree\n",
      "h4. Mignon; petty; little\n",
      "h5. A bishops permission for a priest to leave a diocese\n",
      "v1. To steal; to brush across\n",
      "v2. A sedge (a primitive three-sided grass)\n",
      "v3. Grape jam\n",
      "v4. A flatworm larva\n",
      "v5. Ore refuse; to prepare material for glass by heat\n",
      "h2. waver\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "Assistant:\n",
      "Lets consider the next unfound horizontal word, which is h1. Since we are\n",
      "considering the first horizontal word, we need to look at the first letters of\n",
      "the vertical words we found:\n",
      "- What is the first letter of swipe: s\n",
      "- What is the first letter of carex: c\n",
      "The word we are looking fits the clue \"Dandruff; scum; the bull-trout\" and needs\n",
      "to have the letters s and c in its (v1, one) first and (v2, two) second\n",
      "letters: s c _ _ _. The candidates are: scurf.\n",
      "- scurf (s c u r f, s c _ _ _) fits\n",
      "We add the word scurf for h1. The current words are:\n",
      "h1. scurf\n",
      "h2. waver\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "Now, lets consider the next unfound vertical word, which is v3. Since we are\n",
      "considering the third vertical word, we need to look at the third letters of\n",
      "the horizontal words we found:\n",
      "- What is the third letter of scurf: u\n",
      "- What is the third letter of waver: v\n",
      "- What is the third letter of exeat: e\n",
      "The word we are looking fits the clue \"Grape jam\" and needs to have the letters u,\n",
      "v, and e in its (h1, one) first, (h2, two) second, and (h5, five) fifth\n",
      "letters: u v _ _ e. The candidates are: The candidate is \"uvetta\".\n",
      "- uvetta (u v e t t a, u v _ _ e) doesnt fit\n",
      "Lets consider the next unfound vertical word, which is v4. Since we are\n",
      "considering the fourth vertical word, we need to look at the fourth letters of\n",
      "the horizontal words we found:\n",
      "- What is the fourth letter of scurf: r\n",
      "- What is the fourth letter of waver: e\n",
      "- What is the fourth letter of exeat: a\n",
      "The word we are looking fits the clue \"A flatworm larva\" and needs to have the\n",
      "letters r, e, and a in its (h1, one) first, (h2, two) second, and (h5, five)\n",
      "fifth letters: r e _ _ a. The candidates are: redia.\n",
      "- redia (r e d i a, r e _ _ a) fits\n",
      "We add the word redia for v4. The current words are:\n",
      "h1. scurf\n",
      "h2. waver\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "v4. redia\n",
      "Now, lets consider the next unfound horizontal word, which is h3. Since we are\n",
      "considering the third horizontal word, we need to look at the third letters of\n",
      "the vertical words we found:\n",
      "- What is the third letter of swipe: i\n",
      "- What is the third letter of carex: r\n",
      "- What is the third letter of redia: d\n",
      "The word we are looking fits the clue \"A Turkish written decree\" and needs to have\n",
      "the letters i, r, and d in its (v1, one) first, (v2, two) second, and (v4,\n",
      "four) fourth letters: i r _ d _. The candidates are: irade.\n",
      "- irade (i r a d e, i r _ d _) fits\n",
      "We add the word irade for h3. The current words are:\n",
      "h1. scurf\n",
      "h2. waver\n",
      "h3. irade\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "v4. redia\n",
      "Now, lets consider the last unfound vertical word, which is v5. Since we are\n",
      "considering the fifth vertical word, we need to look at the fifth letters of\n",
      "the horizontal words we found:\n",
      "- What is the fifth letter of scurf: f\n",
      "- What is the fifth letter of waver: r\n",
      "- What is the fifth letter of irade: e\n",
      "- What is the fifth letter of exeat: t\n",
      "The word we are looking fits the clue \"Ore refuse; to prepare material for glass\n",
      "by heat\" and needs to have the letters f, r, e, and t in its (h1, one) first,\n",
      "(h2, two) second, (h3, three) third, and (h5, five) fifth letters: f r e _ t.\n",
      "The candidates are: The candidate is \"frett\".\n",
      "- frett (f r e t t, f r e _ t) fits\n",
      "We add the word frett for v5. The current words are:\n",
      "h1. scurf\n",
      "h2. waver\n",
      "h3. irade\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "v4. redia\n",
      "v5. frett\n",
      "Since we found all horizontal words:\n",
      "answer:\n",
      "h1. scurf\n",
      "h2. waver\n",
      "h3. irade\n",
      "h5. exeat\n",
      "v1. swipe\n",
      "v2. carex\n",
      "v4. redia\n",
      "v5. frett\n",
      "\n",
      "Propose Words\n",
      "User:\n",
      "h1. A lunar valley\n",
      "h2. A fatty oil\n",
      "h3. To entice\n",
      "h4. To lower; to reduce\n",
      "h5. A solitary person\n",
      "v1. According to the roster\n",
      "v2. Another name for Port-Francqui\n",
      "v3. An illicit lover; a European lake\n",
      "v4. To lisp\n",
      "v5. To come in\n",
      "Assistant:\n",
      "All possible 5-letters words for each clue, for each clue we give 10 options:\n",
      "h1. RILLE, VALLIS, CRATER, BASINS, PLAINS\n",
      "h2. OLEIC, OLEIN, GREASE, BUTTER, ANIMAL\n",
      "h3. LURE, TEMPT, SEDUCE, ENTICE, DRAWIN\n",
      "h4. ABASE, LOWER, REDUCE, LESSEN, DEBASE\n",
      "h5. HERMIT, ALONE, LONER, SINGLE, SOLITARY\n",
      "v1. ONTAP, LISTED, ROSTER, SCHEDULE, PLANNED\n",
      "v2. ILEBO, PORTF, CONGO, AFRICA, COLONY\n",
      "v3. LOVER, AMOUR, GENEVA, LEMAN, ZURICH\n",
      "v4. SLUR, LISPS, STUTTER, MUMBLE, STAMMER\n",
      "v5. ENTER, ARRIVE, COMEIN, APPEAR, SHOWUP\n",
      "\n",
      "Creative Writing\n",
      "AoT\n",
      "\"Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph\n",
      "must be:\n",
      "{0}\n",
      "Firstly, make five different plans for a coherent passage, then write. Your output\n",
      "should be of the following format:\n",
      "Plan 1:\n",
      "Your plan here.\n",
      "Plan 2:\n",
      "Your plan here.\n",
      "Plan 3:\n",
      "Your plan here.\n",
      "Plan 4:\n",
      "Your plan here.\n",
      "Plan 5:\n",
      "Your plan here.\n",
      "Secondly, given an instruction and several plans, decide which choice is most\n",
      "promising. Analyze each choice in detail, then conclude in the last line \"The best\n",
      "choice is {{s}}\", where s the integer id of the choice.\n",
      "Thirdly, write the passage according to that chosen plan in the most coherent way. Add\n",
      "\"Passage:\" before writing the passage under it.\n",
      "Passage:\n",
      "Your passage here.\n",
      "Finally, refine the passage in the most coherent way, but you still have to end each\n",
      "paragraph with the given sentences as before.\n",
      "Final Passage:\n",
      "Final passage here.\n",
      "Score Prompt\n",
      "Analyze the following passage, then at the last line conclude \"Thus the coherency\n",
      "score is {{s}}\", where s is an integer from 1 to 10.\n",
      "{0}\n",
      "Acknowledgment: We appreciate the discussions and assistance provided by L. Wang.\n",
      "Contributions: B. Sel played a pivotal role in shaping the primary concept, spearheading the experimental design and eval-\n",
      "uation, and leading the papers writing process. A. Tawaha actively engaged in discussions and conducted experiments. V .\n",
      "Khattar collaborated through discussions and played a role in conducting the experiments. R. Jia and M. Jin both engaged in\n",
      "constructive discussions, with M. Jin also offering advisory guidance.\n",
      "Additional info about the changes from the first version (dated 8/20/2023) can be found in this link (https://tinyurl.com/\n",
      "2vnjxw93).\n"
     ]
    }
   ],
   "source": [
    "# Carica il PDF\n",
    "loader = PyPDFLoader(pdfd)\n",
    "\n",
    "# Carica i documenti\n",
    "documents = loader.load()\n",
    "\n",
    "# Assicurati che ogni documento abbia l'attributo 'page_content'\n",
    "for doc in documents:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created successfully at testo.txt\n"
     ]
    }
   ],
   "source": [
    "# Define the content and the file path\n",
    "content = testo\n",
    "file_path = \"testo.txt\"\n",
    "\n",
    "# Create and write to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(content)\n",
    "\n",
    "print(f\"File created successfully at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Read the text content from the file\n",
    "loader = TextLoader(file_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the document into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size =500,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "splits =text_splitter.split_documents(documents)\n",
    "for sp in splits:\n",
    "    if (len(sp.page_content) <100):\n",
    "        splits.remove(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di chunks: 354\n"
     ]
    }
   ],
   "source": [
    "print (\"Numero di chunks:\",len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata :\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43msplits\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimenzione del chunk:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(splits[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaratteri\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContenuto del chunk: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'splits' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Metadata :\", splits[0].metadata)\n",
    "print(\"Dimenzione del chunk:\", len(splits[1].page_content), \"caratteri\")\n",
    "print(\"Contenuto del chunk: \\n\" )\n",
    "print(splits[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Embeddings model\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "\n",
    "model =\"nomic-embed-text\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Embeddings model questo funziona\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartella=\"algoritmop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "if os.path.exists(cartella):\n",
    "    #Carica indice FAISS cartella corrente attuale\n",
    "    faiss_index=FAISS.load_local(\n",
    "        cartella,\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "else:\n",
    "    #crea indice FAISS dei chunk nella cartella attuale\n",
    "    faiss_index = FAISS.from_documents(\n",
    "        splits,\n",
    "        embeddings\n",
    "    )\n",
    "    faiss_index.save_local(cartella)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "if os.path.exists(cartella):\n",
    "    #Carica indice FAISS cartella corrente attuale\n",
    "    faiss_index=FAISS.load_local(\n",
    "        cartella,\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "else:\n",
    "    #crea indice FAISS dei chunk nella cartella attuale\n",
    "    faiss_index = FAISS.from_documents(\n",
    "        docs,\n",
    "        embeddings\n",
    "    )\n",
    "    faiss_index.save_local(cartella)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = faiss_index.as_retriever(\n",
    "\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt =hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "prompt = ChatPromptTemplate.from_template(\"Sei un assistente preciso e attento ; Rispondi a questa domanda in italiano: {question}, considra il seguente contesto {context}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esempio di template prompt\n",
    "\n",
    "# Definisci il prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Riassumi questo testo {testou} il cui titolo  {titolou}, il cui autore  {autoreu}, il cui indice  {indice}. Dividi le sezioni del riassunto secondo l'indice. Il riassunto deve essere discorsivo e ogni parte deve avere almeno due capoversi. Nella sezione reference o biografia riporta i dati biografici. Inserisci esempi, definizioni e loro spigazione. Non dire in questa sezione parla di o cose del genere, ma spiega in parole pi semplice quello che viene scritto, cercando di non perdere il significato originalie, devi essere informativo. Fai tipo un scheda titolo, autore e riassutnto. Non fare un elenco puntato. Agisci come un ricercatore. Rispondi in italiano.\"\n",
    ")\n",
    "\n",
    "# Crea l'output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Crea la catena di trasformazione\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# Definisci i parametri di input\n",
    "params = {\n",
    "    \"testou\": testo,\n",
    "    \"titolou\": titolo,\n",
    "    \"autoreu\": autore,\n",
    "    \"indice\": indice\n",
    "}\n",
    "\n",
    "# Esegui la catena e ottieni la risposta\n",
    "answer = chain.invoke(params)\n",
    "\n",
    "# Stampa la risposta\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esempio di template prompt\n",
    "\n",
    "# Definisci il prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Riassumi questo testo {testou} il cui titolo  {titolou}, il cui autore  {autoreu}, il cui indice  {indice}. Dividi le sezioni del riassunto secondo l'indice. Il riassunto deve essere discorsivo e ogni parte deve avere almeno due capoversi. Nella sezione reference o biografia riporta i dati biografici. Inserisci esempi, definizioni e loro spigazione. Non dire in questa sezione parla di o cose del genere, ma spiega in parole pi semplice quello che viene scritto, cercando di non perdere il significato originalie, devi essere informativo. Fai tipo un scheda titolo, autore e riassutnto. Non fare un elenco puntato. Agisci come un ricercatore. Rispondi in italiano.\"\n",
    ")\n",
    "\n",
    "# Crea l'output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Crea la catena di trasformazione\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# Definisci i parametri di input\n",
    "params = {\n",
    "    \"testou\": retriever | format_documents,\n",
    "    \"titolou\": titolo,\n",
    "    \"autoreu\": autore,\n",
    "    \"indice\": indice\n",
    "}\n",
    "\n",
    "# Esegui la catena e ottieni la risposta\n",
    "answer = chain.invoke(params)\n",
    "\n",
    "# Stampa la risposta\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_documents(documents):\n",
    "    return \"\\n\\n\".join(doc.page_contente for doc in documents)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_documents,\n",
    "        \"question\": RunnablePassthrough()\n",
    "        \n",
    "    } \n",
    "    |prompt\n",
    "    |model\n",
    "    |StrOutputParser()\n",
    "    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query):\n",
    "    answer = rag_chain.invoke(query)\n",
    "    return answer\n",
    "\n",
    "def queryStream(query):\n",
    "    for chunk in rag_chain.stream(query):\n",
    "        print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"riasumi Algorithm_of_Thoughts-_Enhancing_Exploration_of_Ideas_in_Large_Language_Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryStream(\"Qual  il titolo dell'articolo e qual  il suo autore, che cosa sono le diacostruzione\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
