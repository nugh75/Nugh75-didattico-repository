{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url = \"http://192.168.145.131:1234/v1\",\n",
    "    temperature = 0,\n",
    "    api_key = \"not-needed\",\n",
    "    model_name =\"gemma2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La lingua, misteriosa e bella,\n",
      "Tessuto di suoni, di significati nascosti,\n",
      "Un mondo di relazioni, di strutture e regole,\n",
      "Che ci parlano della nostra mente.\n",
      "\n",
      "Le parole, come pietre preziose,\n",
      "Sono state scelte per la loro forma e colore,\n",
      "Per esprimere i pensieri, le emozioni, i desideri,\n",
      "E comunicare con gli altri in modo chiaro.\n",
      "\n",
      "La grammatica, come un mosaico,\n",
      "Ci aiuta a costruire frasi e discorsi,\n",
      "Con regole e schemi, che ci guidano,\n",
      "Per creare un linguaggio preciso e chiaro.\n",
      "\n",
      "Il lessico, come una biblioteca,\n",
      "Ci offre un vasto repertorio di parole,\n",
      "Da utilizzare per esprimere i nostri pensieri,\n",
      "E comunicare con gli altri in modo efficace.\n",
      "\n",
      "La pragmatica, come un'arte,\n",
      "Ci aiuta a comprendere il contesto,\n",
      "E adattare il nostro linguaggio,\n",
      "Per essere compresi dagli altri.\n",
      "\n",
      "In questo mondo di relazioni e strutture,\n",
      "La linguistica ci parla della nostra mente,\n",
      "E ci aiuta a comunicare in modo chiaro,\n",
      "Con gli altri, con noi stessi, e con il mondo.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"scrivi una poesia sull'argomento ; {argomento}, Rispondi in italiano.\")\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "answer = chain.invoke({\"argomento\": \"La linguistica\"})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "#percorso della cartella contenente i PDF\n",
    "folder_path = 'pdf'\n",
    "\n",
    "# Lista per memorizzare tutti i documenti caricati\n",
    "all_documents = []\n",
    "\n",
    "# Iterare su tutti i file nella cartella\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(folder_path, filename)\n",
    "        loader = PyPDFLoader(file_path=pdf_path)\n",
    "        documents = loader.load()\n",
    "        all_documents.extend(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Algorithm of Thoughts: Enhancing Exploration of Ideas\\nin Large Language Models\\nBilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Ruoxi Jia, and Ming Jin\\nVirginia Tech\\nAbstract\\nCurrent literature, aiming to surpass the “Chain-of-Thought”\\napproach, often resorts to an external modus operandi in-\\nvolving halting, modifying, and then resuming the genera-\\ntion process to boost Large Language Models’ (LLMs) rea-\\nsoning capacities. This mode escalates the number of query\\nrequests, leading to increased costs, memory, and computa-\\ntional overheads. Addressing this, we propose the Algorithm\\nof Thoughts —a novel strategy that propels LLMs through\\nalgorithmic reasoning pathways, pioneering a new mode of\\nin-context learning. By employing algorithmic examples, we\\nexploit the innate recurrence dynamics of LLMs, expand-\\ning their idea exploration with merely one or a few queries.\\nOur technique outperforms earlier single-query methods and\\nstands on par with a recent multi-query strategy that employs\\nan extensive tree search algorithm. Intriguingly, our results\\nsuggest that instructing an LLM using an algorithm can lead\\nto performance surpassing that of the algorithm itself, hinting\\nat LLM’s inherent ability to weave its intuition into optimized\\nsearches. We probe into the underpinnings of our method’s\\nefficacy and its nuances in application.\\nIntroduction\\nRecent developments in large language models (Chowdhery\\net al. 2022; Thoppilan et al. 2022; Liu et al. 2023, inter alia )\\nhave spotlighted their efficacy in general problem solving\\n(Huang and Chang 2022; Suzgun et al. 2022), code gen-\\neration (Chen et al. 2021; Austin et al. 2021), and instruc-\\ntion following (Ouyang et al. 2022; Bai et al. 2022). While\\nearly models relied on direct answer strategies (Brown et al.\\n2020), contemporary research veers towards linear reason-\\ning paths (Wei et al. 2022b; Kojima et al. 2022; Zhang et al.\\n2022) by breaking problems into sub-tasks for solution dis-\\ncovery, or harnesses external mechanisms to alter token gen-\\neration by changing the context (Zhou et al. 2022; Drozdov\\net al. 2022; Yao et al. 2023).\\nAnalogous to human cognition (Sloman 1996; Kahneman\\n2011), early LLM strategies seemed to emulate the instan-\\ntaneous System 1 , characterized by its impulsive decision-\\nmaking. In contrast, more recent methodologies like chain-\\nof-thought (CoT) (Wei et al. 2022b) and least-to-most\\nprompting (L2M) (Zhou et al. 2022; Drozdov et al. 2022)\\nPreprint. Under review.reflect the introspective nature of System 2 . Notably, inte-\\ngrating intermediary reasoning steps has yielded improve-\\nments in arithmetic reasoning tasks (Srivastava et al. 2022;\\nLiang et al. 2022).\\nHowever, as tasks shift towards deeper planning and ex-\\ntensive thought exploration, these methods appear restric-\\ntive. Although CoT integrated with Self-Consistency (CoT-\\nSC) (Wang et al. 2022) enlists multiple LLM outputs for\\na consensus, the lack of meticulous evaluation can result\\nin model misdirection. The “Tree of Thoughts” (Yao et al.\\n2023; Long 2023) emerges as a notable solution. While one\\nLLM is dedicated to idea generation, another steps in to as-\\nsess the merit of these ideas, following a halting-assessment-\\nresuming cycle. This iterative process, anchored by tree\\nsearch, has shown marked effectiveness, especially in tasks\\nwith a breadth of continuations. We see this progression\\nas akin to humans employing tools to circumvent working\\nmemory limitations, serving as an external augmentation for\\nLLMs (Mialon et al. 2023).\\nOn the flip side, this enhanced LLM approach is not\\nwithout pitfalls. A prominent downside is the substantial\\nsurge in the number of queries and computational demands.\\nEach query to online LLM APIs such as GPT-4—a focal\\npoint of our study—incurs a monetary expense (Chen, Za-\\nharia, and Zou 2023) but also contributes to latency, a sig-\\nnificant limitation especially critical in real-time applica-\\ntions. Cumulative delays from these queries can compro-\\nmise solution efficiency. Infrastructure-wise, continuous in-\\nteractions can stress systems, leading to potential bandwidth\\nconstraints and reduced model availability (Aminabadi et al.\\n2022). Moreover, the environmental implications cannot be\\nignored; incessant querying escalates the energy consump-\\ntion of already power-hungry data centers, exacerbating the\\ncarbon footprint (Wu et al. 2022; Dhar 2020).\\nWith this in mind, our goal is to dramatically reduce the\\nquery counts employed by contemporary multi-query rea-\\nsoning methods while maintaining performance for tasks ne-\\ncessitating adept use of world knowledge , thereby steering a\\nmore responsible and proficient use of AI resources.\\nReflecting on the evolution of LLMs from System 1 to\\nSystem 2, an essential ingredient comes to light: algorithms.\\nCharacterized by its methodical nature, the algorithmic per-\\nspective offers a path to keenly explore problem spaces, en-\\nact strategies, and formulate solutions (Helie and Pizlo 2022;arXiv:2308.10379v2  [cs.CL]  28 Sep 2023', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 0}), Document(page_content='Chain-of-Thought\\nModel \\nInput\\nModel \\nOutput\\nUser: \\n8 \\n6 \\n4 \\n4\\nAssistant: \\n8 \\n- \\n6 \\n= \\n2 \\n(left: \\n4, \\n4, \\n2)\\n4 \\n+ \\n2 \\n= \\n6 \\n(left: \\n6, \\n4)\\n6 \\n* \\n4 \\n= \\n24\\nAnswer: \\n(4 \\n+ \\n(8 \\n- \\n6)) \\n* \\n4 \\n= \\n24.\\n \\nUser: \\n11 \\n10 \\n5 \\n1\\nAssistant:\\n11 \\n- \\n10 \\n= \\n1 \\n(left: \\n1, \\n1, \\n5)\\n1 \\n* \\n1 \\n= \\n1 \\n(left: \\n1, \\n5)\\n5 \\n* \\n1 \\n= \\n5 \\n(left: \\n5)\\nAnswer: \\n((11 \\n- \\n10) \\n* \\n1) \\n* \\n5 \\n- \\n1 \\n= \\n24.\\nAlgorithm \\nof \\nThoughts\\nModel \\nInput\\nModel \\nOutput\\nUser: \\n8 \\n6 \\n4 \\n4\\nAssistant:\\n1. \\n4 \\n- \\n4: \\n(left: \\n8, \\n6, \\n0)\\n.\\n.\\n.\\n3. \\n8 \\n- \\n6: \\n(left: \\n4, \\n4, \\n2)\\n- \\n4 \\n+ \\n4: \\n(left: \\n8, \\n2) \\n10, \\n6, \\n16, \\n4\\n- \\n4 \\n- \\n4: \\n(left: \\n2, \\n0) \\n2, \\n2, \\n0, \\nundefined\\n- \\n4 \\n* \\n4: \\n(left: \\n16, \\n2) \\n18, \\n14, \\n32, \\n8\\n- \\n4 \\n/ \\n4: \\n(left: \\n2, \\n1) \\n3, \\n1, \\n2, \\n2\\n- \\n4 \\n+ \\n2: \\n(left: \\n6, \\n4) \\n10, \\n2, \\n24 \\n= \\n6 \\n* \\n4 \\n-> \\nfound \\nit!\\nAnswer: \\n(4 \\n+ \\n(8 \\n- \\n6)) \\n* \\n4 \\n= \\n24.\\n \\nUser: \\n11 \\n10 \\n5 \\n1\\nAssistant:\\n1. \\n11 \\n- \\n1: \\n(left: \\n10, \\n10, \\n5)\\n.\\n.\\n.\\n5. \\n11 \\n+ \\n1: \\n(left: \\n12, \\n10, \\n5)\\n- \\n12 \\n+ \\n10: \\n(left: \\n22, \\n5) \\n27, \\n17, \\n110, \\n4.4\\n- \\n12 \\n- \\n10: \\n(left: \\n5, \\n2) \\n7, \\n3, \\n10, \\n2.5\\n- \\n12 \\n* \\n10: \\n(left: \\n120, \\n5) \\n24 \\n= \\n120 \\n/ \\n5 \\n-> \\nfound \\nit!\\nAnswer: \\n((11 \\n+ \\n1) \\n* \\n10) \\n/ \\n5 \\n= \\n24.\\nStandard \\nPrompting\\nModel \\nInput\\nModel \\nOutput\\nUser: \\n8 \\n6 \\n4 \\n4\\nAssistant: \\nAnswer: \\n(4 \\n+ \\n(8 \\n- \\n6)) \\n* \\n4 \\n= \\n24.\\n \\nUser: \\n11 \\n10 \\n5 \\n1\\nAssistant:\\nAnswer: \\n(11 \\n- \\n1) \\n* \\n(10 \\n- \\n5) \\n= \\n24Figure 1: Comparison between standard prompting, CoT, and AoT in the game of 24. While standard prompting aims for a direct\\nanswer, CoT sketches out the successive steps to the final solution. AoT’s in-context example, distinct from CoT, integrates the\\nsearch process, highlighted by markers ‘1’,..., ‘3’ as “first operations” guiding subtree exploration for the problem set ‘8 6\\n4 4’. For clarity, only a single in-context example is displayed, with a focus on the third subtree exploration. AoT produces\\nprospective search steps (e.g., the subtree exploration ‘5. 11 + 1 ’) and evaluates potential subsequent steps to either progress\\ntowards a solution or retrace to another viable subtree.\\nBanerjee et al. 2022). While much of the prevailing literature\\ntreats algorithms as external to LLMs, given LLMs’ inher-\\nent generative recurrence, can we channel this iterative logic\\ntointernalize an algorithm?\\nDrawing upon both the intricate nuances of human rea-\\nsoning and the disciplined precision of algorithmic method-\\nologies, our work aims to fuse these dual facets to aug-\\nment reasoning capabilities within LLMs. Existing research\\nunderscores that humans, when navigating complex prob-\\nlems, instinctively draw upon past efforts, ensuring a com-\\nprehensive contemplation rather than a narrow focus (Mon-\\nsell 2003; Holyoak and Morrison 2005; Baddeley 2003).\\nLLMs, with their generative span bounded only by token\\nlimits, appear poised to break through the barriers of human\\nworking memory. Spurred by this observation, we investi-\\ngated if LLMs could mirror a similar layered exploration\\nof ideas, referencing prior intermediate steps to sieve out\\ninfeasible options, all within their iterative generation cy-\\ncle. And while humans excel with their intuitive acumen, al-\\ngorithms stand out with organized, systematic exploration.\\nCurrent techniques, like CoT, often sidestep this synergistic\\npotential, imposing undue pressure on LLMs for on-the-spot\\nprecision. By capitalizing on LLMs’ recursive capabilities,\\nwe emulate a hybrid human-algorithmic approach. This is\\nachieved through our use of algorithmic examples that cap-\\nture the essence of exploration, from initial candidates to\\nvalidated solutions. Thus emerges our concept of the Algo-\\nrithm of Thoughts (AoT), as illustrated in Figs. 1 and 2.More broadly, our approach signifies a new paradigm of\\nin-context learning. Instead of the traditional “supervised-\\nlearning” mold of [ PROBLEM ,SOLUTION ] or [ PROBLEM ,\\nSUCCESSIVE STEPS TO SOLUTION ], we present a new\\nstructure that covers [ PROBLEM ,SEARCH PROCESS ,SO-\\nLUTION ]. Naturally, when instructing an LLM using an al-\\ngorithm, the anticipation leans towards the LLM simply\\nimitating the algorithm’s iterative thinking. However, what\\nemerges as intriguing is the LLM’s ability to infuse its own\\n“intuition” to achieve a search efficiency that even surpasses\\nthe algorithm itself (see Fig. 5).\\nIn the subsequent sections, we first situate our work\\nwithin the existing literature, followed by a discussion of\\nour principal idea. We then present our experimental results\\nand probe a series of hypotheses related to this emerging ca-\\npability of LLM before rounding off with a conclusion.\\nRelated Work\\nStandard Prompting. Also known as input-output\\nprompting, it provides a few input-output examples of the\\ntask before getting an answer for the test sample from the\\nlanguage model (Brown et al. 2020). Although this method\\nis very general and does not need any special prompting\\nstrategy, the performance is also worse compared to more\\nadvanced methods (Shao et al. 2023; Wei et al. 2022a; Lyu\\net al. 2023).', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 1}), Document(page_content='Input\\nOutput\\nInput\\nOutput\\nInput\\nOutput\\nInput\\nOutput\\nStandard \\nPrompting\\nChain \\nof \\nThoughts\\nTree \\nof \\nThoughts\\nAlgorithm \\nof \\nThoughtsFigure 2: Illustration outlining various strategies for tackling reasoning problems with LLMs. Each box signifies a distinct\\nthought, functioning as a unified string of words that forms an incremental pathway to reasoning. Green boxes indicate ideas\\ndeemed promising by the LLM, while red boxes represent less promising concepts.\\nChain-of-Thought. In CoT, LLMs are presented with ex-\\namples where a given question xunfolds through a chain\\nof intermediate reasoning pieces c1, . . . , c nto reach an an-\\nswery, represented as x→c1→. . .→cn→y(Wei\\net al. 2022b; Lyu et al. 2023). By mimicking the examples\\nin the context, the LLM automatically divides the solution\\ninto simpler linear steps to arrive at the answer, improv-\\ning performance across numerous reasoning benchmarks.\\nSelf-consistency (Wang et al. 2022) is a widely used de-\\ncoding strategy aimed at generating a variety of reason-\\ning paths by choosing the final answer through a majority\\nvote, though this necessitates additional generations. Con-\\ntrary to CoT’s linear, direct progression, our approach pivots\\ntowards the explorative aspect of LLMs. We reconceptual-\\nize the c1, . . . , c nsequence, not merely as successive steps\\ntowards a solution, but as a dynamic, potentially mutable\\npath that resembles an algorithmic search, allowing for ex-\\nploration, recalibration, and non-linear progression.\\nLeast-to-Most prompting (L2M). Taking cues from ed-\\nucational psychology (Libby et al. 2008), L2M prompting\\ndirects the LLM to decompose the central problem into\\nsmaller subproblems. Each subproblem is tackled in se-\\nquence, with the outcome appended before progressing to\\nthe next (Zhou et al. 2022; Drozdov et al. 2022). While this\\nstructured delineation is beneficial for broader generaliza-\\ntion, it operates on the premise of finding a nearly perfect de-\\ncomposition in a single attempt—ideal for problems with a\\nclear-cut structure. Yet, when tasks intertwine with their de-\\ncomposition complexities (like games of 24), this method’s\\ninflexibility becomes apparent. Contrastingly, AoT not only\\nunderscores the active subproblem (as shown in Fig. 1), but\\nalso permits a more contemplative approach by entertaining\\nvarious options for each subproblem, while maintaining ef-\\nficacy even with minimal prompts.\\nTree of Thoughts (ToT). In the cases where each sub-\\nproblem has multiple viable options to explore, linear rea-\\nsoning paths from CoT or L2M substantially limit the cov-\\nerage of the thought space. Considering possible options for\\neach subproblem, the decision tree can be explored by ex-\\nternal tree-search mechanisms (e.g., BFS, DFS) (Yao et al.2023). Evaluation capabilities of LLMs can also be used to\\ndirect the search by pruning nodes that are hopeless to in-\\ncrease efficiency. However, ToT’s Achilles’ heel is its ex-\\ncessive reliance on LLM queries, at times necessitating hun-\\ndreds for just one problem. We tackle this limitation by gen-\\nerating the whole thought process within a single context.\\nAlgorithm of Thoughts\\nOur strategy pivots on recognizing a core shortcoming of\\ncurrent in-context learning paradigms. CoT, while enhanc-\\ning the coherency of thought linkages leading to solutions,\\noccasionally falters, presenting incorrect intermediate steps\\n(Zelikman et al. 2022; Turpin et al. 2023; Lanham et al.\\n2023). Faithful CoT (Lyu et al. 2023) ought to amend this\\nby eliciting symbolic chains of reasoning where the LLM’s\\noutput resembles task-specific pseudo-code, primed for de-\\nterministic execution like Python. The intention is only to\\nuse the thought processes but not the outputs and inputs of\\neach link since they have a tendency to be unreliable. But,\\nthe occasional missteps of CoT may not necessarily due to\\nthe LLM’s inability to compute correctly . The LLM, when\\nconfronted with questions that closely match conditions of\\nprevious in-context examples, may favor echoing those out-\\nputs over generating the appropriate questions. To shed light\\non this phenomenon, we designed an experiment. Querying\\ntext-davinci-003 for arithmetic tasks (e.g., ‘ 11−2 =’), we\\nprefixed them with multiple in-context equations converging\\nto an identical output (e.g. ‘ 15−5 = 10 ,8 + 2 = 10 ’). Our\\nresults, presented in Fig. 3, reveal a steep decline in accu-\\nracy, suggesting that the mere presence of correct reasoning\\nin the context might inadvertently compromise even basic\\narithmetic skills.\\nTo offset this bias, diversifying the outputs of examples\\nmight seem like a viable solution, but this could subtly skew\\nthe distribution of outputs. Merely adding unsuccessful tri-\\nals, much like a random search, might inadvertently encour-\\nage the model to retry rather than truly solve. Capturing\\nthe true essence of algorithmic behavior, where both failed\\nsearches and subsequent recovering and learning from such\\nattempts play a role, we incorporate in-context examples pat-', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 2}), Document(page_content='0 2 4 6 8 10 12\\n# of Equations0.00.20.40.60.81.0Probability of Correct T okenFigure 3: The probability of generating the correct token as\\nwe add more in-context examples that are correct but possess\\nidentical outputs.\\nterned after search algorithms , notably depth-first search\\n(DFS) and breadth-first search (BFS). See Fig. 1 for an ex-\\nample.\\nThis paper focuses on a broad class of tasks reminiscent of\\ntree-search problems. These tasks necessitate breaking down\\nthe main problem, crafting feasible solutions for each seg-\\nment, and making decisions on the paths to either pursue\\nor forsake, with the option of reevaluating more promising\\nsegmentations. Rather than posing separate queries for ev-\\nery subset, we leverage the iterative capabilities of the LLM\\nto address them in one unified generation sweep. By confin-\\ning ourselves to one or two LLM interactions, this approach\\nnaturally incorporates insights from antecedent context can-\\ndidates and tackles intricate issues requiring an in-depth ex-\\nploration of the solution domain. In alignment with our goal,\\nwe also give insights into how small or big those thoughts\\nshould be and what type of in-context examples should be\\ngiven to the LLM to promote token efficiency. Subsequently,\\nwe outline key components of tree-search algorithms and\\ntheir manifestation in our framework.\\n1. Decomposition into Subproblems. Given a problem,\\nconstructing a search tree that delineates feasible reasoning\\npathways is already a demanding task, excluding the actual\\nproblem-solving aspect. Any decomposition must consider\\nnot just the interrelations between subtasks, but also the ease\\nof addressing each individually. Consider a simple multi-\\ndigit addition: while converting numbers to binary might\\nbe efficient for a computer, humans typically find base 10\\narithmetic more intuitive. Furthermore, even if the subprob-\\nlems remain constant, their execution might vary. Intuition\\ncan lead to shortcuts between solution steps, while its ab-\\nsence might necessitate more detailed steps. Crafting the\\nright prompt (i.e., in-context algorithmic examples) hinges\\non these nuances, determining the minimal tokens an LLM\\nwould need for dependable performance. This is not only\\nessential to fit within the LLM’s context constraints but also\\nvital for efficacy, as we’d expect LLMs to address problems\\nresonant with its context using a similar token volume.\\n2. Proposing Solutions to Subproblems. A dominant ap-\\nproach in existing works involves direct sampling from\\nLLM token output probabilities (Wang et al. 2022; Yao\\nThe \\nfirst \\nfive \\nprime \\nnumbers:\\nText \\nCompletion\\n2 \\n= \\n87.6%\\n1 \\n= \\n12.3%\\n...\\n...\\n2, \\n3, \\n5, \\n7, \\n11\\nprobabilities \\nfor \\nthe \\nfirst \\ntokenFigure 4: An example highlighting the drawback of isolated\\nsampling of sequenced ideas. Input is denoted in blue, with\\nthetext-davinci-003 providing the green completions.\\net al. 2023). Though effective for one-off answers (Kadavath\\net al. 2022) (with certain constraints (Robinson and Wingate\\n2022)), this method falls short in scenarios demanding a se-\\nquence of samples to be integrated or evaluated within sub-\\nsequent prompts (Robinson and Wingate 2022). To mini-\\nmize model queries, we adopt an uninterrupted solution cre-\\nation process. Here, we directly and continuously generate\\nsolutions for the prevailing subproblem without any genera-\\ntion pauses.\\nThe benefits are three-fold. First, with all generated solu-\\ntions existing within a shared context, there’s no need for in-\\ndividual model queries for each solution evaluation. Second,\\nwhile it may seem counterintuitive initially, isolated token or\\ntoken group probabilities might not always yield meaning-\\nful choices. A simple illustration is found in Fig. 4. When\\nevaluated independently, the second-most probable token for\\nour inaugural number is ‘ 1’—not qualifying as prime. But,\\nwhen generation remains unbroken, the derived sequence is\\ncorrect. This incongruence points towards the restrictive na-\\nture of the Markov property in sequence modeling. Core to\\nour perspective is the premise that for sequential tasks like\\nalgorithmic search, LLMs are more adept at generating en-\\ntire sequences than intermittently pausing and re-initiating\\nthe token sampling process.\\n3. Gauging the Promise of a Subproblem. As above,\\nexisting techniques lean on additional prompting to dis-\\ncern the potential of tree nodes, aiding decisions regard-\\ning exploration direction. Our observations suggest that if\\nthe most promising routes are encapsulated within the in-\\ncontext examples, LLMs inherently gravitate towards prior-\\nitizing those promising candidates. This diminishes the need\\nfor intricate prompt engineering and allows the incorpora-\\ntion of intricate heuristics, whether intuitive or knowledge-\\ndriven. Again, the absence of disjoint prompts in our ap-\\nproach allows for an immediate assessment of candidate vi-\\nability in the same generation.\\n4. Backtracking to a Preferable Juncture. The decision\\nof which node to explore next (including retracing to a prior\\nnode) inherently depends on the selected tree-search algo-\\nrithm. While previous studies (Yao et al. 2023) have em-\\nployed external means such as coded mechanisms for the\\nsearch process, this restricts its broader appeal and entails\\nadditional customization. Our designs predominantly adopt\\na DFS approach supplemented by pruning. The aim is to', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 3}), Document(page_content='maintain proximity between nodes sharing the same par-\\nent, thereby encouraging the LLM to prioritize local over\\ndistant features. Additionally, we present performance met-\\nrics for the AoT approach grounded in BFS. Our reliance\\non the model’s inherent capacity to glean insights from in-\\ncontext examples obviates the necessity for additional, be-\\nspoke mechanisms.\\nExperiments\\nWe show that AoT surpasses the performance of other\\nsingle-prompt methods (e.g. standard, CoT/-SC prompting)\\nwhile remaining competitive even when compared to meth-\\nods that utilize external mechanisms, such as ToT, in bench-\\nmarks like the game of 24 and 5x5 mini crosswords.\\nGame of 24\\nThe game of 24 is a mathematical card game in which play-\\ners are given four numbers and must use addition, subtrac-\\ntion, multiplication, and division (each operation can be used\\nmore than once) to manipulate those numbers to total 24.\\nFor instance, for the numbers ‘ 8 8 5 4 ’, one solution would\\nbe ‘8∗(5−(8/4)) = 24 ’. At first glance, the game might\\nappear straightforward. However, a cursory calculation sug-\\ngests there are nearly 13,000 distinct expressions possible\\nfor any set of four numbers (without accounting for the com-\\nmutative properties of addition and multiplication), making\\nit a formidable challenge for present-day LLMs.\\nTask Setup. Adhering to the setup detailed in (Yao et al.\\n2023), we use games from indices 901-1000, sourced from\\nthe 1362 games ranked by relative difficulty at 4nums.com .\\nFor an attempt to be considered successful, it must derive a\\ntotal of 24 using the exact numbers provided and only the\\nallowed operations.\\nBaselines. Standard prompting and CoT are used in the 5-\\nshot setting, with CoT integrating 3 steps for the operations.\\nThese methods are sampled 100 times, and the averaged suc-\\ncess rates from these samples are reported. CoT-SC is also\\ntested with 100 votes in our setup. For ToT, we use a breadth\\nof 5. The performance metrics from their study are directly\\ncited to obviate the need for needless carbon emissions.\\nAoT Setup. We employ the same 5-shot setting as in stan-\\ndard prompting and CoT baseline setup. Our in-context sam-\\nples leverage a DFS-style search algorithm, which, for clar-\\nity, is the same version used when contrasting with tra-\\nditional DFS in Fig. 5. During each subtree exploration,\\ndubbed either the ‘first step’ or ‘first operation’, we choose\\ntwo numbers—illustrated by the selection of 8 and 6 in the\\nthird ’first step’ (i.e., subtree labeled ‘3’) of Fig. 1—and a\\ncorresponding operation (e.g., 8−6). This operation results\\nin a new number, 2, leaving us with three numbers in total.\\nA thorough combing of these three numbers culminates in\\n19 leaf nodes, all visible under the ‘3’ subtree in Fig. 1. We\\naim to assess two aspects: the ability of the LLM to pin-\\npoint promising first operations, which directly impacts the\\nnumber of resolved leaf nodes, and its performance against\\na conventional DFS. Details on the prompts we employed\\nare provided in the Appendix. As our method emphasizessequential generation over trajectory sampling, we operate\\nwith a temperature setting of 0.\\nResults. From Table 1, it’s evident that standard prompt-\\ning combined with CoT/-SC significantly lags behind tree\\nsearch methods when used with LLMs. The “Standard + Re-\\nfine” result, showing a 27% success rate, is referenced from\\n(Yao et al. 2023). This method involves iteratively asking\\nthe LLM (up to 10 iterations) to refine its answer if the initial\\none is incorrect. Meanwhile, ToT is limited to a maximum of\\n100 node visits, translating to several hundred LLM queries\\nfor each example. Remarkably, AoT achieves its results with\\njust a single query . Despite reducing the number of requests\\nby more than a factor of 100, AoT still outperforms ToT in\\nthis task.\\nMethod Success Avg. Queries\\nStandard Prompting 7.3% 1\\nCoT 4.0% 1\\nCoT-SC (k= 100) 9 .0% 100\\nStandard + Refine 27% 10\\nToT (b= 5) 69% 109 .1\\nAoT (ours) 71% 1\\nTable 1: Game of 24: success rates and the average number\\nof LLM queries for each example.\\nError Analysis. Using a strictly LLM-centric approach—\\neschewing any external tooling or edits—we sought to cat-\\negorize mistakes observed during the game of 24. This aids\\nin highlighting areas for refinement when solely deploying\\nLLMs. We’ve classified these errors into four distinct, ex-\\nhaustive categories: 1)Out-of-token error: The LLM reaches\\nits maximum token threshold without identifying a solution.\\n2)Expression misstep: The LLM has the correct logic or\\nsteps but fails when trying to express or formulate them into\\na coherent answer. 3)Non-finalization error: The LLM dis-\\ncovers the solution but continues its search without consol-\\nidating the finding. 4)Other errors: This umbrella term en-\\ncompasses other mistakes like computational errors that re-\\nsult in overlooking the solution or furnishing incorrect an-\\nswers. To exclusively showcase the AoT’s search capabil-\\nities, we also present the AoT + Manual Resolution ver-\\nsion. Here, once the LLM pinpoints a solution, its final ar-\\nticulation is manually processed—a strategy also employed\\nby the ToT method. As evidenced in Table 2, a notable\\n7% of mistakes stem from non-algorithmic factors like non-\\nfinalization and expression missteps. In fact, with manual\\nresolution, AoT attains a 78% success rate, surpassing ToT.\\nThis underlines the potential for refining our prompt, espe-\\ncially in areas concerning recognizing and expressing suc-\\ncessful problem resolutions. Additionally, the token limi-\\ntation underscores the appeal of expanding the generative\\ncontext window, which may further bolster LLMs’ recursive\\nreasoning when engaged with algorithmic examples.', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 4}), Document(page_content='Error Type Error\\nOut-of-token error 9%\\nExpression misstep 4%\\nNon-finalization error 3%\\nOthers 13%\\nMethod Success\\nToT 69%\\nAoT 71%\\nAoT + Manual Resolution 78%\\nTable 2: Game of 24: AoT error analysis.\\nMini Crosswords\\nThe 5×5mini crossword is a compact word puzzle featur-\\ning a grid of 25 squares arranged in a 5-by-5configuration.\\nPlayers are tasked with filling the grid based on provided\\nclues for each word. Clues are given for words that run both\\nacross (horizontally) and down (vertically). Words intersect\\nat certain letters, offering additional hints to complete the\\npuzzle.\\nTask Setup. Adhering to the setup outlined in (Yao et al.\\n2023), we draw our prompts from games 136, 141, 146, 151,\\nand 156 out of the 156 games available on goobix.com . Our\\ntesting focuses on a set of 20 games, specifically games 1, 6,\\n. . ., 91, and 96.\\nBaselines. Mirroring our approach for the game of 24, we\\nbenchmark our method against established techniques: stan-\\ndard prompting, CoT, and ToT. For standard prompting, we\\nprovide both the crosswords and their respective solutions\\nas in-context examples. CoT augments this by prompting\\nthe retrieval of words for each of the ten clues—equally split\\nbetween horizontal and vertical orientations. We directly ex-\\ntract the success rates of ToT from their original publication\\nfor comparison.\\nAoT Setup. We divide the process into two steps, each in-\\nvolving a query. Initially, we task the LLM with suggesting\\nfive potential words for each row and column. We then pin-\\npoint the starting word candidates that have the highest com-\\npatibility with other words within the crossword framework.\\nThis preliminary phase mirrors a ’warm-up’ sequence in al-\\ngorithm initialization. In the subsequent step, we exclusively\\nleverage the LLM’s algorithmic reasoning prowess, starting\\nwith the pre-selected word. The method involves cyclically\\nchoosing a likely option (specifically, a row or column) for\\ninsertion, generating candidate words, and assessing their\\ncompatibility with the words already on the board. If no\\nmatch is found, the process shifts focus to another promising\\ncandidate. Otherwise, the word is added to the crossword,\\nand the search continues. The cycle concludes either when\\nthe board is fully populated or no more suitable words can be\\nfound, which may be due to either incorrect existing words\\nor the absence of matching words. Notably, this entire pro-\\ncess unfolds within a single generation window. The algo-\\nrithmic examples in our prompt (detailed in the Appendix)include three that achieve game completion and two that pre-\\ndominantly populate the crossword, filling 8 or 9 slots.\\nResults. Table 3 underscores AoT’s proficiency in the\\nmini crosswords task, showcasing a word success rate—a\\nmeasure used in existing studies to represent the percent-\\nage of words correctly completed out of the total—that sur-\\npasses earlier methods reliant on various prompting tech-\\nniques. However, it trails behind ToT. An important observa-\\ntion is the sheer volume of queries ToT employs, exceeding\\nAoT’s by over a factor of 100. One factor hindering AoT\\nfrom surpassing ToT is that the backtracking capability in-\\nherent in the algorithmic example isn’t fully activated. Fully\\nunlocking this capability would lead to a significant elonga-\\ntion in the generation phase. In contrast, ToT has the advan-\\ntage of leveraging external memory for its backtracking.\\nMethod Word Success Avg. Queries\\nStandard Prompting 14% 1\\nCoT 15.6% 1\\nToT 60% >200\\nAoT (ours) 52% 2\\nTable 3: 5×5mini crosswords word: word success rates and\\nthe average number of LLM queries for each example.\\nError Analysis. To understand the prevalent mistakes\\nmade by AoT, we’ve categorized the errors into four dis-\\ntinct categories. In our analysis for each game, we focus on\\nthe initial error the LLM produces while charting its rea-\\nsoning path, given that an early error typically cascades into\\nsubsequent failures. 1)No preselections: LLM fails to gen-\\nerate compatible words essential for the warm-start phase.\\nGiven a correctly preselected word, the second phase for re-\\ncursive reasoning can exhibit errors including: 2)Expres-\\nsion misstep: The LLM mistakenly believes it has exhausted\\nall choices and jumps to an answer prematurely. 3)Incor-\\nrect pattern extraction: The LLM wrongly extracts a pattern\\nbased on the current board layout. 4)Erroneous word place-\\nment: Despite recognizing the correct pattern, the LLM se-\\nlects a mismatched word or misses better-fitting alternatives.\\nNavigating the crossword complexity arises from outdated\\nterms, esoteric references, and typographical mishaps. Pre-\\ndominantly, the errors observed are due to misguided word\\nplacements followed by pattern misinterpretations. Also, the\\nLLM seems challenged in aligning letters at precise indices\\nto create word structures— an obstracle circumvented by an\\nexternal mechanism in the ToT framework.\\nDiscussion\\nIn this section, we delve into crucial aspects to consider\\nwhen crafting prompts for AoT, using the game of 24 as our\\nprimary case study.\\nCan AoT surpass the DFS it’s patterned after? A core\\nquery of ours is to ascertain if the LLM has the capability\\nto not only mirror but also outdo the efficiency of the al-\\ngorithm introduced in-context. As evidenced in Fig. 5, AoT', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 5}), Document(page_content='Error Type Error\\nNo preselections 15.8%\\nExpression misstep 5.3%\\nIncorrect pattern extraction 26.3%\\nErroneous word placement 52.6%\\nTable 4: Breakdown of errors in 5×5mini crosswords with\\nAoT. Numbers indicate the relative percentage of each error\\ntype among all errors.\\nsystematically navigates fewer nodes than its DFS counter-\\npart. While DFS employs a uniform strategy when choosing\\nthe subsequent subtree to investigate, AoT’s LLM integrates\\nits inherent heuristic. This amplification over the base algo-\\nrithm exemplifies the advantages of LLM’s recursive reason-\\ning capability.\\n0 200 400 600 800 1000\\n# of Visited Nodes048121620# of Games\\nDFS\\nAoT\\nFigure 5: Histogram showing the number of visited nodes\\nfor AoT and DFS in the Game of 24.\\nHow does algorithm selection influence AoT’s efficacy?\\nTo explore the impact of algorithm choice on AoT’s per-\\nformance, we implemented both BFS and random search\\nwithin the AoT framework. Our findings, presented in Ta-\\nble 5, reveal that all three AoT variations outperform the\\nsingle-query CoT. This outcome was anticipated as AoT, ir-\\nrespective of the algorithm, undertakes a search and revis-\\nits potential mistakes—either by random retry in the ran-\\ndom search variant or through backtracking in the DFS and\\nBFS configurations. Notably, the structured search versions,\\nAoT (DFS) and AoT (BFS), displayed better efficiency than\\nAoT (Random), underscoring the advantage of algorithmic\\ninsights in solution discovery. However, AoT (BFS) lagged\\nbehind AoT (DFS). Closer inspection of errors made by AoT\\n(BFS) revealed the LLM faced greater challenges in identi-\\nfying optimal operations than its DFS counterpart.\\nHow does the search step count within the algorithmic\\nexample modulate AoT’s behavior? We begin with the\\nstandard AoT prompt and modify the subtree explorations.\\nIn AoT (Short), each in-context example uses one or two\\nsteps to reach a solution, while AoT (Long) incorporates\\nthree to five extra subtree explorations. The impact on total\\nsearch steps is illustrated in Fig. 6. Our observations high-\\nlight longer generations for AoT (Long) and shorter onesMethod Success Avg. Queries\\nCoT 4% 1\\nCoT-SC (k=100) 9% 100\\nToT 69% 109 .1\\nAoT (DFS) 71% 1\\nAoT (BFS) 48% 1\\nAoT (Random) 20% 1\\nTable 5: Comparative success rates and average LLM query\\ncounts for AoT variations templated by distinct algorithms.\\nfor AoT (Short) relative to the original AoT. This suggests\\nthat the search step count introduces an implicit bias on the\\nLLM’s search velocity. Notably, even when navigating in-\\ncorrect steps, it’s essential to emphasize the exploration of\\npromising directions.\\n0 50 100 150 200 250 300 350 400\\n# of Visited Nodes020406080100# of Games\\nAoT (Short)\\nAoT\\nAoT (Long)\\nFigure 6: Comparison of AoT with shorter and longer in-\\ncontext examples prompted AoT versions: cumulative num-\\nber of games for the number of visited nodes.\\nLimitations. While AoT substantially cuts down on the\\nnumber of queries relative to ToT, its resource demands ex-\\nceed those of standard prompting and CoT, a consequence\\nof its extensive exploration of ideas via token generation.\\nCrafting token-efficient algorithmic examples is one avenue,\\nbut there’s also potential in judiciously tapping into or un-\\nlocking the LLM’s “tunnel-vision”. Our research primarily\\nspotlighted certain algorithms, with a keen focus on tree-\\nsearch tasks. It’s pertinent to highlight that we conducted our\\ntests exclusively with GPT-4. Though more costly than other\\nLLMs, GPT-4’s advanced capabilities appear pivotal for\\nAoT’s optimal functioning; models of lesser caliber might\\nnot yield comparable performance boosts from AoT.\\nConclusion\\nThis paper presents the Algorithm of Thoughts , a pioneer-\\ning prompting strategy to navigate reasoning pathways in\\nLLMs using minimal queries. Our findings reveal that this\\nmethod not only substantially surpasses prior single-query\\ntechniques but also rivals external tree-search implementa-\\ntions. Such an approach augments the potential to stream-\\nline idea discovery in LLMs, balancing both cost and com-\\nputational demands. Future work includes designing token-', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 6}), Document(page_content='efficient algorithmic examples, developing adaptive mecha-\\nnisms for “tunnel-vision” activation to expedite the search,\\nand deepening the understanding of this fresh mode of in-\\ncontext learning from theoretical angles.\\nReferences\\nAminabadi, R. Y .; Rajbhandari, S.; Awan, A. A.; Li, C.; Li,\\nD.; Zheng, E.; Ruwase, O.; Smith, S.; Zhang, M.; Rasley, J.;\\net al. 2022. DeepSpeed-inference: enabling efficient infer-\\nence of transformer models at unprecedented scale. In SC22:\\nInternational Conference for High Performance Computing,\\nNetworking, Storage and Analysis , 1–15. IEEE.\\nAustin, J.; Odena, A.; Nye, M.; Bosma, M.; Michalewski,\\nH.; Dohan, D.; Jiang, E.; Cai, C.; Terry, M.; Le, Q.; et al.\\n2021. Program synthesis with large language models. arXiv\\npreprint arXiv:2108.07732 .\\nBaddeley, A. 2003. Working memory: looking back and\\nlooking forward. Nature reviews neuroscience , 4(10): 829–\\n839.\\nBai, Y .; Kadavath, S.; Kundu, S.; Askell, A.; Kernion, J.;\\nJones, A.; Chen, A.; Goldie, A.; Mirhoseini, A.; McKinnon,\\nC.; Chen, C.; Olsson, C.; Olah, C.; Hernandez, D.; Drain,\\nD.; Ganguli, D.; Li, D.; Tran-Johnson, E.; Perez, E.; Kerr, J.;\\nMueller, J.; Ladish, J.; Landau, J.; Ndousse, K.; Lukosuite,\\nK.; Lovitt, L.; Sellitto, M.; Elhage, N.; Schiefer, N.; Mer-\\ncado, N.; DasSarma, N.; Lasenby, R.; Larson, R.; Ringer,\\nS.; Johnston, S.; Kravec, S.; Showk, S. E.; Fort, S.; Lanham,\\nT.; Telleen-Lawton, T.; Conerly, T.; Henighan, T.; Hume,\\nT.; Bowman, S. R.; Hatfield-Dodds, Z.; Mann, B.; Amodei,\\nD.; Joseph, N.; McCandlish, S.; Brown, T.; and Kaplan, J.\\n2022. Constitutional AI: Harmlessness from AI Feedback.\\nArXiv:2212.08073 [cs].\\nBanerjee, S.; Bringsjord, S.; Giancola, M.; and Govindara-\\njulu, N. S. 2022. Qualitative Mechanical Problem-Solving\\nby Artificial Agents:: Further Progress, Under Psychometric\\nAI. In The International FLAIRS Conference Proceedings ,\\nvolume 35.\\nBrown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;\\nDhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,\\nA.; Agarwal, S.; Herbert-V oss, A.; Krueger, G.; Henighan,\\nT.; Child, R.; Ramesh, A.; Ziegler, D.; Wu, J.; Winter,\\nC.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.;\\nChess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford,\\nA.; Sutskever, I.; and Amodei, D. 2020. Language Mod-\\nels are Few-Shot Learners. Advances in Neural Information\\nProcessing Systems , 33: 1877–1901.\\nChen, L.; Zaharia, M.; and Zou, J. 2023. FrugalGPT: How\\nto Use Large Language Models While Reducing Cost and\\nImproving Performance. arXiv preprint arXiv:2305.05176 .\\nChen, M.; Tworek, J.; Jun, H.; Yuan, Q.; Pinto, H. P. d. O.;\\nKaplan, J.; Edwards, H.; Burda, Y .; Joseph, N.; Brockman,\\nG.; et al. 2021. Evaluating large language models trained on\\ncode. arXiv preprint arXiv:2107.03374 .\\nChowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra,\\nG.; Roberts, A.; Barham, P.; Chung, H. W.; Sutton, C.;\\nGehrmann, S.; et al. 2022. Palm: Scaling language modeling\\nwith pathways. arXiv preprint arXiv:2204.02311 .Dhar, P. 2020. The carbon impact of artificial intelligence.\\nNat. Mach. Intell. , 2(8): 423–425.\\nDrozdov, A.; Sch ¨arli, N.; Aky ¨urek, E.; Scales, N.; Song, X.;\\nChen, X.; Bousquet, O.; and Zhou, D. 2022. Compositional\\nSemantic Parsing with Large Language Models.\\nHelie, S.; and Pizlo, Z. 2022. When is psychology research\\nuseful in artificial intelligence? A case for reducing compu-\\ntational complexity in problem solving. Topics in Cognitive\\nScience , 14(4): 687–701.\\nHolyoak, K. J.; and Morrison, R. G. 2005. The Cambridge\\nhandbook of thinking and reasoning . Cambridge University\\nPress.\\nHuang, J.; and Chang, K. C.-C. 2022. Towards reason-\\ning in large language models: A survey. arXiv preprint\\narXiv:2212.10403 .\\nKadavath, S.; Conerly, T.; Askell, A.; Henighan, T.; Drain,\\nD.; Perez, E.; Schiefer, N.; Hatfield-Dodds, Z.; DasSarma,\\nN.; Tran-Johnson, E.; et al. 2022. Language models (mostly)\\nknow what they know. arXiv preprint arXiv:2207.05221 .\\nKahneman, D. 2011. Thinking, fast and slow . macmillan.\\nKojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y .; and Iwasawa,\\nY . 2022. Large Language Models are Zero-Shot Reason-\\ners. Advances in Neural Information Processing Systems ,\\n35: 22199–22213.\\nLanham, T.; Chen, A.; Radhakrishnan, A.; Steiner, B.; Deni-\\nson, C.; Hernandez, D.; Li, D.; Durmus, E.; Hubinger, E.;\\nKernion, J.; et al. 2023. Measuring Faithfulness in Chain-\\nof-Thought Reasoning. arXiv preprint arXiv:2307.13702 .\\nLiang, P.; Bommasani, R.; Lee, T.; Tsipras, D.; Soylu, D.;\\nYasunaga, M.; Zhang, Y .; Narayanan, D.; Wu, Y .; Kumar,\\nA.; et al. 2022. Holistic evaluation of language models.\\narXiv preprint arXiv:2211.09110 .\\nLibby, M. E.; Weiss, J. S.; Bancroft, S.; and Ahearn, W. H.\\n2008. A comparison of most-to-least and least-to-most\\nprompting on the acquisition of solitary play skills. Behav-\\nior analysis in practice , 1: 37–43.\\nLiu, Y .; Han, T.; Ma, S.; Zhang, J.; Yang, Y .; Tian, J.; He, H.;\\nLi, A.; He, M.; Liu, Z.; et al. 2023. Summary of chatgpt/gpt-\\n4 research and perspective towards the future of large lan-\\nguage models. arXiv preprint arXiv:2304.01852 .\\nLong, J. 2023. Large Language Model Guided Tree-of-\\nThought. arXiv preprint arXiv:2305.08291 .\\nLyu, Q.; Havaldar, S.; Stein, A.; Zhang, L.; Rao, D.; Wong,\\nE.; Apidianaki, M.; and Callison-Burch, C. 2023. Faithful\\nChain-of-Thought Reasoning. ArXiv:2301.13379 [cs].\\nMialon, G.; Dess `ı, R.; Lomeli, M.; Nalmpantis, C.; Pa-\\nsunuru, R.; Raileanu, R.; Rozi `ere, B.; Schick, T.; Dwivedi-\\nYu, J.; Celikyilmaz, A.; et al. 2023. Augmented language\\nmodels: a survey. arXiv preprint arXiv:2302.07842 .\\nMonsell, S. 2003. Task switching. Trends in cognitive sci-\\nences , 7(3): 134–140.\\nOuyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright, C.;\\nMishkin, P.; Zhang, C.; Agarwal, S.; Slama, K.; Ray, A.;\\net al. 2022. Training language models to follow instructions\\nwith human feedback. Advances in Neural Information Pro-\\ncessing Systems , 35: 27730–27744.', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 7}), Document(page_content='Robinson, J.; and Wingate, D. 2022. Leveraging Large Lan-\\nguage Models for Multiple Choice Question Answering.\\nShao, Z.; Gong, Y .; Shen, Y .; Huang, M.; Duan, N.; and\\nChen, W. 2023. Synthetic Prompting: Generating Chain-\\nof-Thought Demonstrations for Large Language Models.\\nSloman, S. A. 1996. The empirical case for two systems of\\nreasoning. Psychological bulletin , 119(1): 3.\\nSrivastava, A.; Rastogi, A.; Rao, A.; Shoeb, A. A. M.; Abid,\\nA.; Fisch, A.; Brown, A. R.; Santoro, A.; Gupta, A.; Garriga-\\nAlonso, A.; et al. 2022. Beyond the imitation game: Quanti-\\nfying and extrapolating the capabilities of language models.\\narXiv preprint arXiv:2206.04615 .\\nSuzgun, M.; Scales, N.; Sch ¨arli, N.; Gehrmann, S.; Tay,\\nY .; Chung, H. W.; Chowdhery, A.; Le, Q. V .; Chi, E. H.;\\nZhou, D.; and Wei, J. 2022. Challenging BIG-Bench\\nTasks and Whether Chain-of-Thought Can Solve Them.\\nArXiv:2210.09261 [cs].\\nThoppilan, R.; De Freitas, D.; Hall, J.; Shazeer, N.; Kul-\\nshreshtha, A.; Cheng, H.-T.; Jin, A.; Bos, T.; Baker, L.; Du,\\nY .; et al. 2022. Lamda: Language models for dialog appli-\\ncations. arXiv preprint arXiv:2201.08239 .\\nTurpin, M.; Michael, J.; Perez, E.; and Bowman, S. R. 2023.\\nLanguage Models Don’t Always Say What They Think: Un-\\nfaithful Explanations in Chain-of-Thought Prompting. arXiv\\npreprint arXiv:2305.04388 .\\nWang, X.; Wei, J.; Schuurmans, D.; Le, Q. V .; Chi, E. H.;\\nNarang, S.; Chowdhery, A.; and Zhou, D. 2022. Self-\\nConsistency Improves Chain of Thought Reasoning in Lan-\\nguage Models.\\nWei, J.; Tay, Y .; Bommasani, R.; Raffel, C.; Zoph, B.;\\nBorgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler,\\nD.; Chi, E. H.; Hashimoto, T.; Vinyals, O.; Liang, P.; Dean,\\nJ.; and Fedus, W. 2022a. Emergent Abilities of Large Lan-\\nguage Models. ArXiv:2206.07682 [cs].\\nWei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Ichter, B.;\\nXia, F.; Chi, E.; Le, Q. V .; and Zhou, D. 2022b. Chain-\\nof-Thought Prompting Elicits Reasoning in Large Language\\nModels. Advances in Neural Information Processing Sys-\\ntems, 35: 24824–24837.\\nWu, C.-J.; Raghavendra, R.; Gupta, U.; Acun, B.; Ardalani,\\nN.; Maeng, K.; Chang, G.; Aga, F.; Huang, J.; Bai, C.; et al.\\n2022. Sustainable ai: Environmental implications, chal-\\nlenges and opportunities. Proceedings of Machine Learning\\nand Systems , 4: 795–813.\\nYao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.;\\nCao, Y .; and Narasimhan, K. 2023. Tree of Thoughts:\\nDeliberate Problem Solving with Large Language Models.\\nArXiv:2305.10601 [cs].\\nZelikman, E.; Wu, Y .; Mu, J.; and Goodman, N. 2022. Star:\\nBootstrapping reasoning with reasoning. Advances in Neu-\\nral Information Processing Systems , 35: 15476–15488.\\nZhang, Z.; Zhang, A.; Li, M.; and Smola, A. 2022. Auto-\\nmatic Chain of Thought Prompting in Large Language Mod-\\nels.\\nZhou, D.; Sch ¨arli, N.; Hou, L.; Wei, J.; Scales, N.; Wang,\\nX.; Schuurmans, D.; Cui, C.; Bousquet, O.; Le, Q. V .; andChi, E. H. 2022. Least-to-Most Prompting Enables Complex\\nReasoning in Large Language Models.', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 8}), Document(page_content='Game of 24 - Additional Details\\nIn order to avoid confusion in our analysis of AoT in the game of 24, we give additional details in terms of terminologies we\\nuse as well as their direct implications in the performance figures. An Illustration of these are given in Fig. 7.\\n4 \\n- \\n4 \\n= \\n8\\n(left: \\n8, \\n6, \\n0)\\n4 \\n+ \\n2 \\n= \\n6\\n(left: \\n6, \\n4)\\n4 \\n/ \\n4 \\n= \\n1\\n(left: \\n2, \\n1)\\n6 \\n* \\n4 \\n= \\n24\\n(left: \\n24)\\n6 \\n+ \\n4 \\n= \\n10\\n(left: \\n10)\\n...\\nInput: \\n8 \\n6 \\n4 \\n4\\nFirst \\nOperations\\nSecond \\nOperations\\nThird \\nOperations\\nVisited \\nNodes\\n8 \\n- \\n6 \\n= \\n2\\n(left: \\n4, \\n4, \\n2)\\n...\\nSubtree \\nExploration\\nFigure 7: An illustration of terminologies we use for the game of 24. The yellow nodes represent the first operations and the\\nstates they lead to; the green node represents the node where we find the solution; all other nodes are represented by pink.\\nFirst operations / First iterations. This represents the scenario that after we choose the first two number in the game of 24,\\nthe case of either adding, subtracting, multiplying or dividing them.\\nSubtree Exploration. This denotes searching all or most of the nodes coming from the same state, typically states with less\\nthan four numbers left.\\nNumber of nodes visited. This is the number of states that the method has been on the game of 24. Each state is the set of\\nnumber we are left with, after our operations in the numbers. For example, after the first operation we might be left with the\\nnumbers ‘ 831’. This set of numbers represent a state, as well as the state of ‘ 83’ that we will be left with after another operation\\nof ‘8∗1 = 8 ’.\\nCreative Writing\\nWe use the creative writing task, also used by (Yao et al. 2023), where the LLM is provided with four arbitrary sentences.\\nThe objective is to craft a cohesive narrative divided into four paragraphs, with each paragraph culminating in one of the given\\nsentences. This exercise not only fosters creativity but also emphasizes strategic deliberation.\\nTask Setup\\nSentences are randomly sourced from randomwordgenerator.com , resulting in 100 distinct sets of inputs. Given the absence of\\npredetermined correct answers, the primary focus lies in evaluating the coherence of the responses. We have noted that GPT-4\\nconsistently aligns with these input guidelines. Evaluation is centered around assessing passage coherence using a GPT-4 zero-\\nshot prompt, where each output is rated on a scale of 1 to 10. Each task response undergoes five such evaluations, with their\\nscores being averaged subsequently.\\nBaselines\\nFor this task, both standard and CoT prompts are employed without preliminary training. While the standard prompt directly\\nguides the LLM to fashion a cohesive narrative based on stipulated parameters, the CoT prompt obliges the model to initially\\noutline a succinct plan prior to drafting the narrative, serving as an intermediate cognitive bridge. For each task iteration,\\nten samples are generated using both the standard and CoT methods. Results of the ToT approach are presented without\\nmodification.', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 9}), Document(page_content='AoT Setup\\nMirroring ToT’s methodology, the task is tackled in a zero-shot setting. Our prompt instructs the model to first formulate five\\ndistinct plans. Subsequent to this, the model selects the most promising among them to shape a narrative and then refines it for\\noptimal coherence. The exact prompts used for this zero-shot approach will be provided in the subsequent section.\\nResults\\nAs depicted in Fig. 8, AoT outpaces other singular query prompting techniques such as standard prompting and CoT in terms\\nof performance. It also exhibits a marked improvement over ToT, although the difference is not statistically significant. Com-\\nprehensive scores, along with the average query count needed for each method, are consolidated in Table 6. Notably, AoT\\nnecessitates fewer queries compared to ToT.\\nStandard CoT T oT AoT0246810\\nFigure 8: Comparison of the standard prompting, CoT, ToT and AoT on the creative writing task.\\nMethod Score Avg. Queries\\nStandard Prompting 6.19 1\\nCoT 6.93 1\\nToT 7.56 20\\nAoT 7.58 1\\nTable 6: Performance of the methods determined by GPT-4.\\nCoT vs. Single Iteration AoT in the Game of 24\\nTo demonstrate that the tree search mechanism is fundamentally distinct from the CoT prompting, even in scenarios where\\nAoT’s in-context examples include only a single initial operation in the game of 24, we draw a comparison between AoT\\n(Short) and CoT. In this setup, AoT (Short) determines the first operation and subsequently conducts a tree search on the\\nremaining three numbers. Interestingly, AoT (Short) achieves a success rate of 48%, while CoT lags significantly, securing\\nonly 4%. These results underscore the notion that even a rudimentary search mechanism can lead to significant performance\\nenhancements.\\nDetailed Analysis on the Effect of the Length of the Prompts\\nIn this section, we delve deeper into Fig. 6 by presenting histograms for the successful, unsuccessful, and total games of ‘24’,\\nconsidering the number of initial steps in methods AoT (Short), AoT, and AoT (Long). These are displayed in Figs. 9-11.\\nFrom these figures, it becomes evident that the length of the prompts, measured by the number of initial steps included in\\nin-context examples, correlates with the length of their solutions to test examples. This trend is consistent across all three cases,\\nsuggesting that AoT’s strategy in determining the number of initial steps is influenced by its in-context examples.\\nInterestingly, when AoT is provided a well-balanced set of initial steps that emphasize the most promising operations, it\\nexcels in solving the majority of games in earlier iterations. This indicates AoT’s capacity to prioritize swift problem-solving\\nwithout sacrificing performance. This tendency is also observed in AoT (Long), albeit with a somewhat reduced success rate,\\nas illustrated in Fig. 9.', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 10}), Document(page_content='0 2 4 6 8 10 1202040\\n0 2 4 6 8 10 1202040# of Successful Games\\n0 2 4 6 8 10 12\\n# of First Steps02040\\nAoT (Short)\\nAoT\\nAoT (Long)Figure 9: Histogram of the number of successful games with respect to the number of first steps for AoT (Short), AoT and AoT\\n(Long).\\n0 2 4 6 8 10 1202040\\n0 2 4 6 8 10 1202040# of Unsuccessful Games\\n0 2 4 6 8 10 12\\n# of First Steps02040AoT (Short)\\nAoT\\nAoT (Long)\\nFigure 10: Histogram of the number of unsuccessful games with respect to the number of first steps for AoT (Short), AoT and\\nAoT (Long).\\nPrompts\\nGame of 24\\nBelow, we represent the specific prompts employed for the various methods detailed in the experiments section. It’s important\\nto note that the terms “System”,“User”, and “Assistant” are utilized to denote the roles within the OpenAI API when operating\\nin chat completion mode. The line breaks serve to show the transitions between the user and assistant interactions within the\\nAPI.\\nAoT (DFS)\\nSystem:', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 11}), Document(page_content='0 2 4 6 8 10 12050100\\n0 2 4 6 8 10 12050100# of All Games\\n0 2 4 6 8 10 12\\n# of First Steps050100\\nAoT (Short)\\nAoT\\nAoT (Long)Figure 11: Histogram of the number of all games with respect to the number of first steps for AoT (Short), AoT and AoT\\n(Long).\\nUse numbers and basic arithmetic operations (+ - */) to obtain 24. When\\nconsidering the next steps, do not choose operations that will result in a\\nnegative or fractional number. In order to help with the calculations, the\\nnumbers in the parenthesis represent the numbers that are left after the\\noperations and they are in descending order.\\nAnother thing we do is when there are only two numbers left in the parenthesis, we\\ncheck whether we can arrive at 24 only by using basic arithmetic operations\\n(+ - */). Some examples regarding this idea:\\n(21 2) no\\nsince 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\\nto 24.\\n(30 6) 30 - 6 = 24 yes\\n(8 3) 8 *3 = 24 yes\\n(12 8) no\\n(48 2) 48 / 2 = 24 yes\\nMost importantly, do not give up, all the numbers that will be given has indeed a\\nsolution.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n14 8 8 2\\nAssistant:\\nTrying a promising first operation:\\n1. 8 + 2: (14, 10, 8)\\n- 14 + 10: (24, 8) 32, 16, 192, 3\\n- 14 - 10: (8, 4) 12, 8, 32, 2\\n- 14 *10: (140, 8) 148, 132, 1120, fractional\\n- 14 / 10: (8, 1.4) fractional\\n- 14 + 8: (22, 10) 32, 12, 220, fractional\\n- 14 - 8: (10, 6) 16, 4, 60, fractional\\n- 14 *8: (112, 10) 122, 102, 1120, fractional\\n- 14 / 8: fractional\\n- 10 + 8: (18, 14) 32, 4, 252, fractional\\n- 10 - 8: (14, 2) 16, 12, 28, 7\\n- 10 *8: (80, 14) 94, 66, big, fractional\\n- 10 / 8: fractional', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 12}), Document(page_content='Trying another promising first operation:\\n2. 8 / 2: (14, 8, 4)\\n- 14 + 8: (22, 4) 26, 18, 88, fractional\\n- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 2 = 4\\nStep 2:\\n14 - 8 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\\nanswer: (14 - 8) *(8 / 2) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 5 5 5\\nAssistant:\\nTrying a promising first operation:\\n1. 9 - 5: (5, 5, 4)\\n- 5 + 5: (10, 4) 14, 6, 40, fractional\\n- 5 - 5: (4, 0) 4, 4, 0, undefined\\n- 5 *5: (25, 4) 29, 21, 100, fractional\\n- 5 / 5: (4, 1) 5, 3, 4, 4\\n- 5 + 4: (9, 5) 14, 4, 45, fractional\\n- 5 - 4: (5, 1) 6, 4, 5, 0.2\\n- 5 *4: (20, 5) 25, 15, 100, fractional\\n- 5 / 4: fractional\\nTrying another promising first operation:\\n2. 5 + 5: (10, 9, 5)\\n- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\\nBacktracking the solution:\\nStep 1:\\n5 + 5 = 10\\nStep 2:\\n10 + 9 = 19\\nStep 3:\\n19 + 5 = 24\\nConsidering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\\nanswer: ((5 + 5) + 9) + 5 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 6 4 4\\nAssistant:\\nTrying a promising first operation:\\n1. 8 - 6: (4, 4, 2)\\n- 4 + 4: (8, 2) 10, 6, 16, 4\\n- 4 - 4: (2, 0) 2, 2, 0, undefined\\n- 4 *4: (16, 2) 18, 14, 32, 8\\n- 4 / 4: (2, 1) 3, 1, 2, 2\\n- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 - 6 = 2\\nStep 2:\\n4 + 2 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\\nanswer: (4 + (8 - 6)) *4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 10 9 4\\nAssistant:', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 13}), Document(page_content='Trying a promising first operation:\\n1. 13 - 4: (10, 9, 9)\\n- 10 + 9: (19, 9) 28, 10, 171, fractional\\n- 10 - 9: (9, 1) 10, 8, 9, 9\\n- 10 *9: (90, 9) 99, 81, 810, fractional\\n- 10 / 9: fractional\\n- 9 + 9: (18, 10) 28, 8, 180, fractional\\n- 9 - 9: (10, 0) 10, 10, 0, undefined\\n- 9 *9: (81, 10) 91, 71, 810, fractional\\n- 9 / 9: (10, 1) 11, 9, 10, 10\\nTrying another promising first operation:\\n2. 10 - 4: (13, 9, 6)\\n- 13 + 9: (22, 6) 28, 16, 132, fractional\\n- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n10 - 4 = 6\\nStep 2:\\n13 - 9 = 4\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\\nanswer: (10 - 4) *(13 - 9) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 8 5 4\\nAssistant:\\nTrying a promising first operation:\\n1. 8 - 4: (8, 5, 4)\\n- 8 + 5: (13, 4) 17, 9, 52, fractional\\n- 8 - 5: (4, 3) 7, 1, 12, fractional\\n- 8 *5: (40, 4) 44, 36, 160, fractional\\n- 8 / 5: fractional\\n- 8 + 4: (12, 5) 17, 7, 60, fractional\\n- 8 - 4: (5, 4) 9, 1, 20, fractional\\n- 8 *4: (32, 5) 37, 27, 160, fractional\\n- 8 / 4: (5, 2) 7, 3, 10, 2.5\\n- 5 + 4: (9, 8) 17, 1, 72, fractional\\n- 5 - 4: (8, 1) 9, 7, 8, 8\\n- 5 *4: (20, 8) 28, 12, 160, fractional\\n- 5 / 4: fractional\\nTrying another promising first operation:\\n2. 8 / 4: (8, 5, 2)\\n- 8 + 5: (13, 2) 15, 11, 26, fractional\\n- 8 - 5: (3, 2) 5, 1, 6, 1.5\\n- 8 *5: (40, 2) 42, 38, 80, 20\\n- 8 / 5: fractional\\n- 8 + 2: (10, 5) 15, 5, 50, 2\\n- 8 - 2: (6, 5) 11, 1, 30, fractional\\n- 8 *2: (16, 5) 21, 11, 80, fractional\\n- 8 / 2: (5, 4) 9, 1, 20, fractional\\n- 5 + 2: (7, 8) 15, 1, 56, fractional\\n- 5 - 2: (8, 3) 11, 5, 24 = 8 *3 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 4 = 2\\nStep 2:\\n5 - 2 = 3\\nStep 3:\\n8*3 = 24\\nConsidering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\\nanswer: 8 *(5 - (8 / 4)) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 14}), Document(page_content='User:\\n11 11 1 1\\nAssistant:\\nTrying a promising first operation:\\n1. 11 - 1: (11, 10, 1)\\n- 11 + 10: (21, 1) 22, 20, 21, 21\\n- 11 - 10: (1, 1) 2, 0, 1, 1\\n- 11 *10: (110, 1) 111, 109, 110, 110\\n- 11 / 10: fractional\\n- 11 + 1: (12, 10) 22, 2, 120, 1.2\\n- 11 - 1: (10, 10) 20, 0, 100, 1\\n- 11 *1: (11, 10) 21, 1, 110, 1.1\\n- 11 / 1: (11, 10) 21, 1, 110, fractional\\n- 10 + 1: (11, 11) 22, 0, 121, 1\\n- 10 - 1: (11, 9) 20, 2, 99, 1.1\\n- 10 *1: (11, 10) 21, 1, 110, 1.1\\n- 10 / 1: (11, 10) 21, 1, 110, 1.1\\nTrying another promising first operation:\\n2. 11 + 1: (12, 11, 1)\\n- 12 + 11: (23, 1) 24 = 23 + 1 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11 + 1 = 12\\nStep 2:\\n12 + 11 = 23\\nStep 3:\\n23 + 1\\nConsidering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\\nanswer: ((11 + 1) + 11) + 1 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 7 4 1\\nAssistant:\\nTrying a promising first operation:\\n1. 7 *4: (28, 11, 1)\\n- 28 + 11: (39, 1) 40, 38, 39, 39\\n- 28 - 11: (17, 1) 18, 16, 17, 17\\n- 28 *11: (308, 1) 309, 307, 308, 308\\n- 28 / 11: fractional\\n- 28 + 1: (29, 11) 40, 18, 319, fractional\\n- 28 - 1: (27, 11) 38, 16, 297, fractional\\n- 28 *1: (28, 11) 39, 17, 308, fractional\\n- 28 / 1: (28, 11) 39, 17, 308, fractional\\n- 11 + 1: (29, 28) 57, 1, 812, fractional\\n- 11 - 1: (28, 10) 38, 18, 280, fractional\\n- 11 *1: (28, 11) 39, 17, 308, fractional\\n- 11 / 1: (28, 11) 39, 17, 308, fractional\\nTrying another promising first operation:\\n2. 7 + 1: (11 8 4)\\n- 11 + 8: (19, 4) 23, 15, 76, fractional\\n- 11 - 8: (4, 3) 7, 1, 12, fractional\\n- 11 *8: (88, 4) 92, 84, 352, fractional\\n- 11 / 8: fractional\\n- 11 + 4: (15, 8) 23, 7, 120, fractional\\n- 11 - 4: (7, 8) 15, -1, 56, fractional\\n- 11 *4: (44, 8) 52, 36, 352, fractional\\n- 11 / 4: fractional\\n- 8 + 4: (12, 11) 23, -1, 132, fractional\\n- 8 - 4: (11, 4) 15, 7, 44, fractional\\n- 8 *4: (32, 11) 43, 21, 352, fractional\\n- 8 / 4: (11, 2) 13, 9, 22, fractional\\nTrying another promising first operation:', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 15}), Document(page_content='3. 4 + 1: (11 7 5)\\n- 11 + 7: (18, 5) 23, 13, 90, fractional\\n- 11 - 7: (5, 4) 9, 1, 20, fractional\\n- 11 *7: (77, 5) 82, 72, 385, fractional\\n- 11 / 7: fractional\\n- 11 + 5: (16, 7) 23, 9, 112, fractional\\n- 11 - 5: (7, 6) 13, 1, 42, fractional\\n- 11 *5: (55, 7) 62, 48, 385, fractional\\n- 11 / 5: fractional\\n- 7 + 5: (12, 11) 23, 1, 132, fractional\\n- 7 - 5: (11, 2) 13, 9, 22, fractional\\n- 7 *5: (35, 11) 46, 24 = 35 - 11 -> found it!\\nStep 1:\\n4 + 1 = 5\\nStep 2:\\n7*5 = 35\\nStep 3:\\n35 - 11 = 24\\nConsidering these steps: Backtracking the solution:\\n24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\\nanswer: (7 *(4 + 1)) - 11 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 5 4 3\\nAssistant:\\nTrying a promising first operation:\\n1. 5 *4: (20, 11, 3)\\n- 20 + 11: (31, 3) 34, 28, 93, fractional\\n- 20 - 11: (9, 3) 12, 6, 27, 3\\n- 20 *11: (220, 3) 223, 217, 660, fractional\\n- 20 / 11: fractional\\n- 20 + 3: (23, 11) 34, 12, 253, fractional\\n- 20 - 3: (17, 11) 28, 6, 187, fractional\\n- 20 *3: (60, 11) 71, 49, 660, fractional\\n- 20 / 3: fractional\\n- 11 + 3: (14, 20) 34, -6, 280, fractional\\n- 11 - 3: (8, 20) 28, -12, 160, fractional\\n- 11 *3: (33, 20) 53, 13, 660, fractional\\n- 11 / 3: fractional\\nTrying another promising first operation:\\n2. 11 - 3: (8, 5, 4)\\n- 8 + 5: (13, 4) 17, 9, 52, fractional\\n- 8 - 5: (4, 3) 7, 1, 12, fractional\\n- 8 *5: (40, 4) 44, 36, 160, fractional\\n- 8 / 5: fractional\\n- 8 + 4: (12, 5) 17, 7, 60, fractional\\n- 8 - 4: (5, 4) 9, 1, 20, fractional\\n- 8 *4: (32, 5) 37, 27, 160, fractional\\n- 8 / 4: (5, 2) 7, 3, 10, 2.5\\n- 5 + 4: (9, 8) 17, 1, 72, fractional\\n- 5 - 4: (8, 1) 9, 7, 8, 8\\n- 5 *4: (20, 8) 28, 12, 160, fractional\\n- 5 / 4: fractional\\nTrying another promising first operation:\\n3. 11 *3: (33, 5, 4)\\n- 33 + 5: (38, 4) 42, 34, 152, fractional\\n- 33 - 5: (28, 4) 32, 24 = 28 - 4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11*3 = 33\\nStep 2:\\n33 - 5 = 28\\nStep 3:', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 16}), Document(page_content='28 - 4 = 24\\nConsidering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\\nanswer: ((11 *3) - 5) - 4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 12 5 2\\nAssistant:\\nTrying a promising first operation:\\n1. 12 + 2: (14, 13, 5)\\n- 14 + 13: (27, 5) 32, 22, 135, fractional\\n- 14 - 13: (5, 1) 6, 4, 5, 5\\n- 14 *13: (182, 5) 187, 177, 910, fractional\\n- 14 / 13: fractional\\n- 14 + 5: (19, 13) 32, 6, 247, fractional\\n- 14 - 5: (13, 9) 22, 4, 117, fractional\\n- 14 *5: (70, 13) 83, 57, 910, fractional\\n- 14 / 5: fractional\\n- 13 + 5: (18, 14) 32, 4, 252, fractional\\n- 13 - 5: (14, 8) 22, 6, 112, fractional\\n- 13 *5: (65, 14) 79, 51, 910, fractional\\n- 13 / 5: fractional\\nTrying another promising first operation:\\n2. 13 + 5: (18, 12, 2)\\n- 18 + 12: (30, 2) 32, 28, 60, fractional\\n- 18 - 12: (6, 2) 8, 4, 12, 3\\n- 18 *12: (216, 2) 218, 214, 432, fractional\\n- 18 / 12: fractional\\n- 18 + 2: (20, 12) 32, 8, 240, fractional\\n- 18 - 2: (16, 12) 28, 4, 192, fractional\\n- 18 *2: (36, 12) 48, 24 = 36 - 12 -> found it!\\nBacktracking the solution:\\nStep 1:\\n13 + 5 = 18\\nStep 2:\\n18*2 = 36\\nStep 3:\\n36 - 12 = 24\\nConsidering these steps: 24 = 36 - 12 = (18 *2) - 12 = ((13 + 5) *2) - 12 = 24.\\nanswer: ((13 + 5) *2) - 12 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 8 2 1\\nAssistant:\\nTrying a promising first operation:\\n1. 9 - 1: (8, 8, 2)\\n- 8 + 8: (16, 2) 18, 14, 32, 8\\n- 8 - 8: (2, 0) 2, 2, 0, undefined\\n- 8 *8: (64, 2) 66, 62, 128, 32\\n- 8 / 8: (2, 1) 3, 1, 2, 2\\n- 8 + 2: (10, 8) 18, 2, 80, 4\\n- 8 - 2: (6, 8) 14, -2, 48, fractional\\n- 8 *2: (16, 8) 24 = 16 + 8 -> found it!\\nBacktracking the solution:\\nStep 1:\\n9 - 1 = 8\\nStep 2:\\n8*2 = 16\\nStep 3:\\n16 + 8 = 24\\nConsidering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\\nanswer: ((9 - 1) *2) + 8 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nAoT (Long)', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 17}), Document(page_content='System:\\nUse numbers and basic arithmetic operations (+ - */) to obtain 24. When\\nconsidering the next steps, do not choose operations that will result in a\\nnegative or fractional number. In order to help with the calculations, the\\nnumbers in the parenthesis represent the numbers that are left after the\\noperations and they are in descending order.\\nAnother thing we do is when there are only two numbers left in the parenthesis, we\\ncheck whether we can arrive at 24 only by using basic arithmetic operations\\n(+ - */). Some examples regarding this idea:\\n(21 2) no\\nsince 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\\nto 24.\\n(30 6) 30 - 6 = 24 yes\\n(8 3) 8 *3 = 24 yes\\n(12 8) no\\n(48 2) 48 / 2 = 24 yes\\nMost importantly, do not give up, all the numbers that will be given has indeed a\\nsolution.\\nUser:\\n14 8 8 2\\nAssistant:\\nTrying a promising first operation:\\n1. 8 + 2: (14, 10, 8)\\n- 14 + 10: (24, 8) 32, 16, 192, 3\\n- 14 - 10: (8, 4) 12, 8, 32, 2\\n- 14 *10: (140, 8) 148, 132, 1120, fractional\\n- 14 / 10: (8, 1.4) fractional\\n- 14 + 8: (22, 10) 32, 12, 220, fractional\\n- 14 - 8: (10, 6) 16, 4, 60, fractional\\n- 14 *8: (112, 10) 122, 102, 1120, fractional\\n- 14 / 8: fractional\\n- 10 + 8: (18, 14) 32, 4, 252, fractional\\n- 10 - 8: (14, 2) 16, 12, 28, 7\\n- 10 *8: (80, 14) 94, 66, big, fractional\\n- 10 / 8: fractional\\nTrying another promising first operation:\\n2. 14 + 8: (22, 8, 2)\\n- 22 + 8: (30, 2) 32, 28, 60, 15\\n- 22 - 8: (14, 2) 16, 12, 28, 7\\n- 22 *8: (176, 2) 178, 174, 88\\n- 22 / 8: (2.75, 2) fractional\\n- 22 + 2: (24, 8) 32, 16, 192, 3\\n- 22 - 2: (20, 8) 28, 12, 160, fractional\\n- 22 *2: (44, 8) 52, 36, 352, fractional\\n- 22 / 2: (11, 8) 19, 3, 88, fractional\\n- 8 + 2: (22, 10) 32, 12, 220, fractional\\n- 8 - 2: (22, 6) 28, 16, 132, fractional\\n- 8 *2: (22, 16) 38, 6, 352, fractional\\n- 8 / 2: (22, 4) 26, 18, 88, fractional\\nTrying another promising first operation:\\n3. 14 + 2: (16, 8, 8)\\n- 16 + 8: (24, 8) 32, 16, 192, 3\\n- 16 - 8: (8, 8) 16, 0, 64, 1\\n- 16 *8: (128, 8) 136, 120, 1024, 16\\n- 16 / 8: (8, 2) 10, 6, 16, 4\\n- 8 + 8: (16, 16 32, 0, 256, 1\\n- 8 - 8: (16, 0) 16, 16, 0, undefined\\n- 8 *8: (64, 16) 80, 48, 1024, 4\\n- 8 / 8: (16, 1) 17, 15, 16, 16\\nTrying another promising first operation:', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 18}), Document(page_content='4. 8 - 2: (14, 8, 6)\\n- 14 + 8: (22, 14) 36, 8, 308, fractional\\n- 14 - 8: (6, 6) 12, 0, 36, 1\\n- 14 *8: (112, 6) 118, 106, 672, fractional\\n- 14 / 8: (6, 1.75) fractional\\n- 14 + 6: (20, 8) 22, 12, 160, fractional\\n- 14 - 6: (8, 8) 16, 0, 64, 1\\n- 14 *6: (84, 8) 92, 76, 672, fractional\\n- 14 / 6: (8, 2.3) fractional\\n- 8 + 6: (14, 14) 28, 0, 196, 1\\n- 8 - 6: (14, 2) 16, 12, 28, 7\\n- 8 *6: (48, 14) 62, 34, 672, fractional\\n- 8 / 6: (14, 1.3) fractional\\nTrying another promising first operation:\\n5. 8 *2: (16, 14, 8)\\n- 16 + 14: (30, 8) 38, 22, 240, fractional\\n- 16 - 14: (8, 2) 10, 6, 16, 4\\n- 16 *14: (224, 8) 232, 216, 1792, 28\\n- 16 / 14: (8, 1.1) fractional\\n- 16 + 8: (24, 14) 38, 10, 336, fractional\\n- 16 - 8: (14, 8) 22, 6, 112, fractional\\n- 16 *8: (128, 14) 142, 112, 1792, fractional\\n- 16 / 8: (14, 2) 16, 12, 28, 7\\n- 14 + 8: (22, 16) 38, 6, 352, fractional\\n- 14 - 8: (16, 6) 22, 10, 96, fractional\\n- 14 *8: (112, 16) 128, 96, 1792, 7\\n- 14 / 8: (16, 1.7) fractional\\nTrying another promising first operation:\\n6. 14 *2: (28, 8, 8)\\n- 28 + 8: (36, 8) 44, 28, 288, fractional\\n- 28 - 8: (20, 8) 28, 12, 160, fractional\\n- 28 *8: (224, 8) 232, 216, 1792, 28\\n- 28 / 8: (8, 3.5) fractional, fractional, 28, fractional\\n- 8 + 8: (16, 16 32, 0, 256, 1\\n- 8 - 8: (16, 0) 16, 16, 0, undefined\\n- 8 *8: (64, 16) 80, 48, 1024, 4\\n- 8 / 8: (16, 1) 17, 15, 16, 16\\nTrying another promising first operation:\\n7. 8 / 2: (14, 8, 4)\\n- 14 + 8: (22, 4) 26, 18, 88, fractional\\n- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 2 = 4\\nStep 2:\\n14 - 8 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\\nanswer: (14 - 8) *(8 / 2) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 5 5 5\\nAssistant:\\nTrying a promising first operation:\\n1. 9 - 5: (5, 5, 4)\\n- 5 + 5: (10, 4) 14, 6, 40, fractional\\n- 5 - 5: (4, 0) 4, 4, 0, undefined\\n- 5 *5: (25, 4) 29, 21, 100, fractional\\n- 5 / 5: (4, 1) 5, 3, 4, 4\\n- 5 + 4: (9, 5) 14, 4, 45, fractional\\n- 5 - 4: (5, 1) 6, 4, 5, 0.2', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 19}), Document(page_content='- 5 *4: (20, 5) 25, 15, 100, fractional\\n- 5 / 4: fractional\\nTrying another promising first operation:\\n2. 5 *5: (25, 9, 5)\\n- 25 + 9: (34, 5) 39, 29, 170, fractional\\n- 25 - 9: (16, 5) 21, 11, 80, fractional\\n- 25 *9: (225, 5) 230, 220, 1125, 45\\n- 25 / 9: (5, 2.7) fractional\\n- 25 + 5: (30, 9) 39, 21, 270, fractional\\n- 25 - 5: (20, 9) 29, 11, 180, fractional\\n- 25 *5: (75, 9) 84, 66, 675, fractional\\n- 25 / 5: (9, 5) 14, 4, 45, fractional\\n- 9 + 5: (25, 14) 39, 11, 350, fractional\\n- 9 - 5: (25, 4) 29, 21, 100, fractional\\n- 9 *5: (45, 25) 70, 20, 1125, fractional\\n- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\\nTrying another promising first operation:\\n3. 5 - 5: (9, 5, 0)\\n- 9 + 5: (25, 14) 39, 11, 350, fractional\\n- 9 - 5: (25, 4) 29, 21, 100, fractional\\n- 9 *5: (45, 25) 70, 20, 1125, fractional\\n- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\\n- 9 + 0: (9, 5) 14, 4, 45, fractional\\n- 9 - 0: (9, 5) 14, 4, 45, fractional\\n- 9 *0: (5, 0) 5, 5, 0, undefined\\n- 9 / 0: undefined\\n- 5 + 0: (9, 5) 14, 4, 45, fractional\\n- 5 - 0: (9, 5) 14, 4, 45, fractional\\n- 5 *0: (9, 0) 9, 9, 0, undefined\\n- 5 / 0: undefined\\nTrying another promising first operation:\\n4. 5 / 5: (9, 5, 1)\\n- 9 + 5: (25, 14) 39, 11, 350, fractional\\n- 9 - 5: (25, 4) 29, 21, 100, fractional\\n- 9 *5: (45, 25) 70, 20, 1125, fractional\\n- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\\n- 9 + 1: (10, 5) 15, 5, 50, 2\\n- 9 - 1: (8, 5) 13, 3, 40, fractional\\n- 9 *1: (9, 5) 14, 4, 45, fractional\\n- 9 / 1: (9, 5) 14, 4, 45, fractional\\n- 5 + 1: (9, 6) 15, 3, 54, fractional\\n- 5 - 1: (9, 4) 13, 5, 36, fractional\\n- 5 *1: (9, 5) 14, 4, 45, fractional\\n- 5 / 1: (9, 5) 14, 4, 45, fractional\\nTrying another promising first operation:\\n5. 9 *5: (45, 5, 5)\\n- 45 + 5: (50, 5) 55, 45, 250, 10\\n- 45 - 5: (40, 5) 45, 35, 200, 8\\n- 45 *5: (225, 5) 230, 220, 1125, 45\\n- 45 / 5: (9, 5) 14, 4, 45, fractional\\n- 5 + 5: (10, 4) 14, 6, 40, fractional\\n- 5 - 5: (4, 0) 4, 4, 0, undefined\\n- 5 *5: (25, 4) 29, 21, 100, fractional\\n- 5 / 5: (4, 1) 5, 3, 4, 4\\nTrying another promising first operation:\\n6. 5 + 5: (10, 9, 5)\\n- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\\nBacktracking the solution:\\nStep 1:\\n5 + 5 = 10', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 20}), Document(page_content='Step 2:\\n10 + 9 = 19\\nStep 3:\\n19 + 5 = 24\\nConsidering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\\nanswer: ((5 + 5) + 9) + 5 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 6 4 4\\nAssistant:\\nTrying a promising first operation:\\n1. 8 *6: (48, 4, 4)\\n- 48 + 4: (52, 4) 56, 48, 208, 13\\n- 48 - 4: (44, 4) 48, 40, 176, 11\\n- 48 *4: (192, 4) 196, 188, 768, 48\\n- 48 / 4: (12, 4) 16, 8, 48, 3\\n- 4 + 4: (48, 8) 56, 40, 384, 6\\n- 4 - 4: (48, 0) 48, 48, 0, undefined\\n- 4 *4: (48, 16) 64, 32, 768, 3\\n- 4 / 4: (48, 1) 49, 47, 48, 48\\nTrying another promising first operation:\\n2. 4 - 4: (8, 6, 0)\\n- 8 + 6: (14, 0) 14, 14, 0, undefined\\n- 8 - 6: (2, 0) 2, 2, 0, undefined\\n- 8 *6: (48, 0) 48, 48, 0, undefined\\n- 8 / 6: (1.3, 0) fractional\\n- 8 + 0: (8, 6) 14, 2, 48, fractional\\n- 8 - 0: (8, 6) 14, 2, 48, fractional\\n- 8 *0: (6, 0) 6, 6, 0, undefined\\n- 8 / 0: undefined\\n- 6 + 0: (8, 6) 14, 2, 48, fractional\\n- 6 - 0: (8, 6) 14, 2, 48, fractional\\n- 6 *0: (8, 0) 8, 8, 0, undefined\\n- 6 / 0: undefined\\nTrying another promising first operation:\\n3. 4 / 4: (8, 6, 1)\\n- 8 + 6: (14, 1) 15, 13, 14, 14\\n- 8 - 6: (2, 1) 3, 1, 2, 2\\n- 8 *6: (48, 1) 49, 47, 48, 48\\n- 8 / 6: (1.3, 1) fractional\\n- 8 + 1: (9, 6) 15, 3, 54, fractional\\n- 8 - 1: (7, 6) 13, 1, 42, fractional\\n- 8 *1: (8, 6) 14, 2, 48, fractional\\n- 8 / 1: (8, 6) 14, 2, 48, fractional\\n- 6 + 1: (8, 7) 15, 1, 56, fractional\\n- 6 - 1: (8, 5) 13, 3, 40, fractional\\n- 6 *1: (8, 6) 14, 2, 48, fractional\\n- 6 / 1: (8, 1) 9, 7, 8, 8\\nTrying another promising first operation:\\n4. 8 - 6: (4, 4, 2)\\n- 4 + 4: (8, 2) 10, 6, 16, 4\\n- 4 - 4: (2, 0) 2, 2, 0, undefined\\n- 4 *4: (16, 2) 18, 14, 32, 8\\n- 4 / 4: (2, 1) 3, 1, 2, 2\\n- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 - 6 = 2\\nStep 2:\\n4 + 2 = 6\\nStep 3:\\n6*4 = 24', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 21}), Document(page_content='Considering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\\nanswer: (4 + (8 - 6)) *4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 10 9 4\\nAssistant:\\nTrying a promising first operation:\\n1. 13 - 4: (10, 9, 9)\\n- 10 + 9: (19, 9) 28, 10, 171, fractional\\n- 10 - 9: (9, 1) 10, 8, 9, 9\\n- 10 *9: (90, 9) 99, 81, 810, fractional\\n- 10 / 9: fractional\\n- 9 + 9: (18, 10) 28, 8, 180, fractional\\n- 9 - 9: (10, 0) 10, 10, 0, undefined\\n- 9 *9: (81, 10) 91, 71, 810, fractional\\n- 9 / 9: (10, 1) 11, 9, 10, 10\\nTrying another promising first operation:\\n2. 13 / 10: (9, 4, 1.3)\\n- 9 + 4: (13, 1.3) fractional, fractional, fractional, 10\\n- 9 - 4: (5, 1.3) fractional\\n- 9 *4: (36, 1.3) fractional\\n- 9 / 4: (2.3, 1.3) fractional, 1, fractional, fractional\\n- 9 + 1.3: (10.3, 4) fractional\\n- 9 - 1.3: (7.7, 4) fractional\\n- 9 *1.3: (11.7, 4) fractional\\n- 9 / 1.3: (6.9, 4) fractional\\n- 4 + 1.3: (9, 5.3) fractional\\n- 4 - 1.3: (9, 2.7) fractional\\n- 4 *1.3: (9, 5.2) fractional\\n- 4 / 1.3: (9, 3.1) fractional\\nTrying another promising first operation:\\n3. 9 / 4: (13, 10, 2.3)\\n- 13 + 10: (23, 2.3) fractional, fractional, fractional, 10\\n- 13 - 10: (3, 2.3) fractional\\n- 13 *10: (130, 2.3) fractional\\n- 13 / 10: (2.3, 1.3) fractional, 1, fractional, fractional\\n- 13 + 2.3: (15.3, 10) fractional, fractional, 153, fractional\\n- 13 - 2.3: (11.7, 10) fractional, fractional, 117, fractional\\n- 13 *2.3: (29.9, 10) fractional, fractional, 299, fractional\\n- 13 / 2.3: (10, 5.6) fractional, fractional, 560, fractional\\n- 10 + 2.3: (13, 12.3) fractional\\n- 10 - 2.3: (13, 7.7) fractional\\n- 10 *2.3: (23, 13) 36, 10, 299, fractional\\n- 10 / 2.3: (13, 4.3) fractional\\nTrying another promising first operation:\\n4. 13 / 4: (10, 9, 3.3)\\n- 10 + 9: (19, 3.3) fractional\\n- 10 - 9: (3.3, 1) fractional\\n- 10 *9: (90, 3.3) fractional\\n- 10 / 9: (3.3, 1.1) fractional, fractional, fractional, 3\\n- 10 + 3.3: (13.3, 9) fractional\\n- 10 - 3.3: (9, 6.7) fractional\\n- 10 *3.3: (33, 9) 42, 24, 297, fractional\\n- 10 / 3.3: (3.1, 9) fractional\\n- 9 + 3.3: (12.3, 10) fractional, fractional, 123, fractional\\n- 9 - 3.3: (10, 5.7) fractional, fractional, 57, fractional\\n- 9 *3.3: (29.7, 10) fractional, fractional, 297, fractional\\n- 9 / 3.3: (10, 2.7) fractional, fractional, 27, fractional\\nTrying another promising first operation:\\n5. 13 / 9: (10, 9, 1.4)\\n- 10 + 9: (19, 1.4) fractional\\n- 10 - 9: (1.4, 1) fractional\\n- 10 *9: (90, 1.4) fractional, fractional, 130, fractional\\n- 10 / 9: (1.1, 1.4) fractional\\n- 10 + 1.4: (11.4, 9) fractional', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 22}), Document(page_content='- 10 - 1.4: (9, 8.6) fractional\\n- 10 *1.4: (140, 9) 149, 131, 1260, fractional\\n- 10 / 1.4: (9, 7.1) fractional\\n- 9 + 1.4: (10.4, 10) fractional, fractional, 104, fractional\\n- 9 - 1.4: (10, 7.6) fractional, fractional, 76, fractional\\n- 9 *1.4: (12.6, 10) fractional, fractional, 126, fractional\\n- 9 / 1.4: (10, 6.4) fractional, fractional, 64, fractional\\nTrying another promising first operation:\\n6. 10 - 4: (13, 9, 6)\\n- 13 + 9: (22, 6) 28, 16, 132, fractional\\n- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n10 - 4 = 6\\nStep 2:\\n13 - 9 = 4\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\\nanswer: (10 - 4) *(13 - 9) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nAoT (Random)\\nSystem:\\nUse numbers and basic arithmetic operations (+ - */) to obtain 24. Each step, you\\nare only allowed to choose two of the remaining numbers to obtain a new\\nnumber.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n4 4 6 8.\\nAssistant:\\nTrying a promising first operation:\\n(4 + 4) *6 - 8 = 40.\\nTrying another promising first operation:\\n(8 - 6) *4 + 4 = 12.\\nTrying another promising first operation:\\n(6 - 4) *(4 + 8) = 24.\\nanswer: (6 - 4) *(4 + 8) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n2 9 10 12.\\nAssistant:\\nTrying a promising first operation:\\n((12 - 10) / 2) + 9 = 10.\\nTrying another promising first operation:\\n(10 + 9) + (12 / 2) = 25.\\nTrying another promising first operation:\\n(12 *2)*(10 - 9) = 24.\\nanswer: (12 *2)*(10 - 9) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n4 9 10 13.\\nAssistant:\\nTrying a promising first operation:\\n((13 - 10) / 4) + 9 = 10.\\nTrying another promising first operation:\\n4*(9 - (13 - 10)) = 24.\\nanswer: 4 *(9 - (13 - 10)) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 23}), Document(page_content='1 4 8 8.\\nAssistant:\\nTrying a promising first operation:\\n(8 + 1) + 4 *8 + 32.\\nTrying another promising first operation:\\n(1 + 8 / 4) *8 = 24.\\nanswer: (1 + 8 / 4) *8 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n5 5 5 9.\\nAssistant:\\nTrying a promising first operation:\\n((5 + 5) + 5) + 9 = 24.\\nanswer: ((5 + 5) + 5) + 9 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nAoT (BFS)\\nSystem:\\nUse numbers and basic arithmetic operations (+ - */) to obtain 24. When\\nconsidering the next steps, do not choose operations that will result in a\\nnegative or fractional number. In order to help with the calculations, the\\nnumbers in the parenthesis represent the numbers that are left after the\\noperations and they are in descending order.\\nAnother thing we do is when there are only two numbers left in the parenthesis, we\\ncheck whether we can arrive at 24 only by using basic arithmetic operations\\n(+ - */). Some examples regarding this idea:\\n(21, 2): 23, 19, 42, fractional\\n(30, 6): 36, 24 = 30 - 6 -> found it!\\n(8, 3): 11, 5, 24 = 8 *3 yes\\n(12, 8): 20, 4, 72, fractional\\nIn the second steps, when there are three numbers left, we choose the most\\npromising operations so that when we are left with two numbers, we will be\\nable to get to 24.\\nSo, when we reach 24 in the third steps, that means we found the solution, we\\ndirectly backtrack to write the answer.\\nIn each step, we want to choose the best operations so that the numbers left, will\\nhave a good chance to reach 24.\\nUser:\\n14 8 8 2\\nAssistant:\\nLet’s consider the most promising possible first steps:\\n1. 8 + 8: (16, 14, 2)\\n2. 14 - 8: (8, 6, 2)\\n3. 14 + 2: (16, 8, 8)\\n4. 8 / 2: (14, 8, 4)\\nLet’s consider the most promising second steps:\\n1. (16, 14, 2)\\n- 16 - 14: (2, 2)\\n- 16 / 2: (8, 14)\\n- 14 *2: (28, 16)\\n- 14 / 2: (7, 16)\\n2. (8, 6, 2)\\n- 8 - 6: (2, 2)\\n- 8 / 2: (4, 6)\\n- 6 *2: (12, 8)\\n- 6 / 2: (3, 8)\\n3. (16, 8, 8)', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 24}), Document(page_content='- 16 - 8: (8, 8)\\n- 16 / 8: (2, 8)\\n- 8 *8: (64, 16)\\n- 8 / 8: (1, 16)\\n4. (14, 8, 4)\\n- 14 - 8: (6, 4)\\n- 14 / 4: (3.5, 8)\\n- 8 *4: (32, 14)\\n- 8 / 4: (2, 14)\\nLet’s consider the most promising third steps:\\n1. 8 + 8 = 16\\n- 16 - 14: (2, 2): 4, 0, 4, 1\\n- 16 / 2: (8, 14): 22, 6, 112, fractional\\n- 14 *2: (28, 16): 44, 12, 448, fractional\\n- 14 / 2: (7, 16): 23, 9, 112, fractional\\n2. 14 - 8 = 6\\n- 8 - 6: (2, 2): 4, 0, 4, 1\\n- 8 / 2: (6, 4): 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n14 - 8 = 6\\nStep 2:\\n8 / 2 = 4\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (14 - 8) *(8 / 2) = 24.\\nanswer: (14 - 8) *(8 / 2) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 5 5 5\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 9 - 5: (5, 5, 4)\\n2. 5 + 5: (9, 10, 5)\\n3. 9 + 5: (14, 5, 5)\\n4. 5 - 5: (9, 5, 0)\\nLet’s consider the most promising second steps:\\n1. (5, 5, 4)\\n- 5 + 5: (10, 4)\\n- 5 *4: (20, 5)\\n- 5 - 4: (5, 1)\\n- 5 / 4: (5, 1.25)\\n2. (9, 10, 5)\\n- 10 + 9: (19, 5)\\n- 10 - 5: (9, 5)\\n- 10 *5: (50, 9)\\n- 10 / 5: (9, 2)\\n3. (14, 5, 5)\\n- 14 - 5: (9, 5)\\n- 14 + 5: (19, 5)\\n- 5 *5: (25, 14)\\n- 5 / 5: (14, 1)\\n4. (9, 5, 0)\\n- 9 + 5: (14, 0)\\n- 9 - 5: (4, 0)\\n- 5 *0: (9, 0)\\n- 5 / 0: (9, infinity)', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 25}), Document(page_content='Let’s consider the most promising third steps:\\n1. 9 - 5 = 4\\n- 5 + 5: (10, 4): 14, 6, 40, fractional\\n- 5 *4: (20, 5): 25, 15, 100, 4\\n- 5 - 4: (5, 1): 6, 4, 5, 5\\n- 5 / 4: (5, 1.25): 6.25, 3.75, 6.25, 4\\n2. 5 + 5 = 10\\n- 10 + 9: (19, 5): 24 = 19 + 5 -> found it!\\nBacktracking the solution:\\nStep 1:\\n5 + 5 = 10\\nStep 2:\\n10 + 9 = 19\\nStep 3:\\n19 + 5 = 24\\nConsidering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\\nanswer: ((5 + 5) + 9) + 5 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 6 4 4\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 8 *6: (48, 4, 4)\\n2. 8 + 4: (12, 6, 4)\\n3. 8 - 6: (4, 4, 2)\\n4. 6 - 4: (8, 4, 2)\\nLet’s consider the most promising second steps:\\n1. (48, 4, 4)\\n- 4 *4: (48, 16)\\n- 48 / 4: (12, 4)\\n- 4 + 4: (48, 8)\\n- 48 - 4: (44, 4)\\n2. (12, 6, 4)\\n- 12 + 6: (18, 4)\\n- 6 *4: (24, 12)\\n- 6 + 4: (12, 10)\\n- 12 / 4: (6, 3)\\n3. (4, 4, 2)\\n- 4 *4: (16, 2)\\n- 4 + 2: (6, 4)\\n- 4 + 4: (8, 2)\\n- 4 *2: (8, 4)\\n4. (8, 4, 2)\\n- 8 *4: (32, 2)\\n- 4 *2: (8, 8)\\n- 8 + 4: (12, 2)\\n- 8 / 4: (4, 2)\\nLet’s consider the most promising third steps:\\n1. 8 *6 = 48\\n- 4 *4: (48, 16): 64, 32, big, 3\\n- 48 / 4: (12, 4): 16, 8, 48, 3\\n- 4 + 4: (48, 8): 56, 40, big, 6\\n- 48 - 4: (44, 4): 48, 40, big, 11\\n2. 8 + 4 = 12\\n- 12 + 6: (18, 4): 22, 14, 72, fractional\\n- 6 *4: (24, 12): 36, 12, 288, 2\\n- 6 + 4: (12, 10): 22, 2, 120, fractional\\n- 12 / 4: (6, 3): 9, 3, 18, 2', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 26}), Document(page_content='3. 8 - 6 = 2\\n- 4 *4: (16, 2): 19, 14, 32, 8\\n- 4 + 2: (6, 4): 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 - 6 = 2\\nStep 2:\\n4 + 2 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\\nanswer: (4 + (8 - 6)) *4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 10 9 4\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 13 - 4: (10, 9, 9)\\n2. 10 - 4: (13, 9, 6)\\n3. 13 + 9: (22, 10, 4)\\n4. 10 - 9: (13, 4, 1)\\nLet’s consider the most promising second steps:\\n1. (10, 9, 9)\\n- 10 + 9: (19, 9)\\n- 10 - 9: (9, 1)\\n- 9 + 9: (18, 10)\\n- 9 / 9: (9, 1)\\n2. (13, 9, 6)\\n- 9 + 6: (15, 13)\\n- 9 *6: (54, 13)\\n- 13 - 9: (6, 4)\\n- 13 - 6: (9, 7)\\n3. (22, 10, 4)\\n- 22 - 10: (12, 4)\\n- 22 - 4: (18, 10)\\n- 10 *4: (40, 22)\\n- 10 / 4: (22, 5.5)\\n4. (13, 4, 1)\\n- 13 - 4: (9, 1)\\n- 13 *4: (52, 1)\\n- 4 - 1: (13, 3)\\n- 13 - 1: (12, 4)\\nLet’s consider the most promising third steps:\\n1. 13 - 4 = 9\\n- 10 + 9: (19, 9): 28, 10, 171, fractional\\n- 10 - 9: (9, 1): 10, 8, 9, 9\\n- 9 + 9: (18, 10): 28, 8, 180, fractional\\n- 9 / 9: (9, 1): 10, 8, 9, 9\\n2. 10 - 4 = 6\\n- 9 + 6: (15, 13): 28, 2, 195, fractional\\n- 9 *6: (54, 13): 67, 41, 702, fractional\\n- 13 - 9: (6, 4): 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n13 - 9 = 4\\nStep 2:\\n10 - 4 = 6\\nStep 3:', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 27}), Document(page_content='6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (10 - 4) *(13 - 9) = 24.\\nanswer: (10 - 4) *(13 - 9) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 8 5 4\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 5 + 4: (9, 8, 8)\\n2. 8 / 4: (8, 5, 2)\\n3. 8 - 5: (8, 4, 3)\\n4. 8 / 8: (5, 4, 1)\\nLet’s consider the most promising second steps:\\n1. (9, 8, 8)\\n- 9 + 8: (17, 8)\\n- 8 + 8: (16, 9)\\n- 9 *8: (72, 8)\\n- 8 / 8: (9, 1)\\n2. (8, 5, 2)\\n- 5 - 2: (8, 3)\\n- 8 - 2: (6, 5)\\n- 8 + 5: (13, 2)\\n- 5 *2: (10, 8)\\n3. (8, 4, 3)\\n- 8 - 4: (4, 3)\\n- 8 - 3: (5, 4)\\n- 4 *3: (12, 8)\\n- 4 + 3: (8, 7)\\n4. (5, 4, 1)\\n- 5 + 4: (9, 1)\\n- 5 - 4: (1, 1)\\n- 4 - 1: (5, 3)\\n- 5 + 1: (6, 4)\\nLet’s consider the most promising third steps:\\n1. 5 + 4 = 9\\n- 9 + 8: (17, 8): 25, 9, 136, fractional\\n- 8 + 8: (16, 9): 25, 7, 144, fractional\\n- 9 *8: (72, 8): 80, 64, 576, 9\\n- 8 / 8: (9, 1): 10, 8, 9, 9\\n2. 8 / 4 = 2\\n- 5 - 2: (8, 3): 11, 5, 24 = 8 *3 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 4 = 2\\nStep 2:\\n5 - 2 = 3\\nStep 3:\\n8*3 = 24\\nConsidering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\\nanswer: 8 *(5 - (8 / 4)) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 11 1 1\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 11 - 1: (11, 10, 1)\\n2. 11 + 1: (12, 11, 1)\\n3. 11 + 11: (22, 1, 1)\\n4. 1 + 1: (11, 11, 2)', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 28}), Document(page_content='Let’s consider the most promising second steps:\\n1. (11, 10, 1)\\n- 11 + 10: (21, 1)\\n- 10 + 1: (11, 11)\\n- 10 / 1: (11, 10)\\n- 11 / 1: (11, 10)\\n2. (12, 11, 1)\\n- 12 + 11: (23, 1)\\n- 11 + 1: (12, 11)\\n- 11 - 1: (12, 10)\\n- 12 + 1: (13, 11)\\n3. (22, 1, 1)\\n- 22 + 1: (23, 1)\\n- 1 + 1: (22, 2)\\n- 22 / 1: (22, 1)\\n- 1 / 1: (22, 1)\\n4. (11, 11, 2)\\n- 11 + 11: (22, 2)\\n- 11 *2: (22, 11)\\n- 11 + 2: (13, 11)\\n- 2 *11: (22, 11)\\nLet’s consider the most promising third steps:\\n1. 11 - 1 = 10\\n- 11 + 10: (21, 1): 22, 20, 21, 20\\n- 10 + 1: (11, 11): 22, 10, 121, 0\\n- 10 / 1: (11, 10): 21, 1, 110, 0\\n- 11 / 1: (11, 10): 21, 1, 110, 0\\n2. 11 + 1 = 12\\n- 12 + 11: (23, 1): 24 = 23 + 1 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11 + 1 = 12\\nStep 2:\\n12 + 11 = 23\\nStep 3:\\n23 + 1 = 24\\nConsidering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\\nanswer: ((11 + 1) + 11) + 1 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 7 4 1\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 7 *4: (28, 11, 1)\\n2. 7 + 1: (11, 8, 4)\\n3. 4 + 1: (11, 7, 5)\\n4. 11 - 4: (7, 3, 1)\\nLet’s consider the most promising second steps:\\n1. (28, 11, 1)\\n- 28 - 11: (17, 1)\\n- 28 - 1: (27, 11)\\n- 11 + 1: (29, 28)\\n- 11 - 1: (28, 10)\\n2. (11, 8, 4)\\n- 11 + 8: (19, 4)\\n- 8 + 4: (12, 11)\\n- 11 - 8: (4, 3)', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 29}), Document(page_content='- 8 - 4: (7, 11)\\n3. (11, 7, 5)\\n- 11 - 5: (7, 6)\\n- 7 - 5: (11, 2)\\n- 7 *5: (35, 11)\\n- 11 + 5: (16, 7)\\n4. (7, 3, 1)\\n- 7 - 3: (4, 1)\\n- 7 *3: (21, 1)\\n- 3 + 1: (7, 4)\\n- 7 - 1: (6, 3)\\nLet’s consider the most promising third steps:\\n1. 7 *4 = 28\\n- 28 - 11: (17, 1): 18, 16, 17, 17\\n- 28 - 1: (27, 11): 38, 16, 297, 2.45\\n- 11 + 1: (29, 28): 57, 1, 812, 1.03\\n- 11 - 1: (28, 10): 38, 18, 280, 2.8\\n2. 7 + 1 = 8\\n- 11 + 8: (19, 4): 23, 15, 76, 4.75\\n- 8 + 4: (12, 11): 23, 7, 132, 3\\n- 11 - 8: (4, 3): 7, 1, 12, 1.33\\n- 8 - 4: (7, 11): 18, 4, 77, 1.75\\n3. 4 + 1 = 5\\n- 11 - 5: (7, 6): 13, 1, 42, 1.17\\n- 7 - 5: (11, 2): 13, 9, 22, 5.5\\n- 7 *5: (35, 11): 46, 24 = 35 - 11 -> found it!\\nBacktracking the solution:\\nStep 1:\\n4 + 1 = 5\\nStep 2:\\n7*5 = 35\\nStep 3:\\n35 - 11 = 24\\nConsidering these steps: 24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\\nanswer: (7 *(4 + 1)) - 11 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 5 4 3\\nAssistant:\\nLet’s consider the most promising first steps to reach 24:\\n1. 11 *3: (33, 5, 4)\\n2. 5 + 4: (11, 9, 3)\\n3. 11 - 4: (7, 5, 3)\\n4. 4 + 3: (11, 7, 5)\\nLet’s consider the most promising second steps to reach 24:\\n1. (33, 5, 4)\\n- 33 - 5: (28, 4)\\n- 33 - 4: (29, 5)\\n- 5 + 4: (33, 9)\\n- 5 *4: (20, 33)\\n2. (11, 9, 3)\\n- 11 *3: (33, 9)\\n- 11 + 3: (14, 9)\\n- 9 + 3: (12, 11)\\n- 9 / 3: (11, 3)\\n3. (7, 5, 3)', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 30}), Document(page_content='- 7 - 3: (4, 5)\\n- 7 + 5: (12, 3)\\n- 5 + 3: (8, 7)\\n- 5 *3: (7, 6)\\n4. (11, 7, 5)\\n- 11 + 7: (18, 5)\\n- 11 - 5: (6, 7)\\n- 7 + 5: (12, 11)\\n- 7 - 5: (2, 11)\\nLet’s consider the most promising third steps to reach 24:\\n1. 11 *3 = 33\\n- 33 - 5: (28, 4): 32, 24 = 28 - 4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11*3 = 33\\nStep 2:\\n33 - 5 = 28\\nStep 3:\\n28 - 4 = 24\\nConsidering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\\nanswer: ((11 *3) - 5) - 4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 12 5 2\\nAssistant:\\nLet’s consider the most promising first steps to reach 24:\\n1. 12 / 2: (13, 6, 5)\\n2. 13 + 5: (18, 12, 2)\\n3. 12 - 5: (13, 7, 2)\\n4. 5 - 2: (13, 12, 3)\\nLet’s consider the most promising second steps to reach 24:\\n1. (13, 6, 5)\\n- 13 + 6: (19, 5)\\n- 13 - 5: (8, 6)\\n- 6 *5: (30, 13)\\n- 6 - 5: (13, 1)\\n2. (18, 12, 2)\\n- 18 *2: (36, 12)\\n- 12 / 2: (18, 6)\\n- 18 - 2: (16, 12)\\n- 12 *2: (24, 18)\\n3. (13, 7, 2)\\n- 13 + 7: (20, 2)\\n- 13 - 2: (11, 7)\\n- 7 *2: (14, 13)\\n- 7 - 2: (13, 5)\\n4. (13, 12, 3)\\n- 13 *3: (39, 12)\\n- 13 - 3: (10, 12)\\n- 12 *3: (36, 13)\\n- 12 / 3: (13, 4)\\nLet’s consider the most promising third steps to reach 24:\\n1. 12 / 2 = 6\\n- 13 + 6: (19, 5): 24 = 19 + 5 -> found it!\\nBacktracking the solution:\\nStep 1:\\n12 / 2 = 6\\nStep 2:', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 31}), Document(page_content='13 + 6 = 19\\nStep 3:\\n19 + 5 = 24\\nConsidering these steps: 24 = 19 + 5 = (13 + 6) + 5 = (13 + (12 / 2)) + 5 = 24.\\nanswer: (13 + (12 / 2)) + 5 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 8 2 1\\nAssistant:\\nLet’s consider the most promising first steps to reach 24:\\n1. 9 - 1: (8, 8, 2)\\n2. 8 + 2: (10, 9, 1)\\n3. 9 + 1: (10, 8, 2)\\n4. 2 + 1: (9, 8, 3)\\nLet’s consider the most promising second steps to reach 24:\\n1. (8, 8, 2)\\n- 8 + 8: (16, 2)\\n- 8 *2: (16, 8)\\n- 8 - 2: (6, 8)\\n- 8 + 8: (16, 2)\\n2. (10, 9, 1)\\n- 10 + 9: (19, 1)\\n- 10 - 1: (9, 9)\\n- 9 + 1: (10, 10)\\n- 9 / 1: (8, 10)\\n3. (10, 8, 2)\\n- 10 + 8: (18, 2)\\n- 10 *2: (8, 8)\\n- 8 + 2: (10, 10)\\n- 8 / 2: (6, 10)\\n4. (9, 8, 3)\\n- 9 + 8: (17, 3)\\n- 9 / 3: (6, 8)\\n- 8 + 3: (11, 9)\\n- 8 *3: (24, 9)\\nLet’s consider the most promising third steps to reach 24:\\n1. 9 - 1 = 8\\n- 8 + 8: (16, 2): 18, 14, 32, 8\\n- 8 *2: (16, 8): 24 = 16 + 8 -> found it!\\nBacktracking the solution:\\nStep 1:\\n9 - 1 = 8\\nStep 2:\\n8*2 = 16\\nStep 3:\\n16 + 8 = 24\\nConsidering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\\nanswer: ((9 - 1) *2) + 8 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nAoT (Short)\\nSystem:\\nUse numbers and basic arithmetic operations (+ - */) to obtain 24. When\\nconsidering the next steps, do not choose operations that will result in a\\nnegative or fractional number. In order to help with the calculations, the\\nnumbers in the parenthesis represent the numbers that are left after the\\noperations and they are in descending order.', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 32}), Document(page_content='Another thing we do is when there are only two numbers left in the parenthesis, we\\ncheck whether we can arrive at 24 only by using basic arithmetic operations\\n(+ - */). Some examples regarding this idea:\\n(21 2) no\\nsince 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\\nto 24.\\n(30 6) 30 - 6 = 24 yes\\n(8 3) 8 *3 = 24 yes\\n(12 8) no\\n(48 2) 48 / 2 = 24 yes\\nMost importantly, do not give up, all the numbers that will be given has indeed a\\nsolution.\\nUser:\\n14 8 8 2\\nAssistant:\\nTrying a promising first operation:\\n1. 8 / 2: (14, 8, 4)\\n- 14 + 8: (22, 4) 26, 18, 88, fractional\\n- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 2 = 4\\nStep 2:\\n14 - 8 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\\nanswer: (14 - 8) *(8 / 2) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 5 5 5\\nAssistant:\\nTrying a promising first operation:\\n1. 5 + 5: (10, 9, 5)\\n- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\\nBacktracking the solution:\\nStep 1:\\n5 + 5 = 10\\nStep 2:\\n10 + 9 = 19\\nStep 3:\\n19 + 5 = 24\\nConsidering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\\nanswer: ((5 + 5) + 9) + 5 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 6 4 4\\nAssistant:\\nTrying a promising first operation:\\n1. 8 - 6: (4, 4, 2)\\n- 4 + 4: (8, 2) 10, 6, 16, 4\\n- 4 - 4: (2, 0) 2, 2, 0, undefined\\n- 4 *4: (16, 2) 18, 14, 32, 8\\n- 4 / 4: (2, 1) 3, 1, 2, 2\\n- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 - 6 = 2\\nStep 2:\\n4 + 2 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\\nanswer: (4 + (8 - 6)) *4 = 24.', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 33}), Document(page_content='˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 10 9 4\\nAssistant:\\nTrying a promising first operation:\\n1. 10 - 4: (13, 9, 6)\\n- 13 + 9: (22, 6) 28, 16, 132, fractional\\n- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n10 - 4 = 6\\nStep 2:\\n13 - 9 = 4\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\\nanswer: (10 - 4) *(13 - 9) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 8 5 4\\nAssistant:\\nTrying a promising first operation:\\n1. 8 / 4: (8, 5, 2)\\n- 8 + 5: (13, 2) 15, 11, 26, fractional\\n- 8 - 5: (3, 2) 5, 1, 6, 1.5\\n- 8 *5: (40, 2) 42, 38, 80, 20\\n- 8 / 5: fractional\\n- 8 + 2: (10, 5) 15, 5, 50, 2\\n- 8 - 2: (6, 5) 11, 1, 30, fractional\\n- 8 *2: (16, 5) 21, 11, 80, fractional\\n- 8 / 2: (5, 4) 9, 1, 20, fractional\\n- 5 + 2: (7, 8) 15, 1, 56, fractional\\n- 5 - 2: (8, 3) 11, 5, 24 = 8 *3 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 4 = 2\\nStep 2:\\n5 - 2 = 3\\nStep 3:\\n8*3 = 24\\nConsidering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\\nanswer: 8 *(5 - (8 / 4)) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 11 1 1\\nAssistant:\\nTrying a promising first operation:\\n1. 11 + 1: (12, 11, 1)\\n- 12 + 11: (23, 1) 24 = 23 + 1 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11 + 1 = 12\\nStep 2:\\n12 + 11 = 23\\nStep 3:\\n23 + 1\\nConsidering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\\nanswer: ((11 + 1) + 11) + 1 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 7 4 1\\nAssistant:\\nTrying a promising first operation:\\n1. 4 + 1: (11 7 5)\\n- 11 + 7: (18, 5) 23, 13, 90, fractional', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 34}), Document(page_content='- 11 - 7: (5, 4) 9, 1, 20, fractional\\n- 11 *7: (77, 5) 82, 72, 385, fractional\\n- 11 / 7: fractional\\n- 11 + 5: (16, 7) 23, 9, 112, fractional\\n- 11 - 5: (7, 6) 13, 1, 42, fractional\\n- 11 *5: (55, 7) 62, 48, 385, fractional\\n- 11 / 5: fractional\\n- 7 + 5: (12, 11) 23, 1, 132, fractional\\n- 7 - 5: (11, 2) 13, 9, 22, fractional\\n- 7 *5: (35, 11) 46, 24 = 35 - 11 -> found it!\\nStep 1:\\n4 + 1 = 5\\nStep 2:\\n7*5 = 35\\nStep 3:\\n35 - 11 = 24\\nConsidering these steps: Backtracking the solution:\\n24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\\nanswer: (7 *(4 + 1)) - 11 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 5 4 3\\nAssistant:\\nTrying a promising first operation:\\n1. 11 *3: (33, 5, 4)\\n- 33 + 5: (38, 4) 42, 34, 152, fractional\\n- 33 - 5: (28, 4) 32, 24 = 28 - 4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11*3 = 33\\nStep 2:\\n33 - 5 = 28\\nStep 3:\\n28 - 4 = 24\\nConsidering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\\nanswer: ((11 *3) - 5) - 4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 12 5 2\\nAssistant:\\nTrying a promising first operation:\\n1. 13 + 5: (18, 12, 2)\\n- 18 + 12: (30, 2) 32, 28, 60, fractional\\n- 18 - 12: (6, 2) 8, 4, 12, 3\\n- 18 *12: (216, 2) 218, 214, 432, fractional\\n- 18 / 12: fractional\\n- 18 + 2: (20, 12) 32, 8, 240, fractional\\n- 18 - 2: (16, 12) 28, 4, 192, fractional\\n- 18 *2: (36, 12) 48, 24 = 36 - 12 -> found it!\\nBacktracking the solution:\\nStep 1:\\n13 + 5 = 18\\nStep 2:\\n18*2 = 36\\nStep 3:\\n36 - 12 = 24\\nConsidering these steps: 24 = 36 - 12 = (18 *2) - 12 = ((13 + 5) *2) - 12 = 24.\\nanswer: ((13 + 5) *2) - 12 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 8 2 1\\nAssistant:\\nTrying a promising first operation:\\n1. 9 - 1: (8, 8, 2)\\n- 8 + 8: (16, 2) 18, 14, 32, 8', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 35}), Document(page_content='- 8 - 8: (2, 0) 2, 2, 0, undefined\\n- 8 *8: (64, 2) 66, 62, 128, 32\\n- 8 / 8: (2, 1) 3, 1, 2, 2\\n- 8 + 2: (10, 8) 18, 2, 80, 4\\n- 8 - 2: (6, 8) 14, -2, 48, fractional\\n- 8 *2: (16, 8) 24 = 16 + 8 -> found it!\\nBacktracking the solution:\\nStep 1:\\n9 - 1 = 8\\nStep 2:\\n8*2 = 16\\nStep 3:\\n16 + 8 = 24\\nConsidering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\\nanswer: ((9 - 1) *2) + 8 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\n5×5Mini Crosswords Prompts\\nIn the following we give all the exact prompts we used for the methods given in the experiments section and some selection of\\nthe generations from the LLM. In the prompts the keywords “System”, “User” and “Assistant” used are the roles in the OpenAI\\nAPI in chat completion mode. The line breaks are to show the turns between the user and assistant in the API.\\nAoT\\nUser:\\nh1. A lunar valley\\nh2. A fatty oil\\nh3. To entice\\nh4. To lower; to reduce\\nh5. A solitary person\\nv1. According to the roster\\nv2. Another name for Port-Francqui\\nv3. An illicit lover; a European lake\\nv4. To lisp\\nv5. To come in\\nThe words I already found are:\\nh1. rille\\nh3. tempt\\nv2. ilebo\\nv5. enter\\nAssistant:\\nThere are two horizontal and two vertical words. Since they are the amount, let’s\\nconsider the next unfound horizontal word, which is h2. Since we are\\nconsidering the second horizontal word, we need to look at the second letters\\nof the vertical words we found:\\n- What is the second letter of ilebo: e\\n- What is the second letter of enter: n\\nThe word we are looking fits the clue \"A fatty oil\" and needs to have the letters\\ne and n in its (v2, two) second and (v5, five) fifth letters: _ e _ _ n. The\\ncandidates are: oleic, olein, olive.\\n- oleic (o l e i c, _ e _ _ n) doesn’t fit\\n- olein (o l e i n, _ e _ _ n) fits\\n- olive (o l i v e, _ e _ _ n) doesn’t fit\\nWe add the word olein for h2. The current words are:\\nh1. rille\\nh2. olein\\nh3. tempt\\nv2. ilebo\\nv5. enter\\nNow, let’s consider the next unfound vertical word, which is v1. Since we are\\nconsidering the first vertical word, we need to look at the first letters of\\nthe horizontal words we found:\\n- What is the first letter of rille: r\\n- What is the first letter of olein: o', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 36}), Document(page_content='- What is the first letter of tempt: t\\nThe word we are looking fits the clue \"According to the roster\" and needs to have\\nthe letters r, o, and t in its (h1, one) first, (h2, two) second, and (h3,\\nthree) third letters: r o t _ _. The candidates are: none\\nNow, let’s consider the next unfound vertical word, which is v3. Since we are\\nconsidering the third vertical word, we need to look at the third letters of\\nthe horizontal words we found:\\n- What is the third letter of rille: l\\n- What is the third letter of olein: e\\n- What is the third letter of tempt: m\\nThe word we are looking fits the clue \"An illicit lover; a European lake\" and\\nneeds to have the letters l, e, and m in its (h1, one) first, (h2, two) second\\n, and (h3, three) third letters: l e m _ _. The candidates are: leman.\\n- leman (l e m a n, l e m _ _) fits\\nWe add the word leman for v3. The current words are:\\nh1. rille\\nh2. olein\\nh3. tempt\\nv2. ilebo\\nv3. leman\\nv5. enter\\nNow, let’s consider the next unfound horizontal word, which is h4. Since we are\\nconsidering the fourth horizontal word, we need to look at the fourth letters\\nof the vertical words we found:\\n- What is the fourth letter of ilebo: b\\n- What is the fourth letter of leman: a\\n- What is the fourth letter of enter: e\\nThe word we are looking fits the clue \"To lower; to reduce\" and needs to have the\\nletters b, a, and e in its (v2, two) second, (v3, three) third, and (v5, five)\\nfifth letters: _ b a _ e. The candidates are: abase, abate.\\n- abase (a b a s e, _ b a _ e) fits\\n- abate (a b a t e, _ b a _ e) fits\\nSince both fits, let’s consider another word.\\nNow, let’s consider the last unfound vertical word, which is v4. Since we are\\nconsidering the fourth vertical word, we need to look at the fourth letters of\\nthe horizontal words we found:\\n- What is the fourth letter of rille: l\\n- What is the fourth letter of olein: i\\n- What is the fourth letter of tempt: p\\nThe word we are looking fits the clue \"To lisp\" and needs to have the letters l, i\\n, p, and s in its (h1, one) first, (h2, two) second, (h3, three) third letters\\n: l i p _ _. The candidates are: The candidate is \"lisps\".\\n- lisps (l i s p s, l i p _ _) doesn’t fit\\nWe have considered all of the words for the horizontal words, we have two options:\\nabase and abate, let’s choose one of them.\\nanswer:\\nh1. rille\\nh2. olein\\nh3. tempt\\nh4. abase\\nv2. ilebo\\nv3. leman\\nv5. enter\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\nh1. One who saws\\nh2. A fungus genus\\nh3. An assessor\\nh4. Pasture land\\nh5. Receiving by the ear\\nv1. To swell; to increase\\nv2. The Brazilian macaw; an Australian bird\\nv3. A Timorese island\\nv4. Excessive fluid accumulation', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 37}), Document(page_content='v5. Dewy; roscid\\nThe words I already found are:\\nh1. sawer\\nh3. rater\\nv1. surge\\nv4. edema\\nAssistant:\\nThere are two horizontal and two vertical words. Since they are the amount, let’s\\nconsider the next unfound horizontal word, which is h2. Since we are\\nconsidering the second horizontal word, we need to look at the second letters\\nof the vertical words we found:\\n- What is the second letter of surge: u\\n- What is the second letter of edema: d\\nThe word we are looking fits the clue \"A fungus genus\" and needs to have the\\nletters u and d in its (v1, one) first and (v4, four) fourth letters: u _ _ d\\n_. The candidates are: uredo.\\n- uredo (u r e d o, u _ _ d _) fits\\nWe add the word uredo for h2. The current words are:\\nh1. sawer\\nh2. uredo\\nh3. rater\\nv1. surge\\nv4. edema\\nNow, let’s consider the next unfound vertical word, which is v2. Since we are\\nconsidering the second vertical word, we need to look at the second letters of\\nthe horizontal words we found:\\n- What is the second letter of sawer: a\\n- What is the second letter of uredo: r\\n- What is the second letter of rater: a\\nThe word we are looking fits the clue \"The Brazilian macaw; an Australian bird\"\\nand needs to have the letters a, r, and a in its (h1, one) first, (h2, two)\\nsecond, and (h3, third) third letters: a r a _ _. The candidates are: arara.\\n- arara (a r a r a, a r a _ _) fits\\nWe add the word arara for v2. The current words are:\\nh1. sawer\\nh2. uredo\\nh3. rater\\nv1. surge\\nv2. arara\\nv4. edema\\nNow, let’s consider the next unfound horizontal word, which is h4. Since we are\\nconsidering the fourth horizontal word, we need to look at the fourth letters\\nof the vertical words we found:\\n- What is the fourth letter of surge: g\\n- What is the fourth letter of arara: r\\n- What is the fourth letter of edema: m\\nthe word we are looking fits the clue \"Pasture land\" and needs to have the letters\\ng, r, and m in its (v1, one) first, (v2, two) second, and (v4, four) fourth\\nletters: g r _ m _. The candidates are: grama.\\n- grama (g r a m a, g r a _ _) fits\\nWe add the word grama for h4. The current words are:\\nh1. Sawer\\nh2. Uredos\\nh3. Rater\\nh4. Grama\\nv1. surge\\nv2. arara\\nv4. edema\\nNow, let’s consider the next unfound vertical word, which is v3. Since we are\\nconsidering the third vertical word, we need to look at the third letters of\\nthe horizontal words we found:\\n- What is the third letter of sawer: w\\n- What is the third letter of uredo: e\\n- What is the third letter of rater: t', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 38}), Document(page_content='- What is the third letter of grama: a\\nThe word we are looking fits the clue \"A Timorese island\" and needs to have the\\nletters w, e, t, and a in its (h1, one) first, (h2, two) second, (h3, three)\\nthird, and (h4, four) fourth letters: w e t a _. The candidates are: The\\ncandidate is \"wetar\".\\n- wetar (w e t a r, w e t a _) fits\\nWe add the word wetar for v3. The current words are:\\nh1. sawer\\nh2. uredo\\nh3. rater\\nh4. grama\\nv1. surge\\nv2. arara\\nv3. wetar\\nv4. edema\\nNow, let’s consider the last unfound horizontal word, which is h5. Since we are\\nconsidering the fifth horizontal word, we need to look at the fifth letters of\\nthe vertical words we found:\\n- What is the fifth letter of surge: e\\n- What is the fifth letter of arara: a\\n- What is the fifth letter of wetar: r\\n- What is the fifth letter of edema: a\\nThe word we are looking fits the clue \"Receiving by the ear\" and needs to have the\\nletters e, a, r, and a in its (v1, one) first, (v2, two) second, (v3, three)\\nthird, and (v4, four) fourth letters: e a r a _. The candidates are: The\\ncandidate is \"earal\".\\n- earal (e a r a l, e a r a _) fits\\nWe add the word earal for h5. The current words are:\\nh1. sawer\\nh2. uredo\\nh3. rater\\nh4. grama\\nh5. earal\\nv1. surge\\nv2. arara\\nv3. wetar\\nv4. edema\\nSince we found all horizontal words:\\nanswer:\\nh1. sawer\\nh2. uredo\\nh3. rater\\nh4. grama\\nh5. earal\\nv1. surge\\nv2. arara\\nv3. wetar\\nv4. edema\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\nh1. Dandruff; scum; the bull-trout\\nh2. One who greets; to vacillate; a British river\\nh3. A Turkish written decree\\nh4. Mignon; petty; little\\nh5. A bishop’s permission for a priest to leave a diocese\\nv1. To steal; to brush across\\nv2. A sedge (a primitive three-sided grass)\\nv3. Grape jam\\nv4. A flatworm larva\\nv5. Ore refuse; to prepare material for glass by heat\\nh2. waver\\nh5. exeat\\nv1. swipe\\nv2. carex', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 39}), Document(page_content='Assistant:\\nLet’s consider the next unfound horizontal word, which is h1. Since we are\\nconsidering the first horizontal word, we need to look at the first letters of\\nthe vertical words we found:\\n- What is the first letter of swipe: s\\n- What is the first letter of carex: c\\nThe word we are looking fits the clue \"Dandruff; scum; the bull-trout\" and needs\\nto have the letters s and c in its (v1, one) first and (v2, two) second\\nletters: s c _ _ _. The candidates are: scurf.\\n- scurf (s c u r f, s c _ _ _) fits\\nWe add the word scurf for h1. The current words are:\\nh1. scurf\\nh2. waver\\nh5. exeat\\nv1. swipe\\nv2. carex\\nNow, let’s consider the next unfound vertical word, which is v3. Since we are\\nconsidering the third vertical word, we need to look at the third letters of\\nthe horizontal words we found:\\n- What is the third letter of scurf: u\\n- What is the third letter of waver: v\\n- What is the third letter of exeat: e\\nThe word we are looking fits the clue \"Grape jam\" and needs to have the letters u,\\nv, and e in its (h1, one) first, (h2, two) second, and (h5, five) fifth\\nletters: u v _ _ e. The candidates are: The candidate is \"uvetta\".\\n- uvetta (u v e t t a, u v _ _ e) doesn’t fit\\nLet’s consider the next unfound vertical word, which is v4. Since we are\\nconsidering the fourth vertical word, we need to look at the fourth letters of\\nthe horizontal words we found:\\n- What is the fourth letter of scurf: r\\n- What is the fourth letter of waver: e\\n- What is the fourth letter of exeat: a\\nThe word we are looking fits the clue \"A flatworm larva\" and needs to have the\\nletters r, e, and a in its (h1, one) first, (h2, two) second, and (h5, five)\\nfifth letters: r e _ _ a. The candidates are: redia.\\n- redia (r e d i a, r e _ _ a) fits\\nWe add the word redia for v4. The current words are:\\nh1. scurf\\nh2. waver\\nh5. exeat\\nv1. swipe\\nv2. carex\\nv4. redia\\nNow, let’s consider the next unfound horizontal word, which is h3. Since we are\\nconsidering the third horizontal word, we need to look at the third letters of\\nthe vertical words we found:\\n- What is the third letter of swipe: i\\n- What is the third letter of carex: r\\n- What is the third letter of redia: d\\nThe word we are looking fits the clue \"A Turkish written decree\" and needs to have\\nthe letters i, r, and d in its (v1, one) first, (v2, two) second, and (v4,\\nfour) fourth letters: i r _ d _. The candidates are: irade.\\n- irade (i r a d e, i r _ d _) fits\\nWe add the word irade for h3. The current words are:\\nh1. scurf\\nh2. waver\\nh3. irade\\nh5. exeat\\nv1. swipe\\nv2. carex\\nv4. redia\\nNow, let’s consider the last unfound vertical word, which is v5. Since we are\\nconsidering the fifth vertical word, we need to look at the fifth letters of\\nthe horizontal words we found:\\n- What is the fifth letter of scurf: f', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 40}), Document(page_content='- What is the fifth letter of waver: r\\n- What is the fifth letter of irade: e\\n- What is the fifth letter of exeat: t\\nThe word we are looking fits the clue \"Ore refuse; to prepare material for glass\\nby heat\" and needs to have the letters f, r, e, and t in its (h1, one) first,\\n(h2, two) second, (h3, three) third, and (h5, five) fifth letters: f r e _ t.\\nThe candidates are: The candidate is \"frett\".\\n- frett (f r e t t, f r e _ t) fits\\nWe add the word frett for v5. The current words are:\\nh1. scurf\\nh2. waver\\nh3. irade\\nh5. exeat\\nv1. swipe\\nv2. carex\\nv4. redia\\nv5. frett\\nSince we found all horizontal words:\\nanswer:\\nh1. scurf\\nh2. waver\\nh3. irade\\nh5. exeat\\nv1. swipe\\nv2. carex\\nv4. redia\\nv5. frett\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nPropose Words\\nUser:\\nh1. A lunar valley\\nh2. A fatty oil\\nh3. To entice\\nh4. To lower; to reduce\\nh5. A solitary person\\nv1. According to the roster\\nv2. Another name for Port-Francqui\\nv3. An illicit lover; a European lake\\nv4. To lisp\\nv5. To come in\\nAssistant:\\nAll possible 5-letters words for each clue, for each clue we give 10 options:\\nh1. RILLE, VALLIS, CRATER, BASINS, PLAINS\\nh2. OLEIC, OLEIN, GREASE, BUTTER, ANIMAL\\nh3. LURE, TEMPT, SEDUCE, ENTICE, DRAWIN\\nh4. ABASE, LOWER, REDUCE, LESSEN, DEBASE\\nh5. HERMIT, ALONE, LONER, SINGLE, SOLITARY\\nv1. ONTAP, LISTED, ROSTER, SCHEDULE, PLANNED\\nv2. ILEBO, PORTF, CONGO, AFRICA, COLONY\\nv3. LOVER, AMOUR, GENEVA, LEMAN, ZURICH\\nv4. SLUR, LISPS, STUTTER, MUMBLE, STAMMER\\nv5. ENTER, ARRIVE, COMEIN, APPEAR, SHOWUP\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nCreative Writing\\nAoT\\n\"Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph\\nmust be:\\n{0}\\nFirstly, make five different plans for a coherent passage, then write. Your output\\nshould be of the following format:', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 41}), Document(page_content='Plan 1:\\nYour plan here.\\nPlan 2:\\nYour plan here.\\nPlan 3:\\nYour plan here.\\nPlan 4:\\nYour plan here.\\nPlan 5:\\nYour plan here.\\nSecondly, given an instruction and several plans, decide which choice is most\\npromising. Analyze each choice in detail, then conclude in the last line \"The best\\nchoice is {{s}}\", where s the integer id of the choice.\\nThirdly, write the passage according to that chosen plan in the most coherent way. Add\\n\"Passage:\" before writing the passage under it.\\nPassage:\\nYour passage here.\\nFinally, refine the passage in the most coherent way, but you still have to end each\\nparagraph with the given sentences as before.\\nFinal Passage:\\nFinal passage here.\\nScore Prompt\\nAnalyze the following passage, then at the last line conclude \"Thus the coherency\\nscore is {{s}}\", where s is an integer from 1 to 10.\\n{0}\\nAcknowledgment: We appreciate the discussions and assistance provided by L. Wang.\\nContributions: B. Sel played a pivotal role in shaping the primary concept, spearheading the experimental design and eval-\\nuation, and leading the paper’s writing process. A. Tawaha actively engaged in discussions and conducted experiments. V .\\nKhattar collaborated through discussions and played a role in conducting the experiments. R. Jia and M. Jin both engaged in\\nconstructive discussions, with M. Jin also offering advisory guidance.\\nAdditional info about the changes from the first version (dated 8/20/2023) can be found in this link (https://tinyurl.com/\\n2vnjxw93).', metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 42}), Document(page_content='Graph of Thoughts: Solving Elaborate Problems with Large Language Models\\nMaciej Besta1*, Nils Blach1*, Ales Kubicek1, Robert Gerstenberger1,\\nMichał Podstawski2, Lukas Gianinazzi1, Joanna Gajda3, Tomasz Lehmann3,\\nHubert Niewiadomski3, Piotr Nyczyk3, Torsten Hoefler1\\n1ETH Zurich,2Warsaw University of Technology,3Cledar\\nbestam@inf.ethz.ch, nils.blach@inf.ethz.ch, htor@inf.ethz.ch\\nAbstract\\nWe introduce Graph of Thoughts (GoT): a framework that\\nadvances prompting capabilities in large language models\\n(LLMs) beyond those offered by paradigms such as Chain-of-\\nThought or Tree of Thoughts (ToT). The key idea and primary\\nadvantage of GoT is the ability to model the information gen-\\nerated by an LLM as an arbitrary graph , where units of infor-\\nmation (“LLM thoughts”) are vertices, and edges correspond\\nto dependencies between these vertices. This approach en-\\nables combining arbitrary LLM thoughts into synergistic out-\\ncomes, distilling the essence of whole networks of thoughts,\\nor enhancing thoughts using feedback loops. We illustrate\\nthat GoT offers advantages over state of the art on different\\ntasks, for example increasing the quality of sorting by 62%\\nover ToT, while simultaneously reducing costs by >31%.\\nWe ensure that GoT is extensible with new thought transfor-\\nmations and thus can be used to spearhead new prompting\\nschemes. This work brings the LLM reasoning closer to hu-\\nman thinking or brain mechanisms such as recurrence, both\\nof which form complex networks.\\nWebsite & code: https://github.com/spcl/graph-of-thoughts\\n1 Introduction\\nLarge language models (LLMs) are taking over the world\\nof AI. Recent years saw a rapid development of models pri-\\nmarily based on the decoder-only Transformer variant [65],\\nsuch as GPT [13, 14, 53, 54], PaLM [19], or LLaMA [63].\\nPrompt engineering is a resource-efficient approach for\\nsolving different LLM tasks. In brief, one includes the task\\ndescription within the input sent to an LLM. If this descrip-\\ntion is appropriately formulated, the LLM solves the task\\nusing its autoregressive token-based mechanism for gener-\\nating text. Such prompts may contain example tasks with\\nsolutions (few-shot prompting, also referred to as in-context\\nlearning (ICL)), or even no example tasks at all (zero-shot\\nprompting). In recent years it was shown that this mecha-\\nnism can be used to solve a broad set of tasks that involve\\nmathematical, commonsense, or symbolic reasoning.\\nChain-of-Thought (CoT) [71] is an approach for prompt-\\ning, in which one includes the intermediate steps of rea-\\nsoning within the prompt (intermediate “thoughts”), besides\\nthe task input/output. CoT was shown to significantly im-\\nprove the capability of LLMs to solve problems without re-\\nsorting to any model updates. One major improvement over\\n*Equal contributionCoT, Self-Consistency with CoT (CoT-SC) [67], is a scheme\\nwhere multiple CoTs are generated, and then the best one is\\nselected as the outcome. More recently, CoT and CoT-SC\\nwere extended with Tree of Thoughts (ToT) [43, 75, 77],\\nwhich models the LLM reasoning process with a tree. This\\nfacilitates using different paths of thoughts, and offers novel\\ncapabilities such as backtracking from non-promising out-\\ncomes. Unfortunately, the ToT approaches still fundamen-\\ntally limit the reasoning abilities within a prompt by impos-\\ning the rigid tree structure on the thought process.\\nIn this work, we argue that fundamentally more power-\\nful prompting can be achieved by enabling LLM thoughts to\\nform an arbitrary graph structure. This is motivated by nu-\\nmerous phenomena such as human reasoning, brain struc-\\nture, or algorithmic execution. When working on a novel\\nidea, a human would not only follow a chain of thoughts\\n(as in CoT) or try different separate ones (as in ToT), but\\nwould actually form a more complex network of thoughts.\\nFor example, one could explore a certain chain of reason-\\ning, backtrack and start a new one, then realize that a cer-\\ntain idea from the previous chain could be combined with\\nthe currently explored one, and merge them both into a new\\nsolution, taking advantage of their strengths and eliminat-\\ning their weaknesses. Similarly, brains form complex net-\\nworks, with graph-like patterns such as recurrence [28]. Ex-\\necuting algorithms also expose networked patterns, often\\nrepresented by Directed Acyclic Graphs. The correspond-\\ninggraph-enabled transformations bring a promise of more\\npowerful prompting when applied to LLM thoughts, but they\\nare not naturally expressible with CoT or ToT.\\nWe observe that these (and many other) thought trans-\\nformations can be naturally enabled when modeling the\\nreasoning process of an LLM as a graph . For this, we\\npropose Graph of Thoughts (GoT), an approach that en-\\nhances LLMs’ capabilities through networked reasoning\\n(contribution #1 ). In GoT, an LLM thought is modeled\\nas a vertex, while an edge is a dependency between such\\nthoughts. Using GoT, one can aggregate arbitrary thoughts\\nby constructing vertices that have more than one incom-\\ning edge. Overall, the graph abstraction harnessed by GoT\\nseamlessly generalizes CoT and ToT to more complex\\nthought patterns, without resorting to any model updates .\\nYet, putting GoT to practice requires solving several de-\\nsign challenges. For example, what is the best graph struc-\\nture for different tasks? How to best aggregate thoughts to\\nmaximize accuracy and minimize cost? To answer these andarXiv:2308.09687v4  [cs.CL]  6 Feb 2024', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 0}), Document(page_content='many other questions, we carefully design a modular archi-\\ntecture for implementing GoT ( contribution #2 ), coming\\nwith two design highlights. First, we enable a fine-grained\\ncontrol over individual thoughts . This enables us to fully\\ncontrol the ongoing conversation with the LLM, and apply\\nadvanced thought transformations, such as combining most\\npromising thoughts from the ongoing reasoning into a new\\none. Second, we ensure that our architecture can be seam-\\nlessly extended with novel thought transformations, patterns\\nof reasoning (i.e., graphs of thoughts), and LLM models.\\nThis enables rapid prototyping of novel prompting ideas us-\\ning GoT, while experimenting with different models such as\\nGPT-3.5, GPT-4, or Llama-2 [64].\\nWe illustrate several use cases for GoT (sorting, keyword\\ncounting for summaries, set operations, document merging)\\nand we detail how to implement them using the graph-based\\nparadigm ( contribution #3 ). We evaluate GoT and show its\\nadvantages over the state of the art ( contribution #4 ). Over-\\nall, we observe that GoT is particularly well-suited for tasks\\nthat can be naturally decomposed into smaller subtasks that\\nare solved individually and then merged for a final solution.\\nHere, GoT outperforms other schemes, for example improv-\\ning upon CoT and ToT by, respectively, ≈70% and ≈62%,\\nin terms of the quality of sorting, while simultaneously re-\\nducing costs by >31% over ToT.\\nWe qualitatively compare GoT to other prompting\\nschemes1in Table 1. GoT is the only one to enable arbitrary\\ngraph-based thought transformations within a prompt, such\\nas aggregation, embracing all previously proposed schemes.\\nScheme Sc? Mc? Tr? Ag?\\nChain-of-Thought (CoT) [71] /reve /reve /reve\\nSelf-Consistency with CoT [67] /reve /reve\\nThought decomposition [75] /reve\\nTree-of-Thought (ToT) [43] /reve\\nTree of Thoughts (ToT) [77] /reve\\nGraph of Thoughts (GoT) \\nTable 1: Comparison of prompting schemes, with re-\\nspect to the supported transformations of thoughts. “Sc?” :\\nsingle chain of thoughts? “Mc?” : multiple chains of\\nthoughts? “Tr?” : tree of thoughts? “Ag?” : arbitrary graph\\nof thoughts? “ ”: full support, “ ”: partial support, “ /reve”:\\nno support.\\nFinally, we propose a new metric for evaluating a prompt-\\ning strategy, the volume of a thought (contribution #5 ).\\nWith this metric, we aim to understand better the differences\\nbetween prompting schemes. For a given thought v, the vol-\\nume of visthe number of LLM thoughts, from which one\\ncan reach vusing directed edges . Intuitively, these are all\\nthe LLM thoughts that have had the potential to contribute\\n1Note that we do not include a recent scheme called Graph-of-\\nThought [79] because it is not a prompting scheme. While its\\nname suggests close connections to ToT and CoT, as a fine-tuning\\nscheme, it resorts to model updates, and is thus outside the focus\\nof this work. Similarly, the graph-of-thoughts repository [52] does\\nnot enable general graph-based reasoning and harnesses instead\\nToT with BFS.tov. We show that GoT, by incorporating thought transfor-\\nmations such as aggregation, enables thoughts to have fun-\\ndamentally larger volumes than other schemes.\\n2 Background & Notation\\nWe first outline background concepts and notation.\\n2.1 Language Models & In-Context Learning\\nTheconversation with the LLM consists of user messages\\n(prompts ) and LLM replies ( thoughts ). We follow the estab-\\nlished notation [77] and we denote a pre-trained language\\nmodel (LM) with parameters θaspθ. Lowercase letters such\\nasx, y, z, ... indicate LLM thoughts. We purposefully do not\\nprescribe what is a single “thought”, and instead make it use-\\ncase specific. Hence, a single thought can be a paragraph\\n(e.g., in article summary), a document (e.g., in document\\ngeneration), a block of code (e.g., in code debugging or op-\\ntimization), and so on.\\nWe next describe specific prompting approaches .\\nInput-Output (IO) The Input-Output (IO) prompting is a\\nstraightforward approach, in which we use an LLM to turn\\nan input sequence xinto the output ydirectly , without any\\nintermediate thoughts.\\nChain-of-Thought (CoT) Second, in Chain-of-Thought\\n(CoT), one introduces intermediate thoughts a1, a2, ...be-\\ntween xandy. This strategy was shown to significantly en-\\nhance various LM tasks over the plain IO baseline, such as\\nmathematical puzzles [71] or general mathematical reason-\\ning [24].\\nMultiple CoTs Third, one can generalize CoT into multi-\\nple CoTs by generating several (independent) kCoTs, and\\nreturning the one with the best output (according to some\\nprescribed scoring metric). It was introduced by Wang et\\nal. in the scheme called Self-Consistency with CoT (CoT-\\nSC) [67]. This approach enhances CoT because it offers an\\nopportunity to explore different reasoning paths. However,\\nit does not offer “local exploration” within a path, such as\\nbacktracking.\\nTree of Thoughts (ToT) Finally, the Tree of Thoughts\\n(ToT) scheme was introduced independently by Yao [77]\\nand Long [43] (where it is referred to as Tree-of-Thought);\\nit was used implicitly to a certain degree by other schemes\\nsuch as thought decomposition [75]. It enhances CoT-SC by\\nmodeling the process or reasoning as a treeof thoughts. A\\nsingle tree node represents a partial solution. Based on a\\ngiven node, the thought generator constructs a given number\\nkof new nodes. Then, the state evaluator generates scores\\nfor each such new node. Depending on the use case, the eval-\\nuation could be conducted using an LLM itself, or it can har-\\nness human scores. Finally, the schedule of extending the\\ntree is dictated by the utilized search algorithm (for example\\nBFS or DFS).\\n3 The GoT Framework\\nWe now detail the GoT framework. We present it in Figure 1,\\nand compare it to other prompting strategies.\\n2', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 1}), Document(page_content='Input\\nOutputInput\\nOutput OutputThoughts:\\nUnscored\\nNegative\\nscore OutputInput\\nOutput[This work]\\nInput\\nPositive\\nscore\\nDependencies\\nbetween thoughts\\nAbandon thought\\nBacktrackBasic Input-\\nOutput (IO)\\nLegendMultiple CoTs (CoT-SC) Chain-of-\\n-Thought\\n(CoT)Tree of Thoughts (ToT) Graph of Thoughts (GoT)\\nKey novelty:\\nIntermediate\\nLLM thoughts\\nwithin a chainBranching out\\nfrom a chain\\nSelecting\\na chain with\\nthe best scoreAbandon a chain\\nKey novelty\\n(beyond CoT):\\nHarnessing multiple\\nindependent chains\\nof thoughtsKey novelty\\n(beyond CoT-SC):\\nGenerating several\\nnew thoughts based\\non a given arbitrary\\nthought, exploring\\nit further, and possibly\\nbacktracking from itKey novelty (beyond ToT):\\nArbitrary graph-based thought\\ntransformations (aggregating \\nthoughts into a new one, \\nlooping over a thought to \\nrefine it)BacktrackingRefining\\nAggregating\\nthoughtsBacktracking\\nfrom a chain\\nIntermediate\\nthoughts are\\nalso scored\\nAggregating\\nchainsInputFigure 1: Comparison of Graph of Thoughts (GoT) to other prompting strategies.\\nFormally, GoT can be modeled as a tuple (G,T,E,R),\\nwhere Gis the “LLM reasoning process” (i.e., all the LLM\\nthoughts within the context, with their relationships), Tare\\nthe potential thought transformations, Eis an evaluator func-\\ntion used to obtain scores of thoughts, and Ris a ranking\\nfunction used to select most relevant thoughts.\\n3.1 Reasoning Process\\nWe model the reasoning process as a directed graph G=\\n(V, E);Vis a set of vertices and E⊆V×Vis a set of\\nedges. Gis directed and thus the edges are a subset of or-\\ndered vertex pairs E⊆V×V. A vertex contains a solution\\nto a problem at hand (be it an initial, intermediate, or a fi-\\nnal one). The concrete form of such a thought depends on\\nthe use case; it could be a paragraph (in writing tasks) or a\\nsequence of numbers (in sorting). A directed edge (t1, t2)\\nindicates that thought t2has been constructed using t1as\\n“direct input”, i.e., by explicitly instructing the LLM to use\\nt1for generating t2.\\nIn certain use cases, graph nodes belong to different\\nclasses . For example, in writing tasks, some vertices model\\nplans of writing a paragraph , while other vertices model the\\nactual paragraphs of text . In such cases, GoT embraces a\\nheterogeneous graph G= (V, E, c )to model the LLM rea-\\nsoning, where cmaps vertices Vinto their respective classes\\nC(in the above case, it would be C={plan, par }). Hence,\\nany vertex vcan model different aspects of reasoning.\\nWe associate Gwith the LLM reasoning process. To ad-\\nvance this process, one applies thought transformations to\\nG. An example of such a transformation is to merge best-\\nscoring (so far) thoughts into a new one. Another example\\nis to loop over a thought, in order to enhance it. Note that\\nthese transformations strictly extend the set of transforma-\\ntions available in the CoT, CoT-SC, or ToT.\\n3.2 Transformations of Thoughts\\nGoT enables novel transformations of thoughts thanks to\\nthe graph-based model for reasoning. We refer to them as\\n...Graph theory view Example sorting task Example writing taskAggregation Generation...\\n1 2 7 8 1 1 4 5 2 3 6 7\\n1 1 1 2 2 3 4 5 6 7 7 8...\\nArticle\\n1Article\\n2Article\\n3\\nKeyword\\nsummary\\nA vertex models\\na thought. An edge\\nmodels dependency... ...Merging sorted subarrays\\ninto a sorted array of numbers\\nSplitting an unsorted array into\\nsubarrays, for subsequent sortingCombining articles into\\na coherent summary...\\nKeyword\\nsummary 1Keyword\\nsummary 21 4 6 2 4 2 4 9 8 7 5 4\\n1 4 6 2    4 2 4 9    8 7 5 4Article\\n1\\nGenerating summaries from\\nan article, to maximize qualityFigure 2: Examples of aggregation and generation thought\\ntransformations.\\ngraph-enabled transformations . For example, in writing,\\none could combine several input articles into one coherent\\nsummary. In sorting, one could merge several sorted subar-\\nrays of numbers into a final sorted array. We illustrate exam-\\nples of aggregation and generation in Figure 2.\\nFormally, each such transformation can be modeled as\\nT(G, pθ)where G= (V, E)is the graph reflecting the\\ncurrent state of the reasoning, and pθis the used LLM. T\\nmodifies Gusually by adding new vertices and their incom-\\ning edges. We have G′=T(G, pθ) = ( V′, E′), where\\nV′= (V∪V+)\\\\V−andE′= (E∪E+)\\\\E−.V+\\nandE+are new vertices and edges inserted into Gto model\\nthe new thoughts and their dependencies, respectively. To\\nmaximize the expressiveness of GoT – we also enable the\\nuser to explicitly remove thoughts, by specifying the corre-\\nsponding vertices and edges to be removed ( V−andE−, re-\\nspectively). Here, it is the user’s responsibility to ensure that\\nthe sets V+, E+, V−,andE−come with consistent trans-\\nformations (i.e., for example, that the user does not attempt\\nto remove a vertex that does not exist). This enables seam-\\n3', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 2}), Document(page_content='less incorporation of schemes where, in order to save space\\nwithin the context, one can remove parts of reasoning that\\ndo not promise improvements.\\nThe specific form of Tand how it impacts Gdepends on\\na specific transformation. We first detail the primary graph-\\nenabled thought transformations, and then proceed to de-\\nscribe how GoT embraces the transformations from the ear-\\nlier schemes. Unless stated otherwise, V−=E−=∅.\\nAggregation Transformations First, with GoT, one can\\naggregate arbitrary thoughts into new ones, to combine\\nand reinforce the advantages of these thoughts, while elim-\\ninating their disadvantages. In the basic form, in which\\nonly one new vertex is created, V+={v+}andE+=\\n{(v1, v+), ...,(vk, v+)}, where v1, ..., v kare the merged k\\nthoughts. More generally, this enables aggregating reason-\\ning paths , i.e., longer chains of thoughts, beyond just indi-\\nvidual thoughts. With the graph model, it is simply achieved\\nby adding outgoing edges from the vertices v1, ..., v k, mod-\\neling final thoughts in several chains, into a single thought\\nv+combining these chains.\\nRefining Transformations Another thought transforma-\\ntion is the refining of a current thought vby modifying its\\ncontent: V+={}andE+={(v, v)}. This loop in the\\ngraph indicates an iterated thought with the same connec-\\ntions as the original thought.\\nGeneration Transformations Finally, one can generate\\none or more new thoughts based on an existing single\\nthought v. This class embraces analogous reasoning steps\\nfrom earlier schemes, such as ToT or CoT-SC. Formally, we\\nhaveV+={v+\\n1, ..., v+\\nk}andE+={(v, v+\\n1), ...,(v, v+\\nk)}.\\n3.3 Scoring & Ranking Thoughts\\nThoughts are scored to understand whether the current solu-\\ntion is good enough. A score is modeled as a general func-\\ntionE(v, G, p θ), where vis a thought to be evaluated. We\\nuse the state of the whole reasoning process ( G) inEfor\\nmaximum generality, because – for example – in some eval-\\nuation scenarios, scores may be relative to other thoughts.\\nGoT can also rank thoughts. We model this with a func-\\ntionR(G, pθ, h)where hspecifies the number of highest-\\nranking thoughts in Gto be returned by R. While the spe-\\ncific form of Rdepends on the use case, we most often use a\\nsimple yet effective strategy where hthoughts with the high-\\nest scores are returned, i.e., v1, ..., v h=R(G, pθ, h).\\nSpecific forms of EandRdepend on the use case. We dis-\\ncuss the details in Section 5. For example, the score (or rank)\\nfor sorting corresponds to the count of elements correctly\\nsorted (or incorrectly, when using the error as a score).\\n4 System Architecture & Extensibility\\nThe GoT architecture consists of a set of interacting mod-\\nules, see Figure 3 (the blue part). These modules are the\\nPrompter (prepares the messages for the LLM), the Parser\\n(extracts information from LLM thoughts), the Scoring\\nmodule (verifies and scores the LLM thoughts), and theController (coordinates the entire reasoning process, and de-\\ncides on how to progress it). The Controller contains two fur-\\nther important elements: the Graph of Operations (GoO) and\\nthe Graph Reasoning State (GRS). GoO is a static structure\\nthat specifies the graph decomposition of a given task , i.e.,\\nit prescribes transformations to be applied to LLM thoughts,\\ntogether with their order & dependencies. GRS is a dynamic\\nstructure that maintains the state of the ongoing LLM rea-\\nsoning process (the history of its thoughts and their states).\\n4.1 Prompter\\nThe Prompter prepares the prompts to be sent to the LLM.\\nThis module is responsible for the specifics of encoding the\\ngraph structure within the prompt. The GoT architecture en-\\nables the user to implement use case specific graph encod-\\nings by providing full access to the graph structure.\\n4.2 Parser\\nThe Parser extracts information from LLM thoughts. For\\neach such thought, the Parser constructs the thought state ,\\nwhich contains this extracted information. The thought state\\nis then used to update the GRS accordingly.\\n4.3 Scoring & Validation\\nHere, we verify whether a given LLM thought satisfies po-\\ntential correctness conditions, and then we assign it a score.\\nDepending on how the score is derived, the module may\\nconsult the LLM. Moreover, depending on the use case, the\\nscore may also be assigned by a human. Finally, use cases\\nsuch as sorting use simple local scoring functions.\\n4.4 Controller\\nThe Controller implements a specific strategy for select-\\ning thoughts from its GRS structure. It also selects what\\ntransformations should be applied to which thoughts, and\\nthen passes this information to the Prompter. It also decides\\nwhether the whole process should be finalized, or whether\\nthe next round of interaction with the LLM should be initi-\\nated. In our current design, this is dictated by the execution\\nplan specified in the GoO.\\n4.5 GoO & GRS\\nThe user constructs a GoO instance, which prescribes the\\nexecution plan of thought operations. The GoO is a static\\nstructure that is constructed once, before the execution starts.\\nEach operation object knows its predecessor and successor\\noperations. Then, during the execution, an instance of the\\nGRS maintains the continually updated information about\\nthe LLM reasoning process. This includes which operation\\nhas been executed so far, the states of all the generated LLM\\nthoughts, their validity and scores, and any other relevant\\ninformation.\\nThe above elements offer extensible APIs , enabling\\nstraightforward implementations of different prompting\\nschemes. The APIs are outlines in the green part of Fig-\\nure 3, and detailed in the documentation. We also provide\\nexamples of prompts used by these operations and a corre-\\nsponding GRS in the red part of Figure 3.\\n4', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 3}), Document(page_content='Goal: Build a prompt\\nto be sent to the LLMLegend Architecture overview\\nExample prompts and the Graph Reasoning State for the sorting use case (some examples within each prompt are omitted due to space constraints)\\nParser\\nGoal: Extract\\ninformation from\\nLLM thought Goal: Assess the\\nquality of the\\nLLM\\'s solution\\nControllerGoal: Initiate, coordinate, manage,\\nand progress the GoT executionExternal entity Prompt Thought\\nThought stateScore\\nOperation\\nThought state + its\\nassociated operationsThought state\\n+ thought\\'s scoreDependencyModule of the\\nGoT framework Graph of\\nOperations\\nGoal: Specify\\nLLM thought\\ntransformations\\nGraph Reasoning State\\nGoal: Maintain\\nthe ongoing LLM\\nreasoning process\\nUser\\nGoal: Indicate the\\ntop-scoring thoughts\\nGraph of Operations enables seamless specification of not only\\nGoT, but also existing schemes such as CoT, CoT-SC, ToT\\nAPI for Prompter (extensible)\\n➡ Generate(t,k) //generate a prompt for k new thoughts, using thought t➡ //LLM params: model used, temperature, max tokens, api key, org, ...\\n➡ //LLM cost features: prompt token cost, response token cost, ...\\n➡ //Instances of Prompter + Parser + Graph of Operations,\\n➡ //Any additional input parameters (e.g., numbers to be sorted).\\n//Each of the above routines is responsible for parsing an LLM thought\\n//to a corresponding Prompter routine (e.g., ParseScore parses Score).➡ Score(t) //score thought t\\n➡ Validate(t) //generate a prompt to validate the correctness of thought t➡ ValidateAndImprove(t) //generate a prompt to enhance thought t,\\n➡ Aggregate(t1,...,tk) //generate a prompt to combine thoughts t1, ..., tk API for Controller\\nAPI for Parser (extensible)\\nParseGenerate, ParseImprove, ParseScore,\\nParseAggregate, ParseValidate, ...➡ Generate, Aggregate, Score, ... //see Prompter API\\n➡ KeepBest(N) //preserves N best scoring thoughts\\n➡ Repeat(k) //Repeat a given operation k times, generating k thoughts.\\n    //For example, this enables \"Aggregate\" to generate multiple outcomes\\n    //of the combination operation. Each such thought is maintained \\n   //within the Graph Reasoning State and scored individually.Available operations when building the GoO (extensible)\\nSpecifying the Structure of the Graph of Operations (GoO)Ranking Scoring &\\nvalidationPrompter\\nLLM\\nHuman\\nor LLM\\nGray block\\nBlue block\\nA prompt used by\\nAggregate(t1,t2)+Repeat(k=3)+KeepBest(N=1)\\n<Instruction> Merge the following 2 sorted lists of length {length1} each, \\ninto one sorted list of length {length2} using a merge sort style approach.\\nOnly output the final merged list without any additional text or thoughts!\\n</Instruction>\\n<Approach>\\nTo merge the two lists in a merge-sort style approach, follow these steps:\\n1. Compare the first element of both lists.\\n2. Append the smaller element to the merged list and move to the next \\nelement in the list from which the smaller element came.\\n3. Repeat steps 1 and 2 until one of the lists is empty.\\n4. Append the remaining elements of the non-empty list to the merged list.\\n</Approach>\\nMerge the following two lists into one sorted list:\\n1: {input1}\\n2: {input2}\\nMerged list:\\nThis prompt is used by an operation Aggregate where the aggregation factor is \\nk = 2 (2 input thoughts, t1 and t2, are aggregated). This is repeated by GoT 3 times, \\nto maximize quality. Finally, the best result is selected. Note that, in this example, \\nthe prompt explicitly requests the merge operation only. All the remaining opera-\\ntions are specified in the GoO and are handled by the underlying GoT framework.\\nThe input\\nthoughts t1, t2\\n3Initial/system prompt (optional)\\nHello. I want to sort the following input sequence of numbers: {input}I\\n1 2 3I\\n4Improve(t)+Repeat(k=4)\\n<Instruction> The following two lists represent an unsorted list of numbers \\nand a sorted variant of that list. The sorted variant is not correct. Fix the \\nsorted variant so that it is correct. Make sure that the output list is sorted in\\nascending order, has the same number of elements as the input list ({length}),\\nand contains the same elements as the input list. </Instruction>\\n<Approach>\\nTo fix the incorrectly sorted list follow these steps:\\n1. For each number from 0 to 9, compare the frequency of that number in the\\nincorrectly sorted list to the frequency of that number in the input list.\\n2. Iterate through the incorrectly sorted list and add or remove numbers as\\nneeded to make the frequency of each number in the incorrectly sorted list\\nmatch the frequency of that number in the input list.\\n</Approach>\\n<Examples>\\nInput: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9]\\nIncorrectly Sorted: [0, 0, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 7, 7, 8, 8, 9, 9, 9, 9]\\nReason: The incorrectly sorted list contains four extra 0s, two extra 4s and\\nthree extra 9s and is missing two 2s.\\nOutput: [0, 1, 2, 2, 2, 2, 3, 3, 4, 5, 5, 7, 7, 8, 8, 9] \\n    \\nInput: [6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9, 2, 4, 9, 0, 7, 6, 5, 6, 6, 2, 8,\\n3, 9, 5, 6, 1]\\nIncorrectly Sorted: [0, 1, 1, 2, 2, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7,\\n7, 7, 8, 8, 9, 9, 9, 9, 9]\\nReason: The incorrectly sorted list contains two extra 4s and is missing two\\n6s and one 9.\\nOutput: [0, 1, 1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9,\\n9, 9, 9, 9, 9]\\n</Examples>\\nInput: {input}\\nIncorrectly Sorted: {incorrectly_sorted}A prompt used by\\n...\\n...This prompt is used by an operation\\nImprove(t), which enhances a given thought t\\nusing information provided in another thought.\\nDepending on how the Improve + Repeat \\noperation is implemented by the user within\\nGoT, it can either generate a number of new \\nthoughts in GRS (the upper graph on the right), \\nsimilar to Generate + Repeat, or may refine \\nthe same thought in GRS (the lower graph on \\nthe right), chaining k=4 refinement iterations together.\\n4\\nThe input\\nthought tA prompt used by\\nGenerate(t,k=4)\\n<Instruction> Split the following list of 64 numbers into 4 lists of 16\\nnumbers each, the first list should contain the first 16 numbers, the\\nsecond list the second 16 numbers, the third list the third 16 numbers\\nand the fourth list the fourth 16 numbers. Only output the final 4 lists\\nin the following format without any additional text or thoughts!\\n{{\\n    \"List 1\": [3, 4, 3, 5, 7, 8, 1, ...],\\n    \"List 2\": [2, 9, 2, 4, 7, 1, 5, ...],\\n    \"List 3\": [6, 9, 8, 1, 9, 2, 4, ...],\\n    \"List 4\": [9, 0, 7, 6, 5, 6, 6, ...]\\n}} </Instruction>\\n<Example>\\nInput: [3, 1, 9, 3, 7, 5, 5, 4, 8, 1, 5, 3, 3, 2, 3, 0, 9, 7, 2, 2, 4, 4, 8, 5, 0, \\n8, 7, 3, 3, 8, 7, 0, 9, 5, 1, 6, 7, 6, 8, 9, 0, 3, 0, 6, 3, 4, 8, 0, 6, 9, 8, 4, 1, \\n2, 9, 0, 4, 8, 8, 9, 9, 8, 5, 9]\\nOutput:\\n{{\\n    \"List 1\": [3, 1, 9, 3, 7, 5, 5, 4, 8, 1, 5, 3, 3, 2, 3, 0],\\n    \"List 2\": [9, 7, 2, 2, 4, 4, 8, 5, 0, 8, 7, 3, 3, 8, 7, 0],\\n    \"List 3\": [9, 5, 1, 6, 7, 6, 8, 9, 0, 3, 0, 6, 3, 4, 8, 0],\\n    \"List 4\": [6, 9, 8, 4, 1, 2, 9, 0, 4, 8, 8, 9, 9, 8, 5, 9]\\n}}\\n</Example>\\nInput: {input}\\nThis prompt is used by an operation Generate where\\nthe branching factor is k = 4. Four new thoughts are\\nconstructed based on the LLM reply to this prompt.The input\\nthought t1Generate(t,k=1)+Repeat(k=4) A prompt used by\\n<Instruction> Sort the following list of numbers in ascending order.\\nOutput only the sorted list of numbers, no additional text. </Instruction>\\n<Example>\\nInput: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, 5, 6, 6, 4, 4, 5, \\n2, 0, 9, 3, 3, 9, 2, 1]\\nOutput: [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, \\n6, 6, 7, 7, 8, 8, 9, 9, 9]\\n</Example>\\nInput: {input}\\nThe input\\nthought t\\nThis prompt is used by an operation Generate where the\\nbranching factor is k=1, which means, only one thought is\\ngenerated. However, as we chain it with the operation Repeat\\nwith k=4, the underlying GoT framework ensures that Generate\\nexecutes 4 times and results in 4 separate thoughts. Note that, from the graph\\ntheory perspective, the GRS is identical to that in the operation Generate(t, k=4).\\nThe difference between these two is that Generate(t, k=4) gives the user more \\ncontrol over how these multiple thoughts are constructed, while Generate(t, \\nk=1)+Repeat(k=4) is less flexible but more easy to use. Moreover, with Repeat \\none has 4 context-isolated responses from the LLM for identical prompts, \\nwhereas without Repeat there is only one context where all 4 thoughts are\\ngenerated and must be explicitly handled in a single prompt/session.\\n2\\nFigure 3: The system architecture of GoT, and the APIs of respective modules. The user can straightforwardly extend the design\\ntowards new prompting schemes, experiment with novel thought transformations, and plug in different LLMs. The blue part of\\nthe figure contains the architecture overview, the green part lists the API, and the red part contains example prompts together\\nwith a GRS and operations involved.\\n5', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 4}), Document(page_content='5 Example Use Cases\\nWe now describe several use cases of GoT. We detail one\\nuse case (sorting) and summarize the others.\\n5.1 Sorting\\nWe focus on the decomposition of the sorting use case and\\nGraph of Operations, which are central for implementing\\nand executing any workload within GoT.\\nWe consider sorting numbers 0–9 with duplicates. The\\nconsidered LLMs are unable to sort a sequence of such num-\\nbers correctly beyond a certain length consistently because\\nduplicate counts do not match.\\nIn GoT, we employ merge-based sorting: First, one de-\\ncomposes the input sequence of numbers into subarrays.\\nThen, one sorts these subarrays individually, and then re-\\nspectively merges them into a final solution. Figure 4 illus-\\ntrates this use case together with its graph decomposition.\\nHere, an LLM thought is a sequence of sorted numbers.\\nTo score an outcome, denote an input sequence with\\n[a1, a2, ..., a n]and an output one with [b1, b2, ..., b m]. We\\nuse the following score that determines “the scope” of er-\\nrors:\\nerror-scope =X+Y\\nwhere p∈ {1, ..., m},q∈ {1, ..., n}, and\\nX=m−1X\\ni=1sgn(max( bi−bi+1,0)),\\nY=9X\\ni=0| |{bp:bp=i}| − |{ aq:aq=i}| |\\nHere, Xindicates how many consecutive pairs of num-\\nbers are incorrectly sorted. If two numbers iandi+ 1\\nare incorrectly sorted (i.e., bi> bi+1), then the expression\\nwithin the summation returns 1, increasing the error score\\nby one. For two numbers correctly sorted, this expression\\namounts to 0. Then, Ydetermines how well a given output\\nsequence preserves the frequency of output numbers. Specif-\\nically, for each considered number x(x∈ {0, ...,9}), we\\nobtain the difference between the count of input elements\\nbeing equal to x, vs. the count of output elements equal\\ntox. For an output sequence perfectly preserving the fre-\\nquency of x, this would amount to 0. Any single “devia-\\ntion” in this count, increases the “error scope” by 1. We\\nthen sum this over all considered values of x. When plot-\\nting this score, to improve the clarity of plots, we addition-\\nally apply clipping min( error-scope , n), as some baselines\\n(IO, CoT) result in large numbers of outliers with high er-\\nror scope. Finally, to use a “positive score” describing “the\\nscope of correctly sorted” elements, one can use the value\\nmax( n−error-scope ,0).\\n5.2 Set Operations\\nMoreover, we also consider set operations, focusing on set\\nintersection. They have numerous applications (particularly\\nset intersection) in problems ranging from genome or docu-\\nment comparisons to pattern matching [9–11, 20, 27, 38, 50,\\n.....\\n.......... .....1 4  ...  4 316 numbers\\n8 2  ...  1 316 numbers\\n1 1  ...  4 2 1 9  ...  5 416 numbers\\n16 numbers\\nSort\\nPartial solutionGraph of Operations (GoO) for sorting 64 numbers\\nPartial solution Partial solution Partial solution\\nk = 3Generate(k)\\nScoreSort\\nGenerate(k)\\nSort\\nGenerate(k)\\n1 2  ...  7 816 numbers\\n1 1  ...  5 716 numbers\\nPartial solution Partial solution\\n1 2  ...  4 816 numbers\\nPartial solution\\n1 2  ...  7 816 numbers\\n1 1  ...  5 716 numbers\\nPartial solution Partial solution\\n1 2 ... 4 816 numbers\\nPartial solution\\nScore: 78% Score: 86%\\nKeepBest(N)\\nKeep the best\\nscored thoughtsN = 1\\nMerge into a 32\\nelement subarray\\nAggregate(k)\\nk = 10k = 3 k = 3\\nAssess how well each sequence is sorted\\nHow do we score?64 numbers\\n1 4 6 2 4  ...  9 8 7 5 4\\nSplitting into four\\n16-element chunksGenerate(k) k = 1\\nInput\\nSort\\nGenerate(k)\\nk = 3\\nScore: 100%\\n1 2  ...  4 816 numbers\\nPartial solution\\nScore: 100%1 3  ...  4 616 numbers\\nPartial solution\\nScore: 97%..... .....\\n.....1 1  ...  8 932 numbers\\nPartial solution\\nScore: 100%1 1  ...  6 832 numbers\\nPartial solution\\nScore: 97%\\nMerge into a 64\\nelement array\\nAggregate(k)\\nk = 10S\\nScoreS\\nScoreS\\nScoreS\\nScore\\nK\\nG\\nScoreG\\nScoreScore ScoreK K K\\nAG\\nKA\\nAScore\\nScore\\nK KK KKG\\nS\\nAKGLegend\\nGenerateDetails of the highlighted\\npart of GoO are below \\nDetails of the highlighted part of the GoO from above\\nThe first Generate\\nsplits the 64-element\\ninput array into four\\n16-element chunks.\\nSorting is implemented within\\nthe Generate operation. Here,\\nk=3 means that, for each 16\\nelement chunk, we generate\\nthree different sortings. \\nHere, N=1 means that we\\nmaintain a single best\\nsorting outcome out of\\nthe three input ones.\\nHere, k=10 means that we try 10 different\\naggregations of the two input 16-element subarrays.To obtain the score, for every\\nnumber 0 - 9, we get the\\ndifference between the input\\nand the sorted list, and we sum\\nall 10 values. Zero indicates\\ncorrectly sorted. To show\\n\"the higher the better\", we do\\nmax(input_length - score, 0)Note that this is an example graph decomposition. The structure\\nof connections between all operations can be arbitrarily modified.\\nSort\\nKeepBest\\nAggregateFigure 4: An example graph decomposition of the sorting\\nuse case in GoT. All used operations (Generate, Aggregate,\\nScore, KeepBest) are described in Figure 3.\\n6', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 5}), Document(page_content='58]. Set intersection of two sets is implemented similarly as\\nthe sorting. The second input set is split into subsets and the\\nintersection of those subsets with the first input set is deter-\\nmined with the help of the LLM. Afterwards the resulting\\nintersection sets are aggregated for the final results. For the\\nevaluation we use different set sizes of 32, 64 and 128 el-\\nements and we vary the number of elements found in both\\nsets to be between 25% and 75%.\\nOur score indicates the total number of missing or in-\\ncorrectly included elements in the final intersection. Specif-\\nically, denote two input sets with A= [a1, a2, ..., a n]\\nandB= [b1, b2, ..., b n], and the output set with C=\\n[c1, c2, ..., c m]. Then,\\nerror-scope =X1+X2+Xd\\nwhere X1=|C\\\\(A∩B)|are the number of elements in C\\nthat are not supposed to be there, X2=|(A∩B)\\\\C|are the\\nnumber of elements missing from C, and Xdis the number\\nof duplicates in C(because the LLM expresses the set as a\\nlist in natural language). Finally, to use a “positive score”\\ndescribing “the scope of correctly computed” elements, one\\ncan use the value max( n−error-scope ,0).\\n5.3 Keyword Counting\\nKeyword counting finds the frequency of keywords in a\\ngiven category (countries in our example implementation)\\nwithin the input text. GoT splits the input text into multiple\\npassages, counts the keywords in each passage and aggre-\\ngates the subresults. The number of passages is configurable\\nand can also be left to the LLM, making it possible to treat\\neach sentence as a separate passage. Here, to score a thought,\\nwe first – for each keyword – derive the absolute difference\\nbetween the computed count and the correct one. We then\\nsum all these differences to get the final score.\\n5.4 Document Merging\\nFinally, we also provide document merging. Here, the goal\\nis to generate a new Non-Disclosure Agreement (NDA) doc-\\nument based on several input ones that partially overlap\\nin terms of their contents. The goal is to ensure minimal\\namount of duplication, while maximizing information reten-\\ntion. Document merging is broadly applicable in, e.g., legal\\nprocedures, where multiple sources of information have to\\nbe combined into a single document or article. To score a\\nsolution, we query the LLM for two values (3 times for each\\nvalue, and take the average). The first value corresponds to\\nthe solution redundancy (10 indicates no redundancy, 0 im-\\nplies at least half the information is redundant), the second\\nvalue stands for information retention (10 indicates all infor-\\nmation is retained, 0 says that none is retained). We compute\\nthe harmonic mean of these values.\\n6 The Latency-Volume Tradeoff\\nWe now show that GoT improves upon previous prompting\\nschemes in terms of the tradeoff between latency (number of\\nhops in the graph of thoughts to reach a given final thought)\\nandvolume . We define volume – for a given thought t– asthe number of preceding LLM thoughts that could have im-\\npacted t. Formally, the volume of tis the number of thoughts\\nfrom which there exists a path to tin the graph of thoughts.\\nWe assume that outputting a single thought costs O(1)time\\nand fix the total cost to Θ(n)for each prompting scheme.\\nThe structure of the schemes is as follows. CoT-SC con-\\nsists of kindependent chains originating from a single start-\\ning thought. ToT is a complete k-ary tree. Finally, in GoT, a\\ncomplete k-ary tree is joined at its leaves with a “mirrored”\\nk-ary tree of the same size but with its edges reversed.\\nThe analysis is detailed in Table 2. CoT offers a large vol-\\nume of up to N, but at the cost of a high latency of N. CoT-\\nSC reduces the latency by a factor of k(which corresponds\\nto its branching factor), but it simultaneously decreases the\\nvolume by kas well. ToT offers a latency of logkNbut\\nalso has low volume. GoT is the only scheme to come with\\nboth a low latency of logkNand a high volume N. This\\nis enabled by the fact that GoT harnesses aggregations of\\nthoughts, making it possible to reach the final thought from\\nany other intermediate thought in the graph decomposition.\\nScheme Latency Volume\\nChain-of-Thought (CoT) N N\\nSelf-Consistency with CoT (CoT-SC) N/k N/k\\nTree of Thoughts (ToT) logkN O (logkN)\\nGraph of Thoughts (GoT) logkN N\\nTable 2: Comparison of prompting schemes, with respect\\nto their fundamental tradeoff between latency and volume.\\nGoT offers the best tradeoff.\\n7 Evaluation\\nWe show the advantages of GoT over the state of the art. We\\nfocus on comparing GoT to ToT, as it was shown to consis-\\ntently outperform other schemes. Still, for a broad compari-\\nson, we also experiment with IO, CoT, and CoT-SC. As our\\nanalysis results in a large evaluation space, we present rep-\\nresentative results and omit data that does not bring relevant\\ninsights (e.g., CoT-SC).\\n7.1 Evaluation Methodology\\nWe use 100 input samples for each task and comparison\\nbaseline. We set the temperature to 1.0 and use a 4k con-\\ntext size unless stated otherwise. For each experiment, we\\nfix the numbers of thoughts in respective schemes to achieve\\nsimilar costs in each experiment.\\nParameters We experiment extensively with the branch-\\ning factor kand the number of levels Lto ensure that we\\ncompare GoT to cost-effective and advantageous configu-\\nrations. We plot two variants of ToT: one with higher k\\nand lower depth (ToT), the other with lower kbut higher L\\n(ToT2). We usually aim to achieve a sweet spot in the trade-\\noff between sparser generation rounds (lower k) vs. more\\nrounds (larger L). Usually more responses per round is more\\nexpensive (e.g., 80 vs. 60 total responses for Figure 7 but $6\\nvs. $3 costs). We also try different problem sizes P(e.g., in\\nsorting, Pstates how many numbers are to be sorted).\\n7', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 6}), Document(page_content='IOCoT ToTToT2 GoT0246810121416#incorrectly sorted elements; the lower the better\\n32 elements\\n0.00.20.40.60.81.01.21.41.6\\nIOCoT ToTToT2 GoT0481216202428323640444852566064\\n64 elements\\n0.00.30.60.91.21.51.82.12.42.73.03.33.63.94.24.54.8\\nIOCoT ToTToT2 GoT081624324048566472808896104112120128\\n128 elements\\n012345678910111213141516\\nTotal Cost ($); the lower the betterL=2\\nk=20\\nL=3\\nk=10GoT: Figure 4 & Appendix\\nclipped\\nL=4\\nk=20L=7\\nk=10GoT: Figure 4\\n& Appendixclipped\\nL=4\\nk=20\\nL=10\\nk=10GoT:\\nFigure 4\\n&\\nAppendixFigure 5: Number of errors and cost in sorting tasks with ChatGPT-3.5. Landkindicate the structure of ToT (see Sections 3.2\\nand 6).\\nUsed LLMs Due to budget restrictions, we focus on GPT-\\n3.5. We also experimented with Llama-2, but it was usually\\nworse than GPT-3.5 and also much slower to run, making it\\ninfeasible to obtain enough samples.\\n7.2 Analysis of GoT’s Advantages\\nThe results of the analysis are in Figure 5 (sorting), 6 (set\\nintersection), 7 (keyword counting), and 8 (document merg-\\ning); see Section 5 for the description of specific use cases.\\nOverall, GoT improves the quality of outcomes over all the\\nconsidered baselines and it reduces inference costs com-\\npared to ToT .\\nGoT vs. ToT GoT improves upon ToT and ToT2 by a\\nlarge margin over all the considered problem instances. ToT\\nusually comes with somewhat higher quality than ToT2, but\\nsimultaneously much higher costs. GoT’s costs are always\\nlower than ToT, and comparable (in some cases lower, in\\nothers higher) to ToT2. For example, it reduces median er-\\nror by ≈62%, thereby achieving a higher quality of sorting,\\nforP= 128 in comparison to ToT while ensuring >31%\\ncost reductions. These advantages are due to GoT’s ability to\\ndecompose complex tasks into simpler subtasks, solve these\\nsubtasks independently, and then incrementally merge these\\noutcomes into the final result.\\nGoT vs. IO and CoT GoT consistently delivers much\\nhigher quality of outcomes than IO/CoT. For example, for\\nsorting ( P= 64 ), GoT’s median error is ≈65% and ≈83%\\nlower than, respectively, CoT and IO. Yet, the costs of GoT\\n– and ToT – are much higher than in IO and CoT. This is\\nmostly due to our configuration of CoT, where we do not ar-\\ntificially inflate the lengths of the chains of reasoning if this\\ndoes not improve the outcomes. The higher costs of GoT and\\nToT are driven by knew thoughts built for each Generate\\noperation; these multiple thoughts are one of the reasons for\\nGoT’s superiority in quality.\\nIncreasing Complexity of Tackled Problems Most im-\\nportantly, the advantages of GoT in the quality increase for\\nall the baselines with the growing size of the problem P. Forexample, in sorting, while for P= 32 GoT only negligibly\\nimproves upon ToT2, its median error count becomes lower\\nby≈61% for P= 64 and≈69% for P= 128 . The quar-\\ntiles also become respectively better. The results for other\\nschemes also follow the intuition; for example, IO becomes\\nconsistently worse with the increasing P, which is expected\\nas a single thought is unlikely to solve a large problem in-\\nstance. Overall, this analysis illustrates that GoT is indeed\\nwell-suited for elaborate problem cases , as the execution\\nschedules usually become more complex with the growing\\nproblem sizes.\\n7.3 Discussion on Task Decomposition\\nWhen splitting a task into subtasks and then solving these\\nsubtasks, the size of responses and the input (in tokens) are\\nreduced proportionally to the degree of the task decomposi-\\ntion. However, the “static” part of the prompt (i.e., few-shot\\nexamples) may become a significant overhead (see GoT4 to\\nGoT8 in Figure 7). Here, we observe that these few-shot ex-\\namples can usually also be reduced in size (e.g., the passages\\nused to demonstrate keyword counting can also be made\\nsmaller and still be indicative of the actual input size), thus\\nactively working towards decreasing the cost (e.g., see the\\ndifference between GoT8 and GoTx in Figure 7).\\nThe overall goal when conducting graph decomposition is\\nto break down a task to the point, where the LLM can solve\\nit correctly for the majority of time using a single prompt\\n(or with a few additional improvement steps). This signifi-\\ncantly lowers the number of improvement/refinement steps\\nneeded during the later stages of the graph exploration. Fur-\\nthermore, as indicated by our results, combining or concate-\\nnating subresults is usually an easier task than solving large\\ntask instances from scratch. Hence, the LLM is often suc-\\ncessful when aggregating the final solution.\\n8 Related Work\\nWe summarize relations between GoT and related work.\\n8', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 7}), Document(page_content='IOCoT T oTT oT2GoT024681012141618#incorrect elements; the lower the better\\n7 6 31 29 4332 elements\\n0.00.20.40.60.81.01.21.41.61.8\\nIOCoT ToTToT2 GoT048121620242832\\n0 0 0 0 464 elements\\n0.00.61.21.82.43.03.64.24.8\\nIOCoT ToTToT2 GoT0816243240485664728088\\n0 0 0 0 0128 elements\\n01234567891011\\nTotal Cost ($); the lower the betterL=2\\nk=20Solved \\ncorrectly:\\nL=7\\nk=10\\nL=4\\nk=25\\nL=9\\nk=10L=3\\nk=10L=4\\nk=20GoT: Appendix GoT: Appendix GoT: AppendixFigure 6: Number of errors and cost in set intersection tasks with ChatGPT-3.5. Landkindicate the structure of ToT (see\\nSections 3.2 and 6).\\nIO CoT ToT ToT2 GoT4 GoT8 GoTx05101520253035Number of errors; the lower the better\\n0 0 1 0 8 7 25\\n012345678\\nTotal Cost ($); the lower the betterSamples solved\\ncorrectly\\nSplits the input text into 4 passages, counts\\nkeywords in each one, aggregates the sub-\\nresults always 2 at a time\\nL=4\\nk=20\\nL=6\\nk=10Splits the\\ninput into\\nsentences\\n(each input\\nhas 12-19\\nsentences)As GoT4, but splits the\\ninput text into 8 passages\\nFigure 7: Number of errors and cost in keyword counting\\nwith ChatGPT-3.5. Landkindicate the structure of ToT (see\\nSections 3.2 and 6).\\n8.1 Prompting Paradigms & Approaches\\nWe detail different prompting paradigms in Section 1 and\\nTable 1. There are numerous other works related to prompt-\\ning. We now briefly summarize selected most related ones;\\nmore extensive descriptions can be found in dedicated sur-\\nveys [34, 40, 69, 70]. Wang et al. proposed Plan-and-\\nSolve, an approach to enhance CoT with an explicit plan-\\nning stage [66]. Using complexity-based criteria to enhance\\nprompting within a CoT was designed by Fu et al. [29, 67].\\nThe self-taught reasoner (STaR) [80] generates several chain\\nof thoughts, and selects the ones that are valid. Similarly, a\\nscheme by Shum et al. [61] generates a pool of CoT candi-\\ndates, and selects the best candidate based on whether the\\ncandidates match the ground truth and on a policy gradient-\\nbased method. Automatic prompt generation overcomes the\\nIO CoT ToT GoT GoT202468Score (out of 10); the higher the better\\n03691215\\nTotal Cost ($); the lower the betterL=3\\nk=10Aggregation of fully\\nmerged NDAs\\nAggregation\\nof partially\\nmerged\\nNDAsFigure 8: Score and cost in document merging with\\nChatGPT-3.5. Landkindicate the structure of ToT (see Sec-\\ntions 3.2 and 6). Number of samples: 50; context size: 16k\\ntokens.\\nissues of scaling in CoT [41, 42, 59]. Zhou et al. pro-\\npose to harness selecting the best prompt out of a candidate\\nset [84]. Skeleon-of-Thought [47] generates at first a num-\\nber of skeleton answers (brief bullet points of 3 to 5 words)\\nand expands on these points in parallel in a second step.\\nFinally, in prompt chaining, one cascades different LLMs.\\nThis enables prompting different LLMs via different con-\\ntexts, enabling more powerful reasoning [21, 23, 48, 51, 72,\\n73, 73]. GoT is orthogonal to this class of schemes, as it\\nfocuses on a single context capabilities.\\n8.2 Self-Reflection & Self-Evaluation\\nSelf-reflection and self-evaluation were introduced re-\\ncently [45, 49, 60, 75, 85]. They are used to enhance dif-\\nferent tasks, for example for code generation [17] or com-\\n9', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 8}), Document(page_content='puter operation tasks [39]. In GoT, we partially rely on\\nself-evaluation when taking decisions on how to expand the\\ngraph of thoughts within a prompt.\\n8.3 LLMs & Planning\\nThere are many works recently on how to plan complex\\ntasks with LLMs [36, 37, 68, 76, 78, 81]. GoT could be seen\\nas a generic framework that could potentially be used to en-\\nhance such schemes, by offering a paradigm for generating\\ncomplex graph-based plans.\\n8.4 Graphs and Graph Computing\\nGraphs have become an immensely popular and important\\npart of the general computing landscape [31, 32, 44, 46, 56].\\nRecently, there has been a growing interest in domains\\nsuch as graph databases [2–4, 7, 55], graph pattern match-\\ning [8, 10, 11, 18, 25, 62], graph streaming [1, 22, 26],\\nand graph machine learning as well as graph neural net-\\nworks [5, 6, 12, 16, 30, 33, 33, 57, 74, 82, 83]. The graph\\nabstraction has been fruitful for many modern research do-\\nmains, such as social sciences (e.g., studying human inter-\\nactions), bioinformatics (e.g., analyzing protein structures),\\nchemistry (e.g., designing chemical compounds), medicine\\n(e.g., drug discovery), cybersecurity (e.g., identifying in-\\ntruder machines), healthcare (e.g., exposing groups of peo-\\nple who submit fraudulent claims), web graph analysis (e.g.,\\nproviding accurate search services), entertainment services\\n(e.g., predicting movie popularity), linguistics (e.g., model-\\ning relationships between words), transportation (e.g., find-\\ning efficient routes), physics (e.g., understanding phase tran-\\nsitions and critical phenomena), and many others [15, 20,\\n35, 38, 44]. In this work, we harness the graph abstraction\\nas a key mechanism that enhances prompting capabilities in\\nLLMs.\\n9 Conclusion\\nPrompt engineering is one of the central new domains of\\nthe large language model (LLM) research. It enables using\\nLLMs efficiently, without any model updates. However, de-\\nsigning effective prompts is a challenging task.\\nIn this work, we propose Graph of Thoughts (GoT), a new\\nparadigm that enables the LLM to solve different tasks effec-\\ntively without any model updates. The key idea is to model\\nthe LLM reasoning as an arbitrary graph, where thoughts\\nare vertices and dependencies between thoughts are edges.\\nThis enables novel transformations of thoughts, such as ag-\\ngregation. Human’s task solving is often non-linear, and it\\ninvolves combining intermediate solutions into final ones,\\nor changing the flow of reasoning upon discovering new in-\\nsights. GoT reflects this with its graph structure.\\nGoT outperforms other prompting schemes, for example\\nensuring 62% increase in the quality of sorting over ToT,\\nwhile simultaneously reducing costs by >31%. We also pro-\\npose a novel metric for a prompting scheme, the volume of\\na thought, to indicate the scope of information that a given\\nLLM output could carry with it, where GoT also excels. This\\nprovides a step towards more principled prompt engineering.The graph abstraction has been the foundation of several\\nsuccessful designs in computing and AI over last decades,\\nfor example AlphaFold for protein predictions. Our work\\nharnesses it within the realm of prompt engineering.\\nAcknowledgements\\nWe thank Hussein Harake, Colin McMurtrie, Mark Klein, An-\\ngelo Mangili, and the whole CSCS team granting access to the\\nAult and Daint machines, and for their excellent technical sup-\\nport. We thank Timo Schneider for help with infrastructure at\\nSPCL. This project received funding from the European Re-\\nsearch Council (Project PSAP, No. 101002047), and the European\\nHigh-Performance Computing Joint Undertaking (JU) under grant\\nagreement No. 955513 (MAELSTROM). This project was sup-\\nported by the ETH Future Computing Laboratory (EFCL), financed\\nby a donation from Huawei Technologies. This project received\\nfunding from the European Union’s HE research and innovation\\nprogramme under the grant agreement No. 101070141 (Project\\nGLACIATION).\\nReferences\\n[1] Besta, M.; Fischer, M.; Kalavri, V .; Kapralov, M.; and\\nHoefler, T. 2023. Practice of Streaming Processing\\nof Dynamic Graphs: Concepts, Models, and Systems.\\nIEEE Transactions on Parallel and Distributed Sys-\\ntems, 34(6): 1860–1876.\\n[2] Besta, M.; Gerstenberger, R.; Blach, N.; Fischer, M.;\\nand Hoefler, T. 2023. GDI: A Graph Database Inter-\\nface Standard. https://github.com/spcl/GDI-RMA. Ac-\\ncessed: 2023-09-05.\\n[3] Besta, M.; Gerstenberger, R.; Fischer, M.; Podstawski,\\nM.; Blach, N.; Egeli, B.; Mitenkov, G.; Chlapek, W.;\\nMichalewicz, M.; Niewiadomski, H.; M ¨uller, J.; and\\nHoefler, T. 2023. The Graph Database Interface: Scal-\\ning Online Transactional and Analytical Graph Work-\\nloads to Hundreds of Thousands of Cores. In Proceed-\\nings of the International Conference for High Perfor-\\nmance Computing, Networking, Storage and Analysis ,\\nSC ’23. ACM.\\n[4] Besta, M.; Gerstenberger, R.; Peter, E.; Fischer, M.;\\nPodstawski, M.; Barthels, C.; Alonso, G.; and Hoefler,\\nT. 2023. Demystifying Graph Databases: Analysis and\\nTaxonomy of Data Organization, System Designs, and\\nGraph Queries. ACM Comput. Surv. , 56(2).\\n[5] Besta, M.; Grob, R.; Miglioli, C.; Bernold, N.;\\nKwa ´sniewski, G.; Gjini, G.; Kanakagiri, R.; Ashkboos,\\nS.; Gianinazzi, L.; Dryden, N.; and Hoefler, T. 2022.\\nMotif Prediction with Graph Neural Networks. In\\nProceedings of the 28th ACM SIGKDD Conference\\non Knowledge Discovery and Data Mining , KDD ’22,\\n35–45.\\n[6] Besta, M.; and Hoefler, T. 2022. Parallel and Dis-\\ntributed Graph Neural Networks: An In-Depth Concur-\\nrency Analysis. arXiv:2205.09702.\\n[7] Besta, M.; Iff, P.; Scheidl, F.; Osawa, K.; Dryden, N.;\\nPodstawski, M.; Chen, T.; and Hoefler, T. 2022. Neural\\nGraph Databases. In Proceedings of the First Learning\\non Graphs Conference , volume 198 of Proceedings of\\nMachine Learning Research , 31:1–31:38. PMLR.\\n10', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 9}), Document(page_content='[8] Besta, M.; Kanakagiri, R.; Kwa ´sniewski, G.;\\nAusavarungnirun, R.; Ber ´anek, J.; Kanellopoulos,\\nK.; Janda, K.; V onarburg-Shmaria, Z.; Gianinazzi,\\nL.; Stefan, I.; Luna, J. G.; Golinowski, J.; Copik,\\nM.; Kapp-Schwoerer, L.; Di Girolamo, S.; Blach,\\nN.; Konieczny, M.; Mutlu, O.; and Hoefler, T. 2021.\\nSISA: Set-Centric Instruction Set Architecture for\\nGraph Mining on Processing-in-Memory Systems. In\\nProceedings of the 54th Annual IEEE/ACM Interna-\\ntional Symposium on Microarchitecture , MICRO ’21,\\n282–297.\\n[9] Besta, M.; Kanakagiri, R.; Mustafa, H.; Karasikov,\\nM.; R ¨atsch, G.; Hoefler, T.; and Solomonik, E. 2020.\\nCommunication-Efficient Jaccard Similarity for High-\\nPerformance Distributed Genome Comparisons. In\\nProceedings of the IEEE International Parallel and\\nDistributed Processing Symposium , IPDPS ’20, 1122–\\n1132.\\n[10] Besta, M.; Miglioli, C.; Labini, P. S.; T ˇetek, J.; Iff, P.;\\nKanakagiri, R.; Ashkboos, S.; Janda, K.; Podstawski,\\nM.; Kwa ´sniewski, G.; Gleinig, N.; Vella, F.; Mutlu, O.;\\nand Hoefler, T. 2022. ProbGraph: High-Performance\\nand High-Accuracy Graph Mining with Probabilistic\\nSet Representations. In Proceedings of the Interna-\\ntional Conference on High Performance Computing,\\nNetworking, Storage and Analysis , SC ’22. IEEE.\\n[11] Besta, M.; V onarburg-Shmaria, Z.; Schaffner, Y .;\\nSchwarz, L.; Kwa ´sniewski, G.; Gianinazzi, L.; Be-\\nranek, J.; Janda, K.; Holenstein, T.; Leisinger, S.;\\nTatkowski, P.; Ozdemir, E.; Balla, A.; Copik, M.; Lin-\\ndenberger, P.; Konieczny, M.; Mutlu, O.; and Hoe-\\nfler, T. 2021. GraphMineSuite: Enabling High-\\nPerformance and Programmable Graph Mining Algo-\\nrithms with Set Algebra. Proc. VLDB Endow. , 14(11):\\n1922–1935.\\n[12] Bronstein, M. M.; Bruna, J.; LeCun, Y .; Szlam, A.; and\\nVandergheynst, P. 2017. Geometric Deep Learning:\\nGoing beyond Euclidean data. IEEE Signal Process-\\ning Magazine , 34(4): 18–42.\\n[13] Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Ka-\\nplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam,\\nP.; Sastry, G.; Askell, A.; Agarwal, S.; Herbert-V oss,\\nA.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.;\\nZiegler, D.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.;\\nSigler, E.; Litwin, M.; Gray, S.; Chess, B.; Clark, J.;\\nBerner, C.; McCandlish, S.; Radford, A.; Sutskever, I.;\\nand Amodei, D. 2020. Language Models are Few-Shot\\nLearners. In Advances in Neural Information Process-\\ning Systems (NeurIPS ’20) , volume 33, 1877–1901.\\nCurran Associates.\\n[14] Bubeck, S.; Chandrasekaran, V .; Eldan, R.; Gehrke,\\nJ.; Horvitz, E.; Kamar, E.; Lee, P.; Lee, Y . T.; Li,\\nY .; Lundberg, S.; Nori, H.; Palangi, H.; Ribeiro,\\nM. T.; and Zhang, Y . 2023. Sparks of Artificial\\nGeneral Intelligence: Early experiments with GPT-4.\\narXiv:2303.12712.\\n[15] Chakrabarti, D.; and Faloutsos, C. 2006. Graph Min-ing: Laws, Generators, and Algorithms. ACM Comput.\\nSurv. , 38(1).\\n[16] Chami, I.; Abu-El-Haija, S.; Perozzi, B.; R ´e, C.;\\nand Murphy, K. 2020. Machine Learning on\\nGraphs: A Model and Comprehensive Taxonomy.\\narXiv:2005.03675.\\n[17] Chen, X.; Lin, M.; Sch ¨arli, N.; and Zhou, D. 2023.\\nTeaching Large Language Models to Self-Debug.\\narXiv:2304.05128.\\n[18] Cheng, J.; Yu, J. X.; Ding, B.; Philip, S. Y .; and Wang,\\nH. 2008. Fast Graph Pattern Matching. In Proceedings\\nof the IEEE 24th International Conference on Data En-\\ngineering , ICDE ’08, 913–922.\\n[19] Chowdhery, A.; Narang, S.; Devlin, J.; Bosma,\\nM.; Mishra, G.; Roberts, A.; Barham, P.; Chung,\\nH. W.; Sutton, C.; Gehrmann, S.; Schuh, P.; Shi, K.;\\nTsvyashchenko, S.; Maynez, J.; Rao, A.; Barnes, P.;\\nTay, Y .; Shazeer, N.; Prabhakaran, V .; Reif, E.; Du,\\nN.; Hutchinson, B.; Pope, R.; Bradbury, J.; Austin, J.;\\nIsard, M.; Gur-Ari, G.; Yin, P.; Duke, T.; Levskaya,\\nA.; Ghemawat, S.; Dev, S.; Michalewski, H.; Garcia,\\nX.; Misra, V .; Robinson, K.; Fedus, L.; Zhou, D.; Ip-\\npolito, D.; Luan, D.; Lim, H.; Zoph, B.; Spiridonov,\\nA.; Sepassi, R.; Dohan, D.; Agrawal, S.; Omernick,\\nM.; Dai, A. M.; Pillai, T. S.; Pellat, M.; Lewkowycz,\\nA.; Moreira, E.; Child, R.; Polozov, O.; Lee, K.; Zhou,\\nZ.; Wang, X.; Saeta, B.; Diaz, M.; Firat, O.; Catasta,\\nM.; Wei, J.; Meier-Hellstern, K.; Eck, D.; Dean, J.;\\nPetrov, S.; and Fiedel, N. 2022. PaLM: Scaling Lan-\\nguage Modeling with Pathways. arXiv:2204.02311.\\n[20] Cook, D. J.; and Holder, L. B., eds. 2006. Mining\\nGraph Data . John Wiley & Sons.\\n[21] Creswell, A.; Shanahan, M.; and Higgins, I. 2022.\\nSelection-Inference: Exploiting Large Language\\nModels for Interpretable Logical Reasoning.\\narXiv:2205.09712.\\n[22] Dhulipala, L.; Blelloch, G. E.; and Shun, J. 2019. Low-\\nLatency Graph Streaming Using Compressed Purely-\\nFunctional Trees. In Proceedings of the 40th ACM\\nSIGPLAN Conference on Programming Language De-\\nsign and Implementation , PLDI ’19, 918–934.\\n[23] Dohan, D.; Xu, W.; Lewkowycz, A.; Austin, J.; Bieber,\\nD.; Lopes, R. G.; Wu, Y .; Michalewski, H.; Saurous,\\nR. A.; Sohl-Dickstein, J.; Murphy, K.; and Sutton, C.\\n2022. Language Model Cascades. In Beyond Bayes:\\nPaths Towards Universal Reasoning Systems , Work-\\nshop at ICML ’22.\\n[24] Drori, I.; Zhang, S.; Shuttleworth, R.; Tang, L.; Lu, A.;\\nKe, E.; Liu, K.; Chen, L.; Tran, S.; Cheng, N.; Wang,\\nR.; Singh, N.; Patti, T. L.; Lynch, J.; Shporer, A.;\\nVerma, N.; Wu, E.; and Strang, G. 2022. A neural net-\\nwork solves, explains, and generates university math\\nproblems by program synthesis and few-shot learning\\nat human level. Proceedings of the National Academy\\nof Sciences , 119(32): e2123433119.\\n[25] Fan, W.; Li, J.; Ma, S.; Tang, N.; Wu, Y .; and Wu,\\nY . 2010. Graph Pattern Matching: From Intractable\\n11', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 10}), Document(page_content='to Polynomial Time. Proc. VLDB Endow. , 3(1–2):\\n264–275.\\n[26] Feng, G.; Meng, X.; and Ammar, K. 2015. DIS-\\nTINGER: A distributed graph data structure for mas-\\nsive dynamic graph processing. In Proccedings of the\\nIEEE International Conference on Big Data , Big Data\\n’15, 1814–1822.\\n[27] Friggeri, A.; Chelius, G.; and Fleury, E. 2011. Trian-\\ngles to Capture Social Cohesion. In Proceedings of\\nthe IEEE Third International Conference on Privacy,\\nSecurity, Risk and Trust and IEEE Third International\\nConference on Social Computing , PASSAT/SocialCom\\n’11, 258–265.\\n[28] Friston, K. 2008. Hierarchical Models in the Brain.\\nPLOS Computational Biology , 4(11): 1–24.\\n[29] Fu, Y .; Peng, H.; Sabharwal, A.; Clark, P.; and Khot,\\nT. 2022. Complexity-Based Prompting for Multi-Step\\nReasoning. arXiv:2210.00720.\\n[30] Gianinazzi, L.; Fries, M.; Dryden, N.; Ben-Nun, T.;\\nBesta, M.; and Hoefler, T. 2021. Learning Combina-\\ntorial Node Labeling Algorithms. arXiv:2106.03594.\\n[31] Gregor, D.; and Lumsdaine, A. 2005. Lifting Sequen-\\ntial Graph Algorithms for Distributed-Memory Parallel\\nComputation. SIGPLAN Not. , 40(10): 423–437.\\n[32] Gregor, D.; and Lumsdaine, A. 2005. The Parallel\\nBGL: A generic library for distributed graph compu-\\ntations. Parallel Object-Oriented Scientific Computing\\n(POOSC) .\\n[33] Hamilton, W. L.; Ying, R.; and Leskovec, J. 2017. Rep-\\nresentation Learning on Graphs: Methods and Appli-\\ncations. Bulletin of the Technical Committee on Data\\nEngineering , 40(3): 52–74.\\n[34] Hartmann, M.; and Sonntag, D. 2022. A survey on\\nimproving NLP models with human explanations. In\\nProceedings of the First Workshop on Learning with\\nNatural Language Supervision , 40–47. Association for\\nComputational Linguistics.\\n[35] Horv ´ath, T.; G ¨artner, T.; and Wrobel, S. 2004. Cyclic\\nPattern Kernels for Predictive Graph Mining. In Pro-\\nceedings of the Tenth ACM SIGKDD International\\nConference on Knowledge Discovery and Data Min-\\ning, KDD ’04, 158–167.\\n[36] Huang, W.; Abbeel, P.; Pathak, D.; and Mordatch, I.\\n2022. Language Models as Zero-Shot Planners: Ex-\\ntracting Actionable Knowledge for Embodied Agents.\\nInProceedings of the 39th International Conference\\non Machine Learning , volume 162 of Proceedings of\\nMachine Learning Research , 9118–9147. PMLR.\\n[37] Huang, W.; Xia, F.; Xiao, T.; Chan, H.; Liang, J.; Flo-\\nrence, P.; Zeng, A.; Tompson, J.; Mordatch, I.; Cheb-\\notar, Y .; Sermanet, P.; Brown, N.; Jackson, T.; Luu,\\nL.; Levine, S.; Hausman, K.; and Ichter, B. 2022. In-\\nner Monologue: Embodied Reasoning through Plan-\\nning with Language Models. arXiv:2207.05608.\\n[38] Jiang, C.; Coenen, F.; and Zito, M. 2013. A survey of\\nfrequent subgraph mining algorithms. The Knowledge\\nEngineering Review , 28(1): 75–105.[39] Kim, G.; Baldi, P.; and McAleer, S. 2023. Language\\nModels can Solve Computer Tasks. arXiv:2303.17491.\\n[40] Lertvittayakumjorn, P.; and Toni, F. 2021.\\nExplanation-Based Human Debugging of NLP\\nModels: A Survey. Transactions of the Association for\\nComputational Linguistics , 9: 1508–1528.\\n[41] Lester, B.; Al-Rfou, R.; and Constant, N. 2021. The\\nPower of Scale for Parameter-Efficient Prompt Tun-\\ning. In Proceedings of the Conference on Empiri-\\ncal Methods in Natural Language Processing , EMNLP\\n’21, 3045–3059. Association for Computational Lin-\\nguistics.\\n[42] Li, X. L.; and Liang, P. 2021. Prefix-Tuning:\\nOptimizing Continuous Prompts for Generation.\\narXiv:2101.00190.\\n[43] Long, J. 2023. Large Language Model Guided Tree-\\nof-Thought. arXiv:2305.08291.\\n[44] Lumsdaine, A.; Gregor, D.; Hendrickson, B.; and\\nBerry, J. 2007. Challenges in Parallel Graph Process-\\ning. Parallel Processing Letters , 17(1): 5–20.\\n[45] Madaan, A.; Tandon, N.; Gupta, P.; Hallinan, S.; Gao,\\nL.; Wiegreffe, S.; Alon, U.; Dziri, N.; Prabhumoye, S.;\\nYang, Y .; Gupta, S.; Majumder, B. P.; Hermann, K.;\\nWelleck, S.; Yazdanbakhsh, A.; and Clark, P. 2023.\\nSelf-Refine: Iterative Refinement with Self-Feedback.\\narXiv:2303.17651.\\n[46] Malewicz, G.; Austern, M. H.; Bik, A. J.; Dehnert,\\nJ. C.; Horn, I.; Leiser, N.; and Czajkowski, G. 2010.\\nPregel: A System for Large-Scale Graph Processing. In\\nProceedings of the International Conference on Man-\\nagement of Data , SIGMOD ’10, 135–146. ACM.\\n[47] Ning, X.; Lin, Z.; Zhou, Z.; Wang, Z.; Yang, H.; and\\nWang, Y . 2023. Skeleton-of-Thought: Large Language\\nModels Can Do Parallel Decoding. arXiv:2307.15337.\\n[48] Nye, M.; Andreassen, A. J.; Gur-Ari, G.; Michalewski,\\nH.; Austin, J.; Bieber, D.; Dohan, D.; Lewkowycz, A.;\\nBosma, M.; Luan, D.; Sutton, C.; and Odena, A. 2021.\\nShow Your Work: Scratchpads for Intermediate Com-\\nputation with Language Models. arXiv:2112.00114.\\n[49] Paul, D.; Ismayilzada, M.; Peyrard, M.; Borges, B.;\\nBosselut, A.; West, R.; and Faltings, B. 2023. RE-\\nFINER: Reasoning Feedback on Intermediate Repre-\\nsentations. arXiv:2304.01904.\\n[50] Prat-P ´erez, A.; Dominguez-Sal, D.; Brunat, J. M.; and\\nLarriba-Pey, J.-L. 2012. Shaping Communities out\\nof Triangles. In Proceedings of the 21st ACM Inter-\\nnational Conference on Information and Knowledge\\nManagement , CIKM ’12, 1677–1681.\\n[51] Qiao, S.; Ou, Y .; Zhang, N.; Chen, X.; Yao, Y .; Deng,\\nS.; Tan, C.; Huang, F.; and Chen, H. 2023. Reasoning\\nwith Language Model Prompting: A Survey. In Pro-\\nceedings of the 61st Annual Meeting of the Association\\nfor Computational Linguistics , ACL ’23, 5368–5393.\\nAssociation for Computational Linguistics.\\n[52] qrdlgit. 2023. graph-of-thoughts Repository. https:\\n//github.com/qrdlgit/graph-of-thoughts. Accessed:\\n2023-10-11.\\n12', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 11}), Document(page_content='[53] Radford, A.; Narasimhan, K.; Salimans, T.; and\\nSutskever, I. 2018. Improving Language Understand-\\ning by Generative Pre-Training. https://openai.com/\\nresearch/language-unsupervised. Accessed: 2023-09-\\n06.\\n[54] Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.;\\nand Sutskever, I. 2019. Language Models are Unsuper-\\nvised Multitask Learners. https://openai.com/research/\\nbetter-language-models. Accessed: 2023-09-06.\\n[55] Robinson, I.; Webber, J.; and Eifrem, E. 2015. Graph\\nDatabases: New Opportunities for Connected Data .\\nO’Reilly Media, 2nd edition.\\n[56] Sakr, S.; Bonifati, A.; V oigt, H.; Iosup, A.; Ammar, K.;\\nAngles, R.; Aref, W.; Arenas, M.; Besta, M.; Boncz,\\nP. A.; Daudjee, K.; Valle, E. D.; Dumbrava, S.; Har-\\ntig, O.; Haslhofer, B.; Hegeman, T.; Hidders, J.; Hose,\\nK.; Iamnitchi, A.; Kalavri, V .; Kapp, H.; Martens, W.;\\n¨Ozsu, M. T.; Peukert, E.; Plantikow, S.; Ragab, M.; Ri-\\npeanu, M. R.; Salihoglu, S.; Schulz, C.; Selmer, P.; Se-\\nqueda, J. F.; Shinavier, J.; Sz ´arnyas, G.; Tommasini,\\nR.; Tumeo, A.; Uta, A.; Varbanescu, A. L.; Wu, H.-\\nY .; Yakovets, N.; Yan, D.; and Yoneki, E. 2021. The\\nFuture is Big Graphs: A Community View on Graph\\nProcessing Systems. Commun. ACM , 64(9): 62–71.\\n[57] Scarselli, F.; Gori, M.; Tsoi, A. C.; Hagenbuchner, M.;\\nand Monfardini, G. 2008. The Graph Neural Network\\nModel. IEEE Transactions on Neural Networks , 20(1):\\n61–80.\\n[58] Schaeffer, S. E. 2007. Graph clustering. Computer\\nScience Review , 1(1): 27–64.\\n[59] Shin, T.; Razeghi, Y .; Logan IV , R. L.; Wallace, E.;\\nand Singh, S. 2020. AutoPrompt: Eliciting Knowledge\\nfrom Language Models with Automatically Generated\\nPrompts. arXiv:2010.15980.\\n[60] Shinn, N.; Labash, B.; and Gopinath, A. 2023. Re-\\nflexion: Language Agents with Verbal Reinforcement\\nLearning. arXiv:2303.11366.\\n[61] Shum, K.; Diao, S.; and Zhang, T. 2023. Automatic\\nPrompt Augmentation and Selection with Chain-of-\\nThought from Labeled Data. arXiv:2302.12822.\\n[62] Teixeira, C. H. C.; Fonseca, A. J.; Serafini, M.;\\nSiganos, G.; Zaki, M. J.; and Aboulnaga, A. 2015.\\nArabesque: A System for Distributed Graph Mining.\\nInProceedings of the 25th Symposium on Operating\\nSystems Principles , SOSP ’15, 425–440. ACM.\\n[63] Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.;\\nLachaux, M.-A.; Lacroix, T.; Rozi `ere, B.; Goyal,\\nN.; Hambro, E.; Azhar, F.; Rodriguez, A.; Joulin,\\nA.; Grave, E.; and Lample, G. 2023. LLaMA:\\nOpen and Efficient Foundation Language Models.\\narXiv:2302.13971.\\n[64] Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Alma-\\nhairi, A.; Babaei, Y .; Bashlykov, N.; Batra, S.; Bhar-\\ngava, P.; Bhosale, S.; Bikel, D.; Blecher, L.; Ferrer,\\nC. C.; Chen, M.; Cucurull, G.; Esiobu, D.; Fernandes,\\nJ.; Fu, J.; Fu, W.; Fuller, B.; Gao, C.; Goswami, V .;\\nGoyal, N.; Hartshorn, A.; Hosseini, S.; Hou, R.; Inan,H.; Kardas, M.; Kerkez, V .; Khabsa, M.; Kloumann,\\nI.; Korenev, A.; Koura, P. S.; Lachaux, M.-A.; Lavril,\\nT.; Lee, J.; Liskovich, D.; Lu, Y .; Mao, Y .; Martinet,\\nX.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y .;\\nPoulton, A.; Reizenstein, J.; Rungta, R.; Saladi, K.;\\nSchelten, A.; Silva, R.; Smith, E. M.; Subramanian,\\nR.; Tan, X. E.; Tang, B.; Taylor, R.; Williams, A.;\\nKuan, J. X.; Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y .; Fan,\\nA.; Kambadur, M.; Narang, S.; Rodriguez, A.; Sto-\\njnic, R.; Edunov, S.; and Scialom, T. 2023. Llama\\n2: Open Foundation and Fine-Tuned Chat Models.\\narXiv:2307.09288.\\n[65] Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.;\\nJones, L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I.\\n2017. Attention is All you Need. In Advances in Neu-\\nral Information Processing Systems (NIPS ’17) , vol-\\nume 30. Curran Associates.\\n[66] Wang, L.; Xu, W.; Lan, Y .; Hu, Z.; Lan, Y .; Lee, R.\\nK.-W.; and Lim, E.-P. 2023. Plan-and-Solve Prompt-\\ning: Improving Zero-Shot Chain-of-Thought Reason-\\ning by Large Language Models. In Proceedings of the\\n61st Annual Meeting of the Association for Computa-\\ntional Linguistics , ACL ’23, 2609–2634. Association\\nfor Computational Linguistics.\\n[67] Wang, X.; Wei, J.; Schuurmans, D.; Le, Q. V .; Chi,\\nE. H.; Narang, S.; Chowdhery, A.; and Zhou, D. 2023.\\nSelf-Consistency Improves Chain of Thought Rea-\\nsoning in Language Models. In Proceedings of the\\nEleventh International Conference on Learning Rep-\\nresentations , ICLR ’23.\\n[68] Wang, Z.; Cai, S.; Chen, G.; Liu, A.; Ma, X.; and\\nLiang, Y . 2023. Describe, Explain, Plan and Select:\\nInteractive Planning with Large Language Models En-\\nables Open-World Multi-Task Agents. In Advances in\\nNeural Information Processing Systems (NeurIPS ’23) ,\\nvolume 36. Curran Associates.\\n[69] Wang, Z.; Zhang, G.; Yang, K.; Shi, N.; Zhou, W.;\\nHao, S.; Xiong, G.; Li, Y .; Sim, M. Y .; Chen, X.;\\nZhu, Q.; Yang, Z.; Nik, A.; Liu, Q.; Lin, C.; Wang,\\nS.; Liu, R.; Chen, W.; Xu, K.; Liu, D.; Guo, Y .; and\\nFu, J. 2023. Interactive Natural Language Processing.\\narXiv:2305.13246.\\n[70] Wang, Z. J.; Choi, D.; Xu, S.; and Yang, D. 2021.\\nPutting Humans in the Natural Language Processing\\nLoop: A Survey. In Proceedings of the First Work-\\nshop on Bridging Human-Computer Interaction and\\nNatural Language Processing , 47–52. Association for\\nComputational Linguistics.\\n[71] Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Chi,\\nE.; Le, Q.; and Zhou, D. 2022. Chain-of-Thought\\nPrompting Elicits Reasoning in Large Language Mod-\\nels. arXiv:2201.11903.\\n[72] Wu, T.; Jiang, E.; Donsbach, A.; Gray, J.; Molina, A.;\\nTerry, M.; and Cai, C. J. 2022. PromptChainer: Chain-\\ning Large Language Model Prompts through Visual\\nProgramming. In Extended Abstracts of the Confer-\\nence on Human Factors in Computing Systems , CHI\\nEA ’22. ACM.\\n13', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 12}), Document(page_content='[73] Wu, T.; Terry, M.; and Cai, C. J. 2022. AI Chains:\\nTransparent and Controllable Human-AI Interaction\\nby Chaining Large Language Model Prompts. In Pro-\\nceedings of the Conference on Human Factors in Com-\\nputing Systems , CHI ’22. ACM.\\n[74] Wu, Z.; Pan, S.; Chen, F.; Long, G.; Zhang, C.; and Yu,\\nP. S. 2021. A Comprehensive Survey on Graph Neural\\nNetworks. IEEE Transactions on Neural Networks and\\nLearning Systems , 32(1): 4–24.\\n[75] Xie, Y .; Kawaguchi, K.; Zhao, Y .; Zhao, X.; Kan, M.-\\nY .; He, J.; and Xie, Q. 2023. Self-Evaluation Guided\\nBeam Search for Reasoning. In Advances in Neural\\nInformation Processing Systems (NeurIPS ’23) , vol-\\nume 36. Curran Associates.\\n[76] Yang, S.; Nachum, O.; Du, Y .; Wei, J.; Abbeel, P.; and\\nSchuurmans, D. 2023. Foundation Models for Deci-\\nsion Making: Problems, Methods, and Opportunities.\\narXiv:2303.04129.\\n[77] Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.;\\nCao, Y .; and Narasimhan, K. R. 2023. Tree of\\nThoughts: Deliberate Problem Solving with Large\\nLanguage Models. In Advances in Neural Information\\nProcessing Systems (NeurIPS ’23) , volume 36. Curran\\nAssociates.\\n[78] Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.;\\nNarasimhan, K. R.; and Cao, Y . 2023. ReAct: Syner-\\ngizing Reasoning and Acting in Language Models. In\\nProceedings of the Eleventh International Conference\\non Learning Representations , ICLR ’23.\\n[79] Yao, Y .; Li, Z.; and Zhao, H. 2023. Beyond Chain-\\nof-Thought, Effective Graph-of-Thought Reasoning in\\nLarge Language Models. arXiv:2305.16582.\\n[80] Zelikman, E.; Wu, Y .; Mu, J.; and Goodman, N. 2022.\\nSTaR: Bootstrapping Reasoning With Reasoning. In\\nAdvances in Neural Information Processing Systems\\n(NeurIPS ’22) , volume 35, 15476–15488. Curran As-\\nsociates.\\n[81] Zhang, S.; Chen, Z.; Shen, Y .; Ding, M.; Tenenbaum,\\nJ. B.; and Gan, C. 2023. Planning with Large Lan-\\nguage Models for Code Generation. In Proceedings\\nof the Eleventh International Conference on Learning\\nRepresentations , ICLR ’23.\\n[82] Zhang, Z.; Cui, P.; and Zhu, W. 2022. Deep Learning\\non Graphs: A Survey. IEEE Transactions on Knowl-\\nedge and Data Engineering , 34(1): 249–270.\\n[83] Zhou, J.; Cui, G.; Hu, S.; Zhang, Z.; Yang, C.; Liu,\\nZ.; Wang, L.; Li, C.; and Sun, M. 2020. Graph neural\\nnetworks: A review of methods and applications. AI\\nOpen , 1: 57–81.\\n[84] Zhou, Y .; Muresanu, A. I.; Han, Z.; Paster, K.;\\nPitis, S.; Chan, H.; and Ba, J. 2022. Large Lan-\\nguage Models Are Human-Level Prompt Engineers.\\narXiv:2211.01910.\\n[85] Zhu, X.; Wang, J.; Zhang, L.; Zhang, Y .; Huang, Y .;\\nGan, R.; Zhang, J.; and Yang, Y . 2023. Solving Math\\nWord Problems via Cooperative Reasoning inducedLanguage Models. In Proceedings of the 61st Annual\\nMeeting of the Association for Computational Linguis-\\ntics, ACL ’23, 4471–4485. Association for Computa-\\ntional Linguistics.\\n14', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 13}), Document(page_content='A Positive Score Evaluation\\nThe following figures plot the same data as Figures 5 and 6\\nrespectively, however use the ”positive score” described in\\nSections 5.1 and 5.2.\\nIOCoT ToTToT2 GoT0481216202428323640444852566064\\n64 elements\\n0.00.30.60.91.21.51.82.12.42.73.03.33.63.94.24.54.8\\nIOCoT ToTToT2 GoT081624324048566472808896104112120128\\n128 elements\\n012345678910111213141516\\nTotal Cost ($); the lower the better\\nIOCoT ToTToT2 GoT161820222426283032#correct elements; the higher the better\\n32 elements\\n0.00.20.40.60.81.01.21.41.6L=2\\nk=20\\nL=3\\nk=10GoT: Figure 4 GoT: Figure 4 GoT: Figure 4\\nL=4\\nk=20L=7\\nk=10L=4\\nk=20\\nL=10\\nk=10\\nFigure 9: Accuracy and cost in sorting tasks with ChatGPT-\\n3.5.Landkindicate the structure of ToT (see Sections 3.2\\nand 6).\\nIOCoT ToTToT2 GoT8101214161820222426283032#correct elements; the higher the better\\n7 6 31 29 4332 elements\\n0.00.20.40.60.81.01.21.41.61.82.02.22.4\\nIOCoT ToTToT2 GoT16202428323640444852566064\\n0 0 0 0 464 elements\\n0.00.20.40.60.81.01.21.41.61.82.02.22.4\\nIOCoT ToTToT2 GoT081624324048566472808896104112120128\\n0 0 0 0 0128 elements\\n0.00.51.01.52.02.53.03.54.04.55.05.56.06.57.07.58.0\\nTotal Cost ($); the lower the betterL=2\\nk=20\\nL=3\\nk=10Samples\\nsolved\\ncorrectly:\\nL=4\\nk=20L=7\\nk=10L=4\\nk=25L=9\\nk=10\\nFigure 10: Accuracy and cost in set intersection with\\nChatGPT-3.5. Landkindicate the structure of ToT (see Sec-\\ntions 3.2 and 6).\\nB Example Prompts - Sorting\\nWe present the prompts only for the sorting of 32-element\\nlists, as those for 64-element and 128-element lists are iden-\\ntical, except for the split prompt where the number of ele-\\nments in the one-shot example matches the problem size.\\nFor sorting, we employ three distinct types of operations\\nthat interact with the LLM, each with its corresponding\\nprompts. First, there is the Generate operation, utilizing the\\nsort prompt to guide the LLM in sorting a provided list of\\nvalues, and the split prompt to direct the LLM to split a spec-\\nified list into a designated number of sublists. Next, the Im-\\nprove operation employs the improve prompt to instruct the\\nLLM to refine a sorted list if it detects mistakes. Finally, the\\nAggregate operation leverages the merge prompt to guide\\nthe LLM in merging two pre-sorted lists into a single sorted\\nlist.\\nFirst, we present the prompt stubs (Table 3), serving as\\ntemplates to dynamically generate appropriate prompts at\\nruntime. For clarity, we display their corresponding few-shot\\nexamples separately in Table 4. Following this, we outlinethe LLM interactions throughout the process of solving the\\nsorting use case (Table 5 - Table 9).\\n15', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 14}), Document(page_content='Table 3: Prompt stubs for the sorting tasks; parameters in single curly brackets will be substituted at runtime.\\nsort prompt: <Instruction >Sort the following list of numbers in ascending order. Output only the sorted list of numbers,\\nno additional text. </Instruction >\\n<Examples >See Table 4 </Examples >\\nInput:{input list}\\nsplit prompt (32 elements): <Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first\\nlist should contain the first 16 numbers and the second list the second 16 numbers.\\nOnly output the final 2 lists in the following format without any additional text or thoughts!:\\n{{\\n\"List 1\": [3, 4, 3, 5, 7, 8, 1, ...],\\n\"List 2\": [2, 9, 2, 4, 7, 1, 5, ...]\\n}}\\n</Instruction >\\n<Examples >See Table 4 </Examples >\\nInput:{input list}\\nimprove prompt: <Instruction >The following two lists represent an unsorted list of numbers and a sorted variant of that\\nlist. The sorted variant is not correct. Fix the sorted variant so that it is correct. Make sure that the output list is sorted in\\nascending order, has the same number of elements as the input list ( {length}), and contains the same elements as the input\\nlist.</Instruction >\\n<Approach >\\nTo fix the incorrectly sorted list follow these steps:\\n1. For each number from 0 to 9, compare the frequency of that number in the incorrectly sorted list to the frequency of that\\nnumber in the input list.\\n2. Iterate through the incorrectly sorted list and add or remove numbers as needed to make the frequency of each number in\\nthe incorrectly sorted list match the frequency of that number in the input list.\\n</Approach >\\n<Examples >See Table 4 </Examples >\\nInput:{input list}\\nIncorrectly Sorted: {sorted list}\\nmerge prompt: <Instruction >Merge the following 2 sorted lists of length {length}each, into one sorted list of length\\n{length combined }using a merge sort style approach. Only output the final merged list without any additional text or\\nthoughts!: </Instruction >\\n<Approach >\\nTo merge the two lists in a merge-sort style approach, follow these steps:\\n1. Compare the first element of both lists.\\n2. Append the smaller element to the merged list and move to the next element in the list from which the smaller element\\ncame.\\n3. Repeat steps 1 and 2 until one of the lists is empty.\\n4. Append the remaining elements of the non-empty list to the merged list.\\n</Approach >\\nMerge the following two lists into one sorted list:\\n1.{input list1}\\n2.{input list2}\\nMerged list:\\n16', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 15}), Document(page_content='Table 4: Few-shot examples for each prompt used for the sorting tasks; some lists are truncated for brevity.\\nsort prompt:\\n<Examples >\\nInput: [5, 1, 0, 1, 2, 0, 4, 8, 1, 9, 5, 1, 3, 3, 9, 7]\\nOutput: [0, 0, 1, 1, 1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 9, 9]\\nInput: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, . . .(Omitted 14/32 numbers) ]\\nOutput: [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, . . .(Omitted 14/32 numbers) ]\\nInput: [4, 4, 9, 7, 9, 7, 0, 0, 4, 9, 1, 7, 9, 5, 8, 7, 5, 6, . . .(Omitted 46/64 numbers) ]\\nOutput: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, . . .(Omitted 46/64 numbers) ]\\n</Examples >\\nsplit prompt (32 elements):\\n<Examples >\\nInput: [9, 6, 7, 7, 2, 0, 2, 2, 3, 5, 0, 9, 2, 2, 4, 4, 5, 2, . . .(Omitted 14/32 numbers) ]\\nOutput:\\n{{\\n\"List 1\": [9, 6, 7, 7, 2, 0, 2, 2, 3, 5, 0, 9, 2, 2, 4, 4],\\n\"List 2\": [5, 2, 5, 1, 2, 8, 3, 8, 3, 9, 6, 0, 4, 2, 2, 3]\\n}}\\n</Examples >\\nimprove prompt:\\n<Examples >\\nInput: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9]\\nIncorrectly Sorted: [0, 0, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 7, 7, 8, 8, 9, 9, 9, 9]\\nReason: The incorrectly sorted list contains four extra 0s, two extra 4s and three extra 9s and is\\nmissing two 2s.\\nOutput: [0, 1, 2, 2, 2, 2, 3, 3, 4, 5, 5, 7, 7, 8, 8, 9]\\nInput: [6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9, 2, 4, . . .(Omitted 14/32 numbers) ]\\nIncorrectly Sorted: [0, 1, 1, 2, 2, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, . . .(Omitted 14/32 numbers) ]\\nReason: The incorrectly sorted list contains two extra 4s and is missing two 6s and one 9.\\nOutput: [0, 1, 1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, . . .(Omitted 14/32 numbers) ]\\nInput: [4, 4, 9, 7, 9, 7, 0, 0, 4, 9, 1, 7, 9, 5, 8, 7, 5, 6, . . .(Omitted 46/64 numbers) ]\\nIncorrectly Sorted: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, . . .(Omitted 46/64 numbers) ]\\nReason: The incorrectly sorted list contains one extra 8 and is missing two 2s, one 3, three 4s, two\\n5s, one 6, six 7s and one 9.\\nOutput: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, . . .(Omitted 46/64 numbers) ]\\n</Examples >\\nmerge prompt: -\\n17', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 16}), Document(page_content='Table 5: Sorting of a 32 element list: Execution plan ( GoO )\\nGoO:\\n1. Split the input list into two sub-lists of equal size (split prompt)\\n2. For each sub-list: Sort the sub-list (sort prompt) five times; score each sort attempt; keep the best\\n3. Merge the sorted sub-lists into one fully sorted list (merge prompt) 10 times; score each merge attempt; keep the best\\n4. Fix any potential mistakes in the sorted list (improve prompt) 10 times; score each improvement attempt; keep the best\\nTable 6: Sorting of a 32 element list: Step 1 (Prompt/Response)\\nStep 1 – Prompt:\\n<Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first list should contain the first 16\\nnumbers and the second list the second 16 numbers.\\nOnly output the final 2 lists in the following format without any additional text or thoughts!:\\n{{\\n\"List 1\": [3, 4, 3, 5, 7, 8, 1, ...],\\n\"List 2\": [2, 9, 2, 4, 7, 1, 5, ...]\\n}}\\n</Instruction >\\n<Examples >See Table 4 </Examples >\\nInput: [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1, 0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\\nStep 1 – Response (Fully Correct):\\n{{\\n\"List 1\": [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1],\\n\"List 1\": [0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\\n}}\\n18', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 17}), Document(page_content='Table 7: Sorting of a 32 element list: Step 2 (Prompts/Responses)\\nStep 2a – Prompt:\\n<Instruction >Sort the following list of numbers in ascending order. Output only the sorted list of numbers, no additional\\ntext.</Instruction >\\n<Examples >See Table 4 </Examples >\\nInput: [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1]\\nStep 2a – 5 Responses:\\n1.[0, 0, 1, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (Fully Correct)\\n2.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\\n3.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\\n4.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\\n5.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\\nStep 2b – Prompt:\\n<Instruction >Sort the following list of numbers in ascending order. Output only the sorted list of numbers, no additional\\ntext.</Instruction >\\n<Examples >See Table 4 </Examples >\\nInput: [0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\\nStep 2b – 5 Responses:\\n1.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\\n2.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\\n3.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\\n4.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 8, 9] (Fully Correct)\\n5.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\\n19', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 18}), Document(page_content='Table 8: Sorting of a 32 element list: Step 3 (Prompt/Responses)\\nStep 3 – Prompt:\\n<Instruction >Merge the following 2 sorted lists of length 16 each, into one sorted list of length 32 using a merge sort style\\napproach. Only output the final merged list without any additional text or thoughts!: </Instruction >\\n<Approach >\\nTo merge the two lists in a merge-sort style approach, follow these steps:\\n1. Compare the first element of both lists.\\n2. Append the smaller element to the merged list and move to the next element in the list from which the smaller element\\ncame.\\n3. Repeat steps 1 and 2 until one of the lists is empty.\\n4. Append the remaining elements of the non-empty list to the merged list.\\n</Approach >\\nMerge the following two lists into one sorted list:\\n1.[0, 0, 1, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9]\\n2.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 8, 9]\\nMerged list:\\nStep 3 – 10 Responses:\\n1.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and one 5)\\n2.[0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing two 1s)\\n3.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and got one extra 6)\\n4.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9]\\n(3 Errors - Missing one 1, one 9 and got one extra 6)\\n5.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and got one extra 6)\\n6.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and one 5)\\n7.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and got one extra 6)\\n8.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(1 Error - Missing one 1)\\n9.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(1 Error - Missing one 1)\\n10.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and one 5)\\n20', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 19}), Document(page_content='Table 9: Sorting of a 32 element list: Step 4 (Prompt/Responses)\\nStep 4 – Prompt:\\n<Instruction >The following two lists represent an unsorted list of numbers and a sorted variant of that list. The sorted\\nvariant is not correct. Fix the sorted variant so that it is correct. Make sure that the output list is sorted in ascending order,\\nhas the same number of elements as the input list (32), and contains the same elements as the input list. </Instruction >\\n<Approach >\\nTo fix the incorrectly sorted list follow these steps:\\n1. For each number from 0 to 9, compare the frequency of that number in the incorrectly sorted list to the frequency of that\\nnumber in the input list.\\n2. Iterate through the incorrectly sorted list and add or remove numbers as needed to make the frequency of each number in\\nthe incorrectly sorted list match the frequency of that number in the input list.\\n</Approach >\\n<Examples >See Table 4 </Examples >\\nInput: [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1, 0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\\nIncorrectly Sorted: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8,\\n8, 9, 9]\\nStep 4 – 10 Responses:\\n1. Reason: The incorrectly sorted list is missing two 0s, one 3, one 4, one 6 and one\\n9. The incorrectly sorted list also contains one extra 1, one extra 2, and one extra 5.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 5, 5, 5,\\n6, 6, 6, 6, 7, 7, 8, 8, 9, 9] 4 Errors - Missing one 1, two 4s and one 5\\nNote: The output list has the same number of elements as the input list, is sorted in ascending order, and con-\\ntains the same elements as the input list.\\n2.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7,\\n8, 8, 9, 9] 1 Error - One extra 6\\n3.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6,\\n7, 7, 7, 8, 8, 8, 9, 9, 9] 6 Errors - One extra 2, 5, 6, 7, 8 and 9\\n4. Reason: The incorrectly sorted list is missing two 9s and one 0.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7,\\n7, 8, 8, 9, 9, 9, 9] 3 Errors - Missing one 1 and has two extra 9s\\n5. Reason: The incorrectly sorted list is missing one 0, one 3, one 4, four 6s, and one 9.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\\n6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 9] 10 Errors - Missing one 1, 2, has four extra 6s, one extra 7, 8 and two extra 9s\\n6.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6,\\n7, 7, 7, 7, 8, 8, 8, 9, 9, 9, 9] 8 Errors - Has one extra 2, 3, 6, two extra 7s, one extra 8 and two extra 9s\\n7.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8,\\n8, 9, 9] 2 Errors - Missing one 1 and has one extra 4\\n8. Reason: The incorrectly sorted list is missing three 0s, two 3s, two 4s, one 5, two 6s, and one 9.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6,\\n6, 7, 7, 8, 8, 9] 5 Errors - Missing one 1, 9, has one extra 3 and two extra 6s\\n9. Reason: The incorrectly sorted list is missing one 0, three 2s, two 3s, two 4s, three 5s, two 6s, one 7, and one 9.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 5, 6,\\n6, 6, 6, 6, 7, 8, 8, 9, 9] 8 Errors - Missing one 1, one 7, has two extra 2s, two extra 3s, one extra 5 and 6\\n10.Reason: The incorrectly sorted list is missing three 1s, one 3, one 4, two 5s, one 6, one 7, one 8, and one 9.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7,\\n7, 8, 8, 9, 9] (Fully Correct)\\nFinal Result (Correctly Sorted):\\n[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n21', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 20}), Document(page_content='C Example Prompts - Set Intersection\\nWe present the prompts only for the intersection of two 32-\\nelement sets, as those for 64-element and 128-element sets\\nare identical, except for the split prompt where the size of\\nthe split is adjusted proportionally.\\nFor set intersection, we employ two distinct types of op-\\nerations that interact with the LLM, each with its corre-\\nsponding prompts. First, there is the Generate operation,\\nutilizing the intersect prompt to guide the LLM in inter-\\nsecting two input sets, and the split prompt to direct the\\nLLM to split a specified set into a designated number of dis-\\ntinct subsets. Second, the Aggregate operation leverages the\\nmerge prompt to guide the LLM in combining two sets into\\none.\\nFirst, we present the prompt stubs (Table 10), serving as\\ntemplates to dynamically generate appropriate prompts at\\nruntime. For clarity, we display their corresponding few-shot\\nexamples separately in Table 11. Following this, we outline\\nthe LLM interactions throughout a complete set intersection\\nprocess (Table 12 - Table 15).\\n22', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 21}), Document(page_content='Table 10: Prompt stubs for the set intersection tasks; parameters in single curly brackets will be substituted at runtime.\\nintersect prompt: <Instruction >Find the intersection of two sets of numbers. Output only the set of numbers that are\\npresent in both sets, no additional text. </Instruction >\\n<Examples >See Table 11 </Examples >\\nInput Set 1: {set1}\\nInput Set 2: {set2}\\nsplit prompt (32 elements): <Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first\\nlist should contain the first 16 numbers and the second list the second 16 numbers.\\nOnly output the 2 lists in the following format without any additional text or thoughts!\\n{{\\n\"List 1\": [13, 16, 30, 6, 21, 7, 31, ...],\\n\"List 2\": [25, 24, 10, 4, 27, 0, 14, ...]\\n}}\\n</Instruction >\\n<Examples >See Table 11 </Examples >\\nInput:{input}\\nmerge prompt: <Instruction >Merge the following 2 lists into one list by appending the second list to the first list.\\nOnly output the final list without any additional text or thoughts! </Instruction >\\nList 1: {input1}\\nList 2: {input2}\\n23', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 22}), Document(page_content='Table 11: Few-shot examples for each prompt used for the set intersection tasks; some lists are truncated for brevity.\\nintersect prompt:\\n<Examples >\\nInput Set 1: [13, 16, 30, 6, 21, 7, 31, 15, 11, 1, 24, 10, 9, 3, 20, 8]\\nInput Set 2: [25, 24, 10, 4, 27, 0, 14, 12, 8, 2, 29, 20, 17, 19, 26, 23]\\nOutput: [24, 10, 20, 8]\\nInput Set 1: [26, 40, 42, 57, 15, 31, 5, 32, 11, 4, 24, 28, 51, 54, . . .(Omitted 18/32 numbers) ]\\nInput Set 2: [16, 60, 36, 48, 0, 15, 5, 19, 46, 24, 1, 6, 61, 10, . . .(Omitted 18/32 numbers) ]\\nOutput: [40, 15, 5, 24, 35, 59, 16, 63]\\nInput Set 1: [115, 61, 35, 103, 90, 117, 86, 44, 63, 45, 40, 30, 74, 33, . . .(Omitted 50/64 numbers) ]\\nInput Set 2: [13, 35, 20, 96, 34, 18, 47, 127, 126, 9, 21, 16, 77, 22, . . .(Omitted 50/64 numbers) ]\\nOutput: [115, 35, 90, 117, 63, 40, 30, 33, 15, 89, 50, 12, 2, 84, 7, 57, 96]\\n</Examples >\\nsplit prompt (32 elements):\\n<Examples >\\nInput: [26, 40, 42, 57, 15, 31, 5, 32, 11, 4, 24, 28, 51, 54, . . .(Omitted 18/32 numbers) ]\\nOutput:\\n{{\\n\"List 1\": [26, 40, 42, 57, 15, 31, 5, 32, 11, 4, 24, 28, 51, 54, 12, 22],\\n\"List 2\": [33, 35, 7, 13, 2, 59, 8, 23, 43, 16, 29, 55, 25, 63, 21, 18]\\n}}\\n</Examples >\\nmerge prompt: -\\nTable 12: Intersection of two 32-element sets: Execution plan ( GoO )\\nGoO:\\n1. Split the second input set into two sub-sets of equal size (split prompt)\\n2. For each sub-set: Intersect the sub-set with the first input set (intersect prompt) five times; score each sort attempt; keep\\nthe best\\n3. Merge the resulting intersections into one full intersection set (merge prompt) 10 times; score each merge attempt; keep\\nthe best\\n24', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 23}), Document(page_content='Table 13: Intersection of two 32-element sets: Step 1 (Prompt/Response)\\nStep 1 – Prompt:\\n<Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first list should contain the first 16\\nnumbers and the second list the second 16 numbers.\\nOnly output the 2 lists in the following format without any additional text or thoughts!\\n{{\\n\"List 1\": [13, 16, 30, 6, 21, 7, 31, ...],\\n\"List 2\": [25, 24, 10, 4, 27, 0, 14, ...]\\n}}\\n</Instruction >\\n<Examples >See Table 11 </Examples >\\nInput: [31, 11, 4, 63, 38, 58, 59, 24, 61, 14, 32, 39, 27, 46, 48, 19, 52, 57, 50, 56, 3, 2, 53, 29,\\n5, 37, 62, 41, 36, 12, 49, 16]\\nStep 1 – Response (Fully Correct):\\n{{\\n\"List 1\": [31, 11, 4, 63, 38, 58, 59, 24, 61, 14, 32, 39, 27, 46, 48, 19],\\n\"List 1\": [52, 57, 50, 56, 3, 2, 53, 29, 5, 37, 62, 41, 36, 12, 49, 16]\\n}}\\n25', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 24}), Document(page_content='Table 14: Intersection of two 32-element sets: Step 2 (Prompts/Responses)\\nStep 2a – Prompt:\\n<Instruction >Find the intersection of two sets of numbers. Output only the set of numbers that are present in both sets, no\\nadditional text. </Instruction >\\n<Examples >See Table 11 </Examples >\\nInput Set 1: [11, 60, 1, 49, 21, 33, 14, 56, 54, 15, 23, 40, 45, 22, 7, 28, 20, 46, 51, 6, 34, 37, 3,\\n50, 17, 8, 25, 0, 35, 47, 18, 19]\\nInput Set 2: [31, 11, 4, 63, 38, 58, 59, 24, 61, 14, 32, 39, 27, 46, 48, 19]\\nStep 2a – 5 Responses:\\n1.[11, 14, 46, 14, 19] (1 Error - Duplicated 14)\\n2.Output: [11, 14, 46, 19] (Fully Correct)\\n3.[11, 14, 46, 14, 19] (1 Error - Duplicated 14)\\n4.[11, 14, 46, 19] (Fully Correct)\\n5.[11, 14, 46, 14, 19] (1 Error - Duplicated 14)\\nStep 2b – Prompt:\\n<Instruction >Find the intersection of two sets of numbers. Output only the set of numbers that are present in both sets, no\\nadditional text. </Instruction >\\n<Examples >See Table 11 </Examples >\\nInput Set 1: [11, 60, 1, 49, 21, 33, 14, 56, 54, 15, 23, 40, 45, 22, 7, 28, 20, 46, 51, 6, 34, 37, 3,\\n50, 17, 8, 25, 0, 35, 47, 18, 19]\\nInput Set 2: [52, 57, 50, 56, 3, 2, 53, 29, 5, 37, 62, 41, 36, 12, 49, 16]\\nStep 2b – 5 Responses:\\n1.[50, 56, 49] (2 Errors - Missing 3 and 37)\\n2.[50, 56, 37, 49] (1 Error - Missing 3)\\n3.[56, 49, 37, 3, 50] (Fully Correct)\\n4.[50, 56, 37, 49] (1 Error - Missing 3)\\n5.[50, 56, 37, 49] (1 Error - Missing 3)\\n26', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 25}), Document(page_content='Table 15: Intersection of two 32-element sets: Step 3 (Prompt/Responses)\\nStep 3 – Prompt:\\n<Instruction >Merge the following 2 lists into one list by appending the second list to the first list.\\nOnly output the final list without any additional text or thoughts! </Instruction >\\nList 1: [11, 14, 46, 19]\\nList 2: [56, 49, 37, 3, 50]\\nStep 3 – 10 Responses:\\n1.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n2.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n3.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n4.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n5.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n6.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n7.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n8.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n9.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n10.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\nFinal Result (Correct Intersection):\\n[11, 14, 46, 19, 56, 49, 37, 3, 50]\\n27', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 26}), Document(page_content='D Example Prompts - Keyword Counting\\nWe present the prompts only for GoT4 of the keyword count-\\ning task, as those used for GoT8 andGoTx are identical, ex-\\ncept for minor differences in the split prompt where the size\\nof the split is adjusted.\\nFor keyword counting, we employ three distinct types of\\noperations that interact with the LLM, each with its corre-\\nsponding prompts. First, there is the Generate operation,\\nutilizing the count prompt to guide the LLM in counting the\\nkeywords in a text, and the split prompt to direct the LLM\\nto split a given text into a number of passages. Next, the Ag-\\ngregate operation leverages the merge prompt to guide the\\nLLM in merging two dictionaries of counted keywords into\\none. Finally, the ValidateAndImprove operation employs\\ntheimprove merge prompt to instruct the LLM to correct\\nmistakes that were made in a previous Aggregate operation.\\nWe present the prompt stubs (Table 16 - Table 17), serving\\nas templates to dynamically generate appropriate prompts at\\nruntime. For clarity, we display their corresponding few-shot\\nexamples separately in Table 18 and Table 19. Following\\nthis, we outline the LLM interactions throughout a complete\\nkeyword counting process (Table 20 - Table 28).\\n28', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 27}), Document(page_content='Table 16: Prompt stubs for the keyword counting task; parameters in single curly brackets will be substituted at runtime.\\ncount prompt: <Instruction >Count the frequency of how many times each country is explicitly named in the input text.\\nYou can generate any intermedate lists and states, but the final output should only contain the frequency of each country that\\nappears at least once in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each\\ncountry in the output as in the input text):\\n{{\\n\"country1\": frequency1,\\n\"country2\": frequency2,\\n. . .\\n}}\\n</Instruction >\\n<Approach >\\nTo count the frequency for each country follow these steps:\\n1. Split the input passage into four paragraphs of similar length.\\n2. Count the frequency of each country in each paragraph.\\n3. Combine the frequencies of each country from each paragraph by adding them together.\\n</Approach >\\n<Examples >See Table 18 </Examples >\\nInput:{input text}\\nsplit prompt: <Instruction >Split the following input text into 4 paragraphs of approximately same length.\\nOnly output the final 4 paragraphs in the following format without any additional text or thoughts:\\n{{\\n\"Paragraph 1\": \"Some paragraph text . . .\",\\n\"Paragraph 2\": \"Some paragraph text . . .\",\\n\"Paragraph 3\": \"Some paragraph text . . .\",\\n\"Paragraph 4\": \"Some paragraph text . . .\"\\n}}\\n</Instruction >\\n<Example >See Table 19 </Example >\\nInput:{input text}\\n29', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 28}), Document(page_content='Table 17: Prompt stubs for the keyword counting task continued ; parameters in single curly brackets will be substituted at\\nruntime.\\nmerge prompt: <Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text,\\ninto a single dictionary. Simply add the frequencies together for each country and if a country is not present in one of the\\ndictionaries, add it to the final dictionary with the frequency from the other dictionary.\\nOnly output the final merged dictionary without any additional text or thoughts! </Instruction >\\n<Approach >\\nTo combine the 2 dictionaries into single one, follow these steps:\\n1. Create a new dictionary to store the combined frequencies.\\n2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\\n3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\\nalready present, add the frequency to the existing value.\\n</Approach >\\nCombine the following 2 dictionaries into a single dictionary:\\n{dictionary 1}\\n{dictionary 2}\\nCombined Output:\\nimprove merge prompt: <Instruction >The following 2 dictionaries were combined into the third dictionary below. How-\\never, some mistakes occured and the third dictionary is incorrect. Please fix the third dictionary so that it contains the correct\\nfrequencies for each country. The correct frequencies are the sum of the frequencies from the first 2 dictionaries. If a country\\nis not present in one of the dictionaries, add it to the final dictionary with the frequency from the other dictionary.\\n</Instruction >\\n<Example >See Table 19 </Example >\\nDictionary 1: {dictionary 1}\\nDictionary 2: {dictionary 2}\\nIncorrectly Combined Dictionary: {dictionary incorrect }\\nOutput:\\n30', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 29}), Document(page_content='Table 18: Few-shot examples for count prompt used for the keyword counting task; some paragraphs and dictionaries are\\ntruncated and formatting is slightly adjusted for brevity.\\ncount prompt:\\n<Examples >\\nInput: Alexandra boarded the first flight of her grand journey, starting from Canada. With a globe-trotting ... (Omitted)\\nParagraphs:\\nAlexandra boarded the first flight of her grand journey, starting from Canada. With a globe-trotting itinerary ... (Omitted)\\nHer first stop was Mexico, where she marveled at the Mayan ruins. From there, she explored the rainforests ... (Omitted)\\nSublist frequencies:\\n{{\"Canada\": 1 }}\\n{{\"Mexico\": 1, \"Brazil\": 1, \"Argentina\": 1 }}\\nOutput: {{\"Canada\": 1, \"Mexico\": 1, \"Brazil\": 1, \"Argentina\": 1 }}\\nInput: The adventure led him to the peaks of Peru where he trekked to see the mysteries of Machu Picchu ... (Omitted)\\nParagraphs:\\nThe adventure led him to the peaks of Peru where he trekked to see the mysteries of Machu Picchu. He then ... (Omitted)\\nA quick detour to Uruguay and Paraguay allowed him to experience the vibrancy of the local cultures before ... (Omitted)\\nSublists:\\n{{\"Peru\": 1, \"Chile\": 1 }}\\n{{\"Uruguay\": 1, \"Paraguay\": 1, \"Canada\": 1, \"Peru\": 1, \"Brazil\": 1, \"Mexico\": 1 }}\\nOutput: {{\"Peru\": 2, \"Chile\": 1, \"Uruguay\": 1, \"Paraguay\": 1, \"Canada\": 1, \"Brazil\": 1, \"Mexico\": 1 }}\\nInput: Journeying westward, she admired the art in Italy and sipped coffee in France. The music of ... (Omitted)\\nParagraphs:\\nJourneying westward, she admired the art in Italy and sipped coffee in France.\\nThe music of Spain and the history of Greece deepened her love for Europe. The Nordic beauty of Norway, ... (Omitted)\\nShe danced in Ireland, explored castles in Scotland, and marveled at the architecture in Germany and Russia.\\nItaly, Norway, Sweden and Germany will always stay her favourite destinations to visit.\\nSublists:\\n{{\"Italy\": 1, \"France\": 1 }}\\n{{\"Spain\": 1, \"Greece\": 1, \"Norway\": 1, \"Sweden\": 1, \"Finland\": 1, \"Denmark\": 1 }}\\n{{\"Ireland\": 1, \"Scotland\": 1, \"Germany\": 1, \"Russia\": 1 }}\\n{{\"Italy\": 1, \"Norway\": 1, \"Sweden\": 1, \"Germany\": 1 }}\\nOutput: {{\"Italy\": 2, \"France\": 1, \"Spain\": 1, \"Greece\": 1, \"Norway\": 2, \"Sweden\": 2, . . .(Omitted) }}\\n</Examples >\\n31', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 30}), Document(page_content='Table 19: Few-shot examples for split,merge andimprove merge prompts used for the keyword counting task; some para-\\ngraphs and dictionaries are truncated and formatting is slightly adjusted for brevity.\\nsplit prompt:\\n<Examples >\\nInput: Journeying westward, she admired the art in Italy and sipped coffee in France. The music of Spain and the history of\\nGreece deepened her love for Europe. The Nordic beauty of Norway, Sweden, Finland, and Denmark took her breath away.\\nShe danced in Ireland, explored castles in Scotland, and marveled at the architecture in Germany and Russia. Italy, Norway,\\nSweden and Germany will always stay her favourite destinations to visit.\\nOutput:\\n{{\\n\"Paragraph 1\": \"Journeying westward, she admired the art in Italy and sipped coffee in France. \",\\n\"Paragraph 2\": \"The music of Spain and the history of Greece deepened her love for . . .(Omitted)”,\\n\"Paragraph 3\": \"She danced in Ireland, explored castles in Scotland, and marveled . . .(Omitted)”,\\n\"Paragraph 4\": \"Italy, Norway, Sweden and Germany will always stay her favourite . . .(Omitted)”\\n}}\\n</Examples >\\nmerge prompt: -\\nimprove merge prompt:\\n<Example >\\nDictionary 1: {{\"Peru\": 2, \"Chile\": 1, \"Uruguay\": 1, \"Paraguay\": 1 }}\\nDictionary 2: {{\"Peru\": 1, \"Argentina\": 1, \"Canada\": 1, \"Chile\": 3, \"Germany\": 2 }}\\nIncorrectly Combined Dictionary:\\n{{\"Peru\": 3, \"Chile\": 2, \"Uruguay\": 1, \"Paraguay\": 1, \"Argentina\": 1, \"Chile\": 3, \"Germany\": 2 }}\\nOutput:\\n{{\"Peru\": 3, \"Chile\": 4, \"Uruguay\": 1, \"Paraguay\": 1, \"Argentina\": 1, \"Canada\": 1, \"Germany\": 2 }}\\n</Example >\\nTable 20: Keyword counting for an example 4-passage split (GoT4): Execution plan ( GoO )\\nGoO:\\n1. Split the input text into four paragraphs of roughly equal size (split prompt)\\n2. For each paragraph: Count the occurrences of individual countries (count prompt) 10 times; score each counting attempt;\\nkeep the best\\n3. Merge the country counts into one dictionary (merge prompt) 3 times; validate and improve invalid merge attempts\\n(improve merge prompt) up to 3 attempts each; score; keep the best\\n32', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 31}), Document(page_content='Table 21: Keyword counting for an example 4-passage split (GoT4): Step 1 (Prompt/Response)\\nStep 1 – Prompt:\\n<Instruction >Split the following input text into 4 paragraphs of approximately same length.\\nOnly output the final 4 paragraphs in the following format without any additional text or thoughts:\\n{{\\n\"Paragraph 1\": \"Some paragraph text . . .\",\\n\"Paragraph 2\": \"Some paragraph text . . .\",\\n\"Paragraph 3\": \"Some paragraph text . . .\",\\n\"Paragraph 4\": \"Some paragraph text . . .\"\\n}}\\n</Instruction >\\n<Example >See Table 19 </Example >\\nInput: My friend, Alex from Peru , once recounted his journey to Argentina where he learned about the strong cultural ties\\nbetween Argentina and Brazil due to their shared history. He spoke fondly of his time in Argentina and Brazil, marveling at\\nthe similar music, dance, and culinary traditions that seamlessly bridged the borders of these countries. It reminded me\\nof a documentary I’d watched about the ancient Silk Road that spanned across Iran and China. It touched upon the shared\\nhistorical narratives of Iran and China, highlighting how goods, ideas, and culture flowed between these two countries for\\ncenturies. Intriguingly, the documentary also brought up some parallels between this eastern route and the vibrant exchange\\nbetween Italy and France during the Renaissance. The cultural and intellectual bonds between Italy and France were indeed\\nprofound, just as the resilient trade relations that existed between the United States and Canada. The United States\\nand Canada, apart from their geographical proximity, shared an economic bond that strongly influenced their policies\\nand international standing. Similarly, the ties between Australia and New Zealand shed light on their gestalt identity in the\\nPacific region. Despite their unique characteristics, Australia and New Zealand were often viewed as a single entity due to\\ntheir remarkably similar backgrounds in terms of culture, language, and colonial history. Inspired by these chronicles of\\ninterconnectedness, I decided to delve deeper into history and found a fascinating account of how Ukraine and Poland had\\ninfluenced each other through years of coexistence. Despite their tumultuous past , Ukraine and Poland shared a cultural\\ntapestry that was deeply woven into their histories. It was quite similar to the complex relationship between North Korea\\nand South Korea, which, despite their political differences, shared common heritage and traditions. Thus, from Argentina to\\nSouth Korea, the world was an intricate web of countries intertwined with each other through shared histories, cultures, and\\nsometimes, shared destinies.\\nStep 1 – Response (Fully Correct):\\n{{\\n\"Paragraph 1\": \"My friend, Alex from Peru ... (Omitted) ... bridged the borders of these countries.\",\\n\"Paragraph 2\": \"It reminded me of a ... (Omitted) ... between the United States and Canada.\",\\n\"Paragraph 3\": \"The United States and Canada, apart ... (Omitted) ... through years of coexistence.\",\\n\"Paragraph 4\": \"Despite their tumultuous past ... (Omitted) ... and sometimes, shared destinies.\"\\n}}\\n33', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 32}), Document(page_content='Table 22: Keyword counting for an example 4-passage split (GoT4): Step 2a (Prompt/Responses)\\nStep 2a – Prompt:\\n<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\\nany intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\\nonce in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\\noutput as in the input text):\\n{{\\n\"country1\": frequency1,\\n\"country2\": frequency2,\\n. . .\\n}}\\n</Instruction >\\n<Approach >\\nTo count the frequency for each country follow these steps:\\n1. Split the input passage into four paragraphs of similar length.\\n2. Count the frequency of each country in each paragraph.\\n3. Combine the frequencies of each country from each paragraph by adding them together.\\n</Approach >\\n<Examples >See Table 18 </Examples >\\nInput: My friend, Alex from Peru, once recounted his journey to Argentina where he learned about the strong cultural ties\\nbetween Argentina and Brazil due to their shared history. He spoke fondly of his time in Argentina and Brazil, marveling at\\nthe similar music, dance, and culinary traditions that seamlessly bridged the borders of these countries.\\nStep 2a – 10 Responses:\\n1.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n2.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\\n3.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\\n4.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n5.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\\n6.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\\n7.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n8.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n9.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n10.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n34', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 33}), Document(page_content='Table 23: Keyword counting for an example 4-passage split (GoT4): Step 2b (Prompt/Responses)\\nStep 2b – Prompt:\\n<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\\nany intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\\nonce in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\\noutput as in the input text):\\n{{\\n\"country1\": frequency1,\\n\"country2\": frequency2,\\n. . .\\n}}\\n</Instruction >\\n<Approach >\\nTo count the frequency for each country follow these steps:\\n1. Split the input passage into four paragraphs of similar length.\\n2. Count the frequency of each country in each paragraph.\\n3. Combine the frequencies of each country from each paragraph by adding them together.\\n</Approach >\\n<Examples >See Table 18 </Examples >\\nInput: It reminded me of a documentary I’d watched about the ancient Silk Road that spanned across Iran and China. It\\ntouched upon the shared historical narratives of Iran and China, highlighting how goods, ideas, and culture flowed between\\nthese two countries for centuries. Intriguingly, the documentary also brought up some parallels between this eastern route\\nand the vibrant exchange between Italy and France during the Renaissance. The cultural and intellectual bonds between Italy\\nand France were indeed profound, just as the resilient trade relations that existed between the United States and Canada.\\nStep 2b – 10 Responses:\\n1.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n2.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n3.{{\"Iran\": 3, \"China\": 2, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(3 Errors - Surplus of one ”Iran”, missing one ”Italy” and one ”France”)\\n4.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n5.{{\"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(2 Errors - Missing one ”Italy” and one ”France”)\\n6.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n7.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n8.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n9.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n10.{{\"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United States\": 1, \"Canada\": 1 }}\\n(1 Error - Missing one ”Italy”)\\n35', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 34}), Document(page_content='Table 24: Keyword counting for an example 4-passage split (GoT4): Step 2c (Prompt/Responses)\\nStep 2c – Prompt:\\n<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\\nany intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\\nonce in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\\noutput as in the input text):\\n{{\\n\"country1\": frequency1,\\n\"country2\": frequency2,\\n. . .\\n}}\\n</Instruction >\\n<Approach >\\nTo count the frequency for each country follow these steps:\\n1. Split the input passage into four paragraphs of similar length.\\n2. Count the frequency of each country in each paragraph.\\n3. Combine the frequencies of each country from each paragraph by adding them together.\\n</Approach >\\n<Examples >See Table 18 </Examples >\\nInput: The United States and Canada, apart from their geographical proximity, shared an economic bond that strongly\\ninfluenced their policies and international standing. Similarly, the ties between Australia and New Zealand shed light on\\ntheir gestalt identity in the Pacific region. Despite their unique characteristics, Australia and New Zealand were often viewed\\nas a single entity due to their remarkably similar backgrounds in terms of culture, language, and colonial history. Inspired\\nby these chronicles of interconnectedness, I decided to delve deeper into history and found a fascinating account of how\\nUkraine and Poland had influenced each other through years of coexistence.\\nStep 2c – 10 Responses:\\n1.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n2.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n3.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Australia and New Zealand\":\\n1, \"Ukraine\": 1, \"Poland\": 1 }}\\n(3 Errors - Missing one ”Australia, one ”New Zealand” and surplus of one ”Australia and New Zealand”)\\n4.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n5.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Australia and New Zealand\":\\n1, \"Ukraine\": 1, \"Poland\": 1 }}\\n(3 Errors - Missing one ”Australia, one ”New Zealand” and surplus of one ”Australia and New Zealand”)\\n6.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Ukraine\": 1, \"Poland\": 1 }}\\n(2 Errors - Missing one ”Australia” and one ”New Zealand”)\\n7.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n8.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Ukraine\": 1, \"Poland\": 1 }}\\n(2 Errors - Missing one ”Australia” and one ”New Zealand”)\\n9.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n10.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n36', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 35}), Document(page_content='Table 25: Keyword counting for an example 4-passage split (GoT4): Step 2d (Prompt/Responses)\\nStep 2d – Prompt:\\n<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\\nany intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\\nonce in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\\noutput as in the input text):\\n{{\\n\"country1\": frequency1,\\n\"country2\": frequency2,\\n. . .\\n}}\\n</Instruction >\\n<Approach >\\nTo count the frequency for each country follow these steps:\\n1. Split the input passage into four paragraphs of similar length.\\n2. Count the frequency of each country in each paragraph.\\n3. Combine the frequencies of each country from each paragraph by adding them together.\\n</Approach >\\n<Examples >See Table 18 </Examples >\\nInput: Despite their tumultuous past, Ukraine and Poland shared a cultural tapestry that was deeply woven into their histo-\\nries. It was quite similar to the complex relationship between North Korea and South Korea, which, despite their political\\ndifferences, shared common heritage and traditions. Thus, from Argentina to South Korea, the world was an intricate web of\\ncountries intertwined with each other through shared histories, cultures, and sometimes, shared destinies.\\nStep 2d – 10 Responses:\\n1.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n2.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n3.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n4.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n5.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n6.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n7.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n8.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n9.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n10.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n37', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 36}), Document(page_content='Table 26: Keyword counting for an example 4-passage split (GoT4): Step 3a (Prompt/Responses)\\nStep 3a – Prompt:\\n<Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text, into a single\\ndictionary. Simply add the frequencies together for each country and if a country is not present in one of the dictionaries,\\nadd it to the final dictionary with the frequency from the other dictionary.\\nOnly output the final merged dictionary without any additional text or thoughts! </Instruction >\\n<Approach >\\nTo combine the 2 dictionaries into single one, follow these steps:\\n1. Create a new dictionary to store the combined frequencies.\\n2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\\n3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\\nalready present, add the frequency to the existing value.\\n</Approach >\\nCombine the following 2 dictionaries into a single dictionary:\\n{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}\\n{{\"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United States\": 1, \"Canada\": 1 }}\\nCombined Output:\\nStep 3a – 3 Responses:\\n1.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 1, \"Canada\": 1 }}(Valid - No Improvement) (2 Errors - from counting)\\n2.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 1, \"Canada\": 1 }}(Valid - No Improvement) (2 Errors - from counting)\\n3.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 1, \"Canada\": 1 }}(Valid - No Improvement) (2 Errors - from counting)\\n38', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 37}), Document(page_content='Table 27: Keyword counting for an example 4-passage split (GoT4): Step 3b (Prompt/Responses)\\nStep 3b – Prompt:\\n<Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text, into a single\\ndictionary. Simply add the frequencies together for each country and if a country is not present in one of the dictionaries,\\nadd it to the final dictionary with the frequency from the other dictionary.\\nOnly output the final merged dictionary without any additional text or thoughts! </Instruction >\\n<Approach >\\nTo combine the 2 dictionaries into single one, follow these steps:\\n1. Create a new dictionary to store the combined frequencies.\\n2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\\n3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\\nalready present, add the frequency to the existing value.\\n</Approach >\\nCombine the following 2 dictionaries into a single dictionary:\\n{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}\\nCombined Output:\\nStep 3b – 3 Responses:\\n1.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\\n\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Valid - No Improvement) (Fully Correct)\\n2.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\\n\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Valid - No Improvement) (Fully Correct)\\n3.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\\n\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Valid - No Improvement) (Fully Correct)\\n39', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 38}), Document(page_content='Table 28: Keyword counting for an example 4-passage split (GoT4): Step 3c (Prompt/Responses)\\nStep 3c – Prompt:\\n<Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text, into a single\\ndictionary. Simply add the frequencies together for each country and if a country is not present in one of the dictionaries,\\nadd it to the final dictionary with the frequency from the other dictionary.\\nOnly output the final merged dictionary without any additional text or thoughts! </Instruction >\\n<Approach >\\nTo combine the 2 dictionaries into single one, follow these steps:\\n1. Create a new dictionary to store the combined frequencies.\\n2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\\n3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\\nalready present, add the frequency to the existing value.\\n</Approach >\\nCombine the following 2 dictionaries into a single dictionary:\\n{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 1, \"Canada\": 1 }}\\n{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\\n\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}\\nCombined Output:\\nStep 3c – 3 Responses:\\n1.{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North\\nKorea\": 1, \"South Korea\": 2 }}(Valid - No Improvement) (2 Errors - from counting)\\n2.{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North\\nKorea\": 1, \"South Korea\": 2 }}(Valid - No Improvement) (2 Errors - from counting)\\n3.{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North\\nKorea\": 1, \"South Korea\": 2 }}(Valid - No Improvement) (2 Errors - from counting)\\nFinal Result (2 Errors):\\n{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North Korea\":\\n1, \"South Korea\": 2 }}\\n40', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 39}), Document(page_content='E Example Prompts - Document Merging\\nWe present the prompts only for GoTof the document merg-\\ning task, as GoT2 only differs in the fact that it merges the\\n4 NDAs in 2 steps rather than 1. For document merging, we\\nemploy four distinct types of operations that interact with the\\nLLM, each with its corresponding prompts. First, there is the\\nGenerate operation, utilizing the merge prompt to instruct\\nthe LLM to merge the 4 NDAs into 1. Second, the Score\\noperations instructs the LLM to score a given merged NDA\\nusing the score prompt . Next, the Aggregate operation em-\\nploys the aggregate prompt to instruct the LLM to aggregate\\nmultiple merge attempts into a single, better one. Finally, the\\nImprove operation leverages the improve prompt to instruct\\nthe LLM to improve a merged NDA.\\nFirst, we present the prompt stubs (Table 29 - Table 30),\\nserving as templates to dynamically generate appropriate\\nprompts at runtime. Following this, we outline the LLM in-\\nteractions throughout a complete merging process (Table 31\\n- Table 49). However, instead of displaying each input/gen-\\nerated NDA in every prompt/response, we present the 4 in-\\nput NDAs in Table 31 - Table 33 and the final merged NDA\\nin Table 49. Furthermore, as scoring is done using the LLM\\nas well, we will present these interactions for the best per-\\nforming merged NDAs (Tables 39 - 40 and Tables 47 - 48).\\nLastly, most responses are limited to a few lines only, as\\nthey don’t offer any further insights and would otherwise\\nspan multiple pages. However, we refer the interested reader\\nto the results in the corresponding code repository2for full\\nlogs and further examples.\\n2https://github.com/spcl/graph-of-thoughts\\n41', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 40}), Document(page_content='Table 29: Prompt stubs for the document merging task; parameters in single curly brackets will be substituted at runtime.\\nmerge prompt: Merge the following 4 NDA documents <Doc1>-<Doc4>into a single NDA, maximizing retained\\ninformation and minimizing redundancy. Output only the created NDA between the tags <Merged >and</Merged >,\\nwithout any additional text.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>{doc1}</Doc1 >\\n<Doc2>{doc2}</Doc2 >\\n<Doc3>{doc3}</Doc3 >\\n<Doc4>{doc4}</Doc4 >\\nscore prompt: The following NDA <S>merges NDAs <Doc1>-<Doc4>.\\nPlease score the merged NDA <S>in terms of how much redundant information is contained, independent of the original\\nNDAs, as well as how much information is retained from the original NDAs.\\nA score of 10 for redundancy implies that absolutely no information is redundant, while a score of 0 implies that at least half\\nof the information is redundant (so everything is at least mentioned twice).\\nA score of 10 for retained information implies that all information from the original NDAs is retained, while a score of 0\\nimplies that no information is retained.\\nYou may provide reasoning for your scoring, but the final score for redundancy should be between the tags <Redundancy >\\nand</Redundancy >, and the final score for retained information should be between the tags <Retained >and</Retained >,\\nwithout any additional text within any of those tags.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>{doc1}</Doc1 >\\n<Doc2>{doc2}</Doc2 >\\n<Doc3>{doc3}</Doc3 >\\n<Doc4>{doc4}</Doc4 >\\nHere is the merged NDA <S>:\\n<S>{s}</S>\\naggregate prompt: The following NDAs <S1>-<S{num ndas summaries }>each merge the initial NDAs <Doc1>-\\n<Doc4>.\\nCombine the merged NDAs <S1>-<S{num ndas summaries }>into a new one, maximizing their advantages and overall\\ninformation retention, while minimizing redundancy.\\nOutput only the new NDA between the tags <Merged >and</Merged >, without any additional text.\\nHere are the original NDAs <Doc1>-<Doc4>:\\n<Doc1>{doc1}</Doc1 >\\n<Doc2>{doc2}</Doc2 >\\n<Doc3>{doc3}</Doc3 >\\n<Doc4>{doc4}</Doc4 >\\nHere are the merged NDAs <S1>-<S{num ndas summaries }>:\\n<S1>{s1}</S1>\\n. . .\\n<S{num ndas summaries }>{s{num ndas summaries }}</S{num ndas summaries }>\\n42', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 41}), Document(page_content='Table 30: Prompt stubs for the document merging task continued ; parameters in single curly brackets will be substituted at\\nruntime.\\nimprove prompt: The following NDA <S>merges initial NDAs <Doc1>-<Doc4>.\\nPlease improve the merged NDA <S>by adding more information and removing redundancy. Output only the improved\\nNDA, placed between the tags <Merged >and</Merged >, without any additional text.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>{doc1}</Doc1 >\\n<Doc2>{doc2}</Doc2 >\\n<Doc3>{doc3}</Doc3 >\\n<Doc4>{doc4}</Doc4 >\\nHere is the merged NDA <S>:\\n<S>{s}</S>\\n43', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 42}), Document(page_content='Table 31: Input NDA 1 and 2\\n<Doc1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n3. ”Confidential Information” includes all potentially commercially valuable information, specifically software development\\ntactics, processes, and in-house research results.\\n4. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\\ndisclose it without consent.\\n5. Breach penalties include injunctive relief, other remedies, and a $200,000 fee per breach.\\n6. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\\nenforcement doesn’t imply waiver.\\n7. The Agreement is under the laws of [State].\\n8. Signed by [Your Company Name] and [Recipient Name] at the above date.\\n</Doc1 >\\n<Doc2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n1. Purpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\\nfor [Purpose].\\n2. Confidential Information: Defined as all non-public reports, data, designs, and other materials provided by the Disclosing\\nParty to the Receiving Party.\\n3. Receiving Party’s Obligations:\\na. Use, reproduce, or distribute the confidential information only for the agreed purpose.\\nb. Restrict access to the information to necessary parties, ensuring they abide by strict confidentiality.\\nc. Return or destroy all confidential information upon request or at the end of the agreement.\\n4. Exclusions: Information will not be classified as confidential if it is already known to the Receiving Party, publicly known,\\nor independently developed by the Receiving Party.\\n5. Non-Competition: The Receiving Party will not engage in any competing business against the Disclosing Party during\\nthe agreement and one year after its termination.\\n6. Term and Termination: The agreement is valid for [e.g., ”two years”], unless terminated earlier with [e.g., ”30 days”]\\nwritten notice. The Receiving Party’s non-disclosure and non-competition obligations persist post-termination.\\n7. General Provisions:\\na. Governing Law: [Your State]’s laws apply.\\nb. Amendments: Only valid if written and signed by both parties.\\nc. Entire Agreement: This contract overrules previous related agreements.\\nSigned as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party.\\n</Doc2 >\\n44', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 43}), Document(page_content='Table 32: Input NDA 3\\n<Doc3>\\nCONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\\nObjective:\\nTo safeguard classified data during talks of a potential technological alliance.\\nSpecification of Protected Information:\\nParticularly:\\na. System designs and architectural schematics.\\nb. Proprietary computational algorithms.\\nReceiver’s Obligations:\\na. Maintain strict non-disclosure using best practices.\\nb. Employ solely for the aforementioned aim.\\nc. No unveiling without explicit authorization.\\nViolation Ramifications:\\nA charge of $280,000 for every infringement, plus possible legal proceedings.\\nGeneral Terms:\\nBinding for both parties and any successors. This encapsulates the entire accord.\\nLegal Reference:\\nGoverned as per [State]’s legal framework.\\nAttestation:\\nDuly signed on [Date].\\n[AquaBlue Innovations] [PineTree Solutions]\\n</Doc3 >\\n45', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 44}), Document(page_content='Table 33: Input NDA 4\\n<Doc4>\\nSECRECY & DISCLOSURE AGREEMENT\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\\norganization.\\nAim:\\nTo protect exclusive insights amidst dialogues for a technological partnership.\\nCategorization of Sensitive Data:\\nIncludes:\\na. Internal software blueprints.\\nb. Intellectual property awaiting patents.\\nCommitments of Recipient:\\na. Uphold confidentiality, ensuring data integrity.\\nb. Utilize strictly for collaborative ventures.\\nc. No exposure without prior consensus.\\nRepercussions for Non-Compliance:\\n$295,000 fine for each transgression, and the option for legal recourse.\\nOverall Provisions:\\nLegally enforceable for signatories and successors. Complete and sole agreement.\\nJuridical Standpoint:\\nUnder the auspices of [State] laws.\\nRatification:\\nConfirmed and endorsed on [Date].\\n[AquaBlue Innovations] [PineTree Solutions]\\n</Doc4 >\\nTable 34: Merging 4 example NDAs: Execution plan ( GoO )\\nGoO:\\n1. Merge the 4 NDAs into a single one 5 times; Score each attempt and keep the best 3\\n2. Aggregate the merge attempts into a single one 5 times; Score each aggregation attempt and keep the overall best attempt\\n(including Step 1)\\n3. Improve the merged NDA 10 times; Score each and keep the best\\n46', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 45}), Document(page_content='Table 35: Merging 4 example NDAs: Step 1 (Prompt)\\nMerge the following 4 NDA documents <Doc1>-<Doc4>into a single NDA, maximizing retained information and\\nminimizing redundancy. Output only the created NDA between the tags <Merged >and</Merged >, without any additional\\ntext.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted, see Table 31)\\n</Doc1 >\\n<Doc2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n1. Purpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\\nfor [Purpose].\\n. . .(Omitted, see Table 31)\\n</Doc2 >\\n<Doc3>\\nCONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\\nObjective:\\nTo safeguard classified data during talks of a potential . . .(Omitted, see Table 32)\\n</Doc3 >\\n<Doc4>\\nSECRECY & DISCLOSURE AGREEMENT\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\\norganization.\\nAim:\\nTo protect exclusive insights amidst . . .(Omitted, see Table 33)\\n</Doc4 >\\n47', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 46}), Document(page_content='Table 36: Merging 4 example NDAs; we only present the highest scoring response fully in Tables 37-38: Step 1 (Responses)\\nNote that due to the shortening of responses, the appear to be equal, but small differences can be found when observing\\nthe fully generated summaries. The only small differences are reflected in the very similar scores (see Table 39-40 for the\\nscoring of the best response).\\nResponse (1/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.60\\nResponse (2/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted, see Tables 37 - 38)\\nScore: 6.87\\nResponse (3/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.60\\nResponse (4/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 5.78\\nResponse (5/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.50\\n48', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 47}), Document(page_content='Table 37: Merging 4 example NDAs: Step 1 (Highest Scoring Response Part 1)\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n3. ”Confidential Information” includes all potentially commercially valuable information, specifically software development\\ntactics, processes, and in-house research results.\\n4. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\\ndisclose it without consent.\\n5. Breach penalties include injunctive relief, other remedies, and a $200,000 fee per breach.\\n6. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\\nenforcement doesn’t imply waiver.\\n7. The Agreement is under the laws of [State].\\n8. Signed by [Your Company Name] and [Recipient Name] at the above date.\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\nPurpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\\nfor [Purpose].\\nConfidential Information: Defined as all non-public reports, data, designs, and other materials provided by the Disclosing\\nParty to the Receiving Party.\\nReceiving Party’s Obligations:\\na. Use, reproduce, or distribute the confidential information only for the agreed purpose.\\nb. Restrict access to the information to necessary parties, ensuring they abide by strict confidentiality.\\nc. Return or destroy all confidential information upon request or at the end of the agreement.\\nExclusions: Information will not be classified as confidential if it is already known to the Receiving Party, publicly known,\\nor independently developed by the Receiving Party.\\nNon-Competition: The Receiving Party will not engage in any competing business against the Disclosing Party during the\\nagreement and one year after its termination.\\nTerm and Termination: The agreement is valid for [e.g., ”two years”], unless terminated earlier with [e.g., ”30 days”] written\\nnotice. The Receiving Party’s non-disclosure and non-competition obligations persist post-termination.\\nGeneral Provisions:\\na. Governing Law: [Your State]’s laws apply.\\nb. Amendments: Only valid if written and signed by both parties.\\nc. Entire Agreement: This contract overrules previous related agreements.\\nSigned as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party.\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\\nObjective:\\nTo safeguard classified data during talks of a potential technological alliance.\\n49', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 48}), Document(page_content='Table 38: Merging 4 example NDAs: Step 1 (Highest Scoring Response Part 2)\\nSpecification of Protected Information:\\nParticularly:\\na. System designs and architectural schematics.\\nb. Proprietary computational algorithms.\\nReceiver’s Obligations:\\na. Maintain strict non-disclosure using best practices.\\nb. Employ solely for the aforementioned aim.\\nc. No unveiling without explicit authorization.\\nViolation Ramifications:\\nA charge of $280,000 for every infringement, plus possible legal proceedings.\\nGeneral Terms:\\nBinding for both parties and any successors. This encapsulates the entire accord.\\nLegal Reference:\\nGoverned as per [State]’s legal framework.\\nAttestation:\\nDuly signed on [Date].\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\\norganization.\\nAim:\\nTo protect exclusive insights amidst dialogues for a technological partnership.\\nCategorization of Sensitive Data:\\nIncludes:\\na. Internal software blueprints.\\nb. Intellectual property awaiting patents.\\nCommitments of Recipient:\\na. Uphold confidentiality, ensuring data integrity.\\nb. Utilize strictly for collaborative ventures.\\nc. No exposure without prior consensus.\\nRepercussions for Non-Compliance:\\n$295,000 fine for each transgression, and the option for legal recourse.\\nOverall Provisions:\\nLegally enforceable for signatories and successors. Complete and sole agreement.\\nJuridical Standpoint:\\nUnder the auspices of [State] laws.\\nRatification:\\nConfirmed and endorsed on [Date].\\n50', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 49}), Document(page_content='Table 39: Merging 4 example NDAs: Step 1 (Scoring Example – Prompt)\\nPlease score the merged NDA <S>in terms of how much redundant information is contained, independent of the original\\nNDAs, as well as how much information is retained from the original NDAs.\\nA score of 10 for redundancy implies that absolutely no information is redundant, while a score of 0 implies that at least half\\nof the information is redundant (so everything is at least mentioned twice).\\nA score of 10 for retained information implies that all information from the original NDAs is retained, while a score of 0\\nimplies that no information is retained.\\nYou may provide reasoning for your scoring, but the final score for redundancy should be between the tags <Redundancy >\\nand</Redundancy >, and the final score for retained information should be between the tags <Retained >and</Retained >,\\nwithout any additional text within any of those tags.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted, see Table 31)\\n</Doc1 >\\n<Doc2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n. . .(Omitted, see Table 31)\\n</Doc2 >\\n<Doc3>\\nCONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and . . .(Omitted, see Table 32)\\n</Doc3 >\\n<Doc4>\\nSECRECY & DISCLOSURE AGREEMENT\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and . . .(Omitted, see Table 33)\\n</Doc4 >\\nHere is the summary NDA <S>:\\n<S>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted, see Tables 37-38)\\n</S>\\n51', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 50}), Document(page_content='Table 40: Merging 4 example NDAs: Step 1 (Scoring Example – Responses)\\nResponse (1/3):\\n<Redundancy >5</Redundancy >\\n<Retained >10</Retained >\\nReasoning:\\nIn terms of redundancy, there is some overlap in the information contained in the NDAs, such as the definition of ”Confiden-\\ntial Information” and the obligations of the receiving party. However, there are also some unique details in each NDA, such\\nas the specific purpose of information sharing and the penalties for breach. Overall, there is a moderate level of redundancy\\nin the merged NDA.\\nIn terms of retained information, all the key elements from the original NDAs are included in the merged NDA. This\\nincludes the agreement between the parties, the purpose of information sharing, the definition of confidential information,\\nthe obligations of the receiving party, the exclusions for confidential information, non-competition clauses, the term and\\ntermination of the agreement, and the general provisions. Therefore, the merged NDA retains all the important information\\nfrom the original NDAs.\\nResponse (2/3):\\n<Redundancy >8</Redundancy >\\n<Retained >10</Retained >\\nReasoning:\\nThe merged NDA <S>contains multiple redundant sections from the original NDAs. For example, the introductory sections,\\nsuch as the agreement between the parties and the purpose of information sharing, are repeated multiple times. Additionally,\\nsections related to the definition of confidential information, the recipient’s obligations, exclusions, non-competition, term\\nand termination, and general provisions are also redundantly included.\\nHowever, in terms of retained information, the merged NDA retains all the key elements from the original NDAs, including\\nthe parties involved, the objective, specification of protected information, recipient’s obligations, violation ramifications,\\ngeneral terms, legal reference, and attestation. Overall, while there is redundancy in the merged NDA, it successfully retains\\nall the necessary information from the original NDAs.\\nResponse (3/3):\\n<Redundancy >3</Redundancy >\\nThe merged NDA contains some redundancy. There are three sections that have overlapping information between the original\\nNDAs. These sections include:\\n1. The agreement between the parties (Section 1 in Doc1 and the beginning of Doc2)\\n2. Information sharing and the purpose of the NDA (Section 2 in both Doc1 and Doc2)\\n3. General provisions such as governing law and amendments (Section 7 in Doc1 and Doc2)\\n<Retained >9</Retained >\\nThe merged NDA retains a significant amount of information from the original NDAs. It includes all key clauses and provi-\\nsions, such as the definition of confidential information, the obligations of the receiving party, exclusions, non-competition,\\nand general provisions. Only a few minor details, such as specific penalties and fine amounts, are not retained in the merged\\nNDA. Overall, the merged NDA effectively combines the essential elements from the original NDAs.\\nNote: Remember to remove the reasoning from between the tags when providing the final scores.\\nFinal Overall Score (Harmonic Mean of Averages):\\n6.87\\n52', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 51}), Document(page_content='Table 41: Merging 4 example NDAs; Note that S1-S3 are the three best scoring merge attemps from the previous step: Step 2\\n(Prompt)\\nThe following NDAs <S1>-<S3>each merge the initial NDAs <Doc1>-<Doc4>.\\nCombine the merged NDAs <S1>-<S3>into a new one, maximizing their advantages and overall information retention,\\nwhile minimizing redundancy.\\nOutput only the new NDA between the tags <Merged >and</Merged >, without any additional text.\\nHere are the original NDAs <Doc1>-<Doc4>:\\n<Doc1>\\n. . .(Omitted, see Table 31)\\n</Doc1 >\\n<Doc2>\\n. . .(Omitted, see Table 31)\\n</Doc2 >\\n<Doc3>\\n. . .(Omitted, see Table 32)\\n</Doc3 >\\n<Doc4>\\n. . .(Omitted, see Table 33)\\n</Doc4 >\\nHere are the merged NDAs <S1>-<S3>:\\n<S1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted)\\n</S1>\\n<S2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted, see Tables 37-38)\\n</S2>\\n<S3>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted)\\n</S3>\\n53', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 52}), Document(page_content='Table 42: Merging 4 example NDAs: Step 2 (Responses)\\nFor this run, none of the responses improve upon the previous best and thus will all be discarded by the next step. For that\\nreason and due to their long length, we do not present them fully and exclude their scoring.\\nResponse (1/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.50\\nResponse (2/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted)\\nScore: 5.62\\nResponse (3/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.60\\nResponse (4/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.15\\nResponse (5/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.22\\n54', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 53}), Document(page_content='Table 43: Merging 4 example NDAs: Step 3 (Prompt)\\nThe following NDA <S>merges initial NDAs <Doc1>-<Doc4>.\\nPlease improve the merged NDA <S>by adding more information and removing redundancy. Output only the improved\\nNDA, placed between the tags <Merged >and</Merged >, without any additional text.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted, see Table 31)\\n</Doc1 >\\n<Doc2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n1. Purpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\\nfor [Purpose].\\n. . .(Omitted, see Table 31)\\n</Doc2 >\\n<Doc3>\\nCONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\\nObjective:\\nTo safeguard classified data during talks of a potential . . .(Omitted, see Table 32)\\n</Doc3 >\\n<Doc4>\\nSECRECY & DISCLOSURE AGREEMENT\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\\norganization.\\nAim:\\nTo protect exclusive insights amidst . . .(Omitted, see Table 33)\\n</Doc4 >\\nHere is the summary NDA <S>:\\n<S>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted, see Tables 37-38)\\n</S>\\n55', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 54}), Document(page_content='Table 44: Merging 4 example NDAs; we only present the highest scoring response fully in Table 46: Step 3 (Responses Part\\n1)\\nResponse (1/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.35\\nResponse (2/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.35\\nResponse (3/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date], for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, specifically software develop-\\nment tactics, processes, in-house research results, system designs, architectural schematics, proprietary computational\\nalgorithms, internal software blueprints, and intellectual property awaiting patents.\\n. . .(Omitted)\\nScore: 6.87\\nResponse (4/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\\ntactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\\nrithms, internal software blueprints, and intellectual property awaiting patents.\\n. . .(Omitted, see Table 46))\\nScore: 7.78\\nResponse (5/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.43\\n56', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 55}), Document(page_content='Table 45: Merging 4 example NDAs; we only present the highest scoring response fully in Table 46: Step 3 (Responses Part\\n2)\\nResponse (6/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.35\\nResponse (7/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, specifically software develop-\\nment tactics, processes, in-house research results, system designs, architectural schematics, proprietary computational\\nalgorithms, internal software blueprints, and intellectual property awaiting patents.\\n. . .(Omitted)\\nScore: 6.70\\nResponse (8/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes potentially commercially valuable information, such as software development tac-\\ntics, processes, in-house research results, non-public reports, data, designs, and other materials provided by the Disclosing\\nParty.\\n. . .(Omitted)\\nScore: 5.33\\nResponse (9/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose], including [Topic of Research].\\n. . .(Omitted)\\nScore: 7.30\\nResponse (10/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\nAgreement between [Your Company Name] and [Recipient Name] on [Date].\\nInformation sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.40\\n57', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 56}), Document(page_content='Table 46: Merging 4 example NDAs: Step 3 (Highest Scoring Response)\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\\ntactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\\nrithms, internal software blueprints, and intellectual property awaiting patents.\\n3. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\\ndisclose it without consent.\\n4. Breach penalties include injunctive relief, other remedies, and a fine per breach (e.g., $200,000 or $280,000 for each\\ninfringement, depending on the agreement).\\n5. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\\nenforcement doesn’t imply waiver.\\n6. The Agreement is under the laws of [State] and is valid for a specified period (e.g., two years) unless terminated earlier\\nwith written notice (e.g., 30 days).\\n7. The Receiving Party agrees not to engage in any competing business against the Disclosing Party during the agreement\\nand a specified period after its termination (e.g., one year).\\n8. The Agreement can only be amended if written and signed by both parties, and overrules previous related agreements.\\n9. The Agreement is legally enforceable and binding for signatories and successors.\\n10. The Agreement is governed by the laws of [State].\\nSigned as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party, along\\nwith the other parties involved.\\n58', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 57}), Document(page_content='Table 47: Merging 4 example NDAs: Step 3 (Scoring Example – Prompt)\\nPlease score the merged NDA <S>in terms of how much redundant information is contained, independent of the original\\nNDAs, as well as how much information is retained from the original NDAs.\\nA score of 10 for redundancy implies that absolutely no information is redundant, while a score of 0 implies that at least half\\nof the information is redundant (so everything is at least mentioned twice).\\nA score of 10 for retained information implies that all information from the original NDAs is retained, while a score of 0\\nimplies that no information is retained.\\nYou may provide reasoning for your scoring, but the final score for redundancy should be between the tags <Redundancy >\\nand</Redundancy >, and the final score for retained information should be between the tags <Retained >and</Retained >,\\nwithout any additional text within any of those tags.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted, see Table 31)\\n</Doc1 >\\n<Doc2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n. . .(Omitted, see Table 31)\\n</Doc2 >\\n<Doc3>\\nCONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and . . .(Omitted, see Table 32)\\n</Doc3 >\\n<Doc4>\\nSECRECY & DISCLOSURE AGREEMENT\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and . . .(Omitted, see Table 33)\\n</Doc4 >\\nHere is the summary NDA <S>:\\n<S>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\\ntactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\\nrithms, internal software blueprints, and intellectual property awaiting patents.\\n. . .(Omitted, see Table 46)\\n</S>\\n59', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 58}), Document(page_content='Table 48: Merging 4 example NDAs: Step 3 (Scoring Example – Responses)\\nResponse (1/3):\\n<Redundancy >5</Redundancy >\\n<Retained >8</Retained >\\nReasoning:\\nThe merged NDA <S>retains most of the information from the original NDAs, combining relevant clauses and terms\\ninto a single comprehensive agreement. However, some redundancy is present as similar information is mentioned multiple\\ntimes, such as the definition of ”Confidential Information” and the obligations of the receiving party. Additionally, some\\nspecific details from the original NDAs are not included in the merged NDA, such as the exclusion criteria in Doc2 and the\\nprovisions for non-competition in Doc3 and Doc4. Nonetheless, the merged NDA captures the essence of the original NDAs\\nand includes all key information necessary for a non-disclosure agreement.\\nResponse (2/3):\\n<Redundancy >8</Redundancy >\\n<Retained >10</Retained >\\nReasoning:\\nThe merged NDA <S>retains all the key information from the original NDAs, including the purpose of the agreement,\\nthe definition of confidential information, the obligations of the receiving party, breach penalties, applicability to parties and\\nsuccessors, governing law, and signature requirements.\\nThere is some redundant information, such as the inclusion of system designs, architectural schematics, proprietary com-\\nputational algorithms, internal software blueprints, and intellectual property awaiting patents from both Doc3 and Doc4.\\nHowever, this redundancy is minor and does not significantly impact the overall usefulness of the NDA.\\nOverall, the merged NDA <S>retains all important information while minimizing redundancy, making it highly effective\\nin conveying the necessary terms and obligations of the agreement. Therefore, it receives a score of 8 for redundancy and a\\nscore of 10 for retained information.\\nResponse (3/3):\\n<Redundancy >7</Redundancy >\\n<Retained >10</Retained >\\nReasoning:\\nThe merged NDA <S>contains some redundant information, such as the definition of ”Confidential Information” and the\\nobligations of the receiving party. However, it retains all the important information from the original NDAs, including the\\npurpose of the agreement, the specific types of confidential information, the breach penalties, the applicability to parties and\\nsuccessors, the governing law, and the provisions regarding non-competition, amendment, and termination. Additionally, it\\nincorporates the additional information about the agreement’s validity period and the option for legal recourse in case of\\nnon-compliance. Therefore, the merged NDA <S>scores a 7 for redundancy and a 10 for retained information.\\nFinal Overall Score (Harmonic Mean of Averages):\\n7.78\\n60', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 59}), Document(page_content='Table 49: Merging 4 example NDAs: Final Merged NDA\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\\ntactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\\nrithms, internal software blueprints, and intellectual property awaiting patents.\\n3. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\\ndisclose it without consent.\\n4. Breach penalties include injunctive relief, other remedies, and a fine per breach (e.g., $200,000 or $280,000 for each\\ninfringement, depending on the agreement).\\n5. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\\nenforcement doesn’t imply waiver.\\n6. The Agreement is under the laws of [State] and is valid for a specified period (e.g., two years) unless terminated earlier\\nwith written notice (e.g., 30 days).\\n7. The Receiving Party agrees not to engage in any competing business against the Disclosing Party during the agreement\\nand a specified period after its termination (e.g., one year).\\n8. The Agreement can only be amended if written and signed by both parties, and overrules previous related agreements.\\n9. The Agreement is legally enforceable and binding for signatories and successors.\\n10. The Agreement is governed by the laws of [State].\\nSigned as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party, along\\nwith the other parties involved.\\n61', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 60}), Document(page_content='F Evaluation - GoT Configurations\\nWe detail the concrete operations that GoT was configured\\nwith to solve the set intersection and sorting use cases.\\nListing 1: GoT configuration for the set intersection use case\\nwith 32 elements\\n1Generate (k =1) # Split second set into two halves of 16 elements\\n2foreach subset :\\n3 Generate (k =5) # Determine intersected subset of subset and\\nfirst input set\\n4 Score (k =1) # Score locally the intersected subsets\\n5 KeepBestN (1) # Keep the best intersected subset\\n6Aggregate (10) # Merge both intersected subsets\\n7Score (k =1) # Score locally the intersected result sets\\n8KeepBestN (1) # Keep the best result\\n9GroundTruth () # Compare to precomputed result\\nListing 2: GoT configuration for the set intersection use case\\nwith 64 elements\\n1Generate (k =1) # Split second set into four parts of 16 elements\\n2foreach subset :\\n3 Generate (k =5) # Determine intersected subset of subset and\\nfirst input set\\n4 Score (k =1) # Score locally the intersected subsets\\n5 KeepBestN (1) # Keep the best intersected subset\\n6merge step 1:\\n7 Aggregate (10) # Merge intersected subsets 1 and 2\\n8 Score (k =1) # Score locally the intersected result sets\\n9 KeepBestN (1) # Keep the best result\\n10merge step 2:\\n11 Aggregate (10) # Merge intersected subsets 3 and 4\\n12 Score (k =1) # Score locally the intersected result sets\\n13 KeepBestN (1) # Keep the best result\\n14final merge :\\n15 Aggregate (10) # Merge intermediate intersected subsets from\\nmerge step 1 and 2\\n16 Score (k =1) # Score locally the intersected result sets\\n17 KeepBestN (1) # Keep the best result\\n18GroundTruth () # Compare to precomputed result\\nListing 3: GoT configuration for the set intersection use case\\nwith 128 elements\\n1Generate (k =1) # Split second set into eight parts of 16\\nelements\\n2foreach subset :\\n3 Generate (k =5) # Determine intersected subset of subset and\\nfirst input set\\n4 Score (k =1) # Score locally the intersected subsets\\n5 KeepBestN (1) # Keep the best intersected subset\\n6merge step 1:\\n7 Aggregate (5) # Merge intersected subsets 1 and 2\\n8 Score (k =1) # Score locally the intersected result sets\\n9 KeepBestN (1) # Keep the best result\\n10merge step 2:\\n11 Aggregate (5) # Merge intersected subsets 3 and 4\\n12 Score (k =1) # Score locally the intersected result sets\\n13 KeepBestN (1) # Keep the best result\\n14merge step 3:\\n15 Aggregate (5) # Merge intersected subsets 5 and 6\\n16 Score (k =1) # Score locally the intersected result sets\\n17 KeepBestN (1) # Keep the best result\\n18merge step 4:\\n19 Aggregate (5) # Merge intersected subsets 7 and 8\\n20 Score (k =1) # Score locally the intersected result setsListing 4: GoT configuration for the set intersection use case\\nwith 128 elements (cont.)\\n21 KeepBestN (1) # Keep the best result\\n22merge step 5:\\n23 Aggregate (5) # Merge intermediate intersected subsets from\\nmerge step 1 and 2\\n24 Score (k =1) # Score locally the intersected result sets\\n25 KeepBestN (1) # Keep the best result\\n26merge step 6:\\n27 Aggregate (5) # Merge intermediate intersected subsets from\\nmerge step 3 and 4\\n28 Score (k =1) # Score locally the intersected result sets\\n29 KeepBestN (1) # Keep the best result\\n30final merge :\\n31 Aggregate (5) # Merge intermediate intersected subsets from\\nmerge step 5 and 6\\n32 Score (k =1) # Score locally the intersected result sets\\n33 KeepBestN (1) # Keep the best result\\n34GroundTruth () # Compare to precomputed result\\nListing 5: GoT configuration for the sorting use case with 32\\nelements\\n1Generate (k =1) # Split list into two halves of 16 elements\\n2foreach list part :\\n3 Generate (k =5) # Sort list part\\n4 Score (k =1) : # Score partially sorted list\\n5 KeepBestN (1) : # Keep the best partially sorted list\\n6Aggregate (10) # Merge both partially sorted lists\\n7Score (k =1) # Score locally the sorted result lists\\n8KeepBestN (1) # Keep the best result\\n9Generate (k =10) # Try to improve solution\\n10Score (k =1) # Score locally the sorted result lists\\n11KeepBestN (1) # Keep the best result\\n12GroundTruth () # Compare to precomputed result\\nListing 6: GoT configuration for the sorting use case with 64\\nelements\\n1Generate (k =1) # Split list into four parts of 16 elements\\n2foreach list part :\\n3 Generate (k =5) # Sort list part\\n4 Score (k =1) # Score partially sorted list\\n5 KeepBestN (1) # Keep the best partially sorted list\\n6merge step 1:\\n7 Aggregate (10) # Merge partially sorted lists 1 and 2\\n8 Score (k =1) # Score locally the partially sorted result lists\\n9 KeepBestN (1) # Keep the best result\\n10 Generate (k =5) # Try to improve the partial solution\\n11 Score (k =1) # Score locally the partially sorted result lists\\n12 KeepBestN (1) # Keep the best result\\n13merge step 2:\\n14 Aggregate (10) # Merge partially sorted lists 3 and 4\\n15 Score (k =1) # Score locally the partially sorted result lists\\n16 KeepBestN (1) # Keep the best result\\n17 Generate (k =5) # Try to improve the partial solution\\n18 Score (k =1) # Score locally the partially sorted result lists\\n19 KeepBestN (1) # Keep the best result\\n20final merge :\\n21 Aggegrate (10) # Merge partially sorted lists from merge step\\n1 and 2\\n22 Score (k =1) # Score locally the sorted result lists\\n23 KeepBestN (1) # Keep the best result\\n24 Generate (k =10) # Try to improve solution\\n25 Score (k =1) # Score locally the sorted result lists\\n26 KeepBestN (1) # Keep the best result\\n27GroundTruth () # Compare to precomputed result\\n62', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 61}), Document(page_content='Listing 7: GoT configuration for the sorting use case with\\n128 elements\\n1Generate (k =1) # Split list into eight parts of 16 elements\\n2foreach list part :\\n3 Generate (k =5) # Sort list part\\n4 Score (k =1) # Score partially sorted list\\n5 KeepBestN (1) # Keep the best partially sorted list\\n6merge step 1:\\n7 Aggregate (10) # Merge partially sorted lists 1 and 2\\n8 Score (k =1) # Score locally the partially sorted result lists\\n9 KeepBestN (1) # Keep the best result\\n10 Generate (k =5) # Try to improve the partial solution\\n11 Score (k =1) # Score locally the partially sorted result lists\\n12 KeepBestN (1) # Keep the best result\\n13merge step 2:\\n14 Aggregate (10) # Merge partially sorted lists 3 and 4\\n15 Score (k =1) # Score locally the partially sorted result lists\\n16 KeepBestN (1) # Keep the best result\\n17 Generate (k =5) # Try to improve the partial solution\\n18 Score (k =1) # Score locally the partially sorted result lists\\n19 KeepBestN (1) # Keep the best result\\n20merge step 3:\\n21 Aggregate (10) # Merge partially sorted lists 5 and 6\\n22 Score (k =1) # Score locally the partially sorted result lists\\n23 KeepBestN (1) # Keep the best result\\n24 Generate (k =5) # Try to improve the partial solution\\n25 Score (k =1) # Score locally the partially sorted result lists\\n26 KeepBestN (1) # Keep the best result\\n27merge step 4:\\n28 Aggregate (10) # Merge partially sorted lists 7 and 8\\n29 Score (k =1) # Score locally the partially sorted result lists\\n30 KeepBestN (1) # Keep the best result\\n31 Generate (k =5) # Try to improve the partial solution\\n32 Score (k =1) # Score locally the partially sorted result lists\\n33 KeepBestN (1) # Keep the best result\\n34merge step 5:\\n35 Aggregate (10) # Merge partially sorted lists from merge step\\n1 and 2\\n36 Score (k =1) # Score locally the partially sorted result lists\\n37 KeepBestN (1) # Keep the best result\\n38 Generate (k =5) # Try to improve the partial solution\\n39 Score (k =1) # Score locally the partially sorted result lists\\n40 KeepBestN (1) # Keep the best result\\n41merge step 6:\\n42 Aggregate (10) # Merge partially sorted lists from merge step\\n3 and 4\\n43 Score (k =1) # Score locally the partially sorted result lists\\n44 KeepBestN (1) # Keep the best result\\n45 Generate (k =5) # Try to improve the partial solution\\n46 Score (k =1) # Score locally the partially sorted result lists\\n47 KeepBestN (1 # Keep the best result\\n48final merge :\\n49 Aggregate (10) # Merge partially sorted lists from merge step\\n5 and 6\\n50 Score (k =1) # Score locally the partially sorted result lists\\n51 KeepBestN (1) # Keep the best result\\n52 Generate (k =10) # Try to improve solution\\n53 Score (k =1) # Score locally the sorted result lists\\n54 KeepBestN (1) # Keep the best result\\n55GroundTruth () # Compare to precomputed result\\n63', metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 62}), Document(page_content='Chain-of-Thought Prompting Elicits Reasoning\\nin Large Language Models\\nJason Wei Xuezhi Wang Dale Schuurmans Maarten Bosma\\nBrian Ichter Fei Xia Ed H. Chi Quoc V . Le Denny Zhou\\nGoogle Research, Brain Team\\n{jasonwei,dennyzhou}@google.com\\nAbstract\\nWe explore how generating a chain of thought —a series of intermediate reasoning\\nsteps—signiﬁcantly improves the ability of large language models to perform\\ncomplex reasoning. In particular, we show how such reasoning abilities emerge\\nnaturally in sufﬁciently large language models via a simple method called chain-of-\\nthought prompting , where a few chain of thought demonstrations are provided as\\nexemplars in prompting.\\nExperiments on three large language models show that chain-of-thought prompting\\nimproves performance on a range of arithmetic, commonsense, and symbolic\\nreasoning tasks. The empirical gains can be striking. For instance, prompting a\\nPaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art\\naccuracy on the GSM8K benchmark of math word problems, surpassing even\\nﬁnetuned GPT-3 with a veriﬁer.\\nA: The cafeteria had 23 apples originally. They used 20 to make lunch. So they had 23 - 20 = 3. They bought 6 more apples, so they have 3 + 6 = 9. The answer is 9.Chain-of-Thought PromptingQ: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? A: The answer is 11. Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?A: The answer is 27.Standard Prompting\\nQ: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11. Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?Model Input\\nModel OutputModel OutputModel Input\\nFigure 1: Chain-of-thought prompting enables large language models to tackle complex arithmetic,\\ncommonsense, and symbolic reasoning tasks. Chain-of-thought reasoning processes are highlighted.\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2201.11903v6  [cs.CL]  10 Jan 2023', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 0}), Document(page_content='1 Introduction\\nMath Word Problems (GSM8K)020406080100\\n3355\\n1857Solve rate (%)Finetuned GPT-3 175B\\nPrior best\\nPaLM 540B: standard prompting\\nPaLM 540B: chain-of-thought prompting\\nFigure 2: PaLM 540B uses chain-of-\\nthought prompting to achieve new state-\\nof-the-art performance on the GSM8K\\nbenchmark of math word problems.\\nFinetuned GPT-3 and prior best are from\\nCobbe et al. (2021).The NLP landscape has recently been revolutionized by\\nlanguage models (Peters et al., 2018; Devlin et al., 2019;\\nBrown et al., 2020, inter alia ). Scaling up the size of lan-\\nguage models has been shown to confer a range of beneﬁts,\\nsuch as improved performance and sample efﬁciency (Ka-\\nplan et al., 2020; Brown et al., 2020, inter alia ). However,\\nscaling up model size alone has not proved sufﬁcient for\\nachieving high performance on challenging tasks such as\\narithmetic, commonsense, and symbolic reasoning (Rae\\net al., 2021).\\nThis work explores how the reasoning ability of large\\nlanguage models can be unlocked by a simple method\\nmotivated by two ideas. First, techniques for arithmetic\\nreasoning can beneﬁt from generating natural language\\nrationales that lead to the ﬁnal answer. Prior work has\\ngiven models the ability to generate natural language inter-\\nmediate steps by training from scratch (Ling et al., 2017)\\nor ﬁnetuning a pretrained model (Cobbe et al., 2021), in\\naddition to neuro-symbolic methods that use formal lan-\\nguages instead of natural language (Roy and Roth, 2015;\\nChiang and Chen, 2019; Amini et al., 2019; Chen et al.,\\n2019). Second, large language models offer the exciting\\nprospect of in-context few-shot learning via prompting . That is, instead of ﬁnetuning a separate\\nlanguage model checkpoint for each new task, one can simply “prompt” the model with a few\\ninput–output exemplars demonstrating the task. Remarkably, this has been successful for a range of\\nsimple question-answering tasks (Brown et al., 2020).\\nBoth of the above ideas, however, have key limitations. For rationale-augmented training and\\nﬁnetuning methods, it is costly to create a large set of high quality rationales, which is much more\\ncomplicated than simple input–output pairs used in normal machine learning. For the traditional few-\\nshot prompting method used in Brown et al. (2020), it works poorly on tasks that require reasoning\\nabilities, and often does not improve substantially with increasing language model scale (Rae et al.,\\n2021). In this paper, we combine the strengths of these two ideas in a way that avoids their limitations.\\nSpeciﬁcally, we explore the ability of language models to perform few-shot prompting for reasoning\\ntasks, given a prompt that consists of triples: ⟨input, chain of thought , output⟩. Achain of thought is\\na series of intermediate natural language reasoning steps that lead to the ﬁnal output, and we refer to\\nthis approach as chain-of-thought prompting . An example prompt is shown in Figure 1.\\nWe present empirical evaluations on arithmetic, commonsense, and symbolic reasoning benchmarks,\\nshowing that chain-of-thought prompting outperforms standard prompting, sometimes to a striking\\ndegree. Figure 2 illustrates one such result—on the GSM8K benchmark of math word problems\\n(Cobbe et al., 2021), chain-of-thought prompting with PaLM 540B outperforms standard prompting\\nby a large margin and achieves new state-of-the-art performance. A prompting only approach is\\nimportant because it does not require a large training dataset and because a single model checkpoint\\ncan perform many tasks without loss of generality. This work underscores how large language models\\ncan learn via a few examples with natural language data about the task (c.f. automatically learning\\nthe patterns underlying inputs and outputs via a large training dataset).\\n2 Chain-of-Thought Prompting\\nConsider one’s own thought process when solving a complicated reasoning task such as a multi-step\\nmath word problem. It is typical to decompose the problem into intermediate steps and solve each\\nbefore giving the ﬁnal answer: “After Jane gives 2 ﬂowers to her mom she has 10 ...then after she\\ngives 3 to her dad she will have 7 ...so the answer is 7. ” The goal of this paper is to endow language\\nmodels with the ability to generate a similar chain of thought —a coherent series of intermediate\\nreasoning steps that lead to the ﬁnal answer for a problem. We will show that sufﬁciently large\\n2', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 1}), Document(page_content='language models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the ﬁnal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model’s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in sufﬁciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speciﬁc ﬁnetuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following ﬁve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input–output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting—Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 2}), Document(page_content='Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.Q: Sammy wanted to go to where the people were. Where might he go? Options: (a) race track (b) populated areas (c) desert (d) apartment (e) roadblock A: The answer must be a place with a lot of people. Race tracks, desert, apartments, and roadblocks don\\'t have a lot of people, but populated areas do. So the answer is (b). Q: Yes or no: Would a pear sink in water? A: The density of a pear is about 0.6 g/cm^3, which is less than water. Thus, a pear would float. So the answer is no.Q: The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10 days ago in MM/DD/YYYY?  A: One day after 06/01/1943 is 06/02/1943, so today is 06/02/1943. 10 days before today is 05/23/1943. So the answer is 05/23/1943. Q: Is the following sentence plausible? \"Joao Moutinho caught the screen pass in the NFC championship.\"  A: Joao Moutinho is a soccer player. The NFC championship is part of American football, not soccer. So the answer is no.Q: Take the last letters of the words in “Lady Gaga” and concatenate them. A: The last letter of “Lady” is “y”. The last letter of “Gaga” is “a”. Concatenating them is “ya”. So the answer is ya.Q: A coin is heads up. Maybelle flips the coin. Shalonda does not flip the coin. Is the coin still heads up? A: The coin was flipped by Maybelle. So the coin was flipped 1 time, which is an odd number. The coin started heads up, so after an odd number of flips, it will be tails up. So the answer is no.Math Word Problems (free response)Math Word Problems (multiple choice)CSQA (commonsense)\\nStrategyQADate UnderstandingSports Understanding\\nLast Letter ConcatenationCoin Flip (state tracking)Q: How many keystrokes are needed to type the numbers from 1 to 500?Answer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788 A: There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401 three-digit numbers from 100 to 500. 9 + 90(2) + 401(3) = 1392. The answer is (b).\\nSayCan (Instructing a robot)Human: How would you bring me something that isn’t a fruit? Explanation: the user wants something to eat that isn’t a fruit. An energy bar is not a fruit, so I will bring the user an energy bar.  Plan: 1. find(energy bar) 2. pick(energy bar) 3. find(user) 4. put(energy bar) 5. done().Figure 3: Examples of ⟨input, chain of thought, output ⟩triples for arithmetic, commonsense, and\\nsymbolic reasoning benchmarks. Chains of thought are highlighted. Full prompts in Appendix G.\\nmath word problems, we used this single set of eight chain of thought exemplars for all benchmarks\\nexcept AQuA, which is multiple choice instead of free response. For AQuA, we used four exemplars\\nand solutions from the training set, as given in Appendix Table 21.\\nLanguage models. We evaluate ﬁve large language models. The ﬁrst is GPT-3 (Brown et al.,\\n2020), for which we use text-ada-001, text-babbage-001, text-curie-001, and text-davinci-002, which\\npresumably correspond to InstructGPT models of 350M, 1.3B, 6.7B, and 175B parameters (Ouyang\\net al., 2022).The second is LaMDA (Thoppilan et al., 2022), which has models of 422M, 2B, 8B,\\n68B, and 137B parameters. The third is PaLM , which has models of 8B, 62B, and 540B parameters.\\nThe fourth is UL2 20B (Tay et al., 2022), and the ﬁfth is Codex (Chen et al., 2021, code-davinci-002\\nin the OpenAI API). We sample from the models via greedy decoding (though follow-up work shows\\nchain-of-thought prompting can be improved by taking the majority ﬁnal answer over many sampled\\ngenerations (Wang et al., 2022a)). For LaMDA, we report averaged results over ﬁve random seeds,\\nwhere each seed had a different randomly shufﬂed order of exemplars. As LaMDA experiments\\ndid not show large variance among different seeds, to save compute we report results for a single\\nexemplar order for all other models.\\n3.2 Results\\nThe strongest results of chain-of-thought prompting are summarized in Figure 4, with all experimental\\noutputs for each model collection, model size, and benchmark shown in Table 2 in the Appendix.\\nThere are three key takeaways. First, Figure 4 shows that chain-of-thought prompting is an emergent\\nability of model scale (Wei et al., 2022b). That is, chain-of-thought prompting does not positively\\nimpact performance for small models, and only yields performance gains when used with models of\\n∼100B parameters. We qualitatively found that models of smaller scale produced ﬂuent but illogical\\nchains of thought, leading to lower performance than standard prompting.\\n4', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 3}), Document(page_content='0204060GSM8K\\nsolve rate (%)LaMDA GPT PaLMStandard prompting\\nChain-of-thought prompting\\nPrior supervised best\\n020406080SV AMP\\nsolve rate (%)\\n0.4 81370255075100MAWPS\\nsolve rate (%)\\n0.4 7175 862540\\nModel scale (# parameters in billions)\\nFigure 4: Chain-of-thought prompting enables\\nlarge language models to solve challenging math\\nproblems. Notably, chain-of-thought reasoning\\nis an emergent ability of increasing model scale.\\nPrior best numbers are from Cobbe et al. (2021)\\nfor GSM8K, Jie et al. (2022) for SV AMP, and Lan\\net al. (2021) for MAWPS.Second, chain-of-thought prompting has larger\\nperformance gains for more-complicated prob-\\nlems. For instance, for GSM8K (the dataset\\nwith the lowest baseline performance), perfor-\\nmance more than doubled for the largest GPT\\nand PaLM models. On the other hand, for Sin-\\ngleOp, the easiest subset of MAWPS which only\\nrequires a single step to solve, performance im-\\nprovements were either negative or very small\\n(see Appendix Table 3).\\nThird, chain-of-thought prompting via GPT-3\\n175B and PaLM 540B compares favorably to\\nprior state of the art, which typically ﬁnetunes a\\ntask-speciﬁc model on a labeled training dataset.\\nFigure 4 shows how PaLM 540B uses chain-of-\\nthought prompting to achieve new state of the art\\non GSM8K, SV AMP, and MAWPS (though note\\nthat standard prompting already passed the prior\\nbest for SV AMP). On the other two datasets,\\nAQuA and ASDiv, PaLM with chain-of-thought\\nprompting reaches within 2% of the state of the\\nart (Appendix Table 2).\\nTo better understand why chain-of-thought\\nprompting works, we manually examined model-\\ngenerated chains of thought by LaMDA 137B\\nfor GSM8K. Of 50 random examples where the\\nmodel returned the correct ﬁnal answer, all of\\nthe generated chains of thought were also log-\\nically and mathematically correct except two\\nthat coincidentally arrived at the correct answer\\n(see Appendix D.1, and Table 8 for examples\\nof correct model-generated chains of thought).\\nWe also randomly examined 50 random sam-\\nples for which the model gave the wrong answer.\\nThe summary of this analysis is that 46% of the\\nchains of thought were almost correct, barring\\nminor mistakes (calculator error, symbol map-\\nping error, or one reasoning step missing), and that the other 54% of the chains of thought had major\\nerrors in semantic understanding or coherence (see Appendix D.2). To provide a small insight into\\nwhy scaling improves chain-of-thought reasoning ability, we performed a similar analysis of errors\\nmade by PaLM 62B and whether those errors were ﬁxed by scaling to PaLM 540B. The summary\\nis that scaling PaLM to 540B ﬁxes a large portion of one-step missing and semantic understanding\\nerrors in the 62B model (see Appendix A.1).\\n3.3 Ablation Study\\nThe observed beneﬁts of using chain-of-thought prompting raises the natural question of whether the\\nsame performance improvements can be conferred via other types of prompting. Figure 5 shows an\\nablation study with three variations of chain of thought described below.\\nEquation only. One reason for why chain-of-thought prompting might help is that it produces the\\nmathematical equation to be evaluated, and so we test a variation where the model is prompted\\nto output only a mathematical equation before giving the answer. Figure 5 shows that equation\\nonly prompting does not help much for GSM8K, which implies that the semantics of the questions\\nin GSM8K are too challenging to directly translate into an equation without the natural language\\nreasoning steps in chain of thought. For datasets of one-step or two-step problems, however, we ﬁnd\\nthat equation only prompting does improve performance, since the equation can be easily derived\\nfrom the question (see Appendix Table 6).\\n5', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 4}), Document(page_content='LaMDA PaLM0204060GSM8K solve rate (%)Standard prompting\\nEquation only\\nVariable compute only\\nReasoning after answer\\nChain-of-thought prompting\\nFigure 5: Ablation study for dif-\\nferent variations of prompting us-\\ning LaMDA 137B and PaLM 540B.\\nResults for other datasets are given\\nin Appendix Table 6 and Table 7.Variable compute only. Another intuition is that chain of\\nthought allows the model to spend more computation (i.e.,\\nintermediate tokens) on harder problems. To isolate the effect\\nof variable computation from chain-of-thought reasoning, we\\ntest a conﬁguration where the model is prompted to output a\\nonly sequence of dots ( ...) equal to the number of characters in\\nthe equation needed to solve the problem. This variant performs\\nabout the same as the baseline, which suggests that variable\\ncomputation by itself is not the reason for the success of chain-\\nof-thought prompting, and that there appears to be utility from\\nexpressing intermediate steps via natural language.\\nChain of thought after answer. Another potential beneﬁt of\\nchain-of-thought prompting could simply be that such prompts\\nallow the model to better access relevant knowledge acquired\\nduring pretraining. Therefore, we test an alternative conﬁgura-\\ntion where the chain of thought prompt is only given after the\\nanswer, isolating whether the model actually depends on the\\nproduced chain of thought to give the ﬁnal answer. This variant\\nperforms about the same as the baseline, which suggests that\\nthe sequential reasoning embodied in the chain of thought is\\nuseful for reasons beyond just activating knowledge.\\n3.4 Robustness of Chain of Thought\\nGSM8K05101520Solve rate (%)Standard prompting\\nChain-of-thought prompting\\n·different annotator (B)\\n·different annotator (C)\\n·intentionally concise style\\n·exemplars from GSM8K ( α)\\n·exemplars from GSM8K ( β)\\n·exemplars from GSM8K ( γ)\\nMAWPS0204060\\nFigure 6: Chain-of-thought prompting\\nhas variance for different prompt exam-\\nples (as expected) but outperforms stan-\\ndard prompting for various annotators as\\nwell as for different exemplars.Sensitivity to exemplars is a key consideration of prompt-\\ning approaches—for instance, varying the permutation of\\nfew-shot exemplars can cause the accuracy of GPT-3 on\\nSST-2 to range from near chance (54.3%) to near state of\\nthe art (93.4%) (Zhao et al., 2021). In this ﬁnal subsec-\\ntion, we evaluate robustness to chains of thought written\\nby different annotators. In addition to the results above,\\nwhich used chains of thought written by an Annotator\\nA, two other co-authors of this paper (Annotators B and\\nC) independently wrote chains of thought for the same\\nfew-shot exemplars (shown in Appendix H). Annotator A\\nalso wrote another chain of thought that was more concise\\nthan the original, following the style of solutions given in\\nCobbe et al. (2021).1\\nFigure 6 shows these results for LaMDA 137B on GSM8K\\nand MAWPS (ablation results for other datasets are given\\nin Appendix Table 6 / Table 7). Although there is variance\\namong different chain of thought annotations, as would be\\nexpected when using exemplar-based prompting (Le Scao\\nand Rush, 2021; Reynolds and McDonell, 2021; Zhao\\net al., 2021), all sets of chain of thought prompts outper-\\nform the standard baseline by a large margin. This result\\nimplies that successful use of chain of thought does not\\ndepend on a particular linguistic style.\\nTo conﬁrm that successful chain-of-thought prompting\\nworks for other sets of exemplars, we also run experiments\\nwith three sets of eight exemplars randomly sampled from the GSM8K training set, an independent\\n1For instance, whereas original chain of thought uses several short sentences ( “’There were originally 9\\ncomputers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is\\n29. ”), the concise chain of thought would read “5 * 4 = 20 new computers were added. So there are 9 + 20 = 29\\nnew computers in the server room now” .\\n6', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 5}), Document(page_content='source (examples in this dataset already included reasoning steps like a chain of thought).2Fig-\\nure 6 shows that these prompts performed comparably with our manually written exemplars, also\\nsubstantially outperforming standard prompting.\\nIn addition to robustness to annotators, independently-written chains of thought, different exemplars,\\nand various language models, we also ﬁnd that chain-of-thought prompting for arithmetic reasoning\\nis robust to different exemplar orders and varying numbers of exemplars (see Appendix A.2).\\n4 Commonsense Reasoning\\nAlthough chain of thought is particularly suitable for math word problems, the language-based nature\\nof chain of thought actually makes it applicable to a broad class of commonsense reasoning problems,\\nwhich involve reasoning about physical and human interactions under the presumption of general\\nbackground knowledge. Commonsense reasoning is key for interacting with the world and is still\\nbeyond the reach of current natural language understanding systems (Talmor et al., 2021).\\nBenchmarks. We consider ﬁve datasets covering a diverse range of commonsense reasoning types.\\nThe popular CSQA (Talmor et al., 2019) asks commonsense questions about the world involving\\ncomplex semantics that often require prior knowledge. StrategyQA (Geva et al., 2021) requires\\nmodels to infer a multi-hop strategy to answer questions. We choose two specialized evaluation sets\\nfrom the BIG-bench effort (BIG-bench collaboration, 2021): Date Understanding, which involves\\ninferring a date from a given context, and Sports Understanding, which involves determining whether\\na sentence relating to sports is plausible or implausible. Finally, the SayCan dataset (Ahn et al.,\\n2022) involves mapping a natural language instruction to a sequence of robot actions from a discrete\\nset. Figure 3 shows examples with chain of thought annotations for all datasets.\\nPrompts. We follow the same experimental setup as the prior section. For CSQA and StrategyQA,\\nwe randomly selected examples from the training set and manually composed chains of thought for\\nthem to use as few-shot exemplars. The two BIG-bench tasks do not have training sets, so we selected\\nthe ﬁrst ten examples as exemplars in the evaluation set as few-shot exemplars and report numbers on\\nthe rest of the evaluation set. For SayCan, we use six examples from the training set used in Ahn et al.\\n(2022) and also manually composed chains of thought.\\nResults. Figure 7 highlights these results for PaLM (full results for LaMDA, GPT-3, and different\\nmodel scales are shown in Table 4). For all tasks, scaling up model size improved the performance\\nof standard prompting; chain-of-thought prompting led to further gains, with improvements appear-\\ning to be largest for PaLM 540B. With chain-of-thought prompting, PaLM 540B achieved strong\\nperformance relative to baselines, outperforming the prior state of the art on StrategyQA (75.6% vs\\n69.4%) and outperforming an unaided sports enthusiast on sports understanding (95.4% vs 84%).\\nThese results demonstrate that chain-of-thought prompting can also improve performance on tasks\\nrequiring a range of commonsense reasoning abilities (though note that gain was minimal on CSQA).\\n86254020406080100 Solve rate (%)CSQA\\n8625405060708090StrategyQA\\nStandard prompting\\nChain of thought\\nPrior supervised best\\nHuman\\n862540020406080\\nModel scale (# parameters in billions)Date\\n862540406080100Sports\\n86254020406080100SayCan\\nFigure 7: Chain-of-thought prompting also improves the commonsense reasoning abilities of\\nlanguage models. The language model shown here is PaLM. Prior best numbers are from the\\nleaderboards of CSQA (Talmor et al., 2019) and StrategyQA (Geva et al., 2021) (single-model only,\\nas of May 5, 2022). Additional results using various sizes of LaMDA, GPT-3, and PaLM are shown\\nin Table 4.\\n2We sample examples ≤60tokens to ﬁt into our input context window, and also limit the examples to ≤2\\nsteps to solve for a fair comparison with the eight exemplars that we composed.\\n7', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 6}), Document(page_content='5 Symbolic Reasoning\\n0255075100 Solve rate (%)Letter Concat: 2\\n(in domain)Letter Concat: 4\\n(OOD)Standard prompting\\nChain-of-thought prompting\\n8 62 540406080100 Solve rate (%)Coin Flip: 2\\n(in domain)\\n8 62 540\\nModel scale (# parameters in billions)Coin Flip: 4\\n(OOD)\\nFigure 8: Using chain-of-thought\\nprompting facilitates generalization to\\nlonger sequences in two symbolic rea-\\nsoning tasks.Our ﬁnal experimental evaluation considers symbolic rea-\\nsoning, which is simple for humans but potentially chal-\\nlenging for language models. We show that chain-of-\\nthought prompting not only enables language models to\\nperform symbolic reasoning tasks that are challenging in\\nthe standard prompting setting, but also facilitates length\\ngeneralization to inference-time inputs longer than those\\nseen in the few-shot exemplars.\\nTasks. We use the following two toy tasks.\\n•Last letter concatenation. This task asks the model\\nto concatenate the last letters of words in a name (e.g.,\\n“Amy Brown”→“yn” ). It is a more challenging version\\nof ﬁrst letter concatenation, which language models can\\nalready perform without chain of thought.3We generate\\nfull names by randomly concatenating names from the\\ntop one-thousand ﬁrst and last names from name census\\ndata ( https://namecensus.com/ ).\\n•Coin ﬂip. This task asks the model to answer whether a\\ncoin is still heads up after people either ﬂip or don’t ﬂip\\nthe coin (e.g., “A coin is heads up. Phoebe ﬂips the coin.\\nOsvaldo does not ﬂip the coin. Is the coin still heads up?”\\n→“no” ).\\nAs the construction of these symbolic reasoning tasks is\\nwell-deﬁned, for each task we consider an in-domain test\\nset for which examples had the same number of steps as\\nthe training/few-shot exemplars, as well as an out-of-domain (OOD) test set, for which evaluation\\nexamples had more steps than those in the exemplars. For last letter concatenation, the model only\\nsees exemplars of names with two words, and then performs last letter concatenation on names with 3\\nand 4 words.4We do the same for the number of potential ﬂips in the coin ﬂip task. Our experimental\\nsetup uses the same methods and models as in the prior two sections. We again manually compose\\nchains of thought for the few-shot exemplars for each task, which are given in Figure 3.\\nResults. The results of these in-domain and OOD evaluations are shown in Figure 8 for PaLM,\\nwith results for LaMDA shown in Appendix Table 5. With PaLM 540B, chain-of-thought prompting\\nleads to almost 100% solve rates (note that standard prompting already solves coin ﬂip with PaLM\\n540, though not for LaMDA 137B). Note that these in-domain evaluations are “toy tasks” in the\\nsense that perfect solution structures are already provided by the chains of thought in the few-shot\\nexemplars; all the model has to do is repeat the same steps with the new symbols in the test-time\\nexample. And yet, small models still fail—the ability to perform abstract manipulations on unseen\\nsymbols for these three tasks only arises at the scale of 100B model parameters.\\nAs for the OOD evaluations, standard prompting fails for both tasks. With chain-of-thought prompting,\\nlanguage models achieve upward scaling curves (though performance is lower than in the in-domain\\nsetting). Hence, chain-of-thought prompting facilitates length generalization beyond seen chains of\\nthought for language models of sufﬁcient scale.\\n6 Discussion\\nWe have explored chain-of-thought prompting as a simple mechanism for eliciting multi-step rea-\\nsoning behavior in large language models. We ﬁrst saw that chain-of-thought prompting improves\\nperformance by a large margin on arithmetic reasoning, yielding improvements that are much stronger\\nthan ablations and robust to different annotators, exemplars, and language models (Section 3). Next,\\n3We tested 10 common names using GPT-3 davinci and it got all but one correct.\\n4For names of length longer than 2 words, we concatenate multiple ﬁrst and last names together.\\n8', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 7}), Document(page_content='experiments on commonsense reasoning underscored how the linguistic nature of chain-of-thought\\nreasoning makes it generally applicable (Section 4). Finally, we showed that for symbolic reasoning,\\nchain-of-thought prompting facilitates OOD generalization to longer sequence lengths (Section 5). In\\nall experiments, chain-of-thought reasoning is elicited simply by prompting an off-the-shelf language\\nmodel. No language models were ﬁnetuned in the process of writing this paper.\\nThe emergence of chain-of-thought reasoning as a result of model scale has been a prevailing theme\\n(Wei et al., 2022b). For many reasoning tasks where standard prompting has a ﬂat scaling curve, chain-\\nof-thought prompting leads to dramatically increasing scaling curves. Chain-of-thought prompting\\nappears to expand the set of tasks that large language models can perform successfully—in other\\nwords, our work underscores that standard prompting only provides a lower bound on the capabilities\\nof large language models. This observation likely raises more questions than it answers—for instance,\\nhow much more can we expect reasoning ability to improve with a further increase in model scale?\\nWhat other prompting methods might expand the range of tasks that language models can solve?\\nAs for limitations, we ﬁrst qualify that although chain of thought emulates the thought processes of\\nhuman reasoners, this does not answer whether the neural network is actually “reasoning,” which\\nwe leave as an open question. Second, although the cost of manually augmenting exemplars with\\nchains of thought is minimal in the few-shot setting, such annotation costs could be prohibitive for\\nﬁnetuning (though this could potentially be surmounted with synthetic data generation, or zero-shot\\ngeneralization). Third, there is no guarantee of correct reasoning paths, which can lead to both correct\\nand incorrect answers; improving factual generations of language models is an open direction for\\nfuture work (Rashkin et al., 2021; Ye and Durrett, 2022; Wiegreffe et al., 2022, inter alia ). Finally,\\nthe emergence of chain-of-thought reasoning only at large model scales makes it costly to serve in\\nreal-world applications; further research could explore how to induce reasoning in smaller models.\\n7 Related Work\\nThis work is inspired by many research areas, which we detail in an extended related work section\\n(Appendix C). Here we describe two directions and associated papers that are perhaps most relevant.\\nThe ﬁrst relevant direction is using intermediate steps to solve reasoning problems. Ling et al. (2017)\\npioneer the idea of using natural language rationales to solve math word problems through a series\\nof intermediate steps. Their work is a remarkable contrast to the literature using formal languages\\nto reason (Roy et al., 2015; Chiang and Chen, 2019; Amini et al., 2019; Chen et al., 2019). Cobbe\\net al. (2021) extend Ling et al. (2017) by creating a larger dataset and using it to ﬁnetune a pretrained\\nlanguage model rather than training a model from scratch. In the domain of program synthesis,\\nNye et al. (2021) leverage language models to predict the ﬁnal outputs of Python programs via\\nﬁrst line-to-line predicting the intermediate computational results, and show that their step-by-step\\nprediction method performs better than directly predicting the ﬁnal outputs.\\nNaturally, this paper also relates closely to the large body of recent work on prompting. Since the\\npopularization of few-shot prompting as given by Brown et al. (2020), several general approaches\\nhave improved the prompting ability of models, such as automatically learning prompts (Lester et al.,\\n2021) or giving models instructions describing a task (Wei et al., 2022a; Sanh et al., 2022; Ouyang\\net al., 2022). Whereas these approaches improve or augment the input part of the prompt (e.g.,\\ninstructions that are prepended to inputs), our work takes the orthogonal direction of augmenting the\\noutputs of language models with a chain of thought.\\n8 Conclusions\\nWe have explored chain-of-thought prompting as a simple and broadly applicable method for enhanc-\\ning reasoning in language models. Through experiments on arithmetic, symbolic, and commonsense\\nreasoning, we ﬁnd that chain-of-thought reasoning is an emergent property of model scale that allows\\nsufﬁciently large language models to perform reasoning tasks that otherwise have ﬂat scaling curves.\\nBroadening the range of reasoning tasks that language models can perform will hopefully inspire\\nfurther work on language-based approaches to reasoning.\\n9', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 8}), Document(page_content='Acknowledgements\\nWe thank Jacob Devlin, Claire Cui, Andrew Dai, and Ellie Pavlick for providing feedback on the\\npaper. We thank Jacob Austin, Yuhuai Wu, Henryk Michalewski, Aitor Lewkowycz, Charles Sutton,\\nand Aakanksha Chowdhery for helpful discussions. We thank Sid Maxwell for notifying us about a\\nmistake in the manual error analysis in the original manuscript.\\nReferences\\nMichael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea\\nFinn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, et al. 2022. Do as I can, not as I\\nsay: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691 .\\nAida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh\\nHajishirzi. 2019. MathQA: Towards interpretable math word problem solving with operation-\\nbased formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and\\nShort Papers) , Minneapolis, Minnesota. Association for Computational Linguistics.\\nDaniel Andor, Luheng He, Kenton Lee, and Emily Pitler. 2019. Giving BERT a calculator: Finding\\noperations and arguments with reading comprehension. EMNLP .\\nJacob Andreas, Dan Klein, and Sergey Levine. 2018. Learning with latent language. NAACL .\\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\\nEllen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. 2021. Program synthesis with large language\\nmodels. arXiv preprint arXiv:2108.07732 .\\nBIG-bench collaboration. 2021. Beyond the imitation game: Measuring and extrapolating the\\ncapabilities of language models. In preparation .\\nKaj Bostrom, Xinyu Zhao, Swarat Chaudhuri, and Greg Durrett. 2021. Flexible generation of natural\\nlanguage deductions. EMNLP .\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\\nHerbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,\\nJeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\\nand Dario Amodei. 2020. Language models are few-shot learners. NeurIPS .\\nJonathon Cai, Richard Shin, and Dawn Song. 2017. Making neural programming architectures\\ngeneralize via recursion. ICLR .\\nOana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom. 2018. e-SNLI:\\nNatural language inference with natural language explanations. NeurIPS .\\nHoward Chen, Jacqueline He, Karthik Narasimhan, and Danqi Chen. 2022. Can rationalization\\nimprove robustness? NAACL .\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\\nKaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating\\nlarge language models trained on code. arXiv preprint arXiv:2107.03374 .\\nXinyun Chen, Chen Liang, Adams Wei Yu, Denny Zhou, Dawn Song, and Quoc V . Le. 2019. Neural\\nsymbolic reader: Scalable integration of distributed and symbolic representations for reading\\ncomprehension. ICLR .\\nTing-Rui Chiang and Yun-Nung Chen. 2019. Semantically-aligned equation generation for solving\\nand reasoning math word problems. In Proceedings of the 2019 Conference of the North Ameri-\\ncan Chapter of the Association for Computational Linguistics: Human Language Technologies,\\nVolume 1 (Long and Short Papers) , pages 2656–2668, Minneapolis, Minnesota. Association for\\nComputational Linguistics.\\n10', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 9}), Document(page_content='Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over\\nlanguage. IJCAI .\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher\\nHesse, and John Schulman. 2021. Training veriﬁers to solve math word problems. arXiv preprint\\narXiv:2110.14168 .\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of\\ndeep bidirectional transformers for language understanding. NAACL .\\nHonghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, and Denny Zhou. 2019. Neural\\nlogic machines. ICLR .\\nDheeru Dua, Sameer Singh, and Matt Gardner. 2020. Beneﬁts of intermediate annotations in reading\\ncomprehension. ACL.\\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021. Did\\naristotle use a laptop? A question answering benchmark with implicit reasoning strategies. TACL .\\nYuling Gu, Bhavana Dalvi Mishra, and Peter Clark. 2022. DREAM: Uncovering mental models\\nbehind language models. NAACL .\\nBraden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, and Christopher\\nRé. 2018. Training classiﬁers with natural language explanations. ACL.\\nPeter Hase and Mohit Bansal. 2022. When can models learn from explanations? a formal framework\\nfor understanding the roles of explanation data. ACL.\\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song,\\nand Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. arXiv\\npreprint arXiv:2103.03874 .\\nMohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. Learning\\nto solve arithmetic word problems with verb categorization. EMNLP .\\nZhanming Jie, Jierui Li, and Wei Lu. 2022. Learning to reason deductively: Math word problem\\nsolving as complex relation extraction. arXiv preprint arXiv:2203.10316 .\\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child,\\nScott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language\\nmodels. arXiv preprint arXiv:2001.08361 .\\nRik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016.\\nMAWPS: A math word problem repository. NAACL .\\nAndrew K. Lampinen, Ishita Dasgupta, Stephanie C.Y . Chan, Kory Matthewson, Michael Henry\\nTessler, Antonia Creswell, James L. McClelland, Jane X. Wang, and Felix Hill. 2022. Can language\\nmodels learn from explanations in context? arXiv preprint arXiv:2204.02329 .\\nYihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,\\nand Ee-Peng Lim. 2021. MWPToolkit: An open-source framework for deep learning-based math\\nword problem solvers. arXiv preprint arXiv:2109.00799 .\\nTeven Le Scao and Alexander Rush. 2021. How many data points is a prompt worth? NAACL .\\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efﬁcient\\nprompt tuning. EMNLP .\\nIddo Lev, Bill MacCartney, Christopher Manning, and Roger Levy. 2004. Solving logic puzzles:\\nFrom robust processing to precise semantics. Proceedings of the 2nd Workshop on Text Meaning\\nand Interpretation .\\nXiang Lisa Li and Percy Liang. 2021. Preﬁx-tuning: Optimizing continuous prompts for generation.\\nACL.\\n11', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 10}), Document(page_content='Zhengzhong Liang, Steven Bethard, and Mihai Surdeanu. 2021. Explainable multi-hop verbal\\nreasoning through internal monologue. NAACL .\\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program induction by rationale\\ngeneration: Learning to solve and explain algebraic word problems. ACL.\\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021.\\nPre-train, prompt, and predict: A systematic survey of prompting methods in natural language\\nprocessing. arXiv preprint arXiv:2107.13586 .\\nBodhisattwa Prasad Majumder, Oana-Maria Camburu, Thomas Lukasiewicz, and Julian McAuley.\\n2021. Rationale-inspired natural language explanations with commonsense. arXiv preprint\\narXiv:2106.13876 .\\nAna Marasovi ´c, Iz Beltagy, Doug Downey, and Matthew E Peters. 2022. Few-shot self-rationalization\\nwith natural language prompts. NAACL Findings .\\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. On faithfulness and\\nfactuality in abstractive summarization. In ACL.\\nShen Yun Miao, Chao Chun Liang, and Keh Yih Su. 2020. A diverse corpus for evaluating and\\ndeveloping English math word problem solvers. ACL.\\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke\\nZettlemoyer. 2022. Rethinking the role of demonstrations: What makes in-context learning work?\\narXiv preprint arXiv:2202.12837 .\\nSharan Narang, Colin Raffel, Katherine Lee, Adam Roberts, Noah Fiedel, and Karishma Malkan.\\n2020. WT5?! Training text-to-text models to explain their predictions. arXiv preprint\\narXiv:2004.14546 .\\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\\nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work:\\nScratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114 .\\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong\\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to\\nfollow instructions with human feedback. arXiv preprint arXiv:2203.02155 .\\nArkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021. Are NLP models really able to solve\\nsimple math word problems? NAACL .\\nMatthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and\\nLuke Zettlemoyer. 2018. Deep contextualized word representations. NAACL .\\nXinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and\\nWeizhu Chen. 2022. Reasoning like program executors. arXiv preprint arXiv:2201.11473 .\\nPiotr Pi˛ ekos, Mateusz Malinowski, and Henryk Michalewski. 2021. Measuring and improving\\nBERT’s mathematical abilities by predicting the order of reasoning. ACL.\\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John\\nAslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling language models:\\nMethods, analysis & insights from training Gopher. arXiv preprint arXiv:2112.11446 .\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi\\nZhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a uniﬁed\\ntext-to-text transformer. Journal of Machine Learning Research , 21:1–67.\\nDheeraj Rajagopal, Vidhisha Balachandran, Eduard H. Hovy, and Yulia Tsvetkov. 2021. SelfExplain:\\nA self-explaining architecture for neural text classiﬁers. EMNLP .\\nNazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain\\nyourself! Leveraging language models for commonsense reasoning. ACL.\\n12', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 11}), Document(page_content='Qiu Ran, Yankai Lin, Peng Li, Jie Zhou, and Zhiyuan Liu. 2019. NumNet: Machine reading\\ncomprehension with numerical reasoning. EMNLP .\\nHannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Michael Collins, Dipanjan Das, Slav Petrov,\\nGaurav Singh Tomar, Iulia Turc, and David Reitter. 2021. Measuring attribution in natural language\\ngeneration models. arXiv preprint arXiv:2112.12870 .\\nGabriel Recchia. 2021. Teaching autoregressive language models complex tasks by demonstration.\\narXiv preprint arXiv:2109.02102 .\\nEmily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, and Jason Wei. 2022.\\nA recipe for arbitrary text style transfer with large language models. ACL.\\nLaria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond\\nthe few-shot paradigm. Extended Abstracts of the 2021 CHI Conference on Human Factors in\\nComputing Systems .\\nSubhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. EMNLP .\\nSubhro Roy, Tim Vieira, and Dan Roth. 2015. Reasoning about Quantities in Natural Language.\\nTACL .\\nMohammed Saeed, Naser Ahmadi, Preslav Nakov, and Paolo Papotti. 2021. RuleBERT: Teaching\\nsoft rules to pre-trained language models. EMNLP .\\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai,\\nAntoine Chafﬁn, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2022. Multitask prompted\\ntraining enables zero-shot task generalization. ICLR .\\nJianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, and Qun Liu. 2021.\\nGenerate & rank: A multi-task framework for math word problems. In Findings of the Association\\nfor Computational Linguistics: EMNLP 2021 .\\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A\\nquestion answering challenge targeting commonsense knowledge. NAACL .\\nAlon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, and Jonathan Berant. 2020. Leap-of-\\nthought: Teaching pre-trained models to systematically reason over implicit knowledge. NeurIPS .\\nAlon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and\\nJonathan Berant. 2021. CommonsenseQA 2.0: Exposing the limits of ai through gamiﬁcation.\\nNeurIPS Track on Datasets and Benchmarks .\\nYi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven\\nZheng, Neil Houlsby, and Donald Metzler. 2022. Unifying language learning paradigms. arXiv\\npreprint arXiv:2205.05131 .\\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze\\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. LaMDA: Language models for\\ndialog applications. arXiv preprint arXiv:2201.08239 .\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022a.\\nSelf-consistency improves chain of thought reasoning in language models. arXiv preprint\\narXiv:2203.11171 .\\nYizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana\\nArunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022b.\\nBenchmarking generalization via in-context instructions on 1,600+ language tasks. arXiv preprint\\narXiv:2204.07705 .\\nJason Wei, Maarten Bosma, Vincent Y . Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\\nAndrew M. Dai, and Quoc V . Le. 2022a. Finetuned language models are zero-shot learners. ICLR .\\n13', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 12}), Document(page_content='Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,\\nMaarten Bosma, Denny Zhou, Donald Metzler, et al. 2022b. Emergent abilities of large language\\nmodels. Transactions on Machine Learning Research .\\nSarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark Riedl, and Yejin Choi. 2022. Reframing\\nhuman-AI collaboration for generating free-text explanations. NAACL .\\nSarah Wiegreffe and Ana Marasovi ´c. 2021. Teach me to explain: A review of datasets for explainable\\nNLP. NeurIPS .\\nSarah Wiegreffe, Ana Marasovi ´c, and Noah A. Smith. 2021. Measuring association between labels\\nand free-text rationales. EMNLP .\\nTongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and\\nCarrie J Cai. 2022a. PromptChainer: Chaining large language model prompts through visual\\nprogramming. CHI Extended Abstracts .\\nTongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b. AI chains: Transparent and controllable\\nhuman-AI interaction by chaining large language model prompts. CHI.\\nYujun Yan, Kevin Swersky, Danai Koutra, Parthasarathy Ranganathan, and Milad Hashemi. 2020.\\nNeural execution engines: Learning to execute subroutines. NeurIPS .\\nHuihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin, and Xiang Ren. 2021. Reﬁning language models\\nwith compositional explanations. NeurIPS .\\nXi Ye and Greg Durrett. 2022. The unreliability of explanations in few-shot in-context learning.\\narXiv preprint arXiv:2205.03401 .\\nYordan Yordanov, Vid Kocijan, Thomas Lukasiewicz, and Oana-Maria Camburu. 2021. Few-shot\\nout-of-domain transfer learning of natural language explanations. arXiv preprint arXiv:2112.06204 .\\nOmar Zaidan, Jason Eisner, and Christine Piatko. 2007. Using “annotator rationales” to improve\\nmachine learning for text categorization. NAACL .\\nWojciech Zaremba and Ilya Sutskever. 2014. Learning to execute. arXiv preprint arXiv:1410.4615 .\\nEric Zelikman, Yuhuai Wu, and Noah D. Goodman. 2022. STaR: Bootstrapping reasoning with\\nreasoning. arXiv preprint arXiv:2203.14465 .\\nTony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use:\\nImproving few-shot performance of language models. ICML .\\nWangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun, Chenyan Xiong, and\\nJian Tang. 2020. Towards interpretable natural language understanding with explanations as latent\\nvariables. NeurIPS .\\n14', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 13}), Document(page_content='Checklist\\n1. For all authors...\\n(a)Do the main claims made in the abstract and introduction accurately reﬂect the paper’s\\ncontributions and scope? [Yes]\\n(b)Did you describe the limitations of your work? [Yes] See Section 6 and Appendix A.2.\\n(c)Did you discuss any potential negative societal impacts of your work? [Yes] We don’t\\nexpect negative societal impacts as a direct result of the contributions in our paper. One\\nconsideration, however, is that generated chain of thought is not always factual, which\\nis noted as a limitation in Appendix D.1 (and note that we do not suggest using such\\nchains of thought in a factual manner or in any real-world scenario).\\n(d)Have you read the ethics review guidelines and ensured that your paper conforms to\\nthem? [Yes]\\n2. If you are including theoretical results...\\n(a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n(b) Did you include complete proofs of all theoretical results? [N/A]\\n3. If you ran experiments...\\n(a)Did you include the code, data, and instructions needed to reproduce the main experi-\\nmental results (either in the supplemental material or as a URL)? [Yes] We included\\ninputs, outputs, and targets for LaMDA and GPT-3 in the supplementary material.\\nAlthough we use proprietary models, we GPT-3 results are fully reproducible. Repro-\\nducibility is further discussed in Appendix E.1.\\n(b)Did you specify all the training details (e.g., data splits, hyperparameters, how they\\nwere chosen)? [Yes] Data splits were speciﬁed, N/A for hyperparams.\\n(c)Did you report error bars (e.g., with respect to the random seed after running exper-\\niments multiple times)? [Yes] Standard deviation for multiple seeds using LaMDA\\n137B, where each seed is a different random order of exemplars, is given in Table 6\\nand Table 7.\\n(d)Did you include the total amount of compute and the type of resources used (e.g., type\\nof GPUs, internal cluster, or cloud provider)? [Yes] Type of resources are described in\\nAppendix E.2, though we did not estimate the total amount of compute.\\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n(a)If your work uses existing assets, did you cite the creators? [Yes] We used two models\\nthat we anonymized based on the recommendation of the NeurIPS chairs. These models\\nwill be cited in the camera-ready version of the paper.\\n(b) Did you mention the license of the assets? [Yes] See Appendix E.3.\\n(c)Did you include any new assets either in the supplemental material or as a URL? [Yes]\\nThe coinﬂip and last letter concatenation datasets are the only new assets, and they are\\ngiven in the Supplementary Materials.\\n(d)Did you discuss whether and how consent was obtained from people whose data you’re\\nusing/curating? [N/A] No human data collected.\\n(e)Did you discuss whether the data you are using/curating contains personally identiﬁable\\ninformation or offensive content? [N/A] No human data collected.\\n5. If you used crowdsourcing or conducted research with human subjects...\\n(a)Did you include the full text of instructions given to participants and screenshots, if\\napplicable? [N/A]\\n(b)Did you describe any potential participant risks, with links to Institutional Review\\nBoard (IRB) approvals, if applicable? [N/A]\\n(c)Did you include the estimated hourly wage paid to participants and the total amount\\nspent on participant compensation? [N/A]\\n15', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 14}), Document(page_content='A Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe ﬁnding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer beneﬁts such as improved\\nperformance and sample efﬁciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The “other category” included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters ﬁxed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were ﬁxed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often conﬂated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B ﬁxes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B ﬁxes 12 of them)Other\\n(62B made 7 errors of this type, 540B ﬁxes 4 of them)Types of errors made by a 62B language model:Errors ﬁxed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B ﬁxed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The ﬁrst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires sufﬁcient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a ﬁnal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a ﬁnal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 15}), Document(page_content=\"Tracy used a piece of wire 4 feet long to support tomato plants in the garden. The wire was cut into pieces 6 inches long. How many pieces did she obtain?She cut the wire into 6 inch pieces. This means she got 4 * 6 = 24 pieces. The answer is 24. (Incorrect: semantic understanding error)62B Model OutputQuestion540B Model OutputThe wire was 4 feet long. This means it was 4 * 12 = 48 inches long. It was cut into pieces 6 inches long. This means she obtained 48 / 6 = 8 pieces. The answer is 8. (Correct)Tom's ship can travel at 10 miles per hour. He is sailing from 1 to 4 PM. He then travels back at a rate of 6 mph. How long does it take him to get back?He travels from 1 to 4 PM. That means he travels for 3 hours. He travels back at 6 mph. That means he travels for 3 * 6 = 18 miles. The answer is 18. (Incorrect: semantic understanding error)He travels at 10 mph from 1 to 4 PM. This means he travels 3 hours. 3 hours at 10 mph means he travels 3 * 10 = 30 miles. He then travels back at 6 mph. This means he travels 6 miles per hour. He has to travel 30 miles, so it takes him 30 / 6 = 5 hours. The answer is 5. (Correct)Stephen placed an online order for groceries. His final bill came to $40.00. Because this was through a delivery vendor, they tacked on a 25% fee to his final total and charged him $3.00 in delivery fees. Stephen also added a $4.00 tip. After the extra fees, what was the final price of Stephen's groceries?The final price of Stephen's groceries was $40.00. The delivery vendor added 25% to the final total, so the final total was 125% of $40.00. This means the final total was 125% * $40.00 = $50.00. The delivery vendor also charged $3.00 in delivery fees. So the final price of Stephen's groceries was $50.00 + $3.00 = $53.00. The answer is $53.00. (Incorrect: one step missing error)Stephen's bill was $40.00. The delivery vendor added 25% to the bill. This means the bill was increased by 25% of $40.00. This is 0.25 * $40.00 = $10.00. The delivery fee was $3.00. The tip was $4.00. So the total bill was $40.00 + $10.00 + $3.00 + 540b model $4.00 = $57.00. The answer is 57. (Correct)There are four schools competing at a basketball tournament. Each school has sent a girls’ basketball team and a boys’ basketball team and each team has 5 players each. Each school has also sent a coach for each team. In total, how many people have all of the schools sent?There are 4 schools. Each school has sent a girls’ basketball team and a boys’ basketball team. Each team has 5 players each. That means there are 4 * 2 * 5 = 40 players. Each team has a coach. That means there are 40 + 4 = 44 coaches. The answer is 44. (Incorrect: one step missing error)Each school has sent 2 teams, each with 5 players. This means each school has sent 2 * 5 = 10 players. Each school has also sent 2 coaches. This means each school has sent 10 + 2 = 12 people. There are 4 schools, so in total all of the schools have sent 4 * 12 = 48 people. The answer is 48. (Correct)62B Model Output\\n62B Model Output\\n62B Model Output540B Model Output\\n540B Model Output\\n540B Model OutputQuestion\\nQuestion\\nQuestionFigure 10: Examples of semantic understanding and one-step missing errors that were ﬁxed by\\nscaling PaLM from 62B to 540B.\\nA.2 What is the role of prompt engineering?\\nOne of the key considerations of prompting is sensitivity to the exact prompt. There is no shortage\\nof work showing that prompts affect language models in unexpected ways (Min et al., 2022). The\\ngeneral way that we created chain of thought annotations was by taking eight exemplars from the\\ntraining set and decomposing the reasoning process into multiple steps leading to the ﬁnal answer.\\nExamples of chain of thought annotations are provided in Figure 3, with full prompts given in\\nAppendix G. To analyze how sensitive chain of thought is to prompt engineering, we performed\\nrobustness experiments with respect to various factors.\\n•Different annotators. We ﬁrst analyze robustness to three different annotators (Section 3.4 and\\nFigure 6). Although there is notable variance in performance (which we will discuss later), chain\\nof thought performed better than the baseline by a large margin for all three annotators on eight\\ndatasets in arithmetic, commonsense, and symbolic reasoning (Table 6 and Table 7). Similar to the\\nannotation process in Cobbe et al. (2021), annotators were not given speciﬁc instructions about\\n17\", metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 16}), Document(page_content='how to write the chain of thought annotations other than to simply write the step-by-step reasoning\\nprocess that led to the ﬁnal answer. Thus, the annotations were written in each annotator’s own\\nlinguistic “chain of thought” writing style.\\n•Annotators without machine learning background. The GSM8K dataset (Cobbe et al., 2021)\\nconveniently provides a training set with reasoning chains written by crowd compute workers,\\nwhich enables us to investigate whether chain of thought still works with reasoning chains from an\\nindependent source without a background in machine learning. So we randomly sampled three sets\\nof eight exemplars with chains of thought from GSM8K. These chain of thought annotations also\\noutperformed the baseline by a large margin for all four arithmetic datasets (Table 6), indicating\\nthat chain of thought is not dependent on a particular set of annotators.\\n•Different exemplars. The different GSM8K exemplars experiment above (Table 6) also shows\\nthat chain-of-thought prompting works for different sets of exemplars. Notably, we test every set of\\nexemplars on all four arithmetic datasets (instead of picking exemplars from the training set for\\neach dataset), which suggests that the exemplars do not necessarily have to come from the same\\ndataset distribution as the test examples.\\n•Different order of exemplars. Prior work has shown that in some cases (e.g., classiﬁcation) even\\nthe order of prompts matter—varying the permutation of few-shot exemplars can cause the accuracy\\nof GPT-3 on SST-2 to range from near chance (54.3%) to near SOTA (93.4%) (Zhao et al., 2021).\\nWe show the standard deviation of performance from different exemplars in Table 6 and Table 7.\\nStandard deviations with respect to prompt order are relatively minimal in almost all cases. The\\none exception is the coin ﬂip task, for which exemplar orders have high standard deviation, likely\\nfor the reason cited in Zhao et al. (2021)—for classiﬁcation, many exemplars of the same category\\nin a row biases the model outputs).\\n•Different number of exemplars. We also found that gains from chain-of-thought prompting\\ngenerally still held when there was a varying number of few-shot exemplars. This is shown for ﬁve\\ndatasets in Figure 11 (we did not have the compute to run this for all datasets). We also found in\\npreliminary experiments that further increasing the number of exemplars in standard prompting\\ndid not lead to signiﬁcant gains (e.g., increasing from 8 to 16 exemplars did not improve the\\nperformance of standard prompting enough to catch up with chain-of-thought prompting).\\n•Different language models. Another interesting question is whether certain prompts that work\\nbetter for one model work better for other large language models. We ﬁnd that with the same\\nprompts, chain-of-thought prompting improves performance across all three models (LaMDA,\\nGPT-3, and PaLM) for all datasets except CSQA and StrategyQA for GPT-3 (Table 1, Table 4,\\nTable 5). The fact that gains from chain of thought did not transfer perfectly among models is\\na limitation; further work could investigate why how different pre-training datasets and model\\narchitectures affect the performance gain from chain-of-thought prompting.\\nPrompt engineering still matters, though. Although the results are relatively robust to the prompt\\nfor arithmetic reasoning, we want to be clear that prompt engineering still does matter, and can\\nimprove performance signiﬁcantly in many cases. Though most chain of thought annotations\\noutperform standard prompting, there is large variation in many cases. For instance, for the coin\\nﬂip task, the performance varied from 99.6% for Annotator A to 71.4% for Annotator C, though\\nboth were above standard prompting = 50.0% (see Table 7). There are even tasks where prompt\\nengineering is a requirement for good performance. In preliminary experiments, we tried using chain\\nof thought to enable language models to reverse the order of a list of 5 items. While two co-authors\\nwere not able to write chain of thought prompts that solved the task despite their best attempts, a third\\nco-author was able to write a chain of thought that perfectly solved the task.\\nHow to generate chain of thought annotations in a robust fashion could be an interesting direction\\nfor future work. For instance, an idea here could be to use a large language model to automatically\\ngenerate chains of thought via prompting (and potentially optimize this over a validation set).\\nA.3 Will chain-of-thought prompting improve performance for my task of interest?\\nWhile chain-of-thought prompting is in principle applicable for any text-to-text task, it is more\\nhelpful for some tasks than others. Based on the experiments in this paper, our intuition is that chain\\nof thought helps the most when three conditions are met: (1) the task is challenging and requires\\n18', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 17}), Document(page_content='multi-step reasoning, (2) a large language model is used, and (3) the scaling curve is relatively ﬂat.\\nConversely, the beneﬁts are smaller when one or more of these conditions are not met.\\nThese intuitions are perhaps supported by the arithmetic reasoning results. The performance gain\\nfrom chain-of-thought prompting is largest for PaLM 540B on GSM8K (challenging multi-step\\nproblems, ﬂat scaling curve), which meets these conditions. The performance gain is small for the\\nsubsets of MAWPS that only require one or two steps (SingleOP, SingleEq, and AddSub), for which\\nPaLM 540B already achieves performance of 90% or higher (and it is also generally true that there is\\nless headroom for improvement when performance is already strong).\\nAlthough in this paper we focused on multi-step reasoning tasks (arithmetic, commonsense, and\\nsymbolic), chain-of-thought prompting can potentially be applied to any task for which humans use a\\n“chain of thought” to solve (at least in principle). We leave the empirical evaluation of chain-of-thought\\nprompting on such diverse tasks (e.g., machine translation, etc.) to future work.\\nA.4 Why is prompting with the equation only not enough for some arithmetic reasoning\\ndatasets?\\nPrompting with the equation only as an intermediate step does help on many datasets, especially when\\nthe datasets only require a few reasoning steps (SV AMP, ASDiv, MAWPS). For GSM8K, however,\\nusing the equation only did not improve performance substantially. Based on qualitative analysis, we\\nbelieve that these questions are too semantically challenging for the model to directly translate them\\ninto a math equation. Consider this example from LaMDA 137B:\\nQUESTION :Mike plays ping pong for 40 minutes. In the ﬁrst 20 minutes, he scores 4\\npoints. In the second 20 minutes, he scores 25% more points. How many total points did he\\nscore?\\nEQUATION ONLY (WRONG ANSWER ):(4 + 20 * 0.25) = 6. The answer is 6.\\nCHAIN OF THOUGHT (CORRECT ):Mike played ping pong for 40 minutes. In the ﬁrst\\n20 minutes, he scored 4 points. In the second 20 minutes, he scored 25% more points. So\\nhe scored 25% more in the second 20 minutes. 4 x 1.25 = 5. So he scored 5 points in the\\nsecond 20 minutes. So he scored 9 points in total. The answer is 9.\\nIt is hard for the model to directly translate all of the semantics into a single equation, but chain of\\nthought allows it to better reason about each part of the question via intermediate steps in natural\\nlanguage.\\n19', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 18}), Document(page_content='B All Experimental Results\\nThis section contains tables for experimental results for varying models and model sizes, on all\\nbenchmarks, for standard prompting vs. chain-of-thought prompting.\\nFor the arithmetic reasoning benchmarks, some chains of thought (along with the equations produced)\\nwere correct, except the model performed an arithmetic operation incorrectly. A similar observation\\nwas made in Cobbe et al. (2021). Hence, we can further add a Python program as an external\\ncalculator (using the Python eval function) to all the equations in the generated chain of thought.\\nWhen there are multiple equations in a chain of thought, we propagate the external calculator results\\nfrom one equation to the following equations via string matching. As shown in Table 1, we see that\\nadding a calculator signiﬁcantly boosts performance of chain-of-thought prompting on most tasks.\\nTable 1: Chain of thought prompting outperforms standard prompting for various large language\\nmodels on ﬁve arithmetic reasoning benchmarks. All metrics are accuracy (%). Ext. calc.: post-hoc\\nexternal calculator for arithmetic computations only. Prior best numbers are from the following. a:\\nCobbe et al. (2021). b&e: Pi et al. (2022), c: Lan et al. (2021), d: Pi˛ ekos et al. (2021).\\nPrompting GSM8K SV AMP ASDiv AQuA MAWPS\\nPrior best N/A (ﬁnetuning) 55a57.4b75.3c37.9d88.4e\\nUL2 20B Standard 4.1 10.1 16.0 20.5 16.6\\nChain of thought 4.4 (+0.3) 12.5 (+2.4) 16.9 (+0.9) 23.6 (+3.1) 19.1 (+2.5)\\n+ ext. calc 6.9 28.3 34.3 23.6 42.7\\nLaMDA 137B Standard 6.5 29.5 40.1 25.5 43.2\\nChain of thought 14.3 (+7.8) 37.5 (+8.0) 46.6 (+6.5) 20.6 (-4.9) 57.9 (+14.7)\\n+ ext. calc 17.8 42.1 53.4 20.6 69.3\\nGPT-3 175B Standard 15.6 65.7 70.3 24.8 72.7\\n(text-davinci-002) Chain of thought 46.9 (+31.3) 68.9 (+3.2) 71.3 (+1.0) 35.8 (+11.0) 87.1 (+14.4)\\n+ ext. calc 49.6 70.3 71.1 35.8 87.5\\nCodex Standard 19.7 69.9 74.0 29.5 78.7\\n(code-davinci-002) Chain of thought 63.1 (+43.4) 76.4 (+6.5) 80.4 (+6.4) 45.3 (+15.8) 92.6 (+13.9)\\n+ ext. calc 65.4 77.0 80.0 45.3 93.3\\nPaLM 540B Standard 17.9 69.4 72.1 25.2 79.2\\nChain of thought 56.9 (+39.0) 79.0 (+9.6) 73.9 (+1.8) 35.8 (+10.6) 93.3 (+14.2)\\n+ ext. calc 58.6 79.8 72.6 35.8 93.5\\n20', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 19}), Document(page_content='Table 2: Standard prompting versus chain of thought prompting on ﬁve arithmetic reasoning bench-\\nmarks. Note that chain of thought prompting is an emergent ability of model scale—it does not\\npositively impact performance until used with a model of sufﬁcient scale.\\nGSM8K SV AMP ASDiv AQuA MAWPS\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 4.1 4.4 10.1 12.5 16.0 16.9 20.5 23.6 16.6 19.1\\nLaMDA 420M 2.6 0.4 2.5 1.6 3.2 0.8 23.5 8.3 3.2 0.9\\n2B 3.6 1.9 3.3 2.4 4.1 3.8 22.9 17.7 3.9 3.1\\n8B 3.2 1.6 4.3 3.4 5.9 5.0 22.8 18.6 5.3 4.8\\n68B 5.7 8.2 13.6 18.8 21.8 23.1 22.3 20.2 21.6 30.6\\n137B 6.5 14.3 29.5 37.5 40.1 46.6 25.5 20.6 43.2 57.9\\nGPT 350M 2.2 0.5 1.4 0.8 2.1 0.8 18.1 8.7 2.4 1.1\\n1.3B 2.4 0.5 1.5 1.7 2.6 1.4 12.6 4.3 3.1 1.7\\n6.7B 4.0 2.4 6.1 3.1 8.6 3.6 15.4 13.4 8.8 3.5\\n175B 15.6 46.9 65.7 68.9 70.3 71.3 24.8 35.8 72.7 87.1\\nCodex - 19.7 63.1 69.9 76.4 74.0 80.4 29.5 45.3 78.7 92.6\\nPaLM 8B 4.9 4.1 15.1 16.8 23.7 25.2 19.3 21.7 26.2 30.5\\n62B 9.6 29.9 48.2 46.7 58.7 61.9 25.6 22.4 61.8 80.3\\n540B 17.9 56.9 69.4 79.0 72.1 73.9 25.2 35.8 79.2 93.3\\nTable 3: Standard prompting versus chain of thought prompting on the four subsets of the MAWPS\\nbenchmark. The point of stratifying the MAWPS benchmark is to show that performance gains are\\nminimal on easy one-step or two-step problems where large language models already achieve high\\nperformance (e.g., SingleOp, SingleEq, and AddSub).\\nSingleOp SingleEq AddSub MultiArith\\nModel standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 24.9 27.2 18.0 20.2 18.5 18.2 5.0 10.7\\nLaMDA 420M 2.8 1.0 2.4 0.4 1.9 0.7 5.8 1.5\\n2B 4.6 4.1 2.4 3.3 2.7 3.2 5.8 1.8\\n8B 8.0 7.0 4.5 4.4 3.4 5.2 5.2 2.4\\n68B 36.5 40.8 23.9 26.0 17.3 23.2 8.732.4\\n137B 73.2 76.2 48.8 58.7 43.0 51.9 7.644.9\\nGPT 350M 3.2 1.8 2.0 0.2 2.0 1.5 2.3 0.8\\n1.3B 5.3 3.0 2.4 1.6 2.3 1.5 2.2 0.5\\n6.7B 13.5 3.9 8.7 4.9 8.6 2.5 4.5 2.8\\n175B 90.9 88.8 82.7 86.6 83.3 81.3 33.8 91.7\\nCodex - 93.1 91.8 86.8 93.1 90.9 89.1 44.0 96.2\\nPaLM 8B 41.8 46.6 29.5 28.2 29.4 31.4 4.215.8\\n62B 87.9 85.6 77.2 83.5 74.7 78.2 7.373.7\\n540B 94.1 94.1 86.5 92.3 93.9 91.9 42.2 94.7\\n21', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 20}), Document(page_content='Table 4: Standard prompting versus chain of thought prompting on ﬁve commonsense reasoning\\nbenchmarks. Chain of thought prompting is an emergent ability of model scale—it does not positively\\nimpact performance until used with a model of sufﬁcient scale.\\nCSQA StrategyQA Date Sports SayCan\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 34.2 51.4 59.0 53.3 13.5 14.0 57.9 65.3 20.0 41.7\\nLaMDA 420M 20.1 19.2 46.4 24.9 1.9 1.6 50.0 49.7 7.5 7.5\\n2B 20.2 19.6 52.6 45.2 8.0 6.8 49.3 57.5 8.3 8.3\\n8B 19.0 20.3 54.1 46.8 9.5 5.4 50.0 52.1 28.3 33.3\\n68B 37.0 44.1 59.6 62.2 15.5 18.6 55.2 77.5 35.0 42.5\\n137B 53.6 57.9 62.4 65.4 21.5 26.8 59.5 85.8 43.3 46.6\\nGPT 350M 14.7 15.2 20.6 0.9 4.3 0.9 33.8 41.6 12.5 0.8\\n1.3B 12.0 19.2 45.8 35.7 4.0 1.4 0.0 26.9 20.8 9.2\\n6.7B 19.0 24.0 53.6 50.0 8.9 4.9 0.0 4.4 17.5 35.0\\n175B 79.5 73.5 65.9 65.4 43.8 52.1 69.6 82.4 81.7 87.5\\nCodex - 82.3 77.9 67.1 73.2 49.0 64.8 71.7 98.5 85.8 88.3\\nPaLM 8B 19.8 24.9 55.6 53.5 12.9 13.1 55.1 75.2 34.2 40.0\\n62B 65.4 68.1 58.4 63.4 29.8 44.7 72.1 93.6 65.8 70.0\\n540B 78.1 79.9 68.6 77.8 49.0 65.3 80.5 95.4 80.8 91.7\\nTable 5: Standard prompting versus chain of thought prompting enables length generalization to\\nlonger inference examples on two symbolic manipulation tasks.\\nLast Letter Concatenation Coin Flip (state tracking)\\n2 OOD: 3 OOD: 4 2 OOD: 3 OOD: 4\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 0.6 18.8 0.0 0.2 0.0 0.0 70.4 67.1 51.6 52.2 48.7 50.4\\nLaMDA 420M 0.3 1.6 0.0 0.0 0.0 0.0 52.9 49.6 50.0 50.5 49.5 49.1\\n2B 2.3 6.0 0.0 0.0 0.0 0.0 54.9 55.3 47.4 48.7 49.8 50.2\\n8B 1.5 11.5 0.0 0.0 0.0 0.0 52.9 55.5 48.2 49.6 51.2 50.6\\n68B 4.4 52.0 0.0 0.8 0.0 2.5 56.2 83.2 50.4 69.1 50.9 59.6\\n137B 5.8 77.5 0.034.4 0.013.5 49.0 99.6 50.7 91.0 49.1 74.5\\nPaLM 8B 2.6 18.8 0.0 0.0 0.0 0.2 60.0 74.4 47.3 57.1 50.9 51.8\\n62B 6.8 85.0 0.059.6 0.013.4 91.4 96.8 43.9 91.0 38.3 72.4\\n540B 7.6 99.4 0.294.8 0.063.0 98.1 100.0 49.3 98.6 54.8 90.2\\n22', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 21}), Document(page_content='Table 6: Ablation and robustness results for arithmetic reasoning datasets. Chain of thought generally\\noutperforms ablations by a large amount. “Equation only” performs in between standard prompting\\nand chain of thought prompting, as it allows for intermediate reasoning steps via equations but does\\nnot leverage natural language. Chain of thought prompting has variance (as expected) when used\\nwith prompts written by different annotators or when using other exemplars, but still outperforms\\nstandard prompting by a large margin. Standard deviation shown is for different order of few-shot\\nprompting exemplars, with ﬁve different random seeds. Results here are shown for LaMDA 137B, as\\nadditional queries for GPT-3 and PaLM are both limited and expensive.\\nGSM8K SV AMP ASDiv MAWPS\\nStandard prompting 6.5 ±0.4 29.5±0.6 40.1±0.6 43.2±0.9\\nChain of thought prompting 14.3 ±0.4 36.7±0.4 46.6±0.7 57.9±1.5\\nAblations\\n·equation only 5.4 ±0.2 35.1±0.4 45.9±0.6 50.1±1.0\\n·variable compute only 6.4 ±0.3 28.0±0.6 39.4±0.4 41.3±1.1\\n·reasoning after answer 6.1 ±0.4 30.7±0.9 38.6±0.6 43.6±1.0\\nRobustness\\n·different annotator (B) 15.5 ±0.6 35.2±0.4 46.5±0.4 58.2±1.0\\n·different annotator (C) 17.6 ±1.0 37.5±2.0 48.7±0.7 60.1±2.0\\n·intentionally concise style 11.1 ±0.3 38.7±0.8 48.0±0.3 59.6±0.7\\n·exemplars from GSM8K ( α) 12.6 ±0.6 32.8±1.1 44.1±0.9 53.9±1.1\\n·exemplars from GSM8K ( β) 12.7 ±0.5 34.8±1.1 46.9±0.6 60.9±0.8\\n·exemplars from GSM8K ( γ) 12.6 ±0.7 35.6±0.5 44.4±2.6 54.2±4.7\\nTable 7: Ablation and robustness results for four datasets in commonsense and symbolic reasoning.\\nChain of thought generally outperforms ablations by a large amount. Chain of thought prompting has\\nvariance (as expected) when used with prompts written by different annotators or when using other\\nexemplars, but still outperforms standard prompting by a large margin. Standard deviation shown\\nis for different order of few-shot prompting exemplars, with ﬁve different random seeds. Results\\nhere are shown for LaMDA 137B, as additional queries for GPT-3 and PaLM are both limited and\\nexpensive. The exception is that we run SayCan using PaLM here, as the SayCan evaluation set is\\nonly 120 examples and therefore less expensive to run multiple times.\\nCommonsense Symbolic\\nDate Sports SayCan Concat Coin\\nStandard prompting 21.5 ±0.6 59.5±3.0 80.8±1.8 5.8±0.6 49.0±2.1\\nChain of thought prompting 26.8 ±2.1 85.8±1.8 91.7±1.4 77.5±3.8 99.6±0.3\\nAblations\\n·variable compute only 21.3 ±0.7 61.6±2.2 74.2±2.3 7.2±1.6 50.7±0.7\\n·reasoning after answer 20.9 ±1.0 63.0±2.0 83.3±0.6 0.0±0.0 50.2±0.5\\nRobustness\\n·different annotator (B) 27.4 ±1.7 75.4±2.7 88.3±1.4 76.0±1.9 77.5±7.9\\n·different annotator (C) 25.5 ±2.5 81.1±3.6 85.0±1.8 68.1±2.2 71.4±11.1\\n23', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 22}), Document(page_content='C Extended Related Work\\nChain-of-thought prompting is a general approach that is inspired by several prior directions: prompt-\\ning, natural language explanations, program synthesis/execution, numeric and logical reasoning, and\\nintermediate language steps.\\nC.1 Prompting\\nThe recent success of large-scale language models has led to growing interest in improving their\\ncapability to perform tasks via prompting (Brown et al. (2020), and see Liu et al. (2021) for a\\nsurvey). This paper falls in the category of general prompting approaches, whereby input prompts are\\noptimized to allow a single large language model to better perform a variety of tasks (Li and Liang,\\n2021; Lester et al., 2021; Reif et al., 2022, inter alia ).\\nOne recent line of work aims to improve the ability of language models to perform a task by providing\\ninstructions that describe the task (Raffel et al., 2020; Wei et al., 2022a; Ouyang et al., 2022; Sanh\\net al., 2022; Wang et al., 2022b). This line of work is related because it also augments input–output\\npairs with meta-data. But whereas an instruction augments the input to a task (instructions are typically\\nprepended to the inputs), chain-of-thought prompting augments the outputs of language models.\\nAnother related direction is sequentially combining the outputs of language models; human–computer\\ninteraction (HCI) work (Wu et al., 2022a,b) has shown that combining sequential generations of\\nlanguage models improves task outcomes in a 20-person user study.\\nC.2 Natural language explanations\\nAnother closely related direction uses natural language explanations (NLEs), often with the goal of\\nimproving model interpretability (Zhou et al., 2020; Wiegreffe and Marasovi ´c, 2021, inter alia ). That\\nline of work typically focuses on natural language inference (Camburu et al., 2018; Yordanov et al.,\\n2021; Bostrom et al., 2021), and produces explanations either simultaneously to or after the ﬁnal\\nprediction (Narang et al., 2020; Majumder et al., 2021; Wiegreffe et al., 2021, 2022). By contrast,\\nthe chain of thought processing considered in this paper occurs before the ﬁnal answer. And while\\nNLE aims mostly to improve neural network interpretability (Rajagopal et al., 2021), the goal of\\nchain-of-thought prompting is to allow models to decompose multi-hop reasoning tasks into multiple\\nsteps—interpretability is just a side effect. Marasovi ´c et al. (2022) show that prompt-based ﬁnetuning\\nwith NLE improves NLI and classiﬁcation performance, though they largely focus on evaluating\\nexplanation plausibility. In comparison, our work focuses on a range of arithmetic, commonsense,\\nand symbolic tasks that require multi-hop reasoning.\\nC.3 Program synthesis and execution\\nUsing intermediate reasoning steps has a long history in program synthesis and execution (Zaremba\\nand Sutskever, 2014, inter alia ). Recent work along in this direction has included a number of\\narchitectural innovations (Cai et al., 2017; Dong et al., 2019; Yan et al., 2020), as well as the use of\\nlarge language models (Chen et al., 2021; Austin et al., 2021). The program execution work closest to\\nours is perhaps Nye et al. (2021), which show that large language models can perform up to 10-digit\\naddition, evaluate polynomials, and execute python programs. Whereas generating a program and\\nthen executing it can be viewed as a type of reasoning, our work generalizes such domain-speciﬁc\\nprimitives to natural language, which is open-domain and relevant to any text-to-text NLP task in\\nprinciple.\\nC.4 Numeric and logical reasoning\\nNumeric and logical reasoning has been a long-studied task in machine learning and natural language\\nprocessing (Lev et al., 2004, inter alia ). Recent work has also aimed to inject numeric reasoning\\nabilities in language models in various ways, such as augmenting BERT with a predeﬁned set of\\nexecutable operations (Andor et al., 2019), including a graph neural network (Ran et al., 2019), and\\nusing specialized training procedures (Pi˛ ekos et al., 2021). Another line of work aims to enable\\nlanguage models to perform logical or formal reasoning, often by verablizing the rules in natural\\nlanguage formal rules using language (Clark et al., 2020; Saeed et al., 2021; Liang et al., 2021).\\n24', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 23}), Document(page_content='Perhaps the most-related work here is Recchia (2021), which shows that ﬁnetuning enables longhand\\nmodule operations, which has previously been difﬁcult for performers. Whereas work in this direction\\nis often task-speciﬁc and uses ﬁnetuning, we show that chain-of-thought prompting works for a broad\\nrange of tasks without any ﬁnetuning.\\nC.5 Intermediate language steps\\nExtensive prior work has shown the beneﬁts of endowing neural networks with the ability to produce\\nintermediate steps via training or ﬁnetuning confers various beneﬁts in a range of scenarios. As\\nexamples, it has been shown that natural language intermediate steps can improve performance\\n(Zaidan et al., 2007; Yao et al., 2021; Hase and Bansal, 2022; Gu et al., 2022), improve robustness\\n(Chen et al., 2022), speed up training (Hancock et al., 2018), mitigate bias (Dua et al., 2020), and\\neven help in image and reinforcement learning settings (Andreas et al., 2018). To endow models with\\nthe ability to produce intermediate steps, prior work typically ﬁnetunes models on either manually\\nannotated training datasets (Camburu et al., 2018; Rajani et al., 2019, inter alia ) or generates synthetic\\ndatasets (Talmor et al., 2020; Zelikman et al., 2022). Compared with these training or ﬁnetuning\\nmethods, our work shows that various natural language reasoning abilities can be elicited in off-the-\\nshelf language models of sufﬁcient scale simply via prompting. This prompting setup is important\\nbecause it allows for intermediate step reasoning without a large number of labeled annotations, and\\nbecause a single model can perform a range of reasoning tasks without any gradient updates.\\nD Appendix: Additional Analysis\\nD.1 Correct Chain of Thought Analysis\\nAs mentioned in the main text, we analyze 50 chains of thought from LaMDA 137B that led to\\ncorrect answers in the GSM8K dataset. Of these 50, only one arrived at the correct answer through\\nincorrect reasoning (shown in Table 9: “correct by chance”). The other 49 had correct logic and\\nmath, with examples shown in Table 8. Five had minor imperfections while maintaining coherent and\\nunderstandable logic:\\n• One had underspeciﬁed statements (shown in Table 9: “correct but underspeciﬁed statements”).\\n•One made an unrelated but correct statement (shown in Table 9: “correct but unrelated statement”).\\n•Two had the correct logic but omitted speciﬁc steps in the equation, though it was still understand-\\nable (shown in Table 9: “correct but imperfect equation”).\\n•One had the correct math but inverted the semantics (shown in Table 9: “correct but inverted\\nsemantics”)\\nTable 8: Example of correct chains of thought produced by the model for the GSM8K dataset.\\nQUESTION :James decides to run 3 sprints 3 times a week. He runs 60 meters each sprint. How many total\\nmeters does he run a week?\\nMODEL ANSWER (CORRECT): James decides to run 3 sprints 3 times a week. He runs 60 meters each\\nsprint. So he runs 60 meters x 3 sprints x 3 times a week. That is 60 meters x 9. The answer is 540. ✓\\nQUESTION :Brandon’s iPhone is four times as old as Ben’s iPhone. Ben’s iPhone is two times older than Suzy’s\\niPhone. If Suzy’s iPhone is 1 year old, how old is Brandon’s iPhone?\\nMODEL ANSWER (CORRECT): Brandon’s iPhone is 4 times as old as Ben’s iPhone. Ben’s iPhone is 2\\ntimes older than Suzy’s iPhone. So Brandon’s iPhone is 4 x 2 = 8 times older than Suzy’s iPhone. Suzy’s iPhone\\nis 1 year old. So Brandon’s iPhone is 8 x 1 = 8 years old. The answer is 8. ✓\\nQUESTION :Jean has 30 lollipops. Jean eats 2 of the lollipops. With the remaining lollipops, Jean wants to\\npackage 2 lollipops in one bag. How many bags can Jean ﬁll?\\nMODEL ANSWER (CORRECT): Jean started with 30 lollipops. She ate 2 of them. So she has 28 lollipops\\nleft. She wants to package 2 lollipops in one bag. So she can package 28 / 2 = 14 bags. The answer is 14. ✓\\nAlthough we ﬁnd that chain-of-thought reasoning is mostly correct for math questions where the ﬁnal\\nanswer was correct, this is likely because it is hard to arrive at the correct ﬁnal answer by coincidence\\nfor free response questions. For multiple choice or binary classiﬁcation problems, it was much more\\n25', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 24}), Document(page_content='likely that models could arrive at the correct answer via an incorrect reasoning path (e.g., all the\\ncommmonsense reasoning datasets we evaluate). This is a limitation, and future work should perform\\nan analysis of the factuality of such chains of thought.\\nTable 9: Of 50 examples that the model got correct, there were 7 salient cases where the chain of\\nthought the model generated was imperfect. We found the other 43 to be equivalent to what a human\\nwould potentially generate as a ground truth.\\nQUESTION :There are 36 penguins sunbathing in the snow. One-third of them jump in and swim in the ocean.\\nAnother one-third go inside the cave to eat their dinner. How many penguins are still left sunbathing?\\nMODEL ANSWER (CORRECT BY CHANCE ):There are 36 penguins. One-third of them jump in and swim in\\nthe ocean. So that is 12 penguins. Another one-third go inside the cave to eat their dinner. So that is 12 penguins.\\nThe answer is 12.\\nQUESTION :John has 2 houses with 3 bedrooms each. Each bedroom has 2 windows each. There are an\\nadditional 4 windows in each house not connected to bedrooms. How many total windows are there between the\\nhouses?\\nMODEL ANSWER (CORRECT BUT UNDERSPECIFIED STATEMENTS ):There are 2 houses with 3 bedrooms\\neach. Each bedroom has 2 windows each. So there are 2 x 3 = 6 windows in each house. There are an additional\\n4 windows in each house not connected to bedrooms. So there are 4 + 4 = 8 windows in each house. So there are\\n6 x 2 = 12 windows in each house. So there are 12 + 8 = 20 windows in both houses. The answer is 20.\\nQUESTION :If Ann is 9 years old and her brother is twice her age, how old will her brother be in 3 years?\\nMODEL ANSWER (CORRECT BUT UNRELATED STATEMENT ):Ann is 9 years old. Her brother is twice her\\nage. So her brother is 18 years old. In 3 years, she will be 12. So her brother will be 18 + 3 = 21 years old. The\\nanswer is 21.\\nQUESTION :A local gas station is selling gas for $3.00 a gallon. An app company is offering $.20 cashback per\\ngallon if you ﬁll up at this station. If someone buys 10 gallons of gas, how much with their gas be, after the\\ncashback rewards?\\nMODEL ANSWER (CORRECT BUT IMPERFECT EQUATION ):The gas is originally 3 dollars per gallon. If\\nyou buy 10 gallons, that is 3 x 10 = 30 dollars. If you get 20 cents off per gallon, that is 20 x 10 = 2 dollars. So\\nthe total is 30 - 2 = 28 dollars. The answer is 28 dollars.\\nQUESTION :Nissa hires 60 seasonal workers to play elves in her department store’s Santa village. A third of\\nthe elves quit after children vomit on them, then 10 of the remaining elves quit after kids kick their shins. How\\nmany elves are left?\\nMODEL ANSWER (CORRECT BUT IMPERFECT EQUATION ):Nissa hires 60 seasonal workers. A third of\\nthem quit. So 60 - 1/3 = 40 elves are left. Then 10 elves quit. So 40 - 10 = 30 elves are left. The answer is 30\\nelves.\\nQUESTION :Grandma Jones baked 5 apple pies for the ﬁreman’s luncheon. She cut each pie into 8 pieces and\\nset the ﬁve pies out on the buffet table for the guests to serve themselves. At the end of the evening, after the\\nguests had taken and eaten their pieces of pie, there were 14 pieces of pie remaining. How many pieces were\\ntaken by the guests?\\nMODEL ANSWER (CORRECT BUT INVERTED SEMANTICS ):5 pies were baked and cut into 8 pieces each.\\nThe 5 pies were then served to the guests. 8 x 5 = 40 pieces of pie. The guests ate 14 pieces of pie. 40 - 14 = 26\\npieces of pie were left. The answer is 26. ✓\\n26', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 25}), Document(page_content='D.2 Incorrect Chain of Thought Analysis\\nWe also manually analyze 50 randomly sampled outputs of the model that were incorrect on GSM8K\\nfor LaMDA 137B. There are many ways that a chain of thought can be incorrect, making the design\\nof error categorization non-trivial. We decided to categorize errors into what changes are needed to\\nmake the chain of thought correct, with the goal of elucidating how the model can be improved in the\\nfuture.\\nWe found that many chains of thought can be made correct with one of the following three classes of\\nmodiﬁcation.\\n•Calculator error only. We found that 8% of the chains of thought were completely correct except\\nfor a calculator error—in other words, applying an external calculator to equations, as done in\\nCobbe et al. (2021), would make the chain of thought correct. An example of this type of error is\\nshown in Table 10: “calculator error only”. Indeed, the solve rate of chain-of-thought prompting\\non for LaMDA 137B GSM8K went up from 14.3% to 17.3% when we added a Python program\\nas an external calculator, as shown in Table 2. Also, 34% of the examples contained calculator\\nerrors in addition to other types of errors. However, we perform the rest of the error categorization\\nindependently of calculator errors.\\n•Symbol mapping error. We next found that 16% percent of the chains of thought were correct\\nexcept for what we call symbol mapping errors. We deﬁne a symbol mapping error as when the\\nchain of thought is correct except for the number symbols, and it could be made totally correct by\\nmodifying only the equations and not the words. As one might argue that they could simply place\\nthe correct ﬁnal equation in any chain of thought, we constrain this category to chains of thought\\nwhere the chain of thought can be modiﬁed to be a completely correct reasoning process (not just\\nﬁnal answer). An example of this error category is shown in Table 10: “symbol mapping error”.\\n•One step missing error. Our next category of error is chains of thought which were correct except\\nthat they were missing a single step. In other words, these chains of thoughts could be rewritten to\\nbe correct by adding in an additional reasoning step that was missed by the model. An example of\\nthis error category is shown in Table 10: “one step missing error”. We found that 22% percent of\\nthe errors fell into this category.\\nTable 10: Example of incorrect chains of thought, categorized as described in Appendix D.2.\\nQUESTION :Dan plants 3 rose bushes. Each rose bush has 25 roses. Each rose has 8 thorns. How many thorns\\nare there total?\\nMODEL ANSWER (INCORRECT ;CALCULATOR ERROR ONLY ):Dan plants 3 rose bushes. Each rose bush\\nhas 25 roses. Each rose has 8 thorns. So 3 x 25 x 8 = 300. The answer is 300. \\x17\\nEXPLANATION FOR ERROR CATEGORY :The produced chain of thought could be made correct just by\\nrunning the equation through an external calculator, instead of asking the model to do the computation.\\nQUESTION :Jill gets paid $20 per hour to teach and $30 to be a cheerleading coach. If she works 50 weeks a\\nyear, 35 hours a week as a teacher and 15 hours a week as a coach, what’s her annual salary?\\nMODEL ANSWER (INCORRECT ;SYMBOL MAPPING ERROR ):Jill gets paid 20 dollars per hour to teach\\nand 30 dollars per hour to be a cheerleading coach. If she works 50 weeks a year, 35 hours a week as a teacher\\nand 15 hours a week as a coach, then she works 50 x 35 = 1750 hours as a teacher and 15 x 30 = 450 hours as a\\ncoach. So she works 1750 + 450 = 2200 hours. She gets paid 20 dollars per hour for 1750 hours and 30 dollars\\nper hour for 450 hours. So her annual salary is 20 x 1750 + 30 x 450 = $36,500. The answer is $36,500. \\x17\\nEXPLANATION FOR ERROR CATEGORY :The model incorrectly mapped “15 x 30” instead of “15 x 50”, and\\nthe chain of thought would be made correct by ﬁxing just that one change (with an external calculator).\\nQUESTION :Kelian has two recipes for preparing dishes, one having 20 instructions and the second one having\\ntwice as many instructions as the ﬁrst one. How many instructions does Kelian have to read to prepare the two\\ndishes?\\nMODEL ANSWER (INCORRECT ;ONE STEP MISSING ERROR ):Kelian has two recipes. One has 20 instruc-\\ntions. The other has twice as many instructions as the ﬁrst one. So the second one has 40 instructions. So Kelian\\nhas to read 40 instructions to prepare the two dishes. The answer is 40. \\x17\\nEXPLANATION FOR ERROR CATEGORY :The model answer could be made correct just adding one additional\\nstep (in this case, adding 20 and 40).\\n27', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 26}), Document(page_content='We found that the remaining chains of thought (27 of 50; 54%) would require substantial edits to make\\ninto a correct chain of thought. Almost all cases here involved some error in semantic understanding\\n(see Table 11: “semantic understanding error”), and 8 of the 27 also had incoherent chain of thoughts,\\nmeaning that some statements in the generated chain of thought did not follow from prior ones or\\nviolated basic world knowledge (see Table 11: “incoherent chain of thought error”).\\nTable 11: Example of incorrect chains of thought, categorized as described in Appendix D.2. These\\nchains of thought had multiple mistakes that could not be ﬁxed with minor edits.\\nQUESTION :Gretchen has 110 coins. There are 30 more gold coins than silver coins. How many gold coins\\ndoes Gretchen have?\\nMODEL ANSWER (INCORRECT ;SEMANTIC UNDERSTANDING ERROR ):Gretchen has 110 coins. There\\nare 30 more gold coins than silver coins. So there are 110 - 30 = 80 silver coins. So there are 80 silver coins and\\n110 - 80 = 30 gold coins. The answer is 30. \\x17\\nEXPLANATION FOR ERROR CATEGORY :The model does not understand that 110 coins are in total and that\\nit must solve an equation to get the number of gold and silver coins.\\nQUESTION :In a dance class of 20 students, 20% enrolled in contemporary dance, 25% of the remaining\\nenrolled in jazz dance, and the rest enrolled in hip-hop dance. What percentage of the entire students enrolled in\\nhip-hop dance?\\nMODEL ANSWER (INCORRECT ;INCOHERENT CHAIN OF THOUGHT ERROR ):20% of the students en-\\nrolled in contemporary dance. 25% of the remaining students enrolled in jazz dance. The rest enrolled in hip-hop\\ndance. So the percentage of the entire students enrolled in hip-hop dance is the percentage of the students\\nenrolled in hip-hop dance, minus the percentage of the students enrolled in contemporary dance, minus the\\npercentage of the students enrolled in jazz dance. So the percentage of the entire students enrolled in hip-hop\\ndance is (25 + 20) - (25 + 20) = 100%. The answer is 100%. \\x17\\nEXPLANATION FOR ERROR CATEGORY :This chain of thought is incoherent in that the percent of entire\\nstudents enrolled in hip-hope dance cannot be the percent of student enrolled in hip-hop dance minus another\\nterm.\\nOverall, there are no guarantees that the reasoning processes generated by large language models\\nare coherent or factually correct, as underscored by the recent work evaluating the factuality of\\nlanguage model generations and explanations (Maynez et al., 2020; Rashkin et al., 2021; Ye and\\nDurrett, 2022; Marasovi ´c et al., 2022; Wiegreffe et al., 2022). Incorrect reasoning processes can lead\\nto both incorrect ﬁnal answers as well as accidentally correct ﬁnal answers (with accidentally correct\\nﬁnal answers being more likely for tasks such as binary classiﬁcation as opposed to free response).\\nImproving the factuality of language model generations with respect to context and world knowledge\\nis an important direction open problems in language model research and could also be expected to\\npotentially improve multi-step reasoning abilities of language models. One potential method for\\nimproving the quality of decoding could involve generating multiple reasoning paths and scoring\\neach of them with a veriﬁer, though this requires training the veriﬁer (Cobbe et al., 2021; Shen et al.,\\n2021; Thoppilan et al., 2022).\\nD.3 Additional Robustness Analysis\\nAs the experiments in the main paper use a ﬁxed number of few-shot exemplars (8; as constrained by\\nthe input length of 1024 tokens), we verify that the chain-of-thought prompting is robust to various\\nnumbers of few-shot exemplars. We run experiments for LaMDA 137B, comparing chain-of-thought\\nprompting with standard prompting for the ﬁve datasets where standard prompting had a mostly ﬂat\\nscaling curve (the largest model did not achieve high performance). As shown in Figure 11, the\\nimprovement of chain-of-thought prompting over standard prompting remains robust to varying the\\nnumber of few-shot exemplars in the prompt.\\n28', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 27}), Document(page_content='12468051015 Solve rate (%)GSM8K\\n124680204060MultiArith\\n(MAWPS)\\n124680255075100\\nNumber of few-shot exemplarsSports\\nUnderstandingStandard prompting\\nChain of thought prompting\\n124680255075100Coin Flip\\n12340255075100Last Letter\\nConcatenation\\nFigure 11: The improvement of chain of thought prompting over standard prompting appears robust\\nto varying the number of few-shot exemplars in the prompt.\\nTable 12: Summary of math word problem benchmarks we use in this paper with examples. N:\\nnumber of evaluation examples.\\nDataset N Example problem\\nGSM8K 1,319 Josh decides to try ﬂipping a house. He buys a house for $80,000 and then puts\\nin $50,000 in repairs. This increased the value of the house by 150%. How\\nmuch proﬁt did he make?\\nSV AMP 1,000 Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each\\npack. How much do you have to pay to buy each pack?\\nASDiv 2,096 Ellen has six more balls than Marin. Marin has nine balls. How many balls does\\nEllen have?\\nAQuA 254 A car is being driven, in a straight line and at a uniform speed, towards the base\\nof a vertical tower. The top of the tower is observed from the car and, in the\\nprocess, it takes 10 minutes for the angle of elevation to change from 45◦to 60◦.\\nAfter how much more time will this car reach the base of the tower? Answer\\nChoices: (a) 5√\\n3+ 1 (b) 6√\\n3+√\\n2(c) 7√\\n3- 1 (d) 8√\\n3- 2 (e) None of these\\nMAWPS: SingleOp 562 If there are 7 bottle caps in a box and Linda puts 7 more bottle caps inside, how\\nmany bottle caps are in the box?\\nMAWPS: SingleEq 508 Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27\\ndollars. How much did each candy bar cost?\\nMAWPS: AddSub 395 There were 6 roses in the vase. Mary cut some roses from her ﬂower garden.\\nThere are now 16 roses in the vase. How many roses did she cut?\\nMAWPS: MultiArith 600 The school cafeteria ordered 42 red apples and 7 green apples for students\\nlunches. But, if only 9 students wanted fruit, how many extra did the cafeteria\\nend up with?\\n29', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 28}), Document(page_content='E Additional Details\\nVersion Control\\nV5→V6. Fixed minor typo in Figure 3.\\nV4→V5. Added Codex and UL2 results. Small changes to writing and style of paper.\\nV3→V4. Fixed typo in Figure 3 and added a couple citations.\\nV2→V3. Added GPT-3 results. Added SV AMP and AQuA eval datasets for math. Added SayCan\\neval for commonsense. Added Extended Related Work section (Appendix C). Added ablations for\\nCommonsense and Symbolic Reasoning (Table 7). Added FAQ section (Appendix A). Added raw\\nresults in Appendix B.\\nV1→V2. Added PaLM results (V1 only had LaMDA).\\nE.1 Reproducibility Statement\\nAs our results make use of two sets of large language models that is not publicly available, we take\\nthe following actions to facilitate reproducibility. First, we provide the exact input prompts for all\\ntasks in Table 20–Table 27 in Appendix G (and emphasize that we do not perform any ﬁnetuning and\\nonly apply prompting to off-the-shelf language models). Second, we conduct experiments using the\\npublicly available GPT-3 API for four model scales text-ada-001, text-babbage-001, text-curie-001,\\ntext-davinci-002). Finally, we make exact inputs, targets, and predictions for LaMDA 137B for each\\ntask available as a zip ﬁle in the supplementary material.\\nE.2 Computational Resources\\nFor all three language models we evaluated, we did prompting-based inference only. No ﬁnetuning\\nwas done for this paper. For inference on LaMDA 137B we use TPU v3 (8x8 conﬁguration, 64 chips\\n/ 128 cores), and for inference on PaLM 540B we use TPU v4 (4x4x12 conﬁguration, 192 chips / 384\\ncores). GPT-3 experiments were done using the public API.5\\nE.3 Dataset Details and Licenses\\nWe list the details and licenses for all arithmetic and commonsense datasets used in this paper. The\\nsymbolic reasoning datasets were created synthetically, as described in Section 4.\\nArithmetic reasoning\\n•Math Word Problem Repository (Koncel-Kedziorski et al., 2016): AddSub (Hosseini\\net al., 2014): https://www.cs.washington.edu/nlp/arithmetic ; MultiArith (Roy\\nand Roth, 2015), license: CC BY 4.0.\\n• ASDiv (Miao et al., 2020): https://github.com/chaochun/nlu-asdiv-dataset .\\n•AQuA (Ling et al., 2017): https://github.com/deepmind/AQuA , license: https://\\ngithub.com/deepmind/AQuA/blob/master/LICENSE .\\n•GSM8K (Cobbe et al., 2021): https://github.com/openai/grade-school-math ,\\nMIT license: https://github.com/openai/grade-school-math/blob/master/\\nLICENSE .\\n•SV AMP (Patel et al., 2021): https://github.com/arkilpatel/SVAMP , MIT license:\\nhttps://github.com/arkilpatel/SVAMP/blob/main/LICENSE .\\nCommonsense reasoning\\n•CSQA (Talmor et al., 2019): https://www.tau-nlp.org/commonsenseqa ,https://\\ngithub.com/jonathanherzig/commonsenseqa .\\n5https://beta.openai.com/docs/api-reference/making-requests\\n30', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 29}), Document(page_content='•StrategyQA (Geva et al., 2021): we use the open-domain setting (question-only set)\\nfrom BIG-bench collaboration (2021): https://github.com/google/BIG-bench/\\ntree/main/bigbench/benchmark_tasks/strategyqa . The original dataset is from\\nhttps://github.com/eladsegal/strategyqa , MIT license: https://github.com/\\neladsegal/strategyqa/blob/main/LICENSE .\\n•Date understanding and sports understanding from BIG-Bench (BIG-bench collaboration,\\n2021): Apache License v.2: https://github.com/google/BIG-bench/blob/main/\\nLICENSE .\\n•SayCan (Ahn et al., 2022): SayCan dataset can be accessed at https://say-can.github.\\nio/under CC BY 4.0 license.\\n31', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 30}), Document(page_content='F Appendix: Input/Output Examples\\nTable 13: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the\\nletter concatenation task.\\nQUESTION :Take the last letters of the words in “Waldo Schmidt” and concatenate them.\\nMODEL ANSWER (CORRECT): The last letter of “Waldo” is “o”. The last letter of “Schmidt” is “t”.\\nConcatenating them is “ot”. So the answer is ot. ✓\\nQUESTION :Take the last letters of the words in “Daniel Friedman” and concatenate them.\\nMODEL ANSWER (INCORRECT): The last letter of “Daniel” is “l”. The last letter of “Friedman” is “m”.\\nConcatenating them is “lm”. So the answer is lm. \\x17\\nTable 14: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the\\ncoinﬂip task.\\nQUESTION :A coin is heads up. Andree ﬂips the coin. Audrie does not ﬂip the coin. Is the coin still heads up?\\nMODEL ANSWER (CORRECT): The coin was ﬂipped by Andree. So the coin was ﬂipped 1 time, which is\\nan odd number. The coin started heads up, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\n✓\\nQUESTION :A coin is heads up. Kristian does not ﬂip the coin. Dallas does not ﬂip the coin. Is the coin still\\nheads up?\\nMODEL ANSWER (INCORRECT): The coin was ﬂipped by Kristian. So the coin was ﬂipped 1 time, which\\nis an odd number. The coin started heads up, so after an odd number of ﬂips, it will be tails up. So the answer is\\nno.\\x17\\nTable 15: Examples of correct and incorrect chains of thought produced by LaMDA 137B on CSQA.\\nQUESTION :When a person is beginning work, what are they building?\\nAnswer Choices: (a) time (b) accomplishing (c) working (d) momentum (e) tiredness\\nMODEL ANSWER (CORRECT): The answer must be something that is built. Of the above choices, only\\nmomentum is built. So the answer is (d). ✓\\nQUESTION :Where are you likely to ﬁnd a hamburger?\\nAnswer Choices: (a) fast food restaurant (b) pizza (c) ground up dead cows (d) mouth (e) cow carcus\\nMODEL ANSWER (CORRECT): The answer must be a place where hamburgers are found. Of the above\\nchoices, only fast food restaurants serve hamburgers. So the answer is (a). ✓\\nQUESTION :Aside from water and nourishment what does your dog need?\\nAnswer Choices: (a) bone (b) charm (c) petted (d) lots of attention (e) walked\\nMODEL ANSWER (INCORRECT): The answer must be something that a dog needs. Of the above choices,\\nonly bone is something that a dog needs. So the answer is (a). \\x17(Ground truth is (d).)\\nQUESTION :What are you waiting alongside with when you’re in a reception area?\\nAnswer Choices: (a) motel (b) chair (c) hospital (d) people (e) hotels\\nMODEL ANSWER (INCORRECT): The answer must be something that is waiting with you in a reception\\narea. Of the above choices, only people are waiting with you in a reception area. So the answer is (e). \\x17(Ground\\ntruth is (d).)\\n32', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 31}), Document(page_content='Table 16: Examples of correct and incorrect chains of thought produced by LaMDA 137B on\\nStrategyQA.\\nQUESTION :Will The Exorcist stimulate limbic system?\\nMODEL ANSWER (CORRECT): The Exorcist is a horror movie. Horror movies are scary. The limbic system\\nis involved in fear. Thus, The Exorcist will stimulate the limbic system. So the answer is yes. ✓\\nQUESTION :Was Jackson Pollock trained by Leonardo da Vinci?\\nMODEL ANSWER (CORRECT): Leonardo da Vinci lived in the 15th century. Jackson Pollock lived in the\\n20th century. Thus, Jackson Pollock could not have been trained by Leonardo da Vinci. So the answer is no. ✓\\nQUESTION :Can Harry Potter book a ﬂight on Asiana Airlines?\\nMODEL ANSWER (INCORRECT): Harry Potter is a ﬁctional character. Thus, Harry Potter can do anything.\\nSo the answer is yes. \\x17(Ground truth is “no”.)\\nQUESTION :Would a sophist use an épée?\\nMODEL ANSWER (INCORRECT): A sophist is a person who is skilled in the art of persuasion. An épée is\\na type of sword. Thus, a sophist could use an épée. So the answer is yes. \\x17(Ground truth is “no”.)\\nTable 17: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Date\\nUnderstanding.\\nQUESTION :May 6, 1992 is like yesterday to Jane, but that is actually ten years ago. What is the date a month\\nago in MM/DD/YYYY?\\nMODEL ANSWER (CORRECT): May 6, 1992 is ten years ago, so today is May 6, 2002. So a month ago will\\nbe April 6, 2002. So the answer is 04/06/2002. ✓\\nQUESTION :This is the last day of 1899. What is the date 24 hours later in MM/DD/YYYY?\\nMODEL ANSWER (CORRECT): Today is 12/31/1899. 24 hours later will be 01/01/1900. So the answer is\\n01/01/1900. ✓\\nQUESTION :Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one\\nweek ago from today in MM/DD/YYYY?\\nMODEL ANSWER (INCORRECT): Tomorrow is 7/9/1972. One week ago from today is 7/2/1972. So the\\nanswer is 7/2/1972. \\x17(Ground truth is 07/01/1972.)\\nQUESTION :Today is the palindrome day of 2020, because the MMDDYYYY format of the date is the same\\nbackwards as forwards. What is the date tomorrow in MM/DD/YYYY?\\nMODEL ANSWER (INCORRECT): Today is 02/29/2020. Tomorrow will be 03/01/2020. So the answer is\\n03/01/2020. \\x17(Ground truth is “02/03/2020”.)\\nTable 18: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Sports\\nUnderstanding.\\nQUESTION :Is the following sentence plausible? “Joao Moutinho was out at third.”\\nMODEL ANSWER (CORRECT): Joao Moutinho is a soccer player. Being out at third is part of baseball, not\\nsoccer. So the answer is no. ✓\\nQUESTION :Is the following sentence plausible? “Malcolm Brogdon eurostepped to the basket in the NBA\\nChampionship.”\\nMODEL ANSWER (CORRECT): Malcolm Brogdon is a basketball player. Eurostepping to the basket is part\\nof basketball. So the answer is yes. ✓\\nQUESTION :Is the following sentence plausible? “Derrick White backhanded a shot.”\\nMODEL ANSWER (INCORRECT): Derrick White is a basketball player. Backhanding a shot is part of\\nbasketball. So the answer is yes. \\x17(Ground truth is “no”, backhanding a shot is part of hockey.)\\nQUESTION :Is the following sentence plausible? “Nazem Kadri was out at home.”\\nMODEL ANSWER (INCORRECT): Nazem Kadri is a hockey player. Being out at home is part of hockey.\\nSo the answer is yes. \\x17(Ground truth is “no”, being out at home is part of baseball.)\\n33', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 32}), Document(page_content='Table 19: Examples of correct and incorrect chains of thought produced by PaLM 540B on SayCan\\nrobot planning tasks.\\nQUESTION :I spilled my coke on the table, could you throw it away and then bring me something to help clean?\\nMODEL ANSWER (CORRECT): Explanation: The user has spilled their coke on the table. I will throw away\\nthe coke and then bring the user a sponge. Plan: ﬁnd(coke), pick(coke), ﬁnd(trash), put(coke), ﬁnd(sponge),\\npick(sponge), ﬁnd(table), put(sponge). ✓\\nQUESTION :Could you compost that apple for me?\\nMODEL ANSWER (CORRECT): Explanation: The user would like me to compost the apple. I will move the\\napple to the compost. Plan: ﬁnd(apple), pick(apple), ﬁnd(trash), put(apple). ✓\\nQUESTION :Can you bring me a drink that is not coke?\\nMODEL ANSWER (INCORRECT): Explanation: The user asked me to bring a drink that is not coke, I will\\nbring a sprite. Plan: ﬁnd(sprite), pick(sprite), ﬁnd(user), put(sprite). \\x17(Feasible answers including ﬁnding lime\\nsoda, pepsi, grapefruit soda or water, because there is no sprite in the scene as deﬁned in Table 28.)\\nQUESTION :Can you bring me something salty?\\nMODEL ANSWER (INCORRECT): Explanation: The user would like something salty. There are several\\noptions in the objects list, so I will bring the user a lime soda. Plan: ﬁnd(lime soda), pick(lime soda), ﬁnd(user),\\nput(lime soda). \\x17(Feasible answers including ﬁnding chips. The model misidentify lime soda as salty.)\\n34', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 33}), Document(page_content='G Appendix: Full Prompts\\nTable 20: Few-shot exemplars for full chain of thought prompt for math word problems. This set of\\nexemplars was used for all math word problem datasets except AQuA.\\nPROMPT FOR MATH WORD PROBLEMS\\nQ:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA:There are15trees originally. Then there were 21trees aftersome more were planted. Sothere must have\\nbeen 21-15=6. The answer is 6.\\nQ:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA:There areoriginally 3cars. 2more carsarrive. 3+2=5. The answer is 5.\\nQ:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA:Originally, Leah had32choco lates. Hersisterhad42.Sointotalthey had32+42=74.Aftereating35,they\\nhad74-35=39. The answer is 39.\\nQ:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA:Jasonstarted with 20lollipops. Then hehad12aftergivingsome toDenny. Sohegave Denny 20-12=8.\\nThe answer is 8.\\nQ:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA:Shawn started with 5toys. Ifhegot2toys each from hismom anddad, then thatis4more toys. 5+4=9.\\nThe answer is 9.\\nQ:There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA:There were originally 9computers.Foreach of4days, 5more computerswere added. So5*4=20\\ncomputerswere added. 9+20is29. The answer is 29.\\nQ:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA:Michael started with 58golfballs. Afterlosing23ontuesday, hehad58-23=35.Afterlosing2more, he\\nhad35-2=33golfballs. The answer is 33.\\nQ:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA:Olivia had23dollars. 5bagels for3dollarseach willbe5x3=15dollars. Soshehas23-15dollarsleft.23\\n-15is8. The answer is 8.\\n35', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 34}), Document(page_content='Table 21: Few-shot exemplars for full chain of thought prompt for AQuA.\\nPROMPT FOR AQ UAALGEBRAIC WORD PROBLEMS\\nQ:John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers\\nis?\\nAnswer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\\nA:If10isadded toeach number,then themean ofthenumbers alsoincreases by10.Sothenewmean would be\\n50. The answer is (a).\\nQ:If a / b = 3/4 and 8a + 5b = 22,then ﬁnd the value of a.\\nAnswer Choices: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e) 7/2\\nA:Ifa/b=3/4,then b=4a/3.So8a+5(4a /3)=22.This simpliﬁesto8a+20a/3=22,which means 44a/3\\n=22.Soaisequal to3/2. The answer is (b).\\nQ:A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then ﬁnd the distance?\\nAnswer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km\\nA:Thedistance thatthepersontraveled would have been 20km/hr *2.5hrs=50km. The answer is (e).\\nQ:How many keystrokes are needed to type the numbers from 1 to 500?\\nAnswer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788\\nA:There are9one-digit numbers from 1to9.There are90two-digit numbers from 10to99.There are401\\nthree -digit numbers from 100to500. 9+90(2) +401(3) =1392. The answer is (b).\\nTable 22: Few-shot exemplars for full chain of thought prompt for the last letter concatenation task.\\nPROMPT FOR LAST LETTER CONCATENATION\\nQ:Take the last letters of the words in \"Elon Musk\" and concatenate them.\\nA:Thelastletterof\"Elon\" is\"n\".Thelastletterof\"Musk\" is\"k\".Concatenatingthem is\"nk\". The answer is nk.\\nQ:Take the last letters of the words in \"Larry Page\" and concatenate them.\\nA:Thelastletterof\"Larry\" is\"y\".Thelastletterof\"Page\" is\"e\".Concatenatingthem is\"ye\". The answer is ye.\\nQ:Take the last letters of the words in \"Sergey Brin\" and concatenate them.\\nA:Thelastletterof\"Sergey\" is\"y\".Thelastletterof\"Brin\" is\"n\".Concatenatingthem is\"yn\". The answer is\\nyn.\\nQ:Take the last letters of the words in \"Bill Gates\" and concatenate them.\\nA:Thelastletterof\"Bill\" is\"l\".Thelastletterof\"Gates\" is\"s\".Concatenatingthem is\"ls\". The answer is ls.\\n36', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 35}), Document(page_content='Table 23: Few-shot exemplars for full chain of thought prompt for the coinﬂip task.\\nPROMPT FOR COIN FLIP\\nQ:Q: A coin is heads up. Ka ﬂips the coin. Sherrie ﬂips the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byKaandSherrie.Sothecoin wasﬂipped 2times, which isaneven number.Thecoin\\nstarted heads up,soafteraneven numberofﬂips, itwillstillbeheads up. So the answer is yes.\\nQ:A coin is heads up. Jamey ﬂips the coin. Teressa ﬂips the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byJamey andTeressa. Sothecoin wasﬂipped 2times, which isaneven number.The\\ncoin started heads up,soafteraneven numberofﬂips, itwillstillbeheads up. So the answer is yes.\\nQ:A coin is heads up. Maybelle ﬂips the coin. Shalonda does not ﬂip the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byMaybelle. Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin started\\nheads up,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\\nQ:A coin is heads up. Millicent does not ﬂip the coin. Conception ﬂips the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byConception. Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin\\nstarted heads up,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\\nQ:A coin is heads up. Sal ﬂips the coin. Raymond does not ﬂip the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped bySal.Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin started heads\\nup,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\\nQ:A coin is heads up. Conception ﬂips the coin. Kristian does not ﬂip the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byConception. Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin\\nstarted heads up,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\\nQ:A coin is heads up. Inga does not ﬂip the coin. Elanor does not ﬂip the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped bynoone. Sothecoin wasﬂipped 0times. Thecoin started heads up,anditwasnot\\nﬂipped, soitisstillheads up. So the answer is yes.\\nQ:A coin is heads up. Ryan ﬂips the coin. Shaunda ﬂips the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byRyan andShaunda. Sothecoin wasﬂipped 2times, which isaneven number.The\\ncoin started heads up,soafteraneven numberofﬂips, itwillstillbeheads up. So the answer is yes.\\n37', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 36}), Document(page_content='Table 24: Few-shot exemplars for full chain of thought prompt for CSQA. There are newlines\\nbetween the answer choices that are omitted in the table for space reasons.\\nPROMPT FOR CSQA\\nQ:What do people use to absorb extra ink from a fountain pen? Answer Choices: (a) shirt pocket (b)\\ncalligrapher’s hand (c) inkwell (d) desk drawer (e) blotter\\nA:Theanswer must beanitem thatcanabsorb ink.Oftheabove choices, only blottersareused toabsorb ink.\\nSo the answer is (e).\\nQ:What home entertainment equipment requires cable?\\nAnswer Choices: (a) radio shack (b) substation (c) television (d) cabinet\\nA:Theanswer must require cable.Oftheabove choices, only television requires cable. So the answer is (c).\\nQ:The fox walked from the city into the forest, what was it looking for? Answer Choices: (a) pretty ﬂowers (b)\\nhen house (c) natural habitat (d) storybook\\nA:Theanswer must besome thing intheforest.Oftheabove choices, only naturalhabitatisintheforest. So the\\nanswer is (b).\\nQ:Sammy wanted to go to where the people were. Where might he go? Answer Choices: (a) populated areas\\n(b) race track (c) desert (d) apartment (e) roadblock\\nA:Theanswer must beaplace with alotofpeople.Oftheabove choices, only populated areashave alotof\\npeople. So the answer is (a).\\nQ:Where do you put your grapes just before checking out? Answer Choices: (a) mouth (b) grocery cart (c)super\\nmarket (d) fruit basket (e) fruit market\\nA:Theanswer should betheplace where grocery items areplaced beforecheck ingout.Oftheabove choices,\\ngrocery cartmakes themost sense forholdinggrocery items. So the answer is (b).\\nQ:Google Maps and other highway and street GPS services have replaced what? Answer Choices: (a) united\\nstates (b) mexico (c) countryside (d) atlas\\nA:Theanswer must besome thing thatused todowhat Google Maps andGPS services do,which istogive\\ndirections. Oftheabove choices, only atlases areused togive directions. So the answer is (d).\\nQ:Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (a) harder (b)\\nanguish (c) bitterness (d) tears (e) sadness\\nA:Theanswer should bethefeelingofsome onegettingdivorced who wasdoingallthework. Oftheabove\\nchoices, theclosestfeelingisbitterness. So the answer is (c).\\n38', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 37}), Document(page_content='Table 25: Few-shot exemplars for full chain of thought prompt for StrategyQA.\\nPROMPT FOR STRATEGY QA\\nQ:Do hamsters provide food for any animals?\\nA:Ham sters areprey animals. Prey arefood forpreda tors. Thus, hamsters provide food forsome animals. So\\nthe answer is yes.\\nQ:Could Brooke Shields succeed at University of Pennsylvania?\\nA:Brooke Shields went toPrince tonUniversity. Prince tonUniversityisabout asacademically rigorousasthe\\nUniversityofPenn sylvania.Thus, Brooke Shields could alsosucceed attheUniversityofPenn sylvania. So the\\nanswer is yes.\\nQ:Yes or no: Hydrogen’s atomic number squared exceeds number of Spice Girls?\\nA:Hydrogenhasanatomic numberof1.1squared is1.There are5Spice Girls. Thus, Hydrogen’s atomic\\nnumbersquared islessthan 5. So the answer is no.\\nQ:Yes or no: Is it common to see frost during some college commencements?\\nA:College commence ment ceremonies canhappeninDecember,May, andJune. Decemberisinthewinter,so\\nthere canbefrost. Thus, there could befrost atsome commence ments. So the answer is yes.\\nQ:Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?\\nA:TheWar inVietnam was6months. Thegestationperiod forallama is11months, which ismore than 6\\nmonths. Thus, allama could notgive birth twice duringtheWar inVietnam. So the answer is no.\\nQ:Yes or no: Would a pear sink in water?\\nA:Thedensityofapear isabout 0.6g/cm3,which islessthan water.Objects lessdense than waterﬂoat. Thus,\\napear would ﬂoat. So the answer is no.\\nTable 26: Few-shot exemplars for full chain of thought prompt for Date Understanding.\\nPROMPT FOR DATE UNDERSTANDING\\nQ:2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?\\nA:If2015 iscomingin36hours, then itiscomingin2days. 2days before01/01/2015 is12/30/2014, sotoday\\nis12/30/2014. Sooneweek from todaywillbe01/05/2015. So the answer is 01/05/2015.\\nQ:The ﬁrst day of 2019 is a Tuesday, and today is the ﬁrst Monday of 2019. What is the date today in\\nMM/DD/YYYY?\\nA:Iftheﬁrstdayof2019 wasTues day,then 01/01/2019 wasaTues day.Todayistheﬁrstmonday,would besix\\ndays later. Sotodayis01/07/2019. So the answer is 01/07/2019.\\nQ:The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10\\ndays ago in MM/DD/YYYY?\\nA:One dayafter06/01/1943 is06/02/1943, sotodayis06/02/1943. 10days beforetodayis05/23/1943. So the\\nanswer is 05/23/1943.\\nQ:It is 4/19/1969 today. What is the date 24 hours later in MM/DD/YYYY?\\nA:Todayis04/19/1969. 24hours later isonedayaftertoday, which would be04/20/1969. So the answer is\\n04/20/1969.\\nQ:Jane thought today is 3/11/2002, but today is in fact Mar 12, which is 1 day later. What is the date 24 hours\\nlater in MM/DD/YYYY?\\nA:Todayis03/12/2002. Sothedate 24hours later willbe03/13/2002. So the answer is 03/13/2002.\\nQ:Jane was born on the last day of Feburary in 2001. Today is her 16-year-old birthday. What is the date\\nyesterday in MM/DD/YYYY?\\nA:ThelastdayofFebru aryisthe28th, soJane wasborn on02/28/2001. Todayisher16-year oldbirth day, so\\ntodayis02/28/2017. Soyesterdaywas02/27/2017. So the answer is 02/27/2017.\\n39', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 38}), Document(page_content='Table 27: Few-shot exemplars for full chain of thought prompt for Sports Understanding.\\nPROMPT FOR SPORTS UNDERSTANDING\\nQ:Is the following sentence plausible? “Kyle Palmieri was called for slashing.”\\nA:Kyle Palmieri isahockey player. Beingcalled forslash ingispartofhockey. So the answer is yes.\\nQ:Is the following sentence plausible? “Joao Moutinho caught the screen pass in the NFC championship.”\\nA:Joao Moutinho isasoccerplayer. TheNFC cham pionship ispartofAmer icanfootball, notsoccer. So the\\nanswer is no.\\nQ:Is the following sentence plausible? “Carson Wentz set the pick and roll.”\\nA:CarsonWentz isanAmer icanfootballplayer. Pick androllispartofbasketball, notfootball. So the answer\\nis no.\\nQ:Is the following sentence plausible? “Jonas Valanciunas beat the buzzer.”\\nA:Jonas Valan ciunasisabasketballplayer. Beatingthebuzzer ispartofbasketball. So the answer is yes.\\nQ:Is the following sentence plausible? “Jamel Murray was perfect from the line.”\\nA:JamalMurrayisabasketballplayer. Beingperfectfrom thelineispartofbasketball. So the answer is yes.\\nQ:Is the following sentence plausible? “Sam Darnold passed the puck.”\\nA:Sam Darnold isaAmer icanfootballplayer. Passingthepuck ispartofhockey, notAmer icanfootball. So the\\nanswer is no.\\nQ:Is the following sentence plausible? “Draymond Green threw a touchdown.”\\nA:Dray mond Green isanbasketballplayer. Throw ingatouch down ispartoffootball, notbasketball. So the\\nanswer is no.\\nQ:Is the following sentence plausible? “Malcolm Brogdon banked the shot in.”\\nA:Malcolm Brog donisabasketballplayer. Bank ingtheshot inispartofbasketball. So the answer is yes.\\n40', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 39}), Document(page_content='Table 28: Few-shot exemplars for full chain of thought prompt for SayCan robot planning tasks.\\nPROMPT FOR SAYCANROBOT PLANNING\\nLocations = [counter, table, user, trash, bowl].\\nObjects = [7up, apple, kettle chips, tea, multigrain chips, coke, lime soda, jalapeno chips, rice chips, orange,\\ngrapefruit soda, pepsi, redbull, energy bar, sponge, water].\\nThe robot can pick up items with pick(object) and put down items with put(object) as well as ﬁnd objects or\\nlocations with ﬁnd(). The robot can only understand the explicit locations and objects listed.\\nHuman : I’m hungry, can you bring me some chips.\\nExplanation :Theuser ishungryandhasasked forchips. There areseveraltypes ofchips avail able, Iwillbring\\ntheuser thekettlechips.\\nPlan : 1. ﬁnd(kettle chips), 2. pick(kettle chips), 3. ﬁnd(user), 4. put(kettle chips), 5. done().\\nHuman : How would you move the grapefruit drink from the table to the counter?\\nExplanation :Theuser hasasked metomove thegrape fruit drink tothecounter.\\nPlan : 1. ﬁnd(grapefruit soda), 2. pick(grapefruit soda), 3. ﬁnd(counter), 4. put(grapefruit soda), 5. done().\\nHuman : How would you bring me some snacks?\\nExplanation :Theuser hasasked forsnacks, Iwillchoose twoitems andbring them. Iwillbring jalapeno chips\\nandanapple.\\nPlan : 1. ﬁnd(jalapeno chips), 2. pick(jalapeno chips), 3. ﬁnd(user), 4. put(jalapeno chips), 5. ﬁnd(apple), 6.\\npick(apple), 7. ﬁnd(user), 8. put(apple), 9. done().\\nHuman : How would you bring me something to eat that isn’t a fruit?\\nExplanation :Theuser hasasked forafood thatisn’t afruit, Iwillbring anenergy bartothem.\\nPlan : 1. ﬁnd(energy bar), 2. pick(energy bar), 3. ﬁnd(user), 4. put(energy bar), 5. done().\\nHuman : How would you put the rice chips in the bowl and then move the tea to the table?\\nExplanation :Theuser hasasked metodotwotasks, Iwilldooneandthen theother.\\nPlan : 1. ﬁnd(rice chips), 2. pick(rice chips), 3. ﬁnd(bowl), 4. put(rice chips), 5. ﬁnd(tea), 6. pick(tea), 7.\\nﬁnd(table), 8. put(tea), 9. done().\\nHuman : How would you throw away a redbull?\\nExplanation :Theuser hasasked metothrow away theredbull, Iwillmove ittothetrash.\\nPlan : 1. ﬁnd(redbull), 2. pick(redbull), 3. ﬁnd(trash), 4. put(redbull), 5. done().\\nHuman : Bring me a drink.\\nExplanation :Theuser hasasked foradrink andthere aremany options. Iwillbring them awater.\\nPlan : 1. ﬁnd(water), 2. pick(water), 3. ﬁnd(user), 4. put(water), 5. done().\\n41', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 40}), Document(page_content='H Appendix: Alternate Annotators for MWP\\nTable 29: Few-shot exemplars for full chain of thought prompt for math word problems. These\\nexemplars are the same as in Table 20, except that the chains of thought were written by a different\\nannotator (“Annotator B” instead of “Annotator A”). Annotators were co-authors and familiar with\\nthe goal of chain of thought prompting.\\nPROMPT FOR MATH WORD PROBLEMS\\nQ:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA:There are21trees now andthere are15trees inthebeginning, sothework ersplant 21-15=6trees. The\\nanswer is 6.\\nQ:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA:There are3carsinthebeginning, 2more arrive, sonow there should be3+2=5cars. The answer is 5.\\nQ:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA:Leah had32choco lates andhersisterhad42,intotalthey have 32+42=74choco lates. Afterthey ate35,\\nnow there are74-35=39choco lates. The answer is 39.\\nQ:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA:Jasonstarted with 20lollipops, butnow heonly has12,sohegave Denny 20-12=8lollipops. The answer\\nis 8.\\nQ:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA:Shawn got2toys each from hismom anddad, sohegot2*2=4more, now hewillhave 5+4=9toys. The\\nanswer is 9.\\nQ:There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA:5computerswere installed from mondaytothurs day, sointotal5*4=20computersareinstalled. 9\\ncomputersarethere inthebeginning, sonow there are20+9=29computers. The answer is 29.\\nQ:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA:Michael started with 58golfballs andlost23,sohehas58-23=35.Afterhelost2more, hehas35-2=33\\nballs now. The answer is 33.\\nQ:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA:5bagels for$3each should cost5*3=15dollars. Olivia had$23inthebeginning, sonow shehas23-15=\\n8dollarsleft. The answer is 8.\\n42', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 41}), Document(page_content='Table 30: Few-shot exemplars for full chain of thought prompt for math word problems. These\\nexemplars are the same as in Table 20, except that the chains of thought were written by a different\\nannotator (“Annotator C” instead of “Annotator A”).\\nPROMPT FOR MATH WORD PROBLEMS\\nQ:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA:Westart with 15trees. Later wehave 21trees. Thedifference must bethenumberoftrees they planted. So,\\nthey must have planted 21-15=6trees. The answer is 6.\\nQ:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA:There are3carsintheparkinglotalready. 2more arrive. Now there are3+2=5cars. The answer is 5.\\nQ:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA:Leah had32choco lates andLeah’s sisterhad42.That means there were originally 32+42=74choco lates.\\n35have been eaten. Sointotalthey stillhave 74-35=39choco lates. The answer is 39.\\nQ:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA:Jasonhad20lollipops. Since heonly has12now, hemust have given theresttoDenny. Thenumberof\\nlollipops hehasgiven toDenny must have been 20-12=8lollipops. The answer is 8.\\nQ:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA:Hehas5toys. Hegot2from mom, soafterthathehas5+2=7toys. Then hegot2more from dad, soin\\ntotalhehas7+2=9toys. The answer is 9.\\nQ:There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA:There are4days from mondaytothurs day.5computerswere added each day.That means intotal4*5=20\\ncomputerswere added. There were 9computersinthebeginning, sonow there are9+20=29computers. The\\nanswer is 29.\\nQ:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA:Michael initially had58balls. Helost23onTues day, soafterthathehas58-23=35balls. OnWednes day\\nhelost2more sonow hehas35-2=33balls. The answer is 33.\\nQ:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA:Shebought 5bagels for$3each. This means shespent 5*$3=$15onthebagels. Shehad$23inbeginning,\\nsonow shehas$23-$15=$8. The answer is 8.\\n43', metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 42}), Document(page_content='M a s t e r i n g\\nG e n e r a t i v e\\nA I\\na n d\\nP r o m p t\\nE n g i n e e r i n g :\\nA\\nP r a c t i c a l\\nG u i d e\\nf o r\\nD a t a\\nS c i e n t i s t s\\nA s\\nt h e\\nA I - d r i v e n\\ne c o n o m y\\nc o n t i n u e s\\nt o\\ne v o l v e\\na n d\\ne x p a n d ,\\nt h e\\nr o l e\\no f\\np r o m p t\\ne n g i n e e r i n g\\nw i l l\\nb e c o m e\\ni n c r e a s i n g l y\\ns i g n i ﬁ c a n t\\na n d\\nt r a n s f o r m a t i v e\\na c r o s s\\nd i v e r s e\\ns e c t o r s\\na n d\\nd o m a i n s .\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 0}), Document(page_content='C o n t e n t s\\nI n t r o d u c t i o n\\nC h a p t e r\\n1 :\\nU n d e r s t a n d i n g\\nG e n e r a t i v e\\nA I\\n1 . 1 .\\nE v o l u t i o n\\no f\\nA I :\\nF r o m\\nr u l e - b a s e d\\nt o\\ng e n e r a t i v e\\nm o d e l s\\n1 . 2 .\\nK e y\\ng e n e r a t i v e\\nA I\\nm o d e l s :\\nR N N s ,\\nL S T M s ,\\nG P T ,\\na n d\\nm o r e\\n1 . 3 .\\nP o p u l a r\\nu s e\\nc a s e s\\nf o r\\ng e n e r a t i v e\\nA I\\nC h a p t e r\\n2 :\\nI n t r o d u c t i o n\\nt o\\nP r o m p t\\nE n g i n e e r i n g\\n2 . 1 .\\nW h a t\\ni s\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nw h y\\ni t\\nm a t t e r s\\n2 . 2 .\\nP r o m p t\\nt y p e s :\\ne x p l i c i t ,\\ni m p l i c i t ,\\na n d\\nc r e a t i v e\\np r o m p t s\\n2 . 3 .\\nB e s t\\nP r a c t i c e s\\nf o r\\nC r a f t i n g\\nE f f e c t i v e\\nP r o m p t s\\nC h a p t e r\\n3 :\\nP r a c t i c a l\\nA p p l i c a t i o n s\\no f\\nP r o m p t\\nE n g i n e e r i n g\\n3 . 1 .\\nI m p r o v i n g\\nN L P\\nT a s k s\\nw i t h\\nC u s t o m\\nP r o m p t s\\n3 . 2 .\\nE n h a n c i n g\\nC r e a t i v i t y\\na n d\\nD i v e r s i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\n3 . 3 .\\nA d d r e s s i n g\\nA I\\nE t h i c s\\na n d\\nB i a s\\nt h r o u g h\\nT h o u g h t f u l\\nP r o m p t\\nE n g i n e e r i n g\\n3 . 4 .\\nP e r s o n a l i z a t i o n\\na n d\\nA d a p t a b i l i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\nC h a p t e r\\n4 :\\nC h a l l e n g e s\\na n d\\nL i m i t a t i o n s\\no f\\nP r o m p t\\nE n g i n e e r i n g\\n4 . 1 .\\nU n d e r s t a n d i n g\\nA I\\nM o d e l\\nL i m i t a t i o n s\\na n d\\nI n h e r e n t\\nB i a s e s\\n4 . 2 .\\nS t r i k i n g\\nt h e\\nR i g h t\\nB a l a n c e\\nb e t w e e n\\nG u i d a n c e\\na n d\\nF l e x i b i l i t y\\n4 . 3 .\\nE n s u r i n g\\nQ u a l i t y\\na n d\\nR e l i a b i l i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\nC h a p t e r\\n5 :\\nF u t u r e\\nD i r e c t i o n s\\na n d\\nE m e r g i n g\\nT r e n d s\\ni n\\nP r o m p t\\nE n g i n e e r i n g\\n5 . 1 .\\nL e v e r a g i n g\\nA d v a n c e d\\nA I\\nM o d e l s\\na n d\\nT e c h n i q u e s\\n5 . 2 .\\nT h e\\nC o n v e r g e n c e\\no f\\nH u m a n\\na n d\\nA I\\nC r e a t i v i t y\\n5 . 3 .\\nT h e\\nR o l e\\no f\\nP r o m p t\\nE n g i n e e r i n g\\ni n\\nt h e\\nA I - D r i v e n\\nE c o n o m y\\nC h a p t e r\\n6 :\\nP r a c t i c a l\\nT i p s\\na n d\\nB e s t\\nP r a c t i c e s\\nf o r\\nP r o m p t\\nE n g i n e e r i n g\\n6 . 1 .\\nG e t t i n g\\nS t a r t e d\\nw i t h\\nP r o m p t\\nE n g i n e e r i n g\\n6 . 2 .\\nB u i l d i n g\\na n\\nE f f e c t i v e\\nP r o m p t\\nE n g i n e e r i n g\\nW o r k f l o w\\n6 . 3 .\\nO v e r c o m i n g\\nC o m m o n\\nC h a l l e n g e s\\ni n\\nP r o m p t\\nE n g i n e e r i n g\\n6 . 4 .\\nM e a s u r i n g\\nt h e\\nS u c c e s s\\no f\\nY o u r\\nP r o m p t\\nE n g i n e e r i n g\\nE f f o r t s\\nC o n c l u s i o n\\nA p p e n d i c e s\\nA .\\nR e c o m m e n d e d\\nb o o k s ,\\na r t i c l e s ,\\na n d\\nb l o g s\\nB :\\nO n l i n e\\nc o m m u n i t i e s\\na n d\\nf o r u m s\\nf o r\\nd i s c u s s i o n s\\na n d\\nc o l l a b o r a t i o n\\n1\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 1}), Document(page_content=\"I n t r o d u c t i o n\\nT h e\\nﬁ e l d\\no f\\na r t i ﬁ c i a l\\ni n t e l l i g e n c e\\n( A I )\\nh a s\\nc o m e\\na\\nl o n g\\nw a y\\ns i n c e\\ni t s\\ni n c e p t i o n ,\\nw i t h\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g\\np l a y i n g\\nc r u c i a l\\nr o l e s\\ni n\\ni t s\\na d v a n c e m e n t .\\nA s\\nd a t a\\ns c i e n t i s t s ,\\ni t ' s\\ne s s e n t i a l\\nt o\\ns t a y\\nu p d a t e d\\nw i t h\\nt h e\\nl a t e s t\\nt r e n d s\\na n d\\nt e c h n i q u e s\\nt o\\nu n l o c k\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\nA I\\ni n\\nv a r i o u s\\na p p l i c a t i o n s .\\nT h i s\\ns h o r t\\ne b o o k\\na i m s\\nt o\\np r o v i d e\\na\\nc o m p r e h e n s i v e\\ng u i d e\\no n\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g ,\\ne q u i p p i n g\\nr e a d e r s\\nw i t h\\nt h e\\nk n o w l e d g e\\na n d\\nt o o l s\\nn e c e s s a r y\\nt o\\ne x c e l\\ni n\\nt h e\\nr e a l m\\no f\\nd a t a\\ns c i e n c e .\\nG e n e r a t i v e\\nA I\\ne n c o m p a s s e s\\na\\nr a n g e\\no f\\nm o d e l s\\na n d\\nt e c h n i q u e s\\nd e s i g n e d\\nt o\\ng e n e r a t e\\nn e w\\nd a t a\\nb a s e d\\no n\\ne x i s t i n g\\ni n p u t\\nd a t a .\\nT h e s e\\nm o d e l s\\nh a v e\\nd e m o n s t r a t e d\\ns i g n i ﬁ c a n t\\nc a p a b i l i t i e s\\ni n\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g ,\\ni m a g e\\ng e n e r a t i o n ,\\na n d\\nm o r e .\\nB y\\nu n d e r s t a n d i n g\\nt h e\\nm e c h a n i c s\\na n d\\ni n t r i c a c i e s\\no f\\ng e n e r a t i v e\\nA I ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nh a r n e s s\\ni t s\\np o w e r\\nt o\\nc r e a t e\\ni n n o v a t i v e\\ns o l u t i o n s\\nf o r\\na\\nm u l t i t u d e\\no f\\np r o b l e m s .\\nP r o m p t\\ne n g i n e e r i n g ,\\no n\\nt h e\\no t h e r\\nh a n d ,\\nd e a l s\\nw i t h\\nt h e\\na r t\\no f\\nc r a f t i n g\\ne \\x00 e c t i v e\\np r o m p t s\\nt o\\ng u i d e\\nA I\\nm o d e l s\\ni n\\ng e n e r a t i n g\\nd e s i r e d\\no u t p u t s .\\nA s\\nA I\\nm o d e l s\\nb e c o m e\\nm o r e\\ns o p h i s t i c a t e d ,\\nt h e\\nn e e d\\nf o r\\ne \\x00 c i e n t\\na n d\\np r e c i s e\\np r o m p t\\ne n g i n e e r i n g\\nh a s\\ng r o w n\\nm o r e\\nc r i t i c a l .\\nB y\\nm a s t e r i n g\\nt h i s\\ns k i l l ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nb e t t e r\\nd i r e c t\\nA I\\nm o d e l s\\nt o\\np r o d u c e\\nt a r g e t e d\\nr e s u l t s ,\\nu l t i m a t e l y\\ne n h a n c i n g\\nt h e\\ne \\x00 c a c y\\no f\\nt h e i r\\na p p l i c a t i o n s .\\nT h i s\\ne b o o k\\nw i l l\\nd e l v e\\ni n t o\\nt h e\\nk e y\\nc o n c e p t s ,\\nb e s t\\np r a c t i c e s ,\\na n d\\nr e a l - w o r l d\\na p p l i c a t i o n s\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g .\\nI t\\nw i l l\\ne x p l o r e\\nt h e\\nc a p a b i l i t i e s\\na n d\\nl i m i t a t i o n s\\no f\\np o p u l a r\\nA I\\nm o d e l s ,\\nd e t a i l\\nt h e\\np r o c e s s\\no f\\nd e s i g n i n g\\ne \\x00 e c t i v e\\np r o m p t s ,\\na n d\\nd i s c u s s\\nt h e\\ne t h i c a l\\nc o n s i d e r a t i o n s\\nt h a t\\na r i s e\\nw h e n\\nw o r k i n g\\nw i t h\\nt h e s e\\nt e c h n o l o g i e s .\\nT o\\nf u r t h e r\\ns u p p o r t\\ny o u r\\nl e a r n i n g ,\\nt h e\\nb o o k\\nw i l l\\na l s o\\np r e s e n t\\na\\ns e r i e s\\no f\\nc a s e\\ns t u d i e s ,\\nd e m o n s t r a t i n g\\nt h e\\np r a c t i c a l\\na p p l i c a t i o n s\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g\\ni n\\nv a r i o u s\\ni n d u s t r i e s .\\nB y\\nt h e\\ne n d\\no f\\nt h i s\\ne b o o k ,\\ny o u\\nw i l l\\nh a v e\\ng a i n e d\\na\\ns o l i d\\nu n d e r s t a n d i n g\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g ,\\ne n a b l i n g\\ny o u\\nt o\\na p p l y\\nt h e s e\\nt e c h n i q u e s\\nt o\\ny o u r\\no w n\\np r o j e c t s\\ne \\x00 e c t i v e l y .\\nA s\\nA I\\nc o n t i n u e s\\nt o\\ne v o l v e\\na n d\\ni m p a c t\\no u r\\nw o r l d\\ni n\\nu n p r e c e d e n t e d\\nw a y s ,\\nt h e\\nk n o w l e d g e\\ny o u\\ng a i n\\nf r o m\\nt h i s\\ng u i d e\\nw i l l\\np r o v e\\ni n v a l u a b l e\\ni n\\ny o u r\\nj o u r n e y\\na s\\na\\nd a t a\\ns c i e n t i s t .\\n2\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 2}), Document(page_content=\"C h a p t e r\\n1 :\\nU n d e r s t a n d i n g\\nG e n e r a t i v e\\nA I\\nB y\\nu n d e r s t a n d i n g\\nt h e\\ne v o l u t i o n\\no f\\nA I\\na n d\\nt h e\\nm e c h a n i c s\\no f\\ng e n e r a t i v e\\nm o d e l s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nb e t t e r\\nh a r n e s s\\nt h e s e\\nc u t t i n g - e d g e\\nt e c h n o l o g i e s\\nt o\\nc r e a t e\\ni n n o v a t i v e\\ns o l u t i o n s\\nf o r\\na\\nd i v e r s e\\nr a n g e\\no f\\nc h a l l e n g e s .\\n1 . 1 .\\nE v o l u t i o n\\no f\\nA I :\\nF r o m\\nR u l e - B a s e d\\nt o\\nG e n e r a t i v e\\nM o d e l s\\nT h e\\nh i s t o r y\\no f\\na r t i ﬁ c i a l\\ni n t e l l i g e n c e\\nc a n\\nb e\\nt r a c e d\\nb a c k\\nt o\\nt h e\\nm i d - 2 0 t h\\nc e n t u r y\\nw h e n\\nt h e\\nﬁ r s t\\nA I\\nc o n c e p t s\\ne m e r g e d .\\nO v e r\\nt h e\\ny e a r s ,\\nA I\\nh a s\\ne v o l v e d\\nt h r o u g h\\ns e v e r a l\\ns t a g e s ,\\ne a c h\\nm a r k e d\\nb y\\ns i g n i ﬁ c a n t\\na d v a n c e m e n t s\\ni n\\nt e c h n o l o g y\\na n d\\nm e t h o d o l o g y .\\nO n e\\no f\\nt h e\\nm o s t\\nn o t a b l e\\nt r a n s i t i o n s\\ni n\\nA I\\nh a s\\nb e e n\\nt h e\\ns h i f t\\nf r o m\\nr u l e - b a s e d\\ns y s t e m s\\nt o\\ng e n e r a t i v e\\nm o d e l s .\\nI n\\nt h e\\ne a r l y\\nd a y s\\no f\\nA I ,\\nr u l e - b a s e d\\ns y s t e m s\\nw e r e\\nt h e\\np r e d o m i n a n t\\na p p r o a c h .\\nT h e s e\\ns y s t e m s\\nr e l i e d\\no n\\na\\ns e t\\no f\\np r e d e ﬁ n e d\\nr u l e s\\na n d\\nd e c i s i o n\\nt r e e s\\nt o\\np r o c e s s\\ni n p u t\\nd a t a\\na n d\\np r o d u c e\\no u t p u t .\\nW h i l e\\nr u l e - b a s e d\\ns y s t e m s\\nw e r e\\ne \\x00 e c t i v e\\nf o r\\ns i m p l e\\nt a s k s\\na n d\\ns c e n a r i o s\\nw i t h\\nl i m i t e d\\nv a r i a b i l i t y ,\\nt h e y\\ns t r u g g l e d\\nt o\\ns c a l e\\na n d\\na d a p t\\nt o\\nm o r e\\nc o m p l e x\\na n d\\nd y n a m i c\\ns i t u a t i o n s .\\nT h e\\nr i g i d i t y\\no f\\nt h e s e\\ns y s t e m s\\nm a d e\\ni t\\nc h a l l e n g i n g\\nt o\\na c c o u n t\\nf o r\\nt h e\\nv a s t\\na r r a y\\no f\\np o s s i b i l i t i e s\\na n d\\nn u a n c e s\\nf o u n d\\ni n\\nr e a l - w o r l d\\np r o b l e m s .\\nA s\\nA I\\nr e s e a r c h\\np r o g r e s s e d ,\\nm a c h i n e\\nl e a r n i n g\\ne m e r g e d\\na s\\na\\nm o r e\\nﬂ e x i b l e\\na n d\\na d a p t i v e\\na p p r o a c h .\\nM a c h i n e\\nl e a r n i n g\\nm o d e l s\\nl e a r n\\np a t t e r n s\\nf r o m\\nt r a i n i n g\\nd a t a\\na n d\\na p p l y\\nt h o s e\\np a t t e r n s\\nt o\\nm a k e\\np r e d i c t i o n s\\no r\\nd e c i s i o n s .\\nT h i s\\nd a t a - d r i v e n\\na p p r o a c h\\ne n a b l e d\\nA I\\ns y s t e m s\\nt o\\nt a c k l e\\ni n c r e a s i n g l y\\nc o m p l e x\\nt a s k s\\na n d\\nb e t t e r\\ng e n e r a l i z e\\nt o\\nn e w\\ns i t u a t i o n s .\\nG e n e r a t i v e\\nA I\\nr e p r e s e n t s\\nt h e\\nn e x t\\nl e a p\\ni n\\nA I ' s\\ne v o l u t i o n ,\\nb u i l d i n g\\nu p o n\\nm a c h i n e\\nl e a r n i n g ' s\\nf o u n d a t i o n .\\nU n l i k e\\nt r a d i t i o n a l\\nm a c h i n e\\nl e a r n i n g\\nm o d e l s\\nt h a t\\nf o c u s\\no n\\nd i s c r i m i n a t i v e\\nt a s k s — d e t e r m i n i n g\\nt h e\\nm o s t\\nl i k e l y\\no u t p u t\\ng i v e n\\na n\\ni n p u t — g e n e r a t i v e\\nm o d e l s\\na i m\\nt o\\ng e n e r a t e\\nn e w\\nd a t a\\nb a s e d\\no n\\nt h e\\np a t t e r n s\\na n d\\nd i s t r i b u t i o n s\\no b s e r v e d\\ni n\\nt h e\\nt r a i n i n g\\nd a t a .\\nT h i s\\na b i l i t y\\nt o\\nc r e a t e\\nn o v e l\\nd a t a\\na l l o w s\\ng e n e r a t i v e\\nA I\\nt o\\ne x c e l\\ni n\\na\\nw i d e\\nr a n g e\\no f\\na p p l i c a t i o n s ,\\ni n c l u d i n g\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g ,\\ni m a g e\\ns y n t h e s i s ,\\na n d\\nm o r e .\\n3\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 3}), Document(page_content=\"S o m e\\no f\\nt h e\\nk e y\\ng e n e r a t i v e\\nA I\\nm o d e l s\\ni n c l u d e :\\n●\\nR e s t r i c t e d\\nB o l t z m a n n\\nM a c h i n e s\\n( R B M s )\\n●\\nV a r i a t i o n a l\\nA u t o e n c o d e r s\\n( V A E s )\\n●\\nG e n e r a t i v e\\nA d v e r s a r i a l\\nN e t w o r k s\\n( G A N s )\\n●\\nR e c u r r e n t\\nN e u r a l\\nN e t w o r k s\\n( R N N s )\\n●\\nL o n g\\nS h o r t - T e r m\\nM e m o r y\\n( L S T M s )\\n●\\nT r a n s f o r m e r s\\nT h e s e\\nm o d e l s\\nh a v e\\nb e e n\\nd e v e l o p e d\\na n d\\nr e ﬁ n e d\\no v e r\\nt h e\\ny e a r s ,\\nl e a d i n g\\nt o\\ni n c r e a s i n g l y\\np o w e r f u l\\na n d\\ns o p h i s t i c a t e d\\nA I\\ns y s t e m s .\\nB y\\nu n d e r s t a n d i n g\\nt h e\\ne v o l u t i o n\\no f\\nA I\\na n d\\nt h e\\nm e c h a n i c s\\no f\\ng e n e r a t i v e\\nm o d e l s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nb e t t e r\\nh a r n e s s\\nt h e s e\\nc u t t i n g - e d g e\\nt e c h n o l o g i e s\\nt o\\nc r e a t e\\ni n n o v a t i v e\\ns o l u t i o n s\\nf o r\\na\\nd i v e r s e\\nr a n g e\\no f\\nc h a l l e n g e s .\\n1 . 2 .\\nK e y\\nG e n e r a t i v e\\nA I\\nM o d e l s :\\nR N N s ,\\nL S T M s ,\\nG P T ,\\na n d\\nM o r e\\nA s\\ng e n e r a t i v e\\nA I\\nh a s\\ne v o l v e d ,\\ns e v e r a l\\nk e y\\nm o d e l s\\nh a v e\\ne m e r g e d ,\\ne a c h\\nw i t h\\ni t s\\no w n\\nu n i q u e\\nc a p a b i l i t i e s\\na n d\\ns t r e n g t h s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\ne x p l o r e\\ns o m e\\no f\\nt h e\\nm o s t\\np r o m i n e n t\\ng e n e r a t i v e\\nA I\\nm o d e l s ,\\ni n c l u d i n g\\nR N N s ,\\nL S T M s ,\\na n d\\nG P T .\\nR e s t r i c t e d\\nB o l t z m a n n\\nM a c h i n e s\\n( R B M s )\\nR B M s\\na r e\\na\\nt y p e\\no f\\nu n s u p e r v i s e d\\nl e a r n i n g\\nm o d e l\\nt h a t\\nc a n\\nl e a r n\\na\\np r o b a b i l i t y\\nd i s t r i b u t i o n\\no v e r\\ni n p u t\\nd a t a .\\nT h e y\\nc o n s i s t\\no f\\nt w o\\nl a y e r s ,\\na\\nv i s i b l e\\nl a y e r\\nt h a t\\nr e p r e s e n t s\\ni n p u t\\nd a t a\\na n d\\na\\nh i d d e n\\nl a y e r\\nt h a t\\nc a p t u r e s\\nl a t e n t\\nf e a t u r e s .\\nR B M s\\nh a v e\\nb e e n\\nu s e d\\nf o r\\nv a r i o u s\\ng e n e r a t i v e\\nt a s k s ,\\ns u c h\\na s\\ni m a g e\\ns y n t h e s i s\\na n d\\nf e a t u r e\\nl e a r n i n g .\\nV a r i a t i o n a l\\nA u t o e n c o d e r s\\n( V A E s )\\nV A E s\\na r e\\na\\nt y p e\\no f\\ng e n e r a t i v e\\nm o d e l\\nt h a t\\nc o m b i n e s\\na s p e c t s\\no f\\nd e e p\\nl e a r n i n g\\na n d\\nB a y e s i a n\\ni n f e r e n c e\\nt o\\nl e a r n\\nc o m p l e x\\nd a t a\\nd i s t r i b u t i o n s .\\nT h e y\\nc o n s i s t\\no f\\na n\\ne n c o d e r ,\\nw h i c h\\nm a p s\\ni n p u t\\nd a t a\\nt o\\na\\nl a t e n t\\ns p a c e ,\\na n d\\na\\nd e c o d e r ,\\nw h i c h\\nr e c o n s t r u c t s\\nd a t a\\nf r o m\\nt h e\\nl a t e n t\\ns p a c e .\\nV A E s\\nh a v e\\nb e e n\\nu s e d\\nf o r\\nv a r i o u s\\ng e n e r a t i v e\\nt a s k s ,\\ni n c l u d i n g\\ni m a g e\\ns y n t h e s i s ,\\nt e x t\\ng e n e r a t i o n ,\\na n d\\ns t y l e\\nt r a n s f e r .\\nG e n e r a t i v e\\nA d v e r s a r i a l\\nN e t w o r k s\\n( G A N s )\\nG A N s\\nc o n s i s t\\no f\\nt w o\\nn e u r a l\\nn e t w o r k s ,\\na\\ng e n e r a t o r\\na n d\\na\\nd i s c r i m i n a t o r ,\\nt h a t\\nc o m p e t e\\na g a i n s t\\ne a c h\\no t h e r\\ni n\\na\\nz e r o - s u m\\ng a m e .\\nT h e\\ng e n e r a t o r\\nc r e a t e s\\ns y n t h e t i c\\nd a t a ,\\nw h i l e\\nt h e\\nd i s c r i m i n a t o r\\n4\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 4}), Document(page_content=\"a t t e m p t s\\nt o\\nd i s t i n g u i s h\\nb e t w e e n\\nr e a l\\na n d\\ng e n e r a t e d\\nd a t a .\\nG A N s\\nh a v e\\ns h o w n\\nr e m a r k a b l e\\ns u c c e s s\\ni n\\ng e n e r a t i n g\\nh i g h - q u a l i t y\\ni m a g e s ,\\nm u s i c ,\\na n d\\ne v e n\\nt e x t .\\nR e c u r r e n t\\nN e u r a l\\nN e t w o r k s\\n( R N N s )\\nR N N s\\na r e\\na\\nc l a s s\\no f\\nn e u r a l\\nn e t w o r k s\\nd e s i g n e d\\nt o\\np r o c e s s\\ns e q u e n c e s\\no f\\nd a t a .\\nU n l i k e\\nf e e d f o r w a r d\\nn e t w o r k s ,\\nR N N s\\nh a v e\\na\\nf e e d b a c k\\nl o o p\\nt h a t\\na l l o w s\\nt h e m\\nt o\\nm a i n t a i n\\na n\\ni n t e r n a l\\ns t a t e ,\\nm a k i n g\\nt h e m\\nw e l l - s u i t e d\\nf o r\\nt a s k s\\ni n v o l v i n g\\nt i m e\\ns e r i e s\\no r\\ns e q u e n t i a l\\nd a t a .\\nR N N s\\nh a v e\\nb e e n\\nu s e d\\nf o r\\na\\nv a r i e t y\\no f\\ng e n e r a t i v e\\nt a s k s ,\\ns u c h\\na s\\nt e x t\\ng e n e r a t i o n ,\\ns p e e c h\\ns y n t h e s i s ,\\na n d\\nm u s i c\\nc o m p o s i t i o n .\\nL o n g\\nS h o r t - T e r m\\nM e m o r y\\n( L S T M s )\\nL S T M s\\na r e\\na\\nt y p e\\no f\\nR N N\\ns p e c i ﬁ c a l l y\\nd e s i g n e d\\nt o\\na d d r e s s\\nt h e\\nv a n i s h i n g\\ng r a d i e n t\\np r o b l e m ,\\nw h i c h\\nc a n\\no c c u r\\nw h e n\\nt r a i n i n g\\nR N N s\\no n\\nl o n g\\ns e q u e n c e s .\\nB y\\ni n c o r p o r a t i n g\\nm e m o r y\\nc e l l s\\na n d\\ng a t i n g\\nm e c h a n i s m s ,\\nL S T M s\\nc a n\\ne \\x00 e c t i v e l y\\nl e a r n\\nl o n g - r a n g e\\nd e p e n d e n c i e s\\ni n\\ns e q u e n t i a l\\nd a t a .\\nT h e y\\nh a v e\\nb e e n\\nw i d e l y\\nu s e d\\ni n\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g ,\\ns p e e c h\\nr e c o g n i t i o n ,\\na n d\\no t h e r\\ng e n e r a t i v e\\nt a s k s .\\nT r a n s f o r m e r s\\nT r a n s f o r m e r s\\na r e\\na\\nt y p e\\no f\\nn e u r a l\\nn e t w o r k\\na r c h i t e c t u r e\\nt h a t\\nu t i l i z e s\\ns e l f - a t t e n t i o n\\nm e c h a n i s m s\\nt o\\np r o c e s s\\ni n p u t\\nd a t a .\\nU n l i k e\\nR N N s\\na n d\\nL S T M s ,\\nt r a n s f o r m e r s\\nc a n\\np r o c e s s\\ns e q u e n c e s\\ni n\\np a r a l l e l ,\\nm a k i n g\\nt h e m\\nh i g h l y\\ne \\x00 c i e n t\\nf o r\\nl a r g e - s c a l e\\nt a s k s .\\nG P T\\n( G e n e r a t i v e\\nP r e - t r a i n e d\\nT r a n s f o r m e r )\\ni s\\na\\np o p u l a r\\nt r a n s f o r m e r - b a s e d\\nm o d e l\\nd e v e l o p e d\\nb y\\nO p e n A I ,\\nk n o w n\\nf o r\\ni t s\\ni m p r e s s i v e\\nc a p a b i l i t i e s\\ni n\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g\\na n d\\ng e n e r a t i o n .\\nT h e s e\\ng e n e r a t i v e\\nA I\\nm o d e l s\\no \\x00 e r\\nd a t a\\ns c i e n t i s t s\\na\\np o w e r f u l\\nt o o l b o x\\nf o r\\nt a c k l i n g\\na\\nw i d e\\nr a n g e\\no f\\na p p l i c a t i o n s\\na n d\\nc h a l l e n g e s .\\nB y\\nu n d e r s t a n d i n g\\nt h e\\ns t r e n g t h s\\na n d\\nl i m i t a t i o n s\\no f\\ne a c h\\nm o d e l ,\\ny o u\\nc a n\\nc h o o s e\\nt h e\\nm o s t\\ns u i t a b l e\\na p p r o a c h\\nf o r\\ny o u r\\ns p e c i ﬁ c\\nd a t a\\ns c i e n c e\\np r o j e c t\\na n d\\nh a r n e s s\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I .\\n1 . 3 .\\nP o p u l a r\\nU s e\\nC a s e s\\nf o r\\nG e n e r a t i v e\\nA I\\nG e n e r a t i v e\\nA I\\nh a s\\nd e m o n s t r a t e d\\ns i g n i ﬁ c a n t\\np o t e n t i a l\\ni n\\na\\nw i d e\\nr a n g e\\no f\\na p p l i c a t i o n s ,\\nt h a n k s\\nt o\\ni t s\\na b i l i t y\\nt o\\nc r e a t e\\nn o v e l\\nd a t a\\nb a s e d\\no n\\ne x i s t i n g\\np a t t e r n s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\ne x p l o r e\\ns o m e\\np o p u l a r\\nu s e\\nc a s e s\\nf o r\\ng e n e r a t i v e\\nA I ,\\ns h o w c a s i n g\\ni t s\\nv e r s a t i l i t y\\na n d\\ni m p a c t\\na c r o s s\\nv a r i o u s\\nd o m a i n s .\\n5\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 5}), Document(page_content='N a t u r a l\\nL a n g u a g e\\nP r o c e s s i n g\\n( N L P )\\nG e n e r a t i v e\\nA I\\nh a s\\nr e v o l u t i o n i z e d\\nN L P\\nb y\\ne n a b l i n g\\nt h e\\ng e n e r a t i o n\\no f\\nc o h e r e n t\\na n d\\nc o n t e x t u a l l y\\nr e l e v a n t\\nt e x t .\\nA p p l i c a t i o n s\\ni n c l u d e\\nc h a t b o t s ,\\ns u m m a r i z a t i o n ,\\nt r a n s l a t i o n ,\\nc o n t e n t\\ng e n e r a t i o n ,\\na n d\\nm o r e .\\nM o d e l s\\nl i k e\\nG P T\\nh a v e\\nd e m o n s t r a t e d\\ni m p r e s s i v e\\nc a p a b i l i t i e s\\ni n\\ng e n e r a t i n g\\nh u m a n - l i k e\\nt e x t ,\\nm a k i n g\\nt h e m\\ni n v a l u a b l e\\nf o r\\nN L P\\nt a s k s .\\nI m a g e\\nS y n t h e s i s\\na n d\\nE d i t i n g\\nG e n e r a t i v e\\nm o d e l s\\nl i k e\\nG A N s\\na n d\\nV A E s\\nh a v e\\nm a d e\\ns i g n i ﬁ c a n t\\ns t r i d e s\\ni n\\ni m a g e\\ns y n t h e s i s ,\\ne n a b l i n g\\nt h e\\nc r e a t i o n\\no f\\nr e a l i s t i c\\ni m a g e s\\nf r o m\\ns c r a t c h\\no r\\nb a s e d\\no n\\ns p e c i ﬁ c\\na t t r i b u t e s .\\nT h e s e\\nm o d e l s\\nc a n\\na l s o\\nb e\\nu s e d\\nf o r\\ni m a g e - t o - i m a g e\\nt r a n s l a t i o n ,\\ns t y l e\\nt r a n s f e r ,\\na n d\\ni n p a i n t i n g ,\\no \\x00 e r i n g\\nn u m e r o u s\\np o s s i b i l i t i e s\\nf o r\\na r t i s t s ,\\nd e s i g n e r s ,\\na n d\\nr e s e a r c h e r s .\\nM u s i c\\na n d\\nA u d i o\\nG e n e r a t i o n\\nG e n e r a t i v e\\nA I\\nh a s\\nb e e n\\nu s e d\\nt o\\nc r e a t e\\no r i g i n a l\\nm u s i c\\nc o m p o s i t i o n s ,\\ns o u n d\\ne \\x00 e c t s ,\\na n d\\ne v e n\\ns p e e c h\\ns y n t h e s i s .\\nR N N s ,\\nL S T M s ,\\na n d\\nt r a n s f o r m e r s\\nh a v e\\ns h o w n\\np r o m i s e\\ni n\\nc a p t u r i n g\\nt h e\\ns t r u c t u r e\\na n d\\np a t t e r n s\\no f\\nm u s i c ,\\na l l o w i n g\\nf o r\\nt h e\\ng e n e r a t i o n\\no f\\nn e w\\nm e l o d i e s ,\\nh a r m o n i e s ,\\na n d\\nr h y t h m s .\\nD r u g\\nD i s c o v e r y\\na n d\\nM a t e r i a l\\nS c i e n c e\\nG e n e r a t i v e\\nm o d e l s\\nc a n\\nb e\\ne m p l o y e d\\nt o\\ng e n e r a t e\\nn o v e l\\nm o l e c u l a r\\ns t r u c t u r e s\\na n d\\nm a t e r i a l s\\nw i t h\\nd e s i r e d\\np r o p e r t i e s ,\\na c c e l e r a t i n g\\nt h e\\nd r u g\\nd i s c o v e r y\\na n d\\nm a t e r i a l\\nd e s i g n\\np r o c e s s e s .\\nB y\\ne x p l o r i n g\\nt h e\\nv a s t\\ns p a c e\\no f\\nc h e m i c a l\\na n d\\nm a t e r i a l\\nc o m p o s i t i o n s ,\\ng e n e r a t i v e\\nA I\\nc a n\\nh e l p\\ni d e n t i f y\\np r o m i s i n g\\nc a n d i d a t e s\\nf o r\\nf u r t h e r\\ne x p e r i m e n t a t i o n\\na n d\\nt e s t i n g .\\nA n o m a l y\\nD e t e c t i o n\\na n d\\nP a t t e r n\\nR e c o g n i t i o n\\nG e n e r a t i v e\\nA I\\nc a n\\nb e\\nu s e d\\nt o\\nm o d e l\\nt h e\\nu n d e r l y i n g\\nd i s t r i b u t i o n\\no f\\nd a t a ,\\nm a k i n g\\ni t\\np o s s i b l e\\nt o\\ni d e n t i f y\\no u t l i e r s\\na n d\\na n o m a l i e s .\\nT h i s\\nc a p a b i l i t y\\nh a s\\nv a l u a b l e\\na p p l i c a t i o n s\\ni n\\nf r a u d\\nd e t e c t i o n ,\\nn e t w o r k\\ns e c u r i t y ,\\na n d\\nq u a l i t y\\nc o n t r o l ,\\na m o n g\\no t h e r s .\\nD a t a\\nA u g m e n t a t i o n\\nI n\\ns i t u a t i o n s\\nw h e r e\\nd a t a\\ni s\\ns c a r c e\\no r\\ni m b a l a n c e d ,\\ng e n e r a t i v e\\nm o d e l s\\nc a n\\nh e l p\\nc r e a t e\\na d d i t i o n a l\\nt r a i n i n g\\ns a m p l e s ,\\ne n h a n c i n g\\nt h e\\np e r f o r m a n c e\\no f\\nm a c h i n e\\nl e a r n i n g\\na l g o r i t h m s .\\nT h i s\\ni s\\np a r t i c u l a r l y\\nu s e f u l\\ni n\\nd o m a i n s\\nw h e r e\\nd a t a\\nc o l l e c t i o n\\ni s\\ne x p e n s i v e ,\\nt i m e - c o n s u m i n g ,\\no r\\ne t h i c a l l y\\nc h a l l e n g i n g .\\n6\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 6}), Document(page_content='S i m u l a t i o n\\na n d\\nS c e n a r i o\\nP l a n n i n g\\nG e n e r a t i v e\\nA I\\nc a n\\nc r e a t e\\ns y n t h e t i c\\nd a t a\\nt o\\ns i m u l a t e\\nv a r i o u s\\ns c e n a r i o s ,\\ne n a b l i n g\\nb u s i n e s s e s\\na n d\\nr e s e a r c h e r s\\nt o\\nt e s t\\nh y p o t h e s e s ,\\ne v a l u a t e\\ns t r a t e g i e s ,\\na n d\\nm a k e\\ni n f o r m e d\\nd e c i s i o n s .\\nT h i s\\nc a n\\nb e\\np a r t i c u l a r l y\\nu s e f u l\\ni n\\nﬁ e l d s\\nl i k e\\nﬁ n a n c e ,\\nl o g i s t i c s ,\\nu r b a n\\np l a n n i n g ,\\na n d\\ne n v i r o n m e n t a l\\ns t u d i e s .\\nT h e s e\\nu s e\\nc a s e s\\nr e p r e s e n t\\nj u s t\\na\\ng l i m p s e\\no f\\nt h e\\np o t e n t i a l\\na p p l i c a t i o n s\\nf o r\\ng e n e r a t i v e\\nA I .\\nA s\\nt h e\\nt e c h n o l o g y\\nc o n t i n u e s\\nt o\\na d v a n c e\\na n d\\nm a t u r e ,\\ni t\\ni s\\nl i k e l y\\nt h a t\\ne v e n\\nm o r e\\ni n n o v a t i v e\\na n d\\nt r a n s f o r m a t i v e\\na p p l i c a t i o n s\\nw i l l\\ne m e r g e ,\\nf u r t h e r\\ns o l i d i f y i n g\\nt h e\\ni m p o r t a n c e\\no f\\ng e n e r a t i v e\\nA I\\ni n\\nt h e\\nr e a l m\\no f\\nd a t a\\ns c i e n c e .\\n7\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 7}), Document(page_content=\"C h a p t e r\\n2 :\\nI n t r o d u c t i o n\\nt o\\nP r o m p t\\nE n g i n e e r i n g\\nT h e\\ni m p o r t a n c e\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni s\\nf u r t h e r\\nu n d e r s c o r e d\\nb y\\nt h e\\nr a p i d\\ng r o w t h\\na n d\\na d o p t i o n\\no f\\nt r a n s f o r m e r - b a s e d\\nm o d e l s\\nl i k e\\nG P T ,\\nw h i c h\\na r e\\nh e a v i l y\\nr e l i a n t\\no n\\np r o m p t s\\nt o\\ng e n e r a t e\\no u t p u t s .\\n2 . 1 .\\nW h a t\\nP r o m p t\\nE n g i n e e r i n g\\ni s\\na n d\\nW h y\\ni t\\nM a t t e r s\\nP r o m p t\\ne n g i n e e r i n g\\ni s\\nt h e\\np r o c e s s\\no f\\nc r a f t i n g\\ne \\x00 e c t i v e\\np r o m p t s\\nt o\\ng u i d e\\nA I\\nm o d e l s ,\\np a r t i c u l a r l y\\ng e n e r a t i v e\\nm o d e l s ,\\ni n\\ng e n e r a t i n g\\nt h e\\nd e s i r e d\\no u t p u t s .\\nA\\np r o m p t\\ni s\\na n\\ni n p u t\\ng i v e n\\nt o\\na n\\nA I\\nm o d e l\\nt h a t\\ns e t s\\nt h e\\nc o n t e x t ,\\ng o a l ,\\no r\\nc o n s t r a i n t s\\nf o r\\nt h e\\nm o d e l ' s\\nr e s p o n s e .\\nT h e\\nq u a l i t y\\no f\\na\\np r o m p t\\nc a n\\ns i g n i ﬁ c a n t l y\\ni n ﬂ u e n c e\\nt h e\\nq u a l i t y ,\\nr e l e v a n c e ,\\na n d\\na c c u r a c y\\no f\\nt h e\\nA I - g e n e r a t e d\\no u t p u t .\\nA s\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nb e c o m e\\nm o r e\\ns o p h i s t i c a t e d\\na n d\\nc o m p l e x ,\\nt h e\\nn e e d\\nf o r\\ne \\x00 c i e n t\\na n d\\np r e c i s e\\np r o m p t\\ne n g i n e e r i n g\\ng r o w s\\nm o r e\\nc r i t i c a l .\\nA\\nw e l l - c r a f t e d\\np r o m p t\\nc a n\\nh e l p\\nm a x i m i z e\\nt h e\\np o t e n t i a l\\no f\\nA I\\nm o d e l s\\nb y\\ne n s u r i n g\\nt h a t\\nt h e y\\np r o d u c e\\nt a r g e t e d ,\\nm e a n i n g f u l ,\\na n d\\nc o n t e x t u a l l y\\na p p r o p r i a t e\\nr e s p o n s e s .\\nI n\\nc o n t r a s t ,\\na n\\ni n e \\x00 e c t i v e\\np r o m p t\\nm a y\\nl e a d\\nt o\\na m b i g u o u s ,\\ni r r e l e v a n t ,\\no r\\ne v e n\\nn o n s e n s i c a l\\no u t p u t s .\\nP r o m p t\\ne n g i n e e r i n g\\np l a y s\\na\\nc r u c i a l\\nr o l e\\ni n\\nt h e\\ns u c c e s s\\no f\\nA I\\na p p l i c a t i o n s\\na c r o s s\\nv a r i o u s\\nd o m a i n s ,\\nf r o m\\nc o n t e n t\\ng e n e r a t i o n\\na n d\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g\\nt o\\nd a t a\\na n a l y s i s\\na n d\\nv i s u a l i z a t i o n .\\nB y\\nm a s t e r i n g\\nt h e\\na r t\\no f\\np r o m p t\\ne n g i n e e r i n g ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nb e t t e r\\nd i r e c t\\nA I\\nm o d e l s\\nt o\\na c h i e v e\\ns p e c i ﬁ c\\no b j e c t i v e s ,\\no p t i m i z e\\ns y s t e m\\np e r f o r m a n c e ,\\na n d\\ne n h a n c e\\nt h e\\no v e r a l l\\nu s e r\\ne x p e r i e n c e .\\nT h e\\ni m p o r t a n c e\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni s\\nf u r t h e r\\nu n d e r s c o r e d\\nb y\\nt h e\\nr a p i d\\ng r o w t h\\na n d\\na d o p t i o n\\no f\\nt r a n s f o r m e r - b a s e d\\nm o d e l s\\nl i k e\\nG P T ,\\nw h i c h\\na r e\\nh e a v i l y\\nr e l i a n t\\no n\\np r o m p t s\\nt o\\ng e n e r a t e\\no u t p u t s .\\nG i v e n\\nt h e\\nv a s t\\nc a p a b i l i t i e s\\na n d\\np o t e n t i a l\\na p p l i c a t i o n s\\no f\\nt h e s e\\nm o d e l s ,\\nd e v e l o p i n g\\na\\nd e e p\\nu n d e r s t a n d i n g\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni s\\ne s s e n t i a l\\nf o r\\nd a t a\\ns c i e n t i s t s\\nl o o k i n g\\nt o\\nh a r n e s s\\nt h e\\np o w e r\\no f\\ng e n e r a t i v e\\nA I\\ne \\x00 e c t i v e l y .\\n8\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 8}), Document(page_content='2 . 2 .\\nP r o m p t\\nT y p e s :\\nE x p l i c i t ,\\nI m p l i c i t ,\\na n d\\nC r e a t i v e\\nP r o m p t s\\nP r o m p t s\\nc a n\\nb e\\nc a t e g o r i z e d\\ni n t o\\nd i \\x00 e r e n t\\nt y p e s\\nb a s e d\\no n\\nt h e i r\\ns t r u c t u r e ,\\np u r p o s e ,\\na n d\\nt h e\\nl e v e l\\no f\\ng u i d a n c e\\nt h e y\\np r o v i d e\\nt o\\nt h e\\nA I\\nm o d e l .\\nU n d e r s t a n d i n g\\nt h e\\nv a r i o u s\\np r o m p t\\nt y p e s\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\nc r a f t\\ne \\x00 e c t i v e\\np r o m p t s\\nt h a t\\ny i e l d\\nt h e\\nd e s i r e d\\nr e s u l t s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e\\nw i l l\\nd i s c u s s\\nt h r e e\\nc o m m o n\\np r o m p t\\nt y p e s :\\ne x p l i c i t ,\\ni m p l i c i t ,\\na n d\\nc r e a t i v e\\np r o m p t s .\\nE x p l i c i t\\nP r o m p t s\\nE x p l i c i t\\np r o m p t s\\np r o v i d e\\nc l e a r\\na n d\\nd i r e c t\\ni n s t r u c t i o n s\\nt o\\nt h e\\nA I\\nm o d e l ,\\ns p e c i f y i n g\\nt h e\\ne x a c t\\nf o r m a t\\no r\\ni n f o r m a t i o n\\nr e q u i r e d\\ni n\\nt h e\\ng e n e r a t e d\\no u t p u t .\\nT h e s e\\np r o m p t s\\no f t e n\\ni n c l u d e\\nk e y w o r d s\\no r\\np h r a s e s\\nt h a t\\ng u i d e\\nt h e\\nm o d e l\\nt o w a r d s\\na\\ns p e c i ﬁ c\\nr e s p o n s e .\\nF o r\\ne x a m p l e ,\\na n\\ne x p l i c i t\\np r o m p t\\nf o r\\na\\nt r a n s l a t i o n\\nt a s k\\nm i g h t\\nb e ,\\n\" T r a n s l a t e\\nt h e\\nf o l l o w i n g\\nE n g l i s h\\nt e x t\\nt o\\nF r e n c h :\\n\\' T h e\\nw e a t h e r\\ni s\\nn i c e\\nt o d a y . \\' \"\\nE x p l i c i t\\np r o m p t s\\na r e\\ng e n e r a l l y\\ne a s i e r\\nf o r\\nA I\\nm o d e l s\\nt o\\ni n t e r p r e t\\na n d\\nc a n\\nl e a d\\nt o\\nm o r e\\na c c u r a t e\\na n d\\nr e l e v a n t\\nr e s u l t s .\\nH o w e v e r ,\\nt h e y\\nm a y\\ns o m e t i m e s\\nl i m i t\\nt h e\\nm o d e l \\' s\\na b i l i t y\\nt o\\ng e n e r a t e\\nc r e a t i v e\\no r\\nn u a n c e d\\no u t p u t s .\\nI m p l i c i t\\nP r o m p t s\\nI m p l i c i t\\np r o m p t s\\na r e\\nl e s s\\nd i r e c t\\ni n\\nt h e i r\\ni n s t r u c t i o n s ,\\na l l o w i n g\\nt h e\\nA I\\nm o d e l\\nm o r e\\nf r e e d o m\\nt o\\ni n t e r p r e t\\nt h e\\nd e s i r e d\\no u t c o m e .\\nT h e s e\\np r o m p t s\\nr e l y\\no n\\nt h e\\nm o d e l \\' s\\nu n d e r s t a n d i n g\\no f\\nc o n t e x t ,\\nr e l a t i o n s h i p s ,\\no r\\nc o n v e n t i o n s\\nt o\\ng e n e r a t e\\na n\\na p p r o p r i a t e\\nr e s p o n s e .\\nF o r\\ne x a m p l e ,\\na n\\ni m p l i c i t\\np r o m p t\\nf o r\\na\\nt r a n s l a t i o n\\nt a s k\\nm i g h t\\nb e ,\\n\" H o w\\nw o u l d\\ny o u\\ns a y\\n\\' T h e\\nw e a t h e r\\ni s\\nn i c e\\nt o d a y \\'\\ni n\\nF r e n c h ? \"\\nI m p l i c i t\\np r o m p t s\\nc a n\\ne n c o u r a g e\\nA I\\nm o d e l s\\nt o\\nt h i n k\\nm o r e\\nc r e a t i v e l y\\na n d\\ng e n e r a t e\\nm o r e\\nd i v e r s e\\no u t p u t s .\\nH o w e v e r ,\\nt h e y\\nm a y\\na l s o\\ni n c r e a s e\\nt h e\\nr i s k\\no f\\ng e n e r a t i n g\\na m b i g u o u s\\no r\\no \\x00 - t o p i c\\nr e s p o n s e s .\\nC r e a t i v e\\nP r o m p t s\\nC r e a t i v e\\np r o m p t s\\na r e\\nd e s i g n e d\\nt o\\ne n c o u r a g e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nn o v e l ,\\ni m a g i n a t i v e ,\\no r\\nu n c o n v e n t i o n a l\\no u t p u t s .\\nT h e s e\\np r o m p t s\\no f t e n\\ni n v o l v e\\no p e n - e n d e d\\nq u e s t i o n s ,\\ns c e n a r i o s ,\\no r\\nc h a l l e n g e s\\nt h a t\\nr e q u i r e\\nt h e\\nm o d e l\\nt o\\nt h i n k\\nb e y o n d\\ni t s\\nt r a i n i n g\\nd a t a\\na n d\\ne x p l o r e\\nn e w\\ni d e a s\\no r\\np e r s p e c t i v e s .\\nF o r\\ne x a m p l e ,\\na\\nc r e a t i v e\\np r o m p t\\nf o r\\na\\ns t o r y t e l l i n g\\nt a s k\\nm i g h t\\nb e ,\\n\" W r i t e\\na\\ns h o r t\\ns t o r y\\na b o u t\\na\\nw o r l d\\nw h e r e\\nt h e\\nw e a t h e r\\nc h a n g e s\\nb a s e d\\no n\\np e o p l e \\' s\\ne m o t i o n s . \"\\nC r e a t i v e\\np r o m p t s\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\nt a p\\ni n t o\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I ,\\ne n a b l i n g\\nt h e\\nc r e a t i o n\\no f\\nu n i q u e\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nH o w e v e r ,\\nt h e y\\nm a y\\na l s o\\nr e q u i r e\\nm o r e\\ni t e r a t i o n\\na n d\\nﬁ n e - t u n i n g\\nt o\\na c h i e v e\\nt h e\\nd e s i r e d\\nr e s u l t s .\\n9\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 9}), Document(page_content=\"B y\\nu n d e r s t a n d i n g\\nt h e\\nd i \\x00 e r e n t\\np r o m p t\\nt y p e s\\na n d\\nt h e i r\\nr e s p e c t i v e\\ns t r e n g t h s\\na n d\\nl i m i t a t i o n s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nc h o o s e\\nt h e\\nm o s t\\na p p r o p r i a t e\\na p p r o a c h\\nf o r\\nt h e i r\\ns p e c i ﬁ c\\nA I\\na p p l i c a t i o n .\\nA d d i t i o n a l l y ,\\nm a s t e r i n g\\nt h e\\na r t\\no f\\nc r a f t i n g\\nv a r i o u s\\np r o m p t\\nt y p e s\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\nh a r n e s s\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\na n d\\no p t i m i z e\\nt h e i r\\np e r f o r m a n c e\\na c r o s s\\na\\nd i v e r s e\\nr a n g e\\no f\\nt a s k s .\\n2 . 3 .\\nB e s t\\nP r a c t i c e s\\nf o r\\nC r a f t i n g\\nE \\x00 e c t i v e\\nP r o m p t s\\nC r e a t i n g\\ne \\x00 e c t i v e\\np r o m p t s\\ni s\\na n\\ne s s e n t i a l\\ns k i l l\\nf o r\\nd a t a\\ns c i e n t i s t s\\nw o r k i n g\\nw i t h\\ng e n e r a t i v e\\nA I\\nm o d e l s .\\nT h e\\nf o l l o w i n g\\nb e s t\\np r a c t i c e s\\nc a n\\nh e l p\\ny o u\\nc r a f t\\np r o m p t s\\nt h a t\\ny i e l d\\na c c u r a t e ,\\nr e l e v a n t ,\\na n d\\nm e a n i n g f u l\\no u t p u t s\\nw h i l e\\nm i n i m i z i n g\\nt h e\\nr i s k\\no f\\ng e n e r a t i n g\\na m b i g u o u s\\no r\\no \\x00 - t o p i c\\nr e s p o n s e s .\\nB e\\nc l e a r\\na n d\\nc o n c i s e\\nE n s u r e\\nt h a t\\ny o u r\\np r o m p t\\ni s\\ne a s y\\nt o\\nu n d e r s t a n d\\na n d\\np r o v i d e s\\nc l e a r\\ni n s t r u c t i o n s\\nf o r\\nt h e\\nA I\\nm o d e l .\\nA v o i d\\nu s i n g\\no v e r l y\\nc o m p l e x\\nl a n g u a g e\\no r\\nu n n e c e s s a r y\\nj a r g o n\\nt h a t\\nm a y\\nc o n f u s e\\nt h e\\nm o d e l .\\nK e e p i n g\\ny o u r\\np r o m p t\\nc o n c i s e\\nc a n\\na l s o\\nh e l p\\nt h e\\nm o d e l\\nf o c u s\\no n\\nt h e\\ne s s e n t i a l\\ni n f o r m a t i o n\\na n d\\ng e n e r a t e\\nm o r e\\na c c u r a t e\\nr e s u l t s .\\nP r o v i d e\\nc o n t e x t\\nI n c l u d i n g\\nc o n t e x t\\ni n\\ny o u r\\np r o m p t\\nc a n\\nh e l p\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nt o w a r d s\\na\\nm o r e\\nr e l e v a n t\\na n d\\na c c u r a t e\\no u t p u t .\\nF o r\\ne x a m p l e ,\\ni f\\ny o u ' r e\\na s k i n g\\nt h e\\nm o d e l\\nt o\\ng e n e r a t e\\na\\ns u m m a r y\\no f\\na n\\na r t i c l e ,\\np r o v i d i n g\\nt h e\\na r t i c l e ' s\\nt i t l e ,\\na u t h o r ,\\na n d\\np u b l i c a t i o n\\nd a t e\\nc a n\\nh e l p\\nt h e\\nm o d e l\\nu n d e r s t a n d\\nt h e\\nc o n t e x t\\na n d\\ng e n e r a t e\\na\\nm o r e\\na p p r o p r i a t e\\ns u m m a r y .\\nS p e c i f y\\nt h e\\nd e s i r e d\\nf o r m a t\\nI f\\ny o u\\nh a v e\\na\\ns p e c i ﬁ c\\nf o r m a t\\no r\\ns t r u c t u r e\\ni n\\nm i n d\\nf o r\\nt h e\\ng e n e r a t e d\\no u t p u t ,\\nb e\\ns u r e\\nt o\\ni n c l u d e\\nt h i s\\ni n f o r m a t i o n\\ni n\\ny o u r\\np r o m p t .\\nF o r\\ne x a m p l e ,\\ni f\\ny o u\\nw a n t\\nt h e\\nm o d e l\\nt o\\ng e n e r a t e\\na\\nb u l l e t e d\\nl i s t\\no r\\na\\nn u m b e r e d\\ns e q u e n c e ,\\ne x p l i c i t l y\\nm e n t i o n\\nt h i s\\ni n\\ny o u r\\np r o m p t\\nt o\\ng u i d e\\nt h e\\nm o d e l\\na c c o r d i n g l y .\\nE n c o u r a g e\\nm u l t i p l e\\na t t e m p t s\\nG e n e r a t i v e\\nA I\\nm o d e l s\\nc a n\\ns o m e t i m e s\\np r o d u c e\\nu n e x p e c t e d\\no r\\nu n d e s i r a b l e\\no u t p u t s .\\nI f\\nt h e\\ni n i t i a l\\no u t p u t\\nd o e s\\nn o t\\nm e e t\\ny o u r\\ne x p e c t a t i o n s ,\\nt r y\\nr e p h r a s i n g\\ny o u r\\np r o m p t\\no r\\na d j u s t i n g\\ni t s\\np a r a m e t e r s\\nt o\\ne n c o u r a g e\\nt h e\\nm o d e l\\nt o\\ng e n e r a t e\\na\\nd i \\x00 e r e n t\\nr e s p o n s e .\\nI t e r a t i n g\\no n\\ny o u r\\np r o m p t\\nc a n\\nh e l p\\ny o u\\nﬁ n e - t u n e\\ni t s\\ne \\x00 e c t i v e n e s s\\na n d\\na c h i e v e\\nt h e\\nd e s i r e d\\nr e s u l t s .\\n1 0\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 10}), Document(page_content=\"B a l a n c e\\ng u i d a n c e\\na n d\\nf r e e d o m\\nS t r i k i n g\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\np r o v i d i n g\\ng u i d a n c e\\na n d\\na l l o w i n g\\nt h e\\nA I\\nm o d e l\\nc r e a t i v e\\nf r e e d o m\\ni s\\nc r u c i a l\\nf o r\\nc r a f t i n g\\ne \\x00 e c t i v e\\np r o m p t s .\\nO v e r l y\\nr e s t r i c t i v e\\np r o m p t s\\nc a n\\nl i m i t\\nt h e\\nm o d e l ' s\\na b i l i t y\\nt o\\ng e n e r a t e\\nc r e a t i v e\\no r\\nn u a n c e d\\no u t p u t s ,\\nw h i l e\\no v e r l y\\no p e n - e n d e d\\np r o m p t s\\nm a y\\nl e a d\\nt o\\na m b i g u o u s\\no r\\no \\x00 - t o p i c\\nr e s u l t s .\\nE x p e r i m e n t\\nw i t h\\nd i \\x00 e r e n t\\nl e v e l s\\no f\\ng u i d a n c e\\nt o\\nﬁ n d\\nt h e\\ns w e e t\\ns p o t\\nt h a t\\nb e s t\\na l i g n s\\nw i t h\\ny o u r\\np r o j e c t ' s\\no b j e c t i v e s .\\nE v a l u a t e\\na n d\\ni t e r a t e\\nR e g u l a r l y\\ne v a l u a t e\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\ny o u r\\np r o m p t s\\nb y\\nr e v i e w i n g\\nt h e\\nA I - g e n e r a t e d\\no u t p u t s\\na n d\\nc o m p a r i n g\\nt h e m\\na g a i n s t\\ny o u r\\nd e s i r e d\\no u t c o m e s .\\nU s e\\nt h i s\\nf e e d b a c k\\nt o\\nr e ﬁ n e\\na n d\\ni m p r o v e\\ny o u r\\np r o m p t s ,\\ne n s u r i n g\\nt h a t\\nt h e y\\nc o n s i s t e n t l y\\ny i e l d\\nh i g h - q u a l i t y\\nr e s u l t s .\\nI t e r a t i v e\\np r o m p t\\ne n g i n e e r i n g\\ni s\\na n\\ne s s e n t i a l\\np a r t\\no f\\nt h e\\np r o c e s s ,\\na s\\ni t\\na l l o w s\\ny o u\\nt o\\nc o n t i n u o u s l y\\no p t i m i z e\\nt h e\\np e r f o r m a n c e\\no f\\ny o u r\\ng e n e r a t i v e\\nA I\\nm o d e l s .\\nB y\\nf o l l o w i n g\\nt h e s e\\nb e s t\\np r a c t i c e s ,\\ny o u\\nc a n\\nc r e a t e\\ne \\x00 e c t i v e\\np r o m p t s\\nt h a t\\ng u i d e\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nt o w a r d s\\ng e n e r a t i n g\\na c c u r a t e ,\\nr e l e v a n t ,\\na n d\\nm e a n i n g f u l\\no u t p u t s .\\nM a s t e r i n g\\nt h e\\na r t\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni s\\nc r u c i a l\\nf o r\\nd a t a\\ns c i e n t i s t s\\nl o o k i n g\\nt o\\nh a r n e s s\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\na n d\\no p t i m i z e\\ni t s\\np e r f o r m a n c e\\na c r o s s\\na\\nw i d e\\nr a n g e\\no f\\na p p l i c a t i o n s .\\n1 1\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 11}), Document(page_content='C h a p t e r\\n3 :\\nP r a c t i c a l\\nA p p l i c a t i o n s\\no f\\nP r o m p t\\nE n g i n e e r i n g\\nC u s t o m\\np r o m p t s\\nn o t\\no n l y\\nh e l p\\ng u i d e\\nA I\\nm o d e l s\\nt o w a r d s\\ng e n e r a t i n g\\nm o r e\\na c c u r a t e\\na n d\\nc o n t e x t u a l l y\\nr e l e v a n t\\no u t p u t s ,\\nb u t\\nt h e y\\na l s o\\nu n l o c k\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nt o\\nt a c k l e\\nc o m p l e x\\nl a n g u a g e - b a s e d\\nc h a l l e n g e s .\\n3 . 1 .\\nI m p r o v i n g\\nN L P\\nT a s k s\\nw i t h\\nC u s t o m\\nP r o m p t s\\nP r o m p t\\ne n g i n e e r i n g\\np l a y s\\na\\nc r i t i c a l\\nr o l e\\ni n\\ne n h a n c i n g\\nt h e\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s ,\\np a r t i c u l a r l y\\ni n\\nt h e\\nr e a l m\\no f\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g\\n( N L P ) .\\nC u s t o m\\np r o m p t s\\nc a n\\nh e l p\\ng u i d e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nm o r e\\na c c u r a t e ,\\nc o n t e x t u a l l y\\nr e l e v a n t ,\\na n d\\ne n g a g i n g\\no u t p u t s\\na c r o s s\\na\\nv a r i e t y\\no f\\nN L P\\nt a s k s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e \\' l l\\ne x p l o r e\\ns o m e\\nc o m m o n\\nN L P\\nt a s k s\\nw h e r e\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nm a k e\\na\\ns i g n i ﬁ c a n t\\ni m p a c t .\\nT e x t\\nS u m m a r i z a t i o n\\nC r a f t i n g\\na n\\ne \\x00 e c t i v e\\np r o m p t\\nf o r\\nt e x t\\ns u m m a r i z a t i o n\\ni n v o l v e s\\ns p e c i f y i n g\\nt h e\\nd e s i r e d\\nl e n g t h ,\\nf o r m a t ,\\na n d\\nk e y\\np o i n t s\\nt h a t\\nt h e\\ns u m m a r y\\ns h o u l d\\nc o v e r .\\nB y\\np r o v i d i n g\\nc l e a r\\ni n s t r u c t i o n s\\na n d\\nc o n t e x t ,\\ny o u\\nc a n\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nt o\\ng e n e r a t e\\nc o n c i s e\\na n d\\ni n f o r m a t i v e\\ns u m m a r i e s\\nt h a t\\na c c u r a t e l y\\nc a p t u r e\\nt h e\\ne s s e n c e\\no f\\nt h e\\ns o u r c e\\nt e x t .\\nE x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\nt e x t\\ns u m m a r i z a t i o n\\ni n c l u d e :\\n●\\n\" W r i t e\\na\\nc o n c i s e\\ns u m m a r y\\no f\\nt h i s\\nn e w s\\na r t i c l e\\na b o u t\\nt h e\\nl a t e s t\\na d v a n c e m e n t s\\ni n\\na r t i ﬁ c i a l\\ni n t e l l i g e n c e ,\\nf o c u s i n g\\no n\\nt h e\\nm a i n\\nb r e a k t h r o u g h s\\na n d\\nt h e i r\\np o t e n t i a l\\ni m p a c t\\no n\\nv a r i o u s\\ni n d u s t r i e s . \"\\n●\\n\" S u m m a r i z e\\nt h i s\\nr e s e a r c h\\np a p e r\\no n\\nt h e\\ne \\x00 e c t s\\no f\\nc l i m a t e\\nc h a n g e\\no n\\nb i o d i v e r s i t y ,\\nh i g h l i g h t i n g\\nt h e\\nk e y\\nﬁ n d i n g s\\na n d\\nt h e\\ni m p l i c a t i o n s\\nf o r\\nc o n s e r v a t i o n\\ne \\x00 o r t s . \"\\n●\\n\" P r o v i d e\\na\\nb r i e f\\ns u m m a r y\\no f\\nt h i s\\nb o o k\\nc h a p t e r\\no n\\nt h e\\nh i s t o r y\\no f\\nt h e\\ni n t e r n e t ,\\nc o v e r i n g\\nt h e\\nm a j o r\\nd e v e l o p m e n t s\\na n d\\nt h e i r\\ns i g n i ﬁ c a n c e\\nf o r\\nt h e\\nw a y\\nw e\\nc o m m u n i c a t e\\na n d\\na c c e s s\\ni n f o r m a t i o n\\nt o d a y . \"\\n1 2\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 12}), Document(page_content='S e n t i m e n t\\nA n a l y s i s\\nF o r\\ns e n t i m e n t\\na n a l y s i s ,\\np r o m p t s\\ns h o u l d\\nb e\\nd e s i g n e d\\nt o\\ne n c o u r a g e\\nt h e\\nA I\\nm o d e l\\nt o\\nf o c u s\\no n\\nt h e\\nr e l e v a n t\\na s p e c t s\\no f\\nt h e\\nt e x t\\na n d\\ne v a l u a t e\\nt h e\\nu n d e r l y i n g\\ns e n t i m e n t .\\nA\\nw e l l - c r a f t e d\\np r o m p t\\nc a n\\nh e l p\\nt h e\\nm o d e l\\ni d e n t i f y\\np o s i t i v e ,\\nn e g a t i v e ,\\no r\\nn e u t r a l\\ns e n t i m e n t s\\nm o r e\\na c c u r a t e l y ,\\ni m p r o v i n g\\nt h e\\no v e r a l l\\np e r f o r m a n c e\\no f\\ns e n t i m e n t\\na n a l y s i s\\nt a s k s .\\nE x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\ns e n t i m e n t\\na n a l y s i s\\ni n c l u d e :\\n●\\n\" W h a t\\ne m o t i o n s\\nd o\\nc u s t o m e r s\\ne x p r e s s\\ni n\\nt h e i r\\no n l i n e\\nr e v i e w s\\no f\\no u r\\nn e w\\np r o d u c t ? \"\\nT h i s\\np r o m p t\\na s k s\\nf o r\\ns e n t i m e n t\\na n a l y s i s\\no n\\nc u s t o m e r\\nr e v i e w s\\no f\\na\\ns p e c i ﬁ c\\np r o d u c t .\\nI t\\ni s\\nw e l l - c r a f t e d\\nb e c a u s e\\ni t\\ni s\\ns p e c i ﬁ c\\na n d\\np r o v i d e s\\na\\nc l e a r\\nc o n t e x t\\nf o r\\nt h e\\ns e n t i m e n t\\na n a l y s i s\\nt a s k .\\n●\\n\" H o w\\nd o\\nT w i t t e r\\nu s e r s\\nf e e l\\na b o u t\\nt h e\\nl a t e s t\\np o l i t i c a l\\nc o n t r o v e r s y ? \"\\nT h i s\\np r o m p t\\na s k s\\nf o r\\ns e n t i m e n t\\na n a l y s i s\\no n\\na\\ns p e c i ﬁ c\\nt o p i c\\nb e i n g\\nd i s c u s s e d\\no n\\nT w i t t e r .\\nI t\\ni s\\nw e l l - c r a f t e d\\nb e c a u s e\\ni t\\ni s\\ns p e c i ﬁ c\\na n d\\np r o v i d e s\\na\\nc l e a r\\nc o n t e x t\\nf o r\\nt h e\\ns e n t i m e n t\\na n a l y s i s\\nt a s k .\\n●\\n\" W h a t\\ni s\\nt h e\\no v e r a l l\\ns e n t i m e n t\\no f\\nm o v i e\\nr e v i e w s\\nf o r\\nt h e\\nl a t e s t\\nb l o c k b u s t e r\\nﬁ l m ? \"\\nT h i s\\np r o m p t\\na s k s\\nf o r\\ns e n t i m e n t\\na n a l y s i s\\no n\\na\\nc o l l e c t i o n\\no f\\nm o v i e\\nr e v i e w s\\nf o r\\na\\ns p e c i ﬁ c\\nﬁ l m .\\nI t\\ni s\\nw e l l - c r a f t e d\\nb e c a u s e\\ni t\\ni s\\ns p e c i ﬁ c\\na n d\\np r o v i d e s\\na\\nc l e a r\\nc o n t e x t\\nf o r\\nt h e\\ns e n t i m e n t\\na n a l y s i s\\nt a s k .\\nT e x t\\nG e n e r a t i o n\\nW h e t h e r\\ny o u \\' r e\\ng e n e r a t i n g\\nc r e a t i v e\\nc o n t e n t ,\\nn e w s\\na r t i c l e s ,\\no r\\np r o d u c t\\nd e s c r i p t i o n s ,\\nc r a f t i n g\\na n\\ne \\x00 e c t i v e\\np r o m p t\\ni s\\nc r u c i a l\\nf o r\\ng u i d i n g\\nt h e\\nA I\\nm o d e l\\nt o w a r d s\\ng e n e r a t i n g\\nc o n t e x t u a l l y\\nr e l e v a n t\\na n d\\ne n g a g i n g\\nt e x t .\\nI n c l u d i n g\\ns p e c i ﬁ c\\nd e t a i l s ,\\nt h e m e s ,\\no r\\nk e y w o r d s\\ni n\\ny o u r\\np r o m p t\\nc a n\\nh e l p\\nt h e\\nm o d e l\\ng e n e r a t e\\nm o r e\\nt a r g e t e d\\na n d\\nc o h e r e n t\\no u t p u t s .\\nE x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\nt e x t\\ng e n e r a t i o n\\ni n c l u d e :\\n●\\n\" W r i t e\\na\\ns h o r t\\ns t o r y\\na b o u t\\na\\np e r s o n\\nw h o\\nd i s c o v e r s\\na\\nm y s t e r i o u s\\no b j e c t\\ni n\\nt h e i r\\nb a c k y a r d\\na n d\\ni s\\nt r a n s p o r t e d\\nt o\\na\\nd i \\x00 e r e n t\\nd i m e n s i o n . \"\\n●\\n\" I m a g i n e\\na\\nf u t u r e\\nw o r l d\\nw h e r e\\nt e c h n o l o g y\\nh a s\\na d v a n c e d\\nt o\\nt h e\\np o i n t\\nw h e r e\\nh u m a n s\\nc a n\\ni m p l a n t\\nm e m o r i e s\\ni n\\nt h e i r\\nb r a i n s .\\nW r i t e\\na\\nn e w s\\na r t i c l e\\nd e s c r i b i n g\\nt h e\\nc o n t r o v e r s y\\ns u r r o u n d i n g\\nt h i s\\nn e w\\nt e c h n o l o g y . \"\\n●\\n\" W r i t e\\na\\np o e m\\na b o u t\\nt h e\\nc h a n g i n g\\no f\\nt h e\\ns e a s o n s ,\\ne x p l o r i n g\\nt h e\\nd i \\x00 e r e n t\\ne m o t i o n s\\na n d\\ns e n s a t i o n s\\nt h a t\\nc o m e\\nw i t h\\ne a c h\\ns e a s o n . \"\\n1 3\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 13}), Document(page_content='Q u e s t i o n - A n s w e r i n g\\nI n\\nq u e s t i o n - a n s w e r i n g\\nt a s k s ,\\np r o m p t s\\ns h o u l d\\nb e\\nd e s i g n e d\\nt o\\nc o n v e y\\nt h e\\ne x a c t\\ni n f o r m a t i o n\\nr e q u i r e d\\ni n\\nt h e\\na n s w e r .\\nP r o v i d i n g\\nc o n t e x t ,\\ns u c h\\na s\\nt h e\\ns o u r c e\\nt e x t\\no r\\nr e l e v a n t\\nb a c k g r o u n d\\ni n f o r m a t i o n ,\\nc a n\\nh e l p\\nt h e\\nA I\\nm o d e l\\ng e n e r a t e\\nm o r e\\na c c u r a t e\\na n d\\nc o m p r e h e n s i v e\\na n s w e r s\\nt o\\nu s e r\\nq u e s t i o n s .\\nE x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\nq u e s t i o n - a n s w e r i n g\\ni n c l u d e :\\n●\\n\" W h a t\\nw a s\\nt h e\\nm a i n\\nc a u s e\\no f\\nW o r l d\\nW a r\\nI I\\na n d\\nh o w\\nd i d\\ni t\\na \\x00 e c t\\nt h e\\ng l o b a l\\np o l i t i c a l\\nl a n d s c a p e ? \"\\n●\\n\" C a n\\ny o u\\ne x p l a i n\\nt h e\\nc o n c e p t\\no f\\nq u a n t u m\\ne n t a n g l e m e n t\\na n d\\nh o w\\ni t\\nr e l a t e s\\nt o\\nt h e\\nt h e o r y\\no f\\nr e l a t i v i t y ? \"\\n●\\n\" W h a t\\na r e\\ns o m e\\no f\\nt h e\\nm o s t\\ne \\x00 e c t i v e\\nm e t h o d s\\nf o r\\nr e d u c i n g\\nc a r b o n\\ne m i s s i o n s\\na n d\\nm i t i g a t i n g\\nc l i m a t e\\nc h a n g e ,\\na n d\\nh o w\\nh a v e\\nt h e s e\\ns t r a t e g i e s\\nb e e n\\ni m p l e m e n t e d\\ni n\\nd i \\x00 e r e n t\\np a r t s\\no f\\nt h e\\nw o r l d ? \"\\nT e x t\\nC l a s s i f i c a t i o n\\nF o r\\nt e x t\\nc l a s s i ﬁ c a t i o n\\nt a s k s ,\\np r o m p t s\\ns h o u l d\\nb e\\nc r a f t e d\\nt o\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nt o w a r d s\\ni d e n t i f y i n g\\nt h e\\nr e l e v a n t\\nc a t e g o r y\\no r\\nl a b e l\\nf o r\\na\\ng i v e n\\nt e x t .\\nI n c l u d i n g\\ne x a m p l e s\\no f\\nt e x t s\\nb e l o n g i n g\\nt o\\nd i \\x00 e r e n t\\nc a t e g o r i e s\\no r\\np r o v i d i n g\\ne x p l i c i t\\ni n s t r u c t i o n s\\nc a n\\nh e l p\\nt h e\\nA I\\nm o d e l\\nb e t t e r\\nu n d e r s t a n d\\nt h e\\nc l a s s i ﬁ c a t i o n\\nc r i t e r i a\\na n d\\ni m p r o v e\\ni t s\\np e r f o r m a n c e .\\nE x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\nt e x t\\nc l a s s i ﬁ c a t i o n\\ni n c l u d e :\\n●\\nT o p i c\\nC l a s s i ﬁ c a t i o n :\\n\" G i v e n\\na\\ns e t\\no f\\nn e w s\\na r t i c l e s ,\\nc l a s s i f y\\ne a c h\\na r t i c l e\\ni n t o\\no n e\\no f\\ns e v e r a l\\nc a t e g o r i e s\\ns u c h\\na s\\nP o l i t i c s ,\\nS p o r t s ,\\nB u s i n e s s ,\\no r\\nE n t e r t a i n m e n t . \"\\n●\\nI n t e n t\\nC l a s s i ﬁ c a t i o n :\\n\" G i v e n\\na\\ns e t\\no f\\nc u s t o m e r\\nq u e r i e s ,\\nc l a s s i f y\\ne a c h\\nq u e r y\\ni n t o\\no n e\\no f\\ns e v e r a l\\nc a t e g o r i e s\\ns u c h\\na s\\nS a l e s ,\\nS u p p o r t ,\\nT e c h n i c a l\\nI s s u e s ,\\no r\\nF e e d b a c k . \"\\n●\\nS p a m\\nD e t e c t i o n :\\n\" G i v e n\\na\\ns e t\\no f\\ne m a i l\\nm e s s a g e s ,\\nc l a s s i f y\\ne a c h\\nm e s s a g e\\na s\\ns p a m\\no r\\nn o t\\ns p a m . \"\\nM a c h i n e\\nT r a n s l a t i o n\\nI n\\nm a c h i n e\\nt r a n s l a t i o n\\nt a s k s ,\\np r o m p t s\\ns h o u l d\\nb e\\nd e s i g n e d\\nt o\\nc o n v e y\\nt h e\\nd e s i r e d\\nl a n g u a g e\\na n d\\nc o n t e x t\\nf o r\\nt h e\\nt r a n s l a t i o n .\\nP r o v i d i n g\\nc l e a r\\ni n s t r u c t i o n s\\na n d\\ns p e c i f y i n g\\na n y\\ns p e c i ﬁ c\\nf o r m a t t i n g\\no r\\ns t y l e\\nr e q u i r e m e n t s\\nc a n\\nh e l p\\nt h e\\nA I\\nm o d e l\\ng e n e r a t e\\nm o r e\\na c c u r a t e\\na n d\\nﬂ u e n t\\nt r a n s l a t i o n s .\\n1 4\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 14}), Document(page_content='E x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\nm a c h i n e\\nt r a n s l a t i o n\\ni n c l u d e :\\n●\\nT r a n s l a t e\\nt h e\\nf o l l o w i n g\\ns e n t e n c e\\nf r o m\\nE n g l i s h\\nt o\\nF r e n c h :\\n\" T h e\\nq u i c k\\nb r o w n\\nf o x\\nj u m p s\\no v e r\\nt h e\\nl a z y\\nd o g . \"\\n●\\nC o n v e r t\\nt h e\\nf o l l o w i n g\\nd o c u m e n t\\nf r o m\\nS p a n i s h\\nt o\\nE n g l i s h :\\n\" E l\\nc a m b i o\\nc l i m á t i c o\\ne s\\nu n o\\nd e\\nl o s\\nm a y o r e s\\nd e s a f í o s\\nq u e\\ne n f r e n t a\\nl a\\nh u m a n i d a d\\ne n\\nl a\\na c t u a l i d a d . \"\\n●\\nT r a n s l a t e\\nt h e\\nf o l l o w i n g\\nC h i n e s e\\nt e x t\\nt o\\nS p a n i s h :\\n\"\\n这\\n个\\n城\\n市\\n有\\n许\\n多\\n历\\n史\\n遗\\n迹\\n和\\n文\\n化\\n景\\n点\\n，\\n游\\n客\\n可\\n以\\n感\\n受\\n到\\n浓\\n厚\\n的\\n文\\n化\\n氛\\n围\\n和\\n古\\n老\\n的\\n历\\n史\\n传\\n统。\\n\"\\nB y\\nm a s t e r i n g\\nt h e\\na r t\\no f\\np r o m p t\\ne n g i n e e r i n g ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\ni m p r o v e\\nt h e\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\na c r o s s\\na\\nw i d e\\nr a n g e\\no f\\nN L P\\nt a s k s .\\nC u s t o m\\np r o m p t s\\nn o t\\no n l y\\nh e l p\\ng u i d e\\nA I\\nm o d e l s\\nt o w a r d s\\ng e n e r a t i n g\\nm o r e\\na c c u r a t e\\na n d\\nc o n t e x t u a l l y\\nr e l e v a n t\\no u t p u t s ,\\nb u t\\nt h e y\\na l s o\\nu n l o c k\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nt o\\nt a c k l e\\nc o m p l e x\\nl a n g u a g e - b a s e d\\nc h a l l e n g e s .\\n3 . 2 .\\nE n h a n c i n g\\nC r e a t i v i t y\\na n d\\nD i v e r s i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\nO n e\\no f\\nt h e\\nk e y\\na d v a n t a g e s\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\ni s\\nt h e i r\\na b i l i t y\\nt o\\nc r e a t e\\nn o v e l\\na n d\\nd i v e r s e\\nc o n t e n t ,\\nw h e t h e r\\ni t \\' s\\nt e x t ,\\ni m a g e s ,\\no r\\na u d i o .\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\np l a y\\na\\nc r u c i a l\\nr o l e\\ni n\\ne n c o u r a g i n g\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nm o r e\\nc r e a t i v e\\na n d\\nd i v e r s e\\no u t p u t s ,\\ne n h a n c i n g\\nt h e\\no v e r a l l\\nq u a l i t y\\na n d\\na p p e a l\\no f\\nt h e\\ng e n e r a t e d\\nc o n t e n t .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e \\' l l\\nd i s c u s s\\nh o w\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\nu s e d\\nt o\\nb o o s t\\nc r e a t i v i t y\\na n d\\nd i v e r s i t y\\ni n\\nA I - g e n e r a t e d\\nc o n t e n t .\\nO p e n - e n d e d\\nP r o m p t s\\nU s i n g\\no p e n - e n d e d\\np r o m p t s\\nt h a t\\ne n c o u r a g e\\ne x p l o r a t i o n\\na n d\\ni m a g i n a t i o n\\nc a n\\nh e l p\\nA I\\nm o d e l s\\ng e n e r a t e\\nm o r e\\nc r e a t i v e\\nc o n t e n t .\\nF o r\\ne x a m p l e ,\\na s k i n g\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\ns t o r y\\ns e t\\ni n\\na\\nw o r l d\\nw h e r e\\nt i m e\\nﬂ o w s\\nb a c k w a r d \"\\nc a n\\ni n s p i r e\\nt h e\\nm o d e l\\nt o\\nc o m e\\nu p\\nw i t h\\nu n i q u e\\ni d e a s\\na n d\\ns c e n a r i o s\\nt h a t\\ng o\\nb e y o n d\\ni t s\\nt r a i n i n g\\nd a t a .\\nC o n s t r a i n t s\\na n d\\nC h a l l e n g e s\\nI n t r o d u c i n g\\nc o n s t r a i n t s\\no r\\nc h a l l e n g e s\\ni n\\ny o u r\\np r o m p t s\\nc a n\\np u s h\\nA I\\nm o d e l s\\nt o\\nt h i n k\\nm o r e\\nc r e a t i v e l y\\na n d\\nﬁ n d\\ni n n o v a t i v e\\ns o l u t i o n s .\\nF o r\\ne x a m p l e ,\\na s k i n g\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\ns t o r y\\nw i t h o u t\\nu s i n g\\nt h e\\nl e t t e r\\n\\' e \\' \"\\nc a n\\nf o r c e\\nt h e\\nm o d e l\\nt o\\nu s e\\nu n u s u a l\\nw o r d s\\na n d\\np h r a s i n g ,\\nr e s u l t i n g\\ni n\\nm o r e\\ni n v e n t i v e\\nc o n t e n t .\\n1 5\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 15}), Document(page_content='C o m b i n i n g\\nI d e a s\\na n d\\nT h e m e s\\nC r a f t i n g\\np r o m p t s\\nt h a t\\nc o m b i n e\\nm u l t i p l e\\ni d e a s\\no r\\nt h e m e s\\nc a n\\ne n c o u r a g e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nm o r e\\nd i v e r s e\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nF o r\\ne x a m p l e ,\\na s k i n g\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\ns t o r y\\nt h a t\\nc o m b i n e s\\ne l e m e n t s\\no f\\ns c i e n c e\\nﬁ c t i o n\\na n d\\nr o m a n c e \"\\nc a n\\nl e a d\\nt o\\nt h e\\nc r e a t i o n\\no f\\nu n i q u e\\na n d\\nu n e x p e c t e d\\nn a r r a t i v e s .\\nE n c o u r a g i n g\\nV a r i a b i l i t y\\nP r o m p t i n g\\nt h e\\nA I\\nm o d e l\\nt o\\ng e n e r a t e\\nm u l t i p l e\\nv e r s i o n s\\no f\\nt h e\\ns a m e\\nc o n t e n t\\nc a n\\nh e l p\\ni n c r e a s e\\nd i v e r s i t y\\na n d\\np r o v i d e\\na\\nb r o a d e r\\nr a n g e\\no f\\no p t i o n s\\nt o\\nc h o o s e\\nf r o m .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\na s k\\nt h e\\nm o d e l\\nt o\\n\" G e n e r a t e\\nt h r e e\\nd i \\x00 e r e n t\\ne n d i n g s\\nf o r\\nt h e\\nf o l l o w i n g\\ns t o r y \"\\nt o\\ne x p l o r e\\nv a r i o u s\\nn a r r a t i v e\\np o s s i b i l i t i e s .\\nM i x i n g\\nS t y l e s\\na n d\\nF o r m a t s\\nE x p e r i m e n t i n g\\nw i t h\\nd i \\x00 e r e n t\\ns t y l e s ,\\nf o r m a t s ,\\no r\\ng e n r e s\\ni n\\ny o u r\\np r o m p t s\\nc a n\\nl e a d\\nt o\\nm o r e\\nc r e a t i v e\\na n d\\nd i v e r s e\\no u t p u t s .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\np o e m\\ni n\\nt h e\\ns t y l e\\no f\\na\\nn e w s\\nr e p o r t \"\\no r\\n\" R e i m a g i n e\\na\\nc l a s s i c\\nf a i r y\\nt a l e\\na s\\na\\nm o d e r n - d a y\\nt h r i l l e r . \"\\nI t e r a t i v e\\nP r o m p t i n g\\nP r o m p t i n g\\nt h e\\nA I\\nm o d e l\\nt o\\nb u i l d\\nu p o n\\no r\\nr e ﬁ n e\\ni t s\\np r e v i o u s\\no u t p u t s\\nc a n\\nl e a d\\nt o\\nm o r e\\nn u a n c e d\\na n d\\ns o p h i s t i c a t e d\\nc o n t e n t .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\nu s e\\nt h e\\nm o d e l \\' s\\ni n i t i a l\\no u t p u t\\na s\\na\\ns t a r t i n g\\np o i n t\\na n d\\np r o m p t\\ni t\\nt o\\n\" E x p a n d\\no n\\nt h e\\ns t o r y\\nb y\\na d d i n g\\nm o r e\\nd e t a i l s\\na n d\\nd e p t h\\nt o\\nt h e\\nc h a r a c t e r s\\na n d\\np l o t . \"\\nB y\\ne m p l o y i n g\\nt h e s e\\ns t r a t e g i e s\\ni n\\np r o m p t\\ne n g i n e e r i n g ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nh a r n e s s\\nt h e\\nf u l l\\nc r e a t i v e\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\na n d\\ng e n e r a t e\\nm o r e\\nd i v e r s e\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nT h i s\\nn o t\\no n l y\\ne n h a n c e s\\nt h e\\no v e r a l l\\nq u a l i t y\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\nb u t\\na l s o\\ne x p a n d s\\nt h e\\nr a n g e\\no f\\na p p l i c a t i o n s\\na n d\\np o s s i b i l i t i e s\\nf o r\\ng e n e r a t i v e\\nA I\\ni n\\nv a r i o u s\\nd o m a i n s ,\\nf r o m\\ne n t e r t a i n m e n t\\na n d\\nm a r k e t i n g\\nt o\\ne d u c a t i o n\\na n d\\nr e s e a r c h .\\n3 . 3 .\\nA d d r e s s i n g\\nA I\\nE t h i c s\\na n d\\nB i a s\\nt h r o u g h\\nT h o u g h t f u l\\nP r o m p t\\nE n g i n e e r i n g\\nG e n e r a t i v e\\nA I\\nm o d e l s\\nh a v e\\nt h e\\np o t e n t i a l\\nt o\\np e r p e t u a t e\\nb i a s e s\\np r e s e n t\\ni n\\nt h e i r\\nt r a i n i n g\\nd a t a ,\\nw h i c h\\nc a n\\nl e a d\\nt o\\ne t h i c a l\\nc o n c e r n s\\na n d\\nu n i n t e n d e d\\nc o n s e q u e n c e s .\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\np l a y\\na\\nc r i t i c a l\\nr o l e\\ni n\\na d d r e s s i n g\\nt h e s e\\ni s s u e s\\nb y\\ng u i d i n g\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nm o r e\\nb a l a n c e d ,\\nf a i r ,\\na n d\\nr e s p o n s i b l e\\no u t p u t s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e \\' l l\\nd i s c u s s\\nh o w\\nt h o u g h t f u l\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nh e l p\\na d d r e s s\\nA I\\ne t h i c s\\na n d\\nb i a s\\nc o n c e r n s .\\n1 6\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 16}), Document(page_content='E n c o u r a g i n g\\nF a i r n e s s\\na n d\\nI n c l u s i v i t y\\nC r a f t i n g\\np r o m p t s\\nt h a t\\ne m p h a s i z e\\nf a i r n e s s\\na n d\\ni n c l u s i v i t y\\nc a n\\nh e l p\\ng u i d e\\nA I\\nm o d e l s\\nt o w a r d s\\ng e n e r a t i n g\\nm o r e\\nb a l a n c e d\\na n d\\nr e p r e s e n t a t i v e\\nc o n t e n t .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\na s k\\nt h e\\nm o d e l\\nt o\\n\" G e n e r a t e\\na\\ns t o r y\\nt h a t\\nf e a t u r e s\\na\\nd i v e r s e\\nc a s t\\no f\\nc h a r a c t e r s ,\\ne a c h\\nw i t h\\nu n i q u e\\nb a c k g r o u n d s\\na n d\\np e r s p e c t i v e s . \"\\nA v o i d i n g\\nS t e r e o t y p e s\\na n d\\nD i s c r i m i n a t i o n\\nT o\\np r e v e n t\\nA I\\nm o d e l s\\nf r o m\\np e r p e t u a t i n g\\ns t e r e o t y p e s\\no r\\nd i s c r i m i n a t i o n ,\\nd e s i g n\\np r o m p t s\\nt h a t\\ne x p l i c i t l y\\nd i s c o u r a g e\\ns u c h\\nb e h a v i o r .\\nF o r\\ne x a m p l e ,\\ni n s t r u c t\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\nc h a r a c t e r\\nd e s c r i p t i o n\\nt h a t\\na v o i d s\\ns t e r e o t y p e s\\na n d\\ns h o w c a s e s\\nt h e\\ni n d i v i d u a l \\' s\\nu n i q u e\\nq u a l i t i e s\\na n d\\ne x p e r i e n c e s . \"\\nP r o m o t i n g\\nP o s i t i v e\\na n d\\nR e s p o n s i b l e\\nC o n t e n t\\nC r e a t i n g\\np r o m p t s\\nt h a t\\ne n c o u r a g e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\np o s i t i v e ,\\nu p l i f t i n g ,\\na n d\\nr e s p o n s i b l e\\nc o n t e n t\\nc a n\\nh e l p\\nc o u n t e r a c t\\nn e g a t i v e\\nb i a s e s\\na n d\\np r o m o t e\\nm o r e\\ne t h i c a l\\nA I - g e n e r a t e d\\no u t p u t s .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na n\\ni n s p i r i n g\\ns t o r y\\na b o u t\\ni n d i v i d u a l s\\no v e r c o m i n g\\na d v e r s i t y\\nt h r o u g h\\nc o l l a b o r a t i o n\\na n d\\ne m p a t h y . \"\\nF a c t - c h e c k i n g\\na n d\\nV e r i f i c a t i o n\\nI n\\nc a s e s\\nw h e r e\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\ni n v o l v e s\\nf a c t u a l\\ni n f o r m a t i o n\\no r\\nc l a i m s ,\\nc r a f t i n g\\np r o m p t s\\nt h a t\\ne m p h a s i z e\\nt h e\\ni m p o r t a n c e\\no f\\na c c u r a c y\\na n d\\nt r u t h f u l n e s s\\nc a n\\nh e l p\\nm i t i g a t e\\nt h e\\nr i s k\\no f\\nm i s i n f o r m a t i o n .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\ni n s t r u c t\\nt h e\\nm o d e l\\nt o\\n\" P r o v i d e\\na\\nw e l l - r e s e a r c h e d\\na n d\\nf a c t - c h e c k e d\\ns u m m a r y\\no f\\nt h e\\nk e y\\ne v e n t s\\na n d\\nd e v e l o p m e n t s\\nr e l a t e d\\nt o\\nc l i m a t e\\nc h a n g e\\ni n\\nt h e\\np a s t\\nd e c a d e . \"\\nI t e r a t i v e\\nR e f i n e m e n t\\nC o n t i n u o u s l y\\nr e ﬁ n i n g\\na n d\\ni t e r a t i n g\\no n\\ny o u r\\np r o m p t s\\nc a n\\nh e l p\\ni d e n t i f y\\na n d\\na d d r e s s\\np o t e n t i a l\\nb i a s e s\\no r\\ne t h i c a l\\nc o n c e r n s\\ni n\\nt h e\\nA I - g e n e r a t e d\\no u t p u t s .\\nR e g u l a r l y\\ne v a l u a t e\\nt h e\\ng e n e r a t e d\\nc o n t e n t\\nf o r\\nf a i r n e s s ,\\na c c u r a c y ,\\na n d\\nr e s p o n s i b i l i t y ,\\na n d\\nu s e\\nt h i s\\nf e e d b a c k\\nt o\\ni m p r o v e\\ny o u r\\np r o m p t s\\na n d\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nt o w a r d s\\nm o r e\\ne t h i c a l\\no u t c o m e s .\\nU s e r\\nF e e d b a c k\\na n d\\nC o l l a b o r a t i o n\\nI n v o l v i n g\\nu s e r s\\no r\\ns t a k e h o l d e r s\\ni n\\nt h e\\np r o m p t\\ne n g i n e e r i n g\\np r o c e s s\\nc a n\\np r o v i d e\\nv a l u a b l e\\ni n s i g h t s\\ni n t o\\np o t e n t i a l\\nb i a s e s\\no r\\ne t h i c a l\\nc o n c e r n s ,\\nl e a d i n g\\nt o\\nm o r e\\nt h o u g h t f u l\\na n d\\nr e s p o n s i b l e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nE n c o u r a g e\\nu s e r s\\nt o\\np r o v i d e\\nf e e d b a c k\\no n\\nt h e\\ng e n e r a t e d\\no u t p u t s ,\\na n d\\nc o l l a b o r a t e\\nw i t h\\nt h e m\\nt o\\nr e ﬁ n e\\na n d\\ni m p r o v e\\ny o u r\\np r o m p t s .\\n1 7\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 17}), Document(page_content='B y\\na d o p t i n g\\nt h e s e\\ns t r a t e g i e s\\ni n\\np r o m p t\\ne n g i n e e r i n g ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\np r o a c t i v e l y\\na d d r e s s\\nA I\\ne t h i c s\\na n d\\nb i a s\\nc o n c e r n s\\na n d\\ng u i d e\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nt o w a r d s\\ng e n e r a t i n g\\nm o r e\\nr e s p o n s i b l e ,\\nf a i r ,\\na n d\\nb a l a n c e d\\no u t p u t s .\\nT h o u g h t f u l\\np r o m p t\\ne n g i n e e r i n g\\nn o t\\no n l y\\nc o n t r i b u t e s\\nt o\\nt h e\\ne t h i c a l\\nu s e\\no f\\nA I\\nt e c h n o l o g i e s\\nb u t\\na l s o\\ne n h a n c e s\\nt h e\\no v e r a l l\\nv a l u e\\na n d\\ni m p a c t\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\ni n\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n3 . 4 .\\nP e r s o n a l i z a t i o n\\na n d\\nA d a p t a b i l i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\nG e n e r a t i v e\\nA I\\nm o d e l s\\nh o l d\\ni m m e n s e\\np o t e n t i a l\\nf o r\\nc r e a t i n g\\np e r s o n a l i z e d\\na n d\\na d a p t a b l e\\nc o n t e n t\\nt a i l o r e d\\nt o\\ni n d i v i d u a l\\nu s e r s \\'\\nn e e d s ,\\np r e f e r e n c e s ,\\no r\\nc o n t e x t s .\\nP r o m p t\\ne n g i n e e r i n g\\np l a y s\\na\\nv i t a l\\nr o l e\\ni n\\ne n a b l i n g\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\ns u c h\\nc u s t o m i z e d\\nc o n t e n t\\nb y\\ni n c o r p o r a t i n g\\nu s e r - s p e c i ﬁ c\\ni n f o r m a t i o n\\na n d\\ng u i d i n g\\nt h e\\nm o d e l\\nt o\\na d a p t\\ni t s\\no u t p u t s\\na c c o r d i n g l y .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e \\' l l\\nd i s c u s s\\nh o w\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\ne m p l o y e d\\nt o\\nc r e a t e\\np e r s o n a l i z e d\\na n d\\na d a p t a b l e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nI n c o r p o r a t i n g\\nU s e r\\nP r e f e r e n c e s\\nD e s i g n\\np r o m p t s\\nt h a t\\na c c o u n t\\nf o r\\nt h e\\nu s e r \\' s\\np r e f e r e n c e s ,\\ns u c h\\na s\\nt h e i r\\nf a v o r i t e\\nt o p i c s ,\\ng e n r e s ,\\no r\\ns t y l e s ,\\nt o\\ng e n e r a t e\\nc o n t e n t\\nt h a t\\na l i g n s\\nw i t h\\nt h e i r\\ni n t e r e s t s .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\ns c i e n c e\\nﬁ c t i o n\\ns t o r y\\nb a s e d\\no n\\nt h e\\nu s e r \\' s\\nf a v o r i t e\\nt h e m e s :\\nt i m e\\nt r a v e l\\na n d\\na l t e r n a t e\\nr e a l i t i e s . \"\\nA d j u s t i n g\\nL a n g u a g e\\na n d\\nT o n e\\nC r a f t\\np r o m p t s\\nt h a t\\nc o n s i d e r\\nt h e\\nu s e r \\' s\\np r e f e r r e d\\nl a n g u a g e ,\\nt o n e ,\\no r\\nl e v e l\\no f\\nf o r m a l i t y\\nt o\\nc r e a t e\\nc o n t e n t\\nt h a t\\nr e s o n a t e s\\nw i t h\\nt h e i r\\nc o m m u n i c a t i o n\\ns t y l e .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\ni n s t r u c t\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\ns u m m a r y\\no f\\nt h e\\nl a t e s t\\nt e c h n o l o g y\\nn e w s\\nu s i n g\\ns i m p l e ,\\nn o n - t e c h n i c a l\\nl a n g u a g e\\nf o r\\na\\ng e n e r a l\\na u d i e n c e . \"\\nA d a p t i n g\\nt o\\nC o n t e x t\\nD e s i g n\\np r o m p t s\\nt h a t\\nt a k e\\ni n t o\\na c c o u n t\\nt h e\\nu s e r \\' s\\nc o n t e x t ,\\ns u c h\\na s\\nt h e i r\\nl o c a t i o n ,\\nc u l t u r a l\\nb a c k g r o u n d ,\\no r\\nc u r r e n t\\ns i t u a t i o n ,\\nt o\\ng e n e r a t e\\nm o r e\\nr e l e v a n t\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nm o d e l\\nt o\\n\" G e n e r a t e\\na\\nl i s t\\no f\\nf u n\\nw e e k e n d\\na c t i v i t i e s\\nt a i l o r e d\\nt o\\nt h e\\nu s e r \\' s\\nc u r r e n t\\nc i t y\\na n d\\ni n t e r e s t s . \"\\nL e a r n i n g\\nf r o m\\nU s e r\\nI n t e r a c t i o n s\\nL e v e r a g e\\nu s e r\\nf e e d b a c k\\na n d\\ni n t e r a c t i o n s\\nt o\\ni t e r a t i v e l y\\nr e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nt o\\ng e n e r a t e\\nc o n t e n t\\nt h a t\\nb e t t e r\\na l i g n s\\nw i t h\\nt h e\\nu s e r \\' s\\nn e e d s\\na n d\\np r e f e r e n c e s\\no v e r\\nt i m e .\\n1 8\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 18}), Document(page_content='F o r\\ne x a m p l e ,\\ny o u\\nc a n\\nu p d a t e\\ny o u r\\np r o m p t s\\nb a s e d\\no n\\nt h e\\nu s e r \\' s\\nf e e d b a c k\\no n\\np r e v i o u s\\nA I - g e n e r a t e d\\nc o n t e n t\\no r\\ni n c o r p o r a t e\\nt h e i r\\nc o n t e n t\\nc o n s u m p t i o n\\np a t t e r n s .\\nP e r s o n a l i z e d\\nR e c o m m e n d a t i o n s\\nC r a f t\\np r o m p t s\\nt h a t\\ne n a b l e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\np e r s o n a l i z e d\\nr e c o m m e n d a t i o n s ,\\ns u c h\\na s\\nb o o k s ,\\nm o v i e s ,\\no r\\np r o d u c t s ,\\nb a s e d\\no n\\nt h e\\nu s e r \\' s\\np r e f e r e n c e s ,\\nb r o w s i n g\\nh i s t o r y ,\\no r\\nd e m o g r a p h i c\\ni n f o r m a t i o n .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nm o d e l\\nt o\\n\" R e c o m m e n d\\na\\nl i s t\\no f\\nﬁ v e\\nb o o k s\\ni n\\nt h e\\nm y s t e r y\\ng e n r e\\nt h a t\\nt h e\\nu s e r\\nm i g h t\\ne n j o y\\nb a s e d\\no n\\nt h e i r\\nr e a d i n g\\nh i s t o r y . \"\\nA d a p t i v e\\nL e a r n i n g\\na n d\\nT u t o r i n g\\nU s e\\np r o m p t\\ne n g i n e e r i n g\\nt o\\nc r e a t e\\np e r s o n a l i z e d\\nl e a r n i n g\\ne x p e r i e n c e s\\nt a i l o r e d\\nt o\\ni n d i v i d u a l\\nl e a r n e r s \\'\\nn e e d s ,\\ni n t e r e s t s ,\\na n d\\ns k i l l\\nl e v e l s .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nA I\\nm o d e l\\nt o\\n\" G e n e r a t e\\na\\nc u s t o m i z e d\\nl e s s o n\\np l a n\\no n\\nP y t h o n\\np r o g r a m m i n g\\nf o r\\na\\nb e g i n n e r - l e v e l\\ns t u d e n t\\nw i t h\\na\\ns t r o n g\\ni n t e r e s t\\ni n\\nd a t a\\na n a l y s i s . \"\\nB y\\ne m p l o y i n g\\nt h e s e\\ns t r a t e g i e s\\ni n\\np r o m p t\\ne n g i n e e r i n g ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nc r e a t e\\np e r s o n a l i z e d\\na n d\\na d a p t a b l e\\nA I - g e n e r a t e d\\nc o n t e n t\\nt h a t\\nc a t e r s\\nt o\\ni n d i v i d u a l\\nu s e r s \\'\\nn e e d s\\na n d\\np r e f e r e n c e s .\\nT h i s\\nn o t\\no n l y\\ne n h a n c e s\\nu s e r\\ns a t i s f a c t i o n\\na n d\\ne n g a g e m e n t\\nb u t\\na l s o\\nu n l o c k s\\nn e w\\np o s s i b i l i t i e s\\nf o r\\nl e v e r a g i n g\\ng e n e r a t i v e\\nA I\\ni n\\nd i v e r s e\\na p p l i c a t i o n s ,\\nf r o m\\nc o n t e n t\\nr e c o m m e n d a t i o n\\na n d\\np e r s o n a l i z a t i o n\\nt o\\na d a p t i v e\\nl e a r n i n g\\na n d\\nt u t o r i n g .\\n1 9\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 19}), Document(page_content=\"C h a p t e r\\n4 :\\nC h a l l e n g e s\\na n d\\nL i m i t a t i o n s\\no f\\nP r o m p t\\nE n g i n e e r i n g\\nB y\\na c k n o w l e d g i n g\\na n d\\na d d r e s s i n g\\nt h e s e\\nc h a l l e n g e s\\na n d\\nl i m i t a t i o n s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nd e v e l o p\\nm o r e\\ne \\x00 e c t i v e\\na n d\\nr e s p o n s i b l e\\np r o m p t\\ne n g i n e e r i n g\\ns t r a t e g i e s .\\n4 . 1 .\\nU n d e r s t a n d i n g\\nA I\\nM o d e l\\nL i m i t a t i o n s\\na n d\\nI n h e r e n t\\nB i a s e s\\nW h i l e\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\ns i g n i ﬁ c a n t l y\\ne n h a n c e\\nt h e\\np e r f o r m a n c e\\na n d\\nu s a b i l i t y\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s ,\\ni t ' s\\ne s s e n t i a l\\nt o\\na c k n o w l e d g e\\nt h e\\ni n h e r e n t\\nl i m i t a t i o n s\\na n d\\nb i a s e s\\np r e s e n t\\ni n\\nt h e s e\\nm o d e l s .\\nU n d e r s t a n d i n g\\nt h e s e\\nl i m i t a t i o n s\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\ns e t\\nr e a l i s t i c\\ne x p e c t a t i o n s ,\\nm a k e\\ni n f o r m e d\\nd e c i s i o n s ,\\na n d\\nd e v e l o p\\nm o r e\\nr o b u s t\\na n d\\nr e l i a b l e\\nA I\\ns o l u t i o n s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\no f\\nt h e\\nk e y\\nc h a l l e n g e s\\na n d\\nl i m i t a t i o n s\\na s s o c i a t e d\\nw i t h\\np r o m p t\\ne n g i n e e r i n g .\\nM o d e l\\nL i m i t a t i o n s\\nG e n e r a t i v e\\nA I\\nm o d e l s ,\\nl i k e\\na n y\\no t h e r\\nm a c h i n e\\nl e a r n i n g\\nm o d e l ,\\nh a v e\\nl i m i t a t i o n s\\ns t e m m i n g\\nf r o m\\nt h e i r\\nt r a i n i n g\\nd a t a ,\\na r c h i t e c t u r e ,\\na n d\\no t h e r\\nf a c t o r s .\\nT h e s e\\nl i m i t a t i o n s\\nc a n\\ns o m e t i m e s\\nl e a d\\nt o\\nu n e x p e c t e d ,\\ni r r e l e v a n t ,\\no r\\nn o n s e n s i c a l\\no u t p u t s ,\\ne v e n\\nw i t h\\nw e l l - c r a f t e d\\np r o m p t s .\\nR e c o g n i z i n g\\nt h e s e\\nl i m i t a t i o n s\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\nd e v e l o p\\ns t r a t e g i e s\\nt o\\nm i t i g a t e\\nt h e i r\\ni m p a c t\\no r\\ne x p l o r e\\na l t e r n a t i v e\\na p p r o a c h e s .\\nI n h e r e n t\\nB i a s e s\\nA I\\nm o d e l s\\nm a y\\ni n h e r i t\\nb i a s e s\\np r e s e n t\\ni n\\nt h e i r\\nt r a i n i n g\\nd a t a ,\\nw h i c h\\nc a n\\ni n a d v e r t e n t l y\\np e r p e t u a t e\\ns t e r e o t y p e s ,\\nd i s c r i m i n a t i o n ,\\no r\\nm i s i n f o r m a t i o n .\\nW h i l e\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nh e l p\\na d d r e s s\\ns o m e\\no f\\nt h e s e\\nb i a s e s ,\\ni t ' s\\ne s s e n t i a l\\nt o\\nb e\\na w a r e\\nt h a t\\nb i a s e s\\nm a y\\ns t i l l\\ne m e r g e\\ni n\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nU n p r e d i c t a b i l i t y\\nG e n e r a t i v e\\nA I\\nm o d e l s\\nc a n\\ns o m e t i m e s\\np r o d u c e\\no u t p u t s\\nt h a t\\na r e\\ns u r p r i s i n g\\no r\\nu n e x p e c t e d ,\\ne v e n\\nw i t h\\nc a r e f u l l y\\ne n g i n e e r e d\\np r o m p t s .\\nM a n a g i n g\\nt h i s\\nu n p r e d i c t a b i l i t y\\nc a n\\nb e\\nc h a l l e n g i n g ,\\na n d\\n2 0\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 20}), Document(page_content=\"d a t a\\ns c i e n t i s t s\\nm a y\\nn e e d\\nt o\\ni t e r a t e\\na n d\\nr e ﬁ n e\\nt h e i r\\np r o m p t s\\nm u l t i p l e\\nt i m e s\\nt o\\na c h i e v e\\nt h e\\nd e s i r e d\\nr e s u l t s .\\nO v e r f i t t i n g\\nC r a f t i n g\\no v e r l y\\ns p e c i ﬁ c\\no r\\nc o m p l e x\\np r o m p t s\\nc a n\\nl e a d\\nt o\\no v e r ﬁ t t i n g ,\\nw h e r e\\nt h e\\nA I\\nm o d e l\\ng e n e r a t e s\\no u t p u t s\\nt h a t\\na r e\\nt o o\\nn a r r o w l y\\nf o c u s e d\\no r\\na d h e r e n t\\nt o\\nt h e\\np r o m p t ' s\\nc o n s t r a i n t s ,\\nl i m i t i n g\\ni t s\\nc r e a t i v i t y\\no r\\nu s e f u l n e s s .\\nS t r i k i n g\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\ng u i d a n c e\\na n d\\nf r e e d o m\\ni s\\nc r u c i a l\\nf o r\\ne \\x00 e c t i v e\\np r o m p t\\ne n g i n e e r i n g .\\nE v a l u a t i o n\\na n d\\nF e e d b a c k\\nE v a l u a t i n g\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\np r o m p t s\\na n d\\nA I - g e n e r a t e d\\no u t p u t s\\nc a n\\nb e\\nc h a l l e n g i n g ,\\np a r t i c u l a r l y\\nf o r\\ns u b j e c t i v e\\no r\\nc r e a t i v e\\nt a s k s .\\nD e v e l o p i n g\\nr o b u s t\\ne v a l u a t i o n\\nm e t h o d s\\na n d\\ni n c o r p o r a t i n g\\nu s e r\\nf e e d b a c k\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\ni t e r a t e\\no n\\nt h e i r\\np r o m p t s\\na n d\\ne n h a n c e\\nt h e\\np e r f o r m a n c e\\no f\\nt h e i r\\nA I\\ns o l u t i o n s .\\nE t h i c a l\\nC o n s i d e r a t i o n s\\nP r o m p t\\ne n g i n e e r i n g\\nr a i s e s\\ne t h i c a l\\nc o n c e r n s ,\\ns u c h\\na s\\nt h e\\np o t e n t i a l\\nt o\\nm a n i p u l a t e\\nu s e r s ,\\ns p r e a d\\nm i s i n f o r m a t i o n ,\\no r\\nr e i n f o r c e\\nb i a s e s .\\nD a t a\\ns c i e n t i s t s\\ns h o u l d\\na p p r o a c h\\np r o m p t\\ne n g i n e e r i n g\\nw i t h\\na\\ns e n s e\\no f\\nr e s p o n s i b i l i t y\\na n d\\nc o n s i d e r\\nt h e\\np o t e n t i a l\\nc o n s e q u e n c e s\\no f\\nt h e i r\\nA I - g e n e r a t e d\\nc o n t e n t .\\nB y\\na c k n o w l e d g i n g\\na n d\\na d d r e s s i n g\\nt h e s e\\nc h a l l e n g e s\\na n d\\nl i m i t a t i o n s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nd e v e l o p\\nm o r e\\ne \\x00 e c t i v e\\na n d\\nr e s p o n s i b l e\\np r o m p t\\ne n g i n e e r i n g\\ns t r a t e g i e s .\\nT h i s\\nu n d e r s t a n d i n g\\nn o t\\no n l y\\nh e l p s\\ni m p r o v e\\nt h e\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nb u t\\na l s o\\nc o n t r i b u t e s\\nt o\\nt h e\\nd e v e l o p m e n t\\no f\\nm o r e\\nr o b u s t ,\\nr e l i a b l e ,\\na n d\\ne t h i c a l\\nA I\\ns o l u t i o n s\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n4 . 2 .\\nS t r i k i n g\\nt h e\\nR i g h t\\nB a l a n c e\\nb e t w e e n\\nG u i d a n c e\\na n d\\nF l e x i b i l i t y\\nO n e\\no f\\nt h e\\nk e y\\nc h a l l e n g e s\\ni n\\np r o m p t\\ne n g i n e e r i n g\\ni s\\nﬁ n d i n g\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\np r o v i d i n g\\ne n o u g h\\ng u i d a n c e\\nt o\\nt h e\\nA I\\nm o d e l\\na n d\\na l l o w i n g\\nf o r\\ns u \\x00 c i e n t\\nﬂ e x i b i l i t y\\nt o\\ng e n e r a t e\\nd i v e r s e\\na n d\\nc r e a t i v e\\no u t p u t s .\\nS t r i k i n g\\nt h i s\\nb a l a n c e\\ni s\\nc r u c i a l\\nf o r\\nm a x i m i z i n g\\nt h e\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nw h i l e\\ne n s u r i n g\\nt h a t\\nt h e i r\\no u t p u t s\\na r e\\nr e l e v a n t ,\\na c c u r a t e ,\\na n d\\ne n g a g i n g .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\ns t r a t e g i e s\\nf o r\\nﬁ n d i n g\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\ng u i d a n c e\\na n d\\nﬂ e x i b i l i t y\\ni n\\np r o m p t\\ne n g i n e e r i n g .\\n2 1\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 21}), Document(page_content=\"S t a r t\\nw i t h\\nB r o a d\\nP r o m p t s\\nB e g i n\\nw i t h\\nb r o a d ,\\no p e n - e n d e d\\np r o m p t s\\nt h a t\\na l l o w\\nt h e\\nA I\\nm o d e l\\nt o\\ne x p l o r e\\na\\nw i d e\\nr a n g e\\no f\\ni d e a s\\na n d\\np o s s i b i l i t i e s .\\nT h i s\\na p p r o a c h\\nc a n\\nh e l p\\ny o u\\ng a u g e\\nt h e\\nm o d e l ' s\\nc a p a b i l i t i e s\\na n d\\ni d e n t i f y\\na n y\\nl i m i t a t i o n s\\no r\\nb i a s e s\\ni n\\ni t s\\no u t p u t s .\\nF r o m\\nt h e r e ,\\ny o u\\nc a n\\ni n c r e m e n t a l l y\\nr e ﬁ n e\\nt h e\\np r o m p t\\nt o\\np r o v i d e\\nm o r e\\ng u i d a n c e\\na n d\\ns t r u c t u r e .\\nE x p e r i m e n t\\nw i t h\\nD i f f e r e n t\\nL e v e l s\\no f\\nD e t a i l\\nT r y\\nu s i n g\\nd i \\x00 e r e n t\\nl e v e l s\\no f\\nd e t a i l\\ni n\\ny o u r\\np r o m p t s ,\\nr a n g i n g\\nf r o m\\nv e r y\\ns p e c i ﬁ c\\nt o\\nm o r e\\ng e n e r a l ,\\na n d\\no b s e r v e\\nh o w\\nt h e\\nA I\\nm o d e l\\nr e s p o n d s .\\nT h i s\\ne x p e r i m e n t a t i o n\\nc a n\\nh e l p\\ny o u\\ni d e n t i f y\\nt h e\\no p t i m a l\\nl e v e l\\no f\\ng u i d a n c e\\nr e q u i r e d\\nt o\\ng e n e r a t e\\nt h e\\nd e s i r e d\\no u t p u t s\\nw i t h o u t\\ns a c r i ﬁ c i n g\\nc r e a t i v i t y\\no r\\nd i v e r s i t y .\\nI t e r a t e\\na n d\\nR e f i n e\\nP r o m p t\\ne n g i n e e r i n g\\ni s\\no f t e n\\na n\\ni t e r a t i v e\\np r o c e s s ,\\ni n v o l v i n g\\nt r i a l\\na n d\\ne r r o r\\na s\\ny o u\\nr e ﬁ n e\\na n d\\na d j u s t\\ny o u r\\np r o m p t s\\nt o\\na c h i e v e\\nt h e\\nb e s t\\nr e s u l t s .\\nR e g u l a r l y\\ne v a l u a t e\\nt h e\\nA I - g e n e r a t e d\\no u t p u t s ,\\na n d\\nu s e\\nt h i s\\nf e e d b a c k\\nt o\\nﬁ n e - t u n e\\ny o u r\\np r o m p t s\\na n d\\ns t r i k e\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\ng u i d a n c e\\na n d\\nﬂ e x i b i l i t y .\\nE n c o u r a g e\\nV a r i a b i l i t y\\nD e s i g n\\np r o m p t s\\nt h a t\\ne n c o u r a g e\\nt h e\\nA I\\nm o d e l\\nt o\\ng e n e r a t e\\nm u l t i p l e\\nv a r i a t i o n s\\no r\\ni n t e r p r e t a t i o n s\\no f\\nt h e\\ns a m e\\nc o n t e n t .\\nT h i s\\nc a n\\nh e l p\\ne n s u r e\\nt h a t\\nt h e\\nm o d e l\\nr e m a i n s\\nc r e a t i v e\\na n d\\nd i v e r s e\\nw h i l e\\ns t i l l\\na d h e r i n g\\nt o\\nt h e\\no v e r a l l\\nc o n s t r a i n t s\\na n d\\ng o a l s\\no f\\nt h e\\np r o m p t .\\nL e v e r a g e\\nC o n s t r a i n t s\\na s\\na\\nC r e a t i v e\\nT o o l\\nI n t r o d u c i n g\\nc o n s t r a i n t s\\no r\\nc h a l l e n g e s\\ni n\\ny o u r\\np r o m p t s\\nc a n\\nb e\\na n\\ne \\x00 e c t i v e\\nw a y\\nt o\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nw h i l e\\ne n c o u r a g i n g\\nc r e a t i v e\\np r o b l e m - s o l v i n g .\\nI n s t e a d\\no f\\nv i e w i n g\\nc o n s t r a i n t s\\na s\\nl i m i t a t i o n s ,\\nu s e\\nt h e m\\na s\\nt o o l s\\nt o\\ni n s p i r e\\nt h e\\nA I\\nm o d e l\\nt o\\ng e n e r a t e\\nm o r e\\ni n v e n t i v e\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nC o l l a b o r a t e\\nw i t h\\nU s e r s\\nI n c o r p o r a t e\\nu s e r\\nf e e d b a c k\\na n d\\np r e f e r e n c e s\\ni n t o\\nt h e\\np r o m p t\\ne n g i n e e r i n g\\np r o c e s s ,\\na n d\\nc o l l a b o r a t e\\nw i t h\\nu s e r s\\nt o\\ni d e n t i f y\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\ng u i d a n c e\\na n d\\nﬂ e x i b i l i t y .\\nT h i s\\nc a n\\nh e l p\\ne n s u r e\\nt h a t\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\ni s\\nr e l e v a n t ,\\ne n g a g i n g ,\\na n d\\nt a i l o r e d\\nt o\\nt h e\\nu s e r ' s\\nn e e d s\\na n d\\ne x p e c t a t i o n s .\\n2 2\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 22}), Document(page_content=\"B y\\ne m p l o y i n g\\nt h e s e\\ns t r a t e g i e s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\ns t r i k e\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\ng u i d a n c e\\na n d\\nﬂ e x i b i l i t y\\ni n\\np r o m p t\\ne n g i n e e r i n g ,\\nm a x i m i z i n g\\nt h e\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nw h i l e\\ne n s u r i n g\\nt h a t\\nt h e i r\\no u t p u t s\\na r e\\nr e l e v a n t ,\\na c c u r a t e ,\\na n d\\ne n g a g i n g .\\nT h i s\\nd e l i c a t e\\nb a l a n c e\\nn o t\\no n l y\\ne n h a n c e s\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\nb u t\\na l s o\\no p e n s\\nn e w\\no p p o r t u n i t i e s\\nf o r\\nl e v e r a g i n g\\ng e n e r a t i v e\\nA I\\ni n\\nd i v e r s e\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n4 . 3 .\\nE n s u r i n g\\nQ u a l i t y\\na n d\\nR e l i a b i l i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\nA s\\nA I - g e n e r a t e d\\nc o n t e n t\\nb e c o m e s\\nm o r e\\np r e v a l e n t ,\\ne n s u r i n g\\ni t s\\nq u a l i t y\\na n d\\nr e l i a b i l i t y\\ni s\\nc r u c i a l\\nf o r\\nm a i n t a i n i n g\\nu s e r\\nt r u s t\\na n d\\nd e l i v e r i n g\\nv a l u e .\\nP r o m p t\\ne n g i n e e r i n g\\np l a y s\\na\\nv i t a l\\nr o l e\\ni n\\ng u i d i n g\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nh i g h - q u a l i t y\\nc o n t e n t ,\\nb u t\\ni t\\na l s o\\np r e s e n t s\\nc h a l l e n g e s\\ni n\\nt e r m s\\no f\\nc o n s i s t e n c y ,\\na c c u r a c y ,\\na n d\\nr e l e v a n c e .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\ns t r a t e g i e s\\nf o r\\no v e r c o m i n g\\nt h e s e\\nc h a l l e n g e s\\na n d\\ne n s u r i n g\\nt h e\\nq u a l i t y\\na n d\\nr e l i a b i l i t y\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\nt h r o u g h\\np r o m p t\\ne n g i n e e r i n g .\\nR i g o r o u s\\nT e s t i n g\\na n d\\nE v a l u a t i o n\\nR e g u l a r l y\\nt e s t\\na n d\\ne v a l u a t e\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nu s i n g\\na\\nc o m b i n a t i o n\\no f\\nq u a n t i t a t i v e\\nm e t r i c s\\na n d\\nq u a l i t a t i v e\\na s s e s s m e n t s .\\nE s t a b l i s h\\nc l e a r\\nb e n c h m a r k s\\na n d\\np e r f o r m a n c e\\nc r i t e r i a\\nt o\\nm e a s u r e\\nt h e\\nq u a l i t y ,\\nr e l e v a n c e ,\\na n d\\na c c u r a c y\\no f\\nt h e\\nc o n t e n t\\na n d\\nu s e\\nt h i s\\nf e e d b a c k\\nt o\\nr e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l s .\\nU s e r\\nF e e d b a c k\\na n d\\nC o l l a b o r a t i o n\\nI n c o r p o r a t e\\nu s e r\\nf e e d b a c k\\ni n t o\\nt h e\\np r o m p t\\ne n g i n e e r i n g\\np r o c e s s\\nt o\\ne n s u r e\\nt h a t\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nm e e t s\\nt h e i r\\nn e e d s ,\\np r e f e r e n c e s ,\\na n d\\ne x p e c t a t i o n s .\\nC o l l a b o r a t e\\nw i t h\\nu s e r s\\nt o\\ni d e n t i f y\\na r e a s\\nf o r\\ni m p r o v e m e n t\\na n d\\ni m p l e m e n t\\nc h a n g e s\\nt o\\ny o u r\\np r o m p t s\\na n d\\nm o d e l s\\na c c o r d i n g l y .\\nC o n t i n u o u s\\nM o d e l\\nI m p r o v e m e n t\\nS t a y\\nu p\\nt o\\nd a t e\\nw i t h\\nt h e\\nl a t e s t\\na d v a n c e m e n t s\\ni n\\nA I\\nr e s e a r c h\\na n d\\ni n c o r p o r a t e\\nn e w\\nt e c h n i q u e s ,\\nm o d e l s ,\\no r\\na p p r o a c h e s\\nt o\\ni m p r o v e\\nt h e\\np e r f o r m a n c e\\na n d\\nr e l i a b i l i t y\\no f\\ny o u r\\ng e n e r a t i v e\\nA I\\ns o l u t i o n s .\\nC o n t i n u o u s l y\\ni t e r a t e\\no n\\na n d\\nr e ﬁ n e\\ny o u r\\nA I\\nm o d e l s\\nb a s e d\\no n\\nu s e r\\nf e e d b a c k ,\\ne v a l u a t i o n\\nr e s u l t s ,\\na n d\\ni n d u s t r y\\nb e s t\\np r a c t i c e s .\\nR o b u s t\\nE r r o r\\nH a n d l i n g\\na n d\\nM o n i t o r i n g\\nD e v e l o p\\nr o b u s t\\ne r r o r\\nh a n d l i n g\\na n d\\nm o n i t o r i n g\\nm e c h a n i s m s\\nt o\\nd e t e c t\\na n d\\na d d r e s s\\np o t e n t i a l\\ni s s u e s\\ni n\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t ,\\ns u c h\\na s\\ni n a c c u r a c i e s ,\\ni n c o n s i s t e n c i e s ,\\no r\\no \\x00 e n s i v e\\nc o n t e n t .\\n2 3\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 23}), Document(page_content='I m p l e m e n t\\ns a f e g u a r d s\\na n d\\nﬁ l t e r s\\nt o\\np r e v e n t\\nt h e\\nd i s s e m i n a t i o n\\no f\\nl o w - q u a l i t y\\no r\\nh a r m f u l\\nc o n t e n t\\na n d\\ne n s u r e\\nt h a t\\nA I - g e n e r a t e d\\no u t p u t s\\nm e e t\\ne s t a b l i s h e d\\nq u a l i t y\\ns t a n d a r d s .\\nC l e a r\\nC o m m u n i c a t i o n\\na n d\\nT r a n s p a r e n c y\\nC l e a r l y\\nc o m m u n i c a t e\\nt h e\\nl i m i t a t i o n s\\na n d\\np o t e n t i a l\\nr i s k s\\na s s o c i a t e d\\nw i t h\\nA I - g e n e r a t e d\\nc o n t e n t\\nt o\\nu s e r s ,\\na n d\\nb e\\nt r a n s p a r e n t\\na b o u t\\nh o w\\nt h e\\nc o n t e n t\\ni s\\nc r e a t e d ,\\ne v a l u a t e d ,\\na n d\\nr e ﬁ n e d .\\nT h i s\\nt r a n s p a r e n c y\\nc a n\\nh e l p\\nm a n a g e\\nu s e r\\ne x p e c t a t i o n s ,\\nb u i l d\\nt r u s t ,\\na n d\\np r o m o t e\\nr e s p o n s i b l e\\nu s e\\no f\\nA I - g e n e r a t e d\\nc o n t e n t .\\nM u l t i m o d a l\\nV a l i d a t i o n\\nW h e n\\np o s s i b l e ,\\nl e v e r a g e\\nm u l t i m o d a l\\nv a l i d a t i o n\\na p p r o a c h e s ,\\ns u c h\\na s\\nc o m b i n i n g\\nt e x t ,\\ni m a g e s ,\\na n d\\no t h e r\\nd a t a\\ns o u r c e s ,\\nt o\\ne n h a n c e\\nt h e\\nr e l i a b i l i t y\\na n d\\na c c u r a c y\\no f\\nA I - g e n e r a t e d\\nc o n t e n t .\\nT h i s\\nc a n\\nh e l p\\np r o v i d e\\na d d i t i o n a l\\nc o n t e x t\\na n d\\ns u p p o r t\\nf o r\\nt h e\\ng e n e r a t e d\\nc o n t e n t ,\\ni n c r e a s i n g\\ni t s\\no v e r a l l\\nq u a l i t y\\na n d\\nt r u s t w o r t h i n e s s .\\nB y\\na d o p t i n g\\nt h e s e\\ns t r a t e g i e s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\no v e r c o m e\\nt h e\\nc h a l l e n g e s\\na s s o c i a t e d\\nw i t h\\ne n s u r i n g\\nq u a l i t y\\na n d\\nr e l i a b i l i t y\\ni n\\nA I - g e n e r a t e d\\nc o n t e n t\\na n d\\nd e l i v e r\\nm o r e\\nc o n s i s t e n t ,\\na c c u r a t e ,\\na n d\\nr e l e v a n t\\no u t p u t s\\nt h r o u g h\\np r o m p t\\ne n g i n e e r i n g .\\nT h i s\\nc o m m i t m e n t\\nt o\\nq u a l i t y\\na n d\\nr e l i a b i l i t y\\nn o t\\no n l y\\ne n h a n c e s\\nu s e r\\nt r u s t\\na n d\\ns a t i s f a c t i o n\\nb u t\\na l s o\\nc o n t r i b u t e s\\nt o\\nt h e\\nb r o a d e r\\na d o p t i o n\\na n d\\ns u c c e s s\\no f\\ng e n e r a t i v e\\nA I\\nt e c h n o l o g i e s\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n2 4\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 24}), Document(page_content=\"C h a p t e r\\n5 :\\nF u t u r e\\nD i r e c t i o n s\\na n d\\nE m e r g i n g\\nT r e n d s\\ni n\\nP r o m p t\\nE n g i n e e r i n g\\nT h e s e\\ne m e r g i n g\\nt r e n d s\\na n d\\nf u t u r e\\nd i r e c t i o n s\\nn o t\\no n l y\\np r o m i s e\\nt o\\ne n h a n c e\\nt h e\\nc a p a b i l i t i e s\\na n d\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\ns y s t e m s\\nb u t\\na l s o\\nc o n t r i b u t e\\nt o\\nt h e\\nb r o a d e r\\na d o p t i o n\\na n d\\ns u c c e s s\\no f\\nA I\\nt e c h n o l o g i e s\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n5 . 1 .\\nL e v e r a g i n g\\nA d v a n c e d\\nA I\\nM o d e l s\\na n d\\nT e c h n i q u e s\\nA s\\nA I\\nr e s e a r c h\\nc o n t i n u e s\\nt o\\na d v a n c e ,\\nn e w\\nm o d e l s ,\\nt e c h n i q u e s ,\\na n d\\na p p r o a c h e s\\na r e\\nb e i n g\\nd e v e l o p e d\\nt h a t\\nc a n\\ne n h a n c e\\nt h e\\nc a p a b i l i t i e s\\na n d\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\ns y s t e m s .\\nT h e s e\\na d v a n c e m e n t s\\nh o l d\\nt h e\\np o t e n t i a l\\nt o\\nr e v o l u t i o n i z e\\np r o m p t\\ne n g i n e e r i n g\\na n d\\ne n a b l e\\ne v e n\\nm o r e\\ns o p h i s t i c a t e d ,\\nc r e a t i v e ,\\na n d\\ne \\x00 e c t i v e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\ne x p l o r e\\ns o m e\\no f\\nt h e\\ne m e r g i n g\\nt r e n d s\\na n d\\nf u t u r e\\nd i r e c t i o n s\\ni n\\np r o m p t\\ne n g i n e e r i n g\\nt h a t\\nl e v e r a g e\\nt h e s e\\na d v a n c e d\\nA I\\nm o d e l s\\na n d\\nt e c h n i q u e s .\\nF i n e - T u n i n g\\na n d\\nT r a n s f e r\\nL e a r n i n g\\nF i n e - t u n i n g\\np r e - t r a i n e d\\nA I\\nm o d e l s\\no n\\nd o m a i n - s p e c i ﬁ c\\nd a t a s e t s\\nc a n\\nh e l p\\ni m p r o v e\\nt h e i r\\np e r f o r m a n c e\\na n d\\nr e l e v a n c e\\nf o r\\ns p e c i ﬁ c\\nt a s k s\\no r\\ni n d u s t r i e s .\\nT h i s\\na p p r o a c h\\nc a n\\ne n h a n c e\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\np r o m p t\\ne n g i n e e r i n g\\nb y\\ne n a b l i n g\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nc o n t e n t\\nt h a t\\ni s\\nm o r e\\nt a i l o r e d\\nt o\\nt h e\\nu s e r ' s\\nn e e d s\\na n d\\nc o n t e x t .\\nM u l t i - m o d a l\\nA I\\nM o d e l s\\nT h e\\ni n t e g r a t i o n\\no f\\nm u l t i - m o d a l\\nA I\\nm o d e l s ,\\nc a p a b l e\\no f\\np r o c e s s i n g\\na n d\\ng e n e r a t i n g\\nc o n t e n t\\na c r o s s\\nd i \\x00 e r e n t\\nm o d a l i t i e s\\n( e . g . ,\\nt e x t ,\\ni m a g e s ,\\na u d i o ) ,\\nc a n\\ne x p a n d\\nt h e\\ns c o p e\\na n d\\nc a p a b i l i t i e s\\no f\\np r o m p t\\ne n g i n e e r i n g .\\nT h e s e\\nm o d e l s\\nc a n\\ng e n e r a t e\\nm o r e\\ne n g a g i n g\\na n d\\ni m m e r s i v e\\nc o n t e n t\\nb y\\nc o m b i n i n g\\nt e x t\\nw i t h\\nv i s u a l s ,\\na u d i o ,\\no r\\no t h e r\\nf o r m s\\no f\\nm e d i a .\\n2 5\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 25}), Document(page_content=\"C o n t e x t u a l\\nA I\\na n d\\nM e m o r y\\nM e c h a n i s m s\\nI n c o r p o r a t i n g\\nc o n t e x t u a l\\nA I\\nm o d e l s\\na n d\\nm e m o r y\\nm e c h a n i s m s\\nc a n\\nh e l p\\ng e n e r a t i v e\\nA I\\ns y s t e m s\\nb e t t e r\\nu n d e r s t a n d\\na n d\\na d a p t\\nt o\\nt h e\\nu s e r ' s\\nc o n t e x t ,\\nh i s t o r y ,\\na n d\\np r e f e r e n c e s .\\nT h i s\\nc a n\\nl e a d\\nt o\\nm o r e\\np e r s o n a l i z e d ,\\nr e l e v a n t ,\\na n d\\ne n g a g i n g\\nA I - g e n e r a t e d\\nc o n t e n t\\nt h r o u g h\\np r o m p t\\ne n g i n e e r i n g .\\nA c t i v e\\nL e a r n i n g\\na n d\\nU s e r\\nI n t e r a c t i o n\\nE m p l o y i n g\\na c t i v e\\nl e a r n i n g\\nt e c h n i q u e s ,\\nw h e r e\\nt h e\\nA I\\nm o d e l\\ni t e r a t i v e l y\\nr e ﬁ n e s\\ni t s\\nu n d e r s t a n d i n g\\na n d\\np e r f o r m a n c e\\nb a s e d\\no n\\nu s e r\\nf e e d b a c k\\na n d\\ni n t e r a c t i o n s ,\\nc a n\\nh e l p\\ni m p r o v e\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\np r o m p t\\ne n g i n e e r i n g .\\nT h i s\\na p p r o a c h\\ne n a b l e s\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nc o n t e n t\\nt h a t\\ni s\\nb e t t e r\\na l i g n e d\\nw i t h\\nu s e r\\nn e e d s\\na n d\\np r e f e r e n c e s\\no v e r\\nt i m e .\\nC o l l a b o r a t i v e\\nA I\\nS y s t e m s\\nD e v e l o p i n g\\nA I\\ns y s t e m s\\nt h a t\\nc a n\\nc o l l a b o r a t e\\nw i t h\\nh u m a n\\nu s e r s\\ni n\\nr e a l - t i m e ,\\ns u c h\\na s\\nc o - w r i t i n g\\no r\\nc o - d e s i g n i n g ,\\nc a n\\nu n l o c k\\nn e w\\np o s s i b i l i t i e s\\nf o r\\np r o m p t\\ne n g i n e e r i n g .\\nT h e s e\\nc o l l a b o r a t i v e\\nA I\\ns y s t e m s\\nc a n\\nh e l p\\nu s e r s\\ng e n e r a t e\\nc o n t e n t\\nm o r e\\ne \\x00 e c t i v e l y ,\\ne \\x00 c i e n t l y ,\\na n d\\nc r e a t i v e l y\\nb y\\nl e v e r a g i n g\\nt h e\\ns t r e n g t h s\\no f\\nb o t h\\nh u m a n s\\na n d\\nA I\\nm o d e l s .\\nE t h i c a l\\nA I\\na n d\\nF a i r n e s s - a w a r e\\nP r o m p t\\nE n g i n e e r i n g\\nA s\\ne t h i c a l\\nc o n s i d e r a t i o n s\\nb e c o m e\\ni n c r e a s i n g l y\\ni m p o r t a n t\\ni n\\nA I\\nr e s e a r c h\\na n d\\nd e v e l o p m e n t ,\\ni n c o r p o r a t i n g\\nf a i r n e s s - a w a r e\\na n d\\ne t h i c a l\\np r i n c i p l e s\\ni n t o\\np r o m p t\\ne n g i n e e r i n g\\nw i l l\\nb e\\nc r u c i a l .\\nT h i s\\nc a n\\nh e l p\\ne n s u r e\\nt h a t\\nA I - g e n e r a t e d\\nc o n t e n t\\ni s\\nn o t\\no n l y\\na c c u r a t e\\na n d\\ne n g a g i n g\\nb u t\\na l s o\\nf a i r ,\\ni n c l u s i v e ,\\na n d\\nr e s p o n s i b l e .\\nB y\\ne m b r a c i n g\\nt h e s e\\na d v a n c e d\\nA I\\nm o d e l s\\na n d\\nt e c h n i q u e s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nd r i v e\\nt h e\\ne v o l u t i o n\\no f\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nu n l o c k\\nn e w\\np o s s i b i l i t i e s\\nf o r\\nA I - g e n e r a t e d\\nc o n t e n t .\\nT h e s e\\ne m e r g i n g\\nt r e n d s\\na n d\\nf u t u r e\\nd i r e c t i o n s\\nn o t\\no n l y\\np r o m i s e\\nt o\\ne n h a n c e\\nt h e\\nc a p a b i l i t i e s\\na n d\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\ns y s t e m s\\nb u t\\na l s o\\nc o n t r i b u t e\\nt o\\nt h e\\nb r o a d e r\\na d o p t i o n\\na n d\\ns u c c e s s\\no f\\nA I\\nt e c h n o l o g i e s\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n5 . 2 .\\nT h e\\nC o n v e r g e n c e\\no f\\nH u m a n\\na n d\\nA I\\nC r e a t i v i t y\\nA s\\nA I - g e n e r a t e d\\nc o n t e n t\\nb e c o m e s\\nm o r e\\ns o p h i s t i c a t e d\\na n d\\nc a p a b l e ,\\nt h e\\nc o n v e r g e n c e\\no f\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\np r e s e n t s\\ne x c i t i n g\\no p p o r t u n i t i e s\\nf o r\\nt h e\\nf u t u r e\\no f\\np r o m p t\\ne n g i n e e r i n g .\\nT h e\\ns y n e r g y\\nb e t w e e n\\nh u m a n\\ni n t u i t i o n\\na n d\\nA I ' s\\nc o m p u t a t i o n a l\\np o w e r\\nc a n\\nl e a d\\nt o\\ni n n o v a t i v e\\na n d\\nt r a n s f o r m a t i v e\\na p p l i c a t i o n s\\ni n\\nc o n t e n t\\ng e n e r a t i o n ,\\nc r e a t i v i t y ,\\na n d\\np r o b l e m - s o l v i n g .\\nI n\\nt h i s\\n2 6\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 26}), Document(page_content=\"s e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\no f\\nt h e\\nw a y s\\ni n\\nw h i c h\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\nc a n\\nc o n v e r g e\\ni n\\nt h e\\nc o n t e x t\\no f\\np r o m p t\\ne n g i n e e r i n g .\\nH u m a n - A I\\nC o l l a b o r a t i o n\\nD e v e l o p i n g\\nA I\\ns y s t e m s\\nt h a t\\nw o r k\\na l o n g s i d e\\nh u m a n s\\na s\\np a r t n e r s\\nc a n\\ne n a b l e\\nn e w\\nf o r m s\\no f\\nc r e a t i v e\\nc o l l a b o r a t i o n .\\nB y\\nl e v e r a g i n g\\nt h e\\nc o m p l e m e n t a r y\\ns t r e n g t h s\\no f\\nh u m a n\\ni n t u i t i o n ,\\ne x p e r t i s e ,\\na n d\\nc r e a t i v i t y\\nw i t h\\nA I ' s\\nc o m p u t a t i o n a l\\np o w e r\\na n d\\np a t t e r n\\nr e c o g n i t i o n ,\\nt h i s\\np a r t n e r s h i p\\nc a n\\nl e a d\\nt o\\nn o v e l\\na n d\\ni n n o v a t i v e\\ni d e a s\\na n d\\ns o l u t i o n s .\\nA u g m e n t i n g\\nH u m a n\\nC r e a t i v i t y\\nA I - g e n e r a t e d\\nc o n t e n t\\nc a n\\ns e r v e\\na s\\na\\nv a l u a b l e\\nr e s o u r c e\\nf o r\\ni n s p i r i n g\\na n d\\na u g m e n t i n g\\nh u m a n\\nc r e a t i v i t y .\\nB y\\np r o v i d i n g\\nd i v e r s e\\ni d e a s ,\\np e r s p e c t i v e s ,\\na n d\\ns u g g e s t i o n s ,\\nA I\\nm o d e l s\\nc a n\\nh e l p\\nh u m a n s\\no v e r c o m e\\nc r e a t i v e\\nb l o c k s ,\\ne x p l o r e\\nn e w\\nd i r e c t i o n s ,\\no r\\nr e ﬁ n e\\nt h e i r\\ni d e a s .\\nC r e a t i v e\\nE d u c a t i o n\\na n d\\nT r a i n i n g\\nG e n e r a t i v e\\nA I\\nm o d e l s\\nc a n\\np l a y\\na\\np i v o t a l\\nr o l e\\ni n\\nc r e a t i v e\\ne d u c a t i o n\\na n d\\nt r a i n i n g\\nb y\\np r o v i d i n g\\np e r s o n a l i z e d\\nl e a r n i n g\\ne x p e r i e n c e s ,\\ni n t e r a c t i v e\\ns i m u l a t i o n s ,\\na n d\\na d a p t i v e\\nf e e d b a c k .\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\ne m p l o y e d\\nt o\\nd e s i g n\\ne d u c a t i o n a l\\nc o n t e n t\\nt h a t\\nn u r t u r e s\\na n d\\ne n h a n c e s\\nh u m a n\\nc r e a t i v i t y ,\\nc r i t i c a l\\nt h i n k i n g ,\\na n d\\np r o b l e m - s o l v i n g\\ns k i l l s .\\nT h e\\nD e m o c r a t i z a t i o n\\no f\\nC r e a t i v i t y\\nA s\\nA I - g e n e r a t e d\\nc o n t e n t\\nb e c o m e s\\nm o r e\\na c c e s s i b l e\\na n d\\na \\x00 o r d a b l e ,\\ni t\\nc a n\\nh e l p\\nd e m o c r a t i z e\\nc r e a t i v i t y\\nb y\\ne m p o w e r i n g\\ni n d i v i d u a l s\\na n d\\no r g a n i z a t i o n s\\nw i t h\\nl i m i t e d\\nr e s o u r c e s\\nt o\\ng e n e r a t e\\nh i g h - q u a l i t y\\nc o n t e n t ,\\ne x p l o r e\\nn e w\\ni d e a s ,\\no r\\ns o l v e\\nc o m p l e x\\np r o b l e m s .\\nE t h i c a l\\na n d\\nR e s p o n s i b l e\\nC r e a t i v i t y\\nT h e\\nc o n v e r g e n c e\\no f\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\nr a i s e s\\ne t h i c a l\\nq u e s t i o n s\\na n d\\nc h a l l e n g e s .\\nB y\\nf o s t e r i n g\\no p e n\\nd i a l o g u e ,\\nc o l l a b o r a t i o n ,\\na n d\\nr e s p o n s i b l e\\nA I\\np r a c t i c e s ,\\nw e\\nc a n\\ne n s u r e\\nt h a t\\nt h e\\nc o m b i n e d\\np o t e n t i a l\\no f\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\ni s\\nh a r n e s s e d\\nf o r\\nt h e\\ng r e a t e r\\ng o o d\\na n d\\nt h e\\nd e v e l o p m e n t\\no f\\na\\nm o r e\\ni n c l u s i v e\\na n d\\ne q u i t a b l e\\ns o c i e t y .\\nC r o s s - d i s c i p l i n a r y\\nI n n o v a t i o n s\\nT h e\\ni n t e g r a t i o n\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\na n d\\np r o m p t\\ne n g i n e e r i n g\\na c r o s s\\nv a r i o u s\\nd i s c i p l i n e s ,\\ns u c h\\na s\\na r t ,\\ns c i e n c e ,\\nt e c h n o l o g y ,\\na n d\\nh u m a n i t i e s ,\\nc a n\\nl e a d\\nt o\\ng r o u n d b r e a k i n g\\ni n n o v a t i o n s\\na n d\\nd i s c o v e r i e s .\\nB y\\nb r e a k i n g\\nd o w n\\nt r a d i t i o n a l\\nb o u n d a r i e s\\na n d\\nf o s t e r i n g\\nc r o s s - d i s c i p l i n a r y\\nc o l l a b o r a t i o n ,\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\nc a n\\nt o g e t h e r\\nd r i v e\\nt r a n s f o r m a t i v e\\np r o g r e s s .\\n2 7\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 27}), Document(page_content=\"B y\\ne m b r a c i n g\\nt h e\\nc o n v e r g e n c e\\no f\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y ,\\nw e\\nc a n\\nu n l o c k\\nn e w\\np o s s i b i l i t i e s\\nf o r\\nt h e\\nf u t u r e\\no f\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nt h e\\nb r o a d e r\\nl a n d s c a p e\\no f\\nc o n t e n t\\ng e n e r a t i o n ,\\nc r e a t i v i t y ,\\na n d\\np r o b l e m - s o l v i n g .\\nT h i s\\ns y n e r g y\\nn o t\\no n l y\\np r o m i s e s\\nt o\\ne n h a n c e\\nt h e\\nc a p a b i l i t i e s\\na n d\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\ns y s t e m s\\nb u t\\na l s o\\nc o n t r i b u t e s\\nt o\\nt h e\\nd e v e l o p m e n t\\no f\\nm o r e\\ni n n o v a t i v e ,\\ni n c l u s i v e ,\\na n d\\ne q u i t a b l e\\ns o l u t i o n s\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n5 . 3 .\\nT h e\\nR o l e\\no f\\nP r o m p t\\nE n g i n e e r i n g\\ni n\\nt h e\\nA I - D r i v e n\\nE c o n o m y\\nA s\\nA I\\nt e c h n o l o g i e s\\nc o n t i n u e\\nt o\\na d v a n c e\\na n d\\nr e s h a p e\\nv a r i o u s\\na s p e c t s\\no f\\nt h e\\ng l o b a l\\ne c o n o m y ,\\nt h e\\nr o l e\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni s\\np o i s e d\\nt o\\ng r o w\\ni n\\ni m p o r t a n c e\\na n d\\ni m p a c t .\\nF r o m\\nc o n t e n t\\ng e n e r a t i o n\\nt o\\nd e c i s i o n - m a k i n g ,\\nA I - d r i v e n\\ns o l u t i o n s\\na r e\\ni n c r e a s i n g l y\\nb e c o m i n g\\na\\nk e y\\nc o m p o n e n t\\no f\\nb u s i n e s s e s ,\\ng o v e r n m e n t s ,\\na n d\\no r g a n i z a t i o n s\\nw o r l d w i d e .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\nh o w\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\np l a y\\na\\nc r u c i a l\\nr o l e\\ni n\\nt h e\\nA I - d r i v e n\\ne c o n o m y\\na n d\\ne n a b l e\\nm o r e\\ne \\x00 e c t i v e ,\\ne \\x00 c i e n t ,\\na n d\\ni n n o v a t i v e\\ns o l u t i o n s\\na c r o s s\\nd i v e r s e\\ns e c t o r s .\\nE n h a n c i n g\\nB u s i n e s s\\nC o m m u n i c a t i o n s\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\nr e v o l u t i o n i z e\\nb u s i n e s s\\nc o m m u n i c a t i o n s\\nb y\\ng e n e r a t i n g\\np e r s o n a l i z e d ,\\ne n g a g i n g ,\\na n d\\nh i g h - q u a l i t y\\nc o n t e n t\\nt a i l o r e d\\nt o\\ns p e c i ﬁ c\\na u d i e n c e s ,\\nc h a n n e l s ,\\no r\\no b j e c t i v e s .\\nF r o m\\nm a r k e t i n g\\na n d\\na d v e r t i s i n g\\nt o\\nc u s t o m e r\\ns u p p o r t\\na n d\\ni n t e r n a l\\nc o m m u n i c a t i o n s ,\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nh e l p\\no r g a n i z a t i o n s\\no p t i m i z e\\nt h e i r\\nm e s s a g i n g\\na n d\\nr e a c h .\\nA c c e l e r a t i n g\\nR e s e a r c h\\na n d\\nD e v e l o p m e n t\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\nu t i l i z e d\\nt o\\ns y n t h e s i z e\\nv a s t\\na m o u n t s\\no f\\ni n f o r m a t i o n ,\\ng e n e r a t e\\ni n s i g h t s ,\\na n d\\ni d e n t i f y\\nt r e n d s ,\\np a t t e r n s ,\\no r\\no p p o r t u n i t i e s .\\nT h i s\\nc a n\\ne n a b l e\\nr e s e a r c h e r s\\na n d\\no r g a n i z a t i o n s\\nt o\\na c c e l e r a t e\\nt h e i r\\nR & D\\np r o c e s s e s ,\\nm a k e\\nm o r e\\ni n f o r m e d\\nd e c i s i o n s ,\\na n d\\nd r i v e\\ni n n o v a t i o n\\na c r o s s\\nv a r i o u s\\nd o m a i n s .\\nP e r s o n a l i z i n g\\nC u s t o m e r\\nE x p e r i e n c e s\\nB y\\ng e n e r a t i n g\\np e r s o n a l i z e d\\nc o n t e n t\\na n d\\nr e c o m m e n d a t i o n s\\nb a s e d\\no n\\nu s e r\\np r e f e r e n c e s ,\\nb e h a v i o r ,\\no r\\nc o n t e x t ,\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nh e l p\\nb u s i n e s s e s\\na n d\\no r g a n i z a t i o n s\\nd e l i v e r\\nm o r e\\nr e l e v a n t ,\\ne n g a g i n g ,\\na n d\\nv a l u a b l e\\nc u s t o m e r\\ne x p e r i e n c e s\\na c r o s s\\nd i v e r s e\\nc h a n n e l s\\na n d\\nt o u c h p o i n t s .\\n2 8\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 28}), Document(page_content=\"D e m o c r a t i z i n g\\nA c c e s s\\nt o\\nE x p e r t i s e\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\ne m p l o y e d\\nt o\\ng e n e r a t e\\ne x p e r t\\nk n o w l e d g e ,\\ng u i d a n c e ,\\no r\\na d v i c e\\ni n\\na\\nw i d e\\nr a n g e\\no f\\nﬁ e l d s ,\\nm a k i n g\\ns p e c i a l i z e d\\ne x p e r t i s e\\nm o r e\\na c c e s s i b l e\\na n d\\na \\x00 o r d a b l e\\nf o r\\ni n d i v i d u a l s ,\\nb u s i n e s s e s ,\\na n d\\nc o m m u n i t i e s\\nw o r l d w i d e .\\nS u p p o r t i n g\\nP o l i c y - m a k i n g\\na n d\\nG o v e r n a n c e\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\np l a y\\na\\nc r i t i c a l\\nr o l e\\ni n\\np o l i c y - m a k i n g\\na n d\\ng o v e r n a n c e\\nb y\\ng e n e r a t i n g\\ne v i d e n c e - b a s e d\\ni n s i g h t s ,\\nf o r e c a s t s ,\\no r\\nr e c o m m e n d a t i o n s .\\nT h i s\\nc a n\\nh e l p\\ng o v e r n m e n t s\\na n d\\no r g a n i z a t i o n s\\nm a k e\\nm o r e\\ni n f o r m e d ,\\ne \\x00 e c t i v e ,\\na n d\\ne q u i t a b l e\\nd e c i s i o n s\\nt h a t\\nb e t t e r\\ns e r v e\\nt h e\\nn e e d s\\na n d\\ni n t e r e s t s\\no f\\nt h e i r\\nc o n s t i t u e n t s .\\nF o s t e r i n g\\nC r e a t i v i t y\\na n d\\nI n n o v a t i o n\\nT h e\\nc o m b i n a t i o n\\no f\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\nc a n\\nl e a d\\nt o\\ng r o u n d b r e a k i n g\\ni n n o v a t i o n s\\na n d\\nd i s c o v e r i e s\\na c r o s s\\nv a r i o u s\\nd i s c i p l i n e s ,\\na s\\nd i s c u s s e d\\ni n\\nS e c t i o n\\n5 . 2 .\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\na c t\\na s\\na\\nc a t a l y s t\\nf o r\\nc r e a t i v i t y ,\\ne n a b l i n g\\ni n d i v i d u a l s\\na n d\\no r g a n i z a t i o n s\\nt o\\ne x p l o r e\\nn e w\\ni d e a s ,\\nc h a l l e n g e\\na s s u m p t i o n s ,\\na n d\\np u s h\\nt h e\\nb o u n d a r i e s\\no f\\nw h a t ' s\\np o s s i b l e .\\nA d d r e s s i n g\\nG l o b a l\\nC h a l l e n g e s\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\nh a r n e s s e d\\nt o\\ng e n e r a t e\\ns o l u t i o n s ,\\ns t r a t e g i e s ,\\no r\\ni d e a s\\nt o\\na d d r e s s\\nc o m p l e x\\ng l o b a l\\nc h a l l e n g e s ,\\ns u c h\\na s\\nc l i m a t e\\nc h a n g e ,\\np o v e r t y ,\\no r\\ni n e q u a l i t y .\\nB y\\nl e v e r a g i n g\\nA I - g e n e r a t e d\\nc o n t e n t\\na n d\\ni n s i g h t s ,\\nw e\\nc a n\\nd e v e l o p\\nm o r e\\ne \\x00 e c t i v e ,\\ns c a l a b l e ,\\na n d\\ns u s t a i n a b l e\\na p p r o a c h e s\\nt o\\nt a c k l i n g\\np r e s s i n g\\ns o c i e t a l\\ni s s u e s .\\nA s\\nt h e\\nA I - d r i v e n\\ne c o n o m y\\nc o n t i n u e s\\nt o\\ne v o l v e\\na n d\\ne x p a n d ,\\nt h e\\nr o l e\\no f\\np r o m p t\\ne n g i n e e r i n g\\nw i l l\\nb e c o m e\\ni n c r e a s i n g l y\\ns i g n i ﬁ c a n t\\na n d\\nt r a n s f o r m a t i v e\\na c r o s s\\nd i v e r s e\\ns e c t o r s\\na n d\\nd o m a i n s .\\nB y\\ne m b r a c i n g\\np r o m p t\\ne n g i n e e r i n g\\na n d\\ni t s\\np o t e n t i a l ,\\nw e\\nc a n\\ne n a b l e\\nm o r e\\ne \\x00 e c t i v e ,\\ne \\x00 c i e n t ,\\na n d\\ni n n o v a t i v e\\ns o l u t i o n s\\nt h a t\\nd r i v e\\np r o g r e s s ,\\ne n h a n c e\\nw e l l - b e i n g ,\\na n d\\nc r e a t e\\na\\nm o r e\\np r o s p e r o u s\\na n d\\ne q u i t a b l e\\nf u t u r e\\nf o r\\na l l .\\n2 9\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 29}), Document(page_content=\"C h a p t e r\\n6 :\\nP r a c t i c a l\\nT i p s\\na n d\\nB e s t\\nP r a c t i c e s\\nf o r\\nP r o m p t\\nE n g i n e e r i n g\\nB y\\nf o l l o w i n g\\nt h e s e\\np r a c t i c a l\\nt i p s\\na n d\\nb e s t\\np r a c t i c e s ,\\ny o u\\nc a n\\ng e t\\ns t a r t e d\\nw i t h\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nh a r n e s s\\ni t s\\np o t e n t i a l\\nt o\\nc r e a t e\\nh i g h - q u a l i t y ,\\ne n g a g i n g ,\\na n d\\ne \\x00 e c t i v e\\nA I - g e n e r a t e d\\nc o n t e n t .\\n6 . 1 .\\nG e t t i n g\\nS t a r t e d\\nw i t h\\nP r o m p t\\nE n g i n e e r i n g\\nF o r\\nd a t a\\ns c i e n t i s t s\\na n d\\np r a c t i t i o n e r s\\nl o o k i n g\\nt o\\nh a r n e s s\\nt h e\\np o w e r\\no f\\np r o m p t\\ne n g i n e e r i n g\\nf o r\\ng e n e r a t i v e\\nA I\\na p p l i c a t i o n s ,\\ng e t t i n g\\ns t a r t e d\\nc a n\\ns e e m\\nd a u n t i n g .\\nH o w e v e r ,\\nb y\\nf o l l o w i n g\\ns o m e\\np r a c t i c a l\\nt i p s\\na n d\\nb e s t\\np r a c t i c e s ,\\ny o u\\nc a n\\nb e g i n\\nl e v e r a g i n g\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 e c t i v e l y\\na n d\\ne \\x00 c i e n t l y .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\np r o v i d e\\ng u i d a n c e\\no n\\nh o w\\nt o\\ng e t\\ns t a r t e d\\nw i t h\\np r o m p t\\ne n g i n e e r i n g\\na n d\\ne n s u r e\\na\\ns u c c e s s f u l\\ni m p l e m e n t a t i o n .\\nU n d e r s t a n d\\nY o u r\\nA I\\nM o d e l\\nB e f o r e\\nd i v i n g\\ni n t o\\np r o m p t\\ne n g i n e e r i n g ,\\nf a m i l i a r i z e\\ny o u r s e l f\\nw i t h\\nt h e\\nA I\\nm o d e l\\ny o u ' r e\\nw o r k i n g\\nw i t h ,\\ni t s\\nc a p a b i l i t i e s ,\\na n d\\ni t s\\nl i m i t a t i o n s .\\nU n d e r s t a n d i n g\\nt h e\\nm o d e l ' s\\na r c h i t e c t u r e ,\\np r e - t r a i n i n g\\nd a t a ,\\na n d\\nﬁ n e - t u n i n g\\nm e t h o d s\\nc a n\\nh e l p\\ny o u\\nc r a f t\\nb e t t e r\\np r o m p t s\\na n d\\na n t i c i p a t e\\np o t e n t i a l\\ni s s u e s .\\nD e f i n e\\nC l e a r\\nO b j e c t i v e s\\nE s t a b l i s h\\nc l e a r\\no b j e c t i v e s\\nf o r\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t ,\\nc o n s i d e r i n g\\nf a c t o r s\\ns u c h\\na s\\nt h e\\nt a r g e t\\na u d i e n c e ,\\ni n t e n d e d\\np u r p o s e ,\\na n d\\nd e s i r e d\\no u t c o m e .\\nT h e s e\\no b j e c t i v e s\\nw i l l\\ng u i d e\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s\\na n d\\nh e l p\\ne n s u r e\\nt h e\\ng e n e r a t e d\\nc o n t e n t\\ni s\\nr e l e v a n t ,\\ne n g a g i n g ,\\na n d\\ne \\x00 e c t i v e .\\nS t a r t\\nS i m p l e\\nB e g i n\\nw i t h\\ns i m p l e ,\\no p e n - e n d e d\\np r o m p t s\\nt o\\ng a u g e\\nt h e\\nA I\\nm o d e l ' s\\nc a p a b i l i t i e s\\na n d\\ni d e n t i f y\\na n y\\nl i m i t a t i o n s\\no r\\nb i a s e s\\ni n\\ni t s\\no u t p u t s .\\nF r o m\\nt h e r e ,\\ny o u\\nc a n\\ni n c r e m e n t a l l y\\nr e ﬁ n e\\nt h e\\np r o m p t\\nt o\\np r o v i d e\\nm o r e\\ng u i d a n c e\\na n d\\ns t r u c t u r e\\nb a s e d\\no n\\nt h e\\nm o d e l ' s\\np e r f o r m a n c e\\na n d\\ny o u r\\no b j e c t i v e s .\\n3 0\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 30}), Document(page_content=\"I t e r a t e\\na n d\\nE x p e r i m e n t\\nP r o m p t\\ne n g i n e e r i n g\\ni s\\no f t e n\\na n\\ni t e r a t i v e\\np r o c e s s ,\\ni n v o l v i n g\\nt r i a l\\na n d\\ne r r o r\\na s\\ny o u\\nr e ﬁ n e\\na n d\\na d j u s t\\ny o u r\\np r o m p t s\\nt o\\na c h i e v e\\nt h e\\nb e s t\\nr e s u l t s .\\nE x p e r i m e n t\\nw i t h\\nd i \\x00 e r e n t\\np r o m p t\\ns t r u c t u r e s ,\\ng u i d a n c e\\nl e v e l s ,\\na n d\\nc o n t e x t\\nt o\\ni d e n t i f y\\nt h e\\no p t i m a l\\na p p r o a c h\\nf o r\\ny o u r\\ns p e c i ﬁ c\\na p p l i c a t i o n .\\nE v a l u a t e\\na n d\\nM o n i t o r\\nR e g u l a r l y\\ne v a l u a t e\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nu s i n g\\na\\nc o m b i n a t i o n\\no f\\nq u a n t i t a t i v e\\nm e t r i c s\\na n d\\nq u a l i t a t i v e\\na s s e s s m e n t s .\\nE s t a b l i s h\\nc l e a r\\nb e n c h m a r k s\\na n d\\np e r f o r m a n c e\\nc r i t e r i a\\nt o\\nm e a s u r e\\nt h e\\nq u a l i t y ,\\nr e l e v a n c e ,\\na n d\\na c c u r a c y\\no f\\nt h e\\nc o n t e n t ,\\na n d\\nu s e\\nt h i s\\nf e e d b a c k\\nt o\\nr e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l .\\nC o l l a b o r a t e\\na n d\\nL e a r n\\nf r o m\\nO t h e r s\\nP r o m p t\\ne n g i n e e r i n g\\ni s\\na\\ng r o w i n g\\nﬁ e l d ,\\nw i t h\\na\\nv i b r a n t\\nc o m m u n i t y\\no f\\nr e s e a r c h e r s\\na n d\\np r a c t i t i o n e r s\\ns h a r i n g\\ni n s i g h t s ,\\nt e c h n i q u e s ,\\na n d\\nb e s t\\np r a c t i c e s .\\nE n g a g e\\nw i t h\\nt h e\\nc o m m u n i t y ,\\nl e a r n\\nf r o m\\no t h e r s '\\ne x p e r i e n c e s ,\\na n d\\nc o l l a b o r a t e\\no n\\np r o j e c t s\\nt o\\nc o n t i n u o u s l y\\ni m p r o v e\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ns k i l l s\\na n d\\nk n o w l e d g e .\\nB e\\nM i n d f u l\\no f\\nE t h i c s\\na n d\\nR e s p o n s i b i l i t y\\nA s\\ny o u\\nd e v e l o p\\nA I - g e n e r a t e d\\nc o n t e n t ,\\na l w a y s\\nb e\\nm i n d f u l\\no f\\nt h e\\ne t h i c a l\\ni m p l i c a t i o n s\\na n d\\np o t e n t i a l\\nr i s k s\\na s s o c i a t e d\\nw i t h\\ny o u r\\nw o r k .\\nE n s u r e\\nt h a t\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l s\\na d h e r e\\nt o\\ne t h i c a l\\ng u i d e l i n e s\\na n d\\nr e s p o n s i b l e\\nA I\\np r a c t i c e s ,\\na n d\\ns t r i v e\\nt o\\nc r e a t e\\nc o n t e n t\\nt h a t\\ni s\\nf a i r ,\\ni n c l u s i v e ,\\na n d\\nr e s p e c t f u l .\\nB y\\nf o l l o w i n g\\nt h e s e\\np r a c t i c a l\\nt i p s\\na n d\\nb e s t\\np r a c t i c e s ,\\ny o u\\nc a n\\ng e t\\ns t a r t e d\\nw i t h\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nh a r n e s s\\ni t s\\np o t e n t i a l\\nt o\\nc r e a t e\\nh i g h - q u a l i t y ,\\ne n g a g i n g ,\\na n d\\ne \\x00 e c t i v e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nA s\\ny o u\\ng a i n\\ne x p e r i e n c e\\na n d\\ne x p e r t i s e ,\\ny o u ' l l\\nb e\\nb e t t e r\\ne q u i p p e d\\nt o\\nt a c k l e\\nm o r e\\nc o m p l e x\\na p p l i c a t i o n s\\na n d\\nc h a l l e n g e s ,\\nd r i v i n g\\ni n n o v a t i o n\\na n d\\np r o g r e s s\\ni n\\nt h e\\nr a p i d l y\\ne v o l v i n g\\nﬁ e l d\\no f\\ng e n e r a t i v e\\nA I .\\n6 . 2 .\\nB u i l d i n g\\na n\\nE \\x00 e c t i v e\\nP r o m p t\\nE n g i n e e r i n g\\nW o r k ﬂ o w\\nD e v e l o p i n g\\na\\ns t r u c t u r e d\\na n d\\ne \\x00 c i e n t\\np r o m p t\\ne n g i n e e r i n g\\nw o r k ﬂ o w\\ni s\\ne s s e n t i a l\\nf o r\\nc r e a t i n g\\nh i g h - q u a l i t y\\nA I - g e n e r a t e d\\nc o n t e n t\\nc o n s i s t e n t l y .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\nt h e\\nk e y\\nc o m p o n e n t s\\no f\\na n\\ne \\x00 e c t i v e\\np r o m p t\\ne n g i n e e r i n g\\nw o r k ﬂ o w\\na n d\\np r o v i d e\\np r a c t i c a l\\nt i p s\\no n\\nh o w\\nt o\\ns t r e a m l i n e\\na n d\\no p t i m i z e\\ny o u r\\np r o c e s s e s .\\n3 1\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 31}), Document(page_content=\"P l a n n i n g\\na n d\\nR e s e a r c h\\nS t a r t\\nb y\\nc o n d u c t i n g\\nt h o r o u g h\\nr e s e a r c h\\no n\\ny o u r\\nt o p i c ,\\nt a r g e t\\na u d i e n c e ,\\na n d\\nt h e\\nA I\\nm o d e l\\ny o u ' l l\\nb e\\nu s i n g .\\nT h i s\\nr e s e a r c h\\nw i l l\\nh e l p\\ny o u\\ni d e n t i f y\\nt h e\\nm o s t\\nr e l e v a n t\\ni n f o r m a t i o n ,\\nt r e n d s ,\\na n d\\ni n s i g h t s ,\\na n d\\nl a y\\nt h e\\ng r o u n d w o r k\\nf o r\\nc r a f t i n g\\ne \\x00 e c t i v e\\np r o m p t s .\\nO b j e c t i v e\\nS e t t i n g\\nD e ﬁ n e\\nc l e a r\\no b j e c t i v e s\\nf o r\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t ,\\nt a k i n g\\ni n t o\\nc o n s i d e r a t i o n\\nf a c t o r s\\ns u c h\\na s\\np u r p o s e ,\\na u d i e n c e ,\\na n d\\nd e s i r e d\\no u t c o m e s .\\nU s e\\nt h e s e\\no b j e c t i v e s\\na s\\na\\ng u i d e\\nt h r o u g h o u t\\nt h e\\np r o m p t\\ne n g i n e e r i n g\\np r o c e s s\\nt o\\ne n s u r e\\nt h a t\\nt h e\\ng e n e r a t e d\\nc o n t e n t\\ni s\\na l i g n e d\\nw i t h\\ny o u r\\ng o a l s .\\nD r a f t i n g\\nI n i t i a l\\nP r o m p t s\\nB a s e d\\no n\\ny o u r\\nr e s e a r c h\\na n d\\no b j e c t i v e s ,\\nd r a f t\\na\\ns e t\\no f\\ni n i t i a l\\np r o m p t s\\nt h a t\\np r o v i d e\\ng u i d a n c e\\na n d\\nc o n t e x t\\nf o r\\nt h e\\nA I\\nm o d e l .\\nS t a r t\\ns i m p l e ,\\na n d\\ni t e r a t i v e l y\\nr e ﬁ n e\\nt h e\\np r o m p t s\\na s\\nn e e d e d\\nt o\\ni m p r o v e\\nt h e\\nq u a l i t y\\na n d\\nr e l e v a n c e\\no f\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nT e s t i n g\\na n d\\nE v a l u a t i o n\\nT e s t\\ny o u r\\ni n i t i a l\\np r o m p t s\\nu s i n g\\nt h e\\nA I\\nm o d e l\\na n d\\ne v a l u a t e\\nt h e\\ng e n e r a t e d\\nc o n t e n t\\nb a s e d\\no n\\ne s t a b l i s h e d\\nb e n c h m a r k s\\na n d\\np e r f o r m a n c e\\nc r i t e r i a .\\nI d e n t i f y\\na n y\\ni s s u e s ,\\nb i a s e s ,\\no r\\ni n a c c u r a c i e s\\ni n\\nt h e\\nc o n t e n t ,\\na n d\\nu s e\\nt h i s\\nf e e d b a c k\\nt o\\nr e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\ni m p r o v e\\nt h e\\nA I\\nm o d e l ' s\\np e r f o r m a n c e .\\nI t e r a t i o n\\na n d\\nR e f i n e m e n t\\nP r o m p t\\ne n g i n e e r i n g\\ni s\\na n\\ni t e r a t i v e\\np r o c e s s ,\\ns o\\nc o n t i n u a l l y\\nr e ﬁ n e\\na n d\\na d j u s t\\ny o u r\\np r o m p t s\\nb a s e d\\no n\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t ' s\\np e r f o r m a n c e\\na n d\\nf e e d b a c k .\\nE x p e r i m e n t\\nw i t h\\nd i \\x00 e r e n t\\np r o m p t\\ns t r u c t u r e s ,\\ng u i d a n c e\\nl e v e l s ,\\na n d\\nc o n t e x t\\nt o\\no p t i m i z e\\nt h e\\nq u a l i t y\\na n d\\nr e l e v a n c e\\no f\\nt h e\\ng e n e r a t e d\\nc o n t e n t .\\nM o n i t o r i n g\\na n d\\nM a i n t e n a n c e\\nR e g u l a r l y\\nm o n i t o r\\nt h e\\np e r f o r m a n c e\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\na n d\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\ny o u r\\np r o m p t s .\\nK e e p\\nt r a c k\\no f\\na n y\\nc h a n g e s\\ni n\\nt h e\\nt a r g e t\\na u d i e n c e ,\\nt o p i c ,\\no r\\nA I\\nm o d e l ,\\na n d\\na d j u s t\\ny o u r\\np r o m p t s\\na c c o r d i n g l y\\nt o\\nm a i n t a i n\\nc o n t e n t\\nq u a l i t y\\na n d\\nr e l e v a n c e .\\nC o l l a b o r a t i o n\\na n d\\nC o n t i n u o u s\\nL e a r n i n g\\nC o l l a b o r a t e\\nw i t h\\no t h e r\\nd a t a\\ns c i e n t i s t s ,\\nr e s e a r c h e r s ,\\na n d\\np r a c t i t i o n e r s\\nt o\\ns h a r e\\ni n s i g h t s ,\\nt e c h n i q u e s ,\\na n d\\nb e s t\\np r a c t i c e s .\\nS t a y\\nu p\\nt o\\nd a t e\\nw i t h\\nt h e\\nl a t e s t\\na d v a n c e m e n t s\\ni n\\nA I\\nr e s e a r c h\\na n d\\n3 2\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 32}), Document(page_content=\"p r o m p t\\ne n g i n e e r i n g ,\\na n d\\nc o n t i n u o u s l y\\ni m p r o v e\\ny o u r\\ns k i l l s\\na n d\\nk n o w l e d g e\\nt o\\ns t a y\\na h e a d\\ni n\\nt h e\\nﬁ e l d .\\nB y\\nb u i l d i n g\\na n\\ne \\x00 e c t i v e\\np r o m p t\\ne n g i n e e r i n g\\nw o r k ﬂ o w ,\\ny o u\\nc a n\\ns t r e a m l i n e\\ny o u r\\np r o c e s s e s ,\\ne n h a n c e\\nt h e\\nq u a l i t y\\na n d\\nr e l e v a n c e\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t ,\\na n d\\ne n s u r e\\nt h a t\\ny o u r\\np r o j e c t s\\na r e\\na l i g n e d\\nw i t h\\ny o u r\\no b j e c t i v e s\\na n d\\ng o a l s .\\nT h i s\\ns t r u c t u r e d\\na p p r o a c h\\nn o t\\no n l y\\nh e l p s\\ny o u\\nc r e a t e\\ne n g a g i n g\\na n d\\ne \\x00 e c t i v e\\nc o n t e n t\\nb u t\\na l s o\\nc o n t r i b u t e s\\nt o\\ny o u r\\nl o n g - t e r m\\ns u c c e s s\\na n d\\ng r o w t h\\ni n\\nt h e\\nr a p i d l y\\ne v o l v i n g\\nﬁ e l d\\no f\\ng e n e r a t i v e\\nA I .\\n6 . 3 .\\nO v e r c o m i n g\\nC o m m o n\\nC h a l l e n g e s\\ni n\\nP r o m p t\\nE n g i n e e r i n g\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\np r e s e n t\\na\\nv a r i e t y\\no f\\nc h a l l e n g e s ,\\nf r o m\\na d d r e s s i n g\\nA I\\nm o d e l\\nl i m i t a t i o n s\\nt o\\nc r a f t i n g\\ne \\x00 e c t i v e\\np r o m p t s\\nt h a t\\ng e n e r a t e\\nt h e\\nd e s i r e d\\nc o n t e n t .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\nc o m m o n\\nc h a l l e n g e s\\ni n\\np r o m p t\\ne n g i n e e r i n g\\na n d\\np r o v i d e\\np r a c t i c a l\\nt i p s\\no n\\nh o w\\nt o\\no v e r c o m e\\nt h e m .\\nD e a l i n g\\nw i t h\\nA I\\nM o d e l\\nL i m i t a t i o n s\\nA I\\nm o d e l s\\nm a y\\nh a v e\\nl i m i t a t i o n s\\ni n\\nt h e i r\\nu n d e r s t a n d i n g\\no f\\nc e r t a i n\\nt o p i c s ,\\nc o n t e x t s ,\\no r\\nn u a n c e s .\\nT o\\na d d r e s s\\nt h e s e\\nl i m i t a t i o n s ,\\ny o u\\nc a n\\ne x p e r i m e n t\\nw i t h\\nd i \\x00 e r e n t\\np r o m p t\\ns t r u c t u r e s ,\\nﬁ n e - t u n e\\nt h e\\nA I\\nm o d e l\\no n\\nd o m a i n - s p e c i ﬁ c\\nd a t a ,\\no r\\nc o m b i n e\\nt h e\\no u t p u t s\\no f\\nm u l t i p l e\\nA I\\nm o d e l s\\nt o\\ne n h a n c e\\nt h e\\ng e n e r a t e d\\nc o n t e n t ' s\\nq u a l i t y .\\nH a n d l i n g\\nA I\\nM o d e l\\nB i a s\\nA I\\nm o d e l s\\nc a n\\ns o m e t i m e s\\ne x h i b i t\\nb i a s e s\\np r e s e n t\\ni n\\nt h e i r\\nt r a i n i n g\\nd a t a .\\nT o\\nm i t i g a t e\\nt h e s e\\nb i a s e s ,\\ny o u\\nc a n\\ne m p l o y\\nt e c h n i q u e s\\ns u c h\\na s\\nb i a s - a w a r e\\np r o m p t\\ne n g i n e e r i n g\\no r\\nl e v e r a g e\\ne x t e r n a l\\nt o o l s\\na n d\\nr e s o u r c e s\\nt o\\ni d e n t i f y\\na n d\\nc o r r e c t\\nb i a s e d\\no u t p u t s .\\nS t r i k i n g\\nt h e\\nR i g h t\\nB a l a n c e\\no f\\nG u i d a n c e\\nF i n d i n g\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\np r o v i d i n g\\nt o o\\nm u c h\\no r\\nt o o\\nl i t t l e\\ng u i d a n c e\\ni n\\np r o m p t s\\nc a n\\nb e\\nc h a l l e n g i n g .\\nT o\\ns t r i k e\\nt h e\\nr i g h t\\nb a l a n c e ,\\ne x p e r i m e n t\\nw i t h\\nv a r y i n g\\nl e v e l s\\no f\\ns p e c i ﬁ c i t y ,\\nc o n t e x t ,\\na n d\\nc o n s t r a i n t\\ni n\\ny o u r\\np r o m p t s ,\\na n d\\ni t e r a t i v e l y\\nr e ﬁ n e\\nt h e m\\nb a s e d\\no n\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t ' s\\np e r f o r m a n c e\\na n d\\ny o u r\\no b j e c t i v e s .\\nE n s u r i n g\\nC o n t e n t\\nQ u a l i t y\\na n d\\nR e l e v a n c e\\nE n s u r i n g\\nt h a t\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nm e e t s\\ny o u r\\nq u a l i t y\\na n d\\nr e l e v a n c e\\nc r i t e r i a\\nc a n\\nb e\\na\\nd a u n t i n g\\nt a s k .\\nE s t a b l i s h\\nc l e a r\\nb e n c h m a r k s\\na n d\\np e r f o r m a n c e\\nc r i t e r i a ,\\na n d\\nu s e\\na\\nc o m b i n a t i o n\\no f\\n3 3\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 33}), Document(page_content=\"q u a n t i t a t i v e\\nm e t r i c s\\na n d\\nq u a l i t a t i v e\\na s s e s s m e n t s\\nt o\\ne v a l u a t e\\nt h e\\nc o n t e n t .\\nR e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l\\na c c o r d i n g l y\\nt o\\ni m p r o v e\\nt h e\\nc o n t e n t ' s\\nq u a l i t y\\na n d\\nr e l e v a n c e .\\nO v e r c o m i n g\\nC r e a t i v e\\nB l o c k s\\nA I - g e n e r a t e d\\nc o n t e n t\\nm a y\\ns o m e t i m e s\\nl a c k\\nc r e a t i v i t y\\no r\\nf a l l\\ns h o r t\\no f\\ny o u r\\ne x p e c t a t i o n s .\\nI n\\ns u c h\\nc a s e s ,\\nc o n s i d e r\\ne x p e r i m e n t i n g\\nw i t h\\nm o r e\\no p e n - e n d e d\\np r o m p t s ,\\nl e v e r a g i n g\\nm u l t i - m o d a l\\nA I\\nm o d e l s ,\\no r\\nc o m b i n i n g\\nt h e\\no u t p u t s\\no f\\nm u l t i p l e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nm o r e\\nc r e a t i v e\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nA d d r e s s i n g\\nE t h i c a l\\nC o n c e r n s\\nP r o m p t\\ne n g i n e e r i n g\\nr a i s e s\\ne t h i c a l\\nq u e s t i o n s\\na n d\\nc h a l l e n g e s ,\\ns u c h\\na s\\nf a i r n e s s ,\\ni n c l u s i v i t y ,\\na n d\\nr e s p o n s i b i l i t y .\\nT o\\na d d r e s s\\nt h e s e\\nc o n c e r n s ,\\ne n s u r e\\nt h a t\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l s\\na d h e r e\\nt o\\ne t h i c a l\\ng u i d e l i n e s\\na n d\\nr e s p o n s i b l e\\nA I\\np r a c t i c e s ,\\na n d\\ns t r i v e\\nt o\\nc r e a t e\\nc o n t e n t\\nt h a t\\ni s\\nf a i r ,\\ni n c l u s i v e ,\\na n d\\nr e s p e c t f u l .\\nB y\\nu n d e r s t a n d i n g\\na n d\\na d d r e s s i n g\\nt h e s e\\nc o m m o n\\nc h a l l e n g e s\\ni n\\np r o m p t\\ne n g i n e e r i n g ,\\ny o u\\nc a n\\nc r e a t e\\nm o r e\\ne \\x00 e c t i v e ,\\ne n g a g i n g ,\\na n d\\nh i g h - q u a l i t y\\nA I - g e n e r a t e d\\nc o n t e n t .\\nA s\\ny o u\\nc o n t i n u e\\nt o\\nr e ﬁ n e\\ny o u r\\ns k i l l s\\na n d\\no v e r c o m e\\nt h e s e\\nc h a l l e n g e s ,\\ny o u ' l l\\nb e\\nb e t t e r\\ne q u i p p e d\\nt o\\nh a r n e s s\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nd r i v e\\ni n n o v a t i o n\\ni n\\nt h e\\nr a p i d l y\\ne v o l v i n g\\nﬁ e l d\\no f\\ng e n e r a t i v e\\nA I .\\n6 . 4 .\\nM e a s u r i n g\\nt h e\\nS u c c e s s\\no f\\nY o u r\\nP r o m p t\\nE n g i n e e r i n g\\nE \\x00 o r t s\\nT o\\ne n s u r e\\nt h a t\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s\\na r e\\ns u c c e s s f u l ,\\ni t ' s\\nc r u c i a l\\nt o\\ne s t a b l i s h\\nc l e a r\\nm e t r i c s\\na n d\\nb e n c h m a r k s\\nf o r\\ne v a l u a t i n g\\nt h e\\np e r f o r m a n c e\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\nk e y\\np e r f o r m a n c e\\ni n d i c a t o r s\\n( K P I s )\\na n d\\nb e s t\\np r a c t i c e s\\nf o r\\nm e a s u r i n g\\nt h e\\ns u c c e s s\\no f\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s .\\nC o n t e n t\\nQ u a l i t y\\nM e t r i c s\\nA s s e s s\\nt h e\\nq u a l i t y\\no f\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nc o n s i d e r i n g\\nf a c t o r s\\ns u c h\\na s\\nc o h e r e n c e ,\\nc o n s i s t e n c y ,\\ng r a m m a t i c a l\\nc o r r e c t n e s s ,\\na n d\\nr e a d a b i l i t y .\\nU t i l i z e\\nt o o l s\\nl i k e\\nr e a d a b i l i t y\\ns c o r e s ,\\ng r a m m a r\\nc h e c k e r s ,\\no r\\nh u m a n\\ne v a l u a t i o n\\nt o\\ne n s u r e\\nt h a t\\ny o u r\\nc o n t e n t\\nm e e t s\\ny o u r\\nq u a l i t y\\ns t a n d a r d s .\\n3 4\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 34}), Document(page_content=\"C o n t e n t\\nR e l e v a n c e\\nM e t r i c s\\nE v a l u a t e\\nt h e\\nr e l e v a n c e\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nd e t e r m i n i n g\\nh o w\\nw e l l\\ni t\\na l i g n s\\nw i t h\\ny o u r\\no b j e c t i v e s ,\\nt a r g e t\\na u d i e n c e ,\\na n d\\ni n t e n d e d\\np u r p o s e .\\nU s e\\na\\nc o m b i n a t i o n\\no f\\nq u a l i t a t i v e\\na s s e s s m e n t s ,\\nu s e r\\nf e e d b a c k ,\\na n d\\nc o n t e n t\\ne n g a g e m e n t\\nm e t r i c s\\n( e . g . ,\\nc l i c k - t h r o u g h\\nr a t e s ,\\nc o n v e r s i o n s ,\\no r\\nt i m e\\ns p e n t )\\nt o\\ng a u g e\\nr e l e v a n c e .\\nC o n t e n t\\nN o v e l t y\\na n d\\nC r e a t i v i t y\\nM e t r i c s\\nM e a s u r e\\nt h e\\nn o v e l t y\\na n d\\nc r e a t i v i t y\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nc o n s i d e r i n g\\nf a c t o r s\\ns u c h\\na s\\nu n i q u e n e s s ,\\no r i g i n a l i t y ,\\na n d\\nu n e x p e c t e d n e s s .\\nY o u\\nc a n\\nu s e\\nt o o l s\\nl i k e\\np l a g i a r i s m\\nc h e c k e r s ,\\ns i m i l a r i t y\\ns c o r e s ,\\no r\\nh u m a n\\ne v a l u a t i o n\\nt o\\na s s e s s\\nt h e\\nn o v e l t y\\na n d\\nc r e a t i v i t y\\no f\\ny o u r\\nc o n t e n t .\\nC o n t e n t\\nA c c u r a c y\\nM e t r i c s\\nE v a l u a t e\\nt h e\\na c c u r a c y\\no f\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nc o m p a r i n g\\ni t\\nt o\\nr e l i a b l e\\ns o u r c e s ,\\ng r o u n d\\nt r u t h ,\\no r\\ne x p e r t\\nk n o w l e d g e .\\nU s e\\na\\nc o m b i n a t i o n\\no f\\nq u a n t i t a t i v e\\nm e t r i c s\\n( e . g . ,\\nf a c t - c h e c k i n g\\ns c o r e s )\\na n d\\nq u a l i t a t i v e\\na s s e s s m e n t s\\nt o\\ne n s u r e\\ny o u r\\nc o n t e n t\\ni s\\na c c u r a t e\\na n d\\nt r u s t w o r t h y .\\nU s e r\\nS a t i s f a c t i o n\\nM e t r i c s\\nA s s e s s\\nu s e r\\ns a t i s f a c t i o n\\nw i t h\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nc o l l e c t i n g\\nf e e d b a c k\\nt h r o u g h\\ns u r v e y s ,\\nr a t i n g s ,\\no r\\nc o m m e n t s .\\nA n a l y z e\\nt h i s\\nf e e d b a c k\\nt o\\ni d e n t i f y\\na r e a s\\nf o r\\ni m p r o v e m e n t\\na n d\\nr e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l\\na c c o r d i n g l y .\\nE f f i c i e n c y\\nM e t r i c s\\nE v a l u a t e\\nt h e\\ne \\x00 c i e n c y\\no f\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s\\nb y\\nc o n s i d e r i n g\\nf a c t o r s\\ns u c h\\na s\\nt h e\\nt i m e\\nt a k e n\\nt o\\ng e n e r a t e\\nc o n t e n t ,\\nt h e\\nn u m b e r\\no f\\ni t e r a t i o n s\\nr e q u i r e d ,\\na n d\\nt h e\\nc o s t\\no f\\nA I\\nm o d e l\\nu s a g e .\\nU s e\\nt h e s e\\nm e t r i c s\\nt o\\no p t i m i z e\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\nw o r k ﬂ o w\\na n d\\ne n s u r e\\nt h a t\\ny o u ' r e\\ng e n e r a t i n g\\nh i g h - q u a l i t y\\nc o n t e n t\\ni n\\na\\nc o s t - e \\x00 e c t i v e\\na n d\\nt i m e l y\\nm a n n e r .\\nA d a p t a b i l i t y\\nM e t r i c s\\nA s s e s s\\nt h e\\na d a p t a b i l i t y\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nc o n s i d e r i n g\\nh o w\\nw e l l\\ni t\\nc a n\\nb e\\nr e p u r p o s e d\\no r\\nr e u s e d\\na c r o s s\\nd i \\x00 e r e n t\\nc h a n n e l s ,\\nf o r m a t s ,\\no r\\nc o n t e x t s .\\nT r a c k\\nt h e\\np e r f o r m a n c e\\no f\\ny o u r\\nc o n t e n t\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\nt o\\ng a u g e\\ni t s\\nv e r s a t i l i t y\\na n d\\na d a p t a b i l i t y .\\nB y\\ne s t a b l i s h i n g\\nc l e a r\\nK P I s\\na n d\\nb e n c h m a r k s\\nf o r\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s ,\\ny o u\\nc a n\\ne \\x00 e c t i v e l y\\nm e a s u r e\\nt h e\\ns u c c e s s\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\na n d\\ne n s u r e\\nt h a t\\ni t\\nm e e t s\\ny o u r\\nq u a l i t y ,\\nr e l e v a n c e ,\\na n d\\np e r f o r m a n c e\\nc r i t e r i a .\\nT h i s\\nd a t a - d r i v e n\\na p p r o a c h\\nn o t\\no n l y\\nh e l p s\\ny o u\\n3 5\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 35}), Document(page_content='o p t i m i z e\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l\\nb u t\\na l s o\\ne n a b l e s\\ny o u\\nt o\\nc o n t i n u o u s l y\\ni m p r o v e\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ns k i l l s\\na n d\\nd r i v e\\ni n n o v a t i o n\\ni n\\nt h e\\nr a p i d l y\\ne v o l v i n g\\nﬁ e l d\\no f\\ng e n e r a t i v e\\nA I .\\n3 6\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 36}), Document(page_content=\"C o n c l u s i o n\\nI n\\nt h i s\\ns h o r t\\ne b o o k ,\\nw e\\nh a v e\\ne x p l o r e d\\nt h e\\nf a s c i n a t i n g\\nw o r l d\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g ,\\nd e l v i n g\\ni n t o\\nk e y\\nc o n c e p t s ,\\nb e s t\\np r a c t i c e s ,\\na n d\\np o t e n t i a l\\nf u t u r e\\nt r e n d s\\ni n\\nt h i s\\nr a p i d l y\\ne v o l v i n g\\nﬁ e l d .\\nA s\\nA I\\nt e c h n o l o g i e s\\nc o n t i n u e\\nt o\\na d v a n c e\\na n d\\nr e s h a p e\\nv a r i o u s\\na s p e c t s\\no f\\no u r\\nl i v e s ,\\nt h e\\nr o l e\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni n\\ne n h a n c i n g\\nt h e\\nq u a l i t y ,\\nr e l e v a n c e ,\\na n d\\nc r e a t i v i t y\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\nw i l l\\ng r o w\\ni n c r e a s i n g l y\\ns i g n i ﬁ c a n t .\\nR e c a p\\no f\\nk e y\\nc o n c e p t s\\na n d\\nb e s t\\np r a c t i c e s :\\n●\\nW e\\nh a v e\\nc o v e r e d\\nt h e\\nf u n d a m e n t a l s\\no f\\ng e n e r a t i v e\\nA I\\na n d\\nt h e\\ni m p o r t a n c e\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni n\\ng u i d i n g\\nA I\\nm o d e l s\\nt o\\np r o d u c e\\nh i g h - q u a l i t y\\nc o n t e n t\\n●\\nW e\\nh a v e\\nd i s c u s s e d\\nd i \\x00 e r e n t\\nt y p e s\\no f\\np r o m p t s ,\\nt e c h n i q u e s\\nf o r\\np r o m p t\\ne n g i n e e r i n g ,\\na n d\\np r a c t i c a l\\nt i p s\\nt o\\nc r e a t e\\na n\\ne \\x00 e c t i v e\\np r o m p t\\ne n g i n e e r i n g\\nw o r k ﬂ o w\\n●\\nW e\\nh a v e\\ne x a m i n e d\\nc o m m o n\\nc h a l l e n g e s\\na n d\\ne t h i c a l\\nc o n s i d e r a t i o n s ,\\na s\\nw e l l\\na s\\nv a r i o u s\\nm e t r i c s\\nf o r\\nm e a s u r i n g\\nt h e\\ns u c c e s s\\no f\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s\\nF u t u r e\\nt r e n d s\\ni n\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g :\\n●\\nA s\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nb e c o m e\\nm o r e\\ns o p h i s t i c a t e d\\na n d\\nc a p a b l e ,\\np r o m p t\\ne n g i n e e r i n g\\nw i l l\\nc o n t i n u e\\nt o\\ne v o l v e ,\\nu n l o c k i n g\\nn e w\\np o s s i b i l i t i e s\\na n d\\na p p l i c a t i o n s\\na c r o s s\\nd i v e r s e\\ns e c t o r s\\n●\\nF r o m\\ne n h a n c i n g\\nb u s i n e s s\\nc o m m u n i c a t i o n s\\na n d\\np e r s o n a l i z i n g\\nc u s t o m e r\\ne x p e r i e n c e s\\nt o\\nf o s t e r i n g\\nc r e a t i v i t y\\na n d\\na d d r e s s i n g\\ng l o b a l\\nc h a l l e n g e s ,\\np r o m p t\\ne n g i n e e r i n g\\nw i l l\\np l a y\\na\\nc r i t i c a l\\nr o l e\\ni n\\nl e v e r a g i n g\\nA I - g e n e r a t e d\\nc o n t e n t\\nt o\\nd r i v e\\np r o g r e s s\\na n d\\ni n n o v a t i o n\\nI n\\nc o n c l u s i o n ,\\nw e\\ne n c o u r a g e\\ny o u ,\\nt h e\\nr e a d e r ,\\nt o\\ne x p e r i m e n t\\nw i t h\\na n d\\ni n n o v a t e\\ni n\\nt h e\\nr e a l m\\no f\\np r o m p t\\ne n g i n e e r i n g .\\nA s\\ny o u\\nd e l v e\\nd e e p e r\\ni n t o\\nt h i s\\nﬁ e l d ,\\nh a r n e s s\\ny o u r\\nc r e a t i v i t y ,\\nc o l l a b o r a t e\\nw i t h\\no t h e r s ,\\na n d\\np u s h\\nt h e\\nb o u n d a r i e s\\no f\\nw h a t ' s\\np o s s i b l e .\\nB y\\nd o i n g\\ns o ,\\ny o u\\nw i l l\\nn o t\\no n l y\\nc o n t r i b u t e\\nt o\\nt h e\\na d v a n c e m e n t\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g\\nb u t\\na l s o\\nc r e a t e\\na\\nm o r e\\np r o s p e r o u s ,\\ne q u i t a b l e ,\\na n d\\ns u s t a i n a b l e\\nf u t u r e\\nf o r\\na l l .\\nA r m e d\\nw i t h\\nt h e\\nk n o w l e d g e\\na n d\\ni n s i g h t s\\ns h a r e d\\ni n\\nt h i s\\ne b o o k ,\\nw e\\nh o p e\\ny o u\\na r e\\ni n s p i r e d\\nt o\\ne x p l o r e\\nt h e\\ni n c r e d i b l e\\np o t e n t i a l\\no f\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nu n l o c k\\nn e w\\no p p o r t u n i t i e s\\nf o r\\ni n n o v a t i o n\\na n d\\ng r o w t h\\ni n\\nt h e\\ne v e r - e x p a n d i n g\\nw o r l d\\no f\\ng e n e r a t i v e\\nA I .\\n3 7\\n\", metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 37}), Document(page_content='A p p e n d i x\\nA :\\nR e c o m m e n d e d\\nB o o k s ,\\nA r t i c l e s ,\\na n d\\nB l o g s\\nT o\\nf u r t h e r\\ne x p a n d\\ny o u r\\nk n o w l e d g e\\na n d\\nu n d e r s t a n d i n g\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g ,\\nw e\\nh a v e\\nc o m p i l e d\\na\\nl i s t\\no f\\nr e c o m m e n d e d\\nb o o k s ,\\na r t i c l e s ,\\na n d\\nc o u r s e s\\nt h a t\\nc a n\\np r o v i d e\\na d d i t i o n a l\\ni n s i g h t s ,\\np r a c t i c a l\\ne x a m p l e s ,\\na n d\\ng u i d a n c e .\\nB o o k s :\\n●\\n\" D e e p\\nL e a r n i n g \"\\nb y\\nI a n\\nG o o d f e l l o w ,\\nY o s h u a\\nB e n g i o ,\\na n d\\nA a r o n\\nC o u r v i l l e\\n●\\n\" G e n e r a t i v e\\nD e e p\\nL e a r n i n g :\\nT e a c h i n g\\nM a c h i n e s\\nt o\\nP a i n t ,\\nW r i t e ,\\nC o m p o s e ,\\na n d\\nP l a y \"\\nb y\\nD a v i d\\nF o s t e r\\n●\\n\" H a n d s - O n\\nM a c h i n e\\nL e a r n i n g\\nw i t h\\nS c i k i t - L e a r n ,\\nK e r a s\\na n d\\nT e n s o r F l o w \"\\nb y\\nA u r é l i e n\\nG é r o n\\n●\\n\" P a t t e r n\\nR e c o g n i t i o n\\na n d\\nM a c h i n e\\nL e a r n i n g \"\\nb y\\nC h r i s t o p h e r\\nM .\\nB i s h o p\\n●\\n\" H u m a n\\nC o m p a t i b l e :\\nA r t i ﬁ c i a l\\nI n t e l l i g e n c e\\na n d\\nt h e\\nP r o b l e m\\no f\\nC o n t r o l \"\\nb y\\nS t u a r t\\nR u s s e l l\\nA r t i c l e s :\\n●\\n\" T h e\\nI l l u s t r a t e d\\nG P T - 2\\n( V i s u a l i z i n g\\nT r a n s f o r m e r\\nL a n g u a g e\\nM o d e l s ) \"\\nb y\\nJ a y\\nA l a m m a r\\n●\\n\" T h e\\nA n n o t a t e d\\nG P T - 3 \"\\nb y\\nJ o n a t h a n\\nH u i\\n●\\n\" B e t t e r\\nL a n g u a g e\\nM o d e l s\\na n d\\nT h e i r\\nI m p l i c a t i o n s \"\\nb y\\nO p e n A I\\n●\\n\" L a n g u a g e\\nM o d e l s\\na r e\\nF e w - S h o t\\nL e a r n e r s \"\\nb y\\nO p e n A I\\n●\\n\" B u i l d i n g\\nA I\\nA p p l i c a t i o n s\\nw i t h\\nO p e n A I \\' s\\nG P T - 3 :\\nA\\nP r a c t i c a l\\nG u i d e \"\\nb y\\nH a r r i s o n\\nK i n s l e y\\nO n l i n e\\nC o u r s e s :\\n●\\nC o u r s e r a :\\n\" D e e p\\nL e a r n i n g\\nS p e c i a l i z a t i o n \"\\nb y\\nA n d r e w\\nN g\\n●\\nC o u r s e r a :\\n\" N a t u r a l\\nL a n g u a g e\\nP r o c e s s i n g\\nS p e c i a l i z a t i o n \"\\nb y\\nN a t i o n a l\\nR e s e a r c h\\nU n i v e r s i t y\\nH i g h e r\\nS c h o o l\\no f\\nE c o n o m i c s\\n●\\nf a s t . a i :\\n\" P r a c t i c a l\\nD e e p\\nL e a r n i n g\\nf o r\\nC o d e r s \"\\n●\\ne d X :\\n\" C S 2 2 4 N :\\nN a t u r a l\\nL a n g u a g e\\nP r o c e s s i n g\\nw i t h\\nD e e p\\nL e a r n i n g \"\\nb y\\nS t a n f o r d\\n●\\nM I T\\nO p e n C o u r s e W a r e :\\n\" 6 . S 1 9 1 :\\nI n t r o d u c t i o n\\nt o\\nD e e p\\nL e a r n i n g \"\\nb y\\nM I T\\nO n l i n e\\nR e s o u r c e s\\na n d\\nB l o g s :\\n●\\nO p e n A I\\nB l o g\\n(\\nh t t p s : / / o p e n a i . c o m / b l o g /\\n)\\n●\\nG o o g l e\\nA I\\nB l o g\\n(\\nh t t p s : / / a i . g o o g l e b l o g . c o m /\\n)\\n●\\nD i s t i l l\\n(\\nh t t p s : / / d i s t i l l . p u b /\\n)\\n●\\nM a c h i n e\\nL e a r n i n g\\nM a s t e r y\\n(\\nh t t p s : / / m a c h i n e l e a r n i n g m a s t e r y . c o m /\\n)\\n3 8\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 38}), Document(page_content='T h e s e\\nr e s o u r c e s\\nw i l l\\nh e l p\\ny o u\\nd e e p e n\\ny o u r\\nu n d e r s t a n d i n g\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g ,\\ns t a y\\nu p d a t e d\\no n\\nt h e\\nl a t e s t\\na d v a n c e m e n t s\\na n d\\nb r e a k t h r o u g h s\\ni n\\nt h e\\nﬁ e l d ,\\na n d\\ne n h a n c e\\ny o u r\\ns k i l l s\\na n d\\ne x p e r t i s e .\\nB y\\nc o n t i n u a l l y\\nl e a r n i n g ,\\ne x p e r i m e n t i n g ,\\na n d\\nc o l l a b o r a t i n g ,\\ny o u\\nw i l l\\nb e\\nw e l l - e q u i p p e d\\nt o\\nt h r i v e\\ni n\\nt h e\\ne x c i t i n g\\na n d\\nr a p i d l y\\ne v o l v i n g\\nw o r l d\\no f\\ng e n e r a t i v e\\nA I .\\n3 9\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 39}), Document(page_content='A p p e n d i x\\nB :\\nO n l i n e\\nC o m m u n i t i e s\\na n d\\nF o r u m s\\nf o r\\nD i s c u s s i o n s\\na n d\\nC o l l a b o r a t i o n\\nE n g a g i n g\\nw i t h\\no n l i n e\\nc o m m u n i t i e s\\na n d\\nf o r u m s\\ni s\\na n\\ne x c e l l e n t\\nw a y\\nt o\\nl e a r n ,\\ns h a r e\\ni d e a s ,\\na n d\\nc o l l a b o r a t e\\nw i t h\\no t h e r s\\nw h o\\na r e\\ni n t e r e s t e d\\ni n\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g .\\nH e r e\\ni s\\na\\nl i s t\\no f\\np o p u l a r\\no n l i n e\\np l a t f o r m s\\nw h e r e\\ny o u\\nc a n\\nd i s c u s s ,\\na s k\\nq u e s t i o n s ,\\na n d\\nc o n n e c t\\nw i t h\\nl i k e - m i n d e d\\ni n d i v i d u a l s\\na n d\\ne x p e r t s\\ni n\\nt h e\\nﬁ e l d .\\nA I\\nS t a c k\\nE x c h a n g e\\n(\\nh t t p s : / / a i . s t a c k e x c h a n g e . c o m /\\n)\\nA\\nq u e s t i o n\\na n d\\na n s w e r\\np l a t f o r m\\nf o r\\np e o p l e\\ni n t e r e s t e d\\ni n\\nA I\\nc o n c e p t s ,\\nr e s e a r c h ,\\na n d\\na p p l i c a t i o n s .\\nA s k\\nq u e s t i o n s ,\\np r o v i d e\\na n s w e r s ,\\no r\\nb r o w s e\\nt h r o u g h\\ne x i s t i n g\\nd i s c u s s i o n s\\nt o\\ne n h a n c e\\ny o u r\\nk n o w l e d g e .\\nM a c h i n e\\nL e a r n i n g\\nS u b r e d d i t\\n(\\nh t t p s : / / w w w . r e d d i t . c o m / r / M a c h i n e L e a r n i n g /\\n)\\nA\\np o p u l a r\\ns u b r e d d i t\\nf o r\\nd i s c u s s i n g\\nt o p i c s\\nr e l a t e d\\nt o\\nm a c h i n e\\nl e a r n i n g ,\\nd e e p\\nl e a r n i n g ,\\na n d\\ng e n e r a t i v e\\nA I .\\nS h a r e\\ny o u r\\np r o j e c t s ,\\na s k\\nq u e s t i o n s ,\\na n d\\ne n g a g e\\nw i t h\\na\\nd i v e r s e\\nc o m m u n i t y\\no f\\nl e a r n e r s ,\\nr e s e a r c h e r s ,\\na n d\\np r o f e s s i o n a l s .\\nA I\\ns e c t i o n\\no n\\na r X i v\\n(\\nh t t p s : / / a r x i v . o r g / l i s t / c s . A I / r e c e n t\\n)\\nA\\nr e p o s i t o r y\\no f\\np r e p r i n t s\\nf o r\\nA I\\nr e s e a r c h\\np a p e r s .\\nB r o w s e\\nt h e\\nl a t e s t\\nr e s e a r c h ,\\np r o v i d e\\nf e e d b a c k ,\\na n d\\ne n g a g e\\ni n\\nd i s c u s s i o n s\\nw i t h\\no t h e r\\nr e s e a r c h e r s\\na n d\\np r a c t i t i o n e r s .\\nD e e p\\nL e a r n i n g\\nS u b r e d d i t\\n(\\nh t t p s : / / w w w . r e d d i t . c o m / r / d e e p l e a r n i n g /\\n)\\nA\\ns u b r e d d i t\\nd e d i c a t e d\\nt o\\nd e e p\\nl e a r n i n g\\na n d\\ni t s\\na p p l i c a t i o n s ,\\ni n c l u d i n g\\ng e n e r a t i v e\\nA I .\\nS h a r e\\nr e s o u r c e s ,\\na s k\\nq u e s t i o n s ,\\na n d\\nc o l l a b o r a t e\\nw i t h\\na\\nv i b r a n t\\nc o m m u n i t y\\no f\\ne n t h u s i a s t s\\na n d\\np r o f e s s i o n a l s .\\nO p e n A I\\nC o m m u n i t y\\n(\\nh t t p s : / / c o m m u n i t y . o p e n a i . c o m /\\n)\\nA n\\no \\x00 c i a l\\nf o r u m\\nf o r\\nO p e n A I ,\\nw h e r e\\nu s e r s\\nc a n\\nd i s c u s s\\nv a r i o u s\\nt o p i c s\\nr e l a t e d\\nt o\\nA I\\nr e s e a r c h\\na n d\\na p p l i c a t i o n s ,\\ni n c l u d i n g\\nG P T\\nm o d e l s\\na n d\\np r o m p t\\ne n g i n e e r i n g .\\nC o n n e c t\\nw i t h\\no t h e r\\nA I\\ne n t h u s i a s t s ,\\ns h a r e\\ny o u r\\np r o j e c t s ,\\na n d\\nl e a r n\\nf r o m\\ne x p e r t s .\\nD a t a\\nS c i e n c e\\nS t a c k\\nE x c h a n g e\\n(\\nh t t p s : / / d a t a s c i e n c e . s t a c k e x c h a n g e . c o m /\\n)\\nA\\nq u e s t i o n\\na n d\\na n s w e r\\np l a t f o r m\\nf o r\\nd a t a\\ns c i e n c e\\np r o f e s s i o n a l s ,\\nr e s e a r c h e r s ,\\na n d\\ne n t h u s i a s t s .\\nA s k\\nq u e s t i o n s ,\\np r o v i d e\\na n s w e r s ,\\no r\\nb r o w s e\\nt h r o u g h\\ne x i s t i n g\\nd i s c u s s i o n s\\nt o\\nd e e p e n\\ny o u r\\nu n d e r s t a n d i n g\\no f\\nd a t a\\ns c i e n c e ,\\nm a c h i n e\\nl e a r n i n g ,\\na n d\\nA I .\\n4 0\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 40}), Document(page_content='B y\\np a r t i c i p a t i n g\\ni n\\nt h e s e\\no n l i n e\\nc o m m u n i t i e s\\na n d\\nf o r u m s ,\\ny o u\\nc a n\\ne x p a n d\\ny o u r\\nn e t w o r k ,\\ns h a r e\\ny o u r\\nk n o w l e d g e ,\\na n d\\nc o l l a b o r a t e\\nw i t h\\no t h e r s\\nw h o\\ns h a r e\\ny o u r\\np a s s i o n\\nf o r\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g .\\nT h e s e\\np l a t f o r m s\\np r o v i d e\\ni n v a l u a b l e\\no p p o r t u n i t i e s\\nt o\\nl e a r n\\nf r o m\\ne x p e r t s ,\\ns t a y\\nu p d a t e d\\no n\\nt h e\\nl a t e s t\\na d v a n c e m e n t s ,\\na n d\\nc o n t r i b u t e\\nt o\\nt h e\\ng r o w t h\\na n d\\ni n n o v a t i o n\\no f\\nt h e\\nﬁ e l d .\\n4 1\\n', metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 41}), Document(page_content='Tree of Thoughts: Deliberate Problem Solving\\nwith Large Language Models\\nShunyu Yao\\nPrinceton UniversityDian Yu\\nGoogle DeepMindJeffrey Zhao\\nGoogle DeepMindIzhak Shafran\\nGoogle DeepMind\\nThomas L. Grifﬁths\\nPrinceton UniversityYuan Cao\\nGoogle DeepMindKarthik Narasimhan\\nPrinceton University\\nAbstract\\nLanguage models are increasingly being deployed for general problem solving\\nacross a wide range of tasks, but are still conﬁned to token-level, left-to-right\\ndecision-making processes during inference. This means they can fall short in\\ntasks that require exploration, strategic lookahead, or where initial decisions play\\na pivotal role. To surmount these challenges, we introduce a new framework for\\nlanguage model inference, “Tree of Thoughts” (ToT), which generalizes over the\\npopular “Chain of Thought” approach to prompting language models, and enables\\nexploration over coherent units of text (“thoughts”) that serve as intermediate steps\\ntoward problem solving. ToT allows LMs to perform deliberate decision making\\nby considering multiple different reasoning paths and self-evaluating choices to\\ndecide the next course of action, as well as looking ahead or backtracking when\\nnecessary to make global choices. Our experiments show that ToT signiﬁcantly\\nenhances language models’ problem-solving abilities on three novel tasks requiring\\nnon-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.\\nFor instance, in Game of 24, while GPT-4 with chain-of-thought prompting only\\nsolved 4% of tasks, our method achieved a success rate of 74%. Code repo with all\\nprompts: https://github.com/ysymyth/tree-of-thought-llm .\\n1 Introduction\\nOriginally designed to generate text, scaled-up versions of language models (LMs) such as GPT [ 22,\\n23,1,20] and PaLM [ 5] have been shown to be increasingly capable of performing an ever wider\\nrange of tasks requiring mathematical, symbolic, commonsense, and knowledge reasoning. It is\\nperhaps surprising that underlying all this progress is still the original autoregressive mechanism for\\ngenerating text, which makes token-level decisions one by one and in a left-to-right fashion. Is such\\na simple mechanism sufﬁcient for a LM to be built toward a general problem solver? If not, what\\nproblems would challenge the current paradigm, and what should be alternative mechanisms?\\nThe literature on human cognition provides some clues to answer these questions. Research on “dual\\nprocess” models suggests that people have two modes in which they engage with decisions – a fast,\\nautomatic, unconscious mode (“System 1”) and a slow, deliberate, conscious mode (“System 2”)\\n[27,28,13,12]. These two modes have previously been connected to a variety of mathematical\\nmodels used in machine learning. For example, research on reinforcement learning in humans and\\nother animals has explored the circumstances under which they engage in associative “model free”\\nlearning or more deliberative “model based” planning [ 6]. The simple associative token-level choices\\nof LMs are also reminiscent of “System 1”, and thus might beneﬁt from augmentation by a more\\ndeliberate “System 2” planning process that (1) maintains and explores diverse alternatives for current\\nPreprint. Under review.arXiv:2305.10601v1  [cs.CL]  17 May 2023', metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 0}), Document(page_content='GĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜʱÊʲˤGjʱæʲˤ\\x1dĵÉGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x1dĵÉˁ\\x92\\x1dʟʟʟʟaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉĵÉˤʱĵũŗŝʲʟʟʟʟʟʟˤˤʝˤƛĎĵũĈĎƜ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0c0DUN\\x03GLIIHUHQFH\\x03E\\\\\\x03FRORU\\nGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x92òĦƙˤ\\x1dĵĮŝƓŝŤòĮçƆˤƀƓƜĎˤ\\x1dĵÉˤʱ\\x1dĵÉˁ\\x92\\x1dʲaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉŗòòˤĵƙˤ\\x9aĎĵũĈĎŤŝˤʱÉĵÉʲʟʟʟʟʟʟʟʟʟʟˤˤƛĎĵũĈĎƜ\\nʱçʲˤ\\x1dĎÊđĮˤĵƙˤ\\x9aĎĵũĈĎƜˤ\\x89ŗĵĭŔƜđĮĈˤʱ\\x1dĵÉʲʱÊʲˤGĮŔũƜˁjũƜŔũƜˤ\\x89ŗĵĭŔƜđĮĈˤʱGjʲFigure 1: Schematic illustrating various approaches to problem solving with LLMs. Each rectangle\\nbox represents a thought , which is a coherent language sequence that serves as an intermediate\\nstep toward problem solving. See concrete examples of how thoughts are generated, evaluated, and\\nsearched in Figures 2,4,6.\\nchoices instead of just picking one, and (2) evaluates its current status and actively looks ahead or\\nbacktracks to make more global decisions.\\nTo design such a planning process, we return to the origins of artiﬁcial intelligence (and cognitive\\nscience), drawing inspiration from the planning processes explored by Newell, Shaw, and Simon\\nstarting in the 1950s [ 18,19]. Newell and colleagues characterized problem solving [ 18] as search\\nthrough a combinatorial problem space, represented as a tree. We thus propose the Tree of Thoughts\\n(ToT) framework for general problem solving with language models. As Figure 1 illustrates, while\\nexisting methods (detailed below) sample continuous language sequences for problem solving, ToT\\nactively maintains a tree of thoughts, where each thought is a coherent language sequence that serves\\nas an intermediate step toward problem solving (Table 1). Such a high-level semantic unit allows the\\nLM to self-evaluate the progress different intermediate thoughts make towards solving the problem\\nthrough a deliberate reasoning process that is also instantiated in language (Figures 2,4,6). This\\nimplementation of search heuristics via LM self-evaluation and deliberation is novel, as previous\\nsearch heuristics are either programmed or learned. Finally, we combine this language-based\\ncapability to generate and evaluate diverse thoughts with search algorithms, such as breadth-ﬁrst\\nsearch (BFS) or depth-ﬁrst search (DFS), which allow systematic exploration of the tree of thoughts\\nwith lookahead and backtracking.\\nEmpirically, we propose three new problems that challenge existing LM inference methods even with\\nthe state-of-the-art language model, GPT-4 [ 20]: Game of 24, Creative Writing, and Crosswords\\n(Table 1). These tasks require deductive, mathematical, commonsense, lexical reasoning abilities,\\nand a way to incorporate systematic planning or search. We show ToT obtains superior results on\\nall three tasks by being general and ﬂexible enough to support different levels of thoughts, different\\nways to generate and evaluate thoughts, and different search algorithms that adapt to the nature of\\ndifferent problems. We also analyze how such choices affect model performances via systematic\\nablations and discuss future directions to better train and use LMs.\\n2 Background\\nWe ﬁrst formalize some existing methods that use large language models for problem-solving,\\nwhich our approach is inspired by and later compared with. We use pθto denote a pre-trained LM\\nwith parameters θ, and lowercase letters x,y,z,s,···to denote a language sequence , i.e.x=\\n(x[1],···,x[n])where eachx[i]is a token, so that pθ(x) =∏n\\ni=1pθ(x[i]|x[1...i]). We use uppercase\\nlettersS,···to denote a collection of language sequences.\\nInput-output (IO) prompting is the most common way to turn a problem input xinto outputywith\\nLM:y∼pθ(y|promptIO(x)), where promptIO(x)wraps inputxwith task instructions and/or few-\\nshot input-output examples. For simplicity, let us denote pprompt\\nθ(output|input ) =pθ(output|\\nprompt (input )), so that IO prompting can be formulated as y∼pIO\\nθ(y|x).\\n2', metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 1}), Document(page_content='Chain-of-thought (CoT) prompting [35] was proposed to address cases where the mapping of\\ninputxto outputyis non-trivial (e.g. when xis a math question and yis the ﬁnal numerical answer).\\nThe key idea is to introduce a chain of thoughtsz1,···,znto bridgexandy, where each ziis a\\ncoherent language sequence that serves as a meaningful intermediate step toward problem solving\\n(e.g.zicould be an intermediate equation for math QA). To solve problems with CoT, each thought\\nzi∼pCoT\\nθ(zi|x,z1···i−1)is sampled sequentially, then the output y∼pCoT\\nθ(y|x,z1···n). In\\npractice, [z1···n,y]∼pCoT\\nθ(z1···n,y|x)is sampled as a continuous language sequence, and the\\ndecomposition of thoughts (e.g. is each zia phrase, a sentence, or a paragraph) is left ambiguous.\\nSelf-consistency with CoT (CoT-SC) [33] is an ensemble approach that samples ki.i.d. chains\\nof thought: [z(i)\\n1···n,y(i)]∼pCoT\\nθ(z1···n,y|x) (i= 1···k), then returns the most frequent output:\\narg maxy#{i|y(i)=y}. CoT-SC improves upon CoT, because there are generally different\\nthought processes for the same problem (e.g. different ways to prove the same theorem), and the\\noutput decision can be more faithful by exploring a richer set of thoughts. However, within each\\nchain there is no local exploration of different thought steps, and the “most frequent” heuristic only\\napplies when the output space is limited (e.g. multi-choice QA).\\n3 Tree of Thoughts: Deliberate Problem Solving with LM\\nA genuine problem-solving process involves the repeated use of available informa-\\ntion to initiate exploration, which discloses, in turn, more information until a way\\nto attain the solution is ﬁnally discovered.—— Newell et al. [18]\\nResearch on human problem-solving suggests that people search through a combinatorial problem-\\nspace – a tree where the nodes represent partial solutions, and the branches correspond to operators\\nthat modify them [ 18,19]. Which branch to take is determined by heuristics that help to navigate the\\nproblem-space and guide the problem-solver towards a solution. This perspective highlights two key\\nshortcomings of existing approaches that use LMs to solve general problems: 1) Locally, they do not\\nexplore different continuations within a thought process – the branches of the tree. 2) Globally, they\\ndo not incorporate any type of planning, lookahead, or backtracking to help evaluate these different\\noptions – the kind of heuristic-guided search that seems characteristic of human problem-solving.\\nTo address these shortcomings, we introduce Tree of Thoughts (ToT) , a paradigm that allows LMs to\\nexplore multiple reasoning paths over thoughts (Figure 1(c)). ToT frames any problem as a search\\nover a tree, where each node is a states= [x,z1···i]representing a partial solution with the input and\\nthe sequence of thoughts so far. A speciﬁc instantiation of ToT involves answering four questions:\\n1. How to decompose the intermediate process into thought steps; 2. How to generate potential\\nthoughts from each state; 3. How to heuristically evaluate states; 4. What search algorithm to use.\\n1. Thought decomposition. While CoT samples thoughts coherently without explicit decomposition,\\nToT leverages problem properties to design and decompose intermediate thought steps. As Table 1\\nshows, depending on different problems, a thought could be a couple of words (Crosswords), a line of\\nequation (Game of 24), or a whole paragraph of writing plan (Creative Writing). In general, a thought\\nshould be “small” enough so that LMs can generate promising and diverse samples (e.g. generating\\na whole book is usually too “big” to be coherent), yet “big” enough so that LMs can evaluate its\\nprospect toward problem solving (e.g. generating one token is usually too “small” to evaluate).\\n2. Thought generator G(pθ,s,k).Given a tree state s= [x,z1···i], we consider two strategies to\\ngeneratekcandidates for the next thought step:\\n(a)Sample i.i.d. thoughts from a CoT prompt (Creative Writing, Figure 4): z(j)∼\\npCoT\\nθ(zi+1|s) =pCoT\\nθ(zi+1|x,z1···i) (j= 1···k). This works better when the thought\\nspace is rich (e.g. each thought is a paragraph), and i.i.d. samples lead to diversity;\\n(b)Propose thoughts sequentially using a “propose prompt” (Game of 24, Figure 2; Crosswords,\\nFigure 6): [z(1),···,z(k)]∼ppropose\\nθ(z(1···k)\\ni+1|s). This works better when the thought\\nspace is more constrained (e.g. each thought is just a word or a line), so proposing different\\nthoughts in the same context avoids duplication.\\n3. State evaluator V(pθ,S).Given a frontier of different states, the state evaluator evaluates the\\nprogress they make towards solving the problem, serving as a heuristic for the search algorithm\\nto determine which states to keep exploring and in which order. While heuristics are a standard\\napproach to solving search problems, they are typically either programmed (e.g. DeepBlue [ 3]) or\\n3', metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 2}), Document(page_content='learned (e.g. AlphaGo [ 26]). We propose a third alternative, by using the LM to deliberately reason\\nabout states. When applicable, such a deliberate heuristic can be more ﬂexible than programmed\\nrules, and more sample-efﬁcient than learned models. Similar to the thought generator, we consider\\ntwo strategies to evaluate states either independently or together:\\n(a)Value each state independently: V(pθ,S)(s)∼pvalue\\nθ(v|s)∀s∈S, where a value\\nprompt reasons about the state sto generate a scalar value v(e.g. 1-10) or a classiﬁca-\\ntion (e.g. sure/likely/impossible) that could be heuristically turned into a value. The basis\\nof such evaluative reasoning can vary across problems and thought steps. In this work, we\\nexplore evaluation via few lookahead simulations (e.g. quickly conﬁrm that 5, 5, 14 can\\nreach 24 via 5 + 5 + 14, or “hot l” can mean “inn” via ﬁlling “e” in “ ”) plus commonsense\\n(e.g. 1 2 3 are too small to reach 24, or no word can start with “tzxc”). While the former\\nmight promote “good” states, the latter could help eliminate “bad” states. Such valuations\\ndo not need to be perfect, and only need to be approximately\\n(b)Vote across states: V(pθ,S)(s) =1[s=s∗], where a “good” state s∗∼pvote\\nθ(s∗|S)is\\nvoted out based on deliberately comparing different states in Sin a vote prompt. When\\nproblem success is harder to directly value (e.g. passage coherency), it is natural to to instead\\ncompare different partial solutions and vote for the most promising one. This is similar\\nin spirit to a “step-wise” self-consistency strategy, i.e. cast “which state to explore” as a\\nmulti-choice QA, and use LM samples to vote for it.\\nFor both strategies, we could prompt the LM multiple times to aggregate the value or vote results to\\ntrade time/resource/cost for more faithful/robust heuristics.\\nAlgorithm 1 ToT-BFS(x,pθ,G,k,V,T,b )\\nRequire: Inputx, LMpθ, thought generator G()\\n& size limitk, states evaluator V(), step limitT,\\nbreadth limit b.\\nS0←{x}\\nfort= 1,···,Tdo\\nS′\\nt←{[s,z]|s∈St−1,zt∈G(pθ,s,k)}\\nVt←V(pθ,S′\\nt)\\nSt←arg maxS⊂S′\\nt,|S|=b∑\\ns∈SVt(s)\\nend for\\nreturnG(pθ,arg maxs∈STVT(s),1)Algorithm 2 ToT-DFS(s,t,pθ,G,k,V,T,v th)\\nRequire: Current state s, stept, LMpθ, thought\\ngeneratorG()and size limit k, states evaluator\\nV(), step limitT, thresholdvth\\nift>T then record output G(pθ,s,1)\\nend if\\nfors′∈G(pθ,s,k)do⊿sorted candidates\\nifV(pθ,{s′})(s)>vthres then⊿pruning\\nDFS(s′,t+ 1)\\nend if\\nend for\\n4. Search algorithm. Finally, within the ToT framework, one can plug and play different search\\nalgorithms depending on the tree structure. We explore two relatively simple search algorithms and\\nleave more advanced ones (e.g. A* [9], MCTS [2]) for future work:\\n(a)Breadth-ﬁrst search (BFS) (Algorithm 1) maintains a set of the bmost promising states\\nper step. This is used for Game of 24 and Creative Writing where the tree depth is limit\\n(T≤3), and initial thought steps can be evaluated and pruned to a small set ( b≤5).\\n(b)Depth-ﬁrst search (DFS) (Algorithm 2) explores the most promising state ﬁrst, until the\\nﬁnal output is reached ( t > T ), or the state evaluator deems it impossible to solve the\\nproblem from the current s(V(pθ,{s})(s)≤vthfor a value threshold vth). In the latter\\ncase, the subtree from sispruned to trade exploration for exploitation. In both cases, DFS\\nbacktracks to the parent state of sto continue exploration.\\nConceptually, ToT has several beneﬁts as a method for general problem-solving with LMs: (1) Gener-\\nality. IO, CoT, CoT-SC, and self-reﬁnement can be seen as special cases of ToT (i.e. trees of limited\\ndepth and breadth; Figure 1). (2) Modularity. The base LM, as well as the thought decomposition,\\ngeneration, evaluation, and search procedures can all be varied independently. (3) Adaptability .\\nDifferent problem properties, LM capabilities, and resource constraints can be accommodated. (4)\\nConvenience. No extra training is needed, just a pre-trained LM is sufﬁcient. The next section will\\nshow how these conceptual beneﬁts translate to strong empirical performance in different problems.\\n4 Experiments\\nWe propose three tasks that are hard even when sampling from the state-of-the-art language model,\\nGPT-4 [ 20], using standard IO prompting or chain-of-thought (CoT) prompting. We show how\\n4', metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 3}), Document(page_content='Game of 24 Creative Writing 5x5 Crosswords\\nInput 4 numbers (4 9 10 13) 4 random sentences 10 clues (h1. presented;..)\\nOutput An equation to reach 24\\n(13-9)*(10-4)=24A passage of 4 paragraphs\\nending in the 4 sentences5x5 letters: SHOWN;\\nWIRRA; A V AIL; ...\\nThoughts 3 intermediate equations\\n(13-9=4 (left 4,4,10); 10-\\n4=6 (left 4,6); 4*6=24)A short writing plan\\n(1. Introduce a book that\\nconnects...)Words to ﬁll in for clues:\\n(h1. shown; v5. naled; ...)\\n#ToT steps 3 1 5-10 (variable)\\nTable 1: Task overview. Input, output, thought examples are in blue.\\ndeliberate search in trees of thoughts (ToT) produces better results, and more importantly, interesting\\nand promising new ways to use language models to solve problems requiring search or planning.\\nUnless otherwise stated, we perform experiments using a Chat Completion mode GPT-41with a\\nsampling temperature of 0.7.\\n4.1 Game of 24\\nGame of 24 is a mathematical reasoning challenge, where the goal is to use 4 numbers and basic\\narithmetic operations (+-*/) to obtain 24. For example, given input “4 9 10 13”, a solution output\\ncould be “(10 - 4) * (13 - 9) = 24”.\\nʳĵĮòˤòƅÊĭŔĦòʴˤGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀ\\x89ĵŝŝđæĦòˤĮòƅƜˤŝŤòŔŝʝˤˤˤ3URSRVH\\x033URPSWʁˤ̌ˤʆˤ̐ˤɾʀˤʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˤˊˤʁˤ̐ˤʃˤʱĦòƙƜʝˤʃˤʆˤɾʀʲʳʛʛʛĭĵŗòˤĦđĮòŝʟʴ7KRXJKW\\x03*HQHUDWLRQ/0)ſÊĦũÊŤòˤđƙˤĈƓſòĮˤĮũĭæòŗŝˤçÊĮˤŗòÊçĎˤɿʁˤʱŝũŗòʫĦđģòĦƆʫđĭŔĵŝŝđæĦòʲɾɽˤɾʁʝˤɾɽˤ̌ˤɾʁˤ̐ˤɿʁʛˤŝũŗòʳĭĵŗòˤòƅÊĭŔĦòŝʴɾɽˤɾʀˤɾʀ9DOXH\\x033URPSWʱɾʀˤˊˤɾɽʲˤʦˤɾʀˤ̐ˤʀˤʦˤɾʀˤ̐ˤʀʆɾɽˤ̌ˤɾʀˤ̌ˤɾʀˤ̐ˤʀʃ\\x9aĎòŗòˤƓŝˤĮĵˤƀÊƆˤƘĵˤĵæŤÊđĮˤɿʁˤƀƓƜĎˤƛĎòŝòˤĮũĭæòŗŝʛˤđĭŔĵŝŝđæĦò7KRXJKW\\x03(YDOXDWLRQʱæʲʱçʲ/0GĮŔũƜʝˤʁˤʆˤɾɽˤɾʀʁ̌ʆ̐ɾʀʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˁʁ̐ʃʱĦòƙƜʝˤʃˤʆˤɾʀʲʟʟɾʀˁʃ̐ʄʱĦòƙƜʝˤʄˤʆʲɾʀˁʆ̐ʁʱĦòƙƜʝˤʁˤʃʲʟʟʁʦʃ̐ɿʁʱĦòƙƜʝˤɿʁʲʁ̌ʃ̐ɾɽʱĦòƙƜʝˤɾɽʲʟʟʱÊʲ\\nʳĵĮòˤòƅÊĭŔĦòʴˤGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀ\\x89ĵŝŝđæĦòˤĮòƅƜˤŝŤòŔŝʝˤˤˤ\\x0bD\\x0c\\x033URSRVH\\x033URPSWʁˤ̌ˤʆˤ̐ˤɾʀˤʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˤˊˤʁˤ̐ˤʃˤʱĦòƙƜʝˤʃˤʆˤɾʀʲʳʛʛʛĭĵŗòˤĦđĮòŝʟʴ7KRXJKW\\x03*HQHUDWLRQ/0)ſÊĦũÊŤòˤđƙˤĈƓſòĮˤĮũĭæòŗŝˤçÊĮˤŗòÊçĎˤɿʁˤʱŝũŗòʫĦđģòĦƆʫđĭŔĵŝŝđæĦòʲɾɽˤɾʁʝˤɾɽˤ̌ˤɾʁˤ̐ˤɿʁʛˤŝũŗòʳĭĵŗòˤòƅÊĭŔĦòŝʴɾɽˤɾʀˤɾʀ\\x0bE\\x0c\\x039DOXH\\x033URPSWʱɾʀˤˊˤɾɽʲˤʦˤɾʀˤ̐ˤʀˤʦˤɾʀˤ̐ˤʀʆɾɽˤ̌ˤɾʀˤ̌ˤɾʀˤ̐ˤʀʃˤ\\x9aĎòŗòˤƓŝˤĮĵˤƀÊƆˤƘĵˤĵæŤÊđĮˤɿʁˤƀƓƜĎˤƛĎòŝòˤæƓĈˤĮũĭæòŗŝʛˤđĭŔĵŝŝđæĦò7KRXJKW\\x03(YDOXDWLRQ/0GĮŔũƜʝˤʁˤʆˤɾɽˤɾʀʁ̌ʆ̐ɾʀʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˁʁ̐ʃʱĦòƙƜʝˤʃˤʆˤɾʀʲʟʟɾʀˁʃ̐ʄʱĦòƙƜʝˤʄˤʆʲɾʀˁʆ̐ʁʱĦòƙƜʝˤʁˤʃʲʟʟʁʦʃ̐ɿʁʱĦòƙƜʝˤɿʁʲʁ̌ʃ̐ɾɽʱĦòƙƜʝˤɾɽʲʟʟ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0c0DUN\\x03GLII\\x03SURPSW\\x03ZLWK\\x03FRORU\\nFigure 2: ToT in a game of 24. The LM is prompted for (a) thought generation and (b) valuation.\\nTask Setup. We scrape data from 4nums.com, which has 1,362 games that are sorted from easy to\\nhard by human solving time, and use a subset of relatively hard games indexed 901-1,000 for testing.\\nFor each task, we consider the output as success if it is a valid equation that equals 24 and uses the\\ninput numbers each exactly once. We report the success rate across 100 games as the metric.\\nBaselines. We use a standard input-output (IO) prompt with 5 in-context examples. For chain-of-\\nthought (CoT) prompting, we augment each input-output pair with 3 intermediate equations, each\\noperating on two remaining numbers. For example, given input “4 9 10 13”, the thoughts could be\\n“13 - 9 = 4 (left: 4 4 10); 10 - 4 = 6 (left: 4 6); 4 * 6 = 24 (left: 24)”. For each game, we sample IO\\nand CoT prompting for 100 times for average performance. We also consider a CoT self-consistency\\nbaseline, which takes the majority output from 100 CoT samples, and an iterative-reﬁne approach on\\ntop of an IO sample for at most 10iterations. At each iteration, the LM is conditioned on all previous\\nhistory to “reﬂect on your mistakes and generate a reﬁned answer” if the output is incorrect. Note\\nthat it uses groundtruth feedback signals about equation correctness.\\nToT Setup. To frame Game of 24 into ToT, it is natural to decompose the thoughts into 3 steps,\\neach an intermediate equation. As shown in Figure 2(a), at each tree node, we exact the “left”\\nnumbers and prompt the LM to propose some possible next steps. The same “propose prompt” is\\nused for all 3 thought steps, though it only has one example with 4 input numbers. We perform a\\nbreadth-ﬁrst search (BFS) in ToT, where at each step we keep the best b= 5candidates. To perform\\ndeliberate BFS in ToT, as shown in Figure 2(b), we prompt LM to evaluate each thought candidate as\\n“sure/maybe/impossible” with regard to reaching 24. The aim is to promote correct partial solutions\\nthat can be verdicted within few lookahead trials, and eliminate impossible partial solutions based on\\n“too big/small” commonsense, and keep the rest “maybe”. We sample values 3times for each thought.\\n1Experiments were done between May 5-16, 2023.\\n5', metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 4}), Document(page_content='Method Success\\nIO prompt 7.3%\\nCoT prompt 4.0%\\nCoT-SC (k=100) 9.0%\\nToT (ours) (b=1) 45%\\nToT (ours) (b=5) 74%\\nIO + Reﬁne (k=10) 27%\\nIO(best of 100) 33%\\nCoT (best of 100) 49%\\nTable 2: Game of 24 Results.\\n0 25 50 75 1000.20.40.6(a) Success rate with nodes visited\\nIO (best of k)\\nCoT (best of k)\\nToT (b=1...5)\\n1 2 3 4Correct0.00.20.40.6(b) Samples failed at each step\\nCoT\\nToT (b=5) Figure 3: Game of 24 (a) scale analysis & (b) error analysis.\\nResults. As shown in Table 2, IO, CoT, and CoT-SC prompting methods perform badly on the task,\\nachieving only 7.3%, 4.0%, and 9.0% success rates. In contrast, ToT with a breadth of b= 1already\\nachieves a success rate of 45%, whileb= 5 achieves 74%. We also consider an oracle setup for\\nIO/CoT, by calculating the success rate using best of ksamples (1≤k≤100) . To compare IO/CoT\\n(best of k) with ToT, we consider calculating the tree nodes visited per task in ToT across b= 1···5,\\nand map the 5 success rates in Figure 3(a), treating IO/CoT (best of k) as visitingknodes in a bandit.\\nNot surprisingly, CoT scales better than IO, and best of 100 CoT samples achieve a success rate of\\n49%, but still much worse than exploring more nodes in ToT ( b>1).\\nError Analysis. Figure 3(b) breaks down at which step CoT and ToT samples fail the task, i.e. the\\nthought (in CoT) or all bthoughts (in ToT) are invalid or impossible to reach 24. Notably, around\\n60% of CoT samples already failed the task after generating the ﬁrst step, or equivalently, the ﬁrst\\nthree words (e.g. “ 4 + 9 ”). This highlights the issues with direct left-to-right decoding.\\n4.2 Creative writing\\nNext, we invent a creative writing task where the input is 4 random sentences and the output should\\nbe a coherent passage with 4 paragraphs that end in the 4 input sentences respectively. Such a task is\\nopen-ended and exploratory, and challenges creative thinking as well as high-level planning.\\nTask setup. We sample random sentences from randomwordgenerator.com to form 100 inputs, and\\nthere is no groundtruth passage for each input constraint. As we ﬁnd that GPT-4 can follow the\\ninput constraints most of the time, we focus on evaluating passage coherency in two ways: using a\\nGPT-4 zero-shot prompt to provide a 1-10 scalar score, or using human judgments to compare pairs\\nof outputs from different methods. For the former, we sample 5 scores and average them for each task\\noutput, and we ﬁnd these 5 scores usually consistent, with a standard deviation of around 0.56on\\naverage across outputs. For the latter, we employ a subset of the authors in a blind study to compare\\nthe coherency of CoT vs. ToT generated passage pairs, where the order of passages is random ﬂipped\\nover 100 inputs.\\nBaselines. Given the creative nature of the task, both IO and CoT prompts are zero-shot. While the\\nformer prompts the LM to directly generate a coherent passage given input constraints, the latter\\nprompts the LM to ﬁrst make a brief plan then write the passage, i.e. the plan serves as the intermediate\\nthought step. We generate 10 IO and CoT samples per task. We also consider an iterative-reﬁne\\n(k≤5) method on top of a random IO sample for each task, where the LM is conditioned on input\\nconstraints and the last generated passage to decide if the passage is already “perfectly coherent”,\\nand if not generate a reﬁned one.\\nToT setup. We build a ToT with depth 2 (and only 1 intermediate thought step) — the LM ﬁrst\\ngeneratesk= 5plans and votes for the best one (Figure 4), then similarly generate k= 5passages\\nbased on the best plan then vote for the best one. Here the breadth limit b= 1, as only one choice is\\nkept per step. A simple zero-shot vote prompt (“analyze choices below, then conclude which is most\\npromising for the instruction”) is used to sample 5 votes at both steps.\\nResults. Figure 5(a) shows average GPT-4 scores across 100 tasks, where ToT (7.56) is deemed to\\ngenerate more coherent passages than IO (6.19) and CoT (6.93) on average. While such an automatic\\nmetric might be noisy, Figure 5(b) conﬁrms the ﬁnding by showing that humans prefer ToT over\\nCoT in 41 out of 100 passage pairs, while only prefer CoT over ToT in 21 (other 38 pairs are found\\n“similarly coherent”). Lastly, iterative-reﬁne is more effective on this natural language task, where\\n6', metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 5}), Document(page_content='µŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤ\\x9aĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤ\\x92ƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤ\\x9aĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\\x1dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤ\\x89ĦÊĮŝʱʀˤĭĵŗòˤĵĭƓƜŤòíʲʱçʲˤ´ĵŤòŝ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱɽʫʂˤſĵŤòŝʲ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱʀʫʂˤſĵŤòŝʲʟɾɿGĮŔũƜ\\x89ĦÊĮˤɾ\\x89ĦÊĮˤɿʟʟ\\x89ÊŝŝÊĈòɾ\\x89ÊŝŝÊĈòɿʟʟ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0cµŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤ\\x9aĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤ\\x92ƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤ\\x9aĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\\x1dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤ\\x89ĦÊĮŝʱçʲˤ´ĵŤòŝ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛGĮŔũƜ\\x89ĦÊĮˤɾˤ\\x89ĦÊĮˤɿˤˤʟʟ\\x89ÊŝŝÊĈòɾ\\x89ÊŝŝÊĈòɿʟʟɽʫʂˤſĵŤòŝ\\x89ĦÊĮˤɾˤˤˤʟʛʟʛɾʟʛɿʟʟʀʫʂˤſĵŤòŝ\\x89ĦÊĮˤʀˁʂˤˤˤ8VH\\x03UHG\\x12JUHHQ\\x03WR\\x03VKRZ\\x03ILQDO\\x03FKRLFH\\nĮʫʂˤſĵŤòŝ\\x89ĦÊĮˤɿˤˤˤ\\n\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛFigure 4: A step of deliberate search in a randomly picked Creative Writing task. Given the input, the\\nLM samples 5 different plans, then votes 5 times to decide which plan is best. The majority choice is\\nused to consequently write the output passage with the same sample-vote procedure.\\nIO CoT ToT IO\\n+refineToT\\n+refine468\\n(a) GPT-4 coherency scores\\nCoT > ToT Similar ToT > CoT010203040\\n213841(b) Human coherency comparison\\nFigure 5: Creative Writing results.Method Success Rate (%)\\nLetter Word Game\\nIO 38.7 14 0\\nCoT 40.6 15.6 1\\nToT (ours) 78 60 20\\n+best state 82.4 67.5 35\\n-prune 65.4 41.5 5\\n-backtrack 54.6 20 5\\nTable 3: Mini Crosswords results.\\nit improves IO coherency score from 6.19 to 7.67, and ToT coherency score from 7.56 to 7.91. We\\nbelieve it could be thought of as a third approach to thought generation in the ToT framework, where\\nnew thoughts can arise from reﬁning old thoughts instead of i.i.d. or sequentially generated.\\n4.3 Mini Crosswords\\nIn Game of 24 and Creative Writing, ToT is relatively shallow — at most 3 thought steps are needed\\nto reach the ﬁnal output. Here we explore 5×5mini crosswords as a harder search problem involving\\nnatural language. Again, the goal is not just to solve the task, as more general crosswords can be\\nreadily solved with specialized NLP pipelines [ 31] that leverages large-scale retrieval instead of LM.\\nRather, we aim to explore the limit of LM as a general problem solver that explores its own thoughts\\nand guides its own exploration with deliberate reasoning as heuristics.\\nTask Setup. We scrape data from GooBix, which contains 156 games of 5×5mini crosswords. As\\nwe observe adjacent games contain similar clues, we use 20 games with indices 1,6,···,91,96for\\ntesting, and games 136,141,146,151,156for prompting. For each task, the input describes the 5\\nhorizontal clues and 5 vertical clues, and the output should be a board of 5×5 = 25 letters to solve\\nthe crosswords. For evaluation, we consider three levels of success: the portion of correct letters (25\\nper game), words (10 per game), and games.\\nBaselines. We provide 5 example input-output pairs in the IO prompt, and in the CoT prompt\\nadditionally include intermediate words in the order h1..5 then v1..5. We run each prompt for 10\\nsamples and average the results.\\nToT Setup. We leverage a depth-ﬁrst search (Algorithm 2) that keeps exploring the most promising\\nsubsequent word clue until the state is no longer promising, then backtrack to the parent state to\\nexplore alternative thoughts. To make search tractable, subsequent thoughts are constrained not to\\nchange any ﬁlled words or letters, so that the ToT has at most 10 intermediate steps. For thought\\ngeneration, at each state we translate all existing thoughts (e.g. “h2.motor; h1.tasks” for the state\\nin Figure 6(a)) into letter constraints for remaining clues (e.g. “v1.To heap: tm ;...”) and prompt\\na proposal prompt 5times to come up with candidates for where and what to ﬁll in the next word.\\nImportantly, we also prompt the LM to give a conﬁdence level for different thoughts, and aggregate\\n7', metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 6}), Document(page_content='>\\x0b\\nY\\x16\\x11\\x03HORSH\\n\\x0f\\x03\\x16\\x11\\x15\\x0c\\x0f\\x03\\x0b\\nK\\x15\\x11\\x03YDOXH\\n\\x0f\\x03\\x15\\x11\\x13\\x0c\\x0f\\x03\\x0b\\nK\\x14\\x11\\x03SDUFK\\n\\x0f\\x03\\x14\\x11\\x1c\\x0c\\x0f\\x03\\x0b\\nY\\x18\\x11\\x03FRYHW\\n\\x0f\\x03\\x13\\x11\\x19\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x14\\x0c\\x0f\\x03\\x0b\\nK\\x15\\x11\\x03PHULW\\n\\x0f\\x03\\x13\\x11\\x17\\x0c\\x0f\\x03\\x0b\\nY\\x14\\x11\\x03DOORZ\\n\\x0f\\x03\\x13\\x11\\x15\\x0c\\x0f\\x03\\x0b\\nY\\x15\\x11\\x03JULQG\\n\\x0f\\x03\\x13\\x11\\x14\\x0c\\x0f\\x03\\x0b\\nK\\x17\\x11\\x03OHSHU\\n\\x0f\\x03\\x13\\x11\\x14\\x0c@\\nY\\x16\\x11\\x03HORSH\\n0XOWLSOH\\x03UXQV3DUVH\\x0f\\x03ILOWHU\\x03RXW\\x03QRQ\\x10ILYH\\x10OHWWHU\\x0f\\x03VFRUH\\x0f\\x03DJJUHJDWH\\n&KRRVH\\x03\\x0bVRIW\\x03VHOI\\x10FRQVLVWHQF\\\\\"\\x0c\\x14\\x110D[\\x15\\x110D[\\x03ZLWKRXW\\x03YLRODWH\\x16\\x11\\')6\\nGĮŔũƜˤ\\x1dĦũòŝĎɿʛĭĵŤĵŗĎɾʛƘÊŝģŝĎʁʛŝÊĦĵĮƘÊŝģŝƘÊŝģŝ\\nĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVÊĈĈŗòĈÊŤòſʀʛˤ\\x89ŗòŤòĮƜƓĵũŝʞˤƚĦĵƀòŗƆʝˤˈˈˈˈˈˤŝũŗò6WDWH\\x03(YDOXDWRU\\x03\\x0bRYHU\\x03HDFK\\x03FOXH\\x0cſɾʛˤÉĵˤĎòÊŔʝˤƛĭˈŝˈˤʳʛʛʛʴˤđĭŔĵŝŝđæĦòſʂʛˤ#òŝƓççÊŤĵŗʞˤĭĵŗòˤíŗƆʝˤŝŗˈĮˈˤʳʛʛʛʴˤĭÊƆæòʟʟʱæÊçģƜŗÊçģʲĎʀʛĈŗÊĮíʟʟʱŝũæƜŗòòˤŔŗũĮòíʲĎʁʛˤŝÊĦĵĮĎʀʛˤĈŗÊĮíſʀʛˤŝƜŗđĮĈʟʟ\\')6\\x032UGHUĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVʱÊʲʱæʲƛˤÊˤŝˤģˤŝĭˤĵˤƛˤĵˤŗˈˤˈˤˈˤˈˤˈŝˤÊˤĦˤĵˤĮˈˤˈˤˈˤˈˤˈFigure 6: In Mini Crosswords, (a) how thoughts are proposed and aggregated in a priority queue\\nfor depth-ﬁrst search (DFS), and (b) how a state is evaluated based on the possibility of ﬁlling in\\neach remaining word clue, and pruned if any remaining clue is deemed not possible to ﬁll by the LM.\\nThen DFS backtracks to the parent state and explore the next promising thought for clue.\\nthese across proposals to obtain a sorted list of next thoughts to explore (Figure 6(a)). For state\\nevaluations, we similarly translate each state into letter constraints for remaining clues, then evaluate\\nfor each clue if it is possible to ﬁll given the constraints. If any remaining clue is deemed “impossible”\\nto ﬁll in (e.g. “v1. To heap: tm s”), then the exploration of the state’s subtree is pruned and DFS\\nbacktracks to its parent to explore the next promising thought. We limit DFS search steps to 100, and\\nsimply render the deepest explored state (the ﬁrst explored one if multiple) into the ﬁnal output.\\nResults. As shown in Table 3, IO and CoT prompting methods perform poorly with a word-level\\nsuccess rate less than 16%, while ToT signiﬁcantly improves all metrics, achieving a word-level\\nsuccess rate of 60% and solving 4 out of 20 games. Such an improvement is not surprising, given IO\\nand CoT lack mechanisms to try different clues, make changes to decisions, or backtrack.\\nOracle and ablation studies. When outputting from the oracle best DFS state (instead of the\\nheuristically determined best state) per task, ToT performance is even higher and actually solves\\n7/20 games (Table 3, “+best state”), indicating our simple output heuristics can be readily improved.\\nInterestingly, sometimes when the crosswords game is actually solved, the state evaluator might still\\ndeem some words as “impossible” and prune — possibly because 5×5crosswords by design have\\nsome rare or obselete words that GPT-4 cannot recognize2. Given the state evaluation as a pruning\\nheuristic is imperfect, we also explore ablating the pruning, and ﬁnd the performance generally worse\\n(Table 3, “-prune”). However, it could actually ﬁnd the correct solution for 4/20 games (though only\\noutputting 1 via heuristic), 3 of which are games ToT+pruning cannot solve within 100 steps. Thus,\\nbetter heuristics for DFS pruning are critical for problem solving in this case. Lastly, we conﬁrm the\\nimportance of backtracking by running an ablation that keeps ﬁlling the most promising clue for at\\nmost 20 steps, allowing overwrites. This is similar to a “greedy” BFS search with breadth limit of\\nb= 1, and performs poorly with a word level success of only 20% (Table 3, “-backtrack”).\\n5 Related Work\\nPlanning and decision making. Smart planning and decision making are critical to achieving\\npredeﬁned goals. As they are trained on vast amount of world knowledge and human examples, LMs\\nare known to have already absorbed rich commonsense that makes it possible to propose reasonable\\nplans conditioned on problem setting and environmental states [ 10,39,34,11,32,38,37]. Our\\nproposed Tree-of-Thought approach extends existing planning formulations by considering multiple\\npotentially feasible plans simultaneously at each problem-solving step, and proceeding with the most\\npromising ones. The integration between thought sampling and value feedback organically integrates\\nplanning and decision-making mechanisms, enabling effective search inside a solution tree. On the\\nother hand, traditional decision-making procedures usually require training dedicated reward and\\npolicy models as in reinforcement learning (for example CHAI [ 30]), whereas we use the LM itself\\nto provide the value estimates for decision making.\\n2For example, “agend” is an obsolete form of “agendum”, but GPT-4 deems it a typo for “agenda”. External\\nretrieval or web interaction could augment LM for problem solving under knowledge uncertainty.\\n8', metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 7}), Document(page_content='Self-reﬂection. Using LLMs to assess the viability of their own predictions is becoming an in-\\ncreasingly important procedure in problem solving. [ 25,17,21] introduced the “self-reﬂection”\\nmechanism, in which LMs provide feedback to their generation candidates. [ 4] improves LMs code\\ngeneration accuracy by injecting feedback messages generated by the LM itself based on its code\\nexecution results. Similarly, [ 14] also introduces “critic” or review steps over the actions and states,\\ndeciding the next action to take in solving computer operation tasks. Another recent work very\\nrelevant to ours is “self-eval guided decoding” [ 36]. Similar to our method, self-eval decoding\\nalso follows a tree-search procedure with leaves sampled from stochastic beam search decoding,\\nwhich are then evaluated by LLM itself with carefully prepared self-eval prompts. Their approach\\nhowever, uses the PAL formulation [ 7] which represents thoughts as codes, which makes it difﬁcult\\nto tackle challenging tasks like creative writing which we consider in this paper. Our Tree-of-Thought\\nformulation is thus more versatile and handles challenging tasks on which GPT-4 only achieves very\\nlow accuracy with standard prompts.\\nProgram-guided LLM generation. Our proposal is also related to recent advancements that or-\\nganize LM’s behavior with symbolic program guidance. For example [ 24] embeds LMs in an\\nalgorithmic search procedure to help solve problems like question answering step-by-step, in which\\nthe search trees are expanded by relevant paragraphs that might provide answers. This approach\\nhowever differs from ours in that trees are expanded by sampling external paragraphs instead of the\\nLM’s own thoughts, and there is no reﬂection or voting steps. Another approach, LLM+P [ 15], goes\\none step further and delegates the actual planning process to a classical planner.\\nClassical search methods. Last but not least, our approach can be treated as a modern rendition\\nof classical search methods for problem solving. For example it can be considered as a heuristic\\nsearch algorithm like A* [ 8], in which the heuristic at each search node is provided by the LM’s\\nself-assessment. From this perspective, our method is also related to NeuroLogic A*esque decoding\\nproposed in [ 16], which is inspired by A* search but introduces look-ahead heuristics that are\\nefﬁcient for LMs to improve the beam-search or top-k sampling decoding. This method however is\\nconstrained to sentence generation tasks, whereas our framework are designed for complex, multi-step\\nproblem solving guarded by value feedback.\\n6 Discussion\\nLimitations and future directions. Deliberate search such as ToT might not be necessary for\\nmany existing tasks that GPT-4 already excels at, and as an initial step this work only explores\\nthree relatively simple tasks that challenges GPT-4 and calls of better search and planning abilities\\nincorporated with LMs. However, as we begin to deploy LMs for more real-world decision making\\napplications (e.g. coding, data analysis, robotics, etc.), more complex tasks could emerge and present\\nnew opportunities to study these research questions. Also, search methods like ToT requires more\\nresources (e.g. GPT-4 API cost) than sampling methods in order to improve task performances,\\nbut the modular ﬂexibility of ToT allows users to customize such performance-cost tradeoffs, and\\nongoing open-source efforts [ 29] should readily reduce such costs in the near future. Lastly, this work\\nfocuses on using an off-the-shelf LM, and ﬁne-tuning LMs using a ToT-style high-level counterfactual\\ndecision making (e.g. deliberating over potential choices for the next paragraph, instead of predicting\\nthe next token) might present opportunities to enhance the problem-solving capabilities of LMs.\\nBroader impact. ToT is a framework that empowers LMs to more autonomously and intelligently\\nmake decisions and solve problems. While current tasks are limited to reasoning and search problems,\\nfuture applications involving interaction with external environments or humans could bring potential\\ndanger, e.g. facilitating harmful uses of LMs. On the other hand, ToT also improves the interpretability\\nof model decisions and the opportunity for human alignment, as the resulting representations are\\nreadable, high-level language reasoning instead of implicit, low-level token values.\\nConclusion. The associative “System 1” of LMs can be beneﬁcially augmented by a “System 2”\\nbased on searching a tree of possible paths to the solution to a problem. The Tree of Thoughts\\nframework provides a way to translate classical insights about problem-solving into actionable\\nmethods for contemporary LMs. At the same time, LMs address a weakness of these classical\\nmethods, providing a way to solve complex problems that are not easily formalized, such as creative\\nwriting. We see this intersection of LMs with classical approaches to AI as an exciting direction for\\nfuture work.\\n9', metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 8}), Document(page_content='References\\n[1]T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,\\nG. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural\\ninformation processing systems , 33:1877–1901, 2020.\\n[2]C. Browne, E. J. Powley, D. Whitehouse, S. M. M. Lucas, P. I. Cowling, P. Rohlfshagen,\\nS. Tavener, D. P. Liebana, S. Samothrakis, and S. Colton. A survey of monte carlo tree search\\nmethods. IEEE Transactions on Computational Intelligence and AI in Games , 4:1–43, 2012.\\n[3]M. Campbell, A. J. Hoane Jr, and F.-h. Hsu. Deep blue. Artiﬁcial intelligence , 134(1-2):57–83,\\n2002.\\n[4]X. Chen, M. Lin, N. Sch ¨arli, and D. Zhou. Teaching large language models to self-debug, 2023.\\n[5]A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W.\\nChung, C. Sutton, S. Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv\\npreprint arXiv:2204.02311 , 2022.\\n[6]N. D. Daw, Y . Niv, and P. Dayan. Uncertainty-based competition between prefrontal and\\ndorsolateral striatal systems for behavioral control. Nature neuroscience , 8(12):1704–1711,\\n2005.\\n[7]L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y . Yang, J. Callan, and G. Neubig. Pal: Program-\\naided language models, 2023.\\n[8]P. E. Hart, N. J. Nilsson, and B. Raphael. A formal basis for the heuristic determination of\\nminimum cost paths. IEEE Transactions on Systems Science and Cybernetics , 4(2):100–107,\\n1968. doi: 10.1109/TSSC.1968.300136.\\n[9]P. E. Hart, N. J. Nilsson, and B. Raphael. A formal basis for the heuristic determination of\\nminimum cost paths. IEEE transactions on Systems Science and Cybernetics , 4(2):100–107,\\n1968.\\n[10] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch. Language models as zero-shot planners:\\nExtracting actionable knowledge for embodied agents, 2022.\\n[11] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch,\\nY . Chebotar, et al. Inner monologue: Embodied reasoning through planning with language\\nmodels. arXiv preprint arXiv:2207.05608 , 2022.\\n[12] D. Kahneman. Thinking, fast and slow . Macmillan, 2011.\\n[13] D. Kahneman, S. Frederick, et al. Representativeness revisited: Attribute substitution in intuitive\\njudgment. Heuristics and biases: The psychology of intuitive judgment , 49(49-81):74, 2002.\\n[14] G. Kim, P. Baldi, and S. McAleer. Language models can solve computer tasks, 2023.\\n[15] B. Liu, Y . Jiang, X. Zhang, Q. Liu, S. Zhang, J. Biswas, and P. Stone. Llm+p: Empowering\\nlarge language models with optimal planning proﬁciency, 2023.\\n[16] X. Lu, S. Welleck, P. West, L. Jiang, J. Kasai, D. Khashabi, R. L. Bras, L. Qin, Y . Yu,\\nR. Zellers, N. A. Smith, and Y . Choi. Neurologic a*esque decoding: Constrained text generation\\nwith lookahead heuristics. In North American Chapter of the Association for Computational\\nLinguistics , 2021.\\n[17] A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe, U. Alon, N. Dziri,\\nS. Prabhumoye, Y . Yang, S. Welleck, B. P. Majumder, S. Gupta, A. Yazdanbakhsh, and P. Clark.\\nSelf-reﬁne: Iterative reﬁnement with self-feedback, 2023.\\n[18] A. Newell, J. C. Shaw, and H. A. Simon. Report on a general problem solving program. In IFIP\\ncongress , volume 256, page 64. Pittsburgh, PA, 1959.\\n[19] A. Newell, H. A. Simon, et al. Human problem solving . Prentice-Hall, 1972.\\n10', metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 9}), Document(page_content='[20] OpenAI. Gpt-4 technical report. ArXiv , abs/2303.08774, 2023.\\n[21] D. Paul, M. Ismayilzada, M. Peyrard, B. Borges, A. Bosselut, R. West, and B. Faltings. Reﬁner:\\nReasoning feedback on intermediate representations, 2023.\\n[22] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al. Improving language understanding\\nby generative pre-training. OpenAI blog , 2018.\\n[23] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are\\nunsupervised multitask learners. OpenAI blog , 1(8):9, 2019.\\n[24] I. Schlag, S. Sukhbaatar, A. Celikyilmaz, W. tau Yih, J. Weston, J. Schmidhuber, and X. Li.\\nLarge language model programs, 2023.\\n[25] N. Shinn, B. Labash, and A. Gopinath. Reﬂexion: an autonomous agent with dynamic memory\\nand self-reﬂection, 2023.\\n[26] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker,\\nM. Lai, A. Bolton, et al. Mastering the game of go without human knowledge. nature , 550\\n(7676):354–359, 2017.\\n[27] S. A. Sloman. The empirical case for two systems of reasoning. Psychological bulletin , 119(1):\\n3, 1996.\\n[28] K. E. Stanovich. Who is rational? Studies of individual differences in reasoning . Psychology\\nPress, 1999.\\n[29] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozi `ere, N. Goyal,\\nE. Hambro, F. Azhar, et al. Llama: Open and efﬁcient foundation language models. arXiv\\npreprint arXiv:2302.13971 , 2023.\\n[30] S. Verma, J. Fu, S. Yang, and S. Levine. Chai: A chatbot ai for task-oriented dialogue with\\nofﬂine reinforcement learning. In Proceedings of the 2022 Conference of the North American\\nChapter of the Association for Computational Linguistics: Human Language Technologies ,\\npages 4471–4491, 2022.\\n[31] E. Wallace, N. Tomlin, A. Xu, K. Yang, E. Pathak, M. Ginsberg, and D. Klein. Automated\\ncrossword solving. arXiv preprint arXiv:2205.09665 , 2022.\\n[32] L. Wang, W. Xu, Y . Lan, Z. Hu, Y . Lan, R. K.-W. Lee, and E.-P. Lim. Plan-and-solve prompting:\\nImproving zero-shot chain-of-thought reasoning by large language models, 2023.\\n[33] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, and D. Zhou. Self-consistency improves chain\\nof thought reasoning in language models. arXiv preprint arXiv:2203.11171 , 2022.\\n[34] Z. Wang, S. Cai, A. Liu, X. Ma, and Y . Liang. Describe, explain, plan and select: Interactive\\nplanning with large language models enables open-world multi-task agents, 2023.\\n[35] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D. Zhou. Chain of thought\\nprompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903 , 2022.\\n[36] Y . Xie, K. Kawaguchi, Y . Zhao, X. Zhao, M.-Y . Kan, J. He, and Q. Xie. Decomposition\\nenhances reasoning via self-evaluation guided decoding, 2023.\\n[37] S. Yang, O. Nachum, Y . Du, J. Wei, P. Abbeel, and D. Schuurmans. Foundation models for\\ndecision making: Problems, methods, and opportunities, 2023.\\n[38] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y . Cao. ReAct: Synergizing\\nreasoning and acting in language models. arXiv preprint arXiv:2210.03629 , 2022.\\n[39] S. Zhang, Z. Chen, Y . Shen, M. Ding, J. B. Tenenbaum, and C. Gan. Planning with large\\nlanguage models for code generation. In The Eleventh International Conference on Learning\\nRepresentations , 2023. URL https://openreview.net/forum?id=Lr8cOOtYbfL .\\n11', metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 10}), Document(page_content='Published as a conference paper at ICLR 2023\\nSELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT\\nREASONING IN LANGUAGE MODELS\\nXuezhi Wang†‡Jason Wei†Dale Schuurmans†Quoc Le†Ed H. Chi†\\nSharan Narang†Aakanksha Chowdhery†Denny Zhou†§\\n†Google Research, Brain Team\\n‡xuezhiw@google.com ,§dennyzhou@google.com\\nABSTRACT\\nChain-of-thought prompting combined with pre-trained large language models has\\nachieved encouraging results on complex reasoning tasks. In this paper, we propose\\na new decoding strategy, self-consistency , to replace the naive greedy decoding\\nused in chain-of-thought prompting. It ﬁrst samples a diverse set of reasoning paths\\ninstead of only taking the greedy one, and then selects the most consistent answer\\nby marginalizing out the sampled reasoning paths. Self-consistency leverages the\\nintuition that a complex reasoning problem typically admits multiple different ways\\nof thinking leading to its unique correct answer. Our extensive empirical evaluation\\nshows that self-consistency boosts the performance of chain-of-thought prompting\\nwith a striking margin on a range of popular arithmetic and commonsense reasoning\\nbenchmarks, including GSM8K (+17.9%), SV AMP (+11.0%), AQuA (+12.2%),\\nStrategyQA (+6.4%) and ARC-challenge (+3.9%).\\n1 I NTRODUCTION\\nAlthough language models have demonstrated remarkable success across a range of NLP tasks, their\\nability to demonstrate reasoning is often seen as a limitation, which cannot be overcome solely by\\nincreasing model scale (Rae et al., 2021; BIG-bench collaboration, 2021, inter alia ). In an effort\\nto address this shortcoming, Wei et al. (2022) have proposed chain-of-thought prompting , where\\na language model is prompted to generate a series of short sentences that mimic the reasoning\\nprocess a person might employ in solving a task. For example, given the question “If there are 3\\ncars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?” , instead\\nof directly responding with “5”, a language model would be prompted to respond with the entire\\nchain-of-thought: “There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 +\\n2 = 5 cars. The answer is 5. ” . It has been observed that chain-of-thought prompting signiﬁcantly\\nimproves model performance across a variety of multi-step reasoning tasks (Wei et al., 2022).\\nIn this paper, we introduce a novel decoding strategy called self-consistency to replace the greedy\\ndecoding strategy used in chain-of-thought prompting (Wei et al., 2022), that further improves\\nlanguage models’ reasoning performance by a signiﬁcant margin. Self-consistency leverages the\\nintuition that complex reasoning tasks typically admit multiple reasoning paths that reach a correct\\nanswer (Stanovich & West, 2000). The more that deliberate thinking and analysis is required for a\\nproblem (Evans, 2010), the greater the diversity of reasoning paths that can recover the answer.\\nFigure 1 illustrates the self-consistency method with an example. We ﬁrst prompt the language model\\nwith chain-of-thought prompting, then instead of greedily decoding the optimal reasoning path, we\\npropose a “sample-and-marginalize” decoding procedure: we ﬁrst sample from the language model’s\\ndecoder to generate a diverse set of reasoning paths; each reasoning path might lead to a different\\nﬁnal answer, so we determine the optimal answer by marginalizing out the sampled reasoning paths\\nto ﬁnd the most consistent answer in the ﬁnal answer set. Such an approach is analogous to the\\nhuman experience that if multiple different ways of thinking lead to the same answer, one has greater\\nconﬁdence that the ﬁnal answer is correct. Compared to other decoding methods, self-consistency\\navoids the repetitiveness and local-optimality that plague greedy decoding, while mitigating the\\nstochasticity of a single sampled generation.\\n1arXiv:2203.11171v4  [cs.CL]  7 Mar 2023', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 0}), Document(page_content='Published as a conference paper at ICLR 2023\\nLanguage \\nmodel Q: If there are 3 cars in the parking \\nlot and 2 more cars arrive, how many \\ncars are in the parking lot?\\nA: There are 3 cars in the parking lot \\nalready. 2 more arrive. Now there are \\n3 + 2 = 5 cars. The answer is 5. \\n…\\nQ: Janet’s ducks lay 16 eggs per day. \\nShe eats three for breakfast every \\nmorning and bakes muffins for her \\nfriends every day with four. She sells \\nthe remainder for $2 per egg. How \\nmuch does she make every day? \\nA:She has 16 - 3 - 4 = 9 eggs \\nleft. So she makes $2 * 9 = \\n$18 per day. Sample a diverse set of \\nreasoning paths\\nShe eats 3 for breakfast, so \\nshe has 16 - 3 = 13 left. Then \\nshe bakes muffins, so she \\nhas 13 - 4 = 9 eggs left. So \\nshe has 9 eggs * $2 = $18. This means she she sells the \\nremainder for $2 * (16 - 4 - 3) \\n= $26 per day. The answer is $18. \\nThe answer is $26. \\nThe answer is $18. The answer is $18.Marginalize out reasoning paths \\nto aggregate final answers Language \\nmodel This means she uses 3 + 4 = 7 eggs every day.  \\nShe sells the remainder for $2 per egg, so in \\ntotal she sells 7 * $2 = $14 per day. \\nThe answer is $14. The answer is $14. Greedy decode\\nFigure 1: The self-consistency method contains three steps: (1) prompt a language model using\\nchain-of-thought (CoT) prompting; (2) replace the “greedy decode” in CoT prompting by sampling\\nfrom the language model’s decoder to generate a diverse set of reasoning paths; and (3) marginalize\\nout the reasoning paths and aggregate by choosing the most consistent answer in the ﬁnal answer set.\\nSelf-consistency is far simpler than prior approaches that either train an additional veriﬁer (Cobbe\\net al., 2021) or train a re-ranker given additional human annotations to improve generation quality\\n(Thoppilan et al., 2022). Instead, self-consistency is entirely unsupervised , works off-the-shelf with\\npre-trained language models, requires no additional human annotation, and avoids any additional\\ntraining, auxiliary models or ﬁne-tuning. Self-consistency also differs from a typical ensemble\\napproach where multiple models are trained and the outputs from each model are aggregated, it acts\\nmore like a “self-ensemble” that works on top of a single language model.\\nWe evaluate self-consistency on a wide range of arithmetic and commonsense reasoning tasks over\\nfour language models with varying scales: the public UL2-20B (Tay et al., 2022) and GPT-3-175B\\n(Brown et al., 2020), and two densely-activated decoder-only language models: LaMDA-137B\\n(Thoppilan et al., 2022) and PaLM-540B (Chowdhery et al., 2022). On all four language models,\\nself-consistency improves over chain-of-thought prompting by a striking margin across all tasks. In\\nparticular, when used with PaLM-540B or GPT-3, self-consistency achieves new state-of-the-art levels\\nof performance across arithmetic reasoning tasks, including GSM8K (Cobbe et al., 2021) (+17.9%\\nabsolute accuracy gains), SV AMP (Patel et al., 2021) (+11.0%), AQuA (Ling et al., 2017) (+12.2%),\\nand across commonsense reasoning tasks such as StrategyQA (Geva et al., 2021) (+6.4%) and ARC-\\nchallenge (Clark et al., 2018) (+3.9%). In additional experiments, we show self-consistency can\\nrobustly boost performance on NLP tasks where adding a chain-of-thought might hurt performance\\ncompared to standard prompting (Ye & Durrett, 2022). We also show self-consistency signiﬁcantly\\noutperforms sample-and-rank, beam search, ensemble-based approaches, and is robust to sampling\\nstrategies and imperfect prompts.\\n2 S ELF-CONSISTENCY OVER DIVERSE REASONING PATHS\\nA salient aspect of humanity is that people think differently. It is natural to suppose that in tasks\\nrequiring deliberate thinking, there are likely several ways to attack the problem. We propose that\\nsuch a process can be simulated in language models via sampling from the language model’s decoder.\\nFor instance, as shown in Figure 1, a model can generate several plausible responses to a math\\nquestion that all arrive at the same correct answer (Outputs 1 and 3). Since language models are not\\nperfect reasoners, the model might also produce an incorrect reasoning path or make a mistake in\\none of the reasoning steps (e.g., in Output 2), but such solutions are less likely to arrive at the same\\nanswer. That is, we hypothesize that correct reasoning processes, even if they are diverse, tend to\\nhave greater agreement in their ﬁnal answer than incorrect processes.\\nWe leverage this intuition by proposing the following self-consistency method. First, a language\\nmodel is prompted with a set of manually written chain-of-thought exemplars (Wei et al., 2022). Next,\\n2', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 1}), Document(page_content='Published as a conference paper at ICLR 2023\\nGSM8K MultiArith AQuA SV AMP CSQA ARC-c\\nGreedy decode 56.5 94.7 35.8 79.0 79.0 85.2\\nWeighted avg (unnormalized) 56.3 ±0.0 90.5±0.0 35.8±0.073.0±0.074.8±0.082.3±0.0\\nWeighted avg (normalized) 22.1 ±0.0 59.7±0.0 15.7±0.040.5±0.052.1±0.051.7±0.0\\nWeighted sum (unnormalized) 59.9 ±0.0 92.2±0.0 38.2±0.076.2±0.076.2±0.083.5±0.0\\nWeighted sum (normalized) 74.1 ±0.0 99.3±0.0 48.0±0.086.8±0.080.7±0.088.7±0.0\\nUnweighted sum (majority vote) 74.4 ±0.1 99.3±0.0 48.3±0.586.6±0.180.7±0.188.7±0.1\\nTable 1: Accuracy comparison of different answer aggregation strategies on PaLM-540B.\\nwe sample a set of candidate outputs from the language model’s decoder, generating a diverse set of\\ncandidate reasoning paths. Self-consistency is compatible with most existing sampling algorithms,\\nincluding temperature sampling (Ackley et al., 1985; Ficler & Goldberg, 2017), top- ksampling (Fan\\net al., 2018; Holtzman et al., 2018; Radford et al., 2019), and nucleus sampling (Holtzman et al.,\\n2020). Finally, we aggregate the answers by marginalizing out the sampled reasoning paths and\\nchoosing the answer that is the most consistent among the generated answers.\\nIn more detail, assume the generated answers aiare from a ﬁxed answer set, ai∈A, where\\ni= 1, . . . , m indexes the mcandidate outputs sampled from the decoder. Given a prompt and a\\nquestion, self-consistency introduces an additional latent variable ri, which is a sequence of tokens\\nrepresenting the reasoning path in the i-th output, then couples the generation of (ri,ai)where\\nri→ai, i.e., generating a reasoning path riis optional and only used to reach the ﬁnal answer ai. As\\nan example, consider Output 3 from Figure 1: the ﬁrst few sentences “ She eats 3 for breakfast ... So\\nshe has 9 eggs * $2 = $18. ” constitutes ri, while the answer 18from the last sentence, “ The answer\\nis $18 ”, is parsed as ai.1After sampling multiple (ri,ai)from the model’s decoder, self-consistency\\napplies a marginalization over riby taking a majority vote over ai, i.e., arg maxa∑m\\ni=11(ai=a),\\nor as we deﬁned as the most “consistent” answer among the ﬁnal answer set.\\nIn Table 1, we show the test accuracy over a set of reasoning tasks by using different answer\\naggregation strategies. In addition to majority vote, one can also weight each (ri,ai)byP(ri,ai|\\nprompt ,question )when aggregating the answers. Note to compute P(ri,ai|prompt ,question ), we\\ncan either take the unnormalized probability of the model generating (ri,ai)given (prompt ,question ),\\nor we can normalize the conditional probability by the output length (Brown et al., 2020), i.e.,\\nP(ri,ai|prompt ,question ) = exp1\\nK∑K\\nk=1logP(tk|prompt ,question ,t1,...,tk−1), (1)\\nwhere logP(tk|prompt ,question , t1, . . . , t k−1)is the log probability of generating the k-th token\\ntkin(ri,ai)conditioned on the previous tokens, and Kis the total number of tokens in (ri,ai).\\nIn Table 1, we show that taking the “unweighted sum”, i.e., taking a majority vote directly over ai\\nyields a very similar accuracy as aggregating using the “normalized weighted sum”. We took a closer\\nlook at the model’s output probabilities and found this is because for each (ri,ai), the normalized\\nconditional probabilities P(ri,ai|prompt ,question )are quite close to each other, i.e., the language\\nmodel regards those generations as “similarly likely”.2Additionally, when aggregating the answers,\\nthe results in Table 1 show that the “normalized” weighted sum (i.e., Equation 1) yields a much\\nhigher accuracy compared to its unnormalized counterpart. For completeness, in Table 1 we also\\nreport the results by taking a “weighted average”, i.e., each agets a score of its weighted sum divided\\nby∑m\\ni=11(ai=a), which results in a much worse performance.\\nSelf-consistency explores an interesting space between open-ended text generation and optimal\\ntext generation with a ﬁxed answer. Reasoning tasks typically have ﬁxed answers, which is why\\nresearchers have generally considered greedy decoding approaches (Radford et al., 2019; Wei et al.,\\n2022; Chowdhery et al., 2022). However, we have found that even when the desired answer is ﬁxed,\\nintroducing diversity in the reasoning processes can be highly beneﬁcial; therefore we leverage\\n1The parser is task dependent. For arithmetic reasoning, we parse the ﬁrst numerical part as the ﬁnal answer\\nafter the model generates “The answer is ”. For commonsense reasoning, we parse the full string answer as the\\nﬁnal answer after the model generates “The answer is ”. Most generated outputs have a consistent format of\\n“{Reasoning paths}. The answer is X.” if we prompt the language model in this format.\\n2This also means that the language model is not well calibrated and thus cannot distinguish well between\\ncorrect solutions and wrong solutions, which also explains why additional re-rankers were trained to better judge\\nthe quality of the solutions in previous work (Cobbe et al., 2021; Thoppilan et al., 2022).\\n3', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 2}), Document(page_content='Published as a conference paper at ICLR 2023\\nsampling, as commonly used for open-ended text generation (Radford et al., 2019; Brown et al., 2020;\\nThoppilan et al., 2022), to achieve this goal. One should note that self-consistency can be applied\\nonly to problems where the ﬁnal answer is from a ﬁxed answer set, but in principle this approach can\\nbe extended to open-text generation problems if a good metric of consistency can be deﬁned between\\nmultiple generations, e.g., whether two answers agree or contradict each other.\\n3 E XPERIMENTS\\nWe conducted a series of experiments to compare the proposed self-consistency method with existing\\napproaches on a range of reasoning benchmarks. We ﬁnd that self-consistency robustly improves\\nreasoning accuracy for every language model considered, spanning a wide range of model scales.\\n3.1 E XPERIMENT SETUP\\nTasks and datasets. We evaluate self-consistency on the following reasoning benchmarks.3\\n•Arithmetic reasoning . For these tasks, we used the Math Word Problem Repository (Koncel-\\nKedziorski et al., 2016), including AddSub (Hosseini et al., 2014), MultiArith (Roy & Roth,\\n2015), and ASDiv (Miao et al., 2020). We also included AQUA-RAT (Ling et al., 2017), a\\nrecently published benchmark of grade-school-math problems (GSM8K; Cobbe et al., 2021),\\nand a challenge dataset over math word problems (SV AMP; Patel et al., 2021).\\n•Commonsense reasoning . For these tasks, we used CommonsenseQA (Talmor et al., 2019),\\nStrategyQA (Geva et al., 2021), and the AI2 Reasoning Challenge (ARC) (Clark et al., 2018).\\n•Symbolic Reasoning . We evaluate two symbolic reasoning tasks: last letter concatenation (e.g.,\\nthe input is “Elon Musk” and the output should be “nk”), and Coinﬂip (e.g., a coin is heads-up,\\nafter a few ﬂips is the coin still heads-up?) from Wei et al. (2022).\\nLanguage models and prompts. We evaluate self-consistency over four transformer-based lan-\\nguage models with varying scales:\\n•UL2 (Tay et al., 2022) is an encoder-decoder model trained on a mixture of denoisers with 20-\\nbillion parameters. UL2 is completely open-sourced4and has similar or better performance than\\nGPT-3 on zero-shot SuperGLUE, with only 20B parameters and thus is more compute-friendly;\\n•GPT-3 (Brown et al., 2020) with 175-billion parameters. We use two public engines code-davinci-\\n001andcode-davinci-002 from the Codex series (Chen et al., 2021) to aid reproducibility;5\\n•LaMDA-137B (Thoppilan et al., 2022) is a dense left-to-right, decoder-only language model with\\n137-billion parameters, pre-trained on a mixture of web documents, dialog data and Wikipedia;\\n•PaLM-540B (Chowdhery et al., 2022) is a dense left-to-right, decoder-only language model with\\n540-billion parameters, pre-trained on a high quality corpus of 780 billion tokens with ﬁltered\\nwebpages, books, Wikipedia, news articles, source code, and social media conversations.\\nWe perform all experiments in the few-shot setting, without training or ﬁne-tuning the language\\nmodels. For a fair comparison we use the same prompts as in Wei et al. (2022): for all arithmetic\\nreasoning tasks we use the same set of 8 manually written exemplars; for each commonsense\\nreasoning task, 4-7 exemplars are randomly chosen from the training set with manually composed\\nchain-of-thought prompts.6Full details on the prompts used are given in Appendix A.3.\\nSampling scheme. To sample diverse reasoning paths, we followed similar settings to those\\nsuggested in Radford et al. (2019); Holtzman et al. (2020) for open-text generation. In particular, for\\nUL2-20B and LaMDA-137B we applied temperature sampling with T= 0.5and truncated at the\\ntop-k(k= 40 ) tokens with the highest probability, for PaLM-540B we applied T= 0.7, k= 40 , and\\nfor GPT-3 we use T= 0.7without top- ktruncation. We provide an ablation study in Section 3.5 to\\nshow that self-consistency is generally robust to sampling strategies and parameters.\\n3By default we use the test split for all datasets if the labels are available for evaluation. For CommonsenseQA\\nwe use the dev split; for StrategyQA we use the question-only set from BIG-bench collaboration (2021):\\nhttps://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/strategyqa .\\n4Model checkpoints at https://github.com/google-research/google-research/tree/master/ul2 .\\n5Public API available at https://openai.com/api/ .\\n6Self-consistency is robust to different sets of prompts and we provide a study in Appendix A.1.2.\\n4', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 3}), Document(page_content='Published as a conference paper at ICLR 2023\\n3.2 M AINRESULTS\\nWe report the results of self-consistency averaged over 10 runs, where we sampled 40 outputs\\nindependently from the decoder in each run. The baseline we compare to is chain-of-thought\\nprompting with greedy decoding (Wei et al., 2022), referred to as CoT-prompting , which has been\\npreviously used for decoding in large language models (Chowdhery et al., 2022).\\nArithmetic Reasoning The results are shown in Table 2.7Self-consistency improves the arithmetic\\nreasoning performance over all four language models signiﬁcantly over chain-of-thought prompting.\\nMore surprisingly, the gains become more signiﬁcant when the language model’s scale increases,\\ne.g., we see +3%-6% absolute accuracy improvement over UL2-20B but +9%-23% for LaMDA-\\n137B and GPT-3. For larger models that already achieve high accuracy on most tasks (e.g., GPT-3\\nand PaLM-540B), self-consistency still contributes signiﬁcant additional gains with +12%-18%\\nabsolute accuracy on tasks like AQuA and GSM8K, and +7%-11% on SV AMP and ASDiv. With\\nself-consistency, we achieve new state-of-the-art results on almost all tasks: despite the fact that self-\\nconsistency is unsupervised and task-agnostic, these results compare favorably to existing approaches\\nthat require task-speciﬁc training, or ﬁne-tuning with thousands of examples (e.g., on GSM8K).\\nMethod AddSub MultiArith ASDiv AQuA SV AMP GSM8K\\nPrevious SoTA 94.9a60.5a75.3b37.9c57.4d35e/ 55g\\nUL2-20BCoT-prompting 18.2 10.7 16.9 23.6 12.6 4.1\\nSelf-consistency 24.8 (+6.6) 15.0 (+4.3) 21.5 (+4.6) 26.9 (+3.3) 19.4 (+6.8) 7.3 (+3.2)\\nLaMDA-137BCoT-prompting 52.9 51.8 49.0 17.7 38.9 17.1\\nSelf-consistency 63.5 (+10.6) 75.7 (+23.9) 58.2 (+9.2) 26.8 (+9.1) 53.3 (+14.4) 27.7 (+10.6)\\nPaLM-540BCoT-prompting 91.9 94.7 74.0 35.8 79.0 56.5\\nSelf-consistency 93.7 (+1.8) 99.3 (+4.6) 81.9 (+7.9) 48.3 (+12.5) 86.6 (+7.6) 74.4 (+17.9)\\nGPT-3\\nCode-davinci-001CoT-prompting 57.2 59.5 52.7 18.9 39.8 14.6\\nSelf-consistency 67.8 (+10.6) 82.7 (+23.2) 61.9 (+9.2) 25.6 (+6.7) 54.5 (+14.7) 23.4 (+8.8)\\nGPT-3\\nCode-davinci-002CoT-prompting 89.4 96.2 80.1 39.8 75.8 60.1\\nSelf-consistency 91.6 (+2.2) 100.0 (+3.8) 87.8 (+7.6) 52.0 (+12.2) 86.8 (+11.0) 78.0 (+17.9)\\nTable 2: Arithmetic reasoning accuracy by self-consistency compared to chain-of-thought prompting\\n(Wei et al., 2022). The previous SoTA baselines are obtained from: a: Relevance and LCA operation\\nclassiﬁer (Roy & Roth, 2015), b: Lan et al. (2021), c: Amini et al. (2019), d: Pi et al. (2022), e:\\nGPT-3 175B ﬁnetuned with 7.5k examples (Cobbe et al., 2021), g: GPT-3 175B ﬁnetuned plus an\\nadditional 175B veriﬁer (Cobbe et al., 2021). The best performance for each task is shown in bold.\\nMethod CSQA StrategyQA ARC-e ARC-c Letter (4) Coinﬂip (4)\\nPrevious SoTA 91.2a73.9b86.4c75.0cN/A N/A\\nUL2-20BCoT-prompting 51.4 53.3 61.6 42.9 0.0 50.4\\nSelf-consistency 55.7 (+4.3) 54.9 (+1.6) 69.8 (+8.2) 49.5 (+6.8) 0.0 (+0.0) 50.5 (+0.1)\\nLaMDA-137BCoT-prompting 57.9 65.4 75.3 55.1 8.2 72.4\\nSelf-consistency 63.1 (+5.2) 67.8 (+2.4) 79.3 (+4.0) 59.8 (+4.7) 8.2 (+0.0) 73.5 (+1.1)\\nPaLM-540BCoT-prompting 79.0 75.3 95.3 85.2 65.8 88.2\\nSelf-consistency 80.7 (+1.7) 81.6 (+6.3) 96.4 (+1.1) 88.7 (+3.5) 70.8 (+5.0) 91.2 (+3.0)\\nGPT-3\\nCode-davinci-001CoT-prompting 46.6 56.7 63.1 43.1 7.8 71.4\\nSelf-consistency 54.9 (+8.3) 61.7 (+5.0) 72.1 (+9.0) 53.7 (+10.6) 10.0 (+2.2) 75.9 (+4.5)\\nGPT-3\\nCode-davinci-002CoT-prompting 79.0 73.4 94.0 83.6 70.4 99.0\\nSelf-consistency 81.5 (+2.5) 79.8 (+6.4) 96.0 (+2.0) 87.5 (+3.9) 73.4 (+3.0) 99.5 (+0.5)\\nTable 3: Commonsense and symbolic reasoning accuracy by self-consistency compared to chain-\\nof-thought prompting (Wei et al., 2022). The previous SoTA baselines are obtained from: a:\\nDeBERTaV3-large + KEAR (Xu et al., 2021b), b: Chowdhery et al. (2022), c: UniﬁedQA-FT\\n(Khashabi et al., 2020). The best performance for each task is shown in bold.\\n7The standard deviation of self-consistency is ≤0.5for all tasks and is thus omitted in the table. Please refer\\nto Figure 2, Figure 7 and 8 for the standard deviations under varying numbers of sampled paths.\\n5', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 4}), Document(page_content='Published as a conference paper at ICLR 2023\\nCommonsense and Symbolic Reasoning Table 3 shows the results on commonsense and symbolic\\nreasoning tasks. Similarly, self-consistency yields large gains across all four language models, and\\nobtained SoTA results on 5 out of 6 tasks. For symbolic reasoning, we test the out-of-distribution\\n(OOD) setting where the input prompt contains examples of 2-letters or 2-ﬂips but we test examples\\nof 4-letters and 4-ﬂips (this setting is more challenging as PaLM-540B or GPT-3 can already achieve\\nperfect in-distribution accuracy). In this challenging OOD setting, the gain of self-consistency is still\\nquite signiﬁcant compared to CoT-prompting with sufﬁcient model sizes.\\nTo show the effect of the number of sampled reasoning paths, we plot the accuracy (mean and\\nstandard deviation over 10 runs) with respect to varying numbers of sampled paths (1, 5, 10, 20, 40)\\nin Figure 2. The results show that sampling a higher number (e.g., 40) of reasoning paths leads to a\\nconsistently better performance, further emphasizing the importance of introducing diversity in the\\nreasoning paths. In Table 4, we show self-consistency yields a richer set of reasoning paths compared\\nto greedy decoding with a few example questions from two tasks.\\n0510152025303540\\n#Sampled Reasoning Paths505560657075Accuracy (%)\\nMultiArith\\n0510152025303540\\n#Sampled Reasoning Paths3336394245485154\\nSVAMP\\n0510152025303540\\n#Sampled Reasoning Paths56586062\\nCommonsense QA\\n0510152025303540\\n#Sampled Reasoning Paths505254565860\\nARC (Challenge)\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\nFigure 2: Self-consistency (blue) signiﬁcantly improves accuracy over CoT-prompting with greedy\\ndecoding (orange) across arithmetic and commonsense reasoning tasks, over LaMDA-137B. Sampling\\na higher number of diverse reasoning paths consistently improves reasoning accuracy.\\nGSM8K StrategyQA\\nQuestion Henry made two stops during his 60-mile bike trip. He ﬁrst stopped after 20\\nmiles. His second stop was 15 miles before the end of the trip. How many miles\\ndid he travel between his ﬁrst and second stops?Yes or no: Is Albany, Georgia the most populous\\nUS Albany?\\nGreedy\\nDecodeHe traveled 60 miles in total. He stopped after 20 miles, so he traveled 60 - 20\\n= 40 miles between the ﬁrst and second stops. The answer is 40.Albany, Georgia is the most populous US Al-\\nbany. Thus, the answer is yes.\\nSampled\\nPath 1Henry travelled a total of 60 miles. His ﬁrst stop was 20 miles in, and his\\nsecond stop was 15 miles before the end. So between his ﬁrst and second stops\\nhe travelled 60 - 20 -15 = 25 miles. The answer is 25.The most populous US Albany is Albany, New\\nYork. Thus, Albany, Georgia is not the most\\npopulous US Albany. So the answer is no.\\nSampled\\nPath 2He made two stops during a 60-mile trip. The ﬁrst was 20 miles into the trip.\\nThe second was 15 miles before the end of the trip. This means the second stop\\nwas 60 - 15 = 45 miles into the trip. Since he made the stops in order, the second\\nstop must have been 45 - 20 = 25 miles after the ﬁrst stop. The answer is 25.Albany, Georgia has a population of about\\n88,000. Albany, New York has a population of\\nabout 95,000. Thus, Albany, Georgia is not the\\nmost populous US Albany. So the answer is no.\\nTable 4: Examples where self-consistency helps repair the errors over greedy decode, on PaLM-540B.\\nTwo sampled reasoning paths that are consistent with the ground truth are shown.\\n3.3 S ELF-CONSISTENCY HELPS WHEN CHAIN -OF-THOUGHT HURTS PERFORMANCE\\nYe & Durrett (2022) show that sometimes chain-of-thought prompting could hurt performance\\ncompared to standard prompting in few-shot in-context learning. Here we perform a study using\\nself-consistency to see if it can help ﬁll in the gap, over a set of common NLP tasks, including (1)\\nClosed-Book Question Answering: BoolQ (Clark et al., 2019), HotpotQA (Yang et al., 2018), and\\n(2) Natural Language Inference: e-SNLI (Camburu et al., 2018), ANLI (Nie et al., 2020) and RTE\\n(Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009).\\nThe results over PaLM-540B are shown in Table 5. For some tasks (e.g., ANLI-R1, e-SNLI, RTE),\\nadding chain-of-thought does hurt performance compared to standard prompting (Brown et al., 2020),\\nbut self-consistency is able to robustly boost the performance and outperform standard prompting,\\nmaking it a reliable way to add rationales in few-shot in-context learning for common NLP tasks.\\nANLI R1 / R2 / R3 e-SNLI RTE BoolQ HotpotQA (EM/F1)\\nStandard-prompting (no-rationale) 69.1 / 55.8 / 55.8 85.8 84.8 71.3 27.1 / 36.8\\nCoT-prompting (Wei et al., 2022) 68.8 / 58.9 / 60.6 81.0 79.1 74.2 28.9 / 39.8\\nSelf-consistency 78.5 /64.5 /63.4 88.4 86.3 78.4 33.8 / 44.6\\nTable 5: Compare Standard/CoT prompting with self-consistency on common NLP tasks.\\n6', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 5}), Document(page_content='Published as a conference paper at ICLR 2023\\n3.4 C OMPARE TO OTHER EXISTING APPROACHES\\nWe conduct a set of additional studies and show that self-consistency signiﬁcantly outperforms\\nexisting methods including sample-and-rank, beam search, and ensemble-based approaches.\\nComparison to Sample-and-Rank One commonly used approach to improve generation quality is\\nsample-and-rank, where multiple sequences are sampled from the decoder and then ranked according\\nto each sequence’s log probability (Adiwardana et al., 2020). We compare self-consistency with\\nsample-and-rank on GPT-3 code-davinci-001 , by sampling the same number of sequences from the\\ndecoder as self-consistency and taking the ﬁnal answer from the top-ranked sequence. The results are\\nshown in Figure 3. While sample-and-rank does improve the accuracy with additionally sampled\\nsequences and ranking, the gain is much smaller compared to self-consistency.\\n0510152025303540\\n#Sampled Reasoning Paths12141618202224Accuracy (%)\\nGSM8K\\n0510152025303540\\n#Sampled Reasoning Paths50556065707580Accuracy (%)\\nMultiArith\\n0510152025303540\\n#Sampled Reasoning Paths303540455055Accuracy (%)\\nARC (Challenge)\\nSelf Consistency (Multi-path)\\nSample & Rank (Multi-path)\\nGreedy Decode (Single-path)\\nFigure 3: Self-consistency signiﬁcantly outperforms sample-and-rank with the same # of samples.\\nComparison to Beam Search In Table 6, we compare self-consistency with beam search decoding\\non the UL2-20B model. For a fair comparison we report the accuracy under the same number of\\nbeams and reasoning paths. On both tasks self-consistency outperforms beam search signiﬁcantly.\\nNote self-consistency can also adopt beam search to decode each reasoning path (results are shown\\nas “Self-consistency using beam search”), but its performance is worse compared to self-consistency\\nwith sampling. The reason is that beam search yields a lower diversity in the outputs (Li & Jurafsky,\\n2016), while in self-consistency the diversity of the reasoning paths is the key to a better performance.\\nBeam size / Self-consistency paths 1 5 10 20 40\\nAQuABeam search decoding (top beam) 23.6 19.3 16.1 15.0 10.2\\nSelf-consistency using beam search 23.6 19.8 ±0.321.2±0.724.6±0.424.2±0.5\\nSelf-consistency using sampling 19.7 ±2.524.9±2.625.3±1.826.7±1.026.9±0.5\\nMultiArithBeam search decoding (top beam) 10.7 12.0 11.3 11.0 10.5\\nSelf-consistency using beam search 10.7 11.8 ±0.011.4±0.112.3±0.110.8±0.1\\nSelf-consistency using sampling 9.5 ±1.2 11.3±1.212.3±0.813.7±0.914.7±0.3\\nTable 6: Compare self-consistency with beam search decoding on the UL2-20B model.\\nComparison to Ensemble-based Approaches We further compare self-consistency to ensemble-\\nbased methods for few-shot learning. In particular, we consider ensembling by: (1) prompt order\\npermutation: we randomly permute the exemplars in the prompt 40 times to mitigate model’s\\nsensitivity to prompt order (Zhao et al., 2021; Lu et al., 2021); and (2) multiple sets of prompts\\n(Gao et al., 2021): we manually write 3different sets of prompts. We took majority vote of the\\nanswers from greedy decoding in both approaches as an ensemble. Table 7 shows that compared to\\nself-consistency, existing ensemble-based approaches achieve a much smaller gain.8In addition, note\\nthat self-consistency is different from a typical model-ensemble approach, where multiple models\\nare trained and their outputs are aggregated. Self-consistency acts more like a “self-ensemble” on\\ntop of a single language model. We additionally show the results of ensembling multiple models in\\nAppendix A.1.3 where the model-ensembles perform much worse compared to self-consistency.\\nGSM8K MultiArith SV AMP ARC-e ARC-c\\nCoT (Wei et al., 2022) 17.1 51.8 38.9 75.3 55.1\\nEnsemble (3 sets of prompts) 18.6 ±0.5 57.1±0.7 42.1±0.6 76.6±0.1 57.0±0.2\\nEnsemble (40 prompt permutations) 19.2 ±0.1 60.9±0.2 42.7±0.1 76.9±0.1 57.0±0.1\\nSelf-Consistency (40 sampled paths) 27.7±0.2 75.7±0.3 53.3±0.2 79.3±0.3 59.8±0.2\\nTable 7: Self-consistency outperforms prompt-order and multi-prompt ensembles on LaMDA-137B.\\n8Self-consistency is compatible with both ensemble approaches and we show the results in Appendix A.1.4.\\n7', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 6}), Document(page_content='Published as a conference paper at ICLR 2023\\n3.5 A DDITIONAL STUDIES\\nWe conducted a number of additional experiments to analyze different aspects of the self-consistency\\nmethod, including its robustness to sampling strategies and parameters, and how it works with\\nimperfect prompts and non-natural-language reasoning paths.\\nSelf-Consistency is Robust to Sampling Strategies and Scaling We show self-consistency is\\nrobust to sampling strategies and parameters, by varying Tin temperature sampling (Ackley et al.,\\n1985; Ficler & Goldberg, 2017), kin top- ksampling (Fan et al., 2018; Holtzman et al., 2018; Radford\\net al., 2019), and pin nucleus sampling (Holtzman et al., 2020), over PaLM-540B in Figure 4 (left).\\nFigure 4 (right) shows that self-consistency robustly improves performance across all scales for the\\nLaMDA-137B model series. The gain is relatively lower for smaller models due to certain abilities\\n(e.g., arithmetic) only emerge when the model reaches a sufﬁcient scale (Brown et al., 2020).\\n0510152025303540\\n#Sampled Reasoning Paths444852566064687276Accuracy (%)\\nT=0.7, k=40\\nT=0.5, k=40\\nT=0.3, k=40\\nT=0.7, k=20\\nT=0.7, no top k\\np=0.95\\np=0.9\\nGreedy Decode\\n12 51020 50100200\\nModel size (#param in billions)510152025Accuracy (%)\\nSelf Consistency\\nGreedy Decode\\nFigure 4: GSM8K accuracy. (Left) Self-consistency is robust to various sampling strategies and\\nparameters. (Right) Self-consistency improves performance across language model scales.\\nSelf-Consistency Improves Robustness to Imperfect Prompts For few-shot learning with man-\\nually constructed prompts, human annotators sometimes make minor mistakes when creating the\\nprompts. We further study if self-consistency can help improve a language model’s robustness to\\nimperfect prompts.9We show the results in Table 8: while imperfect prompts decrease accuracy with\\ngreedy decoding (17.1 →14.9), self-consistency can ﬁll in the gaps and robustly improve the results.\\nAdditionally, we found that the consistency (in terms of % of decodes agreeing with the ﬁnal\\naggregated answer) is highly correlated with accuracy (Figure 5, over GSM8K). This suggests that\\none can use self-consistency to provide an uncertainty estimate of the model in its generated solutions.\\nIn other words, one can use low consistency as an indicator that the model has low conﬁdence; i.e.,\\nself-consistency confers some ability for the model to “know when it doesn’t know”.\\nLaMDA-137BPrompt with correct chain-of-thought 17.1\\nPrompt with imperfect chain-of-thought 14.9\\n+ Self-consistency (40 paths) 23.4\\nPrompt with equations 5.0\\n+ Self-consistency (40 paths) 6.5\\nPaLM-540BZero-shot CoT (Kojima et al., 2022) 43.0\\n+ Self-consistency (40 paths) 69.2\\nTable 8: Self-consistency works under imperfect prompts, equa-\\ntion prompts and zero-shot chain-of-thought for GSM8K.\\n0 20 40 60 80 100\\nConsistency (%)020406080100Accuracy (%)\\nFigure 5: The consistency is cor-\\nrelated with model’s accuracy.\\nSelf-Consistency Works for Non-Natural-Language Reasoning Paths and Zero-shot CoT We\\nalso tested the generality of the self-consistency concept to alternative forms of intermediate reasoning\\nlike equations (e.g., from “ There are 3 cars in the parking lot already. 2 more arrive. Now there\\nare 3 + 2 = 5 cars. ” to “ 3 + 2 = 5 ”). The results are shown in Table 8 (“Prompt with equations”):\\nself-consistency still improves accuracy by generating intermediate equations; however, compared to\\ngenerating natural language reasoning paths, the gain is smaller since the equations are much shorter\\nand less opportunity remains for generating diversity in the decoding process. In addition, we tested\\nself-consistency with zero-shot chain-of-thought (Kojima et al., 2022) and show that self-consistency\\nworks for zero-shot CoT as well and improves the results signiﬁcantly (+26.2%) in Table 8.\\n9We use the same prompts as before, but swap all the numbers in the reasoning paths with random numbers\\nexcept the ﬁnal answer, e.g., from “ There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 +\\n2 = 5 cars. ” to “ There are 7 cars in the parking lot already. 6 more arrive. Now there are 7 + 6 = 5 cars. ”.\\n8', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 7}), Document(page_content='Published as a conference paper at ICLR 2023\\n4 R ELATED WORK\\nReasoning in language models. Language models are known to struggle in Type 2 tasks, such as\\narithmetic, logical and commonsense reasoning (Evans, 2010). Previous work has primarily focused\\nonspecialized approaches for improving reasoning (Andor et al., 2019; Ran et al., 2019; Geva et al.,\\n2020; Pi˛ ekos et al., 2021). Compared to prior work, self-consistency is applicable to a wide range of\\nreasoning tasks without any additional supervision or ﬁne-tuning, while still substantially improving\\nthe performance of the chain-of-thought prompting approach proposed in Wei et al. (2022).\\nSampling and re-ranking in language models. Multiple decoding strategies for language models\\nhave been proposed in the literature, e.g., temperature sampling (Ackley et al., 1985; Ficler &\\nGoldberg, 2017), top- ksampling (Fan et al., 2018; Holtzman et al., 2018; Radford et al., 2019),\\nnucleus sampling (Holtzman et al., 2020), minimum Bayes risk decoding (Eikema & Aziz, 2020; Shi\\net al., 2022), and typical decoding (Meister et al., 2022). Other work has sought to explicitly promote\\ndiversity in the decoding process (Batra et al., 2012; Li et al., 2016; Vijayakumar et al., 2018).\\nRe-ranking is another common approach to improve generation quality in language models (Adiwar-\\ndana et al., 2020; Shen et al., 2021). Thoppilan et al. (2022) collect additional human annotations\\nto train a re-ranker for response ﬁltering. Cobbe et al. (2021) train a “veriﬁer” to re-rank generated\\nsolutions, which substantially improves the solve rate on math tasks compared to just ﬁne-tuning the\\nlanguage model. Elazar et al. (2021) improve the consistency of factual knowledge extraction by\\nextending pre-training with an additional consistency loss. All these methods require either training\\nan additional re-ranker or collecting additional human annotation, while self-consistency requires no\\nadditional training, ﬁne-tuning, nor extra data collection.\\nExtract reasoning paths. Some previous work has considered task-speciﬁc approaches for iden-\\ntifying reasoning paths, such as constructing semantic graphs (Xu et al., 2021a), learning an RNN\\nto retrieve reasoning paths over the Wikipedia graph (Asai et al., 2020), ﬁne-tuning with human\\nannotated reasoning paths on math problems (Cobbe et al., 2021), or training an extractor with\\nheuristic-based pseudo reasoning paths (Chen et al., 2019). More recently, the importance of di-\\nversity in the reasoning processes has been noticed, but only leveraged via task-speciﬁc training,\\neither through an additional QA model over extracted reasoning paths (Chen et al., 2019), or by the\\nintroduction of latent variables in a commonsense knowledge graph (Yu et al., 2022). Compared to\\nthese approaches, self-consistency is far simpler and requires no additional training. The approach\\nwe propose simply couples the generation of reasoning paths and a ﬁnal answer by sampling from\\nthe decoder, using aggregation to recover the most consistent answer without additional modules.\\nConsistency in language models. Some prior work has shown that language models can suffer\\nfrom inconsistency in conversation (Adiwardana et al., 2020), explanation generation (Camburu et al.,\\n2020), and factual knowledge extraction (Elazar et al., 2021). Welleck et al. (2020) use “consistency”\\nto refer to generating an inﬁnite-length sequence in recurrent language models. Nye et al. (2021)\\nimprove the logical consistency of samples from a System 1 model by adding a System 2-inspired\\nlogical reasoning module. In this paper we focus on a slightly different notion of “consistency”, i.e.,\\nutilizing answer consistency among diverse reasoning paths to improve accuracy.\\n5 C ONCLUSION AND DISCUSSION\\nWe introduced a simple yet effective method called self-consistency, and observed that it signiﬁcantly\\nimproves accuracy in a range of arithmetic and commonsense reasoning tasks, across four large\\nlanguage models with varying scales. Beyond accuracy gains, self-consistency is also useful for\\ncollecting rationales when performing reasoning tasks with language models, and for providing\\nuncertainty estimates and improved calibration of language model outputs.\\nOne limitation of self-consistency is that it incurs more computation cost. In practice people can try a\\nsmall number of paths (e.g., 5 or 10) as a starting point to realize most of the gains while not incurring\\ntoo much cost, as in most cases the performance saturates quickly (Figure 2). As part of future work,\\none could use self-consistency to generate better supervised data to ﬁne-tune the model, such that the\\nmodel can give more accurate predictions in a single inference run after ﬁne-tuning. In addition, we\\nobserved that language models can sometimes generate incorrect or nonsensical reasoning paths (e.g.,\\nthe StrategyQA example in Table 4, the two population numbers are not exactly correct), and further\\nwork is needed to better ground models’ rationale generations.\\n9', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 8}), Document(page_content='Published as a conference paper at ICLR 2023\\nREPRODUCIBILITY STATEMENT\\nIn experiments, we included four different language models with varying scales. Two of them are pub-\\nlic models: UL2 is a completely open-sourced model with model checkpoints available at https://\\ngithub.com/google-research/google-research/tree/master/ul2 ; GPT-3 is\\nalso a public model with public API available at https://openai.com/api/ . For GPT-3,\\nwe have included two public engines (“code-davinci-001” and “code-davinci-002”) to further aid\\nreproducibility, as Codex is currently free so anyone can reproduce the results. In addition, as our\\nresults make use of LaMDA-137B and PaLM-540B that are not publicly available, we provide the\\nexact input prompts for all tasks in Appendix A.3 (and note that we do not perform any ﬁnetuning\\nand only apply prompting to off-the-shelf language models).\\nETHICS STATEMENT\\nAs we stated in the discussion, language models can sometimes generate nonsensical or non-factual\\nreasoning paths, so one should use language models’ outputs with extra caution. We deal with\\nreasoning tasks mostly and the generated rationales are only used for inspecting how a model reaches\\nits answer. One could potentially use the generated rationales to further check why the model makes\\ncertain mistakes or whether the model contains any biases when performing a certain task. For\\nlanguage model in real-world use, further work is needed to better ground models’ predictions and\\nimprove model’s factuality and safety, to ensure the models do not cause harms to users.\\nREFERENCES\\nDavid H. Ackley, Geoffrey E. Hinton, and Terrence J. Sejnowski. A learning algorithm for boltzmann\\nmachines. Cognitive Science , 9(1):147–169, 1985. ISSN 0364-0213. URL https://www.\\nsciencedirect.com/science/article/pii/S0364021385800124 .\\nDaniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel, Romal Thoppilan,\\nZi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, and Quoc V . Le. Towards a human-like\\nopen-domain chatbot, 2020.\\nAida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh\\nHajishirzi. MathQA: Towards interpretable math word problem solving with operation-based\\nformalisms. In Proceedings of the 2019 Conference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long\\nand Short Papers) , pp. 2357–2367. Association for Computational Linguistics, June 2019. URL\\nhttps://aclanthology.org/N19-1245 .\\nDaniel Andor, Luheng He, Kenton Lee, and Emily Pitler. Giving BERT a calculator: Finding\\noperations and arguments with reading comprehension. In Proceedings of the 2019 Conference on\\nEmpirical Methods in Natural Language Processing and the 9th International Joint Conference\\non Natural Language Processing (EMNLP-IJCNLP) , 2019. URL https://aclanthology.\\norg/D19-1609 .\\nAkari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, and Caiming Xiong. Learn-\\ning to retrieve reasoning paths over wikipedia graph for question answering. In International\\nConference on Learning Representations , 2020. URL https://openreview.net/forum?\\nid=SJgVHkrYDH .\\nRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and\\nIdan Szpektor. The second pascal recognising textual entailment challenge. In Proceedings of the\\nsecond PASCAL challenges workshop on recognising textual entailment , 2006.\\nDhruv Batra, Payman Yadollahpour, Abner Guzman-Rivera, and Gregory Shakhnarovich. Diverse\\nm-best solutions in markov random ﬁelds. In Proceedings of the 12th European Conference on\\nComputer Vision - Volume Part V , ECCV’12, pp. 1–16, Berlin, Heidelberg, 2012. Springer-Verlag.\\nISBN 9783642337147. URL https://doi.org/10.1007/978-3-642-33715-4_1 .\\n10', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 9}), Document(page_content='Published as a conference paper at ICLR 2023\\nLuisa Bentivogli, Peter Clark, Ido Dagan, and Danilo Giampiccolo. The ﬁfth pascal recognizing\\ntextual entailment challenge. In TAC, 2009.\\nBIG-bench collaboration. Beyond the imitation game: Measuring and extrapolating the capabil-\\nities of language models. In preparation , 2021. URL https://github.com/google/\\nBIG-bench/ .\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\\nHerbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,\\nJeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\\nand Dario Amodei. Language models are few-shot learners. In Advances in Neural Information\\nProcessing Systems , 2020. URL https://proceedings.neurips.cc/paper/2020/\\nfile/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf .\\nOana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom. e-\\nsnli: Natural language inference with natural language explanations. In S. Ben-\\ngio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett\\n(eds.), Advances in Neural Information Processing Systems 31 , pp. 9539–9549.\\nCurran Associates, Inc., 2018. URL http://papers.nips.cc/paper/\\n8163-e-snli-natural-language-inference-with-natural-language-explanations.\\npdf.\\nOana-Maria Camburu, Brendan Shillingford, Pasquale Minervini, Thomas Lukasiewicz, and Phil\\nBlunsom. Make up your mind! adversarial generation of inconsistent natural language explanations.\\nInProceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pp.\\n4157–4165, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.\\nacl-main.382. URL https://aclanthology.org/2020.acl-main.382 .\\nJifan Chen, Shih-Ting Lin, and Greg Durrett. Multi-hop question answering via reasoning chains.\\nCoRR , abs/1910.02610, 2019. URL http://arxiv.org/abs/1910.02610 .\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\\nKaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large\\nlanguage models trained on code. arXiv preprint arXiv:2107.03374 , 2021.\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\\nKensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\\nShazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\\nBradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\\nskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\\nRobinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph,\\nAlexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M.\\nDai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon\\nChild, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean,\\nSlav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways, 2022. URL\\nhttps://arxiv.org/abs/2204.02311 .\\nChristopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina\\nToutanova. Boolq: Exploring the surprising difﬁculty of natural yes/no questions. In NAACL ,\\n2019.\\nPeter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and\\nOyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge.\\nArXiv , abs/1803.05457, 2018.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\\nMatthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John\\nSchulman. Training veriﬁers to solve math word problems, 2021.\\n11', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 10}), Document(page_content='Published as a conference paper at ICLR 2023\\nIdo Dagan, Oren Glickman, and Bernardo Magnini. The pascal recognising textual entailment\\nchallenge. In Machine Learning Challenges Workshop , pp. 177–190. Springer, 2005.\\nBryan Eikema and Wilker Aziz. Is MAP decoding all you need? the inadequacy of the mode in neural\\nmachine translation. In Proceedings of the 28th International Conference on Computational Lin-\\nguistics , pp. 4506–4520, Barcelona, Spain (Online), December 2020. International Committee on\\nComputational Linguistics. URL https://aclanthology.org/2020.coling-main.\\n398.\\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich\\nSchütze, and Yoav Goldberg. Measuring and improving consistency in pretrained language\\nmodels. Transactions of the Association for Computational Linguistics , 9:1012–1031, 2021. doi:\\n10.1162/tacl_a_00410. URL https://aclanthology.org/2021.tacl-1.60 .\\nJonathan St BT Evans. Intuition and reasoning: A dual-process perspective. Psychological Inquiry ,\\n21(4):313–326, 2010.\\nAngela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. In Proceedings\\nof the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long\\nPapers) , pp. 889–898, Melbourne, Australia, July 2018. Association for Computational Linguistics.\\ndoi: 10.18653/v1/P18-1082. URL https://aclanthology.org/P18-1082 .\\nJessica Ficler and Yoav Goldberg. Controlling linguistic style aspects in neural language generation. In\\nProceedings of the Workshop on Stylistic Variation , pp. 94–104, Copenhagen, Denmark, September\\n2017. Association for Computational Linguistics. doi: 10.18653/v1/W17-4912. URL https:\\n//aclanthology.org/W17-4912 .\\nTianyu Gao, Adam Fisch, and Danqi Chen. Making pre-trained language models better few-shot\\nlearners. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguis-\\ntics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long\\nPapers) , pp. 3816–3830, Online, August 2021. Association for Computational Linguistics. doi:\\n10.18653/v1/2021.acl-long.295. URL https://aclanthology.org/2021.acl-long.\\n295.\\nMor Geva, Ankit Gupta, and Jonathan Berant. Injecting numerical reasoning skills into language\\nmodels. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguis-\\ntics, 2020. doi: 10.18653/v1/2020.acl-main.89. URL https://aclanthology.org/2020.\\nacl-main.89 .\\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle\\nuse a laptop? A question answering benchmark with implicit reasoning strategies. Transactions of\\nthe Association for Computational Linguistics , 2021. URL https://aclanthology.org/\\n2021.tacl-1.21 .\\nDanilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. The third pascal recognizing\\ntextual entailment challenge. In Proceedings of the ACL-PASCAL workshop on textual entailment\\nand paraphrasing , pp. 1–9. Association for Computational Linguistics, 2007.\\nAri Holtzman, Jan Buys, Maxwell Forbes, Antoine Bosselut, David Golub, and Yejin Choi. Learning\\nto write with cooperative discriminators. In Proceedings of the 56th Annual Meeting of the\\nAssociation for Computational Linguistics (Volume 1: Long Papers) , pp. 1638–1649, Melbourne,\\nAustralia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1152.\\nURLhttps://aclanthology.org/P18-1152 .\\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. The curious case of neural text\\ndegeneration. In International Conference on Learning Representations , 2020. URL https:\\n//openreview.net/forum?id=rygGQyrFvH .\\nMohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. Learning to\\nsolve arithmetic word problems with verb categorization. In Proceedings of the 2014 Conference on\\nEmpirical Methods in Natural Language Processing (EMNLP) , 2014. doi: 10.3115/v1/D14-1058.\\nURLhttps://aclanthology.org/D14-1058 .\\n12', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 11}), Document(page_content='Published as a conference paper at ICLR 2023\\nDaniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, and Han-\\nnaneh Hajishirzi. UNIFIEDQA: Crossing format boundaries with a single QA system. In Findings\\nof the Association for Computational Linguistics: EMNLP 2020 , pp. 1896–1907, Online, Novem-\\nber 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.ﬁndings-emnlp.171.\\nURLhttps://aclanthology.org/2020.findings-emnlp.171 .\\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\\nlanguage models are zero-shot reasoners. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave,\\nand Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems , 2022. URL\\nhttps://openreview.net/forum?id=e2TBb5y0yFf .\\nRik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. MAWPS:\\nA math word problem repository. In Proceedings of the 2016 Conference of the North American\\nChapter of the Association for Computational Linguistics: Human Language Technologies , 2016.\\ndoi: 10.18653/v1/N16-1136. URL https://aclanthology.org/N16-1136 .\\nYihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,\\nand Ee-Peng Lim. MWPToolkit: An open-source framework for deep learning-based math word\\nproblem solvers. arXiv preprint arXiv:2109.00799 , 2021. URL https://arxiv.org/abs/\\n2109.00799 .\\nJiwei Li and Dan Jurafsky. Mutual information and diverse decoding improve neural machine\\ntranslation, 2016. URL https://arxiv.org/abs/1601.00372 .\\nJiwei Li, Will Monroe, and Dan Jurafsky. A simple, fast diverse decoding algorithm for neural\\ngeneration. CoRR , abs/1611.08562, 2016. URL http://arxiv.org/abs/1611.08562 .\\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale genera-\\ntion: Learning to solve and explain algebraic word problems. In Proceedings of the 55th Annual\\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers) , 2017. doi:\\n10.18653/v1/P17-1015. URL https://aclanthology.org/P17-1015 .\\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. Fantastically\\nordered prompts and where to ﬁnd them: Overcoming few-shot prompt order sensitivity. ArXiv ,\\nabs/2104.08786, 2021.\\nClara Meister, Tiago Pimentel, Gian Wiher, and Ryan Cotterell. Typical decoding for natural language\\ngeneration. arXiv preprint arXiv:2202.00666 , 2022.\\nShen Yun Miao, Chao Chun Liang, and Keh Yih Su. A diverse corpus for evaluating and developing\\nEnglish math word problem solvers. In Proceedings of the 58th Annual Meeting of the Asso-\\nciation for Computational Linguistics , 2020. URL https://aclanthology.org/2020.\\nacl-main.92 .\\nYixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. Adver-\\nsarial NLI: A new benchmark for natural language understanding. In Proceedings of the 58th\\nAnnual Meeting of the Association for Computational Linguistics . Association for Computational\\nLinguistics, 2020.\\nMaxwell Nye, Michael Henry Tessler, Joshua B. Tenenbaum, and Brenden M. Lake. Improving\\ncoherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning.\\nIn A. Beygelzimer, Y . Dauphin, P. Liang, and J. Wortman Vaughan (eds.), Advances in Neural\\nInformation Processing Systems , 2021. URL https://openreview.net/forum?id=\\nuyKk_avJ-p4 .\\nArkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve simple\\nmath word problems? In Proceedings of the 2021 Conference of the North American Chapter of\\nthe Association for Computational Linguistics: Human Language Technologies , pp. 2080–2094,\\nOnline, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.\\n168. URL https://aclanthology.org/2021.naacl-main.168 .\\nXinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and\\nWeizhu Chen. Reasoning like program executors, 2022.\\n13', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 12}), Document(page_content='Published as a conference paper at ICLR 2023\\nPiotr Pi˛ ekos, Mateusz Malinowski, and Henryk Michalewski. Measuring and improving BERT’s\\nmathematical abilities by predicting the order of reasoning. In Proceedings of the 59th Annual Meet-\\ning of the Association for Computational Linguistics and the 11th International Joint Conference on\\nNatural Language Processing (Volume 2: Short Papers) , 2021. doi: 10.18653/v1/2021.acl-short.49.\\nURLhttps://aclanthology.org/2021.acl-short.49 .\\nAlec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language\\nmodels are unsupervised multitask learners. 2019.\\nJack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John\\nAslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. Scaling language models:\\nMethods, analysis & insights from training gopher. arXiv preprint arXiv:2112.11446 , 2021.\\nQiu Ran, Yankai Lin, Peng Li, Jie Zhou, and Zhiyuan Liu. NumNet: Machine reading comprehension\\nwith numerical reasoning. In Proceedings of the 2019 Conference on Empirical Methods in Natural\\nLanguage Processing and the 9th International Joint Conference on Natural Language Processing\\n(EMNLP-IJCNLP) , 2019. doi: 10.18653/v1/D19-1251. URL https://aclanthology.\\norg/D19-1251 .\\nSubhro Roy and Dan Roth. Solving general arithmetic word problems. In Proceedings of the 2015\\nConference on Empirical Methods in Natural Language Processing , 2015. doi: 10.18653/v1/\\nD15-1202. URL https://aclanthology.org/D15-1202 .\\nJianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, and Qun Liu. Generate\\n& rank: A multi-task framework for math word problems. In Findings of the Association for\\nComputational Linguistics: EMNLP 2021 , pp. 2269–2279, Punta Cana, Dominican Republic,\\nNovember 2021. Association for Computational Linguistics. URL https://aclanthology.\\norg/2021.findings-emnlp.195 .\\nFreda Shi, Daniel Fried, Marjan Ghazvininejad, Luke Zettlemoyer, and Sida I. Wang. Natural\\nlanguage to code translation with execution. In Proceedings of the 2022 Conference on Empirical\\nMethods in Natural Language Processing , pp. 3533–3546, Abu Dhabi, United Arab Emirates,\\nDecember 2022. Association for Computational Linguistics. URL https://aclanthology.\\norg/2022.emnlp-main.231 .\\nKeith E Stanovich and Richard F West. Individual differences in reasoning: Implications for\\nthe rationality debate? Behavioral and brain sciences , 23(5):645–665, 2000. URL https:\\n//pubmed.ncbi.nlm.nih.gov/11301544/ .\\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. CommonsenseQA: A question\\nanswering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference of\\nthe North American Chapter of the Association for Computational Linguistics: Human Language\\nTechnologies, Volume 1 (Long and Short Papers) , 2019. URL https://aclanthology.\\norg/N19-1421 .\\nYi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung,\\nDara Bahri, Tal Schuster, Steven Zheng, Denny Zhou, Neil Houlsby, and Donald Metzler. Unifying\\nlanguage learning paradigms, 2022. URL https://arxiv.org/abs/2205.05131 .\\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze\\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. Lamda: Language models for dialog\\napplications. arXiv preprint arXiv:2201.08239 , 2022. URL https://arxiv.org/abs/\\n2201.08239 .\\nAshwin Vijayakumar, Michael Cogswell, Ramprasaath Selvaraju, Qing Sun, Stefan Lee, David\\nCrandall, and Dhruv Batra. Diverse beam search for improved description of complex scenes.\\nProceedings of the AAAI Conference on Artiﬁcial Intelligence , 32, Apr. 2018. URL https:\\n//ojs.aaai.org/index.php/AAAI/article/view/12340 .\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc\\nLe, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models.\\nConference on Neural Information Processing Systems (NeurIPS) , 2022. URL https://arxiv.\\norg/pdf/2201.11903 .\\n14', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 13}), Document(page_content='Published as a conference paper at ICLR 2023\\nSean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang, and Kyunghyun Cho. Consistency\\nof a recurrent language model with respect to incomplete decoding. In Proceedings of the 2020\\nConference on Empirical Methods in Natural Language Processing (EMNLP) , pp. 5553–5568,\\nOnline, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.\\nemnlp-main.448. URL https://aclanthology.org/2020.emnlp-main.448 .\\nWeiwen Xu, Yang Deng, Huihui Zhang, Deng Cai, and Wai Lam. Exploiting reasoning chains\\nfor multi-hop science question answering. In Findings of the Association for Computational\\nLinguistics: EMNLP 2021 , pp. 1143–1156, Punta Cana, Dominican Republic, November 2021a.\\nAssociation for Computational Linguistics. URL https://aclanthology.org/2021.\\nfindings-emnlp.99 .\\nYichong Xu, Chenguang Zhu, Shuohang Wang, Siqi Sun, Hao Cheng, Xiaodong Liu, Jianfeng\\nGao, Pengcheng He, Michael Zeng, and Xuedong Huang. Human parity on commonsenseqa:\\nAugmenting self-attention with external attention, 2021b. URL https://arxiv.org/abs/\\n2112.03254 .\\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and\\nChristopher D. Manning. HotpotQA: A dataset for diverse, explainable multi-hop question answer-\\ning. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing ,\\npp. 2369–2380, Brussels, Belgium, October-November 2018. Association for Computational Lin-\\nguistics. doi: 10.18653/v1/D18-1259. URL https://aclanthology.org/D18-1259 .\\nXi Ye and Greg Durrett. The unreliability of explanations in few-shot prompting for textual reasoning.\\nIn Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in\\nNeural Information Processing Systems , 2022. URL https://openreview.net/forum?\\nid=Bct2f8fRd8S .\\nWenhao Yu, Chenguang Zhu, Lianhui Qin, Zhihan Zhang, Tong Zhao, and Meng Jiang. Diversifying\\ncontent generation for commonsense reasoning with mixture of knowledge graph experts. In\\nFindings of Annual Meeting of the Association for Computational Linguistics (ACL) , 2022.\\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving\\nfew-shot performance of language models. In Marina Meila and Tong Zhang (eds.), Proceed-\\nings of the 38th International Conference on Machine Learning , volume 139 of Proceedings of\\nMachine Learning Research . PMLR, 2021. URL https://proceedings.mlr.press/\\nv139/zhao21c.html .\\n15', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 14}), Document(page_content='Published as a conference paper at ICLR 2023\\nA A PPENDIX\\nA.1 A DDITIONAL EXPERIMENT RESULTS\\nA.1.1 R OBUSTNESS TO SAMPLING STRATEGIES AND PARAMETERS\\nIn Figure 6 we ablate the results with respect to different sampling strategies and parameters by\\nvarying Tin temperature sampling and kin Top- ksampling, on LaMDA-137B. We show that\\nself-consistency is robust to various sampling strategies and parameters.\\n481216202428323640\\n#Sampled Reasoning Paths182022242628Accuracy (%)\\nT=0.7, k=40\\nT=0.5, k=40\\nT=0.3, k=40\\nT=0.5, k=20\\nT=0.5, no top k\\nGreedy Decode\\nFigure 6: GSM8K accuracy over LaMDA-137B. Self-consistency works under various sampling\\nstrategies and sampling parameters.\\nIn Figure 7 and Figure 8, we show the results of self-consistency compared with greedy decoding a\\nsingle path over LaMDA-137B and PaLM-540B, respectively. Self-consistency improves over greedy\\ndecode by a quite signiﬁcant margin on both models, on top of high accuracy already achieved by\\nscaling up model sizes.\\n0510152025303540\\n#Sampled Reasoning Paths505560657075Accuracy (%)\\nMultiArith\\n0510152025303540\\n#Sampled Reasoning Paths4446485052545658\\nASDiv\\n0510152025303540\\n#Sampled Reasoning Paths3336394245485154\\nSVAMP\\n0510152025303540\\n#Sampled Reasoning Paths1416182022242628\\nGSM8K\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\n0510152025303540\\n#Sampled Reasoning Paths56586062Accuracy (%)\\nCommonsense QA\\n0510152025303540\\n#Sampled Reasoning Paths62636465666768\\nStrategy QA\\n0510152025303540\\n#Sampled Reasoning Paths687072747678\\nARC (Easy)\\n0510152025303540\\n#Sampled Reasoning Paths505254565860\\nARC (Challenge)\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\nFigure 7: Self-consistency (blue) signiﬁcantly improves accuracy across various arithmetic and\\ncommonsense reasoning tasks, over LaMDA-137B. Sampling a higher number of diverse reasoning\\npaths consistently improves reasoning accuracy.\\nWe further show additional sampled reasoning paths from the LaMDA-137B model in Table 12, and\\nsampled reasoning paths from the PaLM-540B model in Table 13. We see that the diversity in the\\nadditionally sampled reasoning paths indeed helps the model arrive at a more correct ﬁnal answer\\nafter aggregation.\\nA.1.2 R OBUSTNESS TO DIFFERENT SETS OF PROMPTS\\nIn Table 9, we further show that self-consistency is quite robust to different sets of input prompts.\\nWe manually wrote 3 different sets of chain-of-thought as prompts to the model. Across all sets of\\nprompts, self-consistency yields consistent gains over the original CoT approach.\\nA.1.3 C OMPARED TO MODEL ENSEMBLES\\nAdditionally, we provide results of directly ensembling the outputs from multiple language models .\\nThe results are shown in Table 10, by greedily decoding sequences from 3 language models and\\n16', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 15}), Document(page_content='Published as a conference paper at ICLR 2023\\n0510152025303540\\n#Sampled Reasoning Chains8688909294Accuracy (%)\\nAddSub\\n0510152025303540\\n#Sampled Reasoning Chains727476788082Accuracy (%)\\nASDiv\\n0510152025303540\\n#Sampled Reasoning Chains30333639424548Accuracy (%)\\nAQuA\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\n0510152025303540\\n#Sampled Reasoning Chains889092949698Accuracy (%)\\nMultiArith\\n0510152025303540\\n#Sampled Reasoning Chains70.072.575.077.580.082.585.087.5Accuracy (%)\\nSVAMP\\n0510152025303540\\n#Sampled Reasoning Chains505560657075Accuracy (%)\\nGSM8K\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\n0510152025303540\\n#Sampled Reasoning Paths7475767778798081Accuracy (%)\\nCommonsense QA\\n0510152025303540\\n#Sampled Reasoning Paths7476788082\\nStrategy QA\\n0510152025303540\\n#Sampled Reasoning Paths8890929496\\nARC (Easy)\\n0510152025303540\\n#Sampled Reasoning Paths788082848688\\nARC (Challenge)\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\nFigure 8: Self-consistency (blue) signiﬁcantly improves accuracy across various arithmetic and\\ncommonsense reasoning tasks, over PaLM-540B. Sampling a higher number of diverse reasoning\\npaths consistently helps reasoning accuracy.\\nPrompt set 1 (used in the main text) Prompt set 2 Prompt set 3\\nCoT (Wei et al., 2022) 56.5 54.6 54.0\\nSelf-consistency 74.4 (+17.9) 72.1 (+17.5) 70.4 (+16.4)\\nTable 9: GSM8K accuracy over PaLM-540B. The results show robustness of self-consistency with\\nrespect to different prompts in the input.\\ntaking the majority vote (averaged over 10 runs). Note this is a typical ensemble approach (averaging\\nover the predictions over multiple models) and it achieves a performance signiﬁcantly worse than\\nself-consistency (self-consistency over PaLM-540B gets an accuracy of 74.4%), as lower-capacity\\nmodels drag down the performance of higher-capacity models. In addition, this approach is limited in\\ntwo ways: 1) It requires multiple models for an ensemble which might not always be available, while\\nself-consistency only requires one single model to “self-ensemble”; 2) If one of the models is much\\nweaker, it can actually hurt the ﬁnal performance.\\nMethod GSM8K accuracy\\nSingle model PaLM-540B, greedy / self-consistency 56.5 / 74.4\\nEnsemble of modelsLaMDA-137B + PaLM-540B 36.9 ±0.5\\nPaLM-540B + GPT-3 (code-davinci-001, 175B) 36.6 ±0.4\\nLaMDA-137B + GPT-3 (code-davinci-001, 175B) 16.0 ±0.8\\nLaMDA-137B + PaLM-540B + GPT-3 (code-davinci-001, 175B) 33.3 ±0.7\\nTable 10: Comparison of GSM8K accuracy over multiple-model ensembles.\\nA.1.4 C OMBINING SELF -CONSISTENCY WITH OTHER ENSEMBLING STRATEGIES\\nSelf-consistency is completely compatible with other ensemble strategies, although the gains achieved\\nby self-consistency are signiﬁcantly higher than other ensemble strategies (and can “override” the\\nperformance gains achieved by other ensemble strategies). We further performed experiments and\\ninclude the results in Table 11 (for a fair comparison, we use 40 sets of prompts, or 40 prompt\\npermutations to compare with self-consistency with 40 paths, all experiments are based on PaLM-\\n540B).\\n17', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 16}), Document(page_content='Published as a conference paper at ICLR 2023\\nGSM8K accuracy\\nDifferent sets of prompts (x40) 58.9\\nPrompt-permutation (x40) 59.6\\nSelf-consistency (x40) 74.4\\nSelf-consistency + different sets of prompts (x40) 75.4\\nSelf-consistency + prompt-permutation (x40) 73.8\\nTable 11: Combining self-consistency with other ensembling strategies.\\nA.2 D ETAILS ON RESOURCES AND INFERENCE\\nFor all four language models we perform prompting-based inference only. For UL2 we use TPU v3\\n(2x2 conﬁguration, 4 chips, 8 cores). For GPT-3 models the experiments are done though the public\\nAPI.10For LaMDA-137B we use TPU v3 (8x8 conﬁguration, 64 chips, 128 cores). For PaLM-540B\\nwe use TPU v4 (4x4x12 conﬁguration, 192 chips, 384 cores). Most inference jobs take 1 to 4 hours\\n(over about 1,000 examples) for each task on UL2 and LaMDA-137B, and about 2 to 12 hours on\\nPaLM-540B. Some tasks (e.g., commonsense reasoning) take longer but do not exceed 2 days for\\neach task.\\nFor GPT-3 models, we use 128 max tokens for all methods, without frequency penalty or presence\\npenalty. For all models, we take the generated outputs until the start of the next “Q:\" to parse the ﬁnal\\nanswers, consistent with our prompting format.\\nQuestion Greedy Decode Sampled Path 1 Sampled Path 2\\n[MultiArith] Sam had 10 socks.\\nIf he threw away 3 old ones\\nthat didn’t ﬁt and bought 36 new\\nones, how many socks would he\\nhave?Sam had 10 socks. He threw\\naway 3 old ones that didn’t ﬁt.\\nHe bought 36 new ones. That\\nmeans he has 10 + 36 - 3 = 41\\nsocks. The answer is 41.Sam had 10 socks. He\\nthrew away 3 old ones. So\\nnow he has 7 left. Then he\\nbought 36 new ones. So\\nnow he has 7 + 36 = 43\\nsocks. The answer is 43.He had 10 socks. He threw away\\n3 old ones that didn’t ﬁt. He\\nbought 36 new ones. So in total\\nhe has 10 - 3 + 36 = 43 socks. The\\nanswer is 43.\\n[SVAMP] In a school there are\\n697 girls and the rest are boys.\\nIf there are 228 more girls than\\nboys. How many boys are there\\nin that school?There are 697 girls and the rest\\nare boys. That means there are\\n697 + 228 = 925 girls. The\\nrest are boys. So the number of\\nboys is 925 - 697 = 228. The\\nanswer is 228.The number of boys is the\\ndifference between 697\\nand 228. This is 697 - 228\\n= 469. The answer is 469.In the beginning there are 697\\ngirls and the rest are boys. So, the\\nnumber of boys must be 697 - 228\\n= 469 boys. The answer is 469.\\n[AQuA] There are 10 oranges in\\na basket. Find the no. of ways in\\nwhich 2 oranges are chosen from\\nthe basket? (a) 45 (b) 90 (c) 120\\n(d) 150 (e) 180There are 10 oranges in a bas-\\nket. So there are 10 ways\\nin which 2 oranges are chosen\\nfrom the basket.There are 10 oranges in a\\nbasket. We need to choose\\n2 oranges from the basket.\\nSo the number of ways are\\n10C2. So the answer is (a).There are 10 oranges in the bas-\\nket. If you choose 2 oranges, you\\nhave 10C2 = 45 ways of choosing\\n2 oranges. So the answer is (a).\\n[CommonsenseQA] The man\\nlaid on the soft moss and looked\\nup at the trees, where was the\\nman? (a) niagra falls (b) forest\\n(c) waterfall (d) ground (e) treeThe answer must be something\\nthat is soft and mossy. Of the\\nabove choices, only ground is\\nsoft and mossy. So the answer\\nis (d).The answer must be\\nsomewhere where moss\\nis found. Of the above\\nchoices, only forests are\\nknown for having moss.\\nSo the answer is (b).The answer must be a place where\\nthe man is laying down and look-\\ning up at trees. Of the above\\nchoices, only forest is a place\\nwhere people lay down and look\\nat trees. So the answer is (b).\\n[ARC] Which of these will most\\nlikely harm a habitat? (a) plant-\\ning trees. (b) water pollution. (c)\\nrainfall. (d) sunlight.Planting trees will not harm a\\nhabitat. So the answer is (a).The answer is (b), water\\npollution, because it will\\nmost likely harm the habi-\\ntat. The other answers are\\nnot likely to harm the habi-\\ntat.The answer is (b), water pollution.\\nTrees are good for a habitat, rain-\\nfall is necessary for a habitat, and\\nsunlight is necessary for a habitat.\\nSo the answer is (b).\\n[ARC-challenge] Which pro-\\ncess in the carbon cycle takes the\\nlongest to complete? (a) emis-\\nsion of waste. (b) respiration in\\nanimals. (c) photosynthesis in\\nplants. (d) formation of fossil fu-\\nels.The process of photosynthesis\\nin plants takes the longest to\\ncomplete. So the answer is (c).The formation of fossil fu-\\nels takes the longest time\\nto complete. So the an-\\nswer is (d).The process that takes the longest\\ntime to complete is the forma-\\ntion of fossil fuels, which hap-\\npens over millions of years. So\\nthe answer is (d).\\nTable 12: Additional examples where self-consistency helps repair the errors over greedy decode on\\nLaMDA-137B. Two sampled reasoning paths that are consistent with the ground truth are shown.\\n10https://beta.openai.com/docs/api-reference/making-requests\\n18', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 17}), Document(page_content='Published as a conference paper at ICLR 2023\\nQuestion Greedy Decode Sampled Path 1 Sampled Path 2\\n[GSM8K] Kyle bought last\\nyear’s best-selling book for\\n$19.50. This is with a 25% dis-\\ncount from the original price.\\nWhat was the original price of\\nthe book?The book was sold for $19.50.\\nThis is 25% less than the origi-\\nnal price. This means the original\\nprice was 100%. 25% of 100%\\nis 25%. So the original price\\nwas 100% - 25% = 75%. The\\noriginal price was 75% of $19.50.\\n75% of $19.50 is 75% * $19.50 =\\n$14.625. The answer is $14.625.The original price of the book\\nis $19.50. Since it was dis-\\ncounted by 25%, the original\\nprice was 19.50 / 0.75 = 26.\\nThe answer is 26.Kyle bought a book that is sold\\nfor $19.50. With a 25% discount,\\nthe original price must be higher.\\nIf we call the original price x,\\nthen the discounted price is 0.75x.\\nSince this is $19.50, we can write\\n0.75x = 19.50. Solving this, we\\nﬁnd that the original price is x =\\n19.50 / 0.75 = $26. The answer is\\n$26.\\n[AQuA] The capacity of a\\ntank of dimensions (8 m x 6\\nm x 2.5 m) is (a) 120 litres (b)\\n1200 litres (c) 12000 litres (d)\\n120000 litres (e) None of theseThe volume of the tank is 8 m *\\n6 m * 2.5 m = 120 m3. So the\\ncapacity of the tank is 120 m3. So\\nthe answer is (c).The volume of the tank is 8m\\n* 6m* 2.5m = 120m3. This is\\nequal to 120000 litres. So the\\nanswer is (d)The volume of the tank is 8 m *\\n6 m * 2.5 m = 120 m3. One cu-\\nbic meter contains 1000 litres, so\\nthe tank contains 120 m3 * 1000\\nliters/m3 = 120,000 liters. So the\\nanswer is (d).\\n[StrategyQA] Yes or no:\\nCan the Great Depression be\\ntreated with Prozac?The Great Depression was an\\neconomic depression. Prozac is\\na drug used to treat depression.\\nThus, the Great Depression could\\nbe treated with Prozac. So the an-\\nswer is yes.Prozac is an anti-depressant\\nmedication. The Great Depres-\\nsion is not a disease. Thus,\\nProzac cannot treat the Great\\nDepression. So the answer is\\nno.The Great Depression is a time pe-\\nriod. Prozac is used to treat de-\\npression (the mental illness). Thus,\\nthe Great Depression can not be\\ntreated with Prozac. So the answer\\nis no.\\n[ARC-easy] Which source of\\nenergy is nonrenewable? (a)\\ncoal. (b) sunlight. (c) water.\\n(d) wood.Coal, sunlight, and water are\\nall renewable sources of energy.\\nWood is a nonrenewable source of\\nenergy. So the answer is (d).A nonrenewable source of en-\\nergy is one in which the source\\nis not replenished in a short\\namount of time. Thus, the only\\noption that is nonrenewable is\\ncoal. So the answer is (a).Coal is a fossil fuel and is formed\\nfrom dead organisms from the past.\\nCoal cannot be produced in a short\\nperiod of time, so it is considered\\na nonrenewable source of energy.\\nSo the answer is (a).\\n[ARC-challenge] Students\\nstudied the revolution of Earth\\naround the Sun. During which\\nmonth will Florida have the\\nmost sunlight energy avail-\\nable? (a) March. (b) June. (c)\\nSeptember. (d) December.The Earth is closest to the Sun\\nin December, hence Florida will\\nhave the most sunlight energy\\navailable in December. So the an-\\nswer is (d).Earth is closest to the Sun on\\nJune 21, the summer solstice.\\nSo the answer is (b).Florida is closer to the sun during\\nJune, so it will have the most sun-\\nlight energy during that month. So\\nthe answer is (b).\\nTable 13: Additional examples where self-consistency helps repair the errors over greedy decode on\\nPaLM-540B. Two sampled reasoning paths that are consistent with the ground truth are shown.\\nA.3 F ULL SETS OF PROMPTS\\nWe list the full details of the prompts used for two newly-introduced datasets, AQUA-RAT (Ling\\net al., 2017) and AI2 Reasoning Challenge (ARC) (Clark et al., 2018), where we manually composed\\nthe example chain-of-thought in this paper, in Table 14 and Table 15, respectively.\\nTable 14: Few-shot exemplars for AQUA-RAT.\\nQ:John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the\\nnumbers is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\\nA:If 10 is added to each number, then the mean of the numbers also increases by 10. So the new mean\\nwould be 50. The answer is (a).\\nQ:If a / b = 3/4 and 8a + 5b = 22,then ﬁnd the value of a. Answer Choices: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e)\\n7/2\\nA:If a / b = 3/4, then b = 4a / 3. So 8a + 5(4a / 3) = 22. This simpliﬁes to 8a + 20a / 3 = 22, which means\\n44a / 3 = 22. So a is equal to 3/2. The answer is (b).\\nQ:A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then ﬁnd the distance? Answer Choices:\\n(a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km\\nA:The distance that the person traveled would have been 20 km/hr * 2.5 hrs = 50 km. The answer is (e).\\nQ:How many keystrokes are needed to type the numbers from 1 to 500? Answer Choices: (a) 1156 (b) 1392\\n(c) 1480 (d) 1562 (e) 1788\\nA:There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401\\nthree-digit numbers from 100 to 500. 9 + 90(2) + 401(3) = 1392. The answer is (b).\\n19', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 18}), Document(page_content='Published as a conference paper at ICLR 2023\\nTable 15: Few-shot exemplars for ARC easy/challenge.\\nQ:George wants to warm his hands quickly by rubbing them. Which skin surface will produce the most\\nheat? (a) dry palms. (b) wet palms. (c) palms covered with oil. (d) palms covered with lotion.\\nA:Dry surfaces will more likely cause more friction via rubbing than other smoother surfaces, hence dry\\npalms will produce the most heat. The answer is (a).\\nQ:Which factor will most likely cause a person to develop a fever? (a) a leg muscle relaxing after exercise.\\n(b) a bacterial population in the bloodstream. (c) several viral particles on the skin. (d) carbohydrates being\\ndigested in the stomach.\\nA:Option (b), bacterial population is the most likely cause for a person developing fever. The answer is (b).\\nQ:Which change in the state of water particles causes the particles to become arranged in a ﬁxed position?\\n(a) boiling. (b) melting. (c) freezing. (d) evaporating.\\nA:When water is freezed, the particles are arranged in a ﬁxed position; the particles are still moving for all\\nother options. The answer is (c).\\nQ:When a switch is used in an electrical circuit, the switch can (a) cause the charge to build. (b) increase\\nand decrease the voltage. (c) cause the current to change direction. (d) stop and start the ﬂow of current.\\nA:The function of a switch is to start and stop the ﬂow of a current. The answer is (d).\\nTable 16: Few-shot exemplars for HotpotQA (closed-book setting).\\nQ:Which magazine was started ﬁrst Arthur’s Magazine or First for Women?\\nA:Arthur’s Magazine started in 1844. First for Women started in 1989. So Arthur’s Magazine was started ﬁrst.\\nThe answer is Arthur’s Magazine.\\nQ:The Oberoi family is part of a hotel company that has a head ofﬁce in what city?\\nA:The Oberoi family is part of the hotel company called The Oberoi Group. The Oberoi Group has its head\\nofﬁce in Delhi. The answer is Delhi.\\nQ:What nationality was James Henry Miller’s wife?\\nA:James Henry Miller’s wife is June Miller. June Miller is an American. The answer is American.\\nQ:The Dutch-Belgian television series that \"House of Anubis\" was based on ﬁrst aired in what year?\\nA:\"House of Anubis\" is based on the Dutch–Belgian television series Het Huis Anubis. Het Huis Anubis is ﬁrst\\naired in September 2006. The answer is 2006.\\nAs additional information, we also list the exact set of prompts used for all arithmetic reasoning tasks\\nin Table 17, since there are multiple sets of prompts introduced in Wei et al. (2022). The prompts for\\nCommonsenseQA and StrategyQA are the same as used in Wei et al. (2022).\\nWe provide the exact prompts used for common NLP tasks in the following tables as well, including\\nNLI (Table 18, Table 19, Table 20) and Closed-Book Question-Answering tasks (Table 16, Table 21).\\n20', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 19}), Document(page_content='Published as a conference paper at ICLR 2023\\nTable 17: Few-shot exemplars for all arithmetic reasoning tasks, from Wei et al. (2022).\\nQ:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\\nthere will be 21 trees. How many trees did the grove workers plant today?\\nA:We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\\nSo, they must have planted 21 - 15 = 6 trees. The answer is 6.\\nQ:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA:There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\\nQ:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA:Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\\nchocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\\nQ:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\\ndid Jason give to Denny?\\nA:Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\\nlollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\\nQ:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does\\nhe have now?\\nA:He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\\nin total he has 7 + 2 = 9 toys. The answer is 9.\\nQ:There were nine computers in the server room. Five more computers were installed each day, from\\nmonday to thursday. How many computers are now in the server room?\\nA:There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\\n20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\\nThe answer is 29.\\nQ:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\\ngolf balls did he have at the end of wednesday?\\nA:Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\\nWednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\\nQ:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA:She bought 5 bagels for $3 each. This means she spent 5 * $3 = $15 on the bagels. She had $23 in\\nbeginning, so now she has $23 - $15 = $8. The answer is 8.\\n21', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 20}), Document(page_content='Published as a conference paper at ICLR 2023\\nTable 18: Few-shot exemplars for ANLI.\\nPremise:\\n\"Conceptually cream skimming has two basic dimensions - product and geography.\"\\nBased on this premise, can we conclude the hypothesis \"Product and geography are what make cream skimming\\nwork.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:Based on \"cream skimming has two basic dimensions\" we can’t infer that these two dimensions are what\\nmake cream skimming work. The answer is it is not possible to tell.\\nPremise:\\n\"One of our member will carry out your instructions minutely.\"\\nBased on this premise, can we conclude the hypothesis \"A member of my team will execute your orders with\\nimmense precision.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:\"one of\" means the same as \"a member of\", \"carry out\" means the same as \"execute\", and \"minutely\" means\\nthe same as \"immense precision\". The answer is yes.\\nPremise:\\n\"Fun for adults and children.\"\\nBased on this premise, can we conclude the hypothesis \"Fun for only children.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:\"adults and children\" contradicts \"only children\". The answer is no.\\nPremise:\\n\"He turned and smiled at Vrenna.\"\\nBased on this premise, can we conclude the hypothesis \"He smiled at Vrenna who was walking slowly behind\\nhim with her mother.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:the premise does not say anything about \"Vrenna was walking\". The answer is it is not possible to tell.\\nPremise:\\n\"well you see that on television also\"\\nBased on this premise, can we conclude the hypothesis \"You can see that on television, as well.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:\"also\" and \"as well\" mean the same thing. The answer is yes.\\nPremise:\\n\"Vrenna and I both fought him and he nearly took us.\"\\nBased on this premise, can we conclude the hypothesis \"Neither Vrenna nor myself have ever fought him.\" is\\ntrue?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:\"Vrenna and I both\" contradicts \"neither Vrenna nor myself\". The answer is no.\\n22', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 21}), Document(page_content='Published as a conference paper at ICLR 2023\\nTable 19: Few-shot exemplars for e-SNLI (the rationales are crowd-sourced annotations from the\\noriginal dataset).\\nPremise:\\n\"A person on a horse jumps over a broken down airplane.\"\\nBased on this premise, can we conclude the hypothesis \"A person is training his horse for a competition.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:The person is not necessarily training his horse. The answer is it is not possible to tell.\\nPremise:\\n\"A person on a horse jumps over a broken down airplane.\"\\nBased on this premise, can we conclude the hypothesis \"A person is at a diner, ordering an omelette.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:One jumping horse cannot be in a diner ordering food. The answer is no.\\nPremise:\\n\"A person on a horse jumps over a broken down airplane.\"\\nBased on this premise, can we conclude the hypothesis \"A person is outdoors, on a horse.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:A broken down airplane is outdoors. The answer is yes.\\nPremise:\\n\"Children smiling and waving at camera.\"\\nBased on this premise, can we conclude the hypothesis \"They are smiling at their parents.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:Just because they are smiling and waving at a camera does not imply their parents or anyone is anyone behind\\nit. The answer is it is not possible to tell.\\nPremise:\\n\"Children smiling and waving at camera.\"\\nBased on this premise, can we conclude the hypothesis \"The kids are frowning.\" is true? OPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:One cannot be smiling and frowning at the same time. The answer is no.\\nPremise:\\n\"Children smiling and waving at camera.\"\\nBased on this premise, can we conclude the hypothesis \"There are children present.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:The children must be present to see them smiling and waving. The answer is yes.\\n23', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 22}), Document(page_content='Published as a conference paper at ICLR 2023\\nTable 20: Few-shot exemplars for RTE.\\nPremise:\\n\"No Weapons of Mass Destruction Found in Iraq Yet.\"\\nBased on this premise, can we conclude the hypothesis \"Weapons of Mass Destruction Found in Iraq.\" is true?\\nA:\"No Weapons of Mass Destruction Found\" contradicts \"Weapons of Mass Destruction Found\". The answer is\\nno.\\nPremise:\\n\"A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful\\ngathered in downtown Chicago to mark the installation of new Pope Benedict XVI.\"\\nBased on this premise, can we conclude the hypothesis \"Pope Benedict XVI is the new leader of the Roman\\nCatholic Church.\" is true?’\\nA:\"installation of new Pope Benedict XVI.\" means \"Pope Benedict XVI is the new leader\". The answer is yes.\\nPremise:\\n\"A man is due in court later charged with the murder 26 years ago of a teenager whose case was the ﬁrst to\\nbe featured on BBC One’s Crimewatch. Colette Aram, 16, was walking to her boyfriend’s house in Keyworth,\\nNottinghamshire, on 30 October 1983 when she disappeared. Her body was later found in a ﬁeld close to her\\nhome. Paul Stewart Hutchinson, 50, has been charged with murder and is due before Nottingham magistrates\\nlater.\"\\nBased on this premise, can we conclude the hypothesis \"Paul Stewart Hutchinson is accused of having stabbed a\\ngirl.\" is true?\\nA:The premise does not say Paul Stewart Hutchinson \"stabbed\" this girl. The answer is no.\\nPremise:\\n\"Herceptin was already approved to treat the sickest breast cancer patients, and the company said, Monday, it\\nwill discuss with federal regulators the possibility of prescribing the drug for more breast cancer patients.\"\\nBased on this premise, can we conclude the hypothesis \"Herceptin can be used to treat breast cancer.\" is true?\\nA:\"Herceptin was approved to treat breast cancer\" implies that \"Herceptin can be used to treat breast cancer\".\\nThe answer is yes.\\nTable 21: Few-shot exemplars for BoolQ (closed-book setting).\\nQ:does system of a down have 2 singers?\\nA:System of a Down currently consists of Serj Tankian, Daron Malakian, Shavo Odadjian and John Dolmayan.\\nSerj and Daron do vocals, so the band does have two singers. The answer is yes.\\nQ:do iran and afghanistan speak the same language?\\nA:Iran and Afghanistan both speak the Indo-European language Persian. The answer is yes.\\nQ:is a cello and a bass the same thing?\\nA:The cello is played sitting down with the instrument between the knees, whereas the double bass is played\\nstanding or sitting on a stool. The answer is no.\\nQ:can you use oyster card at epsom station?\\nA:Epsom railway station serves the town of Epsom in Surrey and is not in the London Oyster card zone. The\\nanswer is no.\\n24', metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 23}), Document(page_content='Beyond Chain-of-Thought, Effective\\nGraph-of-Thought Reasoning in Large Language\\nModels\\nYao Yao1,2, Zuchao Li3,∗and Hai Zhao1,2,∗\\n1Department of Computer Science and Engineering, Shanghai Jiao Tong University\\n2MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University\\n3National Engineering Research Center for Multimedia Software,\\nSchool of Computer Science, Wuhan University, Wuhan, 430072, P. R. China\\nyaoyao27@sjtu.edu.cn, zcli-charlie@whu.edu.cn,\\nzhaohai@cs.sjtu.edu.cn\\nAbstract\\nWith the widespread use of large language models (LLMs) in NLP tasks, re-\\nsearchers have discovered the potential of Chain-of-thought (CoT) to assist LLMs\\nin accomplishing complex reasoning tasks by generating intermediate steps. How-\\never, human thought processes are often non-linear, rather than simply sequential\\nchains of thoughts. Therefore, we propose Graph-of-Thought (GoT) reasoning,\\nwhich models human thought processes not only as a chain but also as a graph. By\\nrepresenting thought units as nodes and connections between them as edges, our\\napproach captures the non-sequential nature of human thinking and allows for a\\nmore realistic modeling of thought processes. Similar to Multimodal-CoT [ 1], we\\nmodeled GoT reasoning as a two-stage framework, generating rationales first and\\nthen producing the final answer. Specifically, we employ an additional graph-of-\\nthoughts encoder for GoT representation learning and fuse the GoT representation\\nwith the original input representation through a gated fusion mechanism. We\\nimplement a GoT reasoning model on the T5 pre-trained model and evaluate its\\nperformance on a text-only reasoning task (GSM8K) and a multimodal reasoning\\ntask (ScienceQA). Our model achieves significant improvement over the strong\\nCoT baseline with 3.41% and 5.08% on the GSM8K test set with T5-base and\\nT5-large architectures, respectively. Additionally, our model boosts accuracy from\\n84.91% to 91.54% using the T5-base model and from 91.68% to 92.77% using the\\nT5-large model over the state-of-the-art Multimodal-CoT on the ScienceQA test\\nset. Experiments have shown that GoT achieves comparable results to Multimodal-\\nCoT largewith over 700M parameters, despite having fewer than 250M backbone\\nmodel parameters, demonstrating the effectiveness of GoT.\\n1 Introduction\\nIn the field of human cognition, it has long been recognized that the human thought process is far\\nmore complex and non-linear than could be captured by a simple, sequential chain of thoughts [ 2].\\nHuman thinking is often characterized by its ability to make sudden leaps and connections between\\nseemingly unrelated ideas, which can lead to novel insights and solutions. This non-linear, jumping\\nthought process is a hallmark of human creativity, reasoning, and problem-solving abilities. However,\\nit also poses a significant challenge for cognitive modeling and understanding.\\n∗Corresponding author.†Equal contribution.\\nPreprint. Under review.arXiv:2305.16582v1  [cs.CL]  26 May 2023', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 0}), Document(page_content=\"Recently, Large Language Models (LLMs) have been advancing at an unprecedented pace. With the\\nemergence of breakthroughs such as GPT-3 [ 3], PaLM [ 4], and GPT-4 [ 5], the field of natural language\\nprocessing has entered a new era of possibilities. Recent studies [ 6–8] have shown that the reasoning\\nability of LLMs can be unlocked by Chain-of-Thought (CoT) prompting. CoT prompting involves a\\nseries of intermediate natural language rationales that lead to the final answer. In addition, Zhang\\net al. [1]have introduced Multimodal-CoT, which combines both language and visual modalities to\\nhelp surpass the limitations of textual information. More detailed related works about CoT can be\\nfound in Appendix A.1.\\nPrevious works on Chain-of-Thought (CoT) prompting, which have been limited to textual and\\nvisual information, often represented the human reasoning process as sequential thought chains. This\\napproach overlooks the modeling of humans’ jumping thought process and neglects to incorporate\\nthe complex structural information of reasoning thoughts into the model. To address this limitation,\\nwe propose the Graph-of-Thought (GoT), a novel approach to modeling human thought processes\\nnot only as a chain but also as a graph. Our method is based on the assumption that the human mind\\nworks by connecting and recombining ideas in a non-sequential, graph fashion, rather than following\\na strict sequential chain. By representing thought units as nodes and connections between thoughts as\\nedges, the Graph-of-Thought captures the rich, non-sequential nature of human thinking and allows\\nfor a more realistic and logical modeling of reasoning processes.\\nDo ferns produce seeds?Text Features\\n(A) Yes (B) No\\nThis diagram shows the life cycle of \\na fern.\\nVision Features (Optional) Graph -of-Thought Features\\nproduceseedsferns\\nshowslife \\ncycle\\nofdiagram\\nFern plants reproduce using both asexual reproduction \\nand sexual reproduction … The heart -shaped plant \\nbegins the fern's sexual reproduction stage … The mature \\nfern can make spores and begin the fern life cycle again.Rationale\\nFerns do not produce seeds. Mature ferns produce spores, \\nand heart -shaped plants produce eggs and sperm.Answer\\nThe answer \\nis (B)Graph -of-Thought with Rationale\\nproduce seeds ferns\\nshowslife \\ncycle\\nofdiagramhassexual \\nproduction\\nstage\\nFigure 1: An example of GoT reasoning. Vision features are optional and are only required in\\nmultimodal reasoning task.\\nAn example of GoT reasoning is shown in Figure 1. Inspired by Multimodal-CoT [ 1], we have\\nadopted a two-stage reasoning framework. It first generates rationales and then generates the final\\nanswer based on the predicted rationales. In addition to text features, graph features of GoT are\\nintegrated during the rationale generation and answer inference. Specifically, GoT is first constructed\\nwith an Extract-Cluster-Coreference (ECC) process, which simulates the deductive process in human\\nreasoning. We have used T5 [ 9] pre-trained language model as our backbone model. GoT is encoded\\nwith a graph attention network and then fused with the original representation via a gated fusion\\nnetwork.\\nFurthermore, we have also presented a multimodal GoT, which integrates not only text features and\\nGoT features but also visual features. For our experiments, we have used both UnifiedQA (T5)-base\\nand UnifiedQA (T5)-large [10] as our backbone models.\\nWe implement GoT as a two-stage framework and fine-tuning language models and integrating text,\\nthought graph, and vision features for a more realistic and accurate reasoning process. GoT demon-\\nstrates exceptional performance on both text-only GSM8K [ 11] and multimodal ScienceQA [ 12]\\nbenchmarks, surpassing the accuracy of online system ChatGPT [ 5] by 25.08%, 14.46%, strong\\nbaseline Multimodal-CoT [ 1] by 6.63%, and even exceeding human performance, establishing a new\\nstate-of-the-art on ScienceQA test set with far more less parameters.\\n2\", metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 1}), Document(page_content='2 Graph-of-Thought\\nThought Graph\\nImage (Optional)\\nGraph -of-Thought \\nConstructor\\nInput Text \\nQuestion: Do ferns \\nproduce seeds?\\nChoices: (A) Yes (B) No\\nContext: This diagram \\nshows the life cycle of \\na fern.\\nPredicted \\nRationalesInput Encoder\\nGoT\\nEncoder\\nText\\nencoder\\nVision \\nencoderGraph \\nAttention \\nNetwork \\nTransformer\\nEncoder\\nFeature\\nExtractorCross\\nAttention\\nCross\\nAttentionGated\\nFusion\\nLayerTransformer\\nDecoder\\nStage 1\\nPredict Rationales\\nLecture：Fern plants reproduce \\nusing both asexual reproduction \\nand sexual reproduction…\\nSolution :  Ferns do not produce \\nseeds. Mature ferns produce \\nspores…\\nThe answer is (B).Decoder\\nOutput Feature FusionStage 2\\nStage 2\\nPredict Answers\\nFigure 2: Graph-of-Thought framework overview\\nThe overview of our proposed GoT can be seen in Figure 2. Inspired by Multimodal-CoT [ 1], GoT\\nalso adopts a two-stage framework. (1) Rationale generation stage: In the first stage, the model\\ngenerates rationales based on the input text (including question, context, and choices) the vision\\nfeatures, and the generated thought graph corresponding to the input text. GoT employs independent\\nencoders to encode input data for each modality. We use a Transformer encoder to encode input text,\\na vision encoder to encode an image, and a graph attention network to encode the thought graph.\\nThe encoded features are further passed into cross-attention to align text tokens with image patches\\nand graph nodes, respectively. We then use a gated fusion layer to fuse these three features further\\nand pass them into the Transformer decoder to predict the target rationales. (2) Answer generation\\nstage: The second stage aims at generating the final answer and is largely similar to the first stage.\\nThe main difference is that the input text is concatenated with the predicted rationales from the first\\nstage. It is worth noting that the above process describes a general multimodal reasoning framework.\\nHowever, for text-only reasoning tasks, there are no image features, so the image encoding and vision\\nfeature fusion processes mentioned above can be omitted. In the following section, we will provide a\\ndetailed exposition of the two key steps of our GoT reasoning framework: GoT construction and GoT\\nencoding and integration.\\n2.1 GoT Construction\\nThe word earthquake \\ncomes from the words \\nearth and quake. The word \\nearth means ground, and \\nthe word quake means to \\nshake.Earthquakecomes \\nfromearth\\nquakemeansground\\nshakeGoT Rationales\\nFigure 3: Graph-of-Thought deduction example\\n3', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 2}), Document(page_content='GoT employs thought graphs to simulate human deductive reasoning, thereby modeling humans’\\nability for leaps of thought. Our aim is to reflect the most fundamental deduction process by con-\\nstructing a thought graph. If we have evidence that x→yandy→z, then it follows that x→z. In\\nFigure 3, the deduction reasoning can be formulated as follows: Earthquakecomes from−→ { earth, quake },\\n{earth, quake }means−→ { ground, shake }. It is easy to reason that Earthquake −→{ ground, shake }.\\nWe propose a novel Extract-Clustering-\\nCoreference (ECC) process to construct\\nthought graphs. ECC first extracts deductive\\ntriplets T={ti= (ti\\nx, ti\\ny, ti\\nz)}as the discrete\\nraw graph, where ti\\nx,ti\\ny, and ti\\nzare thought\\nunits of the i-th triplet, and there exists an\\nedgeei\\nxybetween ti\\nxandti\\ny, and an edge ei\\nyz\\nbetween ti\\nyandti\\nz. Then, ECC clusters the\\nnodes that refer to the same mentions to con-\\nduct coreference resolution. Specifically, we\\nreplace every graph node that belongs to a\\ncoreference cluster with the most representa-\\ntive mention in the cluster. By adopting this\\ntechnique, our model is better equipped with\\ndenser thought graphs and the ability for de-\\nductive reasoning. The detailed algorithm is\\nillustrated in Algorithm 1.Algorithm 1 ECC process\\nInput: Input text S\\nOutput: Thought graph G(N,E)\\nExtract deductive triplet set Tfrom S\\nT={t0, t1, ..., tn},ti= (ti\\nx, ti\\ny, ti\\nz)\\nforevery triplet ti∈Tdo\\nNr← N r∪ {ti\\nx, ti\\ny, ti\\nz}\\nEr← Er∪ {ei\\nxy, ei\\nyz}\\nend for\\nextract coreference clusters CforNr\\nforevery node ni∈ Nrdo\\nifni∈ ∀cj∈ Cthen\\nn∗\\nj←most representative mention in cj\\nN ← N ∪ { n∗\\nj}\\nend if\\nend for\\nReconnect Nbased on Erto construct E\\nreturn N,E\\nIn GoT construction, during the rationale generation stage, the input text consists of concatenated\\nquestion, context, and choices. In multimodal GoT, image caption [ 12] is appended to the input text\\nfor GoT to incorporate image information. During the answer inference stage, the predicted rationales\\nfrom the rationale generation stage are further concatenated with the input text for corresponding\\nGoT construction.\\nIn our implementation of ECC process, inspired by [ 13], we utilize open information extraction (Ope-\\nnIE) systems2[14] to extract subject-verb-object triplets as thought unit nodes. We apply coreference\\nresolution to the extracted nodes using the Stanford CoreNLP system [ 15]. The constructed thought\\ngraph is denoted as G(N,E), where Nrepresents the nodes extracted by OpenIE and Erepresents\\nthe adjacency matrix. Rows and columns correspond to the nodes in the graph, and if there is an edge\\nbetween two nodes, the corresponding matrix element is 1; otherwise, it is 0.\\n2.2 GoT Encoding and Integration\\nGoT reasoning utilizes separate encoders to encode input data for each modality. The thought graph\\nis encoded using a graph attention network, while the input text is encoded using a Transformer\\nencoder. In multimodal GoT reasoning, the image is encoded using an additional vision encoder.\\n2.2.1 Base Encoder\\nText Encoder For text representation, we use the Transformer encoder (e.g. T5 [ 9]) to encode the\\ninput text. Given input sentence S={w0, ..., w l}, we extract the hidden states from the last layer of\\nthe Transformer encoder to obtain the text representation HT:\\nHT={h0, h1, ..., h l}=Encoder text(S) (1)\\nwhere hiis the hidden representation of token iandlrepresents the length of the text input.\\nVision Encoder (Optional) For multimodal reasoning where vision modality is required, follow-\\ning [ 1], we extract patch-level features of image Iusing readily available vision extraction model\\n2https://github.com/philipperemy/Stanford-OpenIE-Python\\n4', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 3}), Document(page_content='as vision encoder Encoder vision and then employ a trainable projection matrix WIto project the\\nextracted features into the vision representation HIwhich have the same shape with HT.\\nHI=WIEncoder vision(I) (2)\\n2.2.2 GoT Encoder\\nNode Embedding We first use special tokens <s>\\nand</s> to highlight every thought graph node.\\nSpecifically, for node set with jnodesN={n0, ...n j}\\n, we construct the node input as p. we then feed the p\\ninto the same text encoder and utilize the output repre-\\nsentation of the special token <s> as the initial node\\nrepresentation. Formally,\\np= [<s>, n0,</s> , ...,<s>, nj,</s> ] (3)\\n[hs\\n0, hn\\n0, he\\n0, ..., hs\\nj, hn\\nj, he\\nj] =Encoder text(p)(4)\\nwhere the hs\\niandhe\\ni∈RDare the representation of <s>\\nand</s> for node nirespectively, Dis the dimension\\nof node embedding, and the hn\\ni={hn\\ni,1, ..., hn\\ni,m}is\\nthe representations of node niwithmtokens. we use\\nthehs\\nito represent the node representation of ni.\\nGAT Encoder We employ a graph attention network\\n(GAT) [ 16,13] to encode the thought graph. For every\\nnode niin graph G(N,E), thegraph attention layer\\nis designed as:\\nDropout\\nGoT inputG𝑁,𝐸Graph \\nAttention LayerGraph \\nAttention LayerConcatenateDropoutGraph \\nAttention LayerFFNNLayernormGoT representation\\nMulti -head \\nattentionResidual connection\\nℎ𝑔′ℎ𝑔′𝐻𝐺\\n…Figure 4: Architecture of GoT encoder\\naij=Attention (\\x02\\nWhs\\ni||Whs\\nj\\x03\\n); qij=LeakyReLU (aij) (5)\\nαij=Softmax (qij) =exp (qij)P\\nk∈K iexp (qik); hg′\\ni=GELU\\uf8eb\\n\\uf8edX\\nj∈K iαijWhs\\nj\\uf8f6\\n\\uf8f8 (6)\\nwhere ||denotes concatenate operation, the Wis a trainable weight and the set Kicontains the node\\nni’s neighbours in thought graph G. Our graph attention layer first employed a shared attention\\nmechanism Attention (.) :RD′×RD′→Rto compute the attention weights, where D′is the\\nattention layer output dimension. The attention weights aijmeasures the importance of node ni’s\\nfeatures to nj’s features. By only calculating the attention weights between nodes who are neighbours,\\nour graph attention layer demonstrates the ability to perceive structural information of graphs. In\\nour implementation, we adopt a single-layer feed-forward neural network (FFNN) as the attention\\nmechanism which is both simple and straight-forward.\\nThe architecture of our GoT encoder can be seen in Figure 4. Our GoT encoder employs a multi-head\\ngraph attention layer, following [ 16], we concatenate the output of each graph attention layer and\\nfurther pass it to a output graph attention layer with the same architecture:\\nhg′\\ni=∥K\\nk=1GELU\\uf8eb\\n\\uf8edX\\nj∈N iαk\\nijWkhs\\nj\\uf8f6\\n\\uf8f8; hg′′\\ni=GELU\\uf8eb\\n\\uf8edX\\nj∈N iαijWhg′\\nj\\uf8f6\\n\\uf8f8 (7)\\nwhere Kis the number of attention heads, ||is the concatenate operation, and nis the number of\\nnodes in thought graph. We then use a single-layer feed-forward neural network (FFNN) to obtain\\nthe final thought graph embedding HG:\\nhg′′= [hg′′\\n0, ..., hg′′\\nn]; HG=FFNN (hg′′) (8)\\n5', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 4}), Document(page_content='2.3 Feature Fusion\\nAfter obtaining the encoded features, we use a single head attention to align the text representation\\nHTwith image representation HIand thought graph representation HG, respectively. The image\\nattention output HIand thought graph attention output HGare calculated by:\\nHI=Softmax\\x12HTHI⊤\\n√\\nd\\x13\\nHI;HG=Softmax\\x12HTHG⊤\\n√\\nd\\x13\\nHG(9)\\nwhere QisHTanddis the dimension of HT. We take both KIandVIasHIandKGandVGas\\nHG. Please note that image representation is optional and is only required for multimodal dataset.\\nNext, a gated fusion mechanism [ 17,1,18,19] is applied to combine the attention outputs HIand\\nHGwith the text representation HT. The feature fusion output Hcan be calculated by:\\nλ=(\\nSigmoid\\x00\\nWTHT+WGHG\\x01\\ntext-only reasoning\\nSigmoid\\x00\\nWTHT+WIHI+WGHG\\x01\\nmultimodal reasoning(10)\\nH=(\\n(1−λ)·HT+λ·HGtext-only reasoning\\n(1−λ)·HT+λ·HI+λ·HGmultimodal reasoning(11)\\nwhere WT,WIandWGare all trainable weights. We then input the fused feature output Hinto the\\ndecoder to predict the rationales or the final answer.\\n3 Experiments\\nDataset We evaluate our model on the text-only GSM8K [ 11] and multimodal ScienceQA bench-\\nmark [ 12]. GSM8K benchmark comprises 8.5K meticulously crafted grade school math problems\\nwith annotated 2 to 8 problem solution steps. For GSM8K, the model is trained to reasoning through\\nthe steps to generate the final answer. ScienceQA benchmark is the pioneering large-scale dataset\\nfor multimodal science questions, equipped with comprehensive annotations for answers, including\\ndetailed lectures and explanations. The dataset contains 21k questions covering three subjects: natural\\nscience, language science, and social science. Each question is presented with a context in the form\\nof natural language or an optional image. The model is trained to elucidate the reasoning process in\\nnatural language while choosing the answer from a set of options. The detailed dataset statistics are\\nshown in Appendix A.2.\\nModel Setup In our experiments, we used T5 [ 9] as our basic model architecture, including both\\nT5-base and T5-large model sizes. Specifically, to ensure a fair comparison, we initialized our model\\nwith the pre-trained T5 checkpoint - UnifiedQA [ 10] and used DETR [ 20] for the vision encoder,\\nfollowing [ 7]. We fine-tuned the models for 50 epochs with a learning rate of 5e-5. The detailed\\ntraining parameters are available in Appendix A.3. We trained our models on four NVIDIA GeForce\\nRTX 4090 24G GPUs.\\n4 Results and Discussion\\n4.1 Main Results\\nBaselines For GSM8K, our baselines include: (1) few-shot LLMs including GPT-3 [ 21], GPT-\\n3.5 [ 5], GPT-4 [ 5], and code-davinci-002 [ 22] (2) LLMs with CoT: To have a fair comparison we\\nalso fine-tuned UnifiedQA baseand UnifiedQA large[10] on GSM8K with traditional two-stage CoT.\\nFor ScienceQA, following [ 1,12], our adopted baselines include: (1) Vision question answering\\n(VQA) baseline models [ 23–30]; (2) Text-to-text LLMs [ 31,32] and (3) Text-to-text LLMs with\\nCoT prompting [ 12,1]. Both UnifiedQA [ 12] and GPT-3.5 [ 12] use generated image captions to\\nincorporate vision semantics. Whereas, Mutimodal-CoT [ 1] injects generated image features into\\ntraditional CoT reasoning.\\n6', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 5}), Document(page_content='Table 1: Rationale generation results (%). (*: we re-run the Mutimodal-CoT baseto report the full\\nrouge scores)\\nMODELS ROUGE-L ROUGE-1 ROUGE-2 ROUGE-LSUM\\nGSM8K\\nUnifiedQA base[31] 70.61 75.32 51.13 70.24\\nUnifiedQA large [31] 72.83 76.91 54.25 72.34\\nGoT-T5 base 71.08 75.46 51.85 70.61\\nGoT-T5 large 72.91 76.93 54.57 72.45\\nScienceQA\\nMutimodal-CoT∗\\nbase[1] 96.98 97.26 94.00 97.16\\nGoT-T5 base 98.29 98.43 96.23 98.37\\nGoT-T5 large 98.35 98.45 96.30 98.41\\nResults The rationales generation results can be seen in Table 1. The overall results are reported in\\nTable 2 and Table 3. On the GSM8K dataset, for rationale generation in the first stage, our GoT base\\nmodel achieves a 0.47 improvement in ROUGE-L compared to the UnifiedQA basemodel that did\\nnot incorporate GoT and the GoT largemodel achieves a 0.08 improvement. In the second stage of\\nanswer generation, the GoT base model showed a 3.41% increase in accuracy, while the GoT large\\nmodel achieved a 5.08% improvement. GoT outperformed GPT-3 by 27.18% in accuracy while using\\nsignificantly fewer parameters than GPT-3. Although GPT-4 achieves a result of 92%, there is a high\\nprobability it has over 175 billion parameters. Our model, compared to UnifiedQA large, reduces the\\naccuracy gap by 5%.\\nFor ScienceQA dataset, in rationale generation stage, we can see from Table 1 that our model\\nachieves a ROUGE-L of 98.29 and outperforms the Mutimodal-CoT baseby 1.31. For the final answer\\ngeneration stage, our GoT achieves SOTA in all subjects and all grades. The most direct comparison\\nis that our model achieves an accuracy of 91.68% which is 6.77% higher than that of the Mutimodal-\\nCoT basewith the similar number of parameters and is competitive to the Mutimodal-CoT largewith\\n738M parameters.\\nWe can observe from Table 1 that the impact of GoT on rationale generation is limited. We attribute\\nthis limitation to the fact that the input text for thought graph construction only includes questions\\nand choices. Consequently, the thought graph constructed from such limited information can only\\nfacilitate constrained deductive reasoning. However, in the answer generation stage, when provided\\nwith rationales, the model needs to possess stronger deductive reasoning capabilities to understand the\\nrelationship between rationales, questions, and choices. Therefore, GoT demonstrates a significant\\nadvantage over traditional CoT, elevating the accuracy from 62.70% to 66.11% in GSM8K and\\nfrom 84.91% to 91.54% in ScienceQA task. The results sufficiently suggest that utilizing thought\\ngraph features for deductive reasoning is a more effective approach than the existing methods, which\\nonly consider text or vision features by simply incorporating image captions or fusing generated\\nimage features. In conclusion, our results confirm the effectiveness of utilizing two-dimensional\\ngraph-of-thought and demonstrate the potential of incorporating GoT into reasoning for LLMs.\\nTable 2: Main test accuracy results (ACC%) of GSM8K. Size=backbone model size.\\nMODELS TRAINING SIZE ACC(%)\\nGPT-3 [21] train-set 175B 55.00\\ncode-davinci-002 [22] few-shot 175B 68.01\\nGPT-3.5 [5] few-shot - 57.10\\nGPT-4 [5] few-shot - 92.00\\nUnifiedQA base[10] train-set 223M 62.70\\nGoT-T5 base train-set 223M 66.11\\nUnifiedQA large[10] train-set 738M 77.10\\nGoT-T5 large train-set 738M 82.18\\n7', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 6}), Document(page_content='Table 3: Main test accuracy results (%) of ScienceQA. SIZE=backbone model size. Question classes:\\nNAT = natural science, SOC = social science, LAN = language science, TXT = text context, IMG =\\nimage context, NO = no context, G1-6 = grades 1-6, G7-12 = grades 7-12, A VG= average accuracy\\nscores\\nMODEL TRAINING SIZE NAT SOC LAN TXT IMG NO G1-6 G7-12 A VG\\nHuman - - 90.23 84.97 87.48 89.60 87.50 88.10 91.59 82.42 88.40\\nVision question answering baselines\\nMCAN [23] train-set 95M 56.08 46.23 58.09 59.43 51.17 55.40 51.65 59.72 54.54\\nTop-Down [24] train-set 70M 59.50 54.33 61.82 62.90 54.88 59.79 57.27 62.16 59.02\\nBAN [25] train-set 112M 60.88 46.57 66.64 62.61 52.60 65.51 56.83 63.94 59.37\\nDFAF [26] train-set 74M 64.03 48.82 63.55 65.88 54.49 64.11 57.12 67.17 60.72\\nViLT [27] train-set 113M 60.48 63.89 60.27 63.20 61.38 57.00 60.72 61.90 61.14\\nPatch-TRM [28] train-set 90M 65.19 46.79 65.55 66.96 55.28 64.95 58.04 67.50 61.42\\nVisualBERT [29, 30] train-set 111M 59.33 69.18 61.18 62.71 62.17 58.54 62.96 59.92 61.87\\nText-to-text LLMs\\nUnifiedQA base[31] zero-shot 223M 68.16 69.18 74.91 63.78 61.38 77.84 72.98 65.00 70.12\\nGPT-3.5 [32] zero-shot 175B 74.64 69.74 76.00 74.44 67.28 77.42 76.80 68.89 73.97\\nText-to-text LLMs with CoT\\nUnifiedQA base(CoT) [12] zero-shot 223M 71.00 76.04 78.91 66.42 66.53 81.81 77.06 68.82 74.11\\nGPT-3.5 (CoT) [12] 2-shot 175B 75.44 70.87 78.09 74.68 67.43 79.93 78.23 69.68 75.17\\nChatGPT (CoT) [33] few-shot - 78.82 70.98 83.18 77.37 67.92 86.13 80.72 74.03 78.31\\nGPT-4 (CoT) [33] few-shot - 85.48 72.44 90.27 82.65 71.49 92.89 86.66 79.04 83.99\\nMutimodal-CoT base[1] train-set 223M 87.52 77.17 85.82 87.88 82.90 86.83 84.65 85.37 84.91\\nGoT-T5 base train-set 223M92.51 88.98 91.61 92.39 90.84 92.33 91.68 91.27 91.54\\n±0.24 ±0.37 ±0.78 ±0.23 ±0.39 ±0.60 ±0.05 ±0.36 ±0.12\\nMutimodal-CoT large[1] train-set 738M 95.91 82.00 90.82 95.26 88.80 92.89 92.44 90.31 91.68\\nGoT-T5 large train-set 738M96.51 82.26 93.61 96.56 89.56 94.29 93.83 90.86 92.77\\n±0.25 ±0.21 ±0.19 ±0.26 ±0.29 ±0.10 ±0.18 ±0.38 ±0.18\\n4.2 Further Exploration\\n4.2.1 Ablation Study\\nIn order to make sure that: (1) our GoT’s performance gain is not simply due to the increase of\\nparameters. We conduct an ablation study where we enlarge the number of parameters of Mutimodal-\\nCoT baseto the same size 233M with our model. The enlarged model is denoted as Mutimodal-\\nCoT base(enlarged). (2) introducing thought graphs into GoT reasoning indeed boost the performance.\\nWe construct a random thought graph by randomly select graph nodes. (3) the multi-head attention\\nmechanism in GoT encoder is necessary. We employ a single-head attention. The overall ablation\\nresults can be found in Table 4.\\nTable 4: Ablation results of GoT.\\nMODEL MODEL SIZE G1-6 G7-12 A VG ∆\\nGoT-T5 base\\n233M91.68 91.27 91.54 -\\nw/ Random Connection 91.23 90.18 90.85 -0.69\\nw/ Single-head attention 91.08 90.77 90.97 -0.53\\nMutimodal-CoT base(enlarged) 233M 89.28 87.21 88.54 -3.00\\nFrom the table, we can see that our model significantly outperforms the enlarged Mutimodal-CoT by\\nan accuracy of 3.00%. The results sufficiently proved the importance of introducing thought graphs\\ninto multimodal reasoning. When reducing the multi-head attention to single-head attention, GoT\\nsuffers a loss of 0.53% accuracy, indicating the necessity of multi-head attention mechanism for GoT\\nencoder. By randomly construct thought graphs to disrupt the deductive reasoning process, our model\\nsuffers a loss of 0.69%, indicating the effectiveness of GoT.\\n4.2.2 Analysis\\nPerformance on Different Classes In order to investigate the impact of GoT on the overall\\nmodel performance across different subjects , we calculated the accuracy for different subjects and\\ncompared it with that of enlarged Mutimodal-CoT. We also compare the performance of two models\\non different question classes.The radar Figure 5 shows the overall results for our base model. With\\nrespect to various subjects and question classes, our model demonstrates superior performance over\\n8', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 7}), Document(page_content='the Mutimodal-CoT baseand attains a more consistent and enhanced outcome. Our model presents\\noutstanding advantages especially in the field of social science, with an accuracy improvement of\\n8.01%. For different question classes, our model demonstrates the largest improvement on questions\\ninvolving images. Our hypothesis is that by constructing a thought graph and integrating the three\\nfeatures of text, image, and thought graph, we can better align the textual and visual information\\nfor the model, thus maximizing the utilization of visual information and obtaining more accurate\\nanswers.\\n75.0080.0085.0090.0095.00100.00NAT\\nSOC\\nLAN\\nTXTIMGNOMutimodal-CoT(enlarged) Ours(base)\\nFigure 5: Performance on different question\\nclasses5 1080859095100\\nGradesAccuracy(%)\\nOurs base\\nMutimodal-CoT base(enlarged)\\nFigure 6: Performance on different grades\\nPerformance on Different Grades It can be seen from the Table 4 that the enlarged Mutimodal-\\nCoT experience a decrease in accuracy of 2.07 as the grade level of the given question increases\\nwhile GoT only has minor decrease of 0.41. We believe the main reason is that by incorporating\\nGoT, models acquires the ability for deductive reasoning and can better comprehend the relationships\\nbetween different entities and thus better understand the meaning of the problems. Through this\\nmethod, for higher-grade problems with greater complexity, the model can construct a thought graph\\nto help itself generate a more complete logical chain for deduction, thereby generating more accurate\\nanswers. More detailed model performance on different grades can be found in Figure 6. We can see\\nfrom the figure that in the lower grade, two models achieves a similar performance. As the grade level\\nincreases and the difficulty of the questions becomes more challenging, the gap between our model\\nand the Mutimodal-CoT model gradually widens. Due to the small number of questions ( ≤130)\\navailable for each grade in grade 1 and grades 9-12, there is greater fluctuation in the accuracy of\\nboth models. Nevertheless, it is evident from the table that our model exhibits stronger and more\\nstable advantages over Mutimodal-CoT in each grade.\\nCase Study and Limitation In order to gain a deeper understanding of the performance of GoT, we\\nconduct a manual investigation of randomly selected examples generated by our approach which can\\nbe found in Appendix A.4. We also visualize the attention weights aijin GoT encoder to demonstrate\\nhow GoT performs deductive reasoning to generate more accurate answers in Appendix A.5\\nFor the limitation of this work, compared to CoT, GoT may result in additional computational costs\\nand slightly slower training times. Detailed limitation analysis can be found in Appendix A.6.\\n5 Conclusion\\nWe introduce a novel Graph-of-Thought (GoT) reasoning approach, which is an innovative method\\nfor modeling the non-sequential nature of human thinking within large language models (LLMs).\\nGoT enhances LLMs with deductive reasoning abilities, providing a more realistic representation of\\n9', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 8}), Document(page_content='thought processes. Our experiments showcases the superiority of GoT on the text-only reasoning\\ndataset, achieving an accuracy of 82.18% on the GSM8K test set, outperforming GPT-3 significantly\\nwhile utilizing significantly fewer parameters. Furthermore, GoT establishes a new state-of-the-art\\non the multimodal reasoning benchmark, ScienceQA, achieving an impressive accuracy of 92.77%\\nwith fewer parameters. This performance surpasses strong ChatGPT and GPT-4 systems, as well as\\nhuman performance, demonstrating the efficacy of GoT. Through comprehensive case studies and\\nablation studies, we provide substantial evidence of the effectiveness of GoT in reasoning tasks. If\\nyou want it, you GoT it!\\nReferences\\n[1]Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multi-\\nmodal chain-of-thought reasoning in language models. CoRR , abs/2302.00923, 2023. doi: 10.\\n48550/arXiv.2302.00923. URL https://doi.org/10.48550/arXiv.2302.00923 .\\n[2]Lawrence W Barsalou. Perceptual symbol systems. Behavioral and brain sciences , 22(4):\\n577–660, 1999.\\n[3]Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-\\nwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,\\nAriel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M.\\nZiegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz\\nLitwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish,\\nAlec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learn-\\ners. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and\\nHsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual\\nConference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-\\n12, 2020, virtual , 2020. URL https://proceedings.neurips.cc/paper/2020/\\nhash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html .\\n[4]Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\\nKensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay,\\nNoam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope,\\nJames Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke,\\nAnselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant\\nMisra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek\\nLim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal,\\nMark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor\\nLewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou,\\nXuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language\\nmodeling with pathways. CoRR , abs/2204.02311, 2022. doi: 10.48550/arXiv.2204.02311. URL\\nhttps://doi.org/10.48550/arXiv.2204.02311 .\\n[5]OpenAI. Gpt-4 technical report. 2023. URL https://cdn.openai.com/papers/\\ngpt-4.pdf .\\n[6]Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi, Quoc Le, and\\nDenny Zhou. Chain of thought prompting elicits reasoning in large language models. CoRR ,\\nabs/2201.11903, 2022. URL https://arxiv.org/abs/2201.11903 .\\n[7]Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V . Le, Ed H. Chi, and Denny Zhou. Self-\\nconsistency improves chain of thought reasoning in language models. CoRR , abs/2203.11171,\\n2022. doi: 10.48550/arXiv.2203.11171. URL https://doi.org/10.48550/arXiv.\\n2203.11171 .\\n[8]Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. Automatic chain of thought prompting\\nin large language models. CoRR , abs/2210.03493, 2022. doi: 10.48550/arXiv.2210.03493.\\nURL https://doi.org/10.48550/arXiv.2210.03493 .\\n10', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 9}), Document(page_content='[9]Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\\nYanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified\\ntext-to-text transformer. Journal of Machine Learning Research , 21(140):1–67, 2020. URL\\nhttp://jmlr.org/papers/v21/20-074.html .\\n[10] Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark,\\nand Hannaneh Hajishirzi. Unifiedqa: Crossing format boundaries with a single QA system. In\\nTrevor Cohn, Yulan He, and Yang Liu, editors, Findings of the Association for Computational\\nLinguistics: EMNLP 2020, Online Event, 16-20 November 2020 , volume EMNLP 2020 of\\nFindings of ACL , pages 1896–1907. Association for Computational Linguistics, 2020. doi:\\n10.18653/v1/2020.findings-emnlp.171. URL https://doi.org/10.18653/v1/2020.\\nfindings-emnlp.171 .\\n[11] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christo-\\npher Hesse, and John Schulman. Training verifiers to solve math word problems. CoRR ,\\nabs/2110.14168, 2021. URL https://arxiv.org/abs/2110.14168 .\\n[12] Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind\\nTafjord, Peter Clark, and Ashwin Kalyan. Learn to explain: Multimodal reasoning via thought\\nchains for science question answering. In The 36th Conference on Neural Information Process-\\ning Systems (NeurIPS) , 2022.\\n[13] Jiaao Chen and Diyi Yang. Structure-aware abstractive conversation summarization via discourse\\nand action graphs. In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-\\nTür, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou, editors,\\nProceedings of the 2021 Conference of the North American Chapter of the Association for\\nComputational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-\\n11, 2021 , pages 1380–1391. Association for Computational Linguistics, 2021. doi: 10.18653/v1/\\n2021.naacl-main.109. URL https://doi.org/10.18653/v1/2021.naacl-main.\\n109.\\n[14] Gabor Angeli, Melvin Jose Johnson Premkumar, and Christopher D. Manning. Leveraging\\nlinguistic structure for open domain information extraction. In Proceedings of the 53rd Annual\\nMeeting of the Association for Computational Linguistics and the 7th International Joint\\nConference on Natural Language Processing (Volume 1: Long Papers) , pages 344–354, Beijing,\\nChina, July 2015. Association for Computational Linguistics. doi: 10.3115/v1/P15-1034. URL\\nhttps://aclanthology.org/P15-1034 .\\n[15] Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, and David\\nMcClosky. The Stanford CoreNLP natural language processing toolkit. In Proceedings of 52nd\\nAnnual Meeting of the Association for Computational Linguistics: System Demonstrations ,\\npages 55–60, Baltimore, Maryland, June 2014. Association for Computational Linguistics. doi:\\n10.3115/v1/P14-5010. URL https://aclanthology.org/P14-5010 .\\n[16] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua\\nBengio. Graph attention networks. In 6th International Conference on Learning Representations,\\nICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings .\\nOpenReview.net, 2018. URL https://openreview.net/forum?id=rJXMpikCZ .\\n[17] Zhiyong Wu, Lingpeng Kong, Wei Bi, Xiang Li, and Ben Kao. Good for misconceived reasons:\\nAn empirical revisiting on the need for visual context in multimodal machine translation. In\\nProceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the\\n11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) ,\\npages 6153–6166, Online, August 2021. Association for Computational Linguistics. doi: 10.\\n18653/v1/2021.acl-long.480. URL https://aclanthology.org/2021.acl-long.\\n480.\\n[18] Bei Li, Chuanhao Lv, Zefan Zhou, Tao Zhou, Tong Xiao, Anxiang Ma, and JingBo Zhu. On\\nvision features in multimodal machine translation. In Proceedings of the 60th Annual Meeting\\nof the Association for Computational Linguistics (Volume 1: Long Papers) , pages 6327–6337,\\nDublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.\\nacl-long.438. URL https://aclanthology.org/2022.acl-long.438 .\\n11', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 10}), Document(page_content='[19] Zhuosheng Zhang, Kehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita, Zuchao Li, and\\nHai Zhao. Neural machine translation with universal visual representation. In 8th International\\nConference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020 .\\nOpenReview.net, 2020. URL https://openreview.net/forum?id=Byl8hhNYPS .\\n[20] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kir-\\nillov, and Sergey Zagoruyko. End-to-end object detection with transformers. In Andrea\\nVedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm, editors, Computer Vision\\n- ECCV 2020 - 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceed-\\nings, Part I , volume 12346 of Lecture Notes in Computer Science , pages 213–229. Springer,\\n2020. doi: 10.1007/978-3-030-58452-8\\\\_13. URL https://doi.org/10.1007/\\n978-3-030-58452-8_13 .\\n[21] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\\nlanguage models are zero-shot reasoners. CoRR , abs/2205.11916, 2022. doi: 10.48550/arXiv.\\n2205.11916. URL https://doi.org/10.48550/arXiv.2205.11916 .\\n[22] Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale\\nSchuurmans, Olivier Bousquet, Quoc Le, and Ed H. Chi. Least-to-most prompting enables\\ncomplex reasoning in large language models. CoRR , abs/2205.10625, 2022. doi: 10.48550/\\narXiv.2205.10625. URL https://doi.org/10.48550/arXiv.2205.10625 .\\n[23] Zhou Yu, Jun Yu, Yuhao Cui, Dacheng Tao, and Qi Tian. Deep modular co-attention\\nnetworks for visual question answering. In IEEE Conference on Computer Vision and Pattern\\nRecognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019 , pages 6281–6290.\\nComputer Vision Foundation / IEEE, 2019. doi: 10.1109/CVPR.2019.00644. URL\\nhttp://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Deep_\\nModular_Co-Attention_Networks_for_Visual_Question_Answering_\\nCVPR_2019_paper.html .\\n[24] Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen\\nGould, and Lei Zhang. Bottom-up and top-down attention for image captioning and vi-\\nsual question answering. In 2018 IEEE Conference on Computer Vision and Pattern\\nRecognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018 , pages 6077–6086.\\nComputer Vision Foundation / IEEE Computer Society, 2018. doi: 10.1109/CVPR.2018.\\n00636. URL http://openaccess.thecvf.com/content_cvpr_2018/html/\\nAnderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.html .\\n[25] Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang. Bilinear attention networks. In Samy Ben-\\ngio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman\\nGarnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on\\nNeural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal,\\nCanada , pages 1571–1581, 2018. URL https://proceedings.neurips.cc/paper/\\n2018/hash/96ea64f3a1aa2fd00c72faacf0cb8ac9-Abstract.html .\\n[26] Peng Gao, Zhengkai Jiang, Haoxuan You, Pan Lu, Steven C. H. Hoi, Xiaogang Wang, and\\nHongsheng Li. Dynamic fusion with intra- and inter-modality attention flow for visual question\\nanswering. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019,\\nLong Beach, CA, USA, June 16-20, 2019 , pages 6639–6648. Computer Vision Foundation\\n/ IEEE, 2019. doi: 10.1109/CVPR.2019.00680. URL http://openaccess.thecvf.\\ncom/content_CVPR_2019/html/Gao_Dynamic_Fusion_With_Intra-_and_\\nInter-Modality_Attention_Flow_for_Visual_CVPR_2019_paper.html .\\n[27] Wonjae Kim, Bokyung Son, and Ildoo Kim. Vilt: Vision-and-language transformer without\\nconvolution or region supervision. In Marina Meila and Tong Zhang, editors, Proceedings of\\nthe 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual\\nEvent , volume 139 of Proceedings of Machine Learning Research , pages 5583–5594. PMLR,\\n2021. URL http://proceedings.mlr.press/v139/kim21k.html .\\n[28] Pan Lu, Liang Qiu, Jiaqi Chen, Tanglin Xia, Yizhou Zhao, Wei Zhang, Zhou Yu, Xiaodan\\nLiang, and Song-Chun Zhu. Iconqa: A new benchmark for abstract diagram understand-\\ning and visual language reasoning. In Joaquin Vanschoren and Sai-Kit Yeung, editors,\\n12', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 11}), Document(page_content='Proceedings of the Neural Information Processing Systems Track on Datasets and Bench-\\nmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual , 2021. URL\\nhttps://datasets-benchmarks-proceedings.neurips.cc/paper/2021/\\nhash/d3d9446802a44259755d38e6d163e820-Abstract-round2.html .\\n[29] Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang. Visualbert: A\\nsimple and performant baseline for vision and language. CoRR , abs/1908.03557, 2019. URL\\nhttp://arxiv.org/abs/1908.03557 .\\n[30] Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang. What does BERT\\nwith vision look at? In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel R. Tetreault, editors,\\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL\\n2020, Online, July 5-10, 2020 , pages 5265–5275. Association for Computational Linguistics,\\n2020. doi: 10.18653/v1/2020.acl-main.469. URL https://doi.org/10.18653/v1/\\n2020.acl-main.469 .\\n[31] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\\nYanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified\\ntext-to-text transformer. J. Mach. Learn. Res. , 21:140:1–140:67, 2020. URL http://jmlr.\\norg/papers/v21/20-074.html .\\n[32] Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey E.\\nHinton. Big self-supervised models are strong semi-supervised learners. In Hugo\\nLarochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien\\nLin, editors, Advances in Neural Information Processing Systems 33: Annual Conference\\non Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,\\nvirtual , 2020. URL https://proceedings.neurips.cc/paper/2020/hash/\\nfcbc95ccdd551da181207c0c1400c655-Abstract.html .\\n[33] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-\\nChun Zhu, and Jianfeng Gao. Chameleon: Plug-and-play compositional reasoning with large\\nlanguage models. CoRR , abs/2304.09842, 2023. doi: 10.48550/arXiv.2304.09842. URL\\nhttps://doi.org/10.48550/arXiv.2304.09842 .\\n13', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 12}), Document(page_content='A Appendix\\nA.1 Related Works\\nIn chain-of-thought reasoning, one idea leads to the next in a logical sequence and builds on previous\\nknowledge. Each idea is supported by evidence or reasoning, and the conclusions drawn from the\\nchain are logical and sound. Most CoT methods can be divided into two categories based on how to\\ngenerate the final answer: (1) prompting for CoT, including zero-shot CoT and few-shot CoT; and (2)\\nfine-tuning for CoT.\\nZero-shot CoT Prompting As large language models continue to advance rapidly, many re-\\nsearchers are beginning to explore CoT reasoning for LLMs. The zero-shot CoT method proposed\\nby Kojima et al. [21] consists of two stages: (1) adding a \" Let’s think step by step \" prompt to generate\\nCoT, and (2) concatenating the generated CoT and adding the phrase \" So the answer is \" to obtain the\\nfinal answer.\\nFew-shot CoT Prompting Few-shot CoT reasoning for LLMs, however, utilizes multiple input-\\noutput pairs to prompt the LLMs to output CoT and obtain the final answer. Due to its ability to\\nprovide better performance compared to Zero-shot CoT, Few-shot CoT has gained more attention in\\nresearch, particularly through effective demonstrations. Few-shot CoT prompting was first formally\\nexplored by Wei et al. [6]and is a form of discrete prompt learning that involves context learning\\nin large models. Compared to traditional in-context learning, which prompts LLMs with a list of\\ninput-output demonstration pairs along with a test input to allow the model to predict output, Few-shot\\nCoT prompting outputs additional logical reasoning procedures apart from the target output. Wang\\net al. [7]proposed a follow-up method to [ 6]. The main improvement is that the model uses the\\nmajority vote for the answers, which was found to significantly improve the performance of the\\nCoT. However, these few-shot CoT models depend on hand-crafted demonstrations. To solve this\\nproblem, Zhang et al. [8]proposed Auto-CoT, which maintains the diversity of sampled questions\\nand generates reasoning chains to automatically construct demonstrations. Specifically, Auto-CoT\\nconsists of two main stages: (1) Problem clustering: divide the given dataset of problems into several\\nclusters; (2) Demonstration sampling: select a representative problem from each cluster and use a\\nsimple heuristic method to generate its reasoning chain. Furthermore, Lu et al. [33] also explores\\nfew-shot CoT reasoning for recently popular LLMs ChatGPT and GPT-4 [5].\\nCoT Fine-tuning In Zhang et al. [1], it was proposed to fine-tune smaller language models instead\\nof prompting them in LLMs. And this approach enabled the CoT to go beyond textual information\\nand incorporate visual (image) modalities using a gated fusion mechanism into a two-stage CoT. The\\nresults demonstrated that CoT fine-tuning with fewer parameters has potential. Therefore, in this\\nwork, we focus on fine-tuning for CoT to reduce the number of required model parameters and help\\nLLMs better comprehend different modalities. However, previous CoT research has been limited\\nto different modalities, such as textual and vision information, without considering the deduction\\nreasoning process. Therefore, in this work, we move beyond modeling the reasoning process solely\\nas a thought chain and elevate it to a thought graph. We provide a more comprehensive and nuanced\\nrepresentation, enabling LLMs to perceive the deduction reasoning process accurately, resulting in\\nmore precise answer generation.\\n14', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 13}), Document(page_content='A.2 Dataset statistics\\nSplits #Problems\\nTrain 7,473\\nTest 1,319\\nTable 5: GSM8K dataset statistics (# denotes\\nnumbers)Statistic Number\\nSplits\\n#Train 12,726\\n#Dev 4,241\\n#Test 4,241\\n#Total 21,208\\nAttribute\\n#Subjects 3\\n#Topic 26\\n#Category 127\\n#Skill 379\\nTable 6: ScienceQA dataset statistics (# denotes\\nnumbers)\\nA.3 Training Parameters\\nParameters Value\\nEpochs 50\\nBatch size for T5-base (per device) 4\\nBatch size for T5-large (per device) 2\\nLearning rate 5e-5\\nWeight decay 0.01\\nMax input length 512\\nMax number of nodes 150\\nTable 7: Training parameters for GoT\\nA.4 Case Study\\nTo facilitate a more illustrative comparison between GoT and the CoT, we have selected several\\nrepresentative examples. Figure 11 demonstrates examples for GSM8K dataset. Figure 8 to Figure\\n10 illustrates examples from ScienceQA dataset. From Figure 7 and Figure 8, we can see that GoT\\ncan better understand the rationales and generate more accurate result. In Figure 9, we can see that\\nwhen provided with wrong rationale, our model is more robust to the noise and can focus on more\\nimportant key information. (We highlight the noisy wrong rationale in red and correct key rationale in\\ngreen). Figure 10 presents a language problem which have less context and requires a certain amount\\nof common sense knowledge. Hence, the impact of constructing a mind map on enhancing the model\\nis not significant. Therefore, both GoT and CoT predict wrong answers.\\nA.5 Representation Visualization\\nIn order to demonstrate the deductive reasoning process of GoT more intuitively, we visualized the\\nattention weights of the GoT encoder. The visualization results can be found in Figure 12. We took\\nFigure 9 as an example. In Figure 9, even given a wrong rationale, GoT still manages to generate the\\nright answer. We select 14 representative thought nodes and found that \"blue\",\"color\", and \"common\"\\nhave the greatest weights which indicates that GoT guides the model to focus on more important\\nwords and conduct correct deductive reasoning. For the disruptive node \"a hard object,\" our model\\ncan effectively discriminate against it and assign a lower attention weight to prevent the model from\\nselecting incorrect answers, as traditional CoT models often do due to erroneous rationales.\\nA.6 Limitation\\nCompared to Mutimodal-CoT [ 1], incorporating GoT may result in additional computational costs\\nand slightly slower training times. The training parameters and inference times of the different\\nmodels are presented in Table 8, which reveals that our model requires a 0.2% increase in parameters\\ncompared to Mutimodal-CoT.\\n15', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 14}), Document(page_content='Table 8: The number of training parameters and inference time of different models (# denotes\\nnumbers)\\n#ParametersInference time\\n(eval samples/per second)\\nMutimodal-CoT base[1] 227M 16.33\\nOurs 233M 13.38\\n16', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 15}), Document(page_content='Dataset\\nGoT Prediction\\nCoT PredictionQuestion: Would you find the word pink on a dictionary page with the following guide words?\\nparrot –property\\nChoices: (A) yes (B) no\\nRationale :lecture :Guide words appear oneach page ofadictionary .They tellyouthefirst\\nword andlastword onthepage .Theother words onthepage come between theguide\\nwords inalphabetical order .Toputwords inalphabetical order, putthem inorder bytheir\\nfirstletters .Ifthefirstletters arethesame, look atthesecond letters .Ifthesecond letters\\narethesame, look atthethird letters, andsoon.Ifoneword isshorter, andthere areno\\nmore letters tocompare, then theshorter word comes first inalphabetical order .For\\nexample, becomes before bed.\\nsolution :Putthewords inalphabetical order .Since pink isbetween theguide words parrot -\\nproperty, itwould befound onthatpage .\\nAnswer :Theanswer is(A)\\nRationale :Solution :Guide words appear oneach page ofadictionary .They tellyouthefirst\\nword andlastword onthepage .Theother words onthepage come between theguide\\nwords inalphabetical order .Toputwords inalphabetical order, putthem inorder bytheir\\nfirstletters .Ifthefirstletters arethesame, look atthesecond letters .Ifthesecond letters\\narethesame, look atthethird letters, andsoon.Ifoneword isshorter, andthere areno\\nmore letters tocompare, then theshorter word comes first inalphabetical order .For\\nexample, becomes before bed.Putthewords inalphabetical order .Since pink isbetween\\ntheguide words parrot -property, itwould befound onthatpage .\\nAnswer :Theanswer is(A)\\nRationale :Solution :Guide words appear oneach page ofadictionary .They tellyouthefirst\\nword andlastword onthepage .Theother words onthepage come between theguide\\nwords inalphabetical order .Toputwords inalphabetical order, putthem inorder bytheir\\nfirstletters .Ifthefirstletters arethesame, look atthesecond letters .Ifthesecond letters\\narethesame, look atthethird letters, andsoon.Ifoneword isshorter, andthere areno\\nmore letters tocompare, then theshorter word comes first inalphabetical order .For\\nexample, becomes before bed.Putthewords inalphabetical order .Since pink isbetween\\ntheguide words parrot -property, itwould befound onthatpage .\\nAnswer :Theanswer is(B)right rationales right answer\\nright rationales wrong answerFigure 7: Examples of ScienceQA\\n17', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 16}), Document(page_content='Dataset\\nGoT Prediction\\nCoT PredictionQuestion: What is the name of the colony shown ?\\nChoices: (A) New Hampshire (B) Vermont\\n(C) New York\\nRationale :The colony isNew York.During the\\ncolonial era,New Hampshire andNew York both\\nclaimed theterritory that would later become the\\nstate ofVermont .Vermont was never itsown\\ncolony .\\nAnswer :Theanswer is(C)\\nRationale :Solution :Thecolony isNew York.During thecolonial era,New Hampshire and\\nNew York both claimed theterritory that would later become thestate ofVermont .\\nVermont wasnever itsown colony .\\nAnswer :Theanswer is(C)\\nRationale :Solution :Thecolony isDelaware York.During thecolonial era,New Hampshire\\nandNew York both claimed theterritory that would later become thestate ofVermont .\\nVermont wasnever itsown colony .\\nAnswer :Theanswer is(D)\\n(D) Delaware\\nright rationales right answer\\nwrong rationales wrong answerFigure 8: Examples of ScienceQA\\n18', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 17}), Document(page_content='Dataset\\nGoT Prediction\\nCoT PredictionQuestion: Which property do these three \\nobjects have in common?\\nChoices: (A) blue (B) hard\\n(C) sticky\\nRationale :lecture :Anobject hasdifferent properties .Aproperty ofanobject cantellyou\\nhow itlooks, feels, tastes, orsmells .Properties canalso tellyouhow anobject willbehave\\nwhen something happens toit.Different objects canhave properties incommon .Youcan\\nusethese properties toputobjects intogroups .\\nSolution :Look ateach object .Foreach object, decide ifithasthatproperty .Asticky object\\ncanattach orstick toother things .Thetoothpaste issticky, butthesoccer shorts andthe\\nwater slide arenot.Blue isacolor .Thiscolor isblue.Allthree objects areblue.Ahard object\\ndoes notchange shape when pressed orsqueezed .The water slide ishard, butthe\\ntoothpaste and thesoccer shorts arenot.The property that allthree objects have in\\ncommon isblue.\\nAnswer :Theanswer is(A)\\nRationale :Solution :Anobject hasdifferent properties .Aproperty ofanobject cantellyou\\nhow itlooks, feels, tastes, orsmells .Properties canalso tellyouhow anobject willbehave\\nwhen something happens toit.Different objects canhave properties incommon .Youcan\\nusethese properties toputobjects intogroups .Look ateach object .Foreach object, decide\\nifithasthatproperty .Ahard object canattach orstick toother things .The issticky, butthe\\nshorts andthepitcher arenot.Blue isacolor .Thiscolor isblue.Thethree objects areblue.\\nAhard object does notchange shape when pressed orsqueezed .Thetennis slide andhard,\\nbutthetennis and thewater shorts arenot.Theproperty that allthree objects have in\\ncommon isblue.\\nAnswer :Theanswer is(A)\\nRationale :Solution :Anobject hasdifferent properties .Aproperty ofanobject cantellyou\\nhow itlooks, feels, tastes, orsmells .Properties canalso tellyouhow anobject willbehave\\nwhen something happens toit.Different objects canhave properties incommon .Youcan\\nusethese properties toputobjects intogroups .Look ateach object .Foreach object, decide\\nifithasthatproperty .Asticky object canattach orstick toother things .Theissticky, butthe\\nshorts andtheblue bottle arenot.Blue isacolor .Thiscolor isblue.None three objects are\\nblue.Ahard object does notchange shape when pressed orsqueezed .None tennis slide\\nandhard, buttheisthewater shorts arenot.Theproperty that allthree objects have in\\ncommon issticky .\\nAnswer :Theanswer is(C)wrong rationales right answer\\nwrong rationales wrong answerFigure 9: Examples of ScienceQA\\n19', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 18}), Document(page_content=\"Dataset\\nGoT Prediction\\nCoT PredictionQuestion: Select the action that doesn't belong\\nChoices:(A) chop (B) blend\\n(C) stir\\nRationale :Chop doesn't belong .Blend, mix,andstiralldescribe ways tocombine\\nthings\\nAnswer :Theanswer is(A)\\nRationale :Solution :Mixp doesn‘tbelong .Murend, chop, andchop allname things toget\\nthings .\\nAnswer :Theanswer is(D)\\nRationale :Solution :Blendp doesn't belong ..Murend ,chop, andblend allname things to\\ngetAnswer :Theanswer is(B)(D) mix\\nwrong rationales wrong answerwrong rationales wrong answerFigure 10: Examples of ScienceQA\\n20\", metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 19}), Document(page_content='Dataset\\nGoT Prediction\\nCoT PredictionQuestion: James is putting together 4 tables.  Each table has 4 legs and each leg needs 2 \\nscrews.  He has 40 screws.  How many screws will he have left over?\\nRationale :Each table will take 4*2=<<4*2=8>>8screws .So he needs\\n8*4=<<8*4=32>>32screws \\\\nThat means hewillhave 40-32=<<40-32=8>>8screws\\nleftover\\nAnswer :Theanswer is8\\nRationale :Each table needs have 4*2=4*2=8>>8screws .Soheneeds 8*4=8*4=32>>32\\nscrews .That means heneeds have 40-32=40-32=8>>8leftleftover\\nAnswer :Theanswer is8\\nRationale :Hetable needs have 4*2=4*2=8>>8screws .Sohewill8*4=8*4=32>>32screws .\\nSomeans heneeds have 40-32=40-32=16>>8screws leftover\\nAnswer :Theanswer is168\\nwrong rationales wrong answerright rationales right answer\\nDataset\\nGoT Prediction\\nCoT PredictionQuestion: The caretaker of the docks needs to buy some new line. He wants 3 feet of line \\nfor every foot of dock. Right now, there is 200 feet of dock, and he has 6 feet of new line. \\nHow many feet of line does he need to buy in total?\\nRationale :200*3=<<200*3=600>>600feetofline.Thecaretaker needs tobuy600-6=\\n<<600-6=594>>594feetofline.\\nAnswer :Theanswer is594\\nRationale :Thefeet3=200*3=3>>600feetofline.Hecaretaker needs 600buy600/6=600-\\n6=1>>>594feetofline.\\nAnswer :Theanswer is594\\nRationale :Thefeet3=200*3=3>>600feetofline.Hecaretaker needs 600buy600/6=600-\\n6=15>>594feetofline.\\nAnswer :Theanswer is1594\\nwrong rationales wrong answerwrong rationales right answerFigure 11: Examples of GSM8K\\n21', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 20}), Document(page_content='three objects\\nhave in\\ncommon\\nobject\\nhas\\ndifferent properties\\nput objects into\\ngroups\\na hard object\\ncan attach to\\nother things\\nis\\ncolor\\nblue49.56\\n44.00\\nFigure 12: Representation visualization\\n22', metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 21}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nSKELETON -OF-THOUGHT : L ARGE LANGUAGE MOD-\\nELSCANDOPARALLEL DECODING\\nXuefei Ning1∗\\nfoxdoraame@gmail.comZinan Lin2∗\\nlinzinan1995@gmail.com\\nZixuan Zhou1∗\\nzhouzx21@mails.tsinghua.edu.cnZifu Wang3\\nzifu.wang@kuleuven.be\\nHuazhong Yang1\\nyanghz@tsinghua.edu.cnYu Wang1\\nyu-wang@tsinghua.edu.cn\\n1Department of Electronic Engineering, Tsinghua University, Beijing, China\\n2Microsoft Research, Redmond, Washington, USA\\n3ESAT-PSI, KU Leuven, Leuven, Belgium\\nWebsite: https://sites.google.com/view/sot-llm\\nABSTRACT\\nThis work aims at decreasing the end-to-end generation latency of large language\\nmodels (LLMs). One of the major causes of the high generation latency is the\\nsequential decoding approach adopted by almost all state-of-the-art LLMs. In\\nthis work, motivated by the thinking and writing process of humans, we propose\\nSkeleton-of-Thought (SoT) , which first guides LLMs to generate the skeleton of\\nthe answer, and then conducts parallel API calls or batched decoding to com-\\nplete the contents of each skeleton point in parallel . Not only does SoT provide\\nconsiderable speed-ups across 12 LLMs, but it can also potentially improve the\\nanswer quality on several question categories. SoT is an initial attempt at data-\\ncentric optimization for inference efficiency, and further underscores the potential\\nof pushing LLMs to think more like a human for answer quality.\\n1 I NTRODUCTION\\nLarge language models (LLMs) (Brown et al., 2020; Touvron et al., 2023a; Du et al., 2022; OpenAI,\\n2023; Zheng et al., 2023) have shown exceptional performance in natural language processing and\\nchatbot systems. However, the inference process of the state-of-the-art LLMs is slow, hindering their\\ninteractive use. For example, it takes 22 seconds for Claude (Anthropic, 2023) (accessed through\\nSlack API) and 43 seconds for Vicuna-33B V1.3 (a 33B LLaMA-based model, running locally on\\none NVIDIA A100 GPU) to answer the question in Fig. 1.\\nWe conclude three major causes of LLMs’ slow inference: (1) A large model size requires a large\\namount of memory, memory access, and computation. For example, the FP16 weights of 175B GPT-\\n3 take 350GB memory, which means at least 5 ×80GB A100 GPUs are needed to keep the model\\nin GPU memory. Even with enough GPUs, the heavy memory access and computation slow down\\nthe inference. (2) The attention operation in the prevailing transformer architecture is I/O bounded\\nand has a quadratic memory and computation complexity in sequence length. (3) The sequential\\ndecoding approach in inference generates tokens one by one. This approach introduces a significant\\n∗Equal contribution.\\n†The main updates in arXiv V2 are as follows: (1) Add the quality and efficiency evaluation of SoT on\\nGPT-4. (2) Use GPT-4 as the judge for answer quality evaluation. The old results with ChatGPT-3.5 as the\\njudge are moved to App. I.3. (3) Add the SoT with Router (SoT-R) method (§ 4) which adaptively triggers SoT\\non suitable questions. (4) Move detailed answer analysis to the appendices.\\n1arXiv:2307.15337v2  [cs.CL]  8 Oct 2023', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 0}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nAnswer1.Active listening involves fully concentrating on …2.Identify issues. Look into the root causes of …3.Compromise. Look for a middle ground …What are the most effective strategies for conflict resolution in the workplace?QuestionSkeleton-of-Thought Decoding\\nGeneratesanswerssequentially ➔SlowerNormal Decoding1. Active listening2. Identify issues3. CompromiseGeneratesanswersinparallel➔Faster(1)Skeletonstage(2)Point-expandingstage\\n1.0 1.2 1.4 1.6 1.8\\nSpeed-up−0.20.00.20.4Net win ratesVicuna-13B V1.3StableVicuna-13B\\nUltraLM-13B\\nVicuna-33B V1.3\\nLLaMA2-Chat-7B\\nLLaMA2-Chat-13BVicuna-7B V1.3ChatGPT-3.5\\nClaude\\nVicuna-7B V1.1OpenChat-13BGPT-4\\nBaseline\\nFigure 1: Left: An illustration of Skeleton-of-Thought (SoT). Instead of producing answers se-\\nquentially, SoT produces different parts of answers in parallel . In more detail, given the question,\\nSoT first prompts the LLM to give out the skeleton, then conducts batched decoding or parallel API\\ncalls to expand multiple points in parallel, and finally aggregates the outputs to get the final answer.\\nRight: The net win rates and speed-ups of SoT with router (SoT-R) compared to normal generation\\non Vicuna-80. The net win rate is the difference between the fraction of questions that SoT-R has\\nbetter and worse answers than normal generation. The speed-up is the ratio between the latency\\nof normal and SoT-R generation. (1.0,0.0)represents normal generation. Higher is better on both\\naxes. For most models, SoT-R not only accelerates the generation but also improves the quality of\\nthe answers (evaluated with FastChat metric (Zheng et al., 2023)). See § 3.2 and 4 for more details.\\ninference latency since the generation of tokens cannot be parallelized. There is a bunch of literature\\naddressing the first two axes: large model size (Xiao et al., 2022; Frantar et al., 2022; Lin et al., 2023;\\nSheng et al., 2023; Wang et al., 2021) and attention operation (Kitaev et al., 2020; Wang et al., 2020;\\nDao et al., 2022; Zaheer et al., 2020; Chen et al., 2023b). These works either compress/redesign the\\nmodel (Xiao et al., 2022; Frantar et al., 2022; Lin et al., 2023; Kitaev et al., 2020; Wang et al., 2020;\\nDao et al., 2022; Zaheer et al., 2020) or redesign the serving system (Sheng et al., 2023; Chen et al.,\\n2023b) and hardware (Wang et al., 2021).\\nIn contrast to prior work, we tackle the third axis and question the common assumption that LLMs\\nhave to do fully sequential decoding. We show the feasibility of parallel decoding of off-the-shelf\\nLLMs without any changes to their model, system, or hardware . For instance, for the question\\nin Fig. 1, we can reduce the latency from 22 seconds to 12 seconds (1.83 ×speed-up) with Claude,\\nand from 43 seconds to 16 seconds (2.69 ×speed-up) with Vicuna-33B V1.3 on an NVIDIA A100.\\nThe idea stems from reflecting on how humans ourselves answer questions. Humans do notalways\\nthink about questions and write answers in a sequential fashion. In contrast, for many question\\ntypes, we first derive the skeleton according to some protocols and strategies, and then add evidence\\nand details to refine and explicate each point. This is especially the case on formal occasions like\\noffering consultancy, taking tests, writing papers, and so on. Can we make LLMs think in the same\\nway? To this end, we propose Skeleton-of-Thought (SoT) . Specifically, as shown in Fig. 1, we guide\\nthe LLM to derive a skeleton first by itself. Based on the skeleton, the LLMs can complete each\\npoint in parallel so that we get a speed-up. SoT can be utilized to accelerate both open-source\\nmodels with batched decoding and API-based models with parallel API calls.\\nTo make the overall solution more practical, we also design an extension, SoT with router (SoT-R),\\nwhich employs a router to only trigger SoT for suitable questions.\\nWe test SoT on 12 recently released LLMs. Not only does SoT provide considerable speed-ups (up\\nto 2.39 ×), but it can also improve the answer quality in many cases (Fig. 1).\\nNote that in contrast to existing model- and system-level efforts for inference efficiency, SoT takes\\na novel “data-level” pathway by letting the LLM organize its output content. This novel perspective\\nis becoming feasible and is expected to grow in relevance, owing to the evolving capabilities of\\nstate-of-the-art LLMs. We hope this work can stimulate more research in the realm of data-centric\\noptimization (Zha et al., 2023; HazyResearch, 2023) for efficiency.\\n2', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 1}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nPrompt 1. Skeleton Prompt Template Ts\\n[User:] You’re an organizer responsible for only giving the skeleton (not the full content) for answering the question.\\nProvide the skeleton in a list of points (numbered 1., 2., 3., etc.) to answer the question. Instead of writing a full sentence,\\neach skeleton point should be very short with only 3 ∼5 words. Generally, the skeleton should have 3 ∼10 points. Now,\\nplease provide the skeleton for the following question.\\n{question }\\nSkeleton:\\n[Assistant:] 1.\\nPrompt 2. Point-Expanding Prompt Template Tpe\\n[User:] You’re responsible for continuing the writing of one and only one point in the overall answer to the following\\nquestion.\\n{question }\\nThe skeleton of the answer is\\n{skeleton }\\nContinue and only continue the writing of point {point index }. Write it **very shortly** in 1 ∼2 sentence and\\ndo not continue with other points!\\n[Assistant:] {point index }.{point skeleton }\\nThe rest of the paper is organized as follows. We first introduce SoT in § 2 and show its results in\\n§ 3. Then, we expand on the SoT-R extension in § 4. § 5 positions SoT in the research ecosystem\\n(expanded in App. D). Finally, we analyze the limitations and share outlooks of SoT in § 6.\\n2 S KELETON -OF-THOUGHT (SOT)\\n2.1 M ETHOD\\nOverview. Based on the intuition that humans usually think about and answer a question in an\\norganized way, the core idea of this work is to guide the LLM itself to give a skeleton first and then\\nwrite the overall answer parallelly instead of sequentially. Fig. 1 illustrates how SoT produces the\\nfinal answer to a user question q.\\n(1) Skeleton stage. SoT first assembles a skeleton request ,Ts(question =q), using the skeleton\\nprompt template Ts(Prompt 1, and Prompt 3 in App. B.1) with the question qas the parameter. The\\nskeleton prompt template is written to guide the LLM to output a concise skeleton of the answer.\\nThen, we extract the Bpoints from the skeleton response Rsof the LLM.\\n(2) Point-expanding stage. Based on the skeleton, we let the LLM expand on each point in parallel.\\nSpecifically, for the point with index band skeleton Rs\\nb, SoT uses Tpe(question =q,skeleton =\\nRs,point index =b,point skeleton =Rs\\nb)as the point-expanding request for the LLM, where\\nTpeis the point-expanding prompt template (Prompt 2). Finally, after completing all points, we\\nconcatenate the point-expanding responses {Rpe\\nb}b=1,···,Bto get the final answer .\\nParallel point expanding. We conduct parallel point-expanding so that SoT is able to achieve a\\nspeed-up than normal decoding.\\n(1) For proprietary models with only API access , we can issue multiple parallel API calls to get an\\nend-to-end latency gain at the cost of an increased number of API requests and tokens.\\n(2) For open-source models that we can run locally , we let them process the point-expanding re-\\nquests as a batch (paddings are added to the left of the point-expanding requests). We explain below\\nwhy this could achieve speed-ups. A typical LLM generative process consists of two phases: (a)\\ntheprefilling phase in which the prompt is parsed to generate the key-value cache for further use,\\nand (b) the decoding phase in which tokens are generated one by one in a sequential manner. The\\ndecoding phase accounts for the majority of the end-to-end latency, especially when generating a\\nlong response. Note that the decoding phase is bottlenecked by weight loading instead of activation\\n3', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 2}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nloading or computation.1Consequently, running LLM inference with increased batch sizes does not\\nincrease the per-token latency much. Therefore, SoT allows us to decode roughly B×more tokens\\nwithin the same amount of time if we parallelly decode Bpoints. See App. E for the expanded\\ndiscussions and the supporting experiments.\\nPlease refer to App. B for more implementation details of SoT.\\n3 S OT E VALUATION\\nDatasets. We evaluate SoT on two recent assistant-style datasets: (1) Vicuna-80 (Chiang et al.,\\n2023), which contains 80 questions spanning nine categories, such as coding ,math ,writing ,role-\\nplay, and so on, and (2) WizardLM (Xu et al., 2023), which contains 218 questions spanning more\\ncategories and diverse difficulties. Due to space constraints, we only report Vicuna-80 results in the\\nmain paper, and defer WizardLM results to the Apps. G and I.\\nModels. We test SoT on 12 recently released models, including 9 open-source models and 3 API-\\nbased models (Table 1). We obtain the weights of all the open-source models from Hugging Face.\\nSee App. A for more details.\\n3.1 E VALUATION OF EFFICIENCY\\nAPI-based models. We record the latency of every API call with\\nstart = time.time(); ...; elapsed_time = time.time() - start , and\\nadd the latency of the skeleton API call and the slowest point-expanding API call as the SoT latency.\\nOpen-source models. All open-source models we currently evaluate are based on the LLaMA 7B,\\n13B, or 33B architectures. Thus, to enable fast analysis, we first make a latency profiling table for\\neach LLaMA architecture on NVIDIA A100. The table contains the architecture’s (1) latency for\\nprefilling sequences of length 1 to 700 with different batch sizes (from 1 to 16), and (2) decoding\\none token with a context of length 1 to 1024 with different batch sizes (from 1 to 16). With these\\nthree latency profiling tables, given the number of points B, the token lengths of the requests and\\nresponses in the skeleton and point-expanding stages, we can quickly estimate the SoT latency\\nby simply looking up entries in the tables and adding them up. See App. F for a more detailed\\ndescription of how we conduct the profiling and estimate the latency.\\nIn addition to the above approach, we also compare the actual latency of SoT and normal sequential\\ngeneration (abbreviated as “normal” in the following discussion) in App. G.1.4.\\nThe rest of this section shows the speed-ups of SoT on different models (§ 3.1.1) and question\\ncategories (§ 3.1.2). In addition, we also report the latency breakdown of SoT stages in App. G.1.2\\nand the SoT speed-ups on an RTX 3090 GPU in App. G.1.3.\\n3.1.1 S PEED -UPBREAKDOWN : M ODELS\\nWe investigate how SoT reduces the end-to-end latency on different models. Fig. 2a shows the\\naverage speed-up for each model across all question categories. We can see that SoT obtains a >2×\\nspeed-up (up to 2.39 ×) on 8 out of 12 models.\\nWe report the detailed statistics about token lengths and numbers of points in Fig. 11. (1) In terms\\nofthe point number B(Fig. 11a), LLaMA2, Vicuna-7B V1.1, Vicuna-7B V1.3, and ChatGPT-3.5\\nyield relatively fewer points ( <6), while GPT-4 and StableVicuna-13B generates the largest number\\nof points on average ( ≈9). (2) Regarding the point-expanding response length , Figs. 11b to 11d\\nshow that the API-based models, ChatGPT-3.5, Claude, and GPT-4, follow the point-expanding\\nrequest better and generate shorter point-expanding responses than the open-source models. One\\ncan also notice that StableVicuna-13B’s longest point-expanding responses for many question cat-\\negories can be as lengthy as the overall normal answer, since it fails to adhere to the “Write it\\n**very shortly**” instruction in the point-expanding request. Consequently, SoT cannot accelerate\\nStableVicuna-13B well. (3) Regarding the length balance degree between point responses , Fig. 11e\\nshows that LLaMA2 and the API-based models generate more balanced point-expanding responses.\\n1This is true when the number of concurrent queries is small; see § 6 for discussion on other scenarios.\\n4', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 3}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n(4) As for the overall length of the final aggregated answer (Fig. 11f), employing SoT on most\\nmodels results in answers that are, on average, 1 ∼2×longer than the normal answer.\\n1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8StableVicuna-13BClaudeVicuna-13B V1.3ChatGPT-3.5GPT-4Vicuna-7B V1.3UltraLM-13BVicuna-33B V1.3OpenChat-13BVicuna-7B V1.1LLaMA2-Chat-13BLLaMA2-Chat-7B\\n1.13×1.31×1.91×1.97×2.00×2.01×2.18×2.24×2.28×2.30×2.38×2.39×\\n(a) Different models.\\n1.01.21.41.61.82.02.22.42.62.8mathfermicounterfactualroleplaycodingcommon-sensewritinggenericknowledge\\n1.34×1.69×1.89×1.95×2.06×2.24×2.26×2.31×2.33× (b) Different categories.\\nFigure 2: Average speed-ups of SoT on different models and question categories.\\n3.1.2 S PEED -UPBREAKDOWN : QUESTION CATEGORIES\\nHere we investigate how SoT reduces the end-to-end latency for different question categories.\\nFig. 2b shows the average speed-up for each question category across all models. The question\\ncategories for which SoT can provide high-quality answers are marked in green, and other cate-\\ngories are marked in red (see § 3.2.3 for the answer quality evaluation). We can see that SoT can\\nobtain speed-ups for all question categories. For the five question categories that SoT can provide\\nhigh-quality answers (i.e., knowledge ,generic ,common-sense ,roleplay ,counterfactual ), SoT can\\nspeed up the overall answer generation process by 1.89 ×to 2.33 ×in the meantime.\\n3.2 E VALUATION OF ANSWER QUALITY\\nIn order to compare the answer quality of the normal sequential generation (abbreviated as “normal”\\nin the following discussion) and SoT generation, we adopt two LLM-based evaluation frameworks:\\nFastChat (Zheng et al., 2023) and LLMZoo (Chen et al., 2023c). The evaluation process is to present\\na question and a pair of answers (from normal or SoT generation) to an LLM judge (GPT-4 in the\\nmain paper; see App. I.3 for the results evaluated using ChatGPT-3.5) and ask for its preference.\\nThe response can be that SoT’s answer wins/ties/loses compared to the normal answer.\\nHere are more details about the evaluation of the answer quality:\\n(1) Detailed metrics. FastChat evaluation provides one metric for the general quality of the answers.\\nIn addition to a general metric, LLMZoo provides five detailed metrics on the answers’ coherence,\\ndiversity, immersion, integrity, and relevance.\\n(2) Question categories. FastChat provides two special evaluation prompts for coding and math\\nquestions for more accurate evaluation, whereas LLMZoo does not. Following the implementation\\nin LLMZoo, we exclude math and coding questions in all LLMZoo evaluation results.\\n(3) Extentions to avoid evaluation bias. To avoid the potential bias from the order of the two answers\\npresented to the LLM judge, we extend FastChat and LLMZoo evaluation frameworks by running\\nthe evaluation twice with either ordering of the two answers. In either evaluation, a score of 1,\\n0, and -1 is assigned when SoT wins, ties, or loses, respectively. The final evaluation is that SoT\\nwins/ties/loses when the sum of the two scores is positive/zero/negative. For example, if SoT wins\\nin one evaluation and loses in the other evaluation, the result is “tie”. If SoT wins (loses) in one\\nevaluation and ties in the other, the result is “win” (“lose”).\\n(4) Net win rates. We further define net win rates to give a summarized view of the answer quality.\\nGiven the number of questions that SoT wins (#win) and loses (#lose), we define net win rates\\nas#win−#lose/total number of questions . 0% means that SoT performs competitively to the normal baseline\\n(wins and loses in the same number of questions). Higher values mean that SoT performs better.\\nThe organization of this section on answer quality evaluation is as follows. We first present the over-\\nall quality of SoT answers (§ 3.2.1), and then go into the details across different question categories\\n(§ 3.2.3), models (§ 3.2.2), and metrics (§ 3.2.4).\\n5', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 4}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n3.2.1 O VERALL QUALITY\\nIn Fig. 3, we show the win/tie/lose rates (the percentage of the cases when SoT wins/ties/loses\\ncompared to normal generation) across all models and questions using the two metrics from FastChat\\nand LLMZoo that capture the general quality of the answers. We notice a discrepancy between the\\ntwo metrics on when SoT is strictly better than the baseline (45.8% v.s. 29.5%). Despite that, the\\ntwo metrics agree that SoT is not worse than the baseline in around 60% of the cases, and the win\\nrates are close to the lose rates. This result suggests that the answers of SoT maintain good quality\\nof that of the normal generation.\\n0% 20% 40% 60% 80% 100%General quality (LLMZoo)General quality (FastChat)\\n45.8%29.5%\\n19.6%29.3%\\n34.5%41.2%Win Tie Lose\\nFigure 3: Win/tie/lose rates of SoT v.s. normal generation using “general” metrics from FastChat\\nand LLMZoo. SoT performs better than or equal to normal generation in around 60% cases.\\n3.2.2 Q UALITY BREAKDOWN : M ODELS\\nNext, we investigate how SoT performs on different models. We compute net win rates on all\\nmodels in Fig. 4. Again, we see that the two general metrics from FastChat and LLMZoo have\\ndifferent absolute values but similar rankings. In particular, both metrics agree that OpenChat-13B,\\nVicuna-7B V1.1, Claude, LLaMA2-Chat-13B have lownet win rates, whereas Vicuna-13B V1.3,\\nStableVicuna-13B, and UltraLM-13B have high net win rates.\\n-60% -40% -20% 0% 20%StableVicuna-13BUltraLM-13BVicuna-13B V1.3GPT-4LLaMA2-Chat-7BVicuna-33B V1.3Vicuna-7B V1.3ChatGPT-3.5LLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.1Claude\\n(a) Metric: general quality (FastChat).\\n-40% -20% 0% 20% 40% 60%StableVicuna-13BUltraLM-13BVicuna-13B V1.3GPT-4LLaMA2-Chat-7BVicuna-33B V1.3Vicuna-7B V1.3ChatGPT-3.5LLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.1Claude (b) Metric: general quality (LLMZoo).\\nFigure 4: Net win rates of SoT on different models.\\nWe investigate the answers in App. I.1.1, and summarize the key takeaways as follows. Some\\nmodels have low SoT quality as they cannot understand the skeleton and point-expanding prompts\\nwell. Some other models have low SoT quality as their normal answers already have good quality,\\nmaking it hard for SoT to beat them (e.g., Claude). For models that are able to understand the\\nSoT prompts, the answer quality is improved. We expect that further improving SoT prompts or\\nfine-tuning the models can make it easier for LLMs to understand the skeleton and point-expanding\\nprompts and ultimately result in better answer quality.\\n3.2.3 Q UALITY BREAKDOWN : QUESTION CATEGORIES\\nNext, we investigate how SoT performs on different question categories. We compute net win rates\\n(win rates minus lose rates) on all question categories in Fig. 5. Similar to Fig. 3, we see that\\nLLMZoo tends to be more optimistic about the quality of SoT than FastChat. Nevertheless, the\\nconclusions are consistent: SoT performs relatively well ongeneric ,common-sense ,knowledge ,\\nroleplay , and counterfactual . SoT performs relatively poorly onwriting ,fermi ,math , and coding .\\nWe investigate the answers in App. I.1.2, and summarize the key takeaways as follows. SoT per-\\nforms well when the question can be answered in several points whose details can be expanded\\nindependently. This includes a wide range of real-world questions. On the other hand, it is fun-\\ndamentally challenging to apply SoT on questions that require step-by-step thinking, in which the\\n6', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 5}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n-80% -60% -40% -20% 0% 20% 40%counterfactualgenericcommon-senseknowledgeroleplayfermiwritingmathcoding\\n(a) Metric: general quality (FastChat).\\n-20% 0% 20% 40% 60%counterfactualgenericcommon-senseknowledgeroleplayfermiwriting (b) Metric: general quality (LLMZoo).\\nFigure 5: Net win rates of SoT on different question categories.\\nlatter steps require the details from the earlier steps, such as math questions. To make SoT general\\nacross broader question categories, one promising pathway is to enable SoT to adaptively fall back\\nto normal generation, which we explore in § 4. Interestingly, our results suggest that some LLMs\\nare already able to do that occasionally without special prompting or tuning (see App. I.1.2).\\n3.2.4 Q UALITY BREAKDOWN : M ETRICS\\nAll previous evaluations use metrics about the general quality of the answer. In Fig. 6, we show\\nmore detailed metrics from LLMZoo to reveal in which aspects SoT can improve or hurt the answer\\nquality. On average, we can see that SoT improves the diversity and relevance while hurting the\\nimmersion and coherence.\\n0% 20% 40% 60% 80% 100%IntegrityCoherenceImmersionRelevanceDiversity\\n23.2%29.8%40.5%61.4%\\n99.9%34.6%30.6%23.7%11.3%\\n0.1%42.1%39.6%35.8%27.3%Win Tie Lose\\nFigure 6: Win/tie/lose rates of SoT v.s. normal generations using metrics from LLMZoo. SoT\\nperforms well on diversity and relevance, and relatively worse on coherence and immersion.\\nThrough answer investigation (App. I.1.3), we summarize the key takeaways as follows. The skele-\\nton stage of SoT explicitly require LLMs to discuss the answers from multiple aspects without filler\\nwords. This improves the diversity and relevance of the answers. As for coherence and immersion,\\nSoT is not worse than the normal generation around 60% of the time. One future direction is to\\nimprove the SoT prompts or pipeline so that the answers can be better in more metrics.\\n4 S OTWITH ROUTER (SOT-R): A DAPATIVELY TRIGGERING SOT\\nIn § 3, we see that SoT provides considerable speed-ups while maintaining (or even improving)\\nanswer quality for many question types. However, the biggest limitation is that SoT is not suitable\\nfor questions that require step-by-step reasoning (§ 3.2.3). Towards pushing the practical adoption\\nof SoT, we explore the possibility of adaptively triggering SoT only when it is suitable. To achieve\\nthat, we propose a router module that decides if SoT should be applied for the user request, and\\nthen call either SoT or normal decoding accordingly. This paradigm aligns with the recent trends\\nof composing multiple models to solve complicated tasks (Chase, 2022; Shen et al., 2023). To\\nimplement the router, we explore two options: LLM prompting as the router (no model training is\\nneeded) (§ 4.1), and trained RoBERTa as the router (§ 4.2). The evaluation is provided in § 4.3.\\n4.1 P ROMPTING ROUTER\\nWe directly ask an LLM if the question is suitable for SoT. More specifically, we ask the LLM if the\\ndesired answer is in a list of independent points (see App. C.1 for the prompt). If the answer is yes,\\n7', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 6}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nwe will use SoT; otherwise, we will use normal generation (i.e., directly feeding the question to the\\nLLM). We employ GPT-4 as the LLM router given its strong capability.\\n4.2 T RAINED ROUTER\\nWhile leveraging GPT-4 as the router obviates the need for model training, its performance remains\\nsensitive to prompt design. Therefore, we approach the problem as a sequence classification task by\\nfine-tuning a small language model as the router. Specifically, we annotate the LIMA dataset (Zhou\\net al., 2023) as the training set to train a RoBERTa model (Liu et al., 2019), which has only 120M\\nparameters. Comprehensive details regarding the annotation and training processes can be found in\\nApps. C.2.1 and C.2.2, respectively.\\n4.3 S OT-R E VALUATION\\nWe compare SoT and SoT-R under the same evaluation setup in § 3. Besides the prompting and\\ntrained routers, we also consider a “human router” where we manually judge whether SoT should\\nbe applied for each question. This serves as a benchmark for comparison.\\n4.3.1 E VALUATION OF EFFICIENCY\\nFig. 7 shows the speed-ups of SoT and SoT-R for different models on the Vicuna-80 dataset (see\\nApp. G.2 for more results on the WizardLM dataset). We can see that: (1) As expected, SoT-R\\nobtains lower speed-ups than SoT, since SoT is not triggered for some questions and the router\\ninduces a small latency overhead. Nevertheless, SoT-R can still benefit most models with >1×\\nspeed-ups. (2) SoT-R with the trained router obtains slightly higher speed-ups for 7 out of 12 models\\non Vicuna-80, while SoT-R with the prompting router obtains higher speed-ups for all models on\\nthe WizardLM dataset (see Fig. 17 in App. G.2).\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75StableVicuna-13BClaudeVicuna-13B V1.3ChatGPT-3.5GPT-4Vicuna-7B V1.3UltraLM-13BVicuna-33B V1.3OpenChat-13BVicuna-7B V1.1LLaMA2-Chat-13BLLaMA2-Chat-7B\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nFigure 7: Speed-ups of SoT and SoT-R on dif-\\nferent models across all question categories of\\nthe Vicuna-80 dataset.\\n-80% -60% -40% -20% 0% 20% 40%counterfactualgenericcommon-senseknowledgeroleplayfermiwritingmathcoding\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nSoT-R w/ human routerFigure 8: Net win rates of SoT and SoT-R on\\ndifferent question categories of the Vicuna-80\\ndataset (evaluated with the FastChat metrics).\\n4.3.2 E VALUATION OF ANSWER QUALITY\\nFig. 8 shows the net win rates (averaged across all models) of SoT and SoT-R on Vicuna-80 with the\\nFastChat metrics (see App. I.2 for results of the WizardLM dataset and LLMZoo metrics). We can\\nsee that: (1) SoT-R significantly improves the answer quality on questions where SoT is not suitable\\n(e.g., coding ,math ,writing ,fermi ) by falling back to normal decoding. At the same time, SoT-R\\nmaintains answer quality improvements on questions where SoT is good at. (2) The trained router\\nperforms similar to (on Vicuna-80) or better than (on WizardLM; see App. I.2) the prompting router.\\nThis accords with our intuition in § 4.2. (3) The prompting and trained routers could even surpass\\nhuman router (e.g., on roleplay questions; see more examples on WizardLM in App. I.2).\\nWe discuss the consistency across three routers in App. C.3. The primary takeaways include: (1)\\non Vicuna-80, there is a notable consistency among all three routers, and (2) on WizardLM, greater\\ndiscrepancies emerge, with the trained router showing higher alignment with human annotations.\\n5 R ELATED WORK\\nThis section positions SoT in related work to reveal how SoT (1) is connected to, (2) is different\\nfrom, and (3) can harness the power of other methods. See App. D for the expanded discussion.\\nEfficient LLM methods at model and system levels. At the model level, prior work proposes ef-\\nficient architectures, including dynamic mixture-of-experts (Lepikhin et al., 2021), low-complexity\\n8', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 7}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nattention (Kitaev et al., 2020), and multi-query attention (Shazeer, 2019). However, they usually\\nrequire a significant re-training cost. In contrast, compression methods require a smaller amount\\nof fine-tuning cost by reducing the complexity of pre-trained LLMs, such as quantization (Frantar\\net al., 2022) and weight or activation sparsification (Mishra et al., 2021; Zaheer et al., 2020).\\nAt the system level, prior work (1) optimizes the computational graph (Dao et al., 2022), (2) op-\\ntimizes the assignment and scheduling of computational graph on devices (Sheng et al., 2023), or\\n(3) designs batching or caching mechanisms for serving multiple users (Fang et al., 2021). These\\ntechniques address the large memory access and footprint posed by the vast model scale and atten-\\ntion mechanism, and mainly aim at enhancing the throughput rather than the end-to-end latency.\\nAs SoT trades off throughput for end-to-end latency, SoT can make these throughput-oriented tech-\\nniques help with end-to-end latency . This interesting synergy offers opportunities for achieving\\nbetter trade-offs between latency and throughput in future serving systems.\\nIn contrast to model- and system-level techniques, SoT is a data-level technique in a new “content\\nco-organization for efficiency” paradigm . See § 6 for more discussions.\\nEfficient LLM methods through parallel generation. Some prior work also addresses the sequen-\\ntial decoding issues. Speculative decoding (SD) methods (Stern et al., 2018) employ smaller models\\nto generate some consecutive tokens sequentially and apply the target LLMs to verify them paral-\\nlelly. Non-autoregressive generation (NAG) methods (Gu et al., 2018; Xiao et al., 2023) sample and\\nrefine consecutive tokens parallelly, often with the support of a modified and tuned model.\\nRelying on either assisting models or special models and sampling schemes, SD and NAG methods\\nconduct parallel verification or sampling and refinement of consecutive tokens . In contrast, SoT\\nprompts the LLM itself to plan the contents in a way that permits the parallel generation of tokens in\\ndifferent segments , by exploiting the emerging instruction-following and planning ability of LLMs.\\nPrompting methods for LLMs. Recent years have witnessed the emergence of the “pre-train,\\nprompt, and predict” paradigm, which has shown promise in enhancing LLMs’ quality in math and\\ncommonsense reasoning (Wei et al., 2022; Kojima et al., 2022; Wang et al., 2022; Chen et al., 2022)\\nand planning for multi-modality tasks (Shen et al., 2023; Zhu et al., 2023). Instead of focusing on\\nanswer quality, SoT is a first attempt at exploiting the power of prompting to improve efficiency .\\n6 L IMITATIONS , FUTURE WORK,AND OPEN QUESTIONS\\nAnswer quality evaluation. Our answer quality evaluation is far from perfect due to the limited\\nprompt set, the potential bias of GPT-4 judges, and the inherent difficulty of evaluating LLM gener-\\nations. Currently, we did not conduct human evaluation since it is easy for a human to tell whether\\nan answer is generated with SoT due to its distinctive pattern, which might cause evaluation bias.\\nWe leave a more thorough evaluation of answer quality to future work.\\nEliciting or improving LLMs’ ability. § 3.2.4 demonstrates SoT’s potential of enhancing answer\\nquality. It is part of a broader trend in recent research, exemplified by work including CoT (Kojima\\net al., 2022; Wei et al., 2022), ToT (Yao et al., 2023), and ReAct (Yao et al., 2022), which collectively\\naffirm the notion that explicitly articulating the thought process in language can elicit high-quality\\nanswers from LLMs . These findings resemble human thinking: rather than relying solely on the\\nfirst intuition or purely sequential thinking, we often document step-by-step reasoning or thought\\norganization to attain high-quality answers. This intriguing parallel prompts us to explore further\\nhow we can draw from the human thinking process to facilitate more effective and efficient AI.\\nFor instance, SoT currently ignores the dependencies between points. A conceptually better way is\\nto organize the points as Graph-of-Thoughts , where the edges represent the dependencies, and each\\npoint is decoded conditioned on the contents of its ancestor points. In addition, instead of complying\\nwith a static graph, we expect the need of having dynamic Graph-of-Thoughts , where the high-level\\nthought structure is adjusted dynamically by LLMs themselves. This could potentially combine the\\nefficiency and global thinking advantages of SoT with the logical reasoning and impromptu thinking\\nstrengths of methods like CoT (Kojima et al., 2022; Wei et al., 2022). Notably, a contemporary\\nwork (Besta et al., 2023) has attempted to design Graph-of-Thoughts to elicit reasoning.\\nFurthermore, there exist self-improving training pipelines (Zelikman et al., 2022; Huang et al., 2022)\\nthat use rationales generated by CoT to fine-tune LLMs, thereby enhancing their reasoning abilities.\\n9', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 8}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nLikewise, it is interesting to investigate how the more structured answers from SoT can be used to\\nfine-tune LLMs to enhance their ability to generate well-organized and comprehensive answers.\\nEfficiency and overhead of SoT in different scenarios. Serving systems commonly adopt batch\\nprocessing to handle concurrent queries. This raises a concern of whether SoT may hurt serving\\nthroughput due to parallel requests. (1) When there is an unsaturated number of concurrent queries,\\nSoT can effectively reduce latency and enhance GPU utilization. Example scenarios include (a)\\nEdge-side applications with a single user; (b) Centralized services during periods with unsaturated\\nuser requests and underutilized computing capacity. It is interesting to study the appropriate SoT\\ntriggering conditions based on system workloads. (2) When there is a saturated number of concur-\\nrent queries, SoT is still useful for improving answer quality. However, in this case, it is important\\nto consider the computation overhead from SoT. We delve into this concern in App. H.\\nFor API-based models, a notable concern arises regarding the increased number of prefilling tokens\\n(App. H). Given that many APIs charge token usage, SoT may lead to higher costs. To address this,\\none can tune the number of parallel API requests (by expanding multiple points in a single API call),\\nor use prompt tuning to design shorter SoT prompts (see App. H).\\nData-centric efficiency optimization. While data-centric engineering for improving answer qual-\\nity(Zha et al., 2023; HazyResearch, 2023) is gaining popularity, its potential for inference efficiency\\nis not explored yet. SoT is the first attempt. As LLM capabilities and the amount of LLM-generated\\ndata are growing rapidly, data-centric techniques could become more useful in the future. We look\\nforward to more explorations to unlock the full potential of data-centric efficiency optimization.\\nACKNOWLEDGEMENTS\\nWe thank Sergey Yekhanin (Microsoft Research), and Tianji Wu (Infinigence AI) for their support\\nand suggestions on the work. We thank Tianyu Fu for many initial discussions on the idea. We\\nthank Ke Hong and Genghan Zhang for their discussions about profiling. We thank Yue Wu for the\\nhelp on the Claude scripts. We thank Da Yu, Chulin Xie, and Saiqian Zhang for their suggestions\\non revising the first version of the paper. We thank Rui Hu, Cheng Cheng, Jack Jin, Zhoutong Ye,\\nMingze Sun, Jun Yan, Zhi Zhang, Yuxuan Tong, and Nianhui Guo for their suggestions on revising\\nthe second version of the paper.\\nREFERENCES\\nAnthropic. Introducing claude, May 2023. URL https://www.anthropic.com/index/\\nintroducing-claude .\\nMaciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna\\nGajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, et al.\\nGraph of thoughts: Solving elaborate problems with large language models. arXiv preprint\\narXiv:2308.09687 , 2023.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\\nfew-shot learners. Advances in neural information processing systems , 33:1877–1901, 2020.\\nHan Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang, and Song Han. Once-for-all: Train one\\nnetwork and specialize it for efficient deployment. arXiv preprint arXiv:1908.09791 , 2019.\\nHarrison Chase. LangChain, October 2022. URL https://github.com/hwchase17/\\nlangchain .\\nCharlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste Lespiau, Laurent Sifre, and John\\nJumper. Accelerating large language model decoding with speculative sampling. arXiv preprint\\narXiv:2302.01318 , 2023a.\\nWenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. Program of thoughts prompt-\\ning: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint\\narXiv:2211.12588 , 2022.\\n10', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 9}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nZhaodong Chen, Zheng Qu, Yuying Quan, Liu Liu, Yufei Ding, and Yuan Xie. Dynamic n: M\\nfine-grained structured sparse attention mechanism. In Proceedings of the 28th ACM SIGPLAN\\nAnnual Symposium on Principles and Practice of Parallel Programming , pp. 369–379, 2023b.\\nZhihong Chen, Junying Chen, Hongbo Zhang, Feng Jiang, Guiming Chen, Fei Yu, Tiannan Wang,\\nJuhao Liang, Chen Zhang, Zhiyi Zhang, Jianquan Li, Xiang Wan, Haizhou Li, and Benyou Wang.\\nLlm zoo: democratizing chatgpt. https://github.com/FreedomIntelligence/\\nLLMZoo , 2023c.\\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,\\nSiyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An\\nopen-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https:\\n//lmsys.org/blog/2023-03-30-vicuna/ .\\nHyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\\nWang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language mod-\\nels.arXiv preprint arXiv:2210.11416 , 2022.\\nTri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher R ´e. Flashattention: Fast and memory-\\nefficient exact attention with io-awareness. Advances in Neural Information Processing Systems ,\\n35:16344–16359, 2022.\\nEmily L Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Exploiting linear\\nstructure within convolutional networks for efficient evaluation. Advances in neural information\\nprocessing systems , 27, 2014.\\nNing Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong\\nSun, and Bowen Zhou. Enhancing chat language models by scaling high-quality instructional\\nconversations. arXiv preprint arXiv:2305.14233 , 2023.\\nZhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. Glm:\\nGeneral language model pretraining with autoregressive blank infilling. In Proceedings of the\\n60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) ,\\npp. 320–335, 2022.\\nThomas Elsken, Jan Hendrik Metzen, and Frank Hutter. Neural architecture search: A survey. The\\nJournal of Machine Learning Research , 20(1):1997–2017, 2019.\\nJiarui Fang, Yang Yu, Chengduo Zhao, and Jie Zhou. Turbotransformers: an efficient gpu serv-\\ning system for transformer models. In Proceedings of the 26th ACM SIGPLAN Symposium on\\nPrinciples and Practice of Parallel Programming , pp. 389–402, 2021.\\nWilliam Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: Scaling to trillion parameter\\nmodels with simple and efficient sparsity. The Journal of Machine Learning Research , 23(1):\\n5232–5270, 2022.\\nElias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. Gptq: Accurate post-training\\nquantization for generative pre-trained transformers. arXiv preprint arXiv:2210.17323 , 2022.\\nPrakhar Ganesh, Yao Chen, Xin Lou, Mohammad Ali Khan, Yin Yang, Hassan Sajjad, Preslav\\nNakov, Deming Chen, and Marianne Winslett. Compressing large-scale transformer-based mod-\\nels: A case study on bert. Transactions of the Association for Computational Linguistics , 9:\\n1061–1080, 2021.\\nJoao Gante. Assisted generation: a new direction toward low-latency text generation. https:\\n//huggingface.co/blog/assisted-generation , 2023. Accessed: 2023-06-23.\\nGoogle. Tensorflow serving, 2021. URL https://github.com/tensorflow/serving .\\nJiatao Gu, James Bradbury, Caiming Xiong, Victor O.K. Li, and Richard Socher. Non-autoregressive\\nneural machine translation. In International Conference on Learning Representations , 2018. URL\\nhttps://openreview.net/forum?id=B1l8BtlCb .\\n11', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 10}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nSong Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks\\nwith pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149 , 2015.\\nHazyResearch. Data-centric ai. https://github.com/HazyResearch/\\ndata-centric-ai , 2023. Accessed: 2023-07-04.\\nJiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei\\nHan. Large language models can self-improve. arXiv preprint arXiv:2210.11610 , 2022.\\nYanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Dehao Chen, Mia Chen, HyoukJoong\\nLee, Jiquan Ngiam, Quoc V Le, Yonghui Wu, et al. Gpipe: Efficient training of giant neural\\nnetworks using pipeline parallelism. Advances in neural information processing systems , 32,\\n2019.\\nAndrei Ivanov, Nikoli Dryden, Tal Ben-Nun, Shigang Li, and Torsten Hoefler. Data movement is\\nall you need: A case study on optimizing transformers. Proceedings of Machine Learning and\\nSystems , 3:711–732, 2021.\\nNikita Kitaev, Łukasz Kaiser, and Anselm Levskaya. Reformer: The efficient transformer. arXiv\\npreprint arXiv:2001.04451 , 2020.\\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\\nlanguage models are zero-shot reasoners. Advances in neural information processing systems ,\\n35:22199–22213, 2022.\\nRaghuraman Krishnamoorthi. Quantizing deep convolutional networks for efficient inference: A\\nwhitepaper. arXiv preprint arXiv:1806.08342 , 2018.\\nAlex Krizhevsky. One weird trick for parallelizing convolutional neural networks. arXiv preprint\\narXiv:1404.5997 , 2014.\\nWoosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E\\nGonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model\\nserving with pagedattention. arXiv preprint arXiv:2309.06180 , 2023.\\nDmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang,\\nMaxim Krikun, Noam Shazeer, and Zhifeng Chen. {GS}hard: Scaling giant models with condi-\\ntional computation and automatic sharding. In International Conference on Learning Represen-\\ntations , 2021. URL https://openreview.net/forum?id=qrwe7XHTmYb .\\nBrian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt\\ntuning. arXiv preprint arXiv:2104.08691 , 2021.\\nYaniv Leviathan, Matan Kalman, and Yossi Matias. Fast inference from transformers via speculative\\ndecoding. arXiv preprint arXiv:2211.17192 , 2022.\\nGuohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\\nCamel: Communicative agents for ”mind” exploration of large scale language model society,\\n2023a.\\nXiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv\\npreprint arXiv:2101.00190 , 2021.\\nXuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy\\nLiang, and Tatsunori B. Hashimoto. Alpacaeval: An automatic evaluator of instruction-following\\nmodels. https://github.com/tatsu-lab/alpaca_eval , 2023b.\\nYifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and Weizhu Chen. Making\\nlanguage models better reasoners with step-aware verifier. In Proceedings of the 61st Annual\\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 5315–\\n5333, 2023c.\\nZhuohan Li, Siyuan Zhuang, Shiyuan Guo, Danyang Zhuo, Hao Zhang, Dawn Song, and Ion Stoica.\\nTerapipe: Token-level pipeline parallelism for training large-scale language models. In Interna-\\ntional Conference on Machine Learning , pp. 6543–6552. PMLR, 2021.\\n12', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 11}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nJi Lin, Jiaming Tang, Haotian Tang, Shang Yang, Xingyu Dang, and Song Han. Awq:\\nActivation-aware weight quantization for llm compression and acceleration. arXiv preprint\\narXiv:2306.00978 , 2023.\\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-\\ntrain, prompt, and predict: A systematic survey of prompting methods in natural language pro-\\ncessing. ACM Computing Surveys , 55(9):1–35, 2023.\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike\\nLewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining\\napproach, 2019.\\nIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International Confer-\\nence on Learning Representations , 2019.\\nWenyan Lu, Guihai Yan, Jiajun Li, Shijun Gong, Yinhe Han, and Xiaowei Li. Flexflow: A flexible\\ndataflow accelerator architecture for convolutional neural networks. In 2017 IEEE International\\nSymposium on High Performance Computer Architecture (HPCA) , pp. 553–564. IEEE, 2017.\\nXupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Zeyu Wang, Rae Ying Yee Wong,\\nZhuoming Chen, Daiyaan Arfeen, Reyna Abhyankar, and Zhihao Jia. Specinfer: Accelerating\\ngenerative llm serving with speculative inference and token tree verification. arXiv preprint\\narXiv:2305.09781 , 2023.\\nAsit Mishra, Jorge Albericio Latorre, Jeff Pool, Darko Stosic, Dusan Stosic, Ganesh Venkatesh,\\nChong Yu, and Paulius Micikevicius. Accelerating sparse deep neural networks. arXiv preprint\\narXiv:2104.08378 , 2021.\\nDeepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek Seshadri, Nikhil R Devanur, Gre-\\ngory R Ganger, Phillip B Gibbons, and Matei Zaharia. Pipedream: Generalized pipeline par-\\nallelism for dnn training. In Proceedings of the 27th ACM Symposium on Operating Systems\\nPrinciples , pp. 1–15, 2019.\\nDeepak Narayanan, Amar Phanishayee, Kaiyu Shi, Xie Chen, and Matei Zaharia. Memory-efficient\\npipeline-parallel dnn training. In International Conference on Machine Learning , pp. 7937–7947.\\nPMLR, 2021.\\nNVIDIA. Fastertransformer, 2019. URL https://github.com/NVIDIA/\\nFasterTransformer .\\nNVIDIA. Triton inference server, 2021. URL https://developer.nvidia.com/\\ntriton-inference-server .\\nOpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 , 2023.\\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow\\ninstructions with human feedback. Advances in Neural Information Processing Systems , 35:\\n27730–27744, 2022.\\nDuy Phung. Stablevicuna-13b, May 2023. URL https://huggingface.co/CarperAI/\\nstable-vicuna-13b-delta .\\nOfir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis. Measuring\\nand narrowing the compositionality gap in language models. arXiv preprint arXiv:2210.03350 ,\\n2022.\\nSamyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. Zero: Memory optimizations\\ntoward training trillion parameter models. In SC20: International Conference for High Perfor-\\nmance Computing, Networking, Storage and Analysis , pp. 1–16. IEEE, 2020.\\nJie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Min-\\njia Zhang, Dong Li, and Yuxiong He. {ZeRO-Offload }: Democratizing {Billion-Scale }model\\ntraining. In 2021 USENIX Annual Technical Conference (USENIX ATC 21) , pp. 551–564, 2021.\\n13', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 12}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nAndrea Santilli, Silvio Severino, Emilian Postolache, Valentino Maiorca, Michele Mancusi, Ric-\\ncardo Marin, and Emanuele Rodol `a. Accelerating transformer inference for translation via paral-\\nlel decoding. In acl, 2023.\\nTimo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\\nNicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\\nuse tools. arXiv preprint arXiv:2302.04761 , 2023.\\nSenseTime. Lightllm. https://github.com/ModelTC/lightllm , 2023a. Accessed:\\n2023-09-26.\\nSenseTime. Openppl. https://github.com/openppl-public/ppl.nn , 2023b. Ac-\\ncessed: 2023-09-26.\\nNoam Shazeer. Fast transformer decoding: One write-head is all you need. arXiv preprint\\narXiv:1911.02150 , 2019.\\nYongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang.\\nHugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint\\narXiv:2303.17580 , 2023.\\nYing Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Daniel Y Fu, Zhiqiang\\nXie, Beidi Chen, Clark Barrett, Joseph E Gonzalez, et al. High-throughput generative inference\\nof large language models with a single gpu. arXiv preprint arXiv:2303.06865 , 2023.\\nTaylor Shin, Yasaman Razeghi, Robert L Logan IV , Eric Wallace, and Sameer Singh. Autoprompt:\\nEliciting knowledge from language models with automatically generated prompts. In Proceedings\\nof the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pp.\\n4222–4235, 2020.\\nMitchell Stern, Noam Shazeer, and Jakob Uszkoreit. Blockwise parallel decoding for deep autore-\\ngressive models. Advances in Neural Information Processing Systems , 31, 2018.\\nZiteng Sun, Ananda Theertha Suresh, Jae Hun Ro, Ahmad Beirami, Himanshu Jain, Felix Yu,\\nMichael Riley, and Sanjiv Kumar. Spectr: Fast speculative decoding via optimal transport.\\nInWorkshop on Efficient Systems for Foundation Models @ ICML2023 , 2023. URL https:\\n//openreview.net/forum?id=d0mGsaheuT .\\nChristian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethink-\\ning the inception architecture for computer vision. In Proceedings of the IEEE conference on\\ncomputer vision and pattern recognition , pp. 2818–2826, 2016.\\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy\\nLiang, and Tatsunori Hashimoto. Alpaca: A strong, replicable instruction-following model.\\nhttps://crfm.stanford.edu/2023/03/13/alpaca.html , 2023. Accessed: 2023-\\n06-23.\\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth ´ee\\nLacroix, Baptiste Rozi `ere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and\\nefficient foundation language models. arXiv preprint arXiv:2302.13971 , 2023a.\\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-\\nlay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher,\\nCristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy\\nFu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn,\\nSaghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel\\nKloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee,\\nDiana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,\\nIgor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi,\\nAlan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh\\nTang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen\\nZhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic,\\nSergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models,\\n2023b.\\n14', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 13}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nGuan Wang, Sijie Cheng, Qiying Yu, and Changling Liu. Openllms: Less is more for open-source\\nmodels, July 2023a. URL https://github.com/imoneoi/openchat .\\nHanrui Wang, Zhekai Zhang, and Song Han. Spatten: Efficient sparse attention architecture with\\ncascade token and head pruning. In 2021 IEEE International Symposium on High-Performance\\nComputer Architecture (HPCA) , pp. 97–110. IEEE, 2021.\\nSinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, and Hao Ma. Linformer: Self-attention\\nwith linear complexity. arXiv preprint arXiv:2006.04768 , 2020.\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\\nery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models.\\narXiv preprint arXiv:2203.11171 , 2022.\\nZifu Wang, Teodora Popordanoska, Jeroen Bertels, Robin Lemmens, and Matthew B Blaschko. Dice\\nsemimetric losses: Optimizing the dice score with soft labels. In Medical Image Computing and\\nComputer Assisted Intervention , 2023b.\\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\\nAndrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint\\narXiv:2109.01652 , 2021.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\\nZhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in\\nNeural Information Processing Systems , 35:24824–24837, 2022.\\nWei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in\\ndeep neural networks. Advances in neural information processing systems , 29, 2016.\\nGuangxuan Xiao, Ji Lin, Mickael Seznec, Julien Demouth, and Song Han. Smoothquant:\\nAccurate and efficient post-training quantization for large language models. arXiv preprint\\narXiv:2211.10438 , 2022.\\nYisheng Xiao, Lijun Wu, Junliang Guo, Juntao Li, Min Zhang, Tao Qin, and Tie-yan Liu. A survey\\non non-autoregressive generation for neural machine translation and beyond. IEEE Transactions\\non Pattern Analysis and Machine Intelligence , 2023.\\nCan Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and\\nDaxin Jiang. Wizardlm: Empowering large language models to follow complex instructions.\\narXiv preprint arXiv:2304.12244 , 2023.\\nYuanzhong Xu, HyoukJoong Lee, Dehao Chen, Blake Hechtman, Yanping Huang, Rahul Joshi,\\nMaxim Krikun, Dmitry Lepikhin, Andy Ly, Marcello Maggioni, et al. Gspmd: general and\\nscalable parallelization for ml computation graphs. arXiv preprint arXiv:2105.04663 , 2021.\\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\\nReact: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629 ,\\n2022.\\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik\\nNarasimhan. Tree of thoughts: Deliberate problem solving with large language models. arXiv\\npreprint arXiv:2305.10601 , 2023.\\nGyeong-In Yu, Joo Seong Jeong, Geon-Woo Kim, Soojeong Kim, and Byung-Gon Chun. Orca: A\\ndistributed serving system for {Transformer-Based }generative models. In 16th USENIX Sympo-\\nsium on Operating Systems Design and Implementation (OSDI 22) , pp. 521–538, 2022.\\nManzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago\\nOntanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et al. Big bird: Transformers for\\nlonger sequences. Advances in neural information processing systems , 33:17283–17297, 2020.\\nEric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman. Star: Bootstrapping reasoning with\\nreasoning. Advances in Neural Information Processing Systems , 35:15476–15488, 2022.\\n15', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 14}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nDaochen Zha, Zaid Pervaiz Bhat, Kwei-Herng Lai, Fan Yang, Zhimeng Jiang, Shaochen Zhong, and\\nXia Hu. Data-centric artificial intelligence: A survey. arXiv preprint arXiv:2303.10158 , 2023.\\nYujia Zhai, Chengquan Jiang, Leyuan Wang, Xiaoying Jia, Shang Zhang, Zizhong Chen, Xin Liu,\\nand Yibo Zhu. Bytetransformer: A high-performance transformer boosted for variable-length\\ninputs. arXiv preprint arXiv:2210.03052 , 2022.\\nYifan Zhang, Jingqin Yang, Yang Yuan, and Andrew Chi-Chih Yao. Cumulative reasoning with\\nlarge language models. arXiv preprint arXiv:2308.04371 , 2023.\\nLianmin Zheng, Zhuohan Li, Hao Zhang, Yonghao Zhuang, Zhifeng Chen, Yanping Huang, Yida\\nWang, Yuanzhong Xu, Danyang Zhuo, Eric P Xing, et al. Alpa: Automating inter-and {Intra-\\nOperator }parallelism for distributed deep learning. In 16th USENIX Symposium on Operating\\nSystems Design and Implementation (OSDI 22) , pp. 559–578, 2022.\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,\\nZi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.\\nJudging llm-as-a-judge with mt-bench and chatbot arena, 2023.\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat,\\nPing Yu, Lili Yu, et al. Lima: Less is more for alignment, 2023.\\nZhe Zhou, Xuechao Wei, Jiejing Zhang, and Guangyu Sun. {PetS}: A unified framework for\\n{Parameter-Efficient }transformers serving. In 2022 USENIX Annual Technical Conference\\n(USENIX ATC 22) , pp. 489–504, 2022.\\nXizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li,\\nLewei Lu, Xiaogang Wang, et al. Ghost in the minecraft: Generally capable agents for open-world\\nenviroments via large language models with text-based knowledge and memory. arXiv preprint\\narXiv:2305.17144 , 2023.\\nBarret Zoph and Quoc V . Le. Neural architecture search with reinforcement learning. In Interna-\\ntional Conference on Learning Representations (ICLR) , 2017.\\n16', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 15}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nAppendix\\nTable of Contents\\nA Model Details 18\\nB Implementation Details of Skeleton-of-Thought 18\\nB.1 Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\nB.2 Supporting Multi-Round Conversation . . . . . . . . . . . . . . . . . . . . . . 20\\nC Implementation Details of Skeleton-of-Thought with Router 20\\nC.1 Prompting Router . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\nC.2 Trained Router . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\nC.3 Router Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nC.4 Concurrent execution for SoT-R . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nD Related Work (Expanded) 22\\nD.1 Efficient LLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nD.2 Prompting Methods for LLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nE Efficiency Analysis 24\\nF Efficiency Profiling 25\\nG Efficiency Evaluation 27\\nG.1 Skeleton-of-Thought . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nG.2 Skeleton-of-Thought with Router . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nH Overhead of SoT in Different Scenarios 31\\nI Answer Quality Evaluation 32\\nI.1 Skeleton-of-Thought . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nI.2 Skeleton-of-Thought with Router . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nI.3 ChatGPT-3.5 as the Judge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\n17', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 16}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nA M ODEL DETAILS\\nTable 1 summarizes the models on which we evaluate SoT. We use GPT-4 in the main paper and\\nChatGPT-3.5 in App. I.3 as the judge in FastChat and LLMZoo evaluation.\\nTable 1: Model evaluated with SoT. All the open-source models are fine-tuned from LLaMA models.\\nAccess Model Name Institution Released Date\\nOpen-SourceLLaMA2-Chat-7B (Touvron et al., 2023b) Meta & Microsoft 2023/07\\nLLaMA2-Chat-13B (Touvron et al., 2023b) Meta & Microsoft 2023/07\\nOpenChat-13B (Wang et al., 2023a) Tsinghua 2023/07\\nVicuna-7B V1.3 (Chiang et al., 2023) LMSYS 2023/06\\nVicuna-13B V1.3 (Chiang et al., 2023) LMSYS 2023/06\\nVicuna-33B V1.3 (Chiang et al., 2023) LMSYS 2023/06\\nStableVicuna-13B (Phung, 2023) CarperAI 2023/05\\nUltraLM-13B (Ding et al., 2023) OpenBMB & Tsinghua 2023/05\\nVicuna-7B V1.1 (Chiang et al., 2023) LMSYS 2023/03\\nAPI-BasedClaude (Anthropic, 2023) Anthropic 2023/05\\nChatGPT-3.5 OpenAI 2022/11\\nGPT-4 OpenAI 2023/03\\nTable 2 shows sources of the models we use in the paper.\\nTable 2: The Hugging Face or API endpoints of the models.\\nAccess Model Name Hugging Face or API Endpoints\\nOpen-SourceLLaMA2-Chat-7B (Touvron et al., 2023b) meta-llama/Llama-2-7b-chat-hf\\nLLaMA2-Chat-13B (Touvron et al., 2023b) meta-llama/Llama-2-13b-chat-hf\\nOpenChat-13B (Wang et al., 2023a) openchat/openchat\\nVicuna-7B V1.3 (Chiang et al., 2023) lmsys/vicuna-7b-v1.3\\nVicuna-13B V1.3 (Chiang et al., 2023) lmsys/vicuna-13b-v1.3\\nVicuna-33B V1.3 (Chiang et al., 2023) lmsys/vicuna-33b-v1.3\\nStableVicuna-13B (Phung, 2023) CarperAI/stable-vicuna-13b-delta2\\nUltraLM-13B (Ding et al., 2023) openbmb/UltraLM-13b2\\nVicuna-7B V1.1 (Chiang et al., 2023) lmsys/vicuna-7b-delta-v1.1\\nAPI-BasedClaude (Anthropic, 2023) Claude extension on Slack3\\nChatGPT-3.5 Azure OpenAI, gpt-35-turbo 0301 version4\\nGPT-4 OpenAI, gpt-4-0613 version\\nB I MPLEMENTATION DETAILS OF SKELETON -OF-THOUGHT\\nB.1 P ROMPT\\nThe skeleton prompt is shown in Prompts 1 and 3 and the point-expanding prompt is shown in\\nPrompt 2.\\nSkeleton prompt template. In order to make the output skeleton short and in a consistent format for\\nthe good of efficiency and ease of point extraction, the skeleton prompt template (1) describes the\\ntask precisely, and (2) provides a partial answer “1.” for the LLM to continue writing. The skeleton\\n2For convenience, we use the non-official endpoint TheBloke/stable-vicuna-13B-HF and\\nTheBloke/UltraLM-13B-fp16 to get merged weights.\\n3https://www.anthropic.com/claude-in-slack\\n4https://azure.microsoft.com/en-us/products/ai-services/openai-service\\n18', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 17}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nPrompt 3. Skeleton Prompt Template Ts(with Two-Shot Demonstrations)\\n[User:] You’re an organizer responsible for only giving the skeleton (not the full content) for answering the question.\\nProvide the skeleton in a list of points (numbered 1., 2., 3., etc.) to answer the question. Instead of writing a full\\nsentence, each skeleton point should be very short with only 3 ∼5 words. Generally, the skeleton should have 3 ∼10\\npoints.\\nQuestion:\\nWhat are the typical types of Chinese dishes?\\nSkeleton:\\n1. Dumplings.\\n2. Noodles.\\n3. Dim Sum.\\n4. Hot Pot.\\n5. Wonton.\\n6. Ma Po Tofu.\\n7. Char Siu.\\n8. Fried Rice.\\nQuestion:\\nWhat are some practical tips for individuals to reduce their carbon emissions?\\nSkeleton:\\n1. Energy conservation.\\n2. Efficient transportation.\\n3. Home energy efficiency.\\n4. Reduce water consumption.\\n5. Sustainable diet.\\n6. Sustainable travel.\\nNow, please provide the skeleton for the following question.\\n{question }\\nSkeleton:\\n[Assistant:] 1.\\nresponses are in the desired format in most cases. Therefore, we can use a simple regular expression\\n(\\\\d+)\\\\.\\\\s?([\\\\s\\\\S]+?)(?=\\\\n|\\\\n *$)to extract point indexes and point skeletons from the\\nskeleton response.\\nWe find that GPT-4 can work well without the two demonstrations in the skeleton prompt. Therefore,\\nwe do not include the two demonstrations for GPT-4 (Prompt 1). For all other models, the two\\ndemonstrations are included, as shown in Prompt 3.\\nPoint-expanding prompt template. It describes the point-expanding task and provides a partial\\nanswer. We also provide instructions “Write it **very shortly** in 1 ∼2 sentence” so that the LLMs\\nkeep the answers concise. Unlike the skeleton prompt template, we find that demonstrations are not\\nnecessary to get reasonable results.\\nWe find that Claude and GPT-4 follows the instruction “Write it **very shortly** in 1 ∼2 sentence\\nand do not continue with other points!” in Prompt 2 very well, so that the answers are very short.\\nTherefore, we delete “**very shortly**” from the prompt template in Claude and GPT-4.\\nPartial answer. In the Prompts 1 and 2, we provide partial answers so that LLMs can follow the\\ndesired response format better.\\nWe can put the partial answer at the end of the prompt for the open-source models to continue\\nwriting. An implementation detail is that different open-source models have different conversa-\\ntion templates (i.e., different ways to combine user and assistant messages into one string). For\\nexample, Vicuna (Chiang et al., 2023) uses the string “USER:” and “ ASSISTANT:” for the place-\\nholder “ [User:] ” and “ [Role] ” in the Prompts 1 and 2, respectively, while UltraLM (Ding et al.,\\n2023) uses “User:” and “ 〈/s〉Assistant:”. We build our open-source model experiments with the\\nhelp of the FastChat codebase (Zheng et al., 2023), in which the conversation templates of many\\nmodels are already handled correctly. We implement the conversation templates of OpenChat-13B,\\nStableVicuna-13B, and UltraLM-13B according to their official guides and codes.\\nFor ChatGPT-3.5, we provide partial answers as a last message in the chat history from the assistant.\\nNote that it is not a documented approach. We find it works well in most cases, in that ChatGPT-3.5\\n19', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 18}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nPrompt 4. LLM Prompting as the Router\\n[User:] Question: {question }\\nHow would you like to answer the question?\\nA. Organize the answer as a list of points or perspectives (in the format of 1., 2., 3., etc.), and the points or perspectives\\ncan be answered independently without referring to the contents of the previous points.\\nB. Organize the answer as a list of points or perspectives (in the format of 1., 2., 3., etc.), and the contents of later points\\nor perspectives cannot be answered independently without referring to the contents of the previous ones.\\nC. Do not organize the answer as a list of points or perspectives.\\nJust say A, B, or C. Do not explain. Do not provide an answer to the question.\\n[Assistant:]\\ncontinues the texts from the provided partial answer. However, in some rare cases, ChatGPT-3.5\\nrepeats the provided partial answers.\\nFor Claude over Slack, there is no obvious way to give the API a partial answer. We resort to\\nmodifying the prompt template slightly by adding\\nPlease start your answer from “ {partial answer }” and do not output other things before that\\nat the end. We find that Claude understands and obeys it well. For GPT-4, we also take this approach.\\nSystem Message. We do not include the system message in the prompts for open-source models\\nexcept LLaMA2.\\nThe partial answer, “**very shortly**”, and the 2-shot demonstrations discussed above are the only\\ndifferences between the prompts we used across all models and all evaluations.\\nB.2 S UPPORTING MULTI -ROUND CONVERSATION\\nTo use SoT in a multi-round conversation, we can just put the question and the final aggregated\\nanswer in the history, removing all the SoT prompts. In this way, using SoT in one conversation\\nround will not introduce additional prefill cost in future rounds.\\nC I MPLEMENTATION DETAILS OF SKELETON -OF-THOUGHT WITH ROUTER\\nC.1 P ROMPTING ROUTER\\nWe use Prompt 4 for querying GPT-4 as the router. If the answer is “A” (i.e., the question can be\\nanswered in a list of independent points), we will use SoT. Otherwise, if the answer is “B” (i.e., the\\nanswer is in a list of points but they depend on each other) or “C” (i.e., the answer should notbe in\\na list of points), SoT is not suitable and we will fall back to normal decoding.\\nC.2 T RAINED ROUTER\\nWe tackle the routing problem as a sequence classification task. We first annotate the LIMA training\\nset (Zhou et al., 2023), and then fine-tune a RoBERTa model (Liu et al., 2019) using the labeled\\ndata. Finally, we apply the tuned RoBERTa as the router on Vicuna-80 and WizardLM. We detail\\nthe steps in the following.\\nC.2.1 A NNOTATION PROCESS\\nIn the classification task, a label of 1 (positive) indicates that this question can be answered with\\nSoT, while a label of 0 (negative) suggests that using the normal generation mode is more suitable.\\nWe annotate the LIMA training set, which consists of 1,030 Q&As sourced from three community\\nwebpages: Stack Exchange, wikiHow, and the Pushshift Reddit. We also annotate the Vicuna-80\\nand WizardLM datasets for evaluation.\\n20', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 19}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nTable 3: Router confusion matrices on the Vicuna-80 dataset. Left: Rows are human annotations\\n(H) and columns are the GPT-4 router (G). Middle: Rows are human annotations (H) and columns\\nare the RoBERTa router (R). Right: Rows are the GPT-4 router (G) and columns are the RoBERTa\\nrouter (R).\\nG0 G1\\nH0 38 5\\nH1 0 37R0 R1\\nH0 37 6\\nH1 5 32R0 R1\\nG0 34 4\\nG1 8 34\\nTable 4: Router confusion matrices on the WizardLM dataset. Left: Rows are human annotations\\n(H) and columns are the GPT-4 router (G). Middle: Rows are human annotations (H) and columns\\nare the RoBERTa router (R). Right: Rows are the GPT-4 router (G) and columns are the RoBERTa\\nrouter (R).\\nG0 G1\\nH0 94 66\\nH1 3 55R0 R1\\nH0 135 25\\nH1 31 27R0 R1\\nG0 93 4\\nG1 73 48\\nWe use GPT-4 to assist the annotation process. Specifically, we present each question to GPT-4 and\\nanalyze its answer to determine whether SoT can be triggered for this question. We assign a positive\\nlabel to a question if GPT-4’s response meets two criteria: (1) it contains a list of points that can be\\nexpanded in parallel, (2) each point provides sufficient details (i.e., the point-expanding response is\\nnot too short), which will enable SoT to achieve a speed-up. Two of the paper’s authors conduct the\\nannotation process independently, and discuss the inconsistent annotations to decide the final label.\\nC.2.2 T RAINING DETAILS\\nWe use roberta-base with 120M parameters as the router model. The finetuning is conducted\\nusing the AdamW optimizer (Loshchilov & Hutter, 2019) with a weight decay of 0.01. The learning\\nrate undergoes a warm-up phase during the first 1% of iterations to 5e-5 and then decays linearly.\\nWe train the model for 2 epochs using a batch size of 32. Input sequences are either padded or\\ntruncated to achieve a consistent length of 512 tokens.\\nIn the application of SoT, false positives (SoT is incorrectly triggered when it should not be, resulting\\nin degraded answer quality) are of more significant concern than false negatives (the router misses a\\npotential SoT trigger, resulting in a reduced speed-up). Thus, to mitigate false positives, we employ\\nthe Tversky loss (Wang et al., 2023b) with parameters α= 0.7andβ= 0.3, which penalizes false\\npositives more heavily than false negatives. We also incorporate label smoothing (Szegedy et al.,\\n2016) with a factor of ϵ= 0.2. Overall, the entire fine-tuning process is efficient, completing in 2\\nminutes on an NVIDIA A100 GPU.\\nC.3 R OUTER CONSISTENCY\\nWe present the confusion matrices for the three routers to illustrate their consistency. The results on\\nVicuna-80 and WizardLM are shown in Tables 3 and 4, respectively.\\nOn Vicuna-80, we can observe a notable level of agreement among the three routers. Compared with\\nthe GPT-4-prompting router, the trained router exhibits a slightly higher number of false negatives\\nw.r.t. the human annotations. Conversely, on WizardLM, given the intricate answer structure and\\nthe presence of many ambiguous cases, the routers show significant discrepancies. Specifically, the\\nGPT-4 router produces many false positives, which pose adverse affects on the answer quality (see\\nApp. I.2). The RoBERTa router aligns more closely with the human annotations.\\nC.4 C ONCURRENT EXECUTION FOR SOT-R\\nIn SoT-R, the router serves as an additional stage that extends the two-stage SoT pipeline. The\\nSoT-R pipeline is illustrated in Fig. 9. To push the limit of latency optimization, we can run the\\nrouter, normal generation, and SoT generation concurrently. Once the router makes a decision, one\\nof the normal and SoT generation processes can be aborted. However, this approach will increase\\n21', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 20}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nRouterSkeleton Expandpositive\\nnegativeDecodeQuestion\\nAnswerAnswer\\nRouterSkeleton Expand\\nDecodeQuestionAnswer\\nAnswerpositive\\nnegative\\nFigure 9: Left: The SoT-R pipeline. Right: A possible approach to further reduce latency at the\\ncost of token overhead.\\nthe token overhead. Therefore, we did not employ this approach in this work and leave it to future\\nwork.\\nD R ELATED WORK (EXPANDED )\\nD.1 E FFICIENT LLM S\\nExtensive research has been dedicated to enhancing the throughput and latency of LLM infer-\\nence. We first discuss model-level architecture design or compression techniques. These techniques\\nchange the model and can benefit both the latency and throughput but require finetuning to retain the\\nmodel quality. Then, we discuss system-level efforts that optimize the computational graph or the\\nassignment and scheduling of the computational graph on computation and storage devices. Most\\nsystem-level efforts accelerate the prefilling phase or focus on improving the throughput. Finally,\\nwe discuss some research efforts that share a similar motivation to ours, namely, addressing the\\nefficiency issue of sequential decoding.\\nModel-level optimization. Considerable architectural design efforts have emerged to (1) improve\\nthe scalability w.r.t. model size by introducing mixture-of-expert inference (Lepikhin et al., 2021;\\nFedus et al., 2022), (2) address the quadratic complexity w.r.t. input size of attention by designing\\nnew attention mechanisms (Kitaev et al., 2020; Wang et al., 2020), (3) reduce the memory access\\nand footprint of attention by using multi-query attention (Shazeer, 2019), and so on. However, these\\nmethods usually require a substantial re-training cost. The model compression techniques require a\\nsmaller amount of fine-tuning by reducing the model complexity of a pre-trained LLM from certain\\naspects (Ganesh et al., 2021). Representative techniques include quantization (Xiao et al., 2022;\\nFrantar et al., 2022; Lin et al., 2023), the static or dynamic pruning of weights, activation, and\\nattention (Mishra et al., 2021; Zaheer et al., 2020; Wang et al., 2021; Chen et al., 2023b), and so on.\\nZooming out from LLM compression to the whole field of model compression, we can see that\\nmodel co-design or compression for efficiency has received tremendous attention in the past few\\nyears and has grown into large research fields, such as pruning (Han et al., 2015; Wen et al., 2016),\\nquantization (Krishnamoorthi, 2018), factorization (Denton et al., 2014), and neural architecture\\nsearch (Zoph & Le, 2017; Elsken et al., 2019; Cai et al., 2019). Different from the model co-design\\nparadigm, SoT is in a “ content co-organization for efficiency ” paradigm for improving the LLM\\nefficiency . Along with the growth in the LLM capabilities and amount of LLM-generated data,\\ndata-level techniques could become important tools in the efficient LLM toolbox.\\nSystem-level optimization. In the realm of lossless acceleration, considerable efforts have been\\ndevoted to addressing the I/O-bound nature of LLMs on modern hardware platforms (Dao et al.,\\n2022). Numerous studies (Dao et al., 2022; Zhai et al., 2022; Ivanov et al., 2021; NVIDIA, 2019)\\nhave focused on adjusting the computational graph by fusing and implementing operations in an\\nI/O-friendly way. As a representative method, FlashAttention (Dao et al., 2022) fuses all operations\\nof one attention into one GPU kernel with spatially tiled computation to reduce the off-chip I/O of\\nthe attention map. While FlashAttention can effectively accelerate training and the prefilling phase\\nof inference, it cannot accelerate the decoding phase much (when the batch size is small), as it is\\nthe I/O of weights rather than activation or attention map that bottlenecks the decoding phase. For\\nexample, when the context length is 64, decoding one token using LLaMA-7B needs to load each\\n22', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 21}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nof the 7B parameters from the off-chip HBM onto the GPU chip at least once, but only transferring\\nabout 20M (0.02B) activation values between the off-chip HBM and GPU chip.\\nIn order to satisfy Service Level Objectives, serving systems focus on improving the serving\\nthroughput under latency constraints. To this end, serving systems (Fang et al., 2021; NVIDIA,\\n2021; Google, 2021) pack multiple queries together into a batch to improve the hardware utiliza-\\ntion. The batching technique has proven highly effective in enhancing throughput, leading to the\\ndevelopment of various variants. For example, some work designs methods to decide which queries\\nto batch together (Fang et al., 2021; Zhou et al., 2022), while others selectively batch parts of the\\nmodel to enable fine-grained iteration-level batching (Yu et al., 2022) or multi-task batching (Zhou\\net al., 2022). Various model parallelism (Lu et al., 2017; Huang et al., 2019; Narayanan et al.,\\n2019; Rajbhandari et al., 2020; Narayanan et al., 2021; Li et al., 2021; Zheng et al., 2022) and\\noffloading (Ren et al., 2021; Sheng et al., 2023) techniques have been proposed to maximize the\\nthroughput of LLM training or inference. In a nutshell, given the computational graph and device\\nconfigurations, these techniques optimize the split, assignment, and scheduling of computations,\\nstorage, and communications on devices. In addition to the model parallelism and batching tech-\\nniques, an efficient memory management mechanism for LLM workloads is also an essential feature\\nin the serving systems (Kwon et al., 2023; SenseTime, 2023a;b).\\nTo sum up, these system-level techniques mainly help with the throughput in training and batched\\ninference. They can be used by SoT to improve the throughput of the batched decoding of multiple\\nsegments. This means that SoT can harness the power of these throughput-oriented techniques and\\nmake them help with the end-to-end latency , offering a new dimension for better trading off latency\\nand throughput in future serving systems.\\nAnother parallelism perspective to position SoT is that SoT guides the LLM to adjust the sequen-\\ntial workload to become “inter-content” parallelizable , which differs from the parallelism levels\\nin existing serving systems, including inter-instance (Krizhevsky, 2014; Rajbhandari et al., 2020),\\ninter-operation (Huang et al., 2019; Narayanan et al., 2019; 2021), intra-operation (Xu et al., 2021),\\nand inter-token (Li et al., 2021). It may be worthwhile to explore the integration of SoT into serving\\nsystems to maximize the hardware utilization .\\nDecoding optimization. One bottleneck for the end-to-end latency lies in the autoregressive de-\\ncoding phase, where tokens must be generated one by one. Due to the dependency between tokens,\\nthe computation of different tokens cannot be parallelized, causing severe under-utilization of GPU.\\nIn order to improve the end-to-end decoding latency of a given LLM, speculative decoding meth-\\nods (Stern et al., 2018; Leviathan et al., 2022; Chen et al., 2023a; Gante, 2023; Sun et al., 2023;\\nMiao et al., 2023) propose to use cheaper approaches to generate short candidate token sequences,\\nfor example, by sequentially decoding with an assisting model much smaller than the given LLM.\\nThen, they use the LLM to parallelly verify the candidates and keep the prefix sequence that matches\\nthe LLM’s verification results.\\nAnother line of work that shares the motivation of addressing the autoregressive efficiency issue is\\nnon-autoregressive generation (NAG) methods (Gu et al., 2018; Xiao et al., 2023). NAG methods\\nsample consecutive tokens parallelly, often with the aid of a modified and tuned model. To maintain\\nthe answer quality, instead of sampling for one iteration, many NAG methods refine the output\\nparallelly for multiple iterations (Xiao et al., 2023; Santilli et al., 2023).\\nTo summarize, the speculative decoding methods use assisting models for letting the LLM conduct\\nparallel verification of consecutive tokens , and the NAG methods rely on specially designed models,\\ntraining schemes, or sampling schemes for the parallel sampling and refinement of consecutive to-\\nkens. In contrast, SoT prompts the LLM itself to plan the contents in a way that permits the parallel\\ngeneration of multiple tokens in different segments . SoT exploits the emerging instruction-following\\nand planning ability of SoTA LLMs rather than relying on specially designed modeling, sampling,\\nand training schemes. This is different from all existing work that targets the autoregressive effi-\\nciency issue.\\nD.2 P ROMPTING METHODS FOR LLM S\\nIn recent years, the “pre-train, prompt, and predict” paradigm has emerged (Liu et al., 2023), which\\ndesigns prompts comprising task descriptions and (optionally) a few demonstrations to guide pre-\\n23', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 22}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nTable 5: The latency and average GPU performance of the prefilling and decoding phases when\\ninferencing LLMs. The prefilling token length is 128, the decoding token length is 64, and the batch\\nsize is 1. The test is run on one NVIDIA A100 GPU.\\nModel Prefill/Decode Latency (ms) Prefill/Decode GPU Perf. (TFLOPS)\\nLLaMA-7B 40 / 2735 43 / 0.31\\nLLaMA-13B 54 / 3725 62 / 0.44\\nLLaMA-33B 100 / 5506 85 / 0.75\\ntrained LLMs in generating answers for a wide range of downstream tasks. Researchers found that\\ninstruction-tuned LLMs (Brown et al., 2020; Wei et al., 2021; Ouyang et al., 2022; Chung et al.,\\n2022; Taori et al., 2023) possess a strong ability to (1) generalize to new tasks thanks to the diverse\\nnatural language descriptions encountered during instruction tuning, and (2) learn in-context using\\na few demonstrations without weight tuning.\\nIn virtue of these abilities, the field has been manually engineering (Brown et al., 2020; Kojima\\net al., 2022; Shen et al., 2023; Li et al., 2023a), automatic searching (Shin et al., 2020), or continu-\\nously tuning (Li & Liang, 2021; Lester et al., 2021) the prompts for uncovering the capabilities of\\nLLMs on downstream tasks. There are a bunch of prompting methods that improves the reasoning\\nperformance of LLMs by designing thinking flows mimicking human reasoning: (1) mimicking the\\nstep-by-step or compositional thinking structure (Wei et al., 2022; Kojima et al., 2022; Press et al.,\\n2022; Yao et al., 2023; Besta et al., 2023; Zhang et al., 2023), (2) designing multiple reasoning paths\\nand their aggregation (Wang et al., 2022; Yao et al., 2023; Li et al., 2023c), and (3) using tools for\\ncalculation and information retrieval (Chen et al., 2022; Yao et al., 2022; Schick et al., 2023). As\\na representative example, the Chain-of-Thought prompts largely improve the performance on tasks\\nthat require logical reasoning by simply providing a “Let’s think step by step” (Kojima et al., 2022)\\ninstruction or a few demonstrations (Wei et al., 2022). Another topic that arises quite a surge of in-\\nterests is to prompt LLMs to help finish complex multi-modality task (Shen et al., 2023; Zhu et al.,\\n2023). For example, HuggingGPT (Shen et al., 2023) design prompts to guide the LLM to generate\\nstructural JSON for the orchestration of multi-model execution to finish complex tasks.\\nTo summarize, the large literature on prompting methods has been aiming at uncovering different\\ncapabilities of LLM and improving the answer quality on different downstream tasks. In contrast,\\nSoT is a first attempt at exploiting the power of prompting to improve efficiency .\\nE E FFICIENCY ANALYSIS\\nThis section gives a detailed explanation on why SoT can reduce the overall decoding latency with\\nthe same computational resource for local models.\\nThe vanilla approach processes only one question and decodes the answers sequentially, whereas\\nSoT processes multiple point-expanding requests and the answers in a batch. We focus on the\\nfollowing question: “Compared to processing only one sequence, how much peak memory overhead\\nand latency increase will be brought by processing a batch of sequences?”\\nA typical LLM generative process consists of two phases: (1) the prefilling phase in which the\\nprompt is parsed to generate the key-value cache for further use, and (2) the decoding phase in\\nwhich tokens are generated one by one in a sequential manner. The decoding phase accounts for\\nthe majority of the end-to-end latency, especially when generating a long response. As shown in\\nTable 5, when running Vicuna-7B on NVIDIA A100-80G, the actual computing performance is\\nonly 0.31 TFLOPS (0.1% utilization) in the decoding phase, compared to 43 TFLOPS (13.8% uti-\\nlization) during prefilling. The utilization is calculated with respect to the FP165tensor core peak\\nperformance – 312 TFLOPS for NVIDIA-A100. As a result, the latency of decoding only one token\\nis comparable to that of prefilling 128 tokens (40ms). This huge gap in actual computing perfor-\\nmance and thereby the latency arises from the fact that all LLM weights need to be loaded onto the\\nGPU chip at least once only for decoding one token, so the decoding is heavily bottlenecked by the\\nI/O of weights and the GPU computation units cannot be well utilized.\\n5All of our experiments are run with FP16 inference.\\n24', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 23}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n1 2 3 4 5 6 7 8 9\\nB300035004000450050005500\\nLLaMA-7B\\nLLaMA-13B\\nLLaMA-33B\\n(a) Latency (ms)\\n1 2 3 4 5 6 7 8 9\\nB0123456\\nLLaMA-7B\\nLLaMA-13B\\nLLaMA-33B (b) Actual GPU Perf. (TFLOPS)\\n1 2 3 4 5 6 7 8 9\\nB203040506070\\nLLaMA-7B\\nLLaMA-13B\\nLLaMA-33B (c) Peak Memory (GB)\\nFigure 10: The trends of latency, average GPU performance of decoding one token, and peak mem-\\nory with respect to the batch size Bof sequences. The prefilling token length is 128, and the\\ndecoding token length is 64. The test is run on one NVIDIA A100 GPU.\\nWhen conducting batched decoding, as the sequence batch size Bincreases, the latency of decoding\\none token for each sequence stays roughly the same (Fig. 10a), as the amount of LLM weights that\\nneeds to be loaded onto the chip does not change. As a result, the GPU computation utilization\\n(Actual GPU Performance\\nPeak GPU Performance) increases almost linearly as Bincreases (Fig. 10b). In other words, for gener-\\nating a final answer of length N, if we cut the answer into Bsegments of length N/B and decode\\nthem as a batch, we can get a B×decoding speed-up compared to sequential decoding. Never-\\ntheless, in practice, as prefilling longer requests brings some overhead, and the lengths of the B\\nsegments could be imbalanced, the actual speed-up of the batched point-expanding stage compared\\nwith the original prefilling and sequential decoding process is smaller than B.\\nAs for the peak memory overhead, the amount of LLM weights can be one to two orders of mag-\\nnitude larger than that of all the intermediate activations as long as the prefilling token length is not\\ntoo large, not to mention that most activations do not need to be saved for back-propagation during\\ninference. Therefore, the LLM weights account for the majority of the memory footprint in our test\\ncases. Consequently, as shown in Fig. 10c, the peak memory overhead due to the increasing size\\nof the KV cache and activation grows at a slow pace as the batch size Bincreases. Thanks to the\\nsmall peak memory overhead, in all of our experiments, we managed to use one GPU to run SoT\\nwithout seeking help from other peak memory optimization techniques (e.g., quantization (Frantar\\net al., 2022; Lin et al., 2023), offloading (Sheng et al., 2023)).\\nF E FFICIENCY PROFILING\\nWe run the profiling on the target GPU (NVIDIA A100-80G and NVIDIA RTX 3090) with CUDA\\n11.7, using the Hugging Face transformer library 4.28.1 and PyTorch 2.0.1. The host of A100-80G\\nhas an Intel Xeon Platinum 8358P CPU and 1T memory. The host of RTX 3090 has an Intel Xeon\\nGold 6246R CPU and 512G memory.\\nLatency profiling and estimation. For the decoding phase, we denote tD\\nB(k)as the latency\\nof batched decoding the k+ 1-th token with batch size B, where the superscript Dstands for\\n“decode”. For each batch size B= 1,···,16and each context length k= 1,···,1024 , we\\nusetorch.cuda.Event to record the latency of decoding one token. We run each decod-\\ning three times continuously and take their geometric mean as {tD\\nB(k)}k=1,···,1024;B=1,···,16. For\\nthe prefilling phase, we profile the latency of batched prefilling the inputs with token length kin\\nrange (1,700,10)and batch size B= 1,···,16, and denote it as tP\\nB(k), where the superscript P\\nstands for “prefill”. We run each test seven times continuously, regard the first two times as the\\nwarmup tests, and take the geometric mean of the last five times as {tP\\nB(k)}k=1,11,···,691;B=1,···,16.\\nOnce we get the latency profiling table, given a request with litokens and the decoding batch size\\nB, the latency of generating lotokens can be estimated as:\\nT(li, lo, B) =˜tP\\nB(li) +li+lo−1X\\nk=litD\\nB(k), (1)\\nwhere the subscripts iandostand for “input” and “output”. Note that we only test the prefill-\\ning latency every ten token lengths (i.e., 1,11,21,···) for fast profiling and estimate ˜tP\\nB(li)by\\ntP\\nB(⌊li\\n10⌋ ×10 + 1) .\\n25', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 24}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nThe SoT decoding process consists of two stages: the skeleton stage and the point-expanding stage.\\nDenoting the token length of the skeleton request and skeleton response as ls\\niandls\\no, the token length\\nof the longest point-expanding request and the longest point-expanding response as lpe\\niandlpe\\no, the\\nnumber of the points as B, we can compute the latency of the skeleton and point-expanding stages\\nas:\\nLs(ls\\ni, ls\\no) =T(ls\\ni, ls\\no,1), (2)\\nLpe(lpe\\ni, lpe\\no, B) =T(lpe\\ni, lpe\\no, B). (3)\\nUsing the latency profiling table, we can further estimate the average GPU computing performance\\nin FLOPS (i.e., FLOPs per second) of decoding lotokens with prefilling length lias\\nPD(li, lo, B) =Pli+lo−1\\nk=lifD\\nB(k)\\nPli+lo−1\\nk=litD\\nB(k), (4)\\nwhere fD\\nB(k)denotes the FLOPs of decoding one token with context length k, which is calculated\\nby DeepSpeed’s FLOPs profiler6. Fig. 10b reports the average GPU computing performance during\\nthe process of decoding 64 tokens (prefilling length=128), i.e., PD(128,64, B).\\nMemory profiling and evaluation. To evaluate the peak memory, we use\\ntorch.cuda.max_memory_allocated to record the memory consumption of prefill-\\ning sequences of different lengths and decoding with different context lengths and a batch size\\nranging from 1 to 16. Then, we calculate the peak memory of each stage as the maximum value of\\nthe prefilling and decoding phases, and calculate the overall peak memory of SoT as the maximum\\nvalue of the skeleton and point-expanding stages.\\n6https://deepspeed.readthedocs.io/en/latest/flops-profiler.html\\n26', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 25}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nG E FFICIENCY EVALUATION\\nG.1 S KELETON -OF-THOUGHT\\nG.1.1 D ETAILED STATISTICS OF TOKEN LENGTHS AND POINT NUMBERS\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage6.4 5.3 4.4 7.3 4.9 7.9 6.6 9.7 7.1 5.0 4.7 5.3 8.6\\n4.4 3.7 3.3 5.7 5.0 4.0 3.7 5.7 5.0 3.3 3.7 4.7 5.3\\n6.3 4.9 5.6 5.4 5.3 6.5 6.9 10.0 5.8 5.5 6.4 4.8 8.5\\n7.4 6.7 6.3 6.7 6.0 7.0 7.3 9.9 9.1 5.3 8.6 6.3 9.9\\n7.5 5.9 6.6 8.2 6.3 8.0 7.8 8.8 8.1 5.8 8.3 5.9 9.8\\n7.4 7.5 5.9 5.9 6.3 7.5 8.6 9.4 8.1 6.4 7.9 6.1 9.4\\n7.8 6.3 6.2 7.4 6.7 8.4 8.6 9.7 9.2 6.4 7.9 6.7 9.5\\n6.8 5.0 6.1 6.1 4.9 9.1 7.7 8.4 8.3 4.4 7.3 4.9 9.5\\n6.8 6.0 5.5 5.5 4.8 8.6 7.8 9.2 8.8 4.1 7.3 5.1 9.3\\n6.8 5.7 5.6 6.5 5.6 7.4 7.2 9.0 7.7 5.1 6.9 5.5 8.9\\n4.05.06.07.08.09.010.0\\n(a) The number of points B.\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage372.4 374.0 462.7 386.9 459.7 394.9 384.9 300.3 338.4 381.4 338.6 343.0 304.3\\n173.5 177.3 208.0 95.0 254.7 159.7 255.0 83.0 273.7 156.7 137.0 139.7 142.7\\n391.8 396.6 350.3 453.0 382.8 429.6 465.3 398.1 272.1 402.1 417.6 333.8 400.2\\n311.4 368.5 356.4 273.4 338.2 285.4 431.7 155.7 361.0 254.3 304.7 235.3 372.5\\n409.8 436.6 478.1 373.9 397.9 404.1 440.4 260.4 325.2 386.0 464.4 366.6 583.6\\n401.0 470.6 488.6 468.9 377.1 369.8 497.8 266.7 376.8 341.1 352.9 320.2 481.8\\n372.7 468.4 469.8 417.2 328.1 341.1 476.3 194.2 417.8 321.8 361.3 231.7 444.3\\n319.0 285.4 419.5 303.3 245.5 332.1 501.9 198.2 399.7 252.3 404.9 173.4 311.3\\n335.6 424.5 487.9 326.0 324.9 307.6 479.6 169.6 337.9 285.9 303.7 206.1 373.5\\n343.0 378.0 413.5 344.2 345.4 336.0 437.0 225.1 344.7 309.1 342.8 261.1 379.4\\n100.0200.0300.0400.0500.0 (b) The normal answer length.\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage114.9 92.6 126.1 151.7 143.0 124.7 104.9 216.0 120.6 128.4 48.0 56.1 67.0\\n95.0 104.3 94.3 27.3 162.0 189.0 101.7 79.3 98.7 108.0 64.7 45.3 65.7\\n116.0 117.2 117.1 170.7 188.9 106.0 126.0 163.3 105.8 80.4 65.0 78.0 74.0\\n89.0 93.1 108.2 63.4 102.0 100.3 118.7 123.4 76.9 71.8 59.4 66.1 84.6\\n97.2 94.4 114.5 161.9 125.1 92.6 118.1 89.5 90.2 85.8 53.8 61.3 79.4\\n94.1 99.9 101.0 98.1 110.5 108.9 114.0 117.8 90.9 81.1 61.2 62.9 83.0\\n86.0 86.3 108.5 106.6 108.6 89.6 105.4 87.3 81.3 76.8 51.3 55.5 75.1\\n93.5 106.2 103.2 101.9 88.9 118.3 113.0 129.2 79.6 75.3 66.6 56.7 83.1\\n86.9 97.4 100.1 75.4 121.3 100.6 98.3 104.2 88.5 75.6 55.0 57.0 69.7\\n97.0 99.0 108.1 106.3 127.8 114.4 111.1 123.3 92.5 87.0 58.3 59.9 75.7\\n50.075.0100.0125.0150.0175.0200.0\\n(c) The maximum point-expanding response length.\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage0.4 0.3 0.4 0.4 0.3 0.3 0.3 0.9 0.5 0.3 0.1 0.2 0.2\\n0.8 0.6 0.5 0.7 0.6 1.3 0.5 3.0 0.6 0.7 0.6 0.3 0.5\\n0.3 0.3 0.4 0.4 0.5 0.3 0.3 0.4 0.5 0.2 0.2 0.2 0.2\\n0.4 0.3 0.4 0.4 0.3 0.4 0.3 1.2 0.3 0.3 0.2 0.3 0.3\\n0.3 0.2 0.2 0.7 0.3 0.2 0.6 0.4 0.6 0.2 0.1 0.2 0.1\\n0.3 0.2 0.2 0.2 0.3 0.3 0.2 0.5 0.3 0.2 0.3 0.2 0.2\\n0.3 0.2 0.2 0.3 0.4 0.3 0.2 0.5 0.3 0.2 0.1 0.2 0.2\\n0.3 0.4 0.2 0.4 0.4 0.4 0.2 0.7 0.3 0.4 0.2 0.3 0.3\\n0.3 0.2 0.2 0.4 0.4 0.3 0.2 0.7 0.4 0.3 0.4 0.3 0.2\\n0.4 0.3 0.3 0.4 0.4 0.4 0.3 0.9 0.4 0.3 0.2 0.3 0.2\\n0.51.01.52.02.5(d) The ratio of the maximum point-expanding re-\\nsponse length to the normal answer length.\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage30.8 13.5 27.6 50.0 42.1 36.2 24.1 64.7 36.6 43.2 10.3 11.8 9.1\\n25.2 23.6 18.4 6.3 48.7 59.1 17.5 22.6 31.8 41.6 13.0 8.9 10.4\\n25.0 21.6 18.9 47.4 49.2 21.8 22.2 35.8 29.8 23.0 12.9 8.7 8.4\\n16.4 9.9 14.8 17.1 21.0 18.0 18.8 26.6 21.5 15.9 9.1 10.8 12.9\\n17.9 10.9 14.3 39.1 27.1 17.1 19.8 17.1 22.1 18.0 9.4 8.4 12.2\\n14.4 9.7 10.6 20.3 17.9 17.2 15.0 19.8 20.4 15.3 8.3 7.4 10.8\\n15.4 9.0 15.9 27.0 24.1 18.4 16.8 16.2 18.0 15.7 7.6 7.6 8.3\\n15.9 12.4 11.4 22.3 13.1 23.8 14.0 34.0 19.6 15.1 8.8 5.3 11.5\\n14.7 10.5 12.1 19.7 27.7 17.6 14.2 19.6 19.0 15.1 7.0 7.4 6.5\\n19.5 13.5 16.0 27.7 30.1 25.5 18.1 28.5 24.3 22.5 9.6 8.5 10.0\\n10.020.030.040.050.060.0\\n(e) The imbalance degree of point-expanding response\\nlengths (standard deviation of point token lengths).\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage1.5 1.2 1.1 1.1 0.8 1.1 1.1 6.8 1.5 0.7 0.5 0.6 1.4\\n2.1 1.5 1.1 3.4 1.9 2.5 1.0 7.6 1.2 1.0 1.4 1.1 1.8\\n1.3 1.2 1.7 1.2 1.5 1.2 1.3 1.9 1.9 0.6 0.7 0.9 1.3\\n1.9 1.6 1.7 1.9 1.3 2.0 1.3 5.5 1.2 1.1 1.4 1.4 1.9\\n1.7 1.1 1.3 2.8 1.4 1.3 3.5 2.2 3.3 1.0 0.7 0.8 1.0\\n1.5 1.3 1.0 0.8 1.5 1.7 1.5 3.0 1.5 1.1 1.7 1.0 1.3\\n1.4 1.0 1.1 1.0 1.7 1.7 1.3 3.5 1.6 1.1 0.9 1.3 1.3\\n1.7 1.6 1.3 2.0 1.5 2.1 1.3 3.4 1.2 1.1 0.9 1.4 2.0\\n1.7 1.2 0.9 2.0 1.2 2.0 1.2 4.5 1.7 0.9 2.1 1.2 1.5\\n1.6 1.3 1.2 1.8 1.4 1.7 1.5 4.3 1.7 1.0 1.1 1.1 1.5\\n1.02.03.04.05.06.07.0(f) The ratio of the final SoT answer length to the nor-\\nmal answer length.\\nFigure 11: The statistics of the token lengths and point numbers on the Vicuna-80 dataset. Each row\\ncorresponds to one question category, and each column corresponds to one model.\\nG.1.2 L ATENCY BREAKDOWN : SOT S TAGES AND PHASES\\nFig. 12 presents the absolute latencies of normal and SoT generations on Vicuna-80. Again, the\\nspeed-ups of SoT compared with normal generation is evident. We can see that the decoding phases\\npredominantly account for the end-to-end latency. Consequently, although SoT has higher prefilling\\nlatency in the skeleton stage than the normal generation and introduces additional point-expanding\\n27', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 26}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nprefilling latency – which is expected – this has negligible impact on the overall latency and thereby\\nthe overall speed-up.\\n0 5000 10000 15000 20000 25000 30000 35000 40000\\nLatency (ms)ChatGPT-3.5StableVicuna-13BVicuna-7B V1.1Vicuna-7B V1.3LLaMA2-Chat-7BClaudeUltraLM-13BVicuna-13B V1.3OpenChat-13BLLaMA2-Chat-13BGPT-4Vicuna-33B V1.3\\nNormal (prefill)\\nNormal (decode)\\nSoT skeleton (prefill)\\nSoT skeleton (decode)\\nSoT point-expanding (prefill)\\nSoT point-expanding (decode)\\n(a) Average latency across all question categories except\\nmath andcode on different models.\\n0 5000 10000 15000 20000\\nLatency (ms)mathroleplaycounterfactualcommon-sensecodingfermigenericknowledgewriting(b) Average latency across all models on different\\nquestion categories.\\nFigure 12: The latency breakdown of SoT and normal generations on the Vicuna-80 dataset. For\\nopen-source models, the latency breakdown of the prefilling and decoding phases is shown in dif-\\nferent colors. For API-based models, we do not record such latency breakdown information; the bar\\nlabeled as “(decode)” indicates the overall latency of prefilling and decoding phases.\\nG.1.3 E FFICIENCY EVALUATION ON NVIDIA RTX 3090\\nWe present the SoT speed-ups and latency breakdown on RTX 3090 in Fig. 13. We test the three\\n7B models, as their FP16-precision version can be run on an RTX 3090 GPU without further peak\\nmemory optimization techniques such as weight quantization (Frantar et al., 2022; Lin et al., 2023)\\nor offloading (Sheng et al., 2023). On these three models, SoT can obtain 1.94 ×to 2.40 ×speed-up\\non average on Vicuna-80.\\nFor the five question categories that SoT can provide high-quality answers (i.e., knowledge ,common-\\nsense ,generic ,roleplay ,counterfactual ), SoT can speed-up the overall answer generation process\\nby 1.96 ×to 2.52 ×in the meantime. Note that for the math category, despite the average speed-up\\nbeing 1.20 ×by calculating the speed-up across the three math questions, SoT does not reduce the\\nabsolute latency of processing the three questions.\\n0 2000 4000 6000 8000 10000 12000 14000 16000\\nLatency (ms)Vicuna-7B V1.3Vicuna-7B V1.1LLaMA2-Chat-7B\\n1.94×2.26×2.40×\\n0 2000 4000 6000 8000 10000 12000 14000 16000\\nLatency (ms)mathfermicounterfactualcodingroleplayknowledgecommon-sensewritinggeneric\\n1.20×1.70×1.96×2.10×2.12×2.37×2.39×2.43×2.52×Normal (prefill)\\nNormal (decode)\\nSoT skeleton (prefill)\\nSoT skeleton (decode)\\nSoT point-expanding (prefill)\\nSoT point-expanding (decode)\\nFigure 13: The latency breakdown of SoT and normal decoding on the Vicuna-80 dataset. The\\naverage speed-up across questions are also marked on the figure.\\nG.1.4 A CTUAL LATENCY TESTING\\nThis section reports the actual SoT speed-up on the Vicuna-80 with batch testing (instead of analyz-\\ning with pre-made profiling tables), using a single NVIDIA A100 GPU. We test the actual end-to-end\\nlatency of the SoT and normal decoding with the 9 open-source models. For each model, we run the\\nspeed-up test for five times and plot the box in Fig. 14.\\n28', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 27}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nAs shown in Fig. 14a, the current SoT solution obtains a >2×speed-up on 6 out of the 9 open-\\nsource models (i.e., Vicuna-7B V1.1, Vicuna-7B V1.3, UltraLM-13B, LLaMA2-Chat-7B, Vicuna-\\n13B V1.3, and LLaMA2-Chat-13B), and a >1.7speed-up on OpenChat-13B and Vicuna-33B V1.3.\\nSoT achieves no speed-up on StableVicuna-13B. As shown in Fig. 14b, for the five question cate-\\ngories that SoT can provide high-quality answers (i.e., knowledge ,common-sense ,generic ,roleplay ,\\ncounterfactual ), SoT can speed-up the overall answer generation process by 2.15 ×to 2.50 ×in the\\nmeantime.\\n1.0 1.5 2.0 2.5 3.0 3.5StableVicuna-13BVicuna-33B V1.3OpenChat-13BLLaMA2-Chat-13BVicuna-13B V1.3LLaMA2-Chat-7BUltraLM-13BVicuna-7B V1.3Vicuna-7B V1.1\\n0.97×1.75×1.97×2.14×2.19×2.20×2.75×2.82×2.88×\\n(a) Average speed-up on different models.\\n1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8 3.0fermimathroleplaywritingcounterfactualcodingknowledgecommon-sensegeneric\\n1.63×1.67×2.15×2.16×2.18×2.29×2.34×2.45×2.50× (b) Average speed-up on different question categories.\\nFigure 14: Speed-ups on 9 open-source models on the Vicuna-80 dataset with actual batch testing.\\nG.2 S KELETON -OF-THOUGHT WITH ROUTER\\nThe overhead brought by the router inference is relatively small: On the Vicuna-80 dataset,\\nthe prompting and trained router have an average latency of 0.65s (0.39s ∼1.37s) and 0.04s\\n(0.008s ∼1.55s), respectively. On the WizardLM dataset, the average latency of the prompting and\\ntrained router is 0.80s (0.36s ∼2.22s) and 0.03s (0.009s ∼2.52s), respectively.\\nG.2.1 S PEED -UP BREAKDOWN :MODELS\\nFig. 15 shows the speed-ups of SoT-R on different models on the Vicuna-80 dataset. Fig. 16 and\\nFig. 17 show the speed-ups of SoT-R on different models on the WizardLM dataset. We can ob-\\nserve that on Vicuna-80, the two methods yield similar speed-ups, whereas on WizardLM, GPT-4\\nprompting router usually obtains higher speed-ups than the trained router, especially on GPT-4 itself.\\n1.0 1.2 1.4 1.6 1.8 2.0 2.2StableVicuna-13BClaudeChatGPT-3.5Vicuna-13B V1.3Vicuna-7B V1.3UltraLM-13BGPT-4Vicuna-7B V1.1Vicuna-33B V1.3OpenChat-13BLLaMA2-Chat-7BLLaMA2-Chat-13B\\n0.98×1.15×1.24×1.32×1.39×1.51×1.54×1.55×1.62×1.66×1.67×1.70×\\n(a) Average speed-up across all question categories\\nwith prompting router.\\n1.0 1.2 1.4 1.6 1.8 2.0 2.2StableVicuna-13BClaudeChatGPT-3.5Vicuna-13B V1.3Vicuna-7B V1.3GPT-4Vicuna-33B V1.3UltraLM-13BVicuna-7B V1.1LLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13B\\n0.99×1.14×1.33×1.34×1.42×1.49×1.57×1.59×1.59×1.69×1.70×1.82×(b) Average speed-up across all question categories\\nwith trained router.\\nFigure 15: Speed-ups of SoT-R on different models on Vicuna-80 dataset.\\n29', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 28}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75StableVicuna-13BClaudeChatGPT-3.5Vicuna-7B V1.3LLaMA2-Chat-7BLLaMA2-Chat-13BVicuna-7B V1.1UltraLM-13BVicuna-13B V1.3OpenChat-13BVicuna-33B V1.3GPT-4\\n1.13×1.13×1.40×1.49×1.51×1.52×1.56×1.57×1.59×1.66×1.68×2.41×\\n(a) Average speed-up across all question categories\\nwith prompting router.\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75ClaudeStableVicuna-13BVicuna-13B V1.3UltraLM-13BVicuna-33B V1.3Vicuna-7B V1.3LLaMA2-Chat-13BVicuna-7B V1.1LLaMA2-Chat-7BChatGPT-3.5OpenChat-13BGPT-4\\n1.09×1.09×1.31×1.33×1.33×1.34×1.35×1.36×1.37×1.37×1.42×1.74×(b) Average speed-up across all question categories\\nwith trained router.\\nFigure 16: Speed-ups of SoT-R on different models on WizardLM dataset.\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75ClaudeStableVicuna-13BVicuna-7B V1.3LLaMA2-Chat-7BLLaMA2-Chat-13BChatGPT-3.5Vicuna-13B V1.3Vicuna-33B V1.3OpenChat-13BVicuna-7B V1.1UltraLM-13BGPT-4\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nFigure 17: Speed-ups of SoT and SoT-R on different models on the WizardLM dataset.\\nG.2.2 S PEED -UP BREAKDOWN :CATEGORIES\\nFig. 18 and Fig. 19 show the speed-ups of SoT-R on different question categories of Vicuna-80\\ndataset. The trained router achieves slightly higher speed-up on most of the categories (except for\\nknowledge ,writing , and fermi ). Fig. 20 and Fig. 21 show the speed-ups of SoT-R on different\\nquestion categories of WizardLM dataset. We can observe that on 19 out of 29 categories, using the\\nprompting router achieves higher speed-ups than using the trained router.\\n1.001.251.501.752.002.252.502.75mathcodingfermiwritingroleplaycounterfactualknowledgecommon-sensegeneric\\n0.90×0.96×1.01×1.10×1.17×1.75×1.95×2.05×2.11×\\n(a) Speed-ups of SoT-R with prompting router on dif-\\nferent question categories.\\n1.001.251.501.752.002.252.502.75mathwritingcodingfermiroleplaycounterfactualknowledgecommon-sensegeneric\\n1.00×1.00×1.00×1.00×1.23×1.79×1.87×2.10×2.26×(b) Speed-ups of SoT-R with trained router on different\\nquestion categories.\\nFigure 18: Speed-ups of SoT-R on different question categories of Vicuna-80 dataset\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00mathfermicounterfactualroleplaycodingcommon-sensewritinggenericknowledge\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nFigure 19: Speed-ups of SoT and SoT-R on different question categories of the Vicuna-80 dataset.\\n30', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 29}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00MathPhysicsReasoningCode GenerationEntertainmentT oxicityComplex FormatMultilingualCommon-SenseCode DebugBiologyArtMusicComputer ScienceRoleplayChemistryEthicsAcademic WritingTruthfulQAWrittingLiteraturePhilosophyLawSportMedicineHistoryT echnologyEconomyCounterfactual\\n0.85×0.94×1.02×1.02×1.03×1.12×1.14×1.22×1.24×1.25×1.34×1.47×1.54×1.54×1.58×1.62×1.67×1.69×1.74×1.77×1.85×1.90×1.90×1.93×2.08×2.10×2.14×2.18×2.23×\\n(a) Speed-ups of SoT-R with prompting router on dif-\\nferent question categories.\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00Code GenerationEntertainmentArtComplex FormatMathLiteratureCode DebugLawAcademic WritingPhilosophyBiologyReasoningPhysicsHistoryComputer ScienceMultilingualMusicT oxicityRoleplayCommon-SenseTruthfulQAWrittingEconomyChemistryEthicsSportT echnologyMedicineCounterfactual\\n0.99×1.00×1.00×1.00×1.00×1.00×1.00×1.00×1.00×1.00×1.07×1.09×1.14×1.16×1.17×1.17×1.20×1.22×1.36×1.37×1.41×1.49×1.65×1.73×1.82×2.01×2.17×2.26×2.41×(b) Speed-ups of SoT-R with trained router on different\\nquestion categories.\\nFigure 20: Speed-ups of SoT-R on different question categories of WizardLM dataset\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00EntertainmentPhysicsReasoningMultilingualMathCommon-SenseBiologyArtMusicT oxicityEthicsComputer ScienceCode DebugChemistryLiteratureAcademic WritingPhilosophyLawTruthfulQARoleplayCode GenerationComplex FormatSportWrittingMedicineHistoryT echnologyEconomyCounterfactual\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nFigure 21: Speed-ups of SoT and SoT-R on different question categories of the WizardLM dataset.\\nH O VERHEAD OF SOTINDIFFERENT SCENARIOS\\nDespite the optimizations made to the decoding phase, SoT brings overhead to the prefilling phase as\\nthe model needs to handle additional SoT prompts. Table 6 reports SoT’s prefilling overhead for the\\nAPI-based models. These statistics are averaged across the Vicuna-80 questions that are suitable for\\nSoT (according to our manual annotation). We can see that SoT significantly increases the number\\nof prefilling tokens. This is because that SoT issues an independent point-expanding request for\\neach point, with the average number of points being 6.8 on Vicuna-80 dataset across all evaluated\\nmodels. Consequently, the APIs need to prefill the point-expanding request multiple times.\\n31', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 30}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nTable 6: SoT’s prefilling token overhead for API-based models.\\nModelPrefill Phase\\nNormal SoT Stage 1 SoT Stage 2 Ratio (SoT / Normal)\\nClaude 12.52 171.41 808.91 78.30\\nChatGPT-3.5 12.52 171.41 591.31 60.92\\nGPT-4 12.52 171.41 983.09 92.21\\nWhen using SoT to serve the open-source models, a simple and small trick is to prefill the common\\nprefix of point-expanding requests with a batch size of 1 during Stage 2 (i.e., the point-expanding\\nstage). Table 7 shows the prefilling overhead after applying the trick. Although the ratio is consid-\\nerably smaller compared to that of the API-based models, this computational overhead remains a\\nconcern, especially during periods of high system workload.\\nThere are some possibilities to further reduce the token and computational overhead that are worth\\nexploring in future work. To name a few: (1) When using SoT in serving systems, we can simply\\nreuse the key-value cache containing the question and skeleton from Stage 1 during Stage 2, rather\\nthan re-prefilling them as in a multi-round conversation. (2) Generally, as LLM capabilities continue\\nto evolve and prompt tuning techniques advance (Shin et al., 2020; Li & Liang, 2021; Lester et al.,\\n2021), the possibility of using much shorter prompts to activate the SoT mode in the future holds\\npromise, which would significantly mitigate the token or computational overhead.\\nTable 7: SoT’s computational overhead (in terms of the number of prefilling tokens) for open-source\\nmodels.\\nModelPrefill Phase\\nNaive SoT Stage 1 SoT Stage 2 Ratio (SoT / Normal)\\nLLaMA2-Chat-7B 12.52 171.41 216.49 30.98\\nLLaMA2-Chat-13B 12.52 171.41 216.41 30.98\\nOpenChat-13B 12.52 171.41 234.38 32.41\\nVicuna-7B V1.3 12.52 171.41 211.61 30.59\\nVicuna-13B V1.3 12.52 171.41 273.39 35.53\\nVicuna-33B V1.3 12.52 171.41 258.88 34.37\\nStableVicuna-13B 12.52 171.41 312.03 38.61\\nUltraLM-13B 12.52 171.41 290.88 36.92\\nVicuna-7B V1.1 12.52 171.41 196.64 29.40\\nI A NSWER QUALITY EVALUATION\\nI.1 S KELETON -OF-THOUGHT\\nI.1.1 A NSWER ANALYSIS : DIFFERENT MODELS\\nModels on which SoT has low net win rates. We observe two types of reasons for the low net win\\nrates.\\n(1) OpenChat-13B, Vicuna-7B V1.1, and LLaMA2-Chat-13B. For the weak models such as\\nOpenChat-13B and Vicuna-7B V1.1, they are not able to follow the SoT prompts precisely. For\\nOpenChat-13B and LLaMA2-Chat-13B, sometimes the skeleton contains undesired contents (e.g.,\\ncompleting the skeleton points as shown below).\\n32', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 31}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: How many lightning strikes occur on Earth each day? Try to explain your answer. Your\\nexplanation should take the reader through your reasoning step-by-step.\\nSoT’s answer (OpenChat-13B) (Orange texts are the skeleton.)\\n(Only showing the skeleton)\\n1.Introduction.\\n2. The Earth’s atmosphere.\\n3. Lightning formation.\\n4. Electrical discharge.\\n5. Lightning strikes per second.\\n6. Calculating the total.\\nSkeleton:\\n1. Introduction.\\nLightning is a beautiful and awe-inspiring natural phenomenon, but it can also be dangerous. It occurs when positively\\ncharged particles in a thundercloud discharge to the negatively charged Earth. The process is still not fully understood,\\nbut scientists have been able to estimate how many lightning strikes occur on Earth each day.\\nSkeleton:\\n1. The Earth’s atmosphere.\\nThe Earth’s atmosphere plays a crucial role in the formation of lightning. It consists of different layers, with the tropo-\\nsphere being the lowest and most active. The troposphere is where most of the weather occurs, and it is where lightning\\nprimarily forms. The atmosphere’s temperature, humidity, and wind patterns all contribute to the likelihood of a lightning\\nstrike.\\nSkeleton:\\n2. Lightning formation.\\nWhen warm, moist air rises, it cools and forms water ¡more texts are omitted...¿\\nFor both OpenChat-13B and Vicuna-7B V1.1, sometimes they do not write anything in the point-\\nexpanding stage when details are needed.\\nQuestion: As a superhero, how would you explain your origin story to a curious child?\\nSoT’s answer (Vicuna-7B V1.1) (Orange texts are the skeleton.)\\n1. Born with extraordinary abilities.\\n2. Trained to use powers for the greater good.\\n3. Protecting the innocent and fighting villains.I use my powers to defend the defenseless and bring justice to those who\\nhave been wronged.\\n4. Inspired by courage, justice, and selflessness.\\nThese two issues result in bad net win rates.\\n(2) Claude. For strong models such as Claude, we do not see major issues with SoT’s answers except\\nthe common issues across all models discussed in § 3.2.3. We hypothesize that the low net win rates\\nare majorly due to the fact that their normal sequential generation is already very good.\\nModels on which SoT has high net win rates. The models with high net win rates (Vicuna-13B\\nV1.3, StableVicuna-13B, and UltraLM-13B) are between the above two extremes. On one hand,\\nthey are good enough to understand SoT prompts. While we observe that they sometimes have the\\nsame issues as OpenChat-13B and Vicuna-7B V1.1 discussed before, these issues happen much less\\nfrequently. On the other hand, their normal sequential generation performance has a larger room for\\nimprovement than Claude and ChatGPT-3.5 so that the benefits from SoT are more visible on these\\nmodels.\\nI.1.2 A NSWER ANALYSIS : DIFFERENT QUESTION CATEGORIES\\nCategories on which SoT has low net win rates.\\n(1) Math. Math questions require step-by-step thinking. Without knowing the previous steps, it is\\nhard to derive the following steps. Chain-of-Thoughts (Kojima et al., 2022; Wei et al., 2022) empha-\\nsize the importance of expanding the sequential thinking steps to solve these problems successfully.\\nIn contrast, SoT requires the models to (a) come up with the skeleton of the solution first and (b)\\ndeduce each individual step independently without referring to previous results. Both of these are\\nchallenging tasks. Strong models are able to get (a) correct but fail at (b). In the following example,\\nChatGPT-3.5 gets the skeleton steps correct. However, without knowing the results from the first\\nstep, the model starts making mistakes in the second step.7\\n7One additional (minor) issue of the API-based ChatGPT-3.5 is that the skeleton point “1.” is repeated in\\nthe answer.\\n33', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 32}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: (Math) Solve for x in the equation 3x + 10 = 5(x - 2).\\n✗SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Move all x terms to one side. 1. Move all x terms to one side by subtracting 5x from both sides, giving -2x + 10 = -10.\\n2. Move all constant terms to the other side. This can be done by subtracting 5x - 10 from both sides, leaving 3x - 5x =\\n-10 - 10.\\n3. Simplify the equation. Combine like terms on both sides of the equation to get 3x + 10 = 5x - 10.\\n4. Divide both sides by the coefficient of x. Divide both sides by 2 to get x = -5.\\n5. Check the solution by plugging it back into the original equation.Substitute the value of x obtained in step 4 back into\\nthe original equation and verify that both sides are equal.\\n✓Normal answer (ChatGPT-3.5)\\n3x + 10 = 5(x - 2) can be simplified as follows:\\n3x + 10 = 5x - 10 (distribute the 5 on the right side)\\n10 + 10 = 5x - 3x (subtract 3x from both sides)\\n20 = 2x (combine like terms on the right side)\\nx = 10 (divide both sides by 2)\\nTherefore, the solution for x in the equation 3x + 10 = 5(x - 2) is x = 10.\\nFor weaker models, it is hard to even get step (a) correct. For example, as shown below, the third\\nstep “Apply FOIL” in Vicuna-13B V1.3’s SoT solution comes out of nowhere. This makes SoT’s\\nsolution incorrect (though the solution from the normal generation is also incorrect).\\nQuestion: (Math) Solve for x in the equation 3x + 10 = 5(x - 2).\\n✗SoT’s answer (Vicuna-13B V1.3) (Orange texts are the skeleton.)\\n1. Simplify equation.\\nWe can simplify the equation by combining like terms:\\n3x + 10 = 5(x - 2)\\n=¿ 3x + 10 = 5x - 10\\n=¿ x + 5 = 2\\n=¿ x = 2 - 5\\n=¿ x = -3\\n2. Factor 5(x - 2).\\n5(x - 2) = 5x - 10.\\n3. Apply FOIL.\\n* Multiply the binomials in the equation, using the first term of each binomial for the first term of the product, the outside\\nterm for the second term of the product, the second term of each binomial for the third term of the product, and the\\nremaining terms for the fourth term of the product.\\n* 3(x - 2) + 10 = 5x + 5(-2)\\n* 3x - 6 = 5x - 10\\n* 3x = 5x - 10\\n* x = 5x - 10 / 3\\n* x = 5/3x - 10/3\\n* x = 2/3x - 5/3\\n4. Solve for x.\\nAfter applying the FOIL method and simplifying the equation, we get 3x = 17. Therefore, x = 17/3.\\n✗Normal answer (Vicuna-13B V1.3)\\nTo solve for x in the equation 3x + 10 = 5(x - 2), we need to first distribute the 5 to multiply both sides by 5.\\n3x + 10 = 5(x - 2)\\n5(3x + 10) = 5(x - 2)\\n15x + 50 = 5x - 10\\nAdd 5x to both sides:\\n20x + 50 = 5x\\nSubtract 5x from both sides:\\n15x = 0\\nDivide both sides by 15:\\nx = 0\\nTherefore, the solution to the equation is x = 0.\\n(2) Fermi. Similar to math questions, questions in the fermi category require solvers to make as-\\nsumptions and calculate the answer step-by-step. For example, to answer the question in the figure\\nbelow, the solver is required to make an assumption about when life began on Earth. In step 4,\\nChatGPT-3.5 does not know that it has already assumed 3.5 billion years in step 3 and uses the\\nwrong number 4.54 billion in the calculation. In step 5, ChatGPT-3.5 does not know that it has\\nalready made the above assumptions and refuses to answer “due to the uncertainties in estimating\\nthe age of the Earth”. In contrast, normal generation is able to create a consistent solution.\\n34', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 33}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: (Fermi) How many times has the Earth orbited the Sun since the beginning of life? Try\\nto explain your answer. Your explanation should take the reader through your reasoning step-by-step.\\n✗SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Estimate the age of the Earth. The age of the Earth is estimated to be around 4.54 billion years, based on radiometric\\ndating of rocks and meteorites.\\n2. Determine when life began on Earth. Life on Earth is estimated to have begun around 3.5 billion years ago, based on\\nthe discovery of ancient microfossils.\\n3. Calculate the number of years since life began. The oldest known fossils suggest that life on Earth began around 3.5\\nbillion years ago. Therefore, the number of years since life began on Earth is approximately 3.5 billion years.\\n4. Divide the number of years by the length of one orbit. Assuming an orbital period of 365.25 days, the Earth has\\norbited the Sun approximately 4.54 billion / 365.25 = 12,425,000 times since the beginning of life.\\n5. The Earth has orbited the Sun approximately X times since the beginning of life. Unfortunately, it is impossible to give\\na specific number for the amount of times the Earth has orbited the Sun since the beginning of life due to the uncertainties\\nin estimating the age of the Earth and when life first emerged.\\nNormal answer (ChatGPT-3.5)\\nThe beginning of life on Earth is estimated to have occurred around 3.5 to 4 billion years ago. Since that time, the Earth\\nhas been orbiting the Sun continuously.\\nThe length of one orbit, or one year, is approximately 365.25 days. This means that the Earth completes one full orbit\\naround the Sun every 365.25 days.\\nTo calculate the number of times the Earth has orbited the Sun since the beginning of life, we can divide the total number\\nof days by the length of one orbit:\\nTotal number of days since the beginning of life = (3.5 billion years) x (365 days per year) = 1.2775 trillion days\\nNumber of orbits = (1.2775 trillion days) / (365.25 days per orbit) = 3.5 billion orbits\\nTherefore, the Earth has orbited the Sun approximately 3.5 billion times since the beginning of life.\\nAs the following example shows, there are also cases when SoT solves the question (with minor\\ncomputation errors) by embedding the computation steps in the skeleton directly in the skeleton\\nstage. The point-expanding stage will then add little content (except some undesired repetition of\\nthe following skeletons occasionally). This happens both on small/weak models and large/powerful\\nmodels. Although this behavior is not what we originally expect, it sheds light on a promising direc-\\ntion for making SoT a general framework: in the problem where step-by-step thinking is needed, the\\nSoT model automatically falls back to the sequential generation mode by outputting the complete\\nanswer in the skeleton stage and skipping the point-expanding stage. Future work needs to be done\\nto control and encourage this behavior better.\\nQuestion: (Fermi) How many times does the average human blink in a lifetime? Try to explain your\\nanswer. Your explanation should take the reader through your reasoning step-by-step.\\nSoT’s answer (Vicuna-7B V1.1) (Orange texts are the skeleton.)\\n1. The average human blinks 12-15 times per minute.\\n2. There are 60 minutes in an hour.\\n3. Therefore, the average human blinks 60 x 12-15 = 720-900 times per hour.\\n4. There are 24 hours in a day.Therefore, the average human blinks 720-900 x 24 = 17,520-22,400 times per day.\\n5. Therefore, the average human blinks 720-900 x 24 = 17,520-22,400 times per day.This translates to blinking approxi-\\nmately 50-65 times per hour, which is a significant portion of the day.\\n6. There are 365 days in a year.Therefore, the average human blinks 17,520-22,400 x 365 = 5,857,600-8,124,000 times\\nper year.\\n7. Therefore, the average human blinks 17,520-22,400 x 365 = 5,857,600-8,124,000 times per year.\\n8. The human lifespan is typically 70-80 years.Therefore, the average human blinks 80,000-112,000 times in their\\nlifetime.\\n9. Therefore, the average human blinks 5,857,600-8,124,000 / 70-80 = 80,000-112,000 times in their lifetime.\\nNormal answer (Vicuna-7B V1.1)\\nThe average human blinks about 12-15 times per minute, which translates to about 18,200 to 20,400 blinks per day. Over\\nthe course of a lifetime, the number of blinks is estimated to be around 7,500,000 to 8,000,000.\\nBlinking is a reflexive action that helps to keep the eyes moist and comfortable, as well as to protect the eyes from dust\\nand other foreign particles. The frequency of blinking can vary depending on a variety of factors, including age, health,\\nand environmental conditions. For example, people who work in dusty or dry environments may blink more frequently\\nthan those who work in a clean, moist environment.\\nOver the course of a lifetime, the average person will spend approximately 27,375 days or 700,000 hours awake. This\\nmeans that the majority of the time spent blinking will occur in the first few decades of life, with the frequency of blinking\\ngradually decreasing as people age.\\nIt is important to note that there is a significant amount of individual variation in the frequency of blinking. Some people\\nmay blink more or less than the average, depending on a variety of factors such as age, health, and environmental condi-\\ntions. Additionally, blinking patterns can be affected by factors such as stress, fatigue, and certain medical conditions.\\n35', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 34}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n(3) Coding. While in most cases, the models are able to decompose the coding problem into smaller\\ntasks in the skeleton stage, the generation quality during the point-expanding stage is bad, potentially\\ndue to the fact that we did not carefully craft a special point-expanding prompt for coding. The\\nfailure cases can be grouped into two cases. (a) In some cases, the model only generates a description\\nof how implementation can be done without giving the code.\\nQuestion: (Coding) Develop a C++ program that reads a text file line by line and counts the number\\nof occurrences of a specific word in the file.\\nSoT’s answer (Claude) (Orange texts are the skeleton.)\\n1. Open file stream by declaring an ifstream object and using the open() method to open the file in read mode.\\n2. Read line by line from the file stream into a string using getline().\\n3. Find word by searching each line for the target word using string::find and keeping track of matches.\\n4. Increment counter by one each time the specified word is encountered in the current line.\\n5. Close file\\nThe file stream should be closed after finishing reading the file to free up resources. This can be done by calling the\\nclose() method on the file stream object.\\nThis might be due to the fact that the powerful models (e.g., Claude) follow the point-expanding\\nprompt “Write it **very shortly** in 1 ∼2 sentence” precisely. Better prompts tailed to coding\\ncould help. (b) In some other cases, the model tends to generate the complete code repeatedly in\\nseveral points.\\nQuestion: (Coding) Develop a C++ program that reads a text file line by line and counts the number\\nof occurrences of a specific word in the file.\\nSoT’s answer (OpenChat-13B) (Orange texts are the skeleton.)\\n1. Read file line by line.\\n2. Store lines in a container.\\n3. Count occurrences of specific word.\\n“‘cpp\\n¡more texts are omitted...¿\\n“‘\\nThis code uses the C++ standard library to read a text file line by line, store each line in a container, and count the\\noccurrences of a specific word. The results are printed.\\n4. Print results.\\nHere’s the C++ program that reads a text file line by line and counts the number of occurrences of a specific word in the\\nfile:\\n“‘cpp\\n¡more texts are omitted...¿\\n“‘\\nPlease note that this is a very basic implementation. You may need to adjust it depending on your specific requirements.\\nThis problem might also be alleviated by prompts that explicitly tell the model to only generate a\\n“code snippet” in each skeleton point.\\nAlthough better prompt engineering could lead to better results, we expect that SoT is not suitable\\nfor the coding questions in Vicuna-80. The reason is that the solutions to the problems in Vicuna-\\n80 are usually in a few lines with strong dependencies between each other. Without knowing the\\npreviously defined variable names or imported libraries, it is hard (or even impossible) to implement\\nthe subsequent code correctly. As a consequence, generating different parts of the answers in parallel\\nis not suitable here. Similar to the math questions, automatically falling back to outputting all the\\ncode in the skeleton stage and not triggering the point-expanding stage might be more suitable for\\nanswering this question type.\\nHowever, we expect that SoT could be helpful for larger coding tasks that involve multiple modules\\n(e.g., functions, classes). The skeleton stage could be in charge of defining the interfaces between\\ndifferent modules (e.g., functionalities, names, parameters, return types). The point-expanding stage\\ncould be in charge of implementing these modules or using these modules to complete the final task,\\nwhich can be done in parallel. This mimics the common practice in software engineering.\\n(4) Writing. The writing questions usually ask for an email, a blog post, or a review in a given\\nscenario. In the detailed evaluation output from FastChat and LLMZoo metrics, the major and\\ncommon complaint is that SoT’s answers are (slightly) less detailed. This could potentially be\\nimproved by point-expanding prompts that request more details.\\n36', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 35}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nWhile inspecting SoT’s answers manually, we observe one additional issue. Writing problems usu-\\nally require a coherent passage without embedded skeleton points, whereas our current SoT pipeline\\n(§ 2) concatenates skeleton points as part of the answer. One example is shown below.\\nQuestion: (Writing) Can you help me write a formal email to a potential business partner proposing\\na joint venture?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Introduce yourself and your company. Dear [Recipient],\\nI hope this email finds you well. My name is [Your Name] and I am the [Your Position] at [Your Company Name].\\n2. State the purpose of the email. The purpose of this email is to propose a joint venture between our companies.\\n3. Explain the potential benefits of the joint venture. By combining our resources and expertise, we can increase market\\nshare and profitability for both companies.\\n4. Provide details on the proposed collaboration. Our proposed collaboration would involve combining our expertise in\\nmarketing with your strong manufacturing capabilities to create a new line of products.\\n5. Suggest a follow-up meeting or call. Please let me know your availability for a follow-up call next week to discuss\\nthis opportunity further.\\n6. Thank the recipient for their time and consideration.Thank you for considering this proposal and we look forward to\\nhearing back from you soon.\\nNormal answer (ChatGPT-3.5)\\nOf course, I can help you with that. Here’s a sample email you can use as a guide:\\nSubject: Proposal for Joint Venture\\nDear [Business Partner’s Name],\\nI hope this email finds you well. I am writing to propose a joint venture between our companies, [Your Company Name]\\nand [Potential Partner Company Name]. We believe that our respective expertise can create a successful partnership that\\nwill benefit both of our businesses.\\nWe have conducted thorough research on your company and admire your innovative approach to [insert industry or niche].\\nWe think our [insert expertise or specialty] could complement your [insert potential partner’s specialty or expertise].\\nBy collaborating on this joint venture, we believe we can create a new and innovative product that will appeal to our\\nrespective markets.\\nWe are confident that our companies would work well together and that our joint venture would be successful. We would\\nlike to set up a meeting to discuss the specifics of our proposal and explore how we can move forward with the joint\\nventure.\\nThank you for considering this proposal. We look forward to hearing from you soon.\\nBest regards,\\n[Your Name]\\nIn such cases, simply removing the skeleton points would greatly improve the answer quality. To\\nmake SoT more general, one future direction is to let the LLM itself decide whether the point index\\nand point skeleton should be included to make the final answer more natural and fluent.\\nCategories on which SoT has high net win rates.\\n(1) Counterfactual, knowledge, common sense, generic. All these four categories have the same\\ncharacteristic: the ideal answer should cover several relatively independent points. Having the LLM\\ngenerate a skeleton before expanding the details can result in more comprehensive discussions for\\nthe question. Besides, organizing the answers as a list of points makes the answers easier to read,\\nwhereas the answers from normal generation are sometimes less structured and less readable. Below,\\nwe give one example for each question category to illustrate these points.\\n37', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 36}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: (Counterfactual) What if the Internet had been invented during the Renaissance period?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Advancements in communication.The invention of the Internet during the Renaissance period would have revolution-\\nized communication, allowing for faster and more efficient exchange of ideas and information across vast distances.\\n2. Increased access to knowledge.The invention of the printing press during the Renaissance period already allowed\\nfor greater access to knowledge, but the internet would have revolutionized this even further by providing instantaneous\\naccess to information from all over the world.\\n3. Improved dissemination of ideas.If the internet had been invented during the Renaissance period, the spread of ideas\\nand knowledge would have been much faster and widespread than it was at the time. This could have led to a faster\\nprogression of scientific and artistic innovations.\\n4. Impact on art and literature.The invention of the internet during the Renaissance period would have revolutionized the\\nway art and literature are created, shared, and consumed, leading to a more diverse and globally-influenced artistic and\\nliterary scene.\\n5. Potential for global trade.The invention of the internet during the Renaissance period would have greatly expanded\\nglobal trade opportunities, allowing for easier communication and collaboration between merchants and traders across\\ncontinents.\\n6. Influence on political and social structures.The invention of the internet during the Renaissance period could have led\\nto significant changes in political and social structures, allowing for greater democratization and communication among\\npeople from different regions and classes.\\nNormal answer (ChatGPT-3.5)\\nIf the Internet had been invented during the Renaissance period, it would have had a significant impact on the way people\\ncommunicated, shared ideas, and gained knowledge. The Renaissance was a time of great intellectual and artistic growth,\\nand the Internet would have facilitated the spread of these ideas and innovations.\\nScholars and artists would have been able to share their work more easily, and people from different parts of the world\\nwould have been able to connect and collaborate more easily. The Internet would have also made it easier to access\\ninformation, which could have accelerated the pace of scientific and technological advancements.\\nHowever, it’s important to note that the infrastructure required for the Internet to exist did not exist during the Renaissance\\nperiod. There were no telecommunications networks or electricity grids, so the idea of the Internet would have been\\nimpossible to realize. Nonetheless, it’s interesting to think about how the Renaissance might have been different if the\\nInternet had existed at that time.\\n38', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 37}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: (Knowledge) What are some potential implications of using a single-use plastic bottle\\nversus a reusable bottle on both the environment and human health?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Single-use plastic waste.Single-use plastic bottles contribute to the massive amount of plastic waste that ends up in\\nlandfills and oceans, harming wildlife and ecosystems.\\n2. Pollution of waterways.Single-use plastic bottles contribute to the pollution of waterways, as they often end up in\\nrivers, lakes, and oceans, causing harm to aquatic life and the overall ecosystem.\\n3. Harmful chemicals leaching.Single-use plastic bottles may release harmful chemicals such as bisphenol A (BPA) and\\nphthalates into the water or liquid they contain, posing a risk to human health.\\n4. Greenhouse gas emissions.The production and disposal of single-use plastic bottles contribute to greenhouse gas\\nemissions, which contribute to climate change. Using a reusable bottle reduces the need for constant production and\\ndisposal, therefore reducing greenhouse gas emissions.\\n5. Microplastic ingestion.Single-use plastic bottles contribute to the accumulation of microplastics in the environment,\\nwhich can be ingested by humans through food and water, leading to potential health risks.\\n6. Increased risk of disease.Single-use plastic bottles can harbor harmful bacteria, leading to an increased risk of disease\\nif not disposed of properly. Reusable bottles, when cleaned regularly, pose a lower risk.\\nNormal answer (ChatGPT-3.5)\\nUsing a single-use plastic bottle has significant implications on the environment and human health.\\nEnvironmental implications:\\n1. Plastic pollution: Single-use plastic bottles are one of the major contributors to plastic pollution in oceans and landfills.\\nThey take hundreds of years to decompose, and during that time, they release toxic chemicals and microplastics into the\\nenvironment.\\n2. Carbon emissions: Manufacturing and transporting single-use plastic bottles require a significant amount of energy\\nand resources, which contribute to greenhouse gas emissions and climate change.\\n3. Natural resource depletion: The production of single-use plastic bottles requires large amounts of water and oil, which\\nare finite resources.\\nHealth implications:\\n1. Chemical exposure: Single-use plastic bottles contain chemicals such as Bisphenol A (BPA) and phthalates, which\\ncan leach into the water and pose a risk to human health.\\n2. Microplastics ingestion: When plastic bottles break down, they release microplastics, which can enter the food chain\\nand be ingested by humans.\\nUsing a reusable bottle, on the other hand, has a positive impact on the environment and human health.\\nEnvironmental benefits:\\n1. Reduced plastic waste: Reusable bottles significantly reduce the amount of plastic waste generated.\\n2. Lower carbon emissions: Reusable bottles have a lower carbon footprint as they can be used multiple times.\\n3. Reduced resource depletion: The production of reusable bottles requires fewer resources than single-use plastic bottles.\\nHealth benefits:\\n1. Chemical-free: Reusable bottles are typically made from materials that are free from harmful chemicals, reducing the\\nrisk of chemical exposure.\\n2. Reduced microplastics: Reusable bottles do not break down easily, reducing the release of microplastics into the\\nenvironment.\\nOverall, using a reusable bottle is a more sustainable and healthier option than using a single-use plastic bottle.\\nQuestion: (Common sense) How can you determine if a person is genuinely interested in a conver-\\nsation or simply being polite?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Pay attention to body language.Notice if their posture is open or closed, if they are facing towards you or away, and if\\nthey are fidgeting or relaxed. These can all indicate their level of interest in the conversation.\\n2. Listen for engaged responses.If the person is genuinely interested in the conversation, they will respond with thoughtful\\nand relevant comments or questions rather than short, generic responses.\\n3. Observe eye contact.If the person maintains steady eye contact and their gaze is focused on you, they are likely\\ngenuinely interested in the conversation. On the other hand, if they frequently look away or seem distracted, they may\\njust be being polite.\\n4. Look for follow-up questions.If the person asks follow-up questions and seems genuinely interested in what you’re\\nsaying, then they are likely interested in the conversation and not just being polite.\\n5. Notice tone of voice.A person who is genuinely interested in a conversation will often have a more enthusiastic and\\nanimated tone of voice, compared to someone who is simply being polite and giving short, monotone responses.\\nNormal answer (ChatGPT-3.5)\\nAs an AI assistant, I cannot determine a person’s true intentions or feelings. However, there are some social cues that\\ncan indicate whether a person is genuinely interested in a conversation or not. For example, if they maintain eye contact,\\nlean in, nod their head and ask follow-up questions, it can be a sign that they are engaged in the conversation. On the\\nother hand, if they avoid eye contact, give short or vague responses, or seem distracted, it may indicate that they are\\nnot as interested. Ultimately, it’s important to remember that everyone has different communication styles, and it can be\\ndifficult to accurately interpret someone’s intentions without directly asking them.\\n39', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 38}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: (Generic) How can I improve my time management skills?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Set clear goals. Setting clear goals is important in improving time management skills as it helps you to focus on what\\nneeds to be done and what can be accomplished within a certain timeframe.\\n2. Prioritize tasks. Make a list of tasks and prioritize them based on their importance and deadline. This will help you\\nfocus on the most critical tasks and avoid wasting time on less important ones.\\n3. Create a schedule. Creating a schedule helps you allocate time for each task and ensures that you complete them\\nwithin the allotted time.\\n4. Minimize distractions. Distractions such as social media, emails, and phone notifications can waste a lot of time. Try\\nto limit them by turning off notifications or setting specific times to check them.\\n5. Take breaks. Taking breaks can actually improve productivity and help prevent burnout. It’s important to schedule\\nshort breaks throughout the day to recharge and refocus.\\n6. Learn to say no. It’s important to prioritize your own tasks and not take on too much at once. Saying no to requests\\nthat don’t align with your goals or schedule can help you manage your time more effectively.\\n7. Delegate tasks. If you have too many tasks to handle, consider delegating some of them to others who can help you.\\nThis will allow you to focus on more important tasks and manage your time more effectively.\\n8. Use time management tools.There are a variety of time management tools available, such as calendars, to-do lists, and\\nproductivity apps, that can help you stay organized and on track with your tasks.\\nNormal answer (ChatGPT-3.5)\\nImproving time management skills can be a challenge, but there are several strategies that can help. Here are a few:\\n1. Set clear goals and priorities: Identify your most important tasks and make sure to complete them first.\\n2. Make a schedule: Create a schedule that includes your most important tasks and set aside time for them.\\n3. Use a timer: Set a timer for a specific amount of time to help you stay focused and avoid distractions.\\n4. Take breaks: Take short breaks throughout the day to help you recharge and avoid burnout.\\n5. Eliminate distractions: Try to limit distractions as much as possible, such as by turning off your phone or closing your\\nemail.\\n6. Delegate tasks: If possible, delegate tasks to others to free up time for more important activities.\\nRemember, improving time management skills takes practice and perseverance. Be patient with yourself and keep trying\\nuntil you find strategies that work well for you.\\n(2) Roleplay. Roleplay questions require LLMs to assume a character and present an introduction\\nor speech to other people. LLMZoo and FastChat metrics usually favor the level of details of SoT\\nwhen assigning it a better score. Similar to the writing category discussed before, SoT’s answers\\ncould be even better if the skeleton points are removed from the answer.\\nQuestion: (Roleplay) How would you introduce yourself as a medieval knight at a royal banquet?\\nSoT’s answer (Claude) (Orange texts are the skeleton.)\\n1. Name and house. My name is Sir Percival of Camelot, knight of the Round Table and protector of King Arthur’s\\nrealm.\\n2. Lands and titles. I hold fiefdom over the lands of Westmarch and Ravenshire, and bear the titles of Baron of the\\nWestern Marches and Knight of the Raven.\\n3. Military feats. I have led my men to great victories against the kingdom’s enemies, winning many battles through\\nstrength of arms and tactical cunning.\\n4. Allegiance to king. I pledge my sword, my loyalty, and my life to serve and protect my noble king and this great\\nkingdom.\\n5. Request to join table. Your Highness, it would be the greatest honor to join your exalted table and share in this\\nmagnificent feast with my fellow knights and loyal subjects.\\nNormal answer (Claude)\\nGreetings, your majesty and honored guests. I am Sir Claude, a knight in service of the king. I hail from the province\\nof Assistantia, where I was trained in the knightly virtues of chivalry, courage and courtesy. Though I am but a humble\\nknight, I shall endeavor to serve you and this kingdom with all the strength and valor I possess. I thank you for allowing\\nme to join you at this royal feast, and hope only that my conduct brings further honor to my liege and this noble court.\\nPlease let me know if I can be of any service during the celebrations, as it would be my honor to assist you in any way.\\nI.1.3 A NSWER ANALYSIS : DIFFERENT METRICS\\nMetrics on which SoT has low net win rates.\\n(1) Coherence. In the prompt of LLMZoo evaluation, coherence is defined as “The response should\\nbe coherent and flow logically from one point to the next that is easy to read and understand without\\nmajor gaps or inconsistencies. The more coherent they are, the better.” SoT’s answer is structured in\\na list of points. It is suitable for some questions but not all. For example, in the questions that require\\n40', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 39}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nLLMs to write a passage, email, or script, the introduction and conclusion paragraphs are usually\\nmissing, and the answers usually lack transition sentences between consecutive points. These make\\nthe answers less coherent. Below is one example from Claude.\\nQuestion: Write a script for a YouTube video exploring the history and cultural significance of jazz.\\nSoT’s answer (Claude) (Orange texts are the skeleton.)\\n1. Origins. Jazz originated in the late 19th and early 20th centuries among African Americans in New Orleans, emerging\\nfrom a combination of African rhythmic traditions, blues, ragtime, and other influences.\\n2. Early jazz styles. The early styles of jazz that emerged in the late 19th and early 20th centuries included ragtime,\\nDixieland, and the blues.\\n3. Jazz age. The Jazz Age was the period during the 1920s when jazz music and dance styles like the Charleston became\\npopular cultural phenomena in American and European society.\\n4. Bebop era. Bebop emerged in the early 1940s with artists like Dizzy Gillespie and Charlie Parker experimenting with\\nfaster tempos, complex chord changes, and unpredictable melodic phrasing.\\n5. Cool jazz. Emerging in the late 1940s and early 1950s, cool jazz was a more subdued, mellow style that broke from\\nthe high-energy virtuosic improvisation of bebop.\\n6. Free jazz emerged in the late 1950s and 1960s as musicians explored free improvisation and atonality, moving away\\nfrom traditional jazz structures.\\n7. Fusion jazz. Major jazz artists such as Miles Davis and Herbie Hancock began experimenting with combining elements\\nof rock, funk, and electronic music in the 1970s, resulting in the emergence of the subgenre known as fusion jazz.\\n8. Jazz festivals. Jazz festivals emerged in the 1950s and 1960s as a way to celebrate jazz music, with famous early\\nfestivals like the Newport Jazz Festival bringing thousands of fans together to hear top performers.\\n9. Jazz instruments. The trumpet, saxophone, piano, double bass, and drum set are some of the key instruments com-\\nmonly used in jazz.\\n10. Influential musicians include Louis Armstrong, Duke Ellington, Charlie Parker, Miles Davis, John Coltrane, and\\nmany others who pioneered new styles and techniques.\\n11. Legacy and impact. Jazz has left an indelible mark on music and culture over the past century, influencing countless\\nartists and genres while spreading the spirit of improvisation and freedom across the globe.\\nNormal answer (Claude)\\nHere is a draft script for a YouTube video exploring the history and cultural significance of jazz:\\nIntroduction\\nHey everyone! Welcome to my channel. In today’s video, we’re going to be exploring the history and cultural impact of\\none of America’s original art forms - jazz music.\\nJazz Origins\\nJazz grew out of the African American communities in the southern United States in the late 19th and early 20th centuries.\\nIt was influenced by a combination of African and European musical traditions. Some key elements that fed into early\\njazz included blues, ragtime, spirituals, work songs, field hollers, and brass band music.\\nNew Orleans is considered the birthplace of jazz, emerging around the turn of the 20th century. The city was a melting\\npot of cultures and musical styles. Musicians mixed improvisation, syncopated rhythms, bent notes and a loose ensemble\\nplaying style to create a new genre that became known as jazz.\\nEarly jazz greats like Buddy Bolden, Jelly Roll Morton and Sidney Bechet began fusing these various influences into the\\ndistinct jazz sound. As the music spread via travel and recordings in the 1910s, jazz captivated listeners and began to\\nevolve into different styles.\\nJazz Styles Emerge\\nIn the 1920s, jazz expanded out from New Orleans and Chicago emerged as a hotspot. Louis Armstrong’s innovative\\nsolos and expressive phrasing became influential. The swing style also developed during the 1930s and 40s, propelled\\nby star big bands and dancers.\\nBebop arose in the 1940s with soloists like Charlie Parker and Dizzy Gillespie exploring new levels of harmonic and\\nrhythmic complexity. In the 50s and 60s, jazz expanded into new fusions like cool jazz, hard bop, free jazz, modal jazz\\nand soul jazz. Artists used jazz to express their unique regional, social and political identities.\\nCultural Significance\\nOver the decades, jazz has become woven into the fabric of American society. It is equated with many values and ideals\\nlike individualism, freedom, spontaneity, innovation and social harmony.\\nJazz was associated with breaking down barriers between races, classes and genres. It represented modernism and urban\\nculture. Musicians like Louis Armstrong and Duke Ellington became some of the first widely popular African American\\nartists.\\nJazz also spread American culture and values abroad through performances, radio and film. It influenced music around\\nthe world and became a truly global art form.\\nToday jazz continues to thrive and evolve both in the U.S. and internationally. Its history and sounds reflect the diversity\\nof both American and global cultures. From its folk roots, jazz has become a sophisticated art music that retains its spirit\\nof freedom and improvisation.\\nConclusion\\nThat covers some of the key points in the history and cultural impact of jazz music. Let me know in the comments about\\nyour favorite jazz styles and musicians! Be sure to like and subscribe. See you next time.\\nWhile the content of SoT’s answer is good, it reads less fluent for the purpose of a YouTube script.\\n(2) Immersion. In the prompt of LLMZoo evaluation, immersion is defined as “the response should\\nact like the assigned role using the tone, manner, and vocabulary the role would use. The more\\nassistant-like tones, the worse. The more in-character, the better.” The way that SoT breaks the\\n41', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 40}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nanswers into a list makes its answer less in-character. Therefore, SoT receives a lower immersion\\nscore. Here is one example.\\nQuestion: Pretend to be a world-famous chef. How would you describe your signature dish to a\\npanel of judges?\\nSoT’s answer (Claude) (Orange texts are the skeleton.)\\n1. Main ingredient: The incredibly fresh and tender salmon caught just this morning from the crystal clear waters of the\\nPacific Northwest.\\n2. Cooking method\\nI slowly braise the main ingredient in a rich broth to bring out its natural flavors before searing it to a perfect golden crust.\\n3. Special seasoning\\nThe dish is seasoned with a blend of fresh herbs like thyme, rosemary, and oregano which provides an aromatic backbone\\nthat pairs nicely with the natural flavors of the main ingredients. I add just a touch of smoked paprika to provide a subtle\\nsmokiness without overpowering the other flavors.\\n4. Texture: The dish has a perfect balance of crispy on the outside and tender on the inside, with each bite yielding a\\ndelightful mix of crunchy and smooth textures that dance across your tongue.\\n5. Plating presentation\\nI purposefully create height and dimension on the plate with the carefully arranged components of the dish, so that the\\ndish appears vibrant and alive. The interplay of colors, textures and shapes is intended to delight the eye before the first\\nbite.\\n6. Inspiration: This dish was inspired by my dear grandmother, who taught me the secret family recipe when I was just\\na child.\\nNormal answer (Claude)\\n*clears throat and speaks in a fancy French accent*\\nBonjour honored judges. Today I present to you my signature dish - la cr `eme de la cr `eme of French haute cuisine.\\nBehold, le poulet `a la Claude!\\nThis succulent chicken is firstly marinated overnight in a bath of fine herbes - thyme, rosemary, and sage cultivated from\\nmy private garden. The young spring chicken is then roasted to perfection, its skin crisping to a beautiful caramel brown.\\nNestled beside the chicken is a tower of pommes dauphine - light and airy potato puffs - alongside a decadent mound of\\ncr`eme fra ˆıche infused with truffle essence.\\nBut the pi `ece de r ´esistance is the sauce. A luxurious pool of velout ´e enriched with cream and butter, brightened with a\\ndash of lemon, and studded with morsels of morel mushrooms foraged at dawn.\\nOne bite of this ensemble will transport you to food heaven. The tender chicken, the creaminess of the potato puffs, and\\nthe rich decadence of the sauce meld together in blissful harmony.\\nSo tell me honored judges, will my poulet `a la Claude earn your coveted approval? I await your discerning verdict as I\\nswirl more vintage Bordeaux into your glasses. Sant ´e!\\nAgain, while the answer from SoT covers sufficient aspects and details, it reads rather stiffly. The\\nnormal answer, in contrast, has the opening sentence ”Bonjour honored judges. Today I present to\\nyou my signature dish...” and the conclusion statement ”So tell me honored judges, will my poulet `a\\nla Claude earn your coveted approval? ...” which reads more like a casual talk from a chef.\\nMetrics on which SoT has high net win rates.\\n(1) Diversity. In the prompt of LLMZoo evaluation, diversity is defined as “The response should\\nbe comprehensive and provide a range of information that is not limited to a single perspective.\\nMore perspectives are better.” The skeleton stage in SoT encourages LLMs to think from multiple\\nperspectives. Therefore, SoT’s answers tend to have better diversity. Below is one example showing\\nthat SoT’s answer has better diversity.\\n42', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 41}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: How can you determine if a person is genuinely interested in a conversation or simply\\nbeing polite?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Pay attention to body language.Notice if their posture is open or closed, if they are facing towards you or away, and if\\nthey are fidgeting or relaxed. These can all indicate their level of interest in the conversation.\\n2. Listen for engaged responses.If the person is genuinely interested in the conversation, they will respond with thoughtful\\nand relevant comments or questions rather than short, generic responses.\\n3. Observe eye contact.If the person maintains steady eye contact and their gaze is focused on you, they are likely\\ngenuinely interested in the conversation. On the other hand, if they frequently look away or seem distracted, they may\\njust be being polite.\\n4. Look for follow-up questions.If the person asks follow-up questions and seems genuinely interested in what you’re\\nsaying, then they are likely interested in the conversation and not just being polite.\\n5. Notice tone of voice.A person who is genuinely interested in a conversation will often have a more enthusiastic and\\nanimated tone of voice, compared to someone who is simply being polite and giving short, monotone responses.\\nNormal answer (ChatGPT-3.5)\\nAs an AI assistant, I cannot determine a person’s true intentions or feelings. However, there are some social cues that\\ncan indicate whether a person is genuinely interested in a conversation or not. For example, if they maintain eye contact,\\nlean in, nod their head and ask follow-up questions, it can be a sign that they are engaged in the conversation. On the\\nother hand, if they avoid eye contact, give short or vague responses, or seem distracted, it may indicate that they are\\nnot as interested. Ultimately, it’s important to remember that everyone has different communication styles, and it can be\\ndifficult to accurately interpret someone’s intentions without directly asking them.\\nSoT answers the question from five aspects, whereas the normal answer only mentions one aspect.\\n(2) Relevance. In the prompt of LLMZoo evaluation, relevance is defined as “The response should\\nbe closely related to the question and answer the question accurately with sufficient details without\\nrepetition or redundancy. The more relevant they are, the better.” In the skeleton stage, LLMs are\\nforced to propose several points around the question; and in the point-expanding stage, LLMs are\\nrequired to only discuss these points. Therefore, answers from SoT tend to have better relevance.\\nOne typical example is shown below.\\nQuestion: Why do some people enjoy the sensation of being scared, such as by watching horror\\nmovies or going on roller coasters, while others avoid these experiences?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Neurological differences.Some people enjoy the sensation of being scared due to the release of adrenaline and\\ndopamine in the brain, while others may have a lower threshold for fear due to differences in their amygdala and pre-\\nfrontal cortex.\\n2. Psychological factors.Some people may enjoy the sensation of being scared because it can provide a sense of excite-\\nment, thrill, and a temporary escape from the mundane aspects of everyday life. On the other hand, others may avoid\\nthese experiences due to past trauma or anxiety.\\n3. Developmental experiences.Individuals who had negative experiences with fear during childhood, such as trauma\\nor abuse, may avoid scary situations as adults, while those who had positive experiences with fear may seek out these\\nexperiences.\\n4. Cultural influences.Some cultures place a greater emphasis on seeking excitement and thrill, while others may priori-\\ntize safety and security, which can impact whether individuals enjoy scary experiences or avoid them.\\n5. Genetics.Research has suggested that some individuals may have a genetic predisposition towards seeking out thrilling\\nor risky experiences, which may include enjoying the sensation of being scared.\\nNormal answer (ChatGPT-3.5)\\nThe enjoyment of being scared is a complex psychological phenomenon. Some people may enjoy the adrenaline rush\\nthat comes with being scared, while others may enjoy the feeling of being able to conquer their fears. Additionally,\\nsome people may be more naturally inclined to seek out new experiences and sensations, including those that are scary\\nor thrilling. On the other hand, some people may be more risk-averse or may have had negative experiences with fear or\\nanxiety in the past, which could make them more likely to avoid scary experiences. Ultimately, the reasons why some\\npeople enjoy being scared while others do not are likely to be influenced by a range of factors, including personality, past\\nexperiences, and individual preferences.\\nIn the answer from the normal generation, the first two sentences provide little information in an-\\nswering the question, and the last sentence only gives keywords such as “personality, past expe-\\nriences, and individual preferences” without providing concrete explanations to each. In contrast,\\n43', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 42}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n-20% 0% 20% 40% 60%counterfactualgenericcommon-senseknowledgeroleplayfermiwriting\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nSoT-R w/ human router\\nFigure 22: Net win rates of SoT and SoT-R on different question categories of Vicuna-80 dataset\\nusing the general quality metric from LLMZoo. Blue dots are from Fig. 5b. SoT-R correctly falls\\nback to normal decoding on questions where SoT is not suitable.\\n-60% -40% -20% 0% 20% 40%PhilosophyCounterfactualEthicsT echnologyLiteratureMusicSportRoleplayHistoryT oxicityPhysicsBiologyArtCommon-SenseLawTruthfulQAComputer ScienceAcademic WritingChemistryMathEconomyReasoningWrittingMedicineEntertainmentCode GenerationMultilingualComplex FormatCode Debug\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nSoT-R w/ human router\\nFigure 23: Net win rates of SoT and SoT-R on different question categories of WizardLM dataset\\nusing the general quality metric from FastChat. SoT-R correctly falls back to normal decoding on\\nquestions where SoT is not suitable.\\nSoT’s answer is well-structured into five reasons with sufficient explanations and it does not waste\\nspace in irrelevant contents.\\nI.2 S KELETON -OF-THOUGHT WITH ROUTER\\nFig. 22 shows net win rates of SoT on Vicuna-80 dataset with LLMZoo metrics, and Fig. 23 shows\\nnet win rates of SoT on WizardLM dataset with FastChat metrics. The key takeaways are: (1) In\\nboth cases, SoT-R achieves similar or better quality than SoT, and the net win rates of SoT-R are\\nusually non-negative. This indicates that SoT-R falls back to normal decoding on the right question\\ncategories. (2) On the WizardLM dataset, we see that the trained router has better performance than\\nthe prompting router in most cases. This is reasonable, as the prompting router is limited by the\\ncapability of GPT-4, whereas the trained router is dedicated to this task. (3) Sometimes, our routers\\ncan even achieve better performance than humans.\\nI.3 C HATGPT-3.5 AS THE JUDGE\\nIn this section, we provide quality evaluation results with ChatGPT-3.5 as the judge in FastChat and\\nLLMZoo metrics. Note that as prior work (e.g., (Li et al., 2023b)) shows, GPT-4-based evaluation\\nusually aligns with human better than ChatGPT-3.5. Therefore, readers should refer to the results\\nin the main paper (with GPT-4 as the judge) for a more accurate view of the performance of SoT.\\nHowever, the takeaway messages from ChatGPT-3.5 are similar to the ones from GPT-4.\\n44', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 43}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nI.3.1 O VERALL QUALITY\\nIn Fig. 24, we show the win/tie/lose rates (the percentage of the cases when SoT wins/ties/loses\\ncompared to normal generation) across all models and questions using the two metrics from FastChat\\nand LLMZoo that capture the general quality of the answers. We notice a discrepancy between the\\ntwo metrics on when SoT is strictly better than the baseline (50.2% v.s. 12.4%). Despite that, the two\\nmetrics agree that SoT is not worse than the baseline in more than 76% of the cases. For FastChat\\nmetric, we also show the rates excluding math and coding questions that SoT is not suitable for (see\\n§ 3.2.3); SoT is not worse than the baseline in more than 89% of the cases. This result suggests that\\nthe answers of SoT maintain good quality.\\n0% 20% 40% 60% 80% 100%General quality (LLMZoo)General quality (FastChat)\\n(excluding math & coding)General quality (FastChat)\\n50.2%12.5%12.4%\\n27.3%76.7%69.2%\\n22.5%10.8%18.4%Win Tie Lose\\nFigure 24: Win/tie/lose rates of SoT v.s. normal generation using “general” metrics from FastChat\\nand LLMZoo. SoT performs better than or equal to normal generation in around 80% of cases.\\n(Evaluated using ChatGPT-3.5 as the judge.)\\nI.3.2 Q UALITY BREAKDOWN : QUESTION CATEGORIES\\nNext, we investigate how SoT performs on different question categories. We compute net win rates\\n(win rates minus lose rates) across all question categories in Fig. 25. Similar to Fig. 24, we see\\nthat LLMZoo tends to be more optimistic about the quality of SoT than FastChat. Nevertheless,\\nthe conclusions are consistent: SoT performs relatively well on generic, common-sense, knowledge,\\nroleplay, and counterfactual. SoT performs relatively badly on writing, fermi, math, and coding.\\n-60%-50%-40%-30%-20%-10%0%10%20%counterfactualroleplayknowledgegenericcommon-sensefermiwritingmathcoding\\n(a) Metric: general quality (FastChat).\\n0% 10% 20% 30% 40%counterfactualroleplayknowledgegenericcommon-sensefermiwriting (b) Metric: general quality (LLMZoo).\\nFigure 25: Net win rates of SoT on different question categories. (Evaluated using ChatGPT-3.5 as\\nthe judge.)\\nI.3.3 Q UALITY BREAKDOWN : M ODELS\\nNext, we investigate how SoT performs on different models. We compute net win rates across all\\nmodels in Fig. 26. Again, we see that the two general metrics from FastChat and LLMZoo have\\ndifferent absolute values but similar rankings. In particular, both metrics agree that OpenChat-\\n13B, Vicuna-7B V1.1, Claude, ChatGPT-3.5 have lownet win rates, whereas Vicuna-13B V1.3,\\nStableVicuna-13B, and UltraLM-13B have high net win rates.\\nI.3.4 Q UALITY BREAKDOWN : QUESTION CATEGORIES AND MODELS\\nIn the main text, we analyze how question categories and models affect SoT’s answer quality inde-\\npendently . Here, we show their joint effect. For each model and question category, we compute the\\nnet win rates. The results are in Fig. 27.\\n45', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 44}), Document(page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n-15% -10% -5% 0% 5%Vicuna-13B V1.3StableVicuna-13BUltraLM-13BVicuna-33B V1.3GPT-4LLaMA2-Chat-7BLLaMA2-Chat-13BVicuna-7B V1.3ChatGPT-3.5ClaudeVicuna-7B V1.1OpenChat-13B\\n(a) Metric: general quality (FastChat).\\n-10% 0% 10% 20% 30% 40% 50% 60%Vicuna-13B V1.3StableVicuna-13BUltraLM-13BVicuna-33B V1.3GPT-4LLaMA2-Chat-7BLLaMA2-Chat-13BVicuna-7B V1.3ChatGPT-3.5ClaudeVicuna-7B V1.1OpenChat-13B (b) Metric: general quality (LLMZoo).\\nFigure 26: Net win rates of SoT on different models. (Evaluated using ChatGPT-3.5 as the judge.)\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BStableVicuna-13BVicuna-7B V1.1 Vicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3UltraLM-13BClaude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage-63% -43% -71% 0% -100% -86% -71% -57% -86% 43% -86% -100% -100%\\n-53% -33% -33% -67% -67% -100% -100% -67% 0% 33% -33% -100% -67%\\n-8% 10% 20% 10% -40% -40% -30% 20% 50% 0% -30% -40% -30%\\n6% 20% 0% -40% 10% 0% 10% 10% 0% 0% 20% 30% 10%\\n-12% 0% 0% -30% 10% -10% 10% 10% 0% -10% -30% 0% -90%\\n4% 0% 0% -10% 20% -10% 0% 10% 10% 0% 0% 0% 30%\\n2% -10% 0% -50% 30% 0% 0% 0% 10% 0% 0% 0% 50%\\n18% 0% 0% 20% 40% 20% 20% 40% 0% 0% -10% -10% 90%\\n2% 0% -20% -20% 20% -10% 0% 10% 0% -20% 10% 10% 40%\\n-12% -6% -12% -21% -9% -26% -18% -3% -2% 5% -18% -23% -7%\\n-100%-75%-50%-25%0%25%50%75%100%\\n(a) FastChat metric.\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BStableVicuna-13BVicuna-7B V1.1 Vicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3UltraLM-13BClaude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage10% 0% -57% 0% 17% 14% -14% 43% 57% 71% -29% 14% 0%\\n14% 0% 67% 0% 67% -33% -100% 67% 33% 67% 33% -67% 33%\\n20% 40% 60% -10% 20% -50% 30% 20% 50% 30% -10% 20% 40%\\n28% 20% 0% -10% 90% -20% 40% 50% 40% 20% 10% 50% 50%\\n8% 10% -10% 30% 60% 40% 30% 0% -10% 20% -60% -10% 0%\\n41% 40% 10% -40% 70% 40% 50% 50% 90% 70% 40% 40% 30%\\n26% -40% -30% -10% 90% 10% 60% 70% 30% 70% -40% 30% 70%\\n47% 60% 30% 60% 10% 0% 70% 80% 40% 70% -10% 50% 100%\\n24% 0% -30% -40% 90% -20% 20% 80% 50% 80% -20% 20% 60%\\n24% 14% 4% -2% 57% -2% 21% 51% 42% 55% -9% 16% 43%\\n-100%-75%-50%-25%0%25%50%75%100% (b) The “general” metric from LLMZoo.\\nFigure 27: Net win rates of different models and question categories. Each row corresponds to one\\nquestion category, and one column corresponds to one model. (Evaluated using ChatGPT-3.5 as the\\njudge.)\\nI.3.5 Q UALITY BREAKDOWN : M ETRICS\\nAll previous evaluations use metrics about the general quality of the answer. In Fig. 28, we show\\nmore detailed metrics from LLMZoo to reveal in which aspects SoT can improve or hurt the answer\\nquality. On average, we can see that SoT improves the diversity and relevance while hurting the\\nimmersion and coherence.\\n0% 20% 40% 60% 80% 100%CoherenceImmersionIntegrityRelevanceDiversity\\n28.3%32.7%34.5%50.0%49.4%\\n31.4%28.6%34.9%21.8%29.0%\\n40.2%38.7%30.6%28.2%21.5%Win Tie Lose\\nFigure 28: Win/tie/lose rates of SoT v.s. normal generations using metrics from LLMZoo. SoT per-\\nforms well on diversity and relevance, and relatively worse on coherence and immersion. (Evaluated\\nusing ChatGPT-3.5 as the judge.)\\n46', metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 45})]\n"
     ]
    }
   ],
   "source": [
    "print(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Error Type Error\\nNo preselections 15.8%\\nExpression misstep 5.3%\\nIncorrect pattern extraction 26.3%\\nErroneous word placement 52.6%\\nTable 4: Breakdown of errors in 5×5mini crosswords with\\nAoT. Numbers indicate the relative percentage of each error\\ntype among all errors.\\nsystematically navigates fewer nodes than its DFS counter-\\npart. While DFS employs a uniform strategy when choosing\\nthe subsequent subtree to investigate, AoT’s LLM integrates\\nits inherent heuristic. This amplification over the base algo-\\nrithm exemplifies the advantages of LLM’s recursive reason-\\ning capability.\\n0 200 400 600 800 1000\\n# of Visited Nodes048121620# of Games\\nDFS\\nAoT\\nFigure 5: Histogram showing the number of visited nodes\\nfor AoT and DFS in the Game of 24.\\nHow does algorithm selection influence AoT’s efficacy?\\nTo explore the impact of algorithm choice on AoT’s per-\\nformance, we implemented both BFS and random search\\nwithin the AoT framework. Our findings, presented in Ta-\\nble 5, reveal that all three AoT variations outperform the\\nsingle-query CoT. This outcome was anticipated as AoT, ir-\\nrespective of the algorithm, undertakes a search and revis-\\nits potential mistakes—either by random retry in the ran-\\ndom search variant or through backtracking in the DFS and\\nBFS configurations. Notably, the structured search versions,\\nAoT (DFS) and AoT (BFS), displayed better efficiency than\\nAoT (Random), underscoring the advantage of algorithmic\\ninsights in solution discovery. However, AoT (BFS) lagged\\nbehind AoT (DFS). Closer inspection of errors made by AoT\\n(BFS) revealed the LLM faced greater challenges in identi-\\nfying optimal operations than its DFS counterpart.\\nHow does the search step count within the algorithmic\\nexample modulate AoT’s behavior? We begin with the\\nstandard AoT prompt and modify the subtree explorations.\\nIn AoT (Short), each in-context example uses one or two\\nsteps to reach a solution, while AoT (Long) incorporates\\nthree to five extra subtree explorations. The impact on total\\nsearch steps is illustrated in Fig. 6. Our observations high-\\nlight longer generations for AoT (Long) and shorter onesMethod Success Avg. Queries\\nCoT 4% 1\\nCoT-SC (k=100) 9% 100\\nToT 69% 109 .1\\nAoT (DFS) 71% 1\\nAoT (BFS) 48% 1\\nAoT (Random) 20% 1\\nTable 5: Comparative success rates and average LLM query\\ncounts for AoT variations templated by distinct algorithms.\\nfor AoT (Short) relative to the original AoT. This suggests\\nthat the search step count introduces an implicit bias on the\\nLLM’s search velocity. Notably, even when navigating in-\\ncorrect steps, it’s essential to emphasize the exploration of\\npromising directions.\\n0 50 100 150 200 250 300 350 400\\n# of Visited Nodes020406080100# of Games\\nAoT (Short)\\nAoT\\nAoT (Long)\\nFigure 6: Comparison of AoT with shorter and longer in-\\ncontext examples prompted AoT versions: cumulative num-\\nber of games for the number of visited nodes.\\nLimitations. While AoT substantially cuts down on the\\nnumber of queries relative to ToT, its resource demands ex-\\nceed those of standard prompting and CoT, a consequence\\nof its extensive exploration of ideas via token generation.\\nCrafting token-efficient algorithmic examples is one avenue,\\nbut there’s also potential in judiciously tapping into or un-\\nlocking the LLM’s “tunnel-vision”. Our research primarily\\nspotlighted certain algorithms, with a keen focus on tree-\\nsearch tasks. It’s pertinent to highlight that we conducted our\\ntests exclusively with GPT-4. Though more costly than other\\nLLMs, GPT-4’s advanced capabilities appear pivotal for\\nAoT’s optimal functioning; models of lesser caliber might\\nnot yield comparable performance boosts from AoT.\\nConclusion\\nThis paper presents the Algorithm of Thoughts , a pioneer-\\ning prompting strategy to navigate reasoning pathways in\\nLLMs using minimal queries. Our findings reveal that this\\nmethod not only substantially surpasses prior single-query\\ntechniques but also rivals external tree-search implementa-\\ntions. Such an approach augments the potential to stream-\\nline idea discovery in LLMs, balancing both cost and com-\\nputational demands. Future work includes designing token-' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 6}\n"
     ]
    }
   ],
   "source": [
    "print(all_documents[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf',\n",
       " 'page': 16}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents[16].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5274"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_documents[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF caricati:\n",
      "page_content='Algorithm of Thoughts: Enhancing Exploration of Ideas\\nin Large Language Models\\nBilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Ruoxi Jia, and Ming Jin\\nVirginia Tech\\nAbstract\\nCurrent literature, aiming to surpass the “Chain-of-Thought”\\napproach, often resorts to an external modus operandi in-\\nvolving halting, modifying, and then resuming the genera-\\ntion process to boost Large Language Models’ (LLMs) rea-\\nsoning capacities. This mode escalates the number of query\\nrequests, leading to increased costs, memory, and computa-\\ntional overheads. Addressing this, we propose the Algorithm\\nof Thoughts —a novel strategy that propels LLMs through\\nalgorithmic reasoning pathways, pioneering a new mode of\\nin-context learning. By employing algorithmic examples, we\\nexploit the innate recurrence dynamics of LLMs, expand-\\ning their idea exploration with merely one or a few queries.\\nOur technique outperforms earlier single-query methods and\\nstands on par with a recent multi-query strategy that employs\\nan extensive tree search algorithm. Intriguingly, our results\\nsuggest that instructing an LLM using an algorithm can lead\\nto performance surpassing that of the algorithm itself, hinting\\nat LLM’s inherent ability to weave its intuition into optimized\\nsearches. We probe into the underpinnings of our method’s\\nefficacy and its nuances in application.\\nIntroduction\\nRecent developments in large language models (Chowdhery\\net al. 2022; Thoppilan et al. 2022; Liu et al. 2023, inter alia )\\nhave spotlighted their efficacy in general problem solving\\n(Huang and Chang 2022; Suzgun et al. 2022), code gen-\\neration (Chen et al. 2021; Austin et al. 2021), and instruc-\\ntion following (Ouyang et al. 2022; Bai et al. 2022). While\\nearly models relied on direct answer strategies (Brown et al.\\n2020), contemporary research veers towards linear reason-\\ning paths (Wei et al. 2022b; Kojima et al. 2022; Zhang et al.\\n2022) by breaking problems into sub-tasks for solution dis-\\ncovery, or harnesses external mechanisms to alter token gen-\\neration by changing the context (Zhou et al. 2022; Drozdov\\net al. 2022; Yao et al. 2023).\\nAnalogous to human cognition (Sloman 1996; Kahneman\\n2011), early LLM strategies seemed to emulate the instan-\\ntaneous System 1 , characterized by its impulsive decision-\\nmaking. In contrast, more recent methodologies like chain-\\nof-thought (CoT) (Wei et al. 2022b) and least-to-most\\nprompting (L2M) (Zhou et al. 2022; Drozdov et al. 2022)\\nPreprint. Under review.reflect the introspective nature of System 2 . Notably, inte-\\ngrating intermediary reasoning steps has yielded improve-\\nments in arithmetic reasoning tasks (Srivastava et al. 2022;\\nLiang et al. 2022).\\nHowever, as tasks shift towards deeper planning and ex-\\ntensive thought exploration, these methods appear restric-\\ntive. Although CoT integrated with Self-Consistency (CoT-\\nSC) (Wang et al. 2022) enlists multiple LLM outputs for\\na consensus, the lack of meticulous evaluation can result\\nin model misdirection. The “Tree of Thoughts” (Yao et al.\\n2023; Long 2023) emerges as a notable solution. While one\\nLLM is dedicated to idea generation, another steps in to as-\\nsess the merit of these ideas, following a halting-assessment-\\nresuming cycle. This iterative process, anchored by tree\\nsearch, has shown marked effectiveness, especially in tasks\\nwith a breadth of continuations. We see this progression\\nas akin to humans employing tools to circumvent working\\nmemory limitations, serving as an external augmentation for\\nLLMs (Mialon et al. 2023).\\nOn the flip side, this enhanced LLM approach is not\\nwithout pitfalls. A prominent downside is the substantial\\nsurge in the number of queries and computational demands.\\nEach query to online LLM APIs such as GPT-4—a focal\\npoint of our study—incurs a monetary expense (Chen, Za-\\nharia, and Zou 2023) but also contributes to latency, a sig-\\nnificant limitation especially critical in real-time applica-\\ntions. Cumulative delays from these queries can compro-\\nmise solution efficiency. Infrastructure-wise, continuous in-\\nteractions can stress systems, leading to potential bandwidth\\nconstraints and reduced model availability (Aminabadi et al.\\n2022). Moreover, the environmental implications cannot be\\nignored; incessant querying escalates the energy consump-\\ntion of already power-hungry data centers, exacerbating the\\ncarbon footprint (Wu et al. 2022; Dhar 2020).\\nWith this in mind, our goal is to dramatically reduce the\\nquery counts employed by contemporary multi-query rea-\\nsoning methods while maintaining performance for tasks ne-\\ncessitating adept use of world knowledge , thereby steering a\\nmore responsible and proficient use of AI resources.\\nReflecting on the evolution of LLMs from System 1 to\\nSystem 2, an essential ingredient comes to light: algorithms.\\nCharacterized by its methodical nature, the algorithmic per-\\nspective offers a path to keenly explore problem spaces, en-\\nact strategies, and formulate solutions (Helie and Pizlo 2022;arXiv:2308.10379v2  [cs.CL]  28 Sep 2023' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 0}\n",
      "page_content='Chain-of-Thought\\nModel \\nInput\\nModel \\nOutput\\nUser: \\n8 \\n6 \\n4 \\n4\\nAssistant: \\n8 \\n- \\n6 \\n= \\n2 \\n(left: \\n4, \\n4, \\n2)\\n4 \\n+ \\n2 \\n= \\n6 \\n(left: \\n6, \\n4)\\n6 \\n* \\n4 \\n= \\n24\\nAnswer: \\n(4 \\n+ \\n(8 \\n- \\n6)) \\n* \\n4 \\n= \\n24.\\n \\nUser: \\n11 \\n10 \\n5 \\n1\\nAssistant:\\n11 \\n- \\n10 \\n= \\n1 \\n(left: \\n1, \\n1, \\n5)\\n1 \\n* \\n1 \\n= \\n1 \\n(left: \\n1, \\n5)\\n5 \\n* \\n1 \\n= \\n5 \\n(left: \\n5)\\nAnswer: \\n((11 \\n- \\n10) \\n* \\n1) \\n* \\n5 \\n- \\n1 \\n= \\n24.\\nAlgorithm \\nof \\nThoughts\\nModel \\nInput\\nModel \\nOutput\\nUser: \\n8 \\n6 \\n4 \\n4\\nAssistant:\\n1. \\n4 \\n- \\n4: \\n(left: \\n8, \\n6, \\n0)\\n.\\n.\\n.\\n3. \\n8 \\n- \\n6: \\n(left: \\n4, \\n4, \\n2)\\n- \\n4 \\n+ \\n4: \\n(left: \\n8, \\n2) \\n10, \\n6, \\n16, \\n4\\n- \\n4 \\n- \\n4: \\n(left: \\n2, \\n0) \\n2, \\n2, \\n0, \\nundefined\\n- \\n4 \\n* \\n4: \\n(left: \\n16, \\n2) \\n18, \\n14, \\n32, \\n8\\n- \\n4 \\n/ \\n4: \\n(left: \\n2, \\n1) \\n3, \\n1, \\n2, \\n2\\n- \\n4 \\n+ \\n2: \\n(left: \\n6, \\n4) \\n10, \\n2, \\n24 \\n= \\n6 \\n* \\n4 \\n-> \\nfound \\nit!\\nAnswer: \\n(4 \\n+ \\n(8 \\n- \\n6)) \\n* \\n4 \\n= \\n24.\\n \\nUser: \\n11 \\n10 \\n5 \\n1\\nAssistant:\\n1. \\n11 \\n- \\n1: \\n(left: \\n10, \\n10, \\n5)\\n.\\n.\\n.\\n5. \\n11 \\n+ \\n1: \\n(left: \\n12, \\n10, \\n5)\\n- \\n12 \\n+ \\n10: \\n(left: \\n22, \\n5) \\n27, \\n17, \\n110, \\n4.4\\n- \\n12 \\n- \\n10: \\n(left: \\n5, \\n2) \\n7, \\n3, \\n10, \\n2.5\\n- \\n12 \\n* \\n10: \\n(left: \\n120, \\n5) \\n24 \\n= \\n120 \\n/ \\n5 \\n-> \\nfound \\nit!\\nAnswer: \\n((11 \\n+ \\n1) \\n* \\n10) \\n/ \\n5 \\n= \\n24.\\nStandard \\nPrompting\\nModel \\nInput\\nModel \\nOutput\\nUser: \\n8 \\n6 \\n4 \\n4\\nAssistant: \\nAnswer: \\n(4 \\n+ \\n(8 \\n- \\n6)) \\n* \\n4 \\n= \\n24.\\n \\nUser: \\n11 \\n10 \\n5 \\n1\\nAssistant:\\nAnswer: \\n(11 \\n- \\n1) \\n* \\n(10 \\n- \\n5) \\n= \\n24Figure 1: Comparison between standard prompting, CoT, and AoT in the game of 24. While standard prompting aims for a direct\\nanswer, CoT sketches out the successive steps to the final solution. AoT’s in-context example, distinct from CoT, integrates the\\nsearch process, highlighted by markers ‘1’,..., ‘3’ as “first operations” guiding subtree exploration for the problem set ‘8 6\\n4 4’. For clarity, only a single in-context example is displayed, with a focus on the third subtree exploration. AoT produces\\nprospective search steps (e.g., the subtree exploration ‘5. 11 + 1 ’) and evaluates potential subsequent steps to either progress\\ntowards a solution or retrace to another viable subtree.\\nBanerjee et al. 2022). While much of the prevailing literature\\ntreats algorithms as external to LLMs, given LLMs’ inher-\\nent generative recurrence, can we channel this iterative logic\\ntointernalize an algorithm?\\nDrawing upon both the intricate nuances of human rea-\\nsoning and the disciplined precision of algorithmic method-\\nologies, our work aims to fuse these dual facets to aug-\\nment reasoning capabilities within LLMs. Existing research\\nunderscores that humans, when navigating complex prob-\\nlems, instinctively draw upon past efforts, ensuring a com-\\nprehensive contemplation rather than a narrow focus (Mon-\\nsell 2003; Holyoak and Morrison 2005; Baddeley 2003).\\nLLMs, with their generative span bounded only by token\\nlimits, appear poised to break through the barriers of human\\nworking memory. Spurred by this observation, we investi-\\ngated if LLMs could mirror a similar layered exploration\\nof ideas, referencing prior intermediate steps to sieve out\\ninfeasible options, all within their iterative generation cy-\\ncle. And while humans excel with their intuitive acumen, al-\\ngorithms stand out with organized, systematic exploration.\\nCurrent techniques, like CoT, often sidestep this synergistic\\npotential, imposing undue pressure on LLMs for on-the-spot\\nprecision. By capitalizing on LLMs’ recursive capabilities,\\nwe emulate a hybrid human-algorithmic approach. This is\\nachieved through our use of algorithmic examples that cap-\\nture the essence of exploration, from initial candidates to\\nvalidated solutions. Thus emerges our concept of the Algo-\\nrithm of Thoughts (AoT), as illustrated in Figs. 1 and 2.More broadly, our approach signifies a new paradigm of\\nin-context learning. Instead of the traditional “supervised-\\nlearning” mold of [ PROBLEM ,SOLUTION ] or [ PROBLEM ,\\nSUCCESSIVE STEPS TO SOLUTION ], we present a new\\nstructure that covers [ PROBLEM ,SEARCH PROCESS ,SO-\\nLUTION ]. Naturally, when instructing an LLM using an al-\\ngorithm, the anticipation leans towards the LLM simply\\nimitating the algorithm’s iterative thinking. However, what\\nemerges as intriguing is the LLM’s ability to infuse its own\\n“intuition” to achieve a search efficiency that even surpasses\\nthe algorithm itself (see Fig. 5).\\nIn the subsequent sections, we first situate our work\\nwithin the existing literature, followed by a discussion of\\nour principal idea. We then present our experimental results\\nand probe a series of hypotheses related to this emerging ca-\\npability of LLM before rounding off with a conclusion.\\nRelated Work\\nStandard Prompting. Also known as input-output\\nprompting, it provides a few input-output examples of the\\ntask before getting an answer for the test sample from the\\nlanguage model (Brown et al. 2020). Although this method\\nis very general and does not need any special prompting\\nstrategy, the performance is also worse compared to more\\nadvanced methods (Shao et al. 2023; Wei et al. 2022a; Lyu\\net al. 2023).' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 1}\n",
      "page_content='Input\\nOutput\\nInput\\nOutput\\nInput\\nOutput\\nInput\\nOutput\\nStandard \\nPrompting\\nChain \\nof \\nThoughts\\nTree \\nof \\nThoughts\\nAlgorithm \\nof \\nThoughtsFigure 2: Illustration outlining various strategies for tackling reasoning problems with LLMs. Each box signifies a distinct\\nthought, functioning as a unified string of words that forms an incremental pathway to reasoning. Green boxes indicate ideas\\ndeemed promising by the LLM, while red boxes represent less promising concepts.\\nChain-of-Thought. In CoT, LLMs are presented with ex-\\namples where a given question xunfolds through a chain\\nof intermediate reasoning pieces c1, . . . , c nto reach an an-\\nswery, represented as x→c1→. . .→cn→y(Wei\\net al. 2022b; Lyu et al. 2023). By mimicking the examples\\nin the context, the LLM automatically divides the solution\\ninto simpler linear steps to arrive at the answer, improv-\\ning performance across numerous reasoning benchmarks.\\nSelf-consistency (Wang et al. 2022) is a widely used de-\\ncoding strategy aimed at generating a variety of reason-\\ning paths by choosing the final answer through a majority\\nvote, though this necessitates additional generations. Con-\\ntrary to CoT’s linear, direct progression, our approach pivots\\ntowards the explorative aspect of LLMs. We reconceptual-\\nize the c1, . . . , c nsequence, not merely as successive steps\\ntowards a solution, but as a dynamic, potentially mutable\\npath that resembles an algorithmic search, allowing for ex-\\nploration, recalibration, and non-linear progression.\\nLeast-to-Most prompting (L2M). Taking cues from ed-\\nucational psychology (Libby et al. 2008), L2M prompting\\ndirects the LLM to decompose the central problem into\\nsmaller subproblems. Each subproblem is tackled in se-\\nquence, with the outcome appended before progressing to\\nthe next (Zhou et al. 2022; Drozdov et al. 2022). While this\\nstructured delineation is beneficial for broader generaliza-\\ntion, it operates on the premise of finding a nearly perfect de-\\ncomposition in a single attempt—ideal for problems with a\\nclear-cut structure. Yet, when tasks intertwine with their de-\\ncomposition complexities (like games of 24), this method’s\\ninflexibility becomes apparent. Contrastingly, AoT not only\\nunderscores the active subproblem (as shown in Fig. 1), but\\nalso permits a more contemplative approach by entertaining\\nvarious options for each subproblem, while maintaining ef-\\nficacy even with minimal prompts.\\nTree of Thoughts (ToT). In the cases where each sub-\\nproblem has multiple viable options to explore, linear rea-\\nsoning paths from CoT or L2M substantially limit the cov-\\nerage of the thought space. Considering possible options for\\neach subproblem, the decision tree can be explored by ex-\\nternal tree-search mechanisms (e.g., BFS, DFS) (Yao et al.2023). Evaluation capabilities of LLMs can also be used to\\ndirect the search by pruning nodes that are hopeless to in-\\ncrease efficiency. However, ToT’s Achilles’ heel is its ex-\\ncessive reliance on LLM queries, at times necessitating hun-\\ndreds for just one problem. We tackle this limitation by gen-\\nerating the whole thought process within a single context.\\nAlgorithm of Thoughts\\nOur strategy pivots on recognizing a core shortcoming of\\ncurrent in-context learning paradigms. CoT, while enhanc-\\ning the coherency of thought linkages leading to solutions,\\noccasionally falters, presenting incorrect intermediate steps\\n(Zelikman et al. 2022; Turpin et al. 2023; Lanham et al.\\n2023). Faithful CoT (Lyu et al. 2023) ought to amend this\\nby eliciting symbolic chains of reasoning where the LLM’s\\noutput resembles task-specific pseudo-code, primed for de-\\nterministic execution like Python. The intention is only to\\nuse the thought processes but not the outputs and inputs of\\neach link since they have a tendency to be unreliable. But,\\nthe occasional missteps of CoT may not necessarily due to\\nthe LLM’s inability to compute correctly . The LLM, when\\nconfronted with questions that closely match conditions of\\nprevious in-context examples, may favor echoing those out-\\nputs over generating the appropriate questions. To shed light\\non this phenomenon, we designed an experiment. Querying\\ntext-davinci-003 for arithmetic tasks (e.g., ‘ 11−2 =’), we\\nprefixed them with multiple in-context equations converging\\nto an identical output (e.g. ‘ 15−5 = 10 ,8 + 2 = 10 ’). Our\\nresults, presented in Fig. 3, reveal a steep decline in accu-\\nracy, suggesting that the mere presence of correct reasoning\\nin the context might inadvertently compromise even basic\\narithmetic skills.\\nTo offset this bias, diversifying the outputs of examples\\nmight seem like a viable solution, but this could subtly skew\\nthe distribution of outputs. Merely adding unsuccessful tri-\\nals, much like a random search, might inadvertently encour-\\nage the model to retry rather than truly solve. Capturing\\nthe true essence of algorithmic behavior, where both failed\\nsearches and subsequent recovering and learning from such\\nattempts play a role, we incorporate in-context examples pat-' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 2}\n",
      "page_content='0 2 4 6 8 10 12\\n# of Equations0.00.20.40.60.81.0Probability of Correct T okenFigure 3: The probability of generating the correct token as\\nwe add more in-context examples that are correct but possess\\nidentical outputs.\\nterned after search algorithms , notably depth-first search\\n(DFS) and breadth-first search (BFS). See Fig. 1 for an ex-\\nample.\\nThis paper focuses on a broad class of tasks reminiscent of\\ntree-search problems. These tasks necessitate breaking down\\nthe main problem, crafting feasible solutions for each seg-\\nment, and making decisions on the paths to either pursue\\nor forsake, with the option of reevaluating more promising\\nsegmentations. Rather than posing separate queries for ev-\\nery subset, we leverage the iterative capabilities of the LLM\\nto address them in one unified generation sweep. By confin-\\ning ourselves to one or two LLM interactions, this approach\\nnaturally incorporates insights from antecedent context can-\\ndidates and tackles intricate issues requiring an in-depth ex-\\nploration of the solution domain. In alignment with our goal,\\nwe also give insights into how small or big those thoughts\\nshould be and what type of in-context examples should be\\ngiven to the LLM to promote token efficiency. Subsequently,\\nwe outline key components of tree-search algorithms and\\ntheir manifestation in our framework.\\n1. Decomposition into Subproblems. Given a problem,\\nconstructing a search tree that delineates feasible reasoning\\npathways is already a demanding task, excluding the actual\\nproblem-solving aspect. Any decomposition must consider\\nnot just the interrelations between subtasks, but also the ease\\nof addressing each individually. Consider a simple multi-\\ndigit addition: while converting numbers to binary might\\nbe efficient for a computer, humans typically find base 10\\narithmetic more intuitive. Furthermore, even if the subprob-\\nlems remain constant, their execution might vary. Intuition\\ncan lead to shortcuts between solution steps, while its ab-\\nsence might necessitate more detailed steps. Crafting the\\nright prompt (i.e., in-context algorithmic examples) hinges\\non these nuances, determining the minimal tokens an LLM\\nwould need for dependable performance. This is not only\\nessential to fit within the LLM’s context constraints but also\\nvital for efficacy, as we’d expect LLMs to address problems\\nresonant with its context using a similar token volume.\\n2. Proposing Solutions to Subproblems. A dominant ap-\\nproach in existing works involves direct sampling from\\nLLM token output probabilities (Wang et al. 2022; Yao\\nThe \\nfirst \\nfive \\nprime \\nnumbers:\\nText \\nCompletion\\n2 \\n= \\n87.6%\\n1 \\n= \\n12.3%\\n...\\n...\\n2, \\n3, \\n5, \\n7, \\n11\\nprobabilities \\nfor \\nthe \\nfirst \\ntokenFigure 4: An example highlighting the drawback of isolated\\nsampling of sequenced ideas. Input is denoted in blue, with\\nthetext-davinci-003 providing the green completions.\\net al. 2023). Though effective for one-off answers (Kadavath\\net al. 2022) (with certain constraints (Robinson and Wingate\\n2022)), this method falls short in scenarios demanding a se-\\nquence of samples to be integrated or evaluated within sub-\\nsequent prompts (Robinson and Wingate 2022). To mini-\\nmize model queries, we adopt an uninterrupted solution cre-\\nation process. Here, we directly and continuously generate\\nsolutions for the prevailing subproblem without any genera-\\ntion pauses.\\nThe benefits are three-fold. First, with all generated solu-\\ntions existing within a shared context, there’s no need for in-\\ndividual model queries for each solution evaluation. Second,\\nwhile it may seem counterintuitive initially, isolated token or\\ntoken group probabilities might not always yield meaning-\\nful choices. A simple illustration is found in Fig. 4. When\\nevaluated independently, the second-most probable token for\\nour inaugural number is ‘ 1’—not qualifying as prime. But,\\nwhen generation remains unbroken, the derived sequence is\\ncorrect. This incongruence points towards the restrictive na-\\nture of the Markov property in sequence modeling. Core to\\nour perspective is the premise that for sequential tasks like\\nalgorithmic search, LLMs are more adept at generating en-\\ntire sequences than intermittently pausing and re-initiating\\nthe token sampling process.\\n3. Gauging the Promise of a Subproblem. As above,\\nexisting techniques lean on additional prompting to dis-\\ncern the potential of tree nodes, aiding decisions regard-\\ning exploration direction. Our observations suggest that if\\nthe most promising routes are encapsulated within the in-\\ncontext examples, LLMs inherently gravitate towards prior-\\nitizing those promising candidates. This diminishes the need\\nfor intricate prompt engineering and allows the incorpora-\\ntion of intricate heuristics, whether intuitive or knowledge-\\ndriven. Again, the absence of disjoint prompts in our ap-\\nproach allows for an immediate assessment of candidate vi-\\nability in the same generation.\\n4. Backtracking to a Preferable Juncture. The decision\\nof which node to explore next (including retracing to a prior\\nnode) inherently depends on the selected tree-search algo-\\nrithm. While previous studies (Yao et al. 2023) have em-\\nployed external means such as coded mechanisms for the\\nsearch process, this restricts its broader appeal and entails\\nadditional customization. Our designs predominantly adopt\\na DFS approach supplemented by pruning. The aim is to' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 3}\n",
      "page_content='maintain proximity between nodes sharing the same par-\\nent, thereby encouraging the LLM to prioritize local over\\ndistant features. Additionally, we present performance met-\\nrics for the AoT approach grounded in BFS. Our reliance\\non the model’s inherent capacity to glean insights from in-\\ncontext examples obviates the necessity for additional, be-\\nspoke mechanisms.\\nExperiments\\nWe show that AoT surpasses the performance of other\\nsingle-prompt methods (e.g. standard, CoT/-SC prompting)\\nwhile remaining competitive even when compared to meth-\\nods that utilize external mechanisms, such as ToT, in bench-\\nmarks like the game of 24 and 5x5 mini crosswords.\\nGame of 24\\nThe game of 24 is a mathematical card game in which play-\\ners are given four numbers and must use addition, subtrac-\\ntion, multiplication, and division (each operation can be used\\nmore than once) to manipulate those numbers to total 24.\\nFor instance, for the numbers ‘ 8 8 5 4 ’, one solution would\\nbe ‘8∗(5−(8/4)) = 24 ’. At first glance, the game might\\nappear straightforward. However, a cursory calculation sug-\\ngests there are nearly 13,000 distinct expressions possible\\nfor any set of four numbers (without accounting for the com-\\nmutative properties of addition and multiplication), making\\nit a formidable challenge for present-day LLMs.\\nTask Setup. Adhering to the setup detailed in (Yao et al.\\n2023), we use games from indices 901-1000, sourced from\\nthe 1362 games ranked by relative difficulty at 4nums.com .\\nFor an attempt to be considered successful, it must derive a\\ntotal of 24 using the exact numbers provided and only the\\nallowed operations.\\nBaselines. Standard prompting and CoT are used in the 5-\\nshot setting, with CoT integrating 3 steps for the operations.\\nThese methods are sampled 100 times, and the averaged suc-\\ncess rates from these samples are reported. CoT-SC is also\\ntested with 100 votes in our setup. For ToT, we use a breadth\\nof 5. The performance metrics from their study are directly\\ncited to obviate the need for needless carbon emissions.\\nAoT Setup. We employ the same 5-shot setting as in stan-\\ndard prompting and CoT baseline setup. Our in-context sam-\\nples leverage a DFS-style search algorithm, which, for clar-\\nity, is the same version used when contrasting with tra-\\nditional DFS in Fig. 5. During each subtree exploration,\\ndubbed either the ‘first step’ or ‘first operation’, we choose\\ntwo numbers—illustrated by the selection of 8 and 6 in the\\nthird ’first step’ (i.e., subtree labeled ‘3’) of Fig. 1—and a\\ncorresponding operation (e.g., 8−6). This operation results\\nin a new number, 2, leaving us with three numbers in total.\\nA thorough combing of these three numbers culminates in\\n19 leaf nodes, all visible under the ‘3’ subtree in Fig. 1. We\\naim to assess two aspects: the ability of the LLM to pin-\\npoint promising first operations, which directly impacts the\\nnumber of resolved leaf nodes, and its performance against\\na conventional DFS. Details on the prompts we employed\\nare provided in the Appendix. As our method emphasizessequential generation over trajectory sampling, we operate\\nwith a temperature setting of 0.\\nResults. From Table 1, it’s evident that standard prompt-\\ning combined with CoT/-SC significantly lags behind tree\\nsearch methods when used with LLMs. The “Standard + Re-\\nfine” result, showing a 27% success rate, is referenced from\\n(Yao et al. 2023). This method involves iteratively asking\\nthe LLM (up to 10 iterations) to refine its answer if the initial\\none is incorrect. Meanwhile, ToT is limited to a maximum of\\n100 node visits, translating to several hundred LLM queries\\nfor each example. Remarkably, AoT achieves its results with\\njust a single query . Despite reducing the number of requests\\nby more than a factor of 100, AoT still outperforms ToT in\\nthis task.\\nMethod Success Avg. Queries\\nStandard Prompting 7.3% 1\\nCoT 4.0% 1\\nCoT-SC (k= 100) 9 .0% 100\\nStandard + Refine 27% 10\\nToT (b= 5) 69% 109 .1\\nAoT (ours) 71% 1\\nTable 1: Game of 24: success rates and the average number\\nof LLM queries for each example.\\nError Analysis. Using a strictly LLM-centric approach—\\neschewing any external tooling or edits—we sought to cat-\\negorize mistakes observed during the game of 24. This aids\\nin highlighting areas for refinement when solely deploying\\nLLMs. We’ve classified these errors into four distinct, ex-\\nhaustive categories: 1)Out-of-token error: The LLM reaches\\nits maximum token threshold without identifying a solution.\\n2)Expression misstep: The LLM has the correct logic or\\nsteps but fails when trying to express or formulate them into\\na coherent answer. 3)Non-finalization error: The LLM dis-\\ncovers the solution but continues its search without consol-\\nidating the finding. 4)Other errors: This umbrella term en-\\ncompasses other mistakes like computational errors that re-\\nsult in overlooking the solution or furnishing incorrect an-\\nswers. To exclusively showcase the AoT’s search capabil-\\nities, we also present the AoT + Manual Resolution ver-\\nsion. Here, once the LLM pinpoints a solution, its final ar-\\nticulation is manually processed—a strategy also employed\\nby the ToT method. As evidenced in Table 2, a notable\\n7% of mistakes stem from non-algorithmic factors like non-\\nfinalization and expression missteps. In fact, with manual\\nresolution, AoT attains a 78% success rate, surpassing ToT.\\nThis underlines the potential for refining our prompt, espe-\\ncially in areas concerning recognizing and expressing suc-\\ncessful problem resolutions. Additionally, the token limi-\\ntation underscores the appeal of expanding the generative\\ncontext window, which may further bolster LLMs’ recursive\\nreasoning when engaged with algorithmic examples.' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 4}\n",
      "page_content='Error Type Error\\nOut-of-token error 9%\\nExpression misstep 4%\\nNon-finalization error 3%\\nOthers 13%\\nMethod Success\\nToT 69%\\nAoT 71%\\nAoT + Manual Resolution 78%\\nTable 2: Game of 24: AoT error analysis.\\nMini Crosswords\\nThe 5×5mini crossword is a compact word puzzle featur-\\ning a grid of 25 squares arranged in a 5-by-5configuration.\\nPlayers are tasked with filling the grid based on provided\\nclues for each word. Clues are given for words that run both\\nacross (horizontally) and down (vertically). Words intersect\\nat certain letters, offering additional hints to complete the\\npuzzle.\\nTask Setup. Adhering to the setup outlined in (Yao et al.\\n2023), we draw our prompts from games 136, 141, 146, 151,\\nand 156 out of the 156 games available on goobix.com . Our\\ntesting focuses on a set of 20 games, specifically games 1, 6,\\n. . ., 91, and 96.\\nBaselines. Mirroring our approach for the game of 24, we\\nbenchmark our method against established techniques: stan-\\ndard prompting, CoT, and ToT. For standard prompting, we\\nprovide both the crosswords and their respective solutions\\nas in-context examples. CoT augments this by prompting\\nthe retrieval of words for each of the ten clues—equally split\\nbetween horizontal and vertical orientations. We directly ex-\\ntract the success rates of ToT from their original publication\\nfor comparison.\\nAoT Setup. We divide the process into two steps, each in-\\nvolving a query. Initially, we task the LLM with suggesting\\nfive potential words for each row and column. We then pin-\\npoint the starting word candidates that have the highest com-\\npatibility with other words within the crossword framework.\\nThis preliminary phase mirrors a ’warm-up’ sequence in al-\\ngorithm initialization. In the subsequent step, we exclusively\\nleverage the LLM’s algorithmic reasoning prowess, starting\\nwith the pre-selected word. The method involves cyclically\\nchoosing a likely option (specifically, a row or column) for\\ninsertion, generating candidate words, and assessing their\\ncompatibility with the words already on the board. If no\\nmatch is found, the process shifts focus to another promising\\ncandidate. Otherwise, the word is added to the crossword,\\nand the search continues. The cycle concludes either when\\nthe board is fully populated or no more suitable words can be\\nfound, which may be due to either incorrect existing words\\nor the absence of matching words. Notably, this entire pro-\\ncess unfolds within a single generation window. The algo-\\nrithmic examples in our prompt (detailed in the Appendix)include three that achieve game completion and two that pre-\\ndominantly populate the crossword, filling 8 or 9 slots.\\nResults. Table 3 underscores AoT’s proficiency in the\\nmini crosswords task, showcasing a word success rate—a\\nmeasure used in existing studies to represent the percent-\\nage of words correctly completed out of the total—that sur-\\npasses earlier methods reliant on various prompting tech-\\nniques. However, it trails behind ToT. An important observa-\\ntion is the sheer volume of queries ToT employs, exceeding\\nAoT’s by over a factor of 100. One factor hindering AoT\\nfrom surpassing ToT is that the backtracking capability in-\\nherent in the algorithmic example isn’t fully activated. Fully\\nunlocking this capability would lead to a significant elonga-\\ntion in the generation phase. In contrast, ToT has the advan-\\ntage of leveraging external memory for its backtracking.\\nMethod Word Success Avg. Queries\\nStandard Prompting 14% 1\\nCoT 15.6% 1\\nToT 60% >200\\nAoT (ours) 52% 2\\nTable 3: 5×5mini crosswords word: word success rates and\\nthe average number of LLM queries for each example.\\nError Analysis. To understand the prevalent mistakes\\nmade by AoT, we’ve categorized the errors into four dis-\\ntinct categories. In our analysis for each game, we focus on\\nthe initial error the LLM produces while charting its rea-\\nsoning path, given that an early error typically cascades into\\nsubsequent failures. 1)No preselections: LLM fails to gen-\\nerate compatible words essential for the warm-start phase.\\nGiven a correctly preselected word, the second phase for re-\\ncursive reasoning can exhibit errors including: 2)Expres-\\nsion misstep: The LLM mistakenly believes it has exhausted\\nall choices and jumps to an answer prematurely. 3)Incor-\\nrect pattern extraction: The LLM wrongly extracts a pattern\\nbased on the current board layout. 4)Erroneous word place-\\nment: Despite recognizing the correct pattern, the LLM se-\\nlects a mismatched word or misses better-fitting alternatives.\\nNavigating the crossword complexity arises from outdated\\nterms, esoteric references, and typographical mishaps. Pre-\\ndominantly, the errors observed are due to misguided word\\nplacements followed by pattern misinterpretations. Also, the\\nLLM seems challenged in aligning letters at precise indices\\nto create word structures— an obstracle circumvented by an\\nexternal mechanism in the ToT framework.\\nDiscussion\\nIn this section, we delve into crucial aspects to consider\\nwhen crafting prompts for AoT, using the game of 24 as our\\nprimary case study.\\nCan AoT surpass the DFS it’s patterned after? A core\\nquery of ours is to ascertain if the LLM has the capability\\nto not only mirror but also outdo the efficiency of the al-\\ngorithm introduced in-context. As evidenced in Fig. 5, AoT' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 5}\n",
      "page_content='Error Type Error\\nNo preselections 15.8%\\nExpression misstep 5.3%\\nIncorrect pattern extraction 26.3%\\nErroneous word placement 52.6%\\nTable 4: Breakdown of errors in 5×5mini crosswords with\\nAoT. Numbers indicate the relative percentage of each error\\ntype among all errors.\\nsystematically navigates fewer nodes than its DFS counter-\\npart. While DFS employs a uniform strategy when choosing\\nthe subsequent subtree to investigate, AoT’s LLM integrates\\nits inherent heuristic. This amplification over the base algo-\\nrithm exemplifies the advantages of LLM’s recursive reason-\\ning capability.\\n0 200 400 600 800 1000\\n# of Visited Nodes048121620# of Games\\nDFS\\nAoT\\nFigure 5: Histogram showing the number of visited nodes\\nfor AoT and DFS in the Game of 24.\\nHow does algorithm selection influence AoT’s efficacy?\\nTo explore the impact of algorithm choice on AoT’s per-\\nformance, we implemented both BFS and random search\\nwithin the AoT framework. Our findings, presented in Ta-\\nble 5, reveal that all three AoT variations outperform the\\nsingle-query CoT. This outcome was anticipated as AoT, ir-\\nrespective of the algorithm, undertakes a search and revis-\\nits potential mistakes—either by random retry in the ran-\\ndom search variant or through backtracking in the DFS and\\nBFS configurations. Notably, the structured search versions,\\nAoT (DFS) and AoT (BFS), displayed better efficiency than\\nAoT (Random), underscoring the advantage of algorithmic\\ninsights in solution discovery. However, AoT (BFS) lagged\\nbehind AoT (DFS). Closer inspection of errors made by AoT\\n(BFS) revealed the LLM faced greater challenges in identi-\\nfying optimal operations than its DFS counterpart.\\nHow does the search step count within the algorithmic\\nexample modulate AoT’s behavior? We begin with the\\nstandard AoT prompt and modify the subtree explorations.\\nIn AoT (Short), each in-context example uses one or two\\nsteps to reach a solution, while AoT (Long) incorporates\\nthree to five extra subtree explorations. The impact on total\\nsearch steps is illustrated in Fig. 6. Our observations high-\\nlight longer generations for AoT (Long) and shorter onesMethod Success Avg. Queries\\nCoT 4% 1\\nCoT-SC (k=100) 9% 100\\nToT 69% 109 .1\\nAoT (DFS) 71% 1\\nAoT (BFS) 48% 1\\nAoT (Random) 20% 1\\nTable 5: Comparative success rates and average LLM query\\ncounts for AoT variations templated by distinct algorithms.\\nfor AoT (Short) relative to the original AoT. This suggests\\nthat the search step count introduces an implicit bias on the\\nLLM’s search velocity. Notably, even when navigating in-\\ncorrect steps, it’s essential to emphasize the exploration of\\npromising directions.\\n0 50 100 150 200 250 300 350 400\\n# of Visited Nodes020406080100# of Games\\nAoT (Short)\\nAoT\\nAoT (Long)\\nFigure 6: Comparison of AoT with shorter and longer in-\\ncontext examples prompted AoT versions: cumulative num-\\nber of games for the number of visited nodes.\\nLimitations. While AoT substantially cuts down on the\\nnumber of queries relative to ToT, its resource demands ex-\\nceed those of standard prompting and CoT, a consequence\\nof its extensive exploration of ideas via token generation.\\nCrafting token-efficient algorithmic examples is one avenue,\\nbut there’s also potential in judiciously tapping into or un-\\nlocking the LLM’s “tunnel-vision”. Our research primarily\\nspotlighted certain algorithms, with a keen focus on tree-\\nsearch tasks. It’s pertinent to highlight that we conducted our\\ntests exclusively with GPT-4. Though more costly than other\\nLLMs, GPT-4’s advanced capabilities appear pivotal for\\nAoT’s optimal functioning; models of lesser caliber might\\nnot yield comparable performance boosts from AoT.\\nConclusion\\nThis paper presents the Algorithm of Thoughts , a pioneer-\\ning prompting strategy to navigate reasoning pathways in\\nLLMs using minimal queries. Our findings reveal that this\\nmethod not only substantially surpasses prior single-query\\ntechniques but also rivals external tree-search implementa-\\ntions. Such an approach augments the potential to stream-\\nline idea discovery in LLMs, balancing both cost and com-\\nputational demands. Future work includes designing token-' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 6}\n",
      "page_content='efficient algorithmic examples, developing adaptive mecha-\\nnisms for “tunnel-vision” activation to expedite the search,\\nand deepening the understanding of this fresh mode of in-\\ncontext learning from theoretical angles.\\nReferences\\nAminabadi, R. Y .; Rajbhandari, S.; Awan, A. A.; Li, C.; Li,\\nD.; Zheng, E.; Ruwase, O.; Smith, S.; Zhang, M.; Rasley, J.;\\net al. 2022. DeepSpeed-inference: enabling efficient infer-\\nence of transformer models at unprecedented scale. In SC22:\\nInternational Conference for High Performance Computing,\\nNetworking, Storage and Analysis , 1–15. IEEE.\\nAustin, J.; Odena, A.; Nye, M.; Bosma, M.; Michalewski,\\nH.; Dohan, D.; Jiang, E.; Cai, C.; Terry, M.; Le, Q.; et al.\\n2021. Program synthesis with large language models. arXiv\\npreprint arXiv:2108.07732 .\\nBaddeley, A. 2003. Working memory: looking back and\\nlooking forward. Nature reviews neuroscience , 4(10): 829–\\n839.\\nBai, Y .; Kadavath, S.; Kundu, S.; Askell, A.; Kernion, J.;\\nJones, A.; Chen, A.; Goldie, A.; Mirhoseini, A.; McKinnon,\\nC.; Chen, C.; Olsson, C.; Olah, C.; Hernandez, D.; Drain,\\nD.; Ganguli, D.; Li, D.; Tran-Johnson, E.; Perez, E.; Kerr, J.;\\nMueller, J.; Ladish, J.; Landau, J.; Ndousse, K.; Lukosuite,\\nK.; Lovitt, L.; Sellitto, M.; Elhage, N.; Schiefer, N.; Mer-\\ncado, N.; DasSarma, N.; Lasenby, R.; Larson, R.; Ringer,\\nS.; Johnston, S.; Kravec, S.; Showk, S. E.; Fort, S.; Lanham,\\nT.; Telleen-Lawton, T.; Conerly, T.; Henighan, T.; Hume,\\nT.; Bowman, S. R.; Hatfield-Dodds, Z.; Mann, B.; Amodei,\\nD.; Joseph, N.; McCandlish, S.; Brown, T.; and Kaplan, J.\\n2022. Constitutional AI: Harmlessness from AI Feedback.\\nArXiv:2212.08073 [cs].\\nBanerjee, S.; Bringsjord, S.; Giancola, M.; and Govindara-\\njulu, N. S. 2022. Qualitative Mechanical Problem-Solving\\nby Artificial Agents:: Further Progress, Under Psychometric\\nAI. In The International FLAIRS Conference Proceedings ,\\nvolume 35.\\nBrown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;\\nDhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,\\nA.; Agarwal, S.; Herbert-V oss, A.; Krueger, G.; Henighan,\\nT.; Child, R.; Ramesh, A.; Ziegler, D.; Wu, J.; Winter,\\nC.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.;\\nChess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford,\\nA.; Sutskever, I.; and Amodei, D. 2020. Language Mod-\\nels are Few-Shot Learners. Advances in Neural Information\\nProcessing Systems , 33: 1877–1901.\\nChen, L.; Zaharia, M.; and Zou, J. 2023. FrugalGPT: How\\nto Use Large Language Models While Reducing Cost and\\nImproving Performance. arXiv preprint arXiv:2305.05176 .\\nChen, M.; Tworek, J.; Jun, H.; Yuan, Q.; Pinto, H. P. d. O.;\\nKaplan, J.; Edwards, H.; Burda, Y .; Joseph, N.; Brockman,\\nG.; et al. 2021. Evaluating large language models trained on\\ncode. arXiv preprint arXiv:2107.03374 .\\nChowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra,\\nG.; Roberts, A.; Barham, P.; Chung, H. W.; Sutton, C.;\\nGehrmann, S.; et al. 2022. Palm: Scaling language modeling\\nwith pathways. arXiv preprint arXiv:2204.02311 .Dhar, P. 2020. The carbon impact of artificial intelligence.\\nNat. Mach. Intell. , 2(8): 423–425.\\nDrozdov, A.; Sch ¨arli, N.; Aky ¨urek, E.; Scales, N.; Song, X.;\\nChen, X.; Bousquet, O.; and Zhou, D. 2022. Compositional\\nSemantic Parsing with Large Language Models.\\nHelie, S.; and Pizlo, Z. 2022. When is psychology research\\nuseful in artificial intelligence? A case for reducing compu-\\ntational complexity in problem solving. Topics in Cognitive\\nScience , 14(4): 687–701.\\nHolyoak, K. J.; and Morrison, R. G. 2005. The Cambridge\\nhandbook of thinking and reasoning . Cambridge University\\nPress.\\nHuang, J.; and Chang, K. C.-C. 2022. Towards reason-\\ning in large language models: A survey. arXiv preprint\\narXiv:2212.10403 .\\nKadavath, S.; Conerly, T.; Askell, A.; Henighan, T.; Drain,\\nD.; Perez, E.; Schiefer, N.; Hatfield-Dodds, Z.; DasSarma,\\nN.; Tran-Johnson, E.; et al. 2022. Language models (mostly)\\nknow what they know. arXiv preprint arXiv:2207.05221 .\\nKahneman, D. 2011. Thinking, fast and slow . macmillan.\\nKojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y .; and Iwasawa,\\nY . 2022. Large Language Models are Zero-Shot Reason-\\ners. Advances in Neural Information Processing Systems ,\\n35: 22199–22213.\\nLanham, T.; Chen, A.; Radhakrishnan, A.; Steiner, B.; Deni-\\nson, C.; Hernandez, D.; Li, D.; Durmus, E.; Hubinger, E.;\\nKernion, J.; et al. 2023. Measuring Faithfulness in Chain-\\nof-Thought Reasoning. arXiv preprint arXiv:2307.13702 .\\nLiang, P.; Bommasani, R.; Lee, T.; Tsipras, D.; Soylu, D.;\\nYasunaga, M.; Zhang, Y .; Narayanan, D.; Wu, Y .; Kumar,\\nA.; et al. 2022. Holistic evaluation of language models.\\narXiv preprint arXiv:2211.09110 .\\nLibby, M. E.; Weiss, J. S.; Bancroft, S.; and Ahearn, W. H.\\n2008. A comparison of most-to-least and least-to-most\\nprompting on the acquisition of solitary play skills. Behav-\\nior analysis in practice , 1: 37–43.\\nLiu, Y .; Han, T.; Ma, S.; Zhang, J.; Yang, Y .; Tian, J.; He, H.;\\nLi, A.; He, M.; Liu, Z.; et al. 2023. Summary of chatgpt/gpt-\\n4 research and perspective towards the future of large lan-\\nguage models. arXiv preprint arXiv:2304.01852 .\\nLong, J. 2023. Large Language Model Guided Tree-of-\\nThought. arXiv preprint arXiv:2305.08291 .\\nLyu, Q.; Havaldar, S.; Stein, A.; Zhang, L.; Rao, D.; Wong,\\nE.; Apidianaki, M.; and Callison-Burch, C. 2023. Faithful\\nChain-of-Thought Reasoning. ArXiv:2301.13379 [cs].\\nMialon, G.; Dess `ı, R.; Lomeli, M.; Nalmpantis, C.; Pa-\\nsunuru, R.; Raileanu, R.; Rozi `ere, B.; Schick, T.; Dwivedi-\\nYu, J.; Celikyilmaz, A.; et al. 2023. Augmented language\\nmodels: a survey. arXiv preprint arXiv:2302.07842 .\\nMonsell, S. 2003. Task switching. Trends in cognitive sci-\\nences , 7(3): 134–140.\\nOuyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright, C.;\\nMishkin, P.; Zhang, C.; Agarwal, S.; Slama, K.; Ray, A.;\\net al. 2022. Training language models to follow instructions\\nwith human feedback. Advances in Neural Information Pro-\\ncessing Systems , 35: 27730–27744.' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 7}\n",
      "page_content='Robinson, J.; and Wingate, D. 2022. Leveraging Large Lan-\\nguage Models for Multiple Choice Question Answering.\\nShao, Z.; Gong, Y .; Shen, Y .; Huang, M.; Duan, N.; and\\nChen, W. 2023. Synthetic Prompting: Generating Chain-\\nof-Thought Demonstrations for Large Language Models.\\nSloman, S. A. 1996. The empirical case for two systems of\\nreasoning. Psychological bulletin , 119(1): 3.\\nSrivastava, A.; Rastogi, A.; Rao, A.; Shoeb, A. A. M.; Abid,\\nA.; Fisch, A.; Brown, A. R.; Santoro, A.; Gupta, A.; Garriga-\\nAlonso, A.; et al. 2022. Beyond the imitation game: Quanti-\\nfying and extrapolating the capabilities of language models.\\narXiv preprint arXiv:2206.04615 .\\nSuzgun, M.; Scales, N.; Sch ¨arli, N.; Gehrmann, S.; Tay,\\nY .; Chung, H. W.; Chowdhery, A.; Le, Q. V .; Chi, E. H.;\\nZhou, D.; and Wei, J. 2022. Challenging BIG-Bench\\nTasks and Whether Chain-of-Thought Can Solve Them.\\nArXiv:2210.09261 [cs].\\nThoppilan, R.; De Freitas, D.; Hall, J.; Shazeer, N.; Kul-\\nshreshtha, A.; Cheng, H.-T.; Jin, A.; Bos, T.; Baker, L.; Du,\\nY .; et al. 2022. Lamda: Language models for dialog appli-\\ncations. arXiv preprint arXiv:2201.08239 .\\nTurpin, M.; Michael, J.; Perez, E.; and Bowman, S. R. 2023.\\nLanguage Models Don’t Always Say What They Think: Un-\\nfaithful Explanations in Chain-of-Thought Prompting. arXiv\\npreprint arXiv:2305.04388 .\\nWang, X.; Wei, J.; Schuurmans, D.; Le, Q. V .; Chi, E. H.;\\nNarang, S.; Chowdhery, A.; and Zhou, D. 2022. Self-\\nConsistency Improves Chain of Thought Reasoning in Lan-\\nguage Models.\\nWei, J.; Tay, Y .; Bommasani, R.; Raffel, C.; Zoph, B.;\\nBorgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler,\\nD.; Chi, E. H.; Hashimoto, T.; Vinyals, O.; Liang, P.; Dean,\\nJ.; and Fedus, W. 2022a. Emergent Abilities of Large Lan-\\nguage Models. ArXiv:2206.07682 [cs].\\nWei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Ichter, B.;\\nXia, F.; Chi, E.; Le, Q. V .; and Zhou, D. 2022b. Chain-\\nof-Thought Prompting Elicits Reasoning in Large Language\\nModels. Advances in Neural Information Processing Sys-\\ntems, 35: 24824–24837.\\nWu, C.-J.; Raghavendra, R.; Gupta, U.; Acun, B.; Ardalani,\\nN.; Maeng, K.; Chang, G.; Aga, F.; Huang, J.; Bai, C.; et al.\\n2022. Sustainable ai: Environmental implications, chal-\\nlenges and opportunities. Proceedings of Machine Learning\\nand Systems , 4: 795–813.\\nYao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.;\\nCao, Y .; and Narasimhan, K. 2023. Tree of Thoughts:\\nDeliberate Problem Solving with Large Language Models.\\nArXiv:2305.10601 [cs].\\nZelikman, E.; Wu, Y .; Mu, J.; and Goodman, N. 2022. Star:\\nBootstrapping reasoning with reasoning. Advances in Neu-\\nral Information Processing Systems , 35: 15476–15488.\\nZhang, Z.; Zhang, A.; Li, M.; and Smola, A. 2022. Auto-\\nmatic Chain of Thought Prompting in Large Language Mod-\\nels.\\nZhou, D.; Sch ¨arli, N.; Hou, L.; Wei, J.; Scales, N.; Wang,\\nX.; Schuurmans, D.; Cui, C.; Bousquet, O.; Le, Q. V .; andChi, E. H. 2022. Least-to-Most Prompting Enables Complex\\nReasoning in Large Language Models.' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 8}\n",
      "page_content='Game of 24 - Additional Details\\nIn order to avoid confusion in our analysis of AoT in the game of 24, we give additional details in terms of terminologies we\\nuse as well as their direct implications in the performance figures. An Illustration of these are given in Fig. 7.\\n4 \\n- \\n4 \\n= \\n8\\n(left: \\n8, \\n6, \\n0)\\n4 \\n+ \\n2 \\n= \\n6\\n(left: \\n6, \\n4)\\n4 \\n/ \\n4 \\n= \\n1\\n(left: \\n2, \\n1)\\n6 \\n* \\n4 \\n= \\n24\\n(left: \\n24)\\n6 \\n+ \\n4 \\n= \\n10\\n(left: \\n10)\\n...\\nInput: \\n8 \\n6 \\n4 \\n4\\nFirst \\nOperations\\nSecond \\nOperations\\nThird \\nOperations\\nVisited \\nNodes\\n8 \\n- \\n6 \\n= \\n2\\n(left: \\n4, \\n4, \\n2)\\n...\\nSubtree \\nExploration\\nFigure 7: An illustration of terminologies we use for the game of 24. The yellow nodes represent the first operations and the\\nstates they lead to; the green node represents the node where we find the solution; all other nodes are represented by pink.\\nFirst operations / First iterations. This represents the scenario that after we choose the first two number in the game of 24,\\nthe case of either adding, subtracting, multiplying or dividing them.\\nSubtree Exploration. This denotes searching all or most of the nodes coming from the same state, typically states with less\\nthan four numbers left.\\nNumber of nodes visited. This is the number of states that the method has been on the game of 24. Each state is the set of\\nnumber we are left with, after our operations in the numbers. For example, after the first operation we might be left with the\\nnumbers ‘ 831’. This set of numbers represent a state, as well as the state of ‘ 83’ that we will be left with after another operation\\nof ‘8∗1 = 8 ’.\\nCreative Writing\\nWe use the creative writing task, also used by (Yao et al. 2023), where the LLM is provided with four arbitrary sentences.\\nThe objective is to craft a cohesive narrative divided into four paragraphs, with each paragraph culminating in one of the given\\nsentences. This exercise not only fosters creativity but also emphasizes strategic deliberation.\\nTask Setup\\nSentences are randomly sourced from randomwordgenerator.com , resulting in 100 distinct sets of inputs. Given the absence of\\npredetermined correct answers, the primary focus lies in evaluating the coherence of the responses. We have noted that GPT-4\\nconsistently aligns with these input guidelines. Evaluation is centered around assessing passage coherence using a GPT-4 zero-\\nshot prompt, where each output is rated on a scale of 1 to 10. Each task response undergoes five such evaluations, with their\\nscores being averaged subsequently.\\nBaselines\\nFor this task, both standard and CoT prompts are employed without preliminary training. While the standard prompt directly\\nguides the LLM to fashion a cohesive narrative based on stipulated parameters, the CoT prompt obliges the model to initially\\noutline a succinct plan prior to drafting the narrative, serving as an intermediate cognitive bridge. For each task iteration,\\nten samples are generated using both the standard and CoT methods. Results of the ToT approach are presented without\\nmodification.' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 9}\n",
      "page_content='AoT Setup\\nMirroring ToT’s methodology, the task is tackled in a zero-shot setting. Our prompt instructs the model to first formulate five\\ndistinct plans. Subsequent to this, the model selects the most promising among them to shape a narrative and then refines it for\\noptimal coherence. The exact prompts used for this zero-shot approach will be provided in the subsequent section.\\nResults\\nAs depicted in Fig. 8, AoT outpaces other singular query prompting techniques such as standard prompting and CoT in terms\\nof performance. It also exhibits a marked improvement over ToT, although the difference is not statistically significant. Com-\\nprehensive scores, along with the average query count needed for each method, are consolidated in Table 6. Notably, AoT\\nnecessitates fewer queries compared to ToT.\\nStandard CoT T oT AoT0246810\\nFigure 8: Comparison of the standard prompting, CoT, ToT and AoT on the creative writing task.\\nMethod Score Avg. Queries\\nStandard Prompting 6.19 1\\nCoT 6.93 1\\nToT 7.56 20\\nAoT 7.58 1\\nTable 6: Performance of the methods determined by GPT-4.\\nCoT vs. Single Iteration AoT in the Game of 24\\nTo demonstrate that the tree search mechanism is fundamentally distinct from the CoT prompting, even in scenarios where\\nAoT’s in-context examples include only a single initial operation in the game of 24, we draw a comparison between AoT\\n(Short) and CoT. In this setup, AoT (Short) determines the first operation and subsequently conducts a tree search on the\\nremaining three numbers. Interestingly, AoT (Short) achieves a success rate of 48%, while CoT lags significantly, securing\\nonly 4%. These results underscore the notion that even a rudimentary search mechanism can lead to significant performance\\nenhancements.\\nDetailed Analysis on the Effect of the Length of the Prompts\\nIn this section, we delve deeper into Fig. 6 by presenting histograms for the successful, unsuccessful, and total games of ‘24’,\\nconsidering the number of initial steps in methods AoT (Short), AoT, and AoT (Long). These are displayed in Figs. 9-11.\\nFrom these figures, it becomes evident that the length of the prompts, measured by the number of initial steps included in\\nin-context examples, correlates with the length of their solutions to test examples. This trend is consistent across all three cases,\\nsuggesting that AoT’s strategy in determining the number of initial steps is influenced by its in-context examples.\\nInterestingly, when AoT is provided a well-balanced set of initial steps that emphasize the most promising operations, it\\nexcels in solving the majority of games in earlier iterations. This indicates AoT’s capacity to prioritize swift problem-solving\\nwithout sacrificing performance. This tendency is also observed in AoT (Long), albeit with a somewhat reduced success rate,\\nas illustrated in Fig. 9.' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 10}\n",
      "page_content='0 2 4 6 8 10 1202040\\n0 2 4 6 8 10 1202040# of Successful Games\\n0 2 4 6 8 10 12\\n# of First Steps02040\\nAoT (Short)\\nAoT\\nAoT (Long)Figure 9: Histogram of the number of successful games with respect to the number of first steps for AoT (Short), AoT and AoT\\n(Long).\\n0 2 4 6 8 10 1202040\\n0 2 4 6 8 10 1202040# of Unsuccessful Games\\n0 2 4 6 8 10 12\\n# of First Steps02040AoT (Short)\\nAoT\\nAoT (Long)\\nFigure 10: Histogram of the number of unsuccessful games with respect to the number of first steps for AoT (Short), AoT and\\nAoT (Long).\\nPrompts\\nGame of 24\\nBelow, we represent the specific prompts employed for the various methods detailed in the experiments section. It’s important\\nto note that the terms “System”,“User”, and “Assistant” are utilized to denote the roles within the OpenAI API when operating\\nin chat completion mode. The line breaks serve to show the transitions between the user and assistant interactions within the\\nAPI.\\nAoT (DFS)\\nSystem:' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 11}\n",
      "page_content='0 2 4 6 8 10 12050100\\n0 2 4 6 8 10 12050100# of All Games\\n0 2 4 6 8 10 12\\n# of First Steps050100\\nAoT (Short)\\nAoT\\nAoT (Long)Figure 11: Histogram of the number of all games with respect to the number of first steps for AoT (Short), AoT and AoT\\n(Long).\\nUse numbers and basic arithmetic operations (+ - */) to obtain 24. When\\nconsidering the next steps, do not choose operations that will result in a\\nnegative or fractional number. In order to help with the calculations, the\\nnumbers in the parenthesis represent the numbers that are left after the\\noperations and they are in descending order.\\nAnother thing we do is when there are only two numbers left in the parenthesis, we\\ncheck whether we can arrive at 24 only by using basic arithmetic operations\\n(+ - */). Some examples regarding this idea:\\n(21 2) no\\nsince 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\\nto 24.\\n(30 6) 30 - 6 = 24 yes\\n(8 3) 8 *3 = 24 yes\\n(12 8) no\\n(48 2) 48 / 2 = 24 yes\\nMost importantly, do not give up, all the numbers that will be given has indeed a\\nsolution.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n14 8 8 2\\nAssistant:\\nTrying a promising first operation:\\n1. 8 + 2: (14, 10, 8)\\n- 14 + 10: (24, 8) 32, 16, 192, 3\\n- 14 - 10: (8, 4) 12, 8, 32, 2\\n- 14 *10: (140, 8) 148, 132, 1120, fractional\\n- 14 / 10: (8, 1.4) fractional\\n- 14 + 8: (22, 10) 32, 12, 220, fractional\\n- 14 - 8: (10, 6) 16, 4, 60, fractional\\n- 14 *8: (112, 10) 122, 102, 1120, fractional\\n- 14 / 8: fractional\\n- 10 + 8: (18, 14) 32, 4, 252, fractional\\n- 10 - 8: (14, 2) 16, 12, 28, 7\\n- 10 *8: (80, 14) 94, 66, big, fractional\\n- 10 / 8: fractional' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 12}\n",
      "page_content='Trying another promising first operation:\\n2. 8 / 2: (14, 8, 4)\\n- 14 + 8: (22, 4) 26, 18, 88, fractional\\n- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 2 = 4\\nStep 2:\\n14 - 8 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\\nanswer: (14 - 8) *(8 / 2) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 5 5 5\\nAssistant:\\nTrying a promising first operation:\\n1. 9 - 5: (5, 5, 4)\\n- 5 + 5: (10, 4) 14, 6, 40, fractional\\n- 5 - 5: (4, 0) 4, 4, 0, undefined\\n- 5 *5: (25, 4) 29, 21, 100, fractional\\n- 5 / 5: (4, 1) 5, 3, 4, 4\\n- 5 + 4: (9, 5) 14, 4, 45, fractional\\n- 5 - 4: (5, 1) 6, 4, 5, 0.2\\n- 5 *4: (20, 5) 25, 15, 100, fractional\\n- 5 / 4: fractional\\nTrying another promising first operation:\\n2. 5 + 5: (10, 9, 5)\\n- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\\nBacktracking the solution:\\nStep 1:\\n5 + 5 = 10\\nStep 2:\\n10 + 9 = 19\\nStep 3:\\n19 + 5 = 24\\nConsidering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\\nanswer: ((5 + 5) + 9) + 5 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 6 4 4\\nAssistant:\\nTrying a promising first operation:\\n1. 8 - 6: (4, 4, 2)\\n- 4 + 4: (8, 2) 10, 6, 16, 4\\n- 4 - 4: (2, 0) 2, 2, 0, undefined\\n- 4 *4: (16, 2) 18, 14, 32, 8\\n- 4 / 4: (2, 1) 3, 1, 2, 2\\n- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 - 6 = 2\\nStep 2:\\n4 + 2 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\\nanswer: (4 + (8 - 6)) *4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 10 9 4\\nAssistant:' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 13}\n",
      "page_content='Trying a promising first operation:\\n1. 13 - 4: (10, 9, 9)\\n- 10 + 9: (19, 9) 28, 10, 171, fractional\\n- 10 - 9: (9, 1) 10, 8, 9, 9\\n- 10 *9: (90, 9) 99, 81, 810, fractional\\n- 10 / 9: fractional\\n- 9 + 9: (18, 10) 28, 8, 180, fractional\\n- 9 - 9: (10, 0) 10, 10, 0, undefined\\n- 9 *9: (81, 10) 91, 71, 810, fractional\\n- 9 / 9: (10, 1) 11, 9, 10, 10\\nTrying another promising first operation:\\n2. 10 - 4: (13, 9, 6)\\n- 13 + 9: (22, 6) 28, 16, 132, fractional\\n- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n10 - 4 = 6\\nStep 2:\\n13 - 9 = 4\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\\nanswer: (10 - 4) *(13 - 9) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 8 5 4\\nAssistant:\\nTrying a promising first operation:\\n1. 8 - 4: (8, 5, 4)\\n- 8 + 5: (13, 4) 17, 9, 52, fractional\\n- 8 - 5: (4, 3) 7, 1, 12, fractional\\n- 8 *5: (40, 4) 44, 36, 160, fractional\\n- 8 / 5: fractional\\n- 8 + 4: (12, 5) 17, 7, 60, fractional\\n- 8 - 4: (5, 4) 9, 1, 20, fractional\\n- 8 *4: (32, 5) 37, 27, 160, fractional\\n- 8 / 4: (5, 2) 7, 3, 10, 2.5\\n- 5 + 4: (9, 8) 17, 1, 72, fractional\\n- 5 - 4: (8, 1) 9, 7, 8, 8\\n- 5 *4: (20, 8) 28, 12, 160, fractional\\n- 5 / 4: fractional\\nTrying another promising first operation:\\n2. 8 / 4: (8, 5, 2)\\n- 8 + 5: (13, 2) 15, 11, 26, fractional\\n- 8 - 5: (3, 2) 5, 1, 6, 1.5\\n- 8 *5: (40, 2) 42, 38, 80, 20\\n- 8 / 5: fractional\\n- 8 + 2: (10, 5) 15, 5, 50, 2\\n- 8 - 2: (6, 5) 11, 1, 30, fractional\\n- 8 *2: (16, 5) 21, 11, 80, fractional\\n- 8 / 2: (5, 4) 9, 1, 20, fractional\\n- 5 + 2: (7, 8) 15, 1, 56, fractional\\n- 5 - 2: (8, 3) 11, 5, 24 = 8 *3 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 4 = 2\\nStep 2:\\n5 - 2 = 3\\nStep 3:\\n8*3 = 24\\nConsidering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\\nanswer: 8 *(5 - (8 / 4)) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 14}\n",
      "page_content='User:\\n11 11 1 1\\nAssistant:\\nTrying a promising first operation:\\n1. 11 - 1: (11, 10, 1)\\n- 11 + 10: (21, 1) 22, 20, 21, 21\\n- 11 - 10: (1, 1) 2, 0, 1, 1\\n- 11 *10: (110, 1) 111, 109, 110, 110\\n- 11 / 10: fractional\\n- 11 + 1: (12, 10) 22, 2, 120, 1.2\\n- 11 - 1: (10, 10) 20, 0, 100, 1\\n- 11 *1: (11, 10) 21, 1, 110, 1.1\\n- 11 / 1: (11, 10) 21, 1, 110, fractional\\n- 10 + 1: (11, 11) 22, 0, 121, 1\\n- 10 - 1: (11, 9) 20, 2, 99, 1.1\\n- 10 *1: (11, 10) 21, 1, 110, 1.1\\n- 10 / 1: (11, 10) 21, 1, 110, 1.1\\nTrying another promising first operation:\\n2. 11 + 1: (12, 11, 1)\\n- 12 + 11: (23, 1) 24 = 23 + 1 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11 + 1 = 12\\nStep 2:\\n12 + 11 = 23\\nStep 3:\\n23 + 1\\nConsidering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\\nanswer: ((11 + 1) + 11) + 1 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 7 4 1\\nAssistant:\\nTrying a promising first operation:\\n1. 7 *4: (28, 11, 1)\\n- 28 + 11: (39, 1) 40, 38, 39, 39\\n- 28 - 11: (17, 1) 18, 16, 17, 17\\n- 28 *11: (308, 1) 309, 307, 308, 308\\n- 28 / 11: fractional\\n- 28 + 1: (29, 11) 40, 18, 319, fractional\\n- 28 - 1: (27, 11) 38, 16, 297, fractional\\n- 28 *1: (28, 11) 39, 17, 308, fractional\\n- 28 / 1: (28, 11) 39, 17, 308, fractional\\n- 11 + 1: (29, 28) 57, 1, 812, fractional\\n- 11 - 1: (28, 10) 38, 18, 280, fractional\\n- 11 *1: (28, 11) 39, 17, 308, fractional\\n- 11 / 1: (28, 11) 39, 17, 308, fractional\\nTrying another promising first operation:\\n2. 7 + 1: (11 8 4)\\n- 11 + 8: (19, 4) 23, 15, 76, fractional\\n- 11 - 8: (4, 3) 7, 1, 12, fractional\\n- 11 *8: (88, 4) 92, 84, 352, fractional\\n- 11 / 8: fractional\\n- 11 + 4: (15, 8) 23, 7, 120, fractional\\n- 11 - 4: (7, 8) 15, -1, 56, fractional\\n- 11 *4: (44, 8) 52, 36, 352, fractional\\n- 11 / 4: fractional\\n- 8 + 4: (12, 11) 23, -1, 132, fractional\\n- 8 - 4: (11, 4) 15, 7, 44, fractional\\n- 8 *4: (32, 11) 43, 21, 352, fractional\\n- 8 / 4: (11, 2) 13, 9, 22, fractional\\nTrying another promising first operation:' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 15}\n",
      "page_content='3. 4 + 1: (11 7 5)\\n- 11 + 7: (18, 5) 23, 13, 90, fractional\\n- 11 - 7: (5, 4) 9, 1, 20, fractional\\n- 11 *7: (77, 5) 82, 72, 385, fractional\\n- 11 / 7: fractional\\n- 11 + 5: (16, 7) 23, 9, 112, fractional\\n- 11 - 5: (7, 6) 13, 1, 42, fractional\\n- 11 *5: (55, 7) 62, 48, 385, fractional\\n- 11 / 5: fractional\\n- 7 + 5: (12, 11) 23, 1, 132, fractional\\n- 7 - 5: (11, 2) 13, 9, 22, fractional\\n- 7 *5: (35, 11) 46, 24 = 35 - 11 -> found it!\\nStep 1:\\n4 + 1 = 5\\nStep 2:\\n7*5 = 35\\nStep 3:\\n35 - 11 = 24\\nConsidering these steps: Backtracking the solution:\\n24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\\nanswer: (7 *(4 + 1)) - 11 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 5 4 3\\nAssistant:\\nTrying a promising first operation:\\n1. 5 *4: (20, 11, 3)\\n- 20 + 11: (31, 3) 34, 28, 93, fractional\\n- 20 - 11: (9, 3) 12, 6, 27, 3\\n- 20 *11: (220, 3) 223, 217, 660, fractional\\n- 20 / 11: fractional\\n- 20 + 3: (23, 11) 34, 12, 253, fractional\\n- 20 - 3: (17, 11) 28, 6, 187, fractional\\n- 20 *3: (60, 11) 71, 49, 660, fractional\\n- 20 / 3: fractional\\n- 11 + 3: (14, 20) 34, -6, 280, fractional\\n- 11 - 3: (8, 20) 28, -12, 160, fractional\\n- 11 *3: (33, 20) 53, 13, 660, fractional\\n- 11 / 3: fractional\\nTrying another promising first operation:\\n2. 11 - 3: (8, 5, 4)\\n- 8 + 5: (13, 4) 17, 9, 52, fractional\\n- 8 - 5: (4, 3) 7, 1, 12, fractional\\n- 8 *5: (40, 4) 44, 36, 160, fractional\\n- 8 / 5: fractional\\n- 8 + 4: (12, 5) 17, 7, 60, fractional\\n- 8 - 4: (5, 4) 9, 1, 20, fractional\\n- 8 *4: (32, 5) 37, 27, 160, fractional\\n- 8 / 4: (5, 2) 7, 3, 10, 2.5\\n- 5 + 4: (9, 8) 17, 1, 72, fractional\\n- 5 - 4: (8, 1) 9, 7, 8, 8\\n- 5 *4: (20, 8) 28, 12, 160, fractional\\n- 5 / 4: fractional\\nTrying another promising first operation:\\n3. 11 *3: (33, 5, 4)\\n- 33 + 5: (38, 4) 42, 34, 152, fractional\\n- 33 - 5: (28, 4) 32, 24 = 28 - 4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11*3 = 33\\nStep 2:\\n33 - 5 = 28\\nStep 3:' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 16}\n",
      "page_content='28 - 4 = 24\\nConsidering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\\nanswer: ((11 *3) - 5) - 4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 12 5 2\\nAssistant:\\nTrying a promising first operation:\\n1. 12 + 2: (14, 13, 5)\\n- 14 + 13: (27, 5) 32, 22, 135, fractional\\n- 14 - 13: (5, 1) 6, 4, 5, 5\\n- 14 *13: (182, 5) 187, 177, 910, fractional\\n- 14 / 13: fractional\\n- 14 + 5: (19, 13) 32, 6, 247, fractional\\n- 14 - 5: (13, 9) 22, 4, 117, fractional\\n- 14 *5: (70, 13) 83, 57, 910, fractional\\n- 14 / 5: fractional\\n- 13 + 5: (18, 14) 32, 4, 252, fractional\\n- 13 - 5: (14, 8) 22, 6, 112, fractional\\n- 13 *5: (65, 14) 79, 51, 910, fractional\\n- 13 / 5: fractional\\nTrying another promising first operation:\\n2. 13 + 5: (18, 12, 2)\\n- 18 + 12: (30, 2) 32, 28, 60, fractional\\n- 18 - 12: (6, 2) 8, 4, 12, 3\\n- 18 *12: (216, 2) 218, 214, 432, fractional\\n- 18 / 12: fractional\\n- 18 + 2: (20, 12) 32, 8, 240, fractional\\n- 18 - 2: (16, 12) 28, 4, 192, fractional\\n- 18 *2: (36, 12) 48, 24 = 36 - 12 -> found it!\\nBacktracking the solution:\\nStep 1:\\n13 + 5 = 18\\nStep 2:\\n18*2 = 36\\nStep 3:\\n36 - 12 = 24\\nConsidering these steps: 24 = 36 - 12 = (18 *2) - 12 = ((13 + 5) *2) - 12 = 24.\\nanswer: ((13 + 5) *2) - 12 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 8 2 1\\nAssistant:\\nTrying a promising first operation:\\n1. 9 - 1: (8, 8, 2)\\n- 8 + 8: (16, 2) 18, 14, 32, 8\\n- 8 - 8: (2, 0) 2, 2, 0, undefined\\n- 8 *8: (64, 2) 66, 62, 128, 32\\n- 8 / 8: (2, 1) 3, 1, 2, 2\\n- 8 + 2: (10, 8) 18, 2, 80, 4\\n- 8 - 2: (6, 8) 14, -2, 48, fractional\\n- 8 *2: (16, 8) 24 = 16 + 8 -> found it!\\nBacktracking the solution:\\nStep 1:\\n9 - 1 = 8\\nStep 2:\\n8*2 = 16\\nStep 3:\\n16 + 8 = 24\\nConsidering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\\nanswer: ((9 - 1) *2) + 8 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nAoT (Long)' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 17}\n",
      "page_content='System:\\nUse numbers and basic arithmetic operations (+ - */) to obtain 24. When\\nconsidering the next steps, do not choose operations that will result in a\\nnegative or fractional number. In order to help with the calculations, the\\nnumbers in the parenthesis represent the numbers that are left after the\\noperations and they are in descending order.\\nAnother thing we do is when there are only two numbers left in the parenthesis, we\\ncheck whether we can arrive at 24 only by using basic arithmetic operations\\n(+ - */). Some examples regarding this idea:\\n(21 2) no\\nsince 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\\nto 24.\\n(30 6) 30 - 6 = 24 yes\\n(8 3) 8 *3 = 24 yes\\n(12 8) no\\n(48 2) 48 / 2 = 24 yes\\nMost importantly, do not give up, all the numbers that will be given has indeed a\\nsolution.\\nUser:\\n14 8 8 2\\nAssistant:\\nTrying a promising first operation:\\n1. 8 + 2: (14, 10, 8)\\n- 14 + 10: (24, 8) 32, 16, 192, 3\\n- 14 - 10: (8, 4) 12, 8, 32, 2\\n- 14 *10: (140, 8) 148, 132, 1120, fractional\\n- 14 / 10: (8, 1.4) fractional\\n- 14 + 8: (22, 10) 32, 12, 220, fractional\\n- 14 - 8: (10, 6) 16, 4, 60, fractional\\n- 14 *8: (112, 10) 122, 102, 1120, fractional\\n- 14 / 8: fractional\\n- 10 + 8: (18, 14) 32, 4, 252, fractional\\n- 10 - 8: (14, 2) 16, 12, 28, 7\\n- 10 *8: (80, 14) 94, 66, big, fractional\\n- 10 / 8: fractional\\nTrying another promising first operation:\\n2. 14 + 8: (22, 8, 2)\\n- 22 + 8: (30, 2) 32, 28, 60, 15\\n- 22 - 8: (14, 2) 16, 12, 28, 7\\n- 22 *8: (176, 2) 178, 174, 88\\n- 22 / 8: (2.75, 2) fractional\\n- 22 + 2: (24, 8) 32, 16, 192, 3\\n- 22 - 2: (20, 8) 28, 12, 160, fractional\\n- 22 *2: (44, 8) 52, 36, 352, fractional\\n- 22 / 2: (11, 8) 19, 3, 88, fractional\\n- 8 + 2: (22, 10) 32, 12, 220, fractional\\n- 8 - 2: (22, 6) 28, 16, 132, fractional\\n- 8 *2: (22, 16) 38, 6, 352, fractional\\n- 8 / 2: (22, 4) 26, 18, 88, fractional\\nTrying another promising first operation:\\n3. 14 + 2: (16, 8, 8)\\n- 16 + 8: (24, 8) 32, 16, 192, 3\\n- 16 - 8: (8, 8) 16, 0, 64, 1\\n- 16 *8: (128, 8) 136, 120, 1024, 16\\n- 16 / 8: (8, 2) 10, 6, 16, 4\\n- 8 + 8: (16, 16 32, 0, 256, 1\\n- 8 - 8: (16, 0) 16, 16, 0, undefined\\n- 8 *8: (64, 16) 80, 48, 1024, 4\\n- 8 / 8: (16, 1) 17, 15, 16, 16\\nTrying another promising first operation:' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 18}\n",
      "page_content='4. 8 - 2: (14, 8, 6)\\n- 14 + 8: (22, 14) 36, 8, 308, fractional\\n- 14 - 8: (6, 6) 12, 0, 36, 1\\n- 14 *8: (112, 6) 118, 106, 672, fractional\\n- 14 / 8: (6, 1.75) fractional\\n- 14 + 6: (20, 8) 22, 12, 160, fractional\\n- 14 - 6: (8, 8) 16, 0, 64, 1\\n- 14 *6: (84, 8) 92, 76, 672, fractional\\n- 14 / 6: (8, 2.3) fractional\\n- 8 + 6: (14, 14) 28, 0, 196, 1\\n- 8 - 6: (14, 2) 16, 12, 28, 7\\n- 8 *6: (48, 14) 62, 34, 672, fractional\\n- 8 / 6: (14, 1.3) fractional\\nTrying another promising first operation:\\n5. 8 *2: (16, 14, 8)\\n- 16 + 14: (30, 8) 38, 22, 240, fractional\\n- 16 - 14: (8, 2) 10, 6, 16, 4\\n- 16 *14: (224, 8) 232, 216, 1792, 28\\n- 16 / 14: (8, 1.1) fractional\\n- 16 + 8: (24, 14) 38, 10, 336, fractional\\n- 16 - 8: (14, 8) 22, 6, 112, fractional\\n- 16 *8: (128, 14) 142, 112, 1792, fractional\\n- 16 / 8: (14, 2) 16, 12, 28, 7\\n- 14 + 8: (22, 16) 38, 6, 352, fractional\\n- 14 - 8: (16, 6) 22, 10, 96, fractional\\n- 14 *8: (112, 16) 128, 96, 1792, 7\\n- 14 / 8: (16, 1.7) fractional\\nTrying another promising first operation:\\n6. 14 *2: (28, 8, 8)\\n- 28 + 8: (36, 8) 44, 28, 288, fractional\\n- 28 - 8: (20, 8) 28, 12, 160, fractional\\n- 28 *8: (224, 8) 232, 216, 1792, 28\\n- 28 / 8: (8, 3.5) fractional, fractional, 28, fractional\\n- 8 + 8: (16, 16 32, 0, 256, 1\\n- 8 - 8: (16, 0) 16, 16, 0, undefined\\n- 8 *8: (64, 16) 80, 48, 1024, 4\\n- 8 / 8: (16, 1) 17, 15, 16, 16\\nTrying another promising first operation:\\n7. 8 / 2: (14, 8, 4)\\n- 14 + 8: (22, 4) 26, 18, 88, fractional\\n- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 2 = 4\\nStep 2:\\n14 - 8 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\\nanswer: (14 - 8) *(8 / 2) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 5 5 5\\nAssistant:\\nTrying a promising first operation:\\n1. 9 - 5: (5, 5, 4)\\n- 5 + 5: (10, 4) 14, 6, 40, fractional\\n- 5 - 5: (4, 0) 4, 4, 0, undefined\\n- 5 *5: (25, 4) 29, 21, 100, fractional\\n- 5 / 5: (4, 1) 5, 3, 4, 4\\n- 5 + 4: (9, 5) 14, 4, 45, fractional\\n- 5 - 4: (5, 1) 6, 4, 5, 0.2' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 19}\n",
      "page_content='- 5 *4: (20, 5) 25, 15, 100, fractional\\n- 5 / 4: fractional\\nTrying another promising first operation:\\n2. 5 *5: (25, 9, 5)\\n- 25 + 9: (34, 5) 39, 29, 170, fractional\\n- 25 - 9: (16, 5) 21, 11, 80, fractional\\n- 25 *9: (225, 5) 230, 220, 1125, 45\\n- 25 / 9: (5, 2.7) fractional\\n- 25 + 5: (30, 9) 39, 21, 270, fractional\\n- 25 - 5: (20, 9) 29, 11, 180, fractional\\n- 25 *5: (75, 9) 84, 66, 675, fractional\\n- 25 / 5: (9, 5) 14, 4, 45, fractional\\n- 9 + 5: (25, 14) 39, 11, 350, fractional\\n- 9 - 5: (25, 4) 29, 21, 100, fractional\\n- 9 *5: (45, 25) 70, 20, 1125, fractional\\n- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\\nTrying another promising first operation:\\n3. 5 - 5: (9, 5, 0)\\n- 9 + 5: (25, 14) 39, 11, 350, fractional\\n- 9 - 5: (25, 4) 29, 21, 100, fractional\\n- 9 *5: (45, 25) 70, 20, 1125, fractional\\n- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\\n- 9 + 0: (9, 5) 14, 4, 45, fractional\\n- 9 - 0: (9, 5) 14, 4, 45, fractional\\n- 9 *0: (5, 0) 5, 5, 0, undefined\\n- 9 / 0: undefined\\n- 5 + 0: (9, 5) 14, 4, 45, fractional\\n- 5 - 0: (9, 5) 14, 4, 45, fractional\\n- 5 *0: (9, 0) 9, 9, 0, undefined\\n- 5 / 0: undefined\\nTrying another promising first operation:\\n4. 5 / 5: (9, 5, 1)\\n- 9 + 5: (25, 14) 39, 11, 350, fractional\\n- 9 - 5: (25, 4) 29, 21, 100, fractional\\n- 9 *5: (45, 25) 70, 20, 1125, fractional\\n- 9 / 5: (25, 1.8) fractional, fractional, 45, fractional\\n- 9 + 1: (10, 5) 15, 5, 50, 2\\n- 9 - 1: (8, 5) 13, 3, 40, fractional\\n- 9 *1: (9, 5) 14, 4, 45, fractional\\n- 9 / 1: (9, 5) 14, 4, 45, fractional\\n- 5 + 1: (9, 6) 15, 3, 54, fractional\\n- 5 - 1: (9, 4) 13, 5, 36, fractional\\n- 5 *1: (9, 5) 14, 4, 45, fractional\\n- 5 / 1: (9, 5) 14, 4, 45, fractional\\nTrying another promising first operation:\\n5. 9 *5: (45, 5, 5)\\n- 45 + 5: (50, 5) 55, 45, 250, 10\\n- 45 - 5: (40, 5) 45, 35, 200, 8\\n- 45 *5: (225, 5) 230, 220, 1125, 45\\n- 45 / 5: (9, 5) 14, 4, 45, fractional\\n- 5 + 5: (10, 4) 14, 6, 40, fractional\\n- 5 - 5: (4, 0) 4, 4, 0, undefined\\n- 5 *5: (25, 4) 29, 21, 100, fractional\\n- 5 / 5: (4, 1) 5, 3, 4, 4\\nTrying another promising first operation:\\n6. 5 + 5: (10, 9, 5)\\n- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\\nBacktracking the solution:\\nStep 1:\\n5 + 5 = 10' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 20}\n",
      "page_content='Step 2:\\n10 + 9 = 19\\nStep 3:\\n19 + 5 = 24\\nConsidering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\\nanswer: ((5 + 5) + 9) + 5 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 6 4 4\\nAssistant:\\nTrying a promising first operation:\\n1. 8 *6: (48, 4, 4)\\n- 48 + 4: (52, 4) 56, 48, 208, 13\\n- 48 - 4: (44, 4) 48, 40, 176, 11\\n- 48 *4: (192, 4) 196, 188, 768, 48\\n- 48 / 4: (12, 4) 16, 8, 48, 3\\n- 4 + 4: (48, 8) 56, 40, 384, 6\\n- 4 - 4: (48, 0) 48, 48, 0, undefined\\n- 4 *4: (48, 16) 64, 32, 768, 3\\n- 4 / 4: (48, 1) 49, 47, 48, 48\\nTrying another promising first operation:\\n2. 4 - 4: (8, 6, 0)\\n- 8 + 6: (14, 0) 14, 14, 0, undefined\\n- 8 - 6: (2, 0) 2, 2, 0, undefined\\n- 8 *6: (48, 0) 48, 48, 0, undefined\\n- 8 / 6: (1.3, 0) fractional\\n- 8 + 0: (8, 6) 14, 2, 48, fractional\\n- 8 - 0: (8, 6) 14, 2, 48, fractional\\n- 8 *0: (6, 0) 6, 6, 0, undefined\\n- 8 / 0: undefined\\n- 6 + 0: (8, 6) 14, 2, 48, fractional\\n- 6 - 0: (8, 6) 14, 2, 48, fractional\\n- 6 *0: (8, 0) 8, 8, 0, undefined\\n- 6 / 0: undefined\\nTrying another promising first operation:\\n3. 4 / 4: (8, 6, 1)\\n- 8 + 6: (14, 1) 15, 13, 14, 14\\n- 8 - 6: (2, 1) 3, 1, 2, 2\\n- 8 *6: (48, 1) 49, 47, 48, 48\\n- 8 / 6: (1.3, 1) fractional\\n- 8 + 1: (9, 6) 15, 3, 54, fractional\\n- 8 - 1: (7, 6) 13, 1, 42, fractional\\n- 8 *1: (8, 6) 14, 2, 48, fractional\\n- 8 / 1: (8, 6) 14, 2, 48, fractional\\n- 6 + 1: (8, 7) 15, 1, 56, fractional\\n- 6 - 1: (8, 5) 13, 3, 40, fractional\\n- 6 *1: (8, 6) 14, 2, 48, fractional\\n- 6 / 1: (8, 1) 9, 7, 8, 8\\nTrying another promising first operation:\\n4. 8 - 6: (4, 4, 2)\\n- 4 + 4: (8, 2) 10, 6, 16, 4\\n- 4 - 4: (2, 0) 2, 2, 0, undefined\\n- 4 *4: (16, 2) 18, 14, 32, 8\\n- 4 / 4: (2, 1) 3, 1, 2, 2\\n- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 - 6 = 2\\nStep 2:\\n4 + 2 = 6\\nStep 3:\\n6*4 = 24' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 21}\n",
      "page_content='Considering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\\nanswer: (4 + (8 - 6)) *4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 10 9 4\\nAssistant:\\nTrying a promising first operation:\\n1. 13 - 4: (10, 9, 9)\\n- 10 + 9: (19, 9) 28, 10, 171, fractional\\n- 10 - 9: (9, 1) 10, 8, 9, 9\\n- 10 *9: (90, 9) 99, 81, 810, fractional\\n- 10 / 9: fractional\\n- 9 + 9: (18, 10) 28, 8, 180, fractional\\n- 9 - 9: (10, 0) 10, 10, 0, undefined\\n- 9 *9: (81, 10) 91, 71, 810, fractional\\n- 9 / 9: (10, 1) 11, 9, 10, 10\\nTrying another promising first operation:\\n2. 13 / 10: (9, 4, 1.3)\\n- 9 + 4: (13, 1.3) fractional, fractional, fractional, 10\\n- 9 - 4: (5, 1.3) fractional\\n- 9 *4: (36, 1.3) fractional\\n- 9 / 4: (2.3, 1.3) fractional, 1, fractional, fractional\\n- 9 + 1.3: (10.3, 4) fractional\\n- 9 - 1.3: (7.7, 4) fractional\\n- 9 *1.3: (11.7, 4) fractional\\n- 9 / 1.3: (6.9, 4) fractional\\n- 4 + 1.3: (9, 5.3) fractional\\n- 4 - 1.3: (9, 2.7) fractional\\n- 4 *1.3: (9, 5.2) fractional\\n- 4 / 1.3: (9, 3.1) fractional\\nTrying another promising first operation:\\n3. 9 / 4: (13, 10, 2.3)\\n- 13 + 10: (23, 2.3) fractional, fractional, fractional, 10\\n- 13 - 10: (3, 2.3) fractional\\n- 13 *10: (130, 2.3) fractional\\n- 13 / 10: (2.3, 1.3) fractional, 1, fractional, fractional\\n- 13 + 2.3: (15.3, 10) fractional, fractional, 153, fractional\\n- 13 - 2.3: (11.7, 10) fractional, fractional, 117, fractional\\n- 13 *2.3: (29.9, 10) fractional, fractional, 299, fractional\\n- 13 / 2.3: (10, 5.6) fractional, fractional, 560, fractional\\n- 10 + 2.3: (13, 12.3) fractional\\n- 10 - 2.3: (13, 7.7) fractional\\n- 10 *2.3: (23, 13) 36, 10, 299, fractional\\n- 10 / 2.3: (13, 4.3) fractional\\nTrying another promising first operation:\\n4. 13 / 4: (10, 9, 3.3)\\n- 10 + 9: (19, 3.3) fractional\\n- 10 - 9: (3.3, 1) fractional\\n- 10 *9: (90, 3.3) fractional\\n- 10 / 9: (3.3, 1.1) fractional, fractional, fractional, 3\\n- 10 + 3.3: (13.3, 9) fractional\\n- 10 - 3.3: (9, 6.7) fractional\\n- 10 *3.3: (33, 9) 42, 24, 297, fractional\\n- 10 / 3.3: (3.1, 9) fractional\\n- 9 + 3.3: (12.3, 10) fractional, fractional, 123, fractional\\n- 9 - 3.3: (10, 5.7) fractional, fractional, 57, fractional\\n- 9 *3.3: (29.7, 10) fractional, fractional, 297, fractional\\n- 9 / 3.3: (10, 2.7) fractional, fractional, 27, fractional\\nTrying another promising first operation:\\n5. 13 / 9: (10, 9, 1.4)\\n- 10 + 9: (19, 1.4) fractional\\n- 10 - 9: (1.4, 1) fractional\\n- 10 *9: (90, 1.4) fractional, fractional, 130, fractional\\n- 10 / 9: (1.1, 1.4) fractional\\n- 10 + 1.4: (11.4, 9) fractional' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 22}\n",
      "page_content='- 10 - 1.4: (9, 8.6) fractional\\n- 10 *1.4: (140, 9) 149, 131, 1260, fractional\\n- 10 / 1.4: (9, 7.1) fractional\\n- 9 + 1.4: (10.4, 10) fractional, fractional, 104, fractional\\n- 9 - 1.4: (10, 7.6) fractional, fractional, 76, fractional\\n- 9 *1.4: (12.6, 10) fractional, fractional, 126, fractional\\n- 9 / 1.4: (10, 6.4) fractional, fractional, 64, fractional\\nTrying another promising first operation:\\n6. 10 - 4: (13, 9, 6)\\n- 13 + 9: (22, 6) 28, 16, 132, fractional\\n- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n10 - 4 = 6\\nStep 2:\\n13 - 9 = 4\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\\nanswer: (10 - 4) *(13 - 9) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nAoT (Random)\\nSystem:\\nUse numbers and basic arithmetic operations (+ - */) to obtain 24. Each step, you\\nare only allowed to choose two of the remaining numbers to obtain a new\\nnumber.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n4 4 6 8.\\nAssistant:\\nTrying a promising first operation:\\n(4 + 4) *6 - 8 = 40.\\nTrying another promising first operation:\\n(8 - 6) *4 + 4 = 12.\\nTrying another promising first operation:\\n(6 - 4) *(4 + 8) = 24.\\nanswer: (6 - 4) *(4 + 8) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n2 9 10 12.\\nAssistant:\\nTrying a promising first operation:\\n((12 - 10) / 2) + 9 = 10.\\nTrying another promising first operation:\\n(10 + 9) + (12 / 2) = 25.\\nTrying another promising first operation:\\n(12 *2)*(10 - 9) = 24.\\nanswer: (12 *2)*(10 - 9) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n4 9 10 13.\\nAssistant:\\nTrying a promising first operation:\\n((13 - 10) / 4) + 9 = 10.\\nTrying another promising first operation:\\n4*(9 - (13 - 10)) = 24.\\nanswer: 4 *(9 - (13 - 10)) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 23}\n",
      "page_content='1 4 8 8.\\nAssistant:\\nTrying a promising first operation:\\n(8 + 1) + 4 *8 + 32.\\nTrying another promising first operation:\\n(1 + 8 / 4) *8 = 24.\\nanswer: (1 + 8 / 4) *8 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n5 5 5 9.\\nAssistant:\\nTrying a promising first operation:\\n((5 + 5) + 5) + 9 = 24.\\nanswer: ((5 + 5) + 5) + 9 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nAoT (BFS)\\nSystem:\\nUse numbers and basic arithmetic operations (+ - */) to obtain 24. When\\nconsidering the next steps, do not choose operations that will result in a\\nnegative or fractional number. In order to help with the calculations, the\\nnumbers in the parenthesis represent the numbers that are left after the\\noperations and they are in descending order.\\nAnother thing we do is when there are only two numbers left in the parenthesis, we\\ncheck whether we can arrive at 24 only by using basic arithmetic operations\\n(+ - */). Some examples regarding this idea:\\n(21, 2): 23, 19, 42, fractional\\n(30, 6): 36, 24 = 30 - 6 -> found it!\\n(8, 3): 11, 5, 24 = 8 *3 yes\\n(12, 8): 20, 4, 72, fractional\\nIn the second steps, when there are three numbers left, we choose the most\\npromising operations so that when we are left with two numbers, we will be\\nable to get to 24.\\nSo, when we reach 24 in the third steps, that means we found the solution, we\\ndirectly backtrack to write the answer.\\nIn each step, we want to choose the best operations so that the numbers left, will\\nhave a good chance to reach 24.\\nUser:\\n14 8 8 2\\nAssistant:\\nLet’s consider the most promising possible first steps:\\n1. 8 + 8: (16, 14, 2)\\n2. 14 - 8: (8, 6, 2)\\n3. 14 + 2: (16, 8, 8)\\n4. 8 / 2: (14, 8, 4)\\nLet’s consider the most promising second steps:\\n1. (16, 14, 2)\\n- 16 - 14: (2, 2)\\n- 16 / 2: (8, 14)\\n- 14 *2: (28, 16)\\n- 14 / 2: (7, 16)\\n2. (8, 6, 2)\\n- 8 - 6: (2, 2)\\n- 8 / 2: (4, 6)\\n- 6 *2: (12, 8)\\n- 6 / 2: (3, 8)\\n3. (16, 8, 8)' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 24}\n",
      "page_content='- 16 - 8: (8, 8)\\n- 16 / 8: (2, 8)\\n- 8 *8: (64, 16)\\n- 8 / 8: (1, 16)\\n4. (14, 8, 4)\\n- 14 - 8: (6, 4)\\n- 14 / 4: (3.5, 8)\\n- 8 *4: (32, 14)\\n- 8 / 4: (2, 14)\\nLet’s consider the most promising third steps:\\n1. 8 + 8 = 16\\n- 16 - 14: (2, 2): 4, 0, 4, 1\\n- 16 / 2: (8, 14): 22, 6, 112, fractional\\n- 14 *2: (28, 16): 44, 12, 448, fractional\\n- 14 / 2: (7, 16): 23, 9, 112, fractional\\n2. 14 - 8 = 6\\n- 8 - 6: (2, 2): 4, 0, 4, 1\\n- 8 / 2: (6, 4): 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n14 - 8 = 6\\nStep 2:\\n8 / 2 = 4\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (14 - 8) *(8 / 2) = 24.\\nanswer: (14 - 8) *(8 / 2) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 5 5 5\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 9 - 5: (5, 5, 4)\\n2. 5 + 5: (9, 10, 5)\\n3. 9 + 5: (14, 5, 5)\\n4. 5 - 5: (9, 5, 0)\\nLet’s consider the most promising second steps:\\n1. (5, 5, 4)\\n- 5 + 5: (10, 4)\\n- 5 *4: (20, 5)\\n- 5 - 4: (5, 1)\\n- 5 / 4: (5, 1.25)\\n2. (9, 10, 5)\\n- 10 + 9: (19, 5)\\n- 10 - 5: (9, 5)\\n- 10 *5: (50, 9)\\n- 10 / 5: (9, 2)\\n3. (14, 5, 5)\\n- 14 - 5: (9, 5)\\n- 14 + 5: (19, 5)\\n- 5 *5: (25, 14)\\n- 5 / 5: (14, 1)\\n4. (9, 5, 0)\\n- 9 + 5: (14, 0)\\n- 9 - 5: (4, 0)\\n- 5 *0: (9, 0)\\n- 5 / 0: (9, infinity)' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 25}\n",
      "page_content='Let’s consider the most promising third steps:\\n1. 9 - 5 = 4\\n- 5 + 5: (10, 4): 14, 6, 40, fractional\\n- 5 *4: (20, 5): 25, 15, 100, 4\\n- 5 - 4: (5, 1): 6, 4, 5, 5\\n- 5 / 4: (5, 1.25): 6.25, 3.75, 6.25, 4\\n2. 5 + 5 = 10\\n- 10 + 9: (19, 5): 24 = 19 + 5 -> found it!\\nBacktracking the solution:\\nStep 1:\\n5 + 5 = 10\\nStep 2:\\n10 + 9 = 19\\nStep 3:\\n19 + 5 = 24\\nConsidering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\\nanswer: ((5 + 5) + 9) + 5 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 6 4 4\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 8 *6: (48, 4, 4)\\n2. 8 + 4: (12, 6, 4)\\n3. 8 - 6: (4, 4, 2)\\n4. 6 - 4: (8, 4, 2)\\nLet’s consider the most promising second steps:\\n1. (48, 4, 4)\\n- 4 *4: (48, 16)\\n- 48 / 4: (12, 4)\\n- 4 + 4: (48, 8)\\n- 48 - 4: (44, 4)\\n2. (12, 6, 4)\\n- 12 + 6: (18, 4)\\n- 6 *4: (24, 12)\\n- 6 + 4: (12, 10)\\n- 12 / 4: (6, 3)\\n3. (4, 4, 2)\\n- 4 *4: (16, 2)\\n- 4 + 2: (6, 4)\\n- 4 + 4: (8, 2)\\n- 4 *2: (8, 4)\\n4. (8, 4, 2)\\n- 8 *4: (32, 2)\\n- 4 *2: (8, 8)\\n- 8 + 4: (12, 2)\\n- 8 / 4: (4, 2)\\nLet’s consider the most promising third steps:\\n1. 8 *6 = 48\\n- 4 *4: (48, 16): 64, 32, big, 3\\n- 48 / 4: (12, 4): 16, 8, 48, 3\\n- 4 + 4: (48, 8): 56, 40, big, 6\\n- 48 - 4: (44, 4): 48, 40, big, 11\\n2. 8 + 4 = 12\\n- 12 + 6: (18, 4): 22, 14, 72, fractional\\n- 6 *4: (24, 12): 36, 12, 288, 2\\n- 6 + 4: (12, 10): 22, 2, 120, fractional\\n- 12 / 4: (6, 3): 9, 3, 18, 2' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 26}\n",
      "page_content='3. 8 - 6 = 2\\n- 4 *4: (16, 2): 19, 14, 32, 8\\n- 4 + 2: (6, 4): 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 - 6 = 2\\nStep 2:\\n4 + 2 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\\nanswer: (4 + (8 - 6)) *4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 10 9 4\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 13 - 4: (10, 9, 9)\\n2. 10 - 4: (13, 9, 6)\\n3. 13 + 9: (22, 10, 4)\\n4. 10 - 9: (13, 4, 1)\\nLet’s consider the most promising second steps:\\n1. (10, 9, 9)\\n- 10 + 9: (19, 9)\\n- 10 - 9: (9, 1)\\n- 9 + 9: (18, 10)\\n- 9 / 9: (9, 1)\\n2. (13, 9, 6)\\n- 9 + 6: (15, 13)\\n- 9 *6: (54, 13)\\n- 13 - 9: (6, 4)\\n- 13 - 6: (9, 7)\\n3. (22, 10, 4)\\n- 22 - 10: (12, 4)\\n- 22 - 4: (18, 10)\\n- 10 *4: (40, 22)\\n- 10 / 4: (22, 5.5)\\n4. (13, 4, 1)\\n- 13 - 4: (9, 1)\\n- 13 *4: (52, 1)\\n- 4 - 1: (13, 3)\\n- 13 - 1: (12, 4)\\nLet’s consider the most promising third steps:\\n1. 13 - 4 = 9\\n- 10 + 9: (19, 9): 28, 10, 171, fractional\\n- 10 - 9: (9, 1): 10, 8, 9, 9\\n- 9 + 9: (18, 10): 28, 8, 180, fractional\\n- 9 / 9: (9, 1): 10, 8, 9, 9\\n2. 10 - 4 = 6\\n- 9 + 6: (15, 13): 28, 2, 195, fractional\\n- 9 *6: (54, 13): 67, 41, 702, fractional\\n- 13 - 9: (6, 4): 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n13 - 9 = 4\\nStep 2:\\n10 - 4 = 6\\nStep 3:' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 27}\n",
      "page_content='6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (10 - 4) *(13 - 9) = 24.\\nanswer: (10 - 4) *(13 - 9) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 8 5 4\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 5 + 4: (9, 8, 8)\\n2. 8 / 4: (8, 5, 2)\\n3. 8 - 5: (8, 4, 3)\\n4. 8 / 8: (5, 4, 1)\\nLet’s consider the most promising second steps:\\n1. (9, 8, 8)\\n- 9 + 8: (17, 8)\\n- 8 + 8: (16, 9)\\n- 9 *8: (72, 8)\\n- 8 / 8: (9, 1)\\n2. (8, 5, 2)\\n- 5 - 2: (8, 3)\\n- 8 - 2: (6, 5)\\n- 8 + 5: (13, 2)\\n- 5 *2: (10, 8)\\n3. (8, 4, 3)\\n- 8 - 4: (4, 3)\\n- 8 - 3: (5, 4)\\n- 4 *3: (12, 8)\\n- 4 + 3: (8, 7)\\n4. (5, 4, 1)\\n- 5 + 4: (9, 1)\\n- 5 - 4: (1, 1)\\n- 4 - 1: (5, 3)\\n- 5 + 1: (6, 4)\\nLet’s consider the most promising third steps:\\n1. 5 + 4 = 9\\n- 9 + 8: (17, 8): 25, 9, 136, fractional\\n- 8 + 8: (16, 9): 25, 7, 144, fractional\\n- 9 *8: (72, 8): 80, 64, 576, 9\\n- 8 / 8: (9, 1): 10, 8, 9, 9\\n2. 8 / 4 = 2\\n- 5 - 2: (8, 3): 11, 5, 24 = 8 *3 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 4 = 2\\nStep 2:\\n5 - 2 = 3\\nStep 3:\\n8*3 = 24\\nConsidering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\\nanswer: 8 *(5 - (8 / 4)) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 11 1 1\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 11 - 1: (11, 10, 1)\\n2. 11 + 1: (12, 11, 1)\\n3. 11 + 11: (22, 1, 1)\\n4. 1 + 1: (11, 11, 2)' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 28}\n",
      "page_content='Let’s consider the most promising second steps:\\n1. (11, 10, 1)\\n- 11 + 10: (21, 1)\\n- 10 + 1: (11, 11)\\n- 10 / 1: (11, 10)\\n- 11 / 1: (11, 10)\\n2. (12, 11, 1)\\n- 12 + 11: (23, 1)\\n- 11 + 1: (12, 11)\\n- 11 - 1: (12, 10)\\n- 12 + 1: (13, 11)\\n3. (22, 1, 1)\\n- 22 + 1: (23, 1)\\n- 1 + 1: (22, 2)\\n- 22 / 1: (22, 1)\\n- 1 / 1: (22, 1)\\n4. (11, 11, 2)\\n- 11 + 11: (22, 2)\\n- 11 *2: (22, 11)\\n- 11 + 2: (13, 11)\\n- 2 *11: (22, 11)\\nLet’s consider the most promising third steps:\\n1. 11 - 1 = 10\\n- 11 + 10: (21, 1): 22, 20, 21, 20\\n- 10 + 1: (11, 11): 22, 10, 121, 0\\n- 10 / 1: (11, 10): 21, 1, 110, 0\\n- 11 / 1: (11, 10): 21, 1, 110, 0\\n2. 11 + 1 = 12\\n- 12 + 11: (23, 1): 24 = 23 + 1 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11 + 1 = 12\\nStep 2:\\n12 + 11 = 23\\nStep 3:\\n23 + 1 = 24\\nConsidering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\\nanswer: ((11 + 1) + 11) + 1 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 7 4 1\\nAssistant:\\nLet’s consider the most promising first steps:\\n1. 7 *4: (28, 11, 1)\\n2. 7 + 1: (11, 8, 4)\\n3. 4 + 1: (11, 7, 5)\\n4. 11 - 4: (7, 3, 1)\\nLet’s consider the most promising second steps:\\n1. (28, 11, 1)\\n- 28 - 11: (17, 1)\\n- 28 - 1: (27, 11)\\n- 11 + 1: (29, 28)\\n- 11 - 1: (28, 10)\\n2. (11, 8, 4)\\n- 11 + 8: (19, 4)\\n- 8 + 4: (12, 11)\\n- 11 - 8: (4, 3)' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 29}\n",
      "page_content='- 8 - 4: (7, 11)\\n3. (11, 7, 5)\\n- 11 - 5: (7, 6)\\n- 7 - 5: (11, 2)\\n- 7 *5: (35, 11)\\n- 11 + 5: (16, 7)\\n4. (7, 3, 1)\\n- 7 - 3: (4, 1)\\n- 7 *3: (21, 1)\\n- 3 + 1: (7, 4)\\n- 7 - 1: (6, 3)\\nLet’s consider the most promising third steps:\\n1. 7 *4 = 28\\n- 28 - 11: (17, 1): 18, 16, 17, 17\\n- 28 - 1: (27, 11): 38, 16, 297, 2.45\\n- 11 + 1: (29, 28): 57, 1, 812, 1.03\\n- 11 - 1: (28, 10): 38, 18, 280, 2.8\\n2. 7 + 1 = 8\\n- 11 + 8: (19, 4): 23, 15, 76, 4.75\\n- 8 + 4: (12, 11): 23, 7, 132, 3\\n- 11 - 8: (4, 3): 7, 1, 12, 1.33\\n- 8 - 4: (7, 11): 18, 4, 77, 1.75\\n3. 4 + 1 = 5\\n- 11 - 5: (7, 6): 13, 1, 42, 1.17\\n- 7 - 5: (11, 2): 13, 9, 22, 5.5\\n- 7 *5: (35, 11): 46, 24 = 35 - 11 -> found it!\\nBacktracking the solution:\\nStep 1:\\n4 + 1 = 5\\nStep 2:\\n7*5 = 35\\nStep 3:\\n35 - 11 = 24\\nConsidering these steps: 24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\\nanswer: (7 *(4 + 1)) - 11 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 5 4 3\\nAssistant:\\nLet’s consider the most promising first steps to reach 24:\\n1. 11 *3: (33, 5, 4)\\n2. 5 + 4: (11, 9, 3)\\n3. 11 - 4: (7, 5, 3)\\n4. 4 + 3: (11, 7, 5)\\nLet’s consider the most promising second steps to reach 24:\\n1. (33, 5, 4)\\n- 33 - 5: (28, 4)\\n- 33 - 4: (29, 5)\\n- 5 + 4: (33, 9)\\n- 5 *4: (20, 33)\\n2. (11, 9, 3)\\n- 11 *3: (33, 9)\\n- 11 + 3: (14, 9)\\n- 9 + 3: (12, 11)\\n- 9 / 3: (11, 3)\\n3. (7, 5, 3)' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 30}\n",
      "page_content='- 7 - 3: (4, 5)\\n- 7 + 5: (12, 3)\\n- 5 + 3: (8, 7)\\n- 5 *3: (7, 6)\\n4. (11, 7, 5)\\n- 11 + 7: (18, 5)\\n- 11 - 5: (6, 7)\\n- 7 + 5: (12, 11)\\n- 7 - 5: (2, 11)\\nLet’s consider the most promising third steps to reach 24:\\n1. 11 *3 = 33\\n- 33 - 5: (28, 4): 32, 24 = 28 - 4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11*3 = 33\\nStep 2:\\n33 - 5 = 28\\nStep 3:\\n28 - 4 = 24\\nConsidering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\\nanswer: ((11 *3) - 5) - 4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 12 5 2\\nAssistant:\\nLet’s consider the most promising first steps to reach 24:\\n1. 12 / 2: (13, 6, 5)\\n2. 13 + 5: (18, 12, 2)\\n3. 12 - 5: (13, 7, 2)\\n4. 5 - 2: (13, 12, 3)\\nLet’s consider the most promising second steps to reach 24:\\n1. (13, 6, 5)\\n- 13 + 6: (19, 5)\\n- 13 - 5: (8, 6)\\n- 6 *5: (30, 13)\\n- 6 - 5: (13, 1)\\n2. (18, 12, 2)\\n- 18 *2: (36, 12)\\n- 12 / 2: (18, 6)\\n- 18 - 2: (16, 12)\\n- 12 *2: (24, 18)\\n3. (13, 7, 2)\\n- 13 + 7: (20, 2)\\n- 13 - 2: (11, 7)\\n- 7 *2: (14, 13)\\n- 7 - 2: (13, 5)\\n4. (13, 12, 3)\\n- 13 *3: (39, 12)\\n- 13 - 3: (10, 12)\\n- 12 *3: (36, 13)\\n- 12 / 3: (13, 4)\\nLet’s consider the most promising third steps to reach 24:\\n1. 12 / 2 = 6\\n- 13 + 6: (19, 5): 24 = 19 + 5 -> found it!\\nBacktracking the solution:\\nStep 1:\\n12 / 2 = 6\\nStep 2:' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 31}\n",
      "page_content='13 + 6 = 19\\nStep 3:\\n19 + 5 = 24\\nConsidering these steps: 24 = 19 + 5 = (13 + 6) + 5 = (13 + (12 / 2)) + 5 = 24.\\nanswer: (13 + (12 / 2)) + 5 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 8 2 1\\nAssistant:\\nLet’s consider the most promising first steps to reach 24:\\n1. 9 - 1: (8, 8, 2)\\n2. 8 + 2: (10, 9, 1)\\n3. 9 + 1: (10, 8, 2)\\n4. 2 + 1: (9, 8, 3)\\nLet’s consider the most promising second steps to reach 24:\\n1. (8, 8, 2)\\n- 8 + 8: (16, 2)\\n- 8 *2: (16, 8)\\n- 8 - 2: (6, 8)\\n- 8 + 8: (16, 2)\\n2. (10, 9, 1)\\n- 10 + 9: (19, 1)\\n- 10 - 1: (9, 9)\\n- 9 + 1: (10, 10)\\n- 9 / 1: (8, 10)\\n3. (10, 8, 2)\\n- 10 + 8: (18, 2)\\n- 10 *2: (8, 8)\\n- 8 + 2: (10, 10)\\n- 8 / 2: (6, 10)\\n4. (9, 8, 3)\\n- 9 + 8: (17, 3)\\n- 9 / 3: (6, 8)\\n- 8 + 3: (11, 9)\\n- 8 *3: (24, 9)\\nLet’s consider the most promising third steps to reach 24:\\n1. 9 - 1 = 8\\n- 8 + 8: (16, 2): 18, 14, 32, 8\\n- 8 *2: (16, 8): 24 = 16 + 8 -> found it!\\nBacktracking the solution:\\nStep 1:\\n9 - 1 = 8\\nStep 2:\\n8*2 = 16\\nStep 3:\\n16 + 8 = 24\\nConsidering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\\nanswer: ((9 - 1) *2) + 8 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nAoT (Short)\\nSystem:\\nUse numbers and basic arithmetic operations (+ - */) to obtain 24. When\\nconsidering the next steps, do not choose operations that will result in a\\nnegative or fractional number. In order to help with the calculations, the\\nnumbers in the parenthesis represent the numbers that are left after the\\noperations and they are in descending order.' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 32}\n",
      "page_content='Another thing we do is when there are only two numbers left in the parenthesis, we\\ncheck whether we can arrive at 24 only by using basic arithmetic operations\\n(+ - */). Some examples regarding this idea:\\n(21 2) no\\nsince 21 + 2 = 23, 21 - 2 = 19, 21 *2 = 42, 21 / 2 = 10.5, none of which is equal\\nto 24.\\n(30 6) 30 - 6 = 24 yes\\n(8 3) 8 *3 = 24 yes\\n(12 8) no\\n(48 2) 48 / 2 = 24 yes\\nMost importantly, do not give up, all the numbers that will be given has indeed a\\nsolution.\\nUser:\\n14 8 8 2\\nAssistant:\\nTrying a promising first operation:\\n1. 8 / 2: (14, 8, 4)\\n- 14 + 8: (22, 4) 26, 18, 88, fractional\\n- 14 - 8: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 2 = 4\\nStep 2:\\n14 - 8 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (14 - 8) *4 = (14 - 8) *(8 / 2) = 24.\\nanswer: (14 - 8) *(8 / 2) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 5 5 5\\nAssistant:\\nTrying a promising first operation:\\n1. 5 + 5: (10, 9, 5)\\n- 10 + 9: (19, 5) 24 = 19 + 5 -> found it!\\nBacktracking the solution:\\nStep 1:\\n5 + 5 = 10\\nStep 2:\\n10 + 9 = 19\\nStep 3:\\n19 + 5 = 24\\nConsidering these steps: 24 = 19 + 5 = (10 + 9) + 5 = ((5 + 5) + 9) + 5 = 24.\\nanswer: ((5 + 5) + 9) + 5 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 6 4 4\\nAssistant:\\nTrying a promising first operation:\\n1. 8 - 6: (4, 4, 2)\\n- 4 + 4: (8, 2) 10, 6, 16, 4\\n- 4 - 4: (2, 0) 2, 2, 0, undefined\\n- 4 *4: (16, 2) 18, 14, 32, 8\\n- 4 / 4: (2, 1) 3, 1, 2, 2\\n- 4 + 2: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 - 6 = 2\\nStep 2:\\n4 + 2 = 6\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = (4 + 2) *4 = (4 + (8 - 6)) *4 = 24.\\nanswer: (4 + (8 - 6)) *4 = 24.' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 33}\n",
      "page_content='˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 10 9 4\\nAssistant:\\nTrying a promising first operation:\\n1. 10 - 4: (13, 9, 6)\\n- 13 + 9: (22, 6) 28, 16, 132, fractional\\n- 13 - 9: (6, 4) 10, 2, 24 = 6 *4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n10 - 4 = 6\\nStep 2:\\n13 - 9 = 4\\nStep 3:\\n6*4 = 24\\nConsidering these steps: 24 = 6 *4 = 6 *(13 - 9) = (10 - 4) *(13 - 9) = 24.\\nanswer: (10 - 4) *(13 - 9) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n8 8 5 4\\nAssistant:\\nTrying a promising first operation:\\n1. 8 / 4: (8, 5, 2)\\n- 8 + 5: (13, 2) 15, 11, 26, fractional\\n- 8 - 5: (3, 2) 5, 1, 6, 1.5\\n- 8 *5: (40, 2) 42, 38, 80, 20\\n- 8 / 5: fractional\\n- 8 + 2: (10, 5) 15, 5, 50, 2\\n- 8 - 2: (6, 5) 11, 1, 30, fractional\\n- 8 *2: (16, 5) 21, 11, 80, fractional\\n- 8 / 2: (5, 4) 9, 1, 20, fractional\\n- 5 + 2: (7, 8) 15, 1, 56, fractional\\n- 5 - 2: (8, 3) 11, 5, 24 = 8 *3 -> found it!\\nBacktracking the solution:\\nStep 1:\\n8 / 4 = 2\\nStep 2:\\n5 - 2 = 3\\nStep 3:\\n8*3 = 24\\nConsidering these steps: 24 = 8 *3 = 8 *(5 - 2) = 8 *(5 - (8 / 4)) = 24.\\nanswer: 8 *(5 - (8 / 4)) = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 11 1 1\\nAssistant:\\nTrying a promising first operation:\\n1. 11 + 1: (12, 11, 1)\\n- 12 + 11: (23, 1) 24 = 23 + 1 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11 + 1 = 12\\nStep 2:\\n12 + 11 = 23\\nStep 3:\\n23 + 1\\nConsidering these steps: 24 = 23 + 1 = (12 + 11) + 1 = ((11 + 1) + 11) + 1 = 24.\\nanswer: ((11 + 1) + 11) + 1 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 7 4 1\\nAssistant:\\nTrying a promising first operation:\\n1. 4 + 1: (11 7 5)\\n- 11 + 7: (18, 5) 23, 13, 90, fractional' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 34}\n",
      "page_content='- 11 - 7: (5, 4) 9, 1, 20, fractional\\n- 11 *7: (77, 5) 82, 72, 385, fractional\\n- 11 / 7: fractional\\n- 11 + 5: (16, 7) 23, 9, 112, fractional\\n- 11 - 5: (7, 6) 13, 1, 42, fractional\\n- 11 *5: (55, 7) 62, 48, 385, fractional\\n- 11 / 5: fractional\\n- 7 + 5: (12, 11) 23, 1, 132, fractional\\n- 7 - 5: (11, 2) 13, 9, 22, fractional\\n- 7 *5: (35, 11) 46, 24 = 35 - 11 -> found it!\\nStep 1:\\n4 + 1 = 5\\nStep 2:\\n7*5 = 35\\nStep 3:\\n35 - 11 = 24\\nConsidering these steps: Backtracking the solution:\\n24 = 35 - 11 = (7 *5) - 11 = (7 *(4 + 1)) - 11 = 24.\\nanswer: (7 *(4 + 1)) - 11 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n11 5 4 3\\nAssistant:\\nTrying a promising first operation:\\n1. 11 *3: (33, 5, 4)\\n- 33 + 5: (38, 4) 42, 34, 152, fractional\\n- 33 - 5: (28, 4) 32, 24 = 28 - 4 -> found it!\\nBacktracking the solution:\\nStep 1:\\n11*3 = 33\\nStep 2:\\n33 - 5 = 28\\nStep 3:\\n28 - 4 = 24\\nConsidering these steps: 24 = 28 - 4 = (33 - 5) - 4 = ((11 *3) - 5) - 4 = 24.\\nanswer: ((11 *3) - 5) - 4 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n13 12 5 2\\nAssistant:\\nTrying a promising first operation:\\n1. 13 + 5: (18, 12, 2)\\n- 18 + 12: (30, 2) 32, 28, 60, fractional\\n- 18 - 12: (6, 2) 8, 4, 12, 3\\n- 18 *12: (216, 2) 218, 214, 432, fractional\\n- 18 / 12: fractional\\n- 18 + 2: (20, 12) 32, 8, 240, fractional\\n- 18 - 2: (16, 12) 28, 4, 192, fractional\\n- 18 *2: (36, 12) 48, 24 = 36 - 12 -> found it!\\nBacktracking the solution:\\nStep 1:\\n13 + 5 = 18\\nStep 2:\\n18*2 = 36\\nStep 3:\\n36 - 12 = 24\\nConsidering these steps: 24 = 36 - 12 = (18 *2) - 12 = ((13 + 5) *2) - 12 = 24.\\nanswer: ((13 + 5) *2) - 12 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\n9 8 2 1\\nAssistant:\\nTrying a promising first operation:\\n1. 9 - 1: (8, 8, 2)\\n- 8 + 8: (16, 2) 18, 14, 32, 8' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 35}\n",
      "page_content='- 8 - 8: (2, 0) 2, 2, 0, undefined\\n- 8 *8: (64, 2) 66, 62, 128, 32\\n- 8 / 8: (2, 1) 3, 1, 2, 2\\n- 8 + 2: (10, 8) 18, 2, 80, 4\\n- 8 - 2: (6, 8) 14, -2, 48, fractional\\n- 8 *2: (16, 8) 24 = 16 + 8 -> found it!\\nBacktracking the solution:\\nStep 1:\\n9 - 1 = 8\\nStep 2:\\n8*2 = 16\\nStep 3:\\n16 + 8 = 24\\nConsidering these steps: 24 = 16 + 8 = (8 *2) + 8 = ((9 - 1) *2) + 8 = 24.\\nanswer: ((9 - 1) *2) + 8 = 24.\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\n5×5Mini Crosswords Prompts\\nIn the following we give all the exact prompts we used for the methods given in the experiments section and some selection of\\nthe generations from the LLM. In the prompts the keywords “System”, “User” and “Assistant” used are the roles in the OpenAI\\nAPI in chat completion mode. The line breaks are to show the turns between the user and assistant in the API.\\nAoT\\nUser:\\nh1. A lunar valley\\nh2. A fatty oil\\nh3. To entice\\nh4. To lower; to reduce\\nh5. A solitary person\\nv1. According to the roster\\nv2. Another name for Port-Francqui\\nv3. An illicit lover; a European lake\\nv4. To lisp\\nv5. To come in\\nThe words I already found are:\\nh1. rille\\nh3. tempt\\nv2. ilebo\\nv5. enter\\nAssistant:\\nThere are two horizontal and two vertical words. Since they are the amount, let’s\\nconsider the next unfound horizontal word, which is h2. Since we are\\nconsidering the second horizontal word, we need to look at the second letters\\nof the vertical words we found:\\n- What is the second letter of ilebo: e\\n- What is the second letter of enter: n\\nThe word we are looking fits the clue \"A fatty oil\" and needs to have the letters\\ne and n in its (v2, two) second and (v5, five) fifth letters: _ e _ _ n. The\\ncandidates are: oleic, olein, olive.\\n- oleic (o l e i c, _ e _ _ n) doesn’t fit\\n- olein (o l e i n, _ e _ _ n) fits\\n- olive (o l i v e, _ e _ _ n) doesn’t fit\\nWe add the word olein for h2. The current words are:\\nh1. rille\\nh2. olein\\nh3. tempt\\nv2. ilebo\\nv5. enter\\nNow, let’s consider the next unfound vertical word, which is v1. Since we are\\nconsidering the first vertical word, we need to look at the first letters of\\nthe horizontal words we found:\\n- What is the first letter of rille: r\\n- What is the first letter of olein: o' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 36}\n",
      "page_content='- What is the first letter of tempt: t\\nThe word we are looking fits the clue \"According to the roster\" and needs to have\\nthe letters r, o, and t in its (h1, one) first, (h2, two) second, and (h3,\\nthree) third letters: r o t _ _. The candidates are: none\\nNow, let’s consider the next unfound vertical word, which is v3. Since we are\\nconsidering the third vertical word, we need to look at the third letters of\\nthe horizontal words we found:\\n- What is the third letter of rille: l\\n- What is the third letter of olein: e\\n- What is the third letter of tempt: m\\nThe word we are looking fits the clue \"An illicit lover; a European lake\" and\\nneeds to have the letters l, e, and m in its (h1, one) first, (h2, two) second\\n, and (h3, three) third letters: l e m _ _. The candidates are: leman.\\n- leman (l e m a n, l e m _ _) fits\\nWe add the word leman for v3. The current words are:\\nh1. rille\\nh2. olein\\nh3. tempt\\nv2. ilebo\\nv3. leman\\nv5. enter\\nNow, let’s consider the next unfound horizontal word, which is h4. Since we are\\nconsidering the fourth horizontal word, we need to look at the fourth letters\\nof the vertical words we found:\\n- What is the fourth letter of ilebo: b\\n- What is the fourth letter of leman: a\\n- What is the fourth letter of enter: e\\nThe word we are looking fits the clue \"To lower; to reduce\" and needs to have the\\nletters b, a, and e in its (v2, two) second, (v3, three) third, and (v5, five)\\nfifth letters: _ b a _ e. The candidates are: abase, abate.\\n- abase (a b a s e, _ b a _ e) fits\\n- abate (a b a t e, _ b a _ e) fits\\nSince both fits, let’s consider another word.\\nNow, let’s consider the last unfound vertical word, which is v4. Since we are\\nconsidering the fourth vertical word, we need to look at the fourth letters of\\nthe horizontal words we found:\\n- What is the fourth letter of rille: l\\n- What is the fourth letter of olein: i\\n- What is the fourth letter of tempt: p\\nThe word we are looking fits the clue \"To lisp\" and needs to have the letters l, i\\n, p, and s in its (h1, one) first, (h2, two) second, (h3, three) third letters\\n: l i p _ _. The candidates are: The candidate is \"lisps\".\\n- lisps (l i s p s, l i p _ _) doesn’t fit\\nWe have considered all of the words for the horizontal words, we have two options:\\nabase and abate, let’s choose one of them.\\nanswer:\\nh1. rille\\nh2. olein\\nh3. tempt\\nh4. abase\\nv2. ilebo\\nv3. leman\\nv5. enter\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\nh1. One who saws\\nh2. A fungus genus\\nh3. An assessor\\nh4. Pasture land\\nh5. Receiving by the ear\\nv1. To swell; to increase\\nv2. The Brazilian macaw; an Australian bird\\nv3. A Timorese island\\nv4. Excessive fluid accumulation' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 37}\n",
      "page_content='v5. Dewy; roscid\\nThe words I already found are:\\nh1. sawer\\nh3. rater\\nv1. surge\\nv4. edema\\nAssistant:\\nThere are two horizontal and two vertical words. Since they are the amount, let’s\\nconsider the next unfound horizontal word, which is h2. Since we are\\nconsidering the second horizontal word, we need to look at the second letters\\nof the vertical words we found:\\n- What is the second letter of surge: u\\n- What is the second letter of edema: d\\nThe word we are looking fits the clue \"A fungus genus\" and needs to have the\\nletters u and d in its (v1, one) first and (v4, four) fourth letters: u _ _ d\\n_. The candidates are: uredo.\\n- uredo (u r e d o, u _ _ d _) fits\\nWe add the word uredo for h2. The current words are:\\nh1. sawer\\nh2. uredo\\nh3. rater\\nv1. surge\\nv4. edema\\nNow, let’s consider the next unfound vertical word, which is v2. Since we are\\nconsidering the second vertical word, we need to look at the second letters of\\nthe horizontal words we found:\\n- What is the second letter of sawer: a\\n- What is the second letter of uredo: r\\n- What is the second letter of rater: a\\nThe word we are looking fits the clue \"The Brazilian macaw; an Australian bird\"\\nand needs to have the letters a, r, and a in its (h1, one) first, (h2, two)\\nsecond, and (h3, third) third letters: a r a _ _. The candidates are: arara.\\n- arara (a r a r a, a r a _ _) fits\\nWe add the word arara for v2. The current words are:\\nh1. sawer\\nh2. uredo\\nh3. rater\\nv1. surge\\nv2. arara\\nv4. edema\\nNow, let’s consider the next unfound horizontal word, which is h4. Since we are\\nconsidering the fourth horizontal word, we need to look at the fourth letters\\nof the vertical words we found:\\n- What is the fourth letter of surge: g\\n- What is the fourth letter of arara: r\\n- What is the fourth letter of edema: m\\nthe word we are looking fits the clue \"Pasture land\" and needs to have the letters\\ng, r, and m in its (v1, one) first, (v2, two) second, and (v4, four) fourth\\nletters: g r _ m _. The candidates are: grama.\\n- grama (g r a m a, g r a _ _) fits\\nWe add the word grama for h4. The current words are:\\nh1. Sawer\\nh2. Uredos\\nh3. Rater\\nh4. Grama\\nv1. surge\\nv2. arara\\nv4. edema\\nNow, let’s consider the next unfound vertical word, which is v3. Since we are\\nconsidering the third vertical word, we need to look at the third letters of\\nthe horizontal words we found:\\n- What is the third letter of sawer: w\\n- What is the third letter of uredo: e\\n- What is the third letter of rater: t' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 38}\n",
      "page_content='- What is the third letter of grama: a\\nThe word we are looking fits the clue \"A Timorese island\" and needs to have the\\nletters w, e, t, and a in its (h1, one) first, (h2, two) second, (h3, three)\\nthird, and (h4, four) fourth letters: w e t a _. The candidates are: The\\ncandidate is \"wetar\".\\n- wetar (w e t a r, w e t a _) fits\\nWe add the word wetar for v3. The current words are:\\nh1. sawer\\nh2. uredo\\nh3. rater\\nh4. grama\\nv1. surge\\nv2. arara\\nv3. wetar\\nv4. edema\\nNow, let’s consider the last unfound horizontal word, which is h5. Since we are\\nconsidering the fifth horizontal word, we need to look at the fifth letters of\\nthe vertical words we found:\\n- What is the fifth letter of surge: e\\n- What is the fifth letter of arara: a\\n- What is the fifth letter of wetar: r\\n- What is the fifth letter of edema: a\\nThe word we are looking fits the clue \"Receiving by the ear\" and needs to have the\\nletters e, a, r, and a in its (v1, one) first, (v2, two) second, (v3, three)\\nthird, and (v4, four) fourth letters: e a r a _. The candidates are: The\\ncandidate is \"earal\".\\n- earal (e a r a l, e a r a _) fits\\nWe add the word earal for h5. The current words are:\\nh1. sawer\\nh2. uredo\\nh3. rater\\nh4. grama\\nh5. earal\\nv1. surge\\nv2. arara\\nv3. wetar\\nv4. edema\\nSince we found all horizontal words:\\nanswer:\\nh1. sawer\\nh2. uredo\\nh3. rater\\nh4. grama\\nh5. earal\\nv1. surge\\nv2. arara\\nv3. wetar\\nv4. edema\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nUser:\\nh1. Dandruff; scum; the bull-trout\\nh2. One who greets; to vacillate; a British river\\nh3. A Turkish written decree\\nh4. Mignon; petty; little\\nh5. A bishop’s permission for a priest to leave a diocese\\nv1. To steal; to brush across\\nv2. A sedge (a primitive three-sided grass)\\nv3. Grape jam\\nv4. A flatworm larva\\nv5. Ore refuse; to prepare material for glass by heat\\nh2. waver\\nh5. exeat\\nv1. swipe\\nv2. carex' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 39}\n",
      "page_content='Assistant:\\nLet’s consider the next unfound horizontal word, which is h1. Since we are\\nconsidering the first horizontal word, we need to look at the first letters of\\nthe vertical words we found:\\n- What is the first letter of swipe: s\\n- What is the first letter of carex: c\\nThe word we are looking fits the clue \"Dandruff; scum; the bull-trout\" and needs\\nto have the letters s and c in its (v1, one) first and (v2, two) second\\nletters: s c _ _ _. The candidates are: scurf.\\n- scurf (s c u r f, s c _ _ _) fits\\nWe add the word scurf for h1. The current words are:\\nh1. scurf\\nh2. waver\\nh5. exeat\\nv1. swipe\\nv2. carex\\nNow, let’s consider the next unfound vertical word, which is v3. Since we are\\nconsidering the third vertical word, we need to look at the third letters of\\nthe horizontal words we found:\\n- What is the third letter of scurf: u\\n- What is the third letter of waver: v\\n- What is the third letter of exeat: e\\nThe word we are looking fits the clue \"Grape jam\" and needs to have the letters u,\\nv, and e in its (h1, one) first, (h2, two) second, and (h5, five) fifth\\nletters: u v _ _ e. The candidates are: The candidate is \"uvetta\".\\n- uvetta (u v e t t a, u v _ _ e) doesn’t fit\\nLet’s consider the next unfound vertical word, which is v4. Since we are\\nconsidering the fourth vertical word, we need to look at the fourth letters of\\nthe horizontal words we found:\\n- What is the fourth letter of scurf: r\\n- What is the fourth letter of waver: e\\n- What is the fourth letter of exeat: a\\nThe word we are looking fits the clue \"A flatworm larva\" and needs to have the\\nletters r, e, and a in its (h1, one) first, (h2, two) second, and (h5, five)\\nfifth letters: r e _ _ a. The candidates are: redia.\\n- redia (r e d i a, r e _ _ a) fits\\nWe add the word redia for v4. The current words are:\\nh1. scurf\\nh2. waver\\nh5. exeat\\nv1. swipe\\nv2. carex\\nv4. redia\\nNow, let’s consider the next unfound horizontal word, which is h3. Since we are\\nconsidering the third horizontal word, we need to look at the third letters of\\nthe vertical words we found:\\n- What is the third letter of swipe: i\\n- What is the third letter of carex: r\\n- What is the third letter of redia: d\\nThe word we are looking fits the clue \"A Turkish written decree\" and needs to have\\nthe letters i, r, and d in its (v1, one) first, (v2, two) second, and (v4,\\nfour) fourth letters: i r _ d _. The candidates are: irade.\\n- irade (i r a d e, i r _ d _) fits\\nWe add the word irade for h3. The current words are:\\nh1. scurf\\nh2. waver\\nh3. irade\\nh5. exeat\\nv1. swipe\\nv2. carex\\nv4. redia\\nNow, let’s consider the last unfound vertical word, which is v5. Since we are\\nconsidering the fifth vertical word, we need to look at the fifth letters of\\nthe horizontal words we found:\\n- What is the fifth letter of scurf: f' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 40}\n",
      "page_content='- What is the fifth letter of waver: r\\n- What is the fifth letter of irade: e\\n- What is the fifth letter of exeat: t\\nThe word we are looking fits the clue \"Ore refuse; to prepare material for glass\\nby heat\" and needs to have the letters f, r, e, and t in its (h1, one) first,\\n(h2, two) second, (h3, three) third, and (h5, five) fifth letters: f r e _ t.\\nThe candidates are: The candidate is \"frett\".\\n- frett (f r e t t, f r e _ t) fits\\nWe add the word frett for v5. The current words are:\\nh1. scurf\\nh2. waver\\nh3. irade\\nh5. exeat\\nv1. swipe\\nv2. carex\\nv4. redia\\nv5. frett\\nSince we found all horizontal words:\\nanswer:\\nh1. scurf\\nh2. waver\\nh3. irade\\nh5. exeat\\nv1. swipe\\nv2. carex\\nv4. redia\\nv5. frett\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nPropose Words\\nUser:\\nh1. A lunar valley\\nh2. A fatty oil\\nh3. To entice\\nh4. To lower; to reduce\\nh5. A solitary person\\nv1. According to the roster\\nv2. Another name for Port-Francqui\\nv3. An illicit lover; a European lake\\nv4. To lisp\\nv5. To come in\\nAssistant:\\nAll possible 5-letters words for each clue, for each clue we give 10 options:\\nh1. RILLE, VALLIS, CRATER, BASINS, PLAINS\\nh2. OLEIC, OLEIN, GREASE, BUTTER, ANIMAL\\nh3. LURE, TEMPT, SEDUCE, ENTICE, DRAWIN\\nh4. ABASE, LOWER, REDUCE, LESSEN, DEBASE\\nh5. HERMIT, ALONE, LONER, SINGLE, SOLITARY\\nv1. ONTAP, LISTED, ROSTER, SCHEDULE, PLANNED\\nv2. ILEBO, PORTF, CONGO, AFRICA, COLONY\\nv3. LOVER, AMOUR, GENEVA, LEMAN, ZURICH\\nv4. SLUR, LISPS, STUTTER, MUMBLE, STAMMER\\nv5. ENTER, ARRIVE, COMEIN, APPEAR, SHOWUP\\n˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜˜\\nCreative Writing\\nAoT\\n\"Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph\\nmust be:\\n{0}\\nFirstly, make five different plans for a coherent passage, then write. Your output\\nshould be of the following format:' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 41}\n",
      "page_content='Plan 1:\\nYour plan here.\\nPlan 2:\\nYour plan here.\\nPlan 3:\\nYour plan here.\\nPlan 4:\\nYour plan here.\\nPlan 5:\\nYour plan here.\\nSecondly, given an instruction and several plans, decide which choice is most\\npromising. Analyze each choice in detail, then conclude in the last line \"The best\\nchoice is {{s}}\", where s the integer id of the choice.\\nThirdly, write the passage according to that chosen plan in the most coherent way. Add\\n\"Passage:\" before writing the passage under it.\\nPassage:\\nYour passage here.\\nFinally, refine the passage in the most coherent way, but you still have to end each\\nparagraph with the given sentences as before.\\nFinal Passage:\\nFinal passage here.\\nScore Prompt\\nAnalyze the following passage, then at the last line conclude \"Thus the coherency\\nscore is {{s}}\", where s is an integer from 1 to 10.\\n{0}\\nAcknowledgment: We appreciate the discussions and assistance provided by L. Wang.\\nContributions: B. Sel played a pivotal role in shaping the primary concept, spearheading the experimental design and eval-\\nuation, and leading the paper’s writing process. A. Tawaha actively engaged in discussions and conducted experiments. V .\\nKhattar collaborated through discussions and played a role in conducting the experiments. R. Jia and M. Jin both engaged in\\nconstructive discussions, with M. Jin also offering advisory guidance.\\nAdditional info about the changes from the first version (dated 8/20/2023) can be found in this link (https://tinyurl.com/\\n2vnjxw93).' metadata={'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 42}\n",
      "page_content='Graph of Thoughts: Solving Elaborate Problems with Large Language Models\\nMaciej Besta1*, Nils Blach1*, Ales Kubicek1, Robert Gerstenberger1,\\nMichał Podstawski2, Lukas Gianinazzi1, Joanna Gajda3, Tomasz Lehmann3,\\nHubert Niewiadomski3, Piotr Nyczyk3, Torsten Hoefler1\\n1ETH Zurich,2Warsaw University of Technology,3Cledar\\nbestam@inf.ethz.ch, nils.blach@inf.ethz.ch, htor@inf.ethz.ch\\nAbstract\\nWe introduce Graph of Thoughts (GoT): a framework that\\nadvances prompting capabilities in large language models\\n(LLMs) beyond those offered by paradigms such as Chain-of-\\nThought or Tree of Thoughts (ToT). The key idea and primary\\nadvantage of GoT is the ability to model the information gen-\\nerated by an LLM as an arbitrary graph , where units of infor-\\nmation (“LLM thoughts”) are vertices, and edges correspond\\nto dependencies between these vertices. This approach en-\\nables combining arbitrary LLM thoughts into synergistic out-\\ncomes, distilling the essence of whole networks of thoughts,\\nor enhancing thoughts using feedback loops. We illustrate\\nthat GoT offers advantages over state of the art on different\\ntasks, for example increasing the quality of sorting by 62%\\nover ToT, while simultaneously reducing costs by >31%.\\nWe ensure that GoT is extensible with new thought transfor-\\nmations and thus can be used to spearhead new prompting\\nschemes. This work brings the LLM reasoning closer to hu-\\nman thinking or brain mechanisms such as recurrence, both\\nof which form complex networks.\\nWebsite & code: https://github.com/spcl/graph-of-thoughts\\n1 Introduction\\nLarge language models (LLMs) are taking over the world\\nof AI. Recent years saw a rapid development of models pri-\\nmarily based on the decoder-only Transformer variant [65],\\nsuch as GPT [13, 14, 53, 54], PaLM [19], or LLaMA [63].\\nPrompt engineering is a resource-efficient approach for\\nsolving different LLM tasks. In brief, one includes the task\\ndescription within the input sent to an LLM. If this descrip-\\ntion is appropriately formulated, the LLM solves the task\\nusing its autoregressive token-based mechanism for gener-\\nating text. Such prompts may contain example tasks with\\nsolutions (few-shot prompting, also referred to as in-context\\nlearning (ICL)), or even no example tasks at all (zero-shot\\nprompting). In recent years it was shown that this mecha-\\nnism can be used to solve a broad set of tasks that involve\\nmathematical, commonsense, or symbolic reasoning.\\nChain-of-Thought (CoT) [71] is an approach for prompt-\\ning, in which one includes the intermediate steps of rea-\\nsoning within the prompt (intermediate “thoughts”), besides\\nthe task input/output. CoT was shown to significantly im-\\nprove the capability of LLMs to solve problems without re-\\nsorting to any model updates. One major improvement over\\n*Equal contributionCoT, Self-Consistency with CoT (CoT-SC) [67], is a scheme\\nwhere multiple CoTs are generated, and then the best one is\\nselected as the outcome. More recently, CoT and CoT-SC\\nwere extended with Tree of Thoughts (ToT) [43, 75, 77],\\nwhich models the LLM reasoning process with a tree. This\\nfacilitates using different paths of thoughts, and offers novel\\ncapabilities such as backtracking from non-promising out-\\ncomes. Unfortunately, the ToT approaches still fundamen-\\ntally limit the reasoning abilities within a prompt by impos-\\ning the rigid tree structure on the thought process.\\nIn this work, we argue that fundamentally more power-\\nful prompting can be achieved by enabling LLM thoughts to\\nform an arbitrary graph structure. This is motivated by nu-\\nmerous phenomena such as human reasoning, brain struc-\\nture, or algorithmic execution. When working on a novel\\nidea, a human would not only follow a chain of thoughts\\n(as in CoT) or try different separate ones (as in ToT), but\\nwould actually form a more complex network of thoughts.\\nFor example, one could explore a certain chain of reason-\\ning, backtrack and start a new one, then realize that a cer-\\ntain idea from the previous chain could be combined with\\nthe currently explored one, and merge them both into a new\\nsolution, taking advantage of their strengths and eliminat-\\ning their weaknesses. Similarly, brains form complex net-\\nworks, with graph-like patterns such as recurrence [28]. Ex-\\necuting algorithms also expose networked patterns, often\\nrepresented by Directed Acyclic Graphs. The correspond-\\ninggraph-enabled transformations bring a promise of more\\npowerful prompting when applied to LLM thoughts, but they\\nare not naturally expressible with CoT or ToT.\\nWe observe that these (and many other) thought trans-\\nformations can be naturally enabled when modeling the\\nreasoning process of an LLM as a graph . For this, we\\npropose Graph of Thoughts (GoT), an approach that en-\\nhances LLMs’ capabilities through networked reasoning\\n(contribution #1 ). In GoT, an LLM thought is modeled\\nas a vertex, while an edge is a dependency between such\\nthoughts. Using GoT, one can aggregate arbitrary thoughts\\nby constructing vertices that have more than one incom-\\ning edge. Overall, the graph abstraction harnessed by GoT\\nseamlessly generalizes CoT and ToT to more complex\\nthought patterns, without resorting to any model updates .\\nYet, putting GoT to practice requires solving several de-\\nsign challenges. For example, what is the best graph struc-\\nture for different tasks? How to best aggregate thoughts to\\nmaximize accuracy and minimize cost? To answer these andarXiv:2308.09687v4  [cs.CL]  6 Feb 2024' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 0}\n",
      "page_content='many other questions, we carefully design a modular archi-\\ntecture for implementing GoT ( contribution #2 ), coming\\nwith two design highlights. First, we enable a fine-grained\\ncontrol over individual thoughts . This enables us to fully\\ncontrol the ongoing conversation with the LLM, and apply\\nadvanced thought transformations, such as combining most\\npromising thoughts from the ongoing reasoning into a new\\none. Second, we ensure that our architecture can be seam-\\nlessly extended with novel thought transformations, patterns\\nof reasoning (i.e., graphs of thoughts), and LLM models.\\nThis enables rapid prototyping of novel prompting ideas us-\\ning GoT, while experimenting with different models such as\\nGPT-3.5, GPT-4, or Llama-2 [64].\\nWe illustrate several use cases for GoT (sorting, keyword\\ncounting for summaries, set operations, document merging)\\nand we detail how to implement them using the graph-based\\nparadigm ( contribution #3 ). We evaluate GoT and show its\\nadvantages over the state of the art ( contribution #4 ). Over-\\nall, we observe that GoT is particularly well-suited for tasks\\nthat can be naturally decomposed into smaller subtasks that\\nare solved individually and then merged for a final solution.\\nHere, GoT outperforms other schemes, for example improv-\\ning upon CoT and ToT by, respectively, ≈70% and ≈62%,\\nin terms of the quality of sorting, while simultaneously re-\\nducing costs by >31% over ToT.\\nWe qualitatively compare GoT to other prompting\\nschemes1in Table 1. GoT is the only one to enable arbitrary\\ngraph-based thought transformations within a prompt, such\\nas aggregation, embracing all previously proposed schemes.\\nScheme Sc? Mc? Tr? Ag?\\nChain-of-Thought (CoT) [71] /reve /reve /reve\\nSelf-Consistency with CoT [67] /reve /reve\\nThought decomposition [75] /reve\\nTree-of-Thought (ToT) [43] /reve\\nTree of Thoughts (ToT) [77] /reve\\nGraph of Thoughts (GoT) \\nTable 1: Comparison of prompting schemes, with re-\\nspect to the supported transformations of thoughts. “Sc?” :\\nsingle chain of thoughts? “Mc?” : multiple chains of\\nthoughts? “Tr?” : tree of thoughts? “Ag?” : arbitrary graph\\nof thoughts? “ ”: full support, “ ”: partial support, “ /reve”:\\nno support.\\nFinally, we propose a new metric for evaluating a prompt-\\ning strategy, the volume of a thought (contribution #5 ).\\nWith this metric, we aim to understand better the differences\\nbetween prompting schemes. For a given thought v, the vol-\\nume of visthe number of LLM thoughts, from which one\\ncan reach vusing directed edges . Intuitively, these are all\\nthe LLM thoughts that have had the potential to contribute\\n1Note that we do not include a recent scheme called Graph-of-\\nThought [79] because it is not a prompting scheme. While its\\nname suggests close connections to ToT and CoT, as a fine-tuning\\nscheme, it resorts to model updates, and is thus outside the focus\\nof this work. Similarly, the graph-of-thoughts repository [52] does\\nnot enable general graph-based reasoning and harnesses instead\\nToT with BFS.tov. We show that GoT, by incorporating thought transfor-\\nmations such as aggregation, enables thoughts to have fun-\\ndamentally larger volumes than other schemes.\\n2 Background & Notation\\nWe first outline background concepts and notation.\\n2.1 Language Models & In-Context Learning\\nTheconversation with the LLM consists of user messages\\n(prompts ) and LLM replies ( thoughts ). We follow the estab-\\nlished notation [77] and we denote a pre-trained language\\nmodel (LM) with parameters θaspθ. Lowercase letters such\\nasx, y, z, ... indicate LLM thoughts. We purposefully do not\\nprescribe what is a single “thought”, and instead make it use-\\ncase specific. Hence, a single thought can be a paragraph\\n(e.g., in article summary), a document (e.g., in document\\ngeneration), a block of code (e.g., in code debugging or op-\\ntimization), and so on.\\nWe next describe specific prompting approaches .\\nInput-Output (IO) The Input-Output (IO) prompting is a\\nstraightforward approach, in which we use an LLM to turn\\nan input sequence xinto the output ydirectly , without any\\nintermediate thoughts.\\nChain-of-Thought (CoT) Second, in Chain-of-Thought\\n(CoT), one introduces intermediate thoughts a1, a2, ...be-\\ntween xandy. This strategy was shown to significantly en-\\nhance various LM tasks over the plain IO baseline, such as\\nmathematical puzzles [71] or general mathematical reason-\\ning [24].\\nMultiple CoTs Third, one can generalize CoT into multi-\\nple CoTs by generating several (independent) kCoTs, and\\nreturning the one with the best output (according to some\\nprescribed scoring metric). It was introduced by Wang et\\nal. in the scheme called Self-Consistency with CoT (CoT-\\nSC) [67]. This approach enhances CoT because it offers an\\nopportunity to explore different reasoning paths. However,\\nit does not offer “local exploration” within a path, such as\\nbacktracking.\\nTree of Thoughts (ToT) Finally, the Tree of Thoughts\\n(ToT) scheme was introduced independently by Yao [77]\\nand Long [43] (where it is referred to as Tree-of-Thought);\\nit was used implicitly to a certain degree by other schemes\\nsuch as thought decomposition [75]. It enhances CoT-SC by\\nmodeling the process or reasoning as a treeof thoughts. A\\nsingle tree node represents a partial solution. Based on a\\ngiven node, the thought generator constructs a given number\\nkof new nodes. Then, the state evaluator generates scores\\nfor each such new node. Depending on the use case, the eval-\\nuation could be conducted using an LLM itself, or it can har-\\nness human scores. Finally, the schedule of extending the\\ntree is dictated by the utilized search algorithm (for example\\nBFS or DFS).\\n3 The GoT Framework\\nWe now detail the GoT framework. We present it in Figure 1,\\nand compare it to other prompting strategies.\\n2' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 1}\n",
      "page_content='Input\\nOutputInput\\nOutput OutputThoughts:\\nUnscored\\nNegative\\nscore OutputInput\\nOutput[This work]\\nInput\\nPositive\\nscore\\nDependencies\\nbetween thoughts\\nAbandon thought\\nBacktrackBasic Input-\\nOutput (IO)\\nLegendMultiple CoTs (CoT-SC) Chain-of-\\n-Thought\\n(CoT)Tree of Thoughts (ToT) Graph of Thoughts (GoT)\\nKey novelty:\\nIntermediate\\nLLM thoughts\\nwithin a chainBranching out\\nfrom a chain\\nSelecting\\na chain with\\nthe best scoreAbandon a chain\\nKey novelty\\n(beyond CoT):\\nHarnessing multiple\\nindependent chains\\nof thoughtsKey novelty\\n(beyond CoT-SC):\\nGenerating several\\nnew thoughts based\\non a given arbitrary\\nthought, exploring\\nit further, and possibly\\nbacktracking from itKey novelty (beyond ToT):\\nArbitrary graph-based thought\\ntransformations (aggregating \\nthoughts into a new one, \\nlooping over a thought to \\nrefine it)BacktrackingRefining\\nAggregating\\nthoughtsBacktracking\\nfrom a chain\\nIntermediate\\nthoughts are\\nalso scored\\nAggregating\\nchainsInputFigure 1: Comparison of Graph of Thoughts (GoT) to other prompting strategies.\\nFormally, GoT can be modeled as a tuple (G,T,E,R),\\nwhere Gis the “LLM reasoning process” (i.e., all the LLM\\nthoughts within the context, with their relationships), Tare\\nthe potential thought transformations, Eis an evaluator func-\\ntion used to obtain scores of thoughts, and Ris a ranking\\nfunction used to select most relevant thoughts.\\n3.1 Reasoning Process\\nWe model the reasoning process as a directed graph G=\\n(V, E);Vis a set of vertices and E⊆V×Vis a set of\\nedges. Gis directed and thus the edges are a subset of or-\\ndered vertex pairs E⊆V×V. A vertex contains a solution\\nto a problem at hand (be it an initial, intermediate, or a fi-\\nnal one). The concrete form of such a thought depends on\\nthe use case; it could be a paragraph (in writing tasks) or a\\nsequence of numbers (in sorting). A directed edge (t1, t2)\\nindicates that thought t2has been constructed using t1as\\n“direct input”, i.e., by explicitly instructing the LLM to use\\nt1for generating t2.\\nIn certain use cases, graph nodes belong to different\\nclasses . For example, in writing tasks, some vertices model\\nplans of writing a paragraph , while other vertices model the\\nactual paragraphs of text . In such cases, GoT embraces a\\nheterogeneous graph G= (V, E, c )to model the LLM rea-\\nsoning, where cmaps vertices Vinto their respective classes\\nC(in the above case, it would be C={plan, par }). Hence,\\nany vertex vcan model different aspects of reasoning.\\nWe associate Gwith the LLM reasoning process. To ad-\\nvance this process, one applies thought transformations to\\nG. An example of such a transformation is to merge best-\\nscoring (so far) thoughts into a new one. Another example\\nis to loop over a thought, in order to enhance it. Note that\\nthese transformations strictly extend the set of transforma-\\ntions available in the CoT, CoT-SC, or ToT.\\n3.2 Transformations of Thoughts\\nGoT enables novel transformations of thoughts thanks to\\nthe graph-based model for reasoning. We refer to them as\\n...Graph theory view Example sorting task Example writing taskAggregation Generation...\\n1 2 7 8 1 1 4 5 2 3 6 7\\n1 1 1 2 2 3 4 5 6 7 7 8...\\nArticle\\n1Article\\n2Article\\n3\\nKeyword\\nsummary\\nA vertex models\\na thought. An edge\\nmodels dependency... ...Merging sorted subarrays\\ninto a sorted array of numbers\\nSplitting an unsorted array into\\nsubarrays, for subsequent sortingCombining articles into\\na coherent summary...\\nKeyword\\nsummary 1Keyword\\nsummary 21 4 6 2 4 2 4 9 8 7 5 4\\n1 4 6 2    4 2 4 9    8 7 5 4Article\\n1\\nGenerating summaries from\\nan article, to maximize qualityFigure 2: Examples of aggregation and generation thought\\ntransformations.\\ngraph-enabled transformations . For example, in writing,\\none could combine several input articles into one coherent\\nsummary. In sorting, one could merge several sorted subar-\\nrays of numbers into a final sorted array. We illustrate exam-\\nples of aggregation and generation in Figure 2.\\nFormally, each such transformation can be modeled as\\nT(G, pθ)where G= (V, E)is the graph reflecting the\\ncurrent state of the reasoning, and pθis the used LLM. T\\nmodifies Gusually by adding new vertices and their incom-\\ning edges. We have G′=T(G, pθ) = ( V′, E′), where\\nV′= (V∪V+)\\\\V−andE′= (E∪E+)\\\\E−.V+\\nandE+are new vertices and edges inserted into Gto model\\nthe new thoughts and their dependencies, respectively. To\\nmaximize the expressiveness of GoT – we also enable the\\nuser to explicitly remove thoughts, by specifying the corre-\\nsponding vertices and edges to be removed ( V−andE−, re-\\nspectively). Here, it is the user’s responsibility to ensure that\\nthe sets V+, E+, V−,andE−come with consistent trans-\\nformations (i.e., for example, that the user does not attempt\\nto remove a vertex that does not exist). This enables seam-\\n3' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 2}\n",
      "page_content='less incorporation of schemes where, in order to save space\\nwithin the context, one can remove parts of reasoning that\\ndo not promise improvements.\\nThe specific form of Tand how it impacts Gdepends on\\na specific transformation. We first detail the primary graph-\\nenabled thought transformations, and then proceed to de-\\nscribe how GoT embraces the transformations from the ear-\\nlier schemes. Unless stated otherwise, V−=E−=∅.\\nAggregation Transformations First, with GoT, one can\\naggregate arbitrary thoughts into new ones, to combine\\nand reinforce the advantages of these thoughts, while elim-\\ninating their disadvantages. In the basic form, in which\\nonly one new vertex is created, V+={v+}andE+=\\n{(v1, v+), ...,(vk, v+)}, where v1, ..., v kare the merged k\\nthoughts. More generally, this enables aggregating reason-\\ning paths , i.e., longer chains of thoughts, beyond just indi-\\nvidual thoughts. With the graph model, it is simply achieved\\nby adding outgoing edges from the vertices v1, ..., v k, mod-\\neling final thoughts in several chains, into a single thought\\nv+combining these chains.\\nRefining Transformations Another thought transforma-\\ntion is the refining of a current thought vby modifying its\\ncontent: V+={}andE+={(v, v)}. This loop in the\\ngraph indicates an iterated thought with the same connec-\\ntions as the original thought.\\nGeneration Transformations Finally, one can generate\\none or more new thoughts based on an existing single\\nthought v. This class embraces analogous reasoning steps\\nfrom earlier schemes, such as ToT or CoT-SC. Formally, we\\nhaveV+={v+\\n1, ..., v+\\nk}andE+={(v, v+\\n1), ...,(v, v+\\nk)}.\\n3.3 Scoring & Ranking Thoughts\\nThoughts are scored to understand whether the current solu-\\ntion is good enough. A score is modeled as a general func-\\ntionE(v, G, p θ), where vis a thought to be evaluated. We\\nuse the state of the whole reasoning process ( G) inEfor\\nmaximum generality, because – for example – in some eval-\\nuation scenarios, scores may be relative to other thoughts.\\nGoT can also rank thoughts. We model this with a func-\\ntionR(G, pθ, h)where hspecifies the number of highest-\\nranking thoughts in Gto be returned by R. While the spe-\\ncific form of Rdepends on the use case, we most often use a\\nsimple yet effective strategy where hthoughts with the high-\\nest scores are returned, i.e., v1, ..., v h=R(G, pθ, h).\\nSpecific forms of EandRdepend on the use case. We dis-\\ncuss the details in Section 5. For example, the score (or rank)\\nfor sorting corresponds to the count of elements correctly\\nsorted (or incorrectly, when using the error as a score).\\n4 System Architecture & Extensibility\\nThe GoT architecture consists of a set of interacting mod-\\nules, see Figure 3 (the blue part). These modules are the\\nPrompter (prepares the messages for the LLM), the Parser\\n(extracts information from LLM thoughts), the Scoring\\nmodule (verifies and scores the LLM thoughts), and theController (coordinates the entire reasoning process, and de-\\ncides on how to progress it). The Controller contains two fur-\\nther important elements: the Graph of Operations (GoO) and\\nthe Graph Reasoning State (GRS). GoO is a static structure\\nthat specifies the graph decomposition of a given task , i.e.,\\nit prescribes transformations to be applied to LLM thoughts,\\ntogether with their order & dependencies. GRS is a dynamic\\nstructure that maintains the state of the ongoing LLM rea-\\nsoning process (the history of its thoughts and their states).\\n4.1 Prompter\\nThe Prompter prepares the prompts to be sent to the LLM.\\nThis module is responsible for the specifics of encoding the\\ngraph structure within the prompt. The GoT architecture en-\\nables the user to implement use case specific graph encod-\\nings by providing full access to the graph structure.\\n4.2 Parser\\nThe Parser extracts information from LLM thoughts. For\\neach such thought, the Parser constructs the thought state ,\\nwhich contains this extracted information. The thought state\\nis then used to update the GRS accordingly.\\n4.3 Scoring & Validation\\nHere, we verify whether a given LLM thought satisfies po-\\ntential correctness conditions, and then we assign it a score.\\nDepending on how the score is derived, the module may\\nconsult the LLM. Moreover, depending on the use case, the\\nscore may also be assigned by a human. Finally, use cases\\nsuch as sorting use simple local scoring functions.\\n4.4 Controller\\nThe Controller implements a specific strategy for select-\\ning thoughts from its GRS structure. It also selects what\\ntransformations should be applied to which thoughts, and\\nthen passes this information to the Prompter. It also decides\\nwhether the whole process should be finalized, or whether\\nthe next round of interaction with the LLM should be initi-\\nated. In our current design, this is dictated by the execution\\nplan specified in the GoO.\\n4.5 GoO & GRS\\nThe user constructs a GoO instance, which prescribes the\\nexecution plan of thought operations. The GoO is a static\\nstructure that is constructed once, before the execution starts.\\nEach operation object knows its predecessor and successor\\noperations. Then, during the execution, an instance of the\\nGRS maintains the continually updated information about\\nthe LLM reasoning process. This includes which operation\\nhas been executed so far, the states of all the generated LLM\\nthoughts, their validity and scores, and any other relevant\\ninformation.\\nThe above elements offer extensible APIs , enabling\\nstraightforward implementations of different prompting\\nschemes. The APIs are outlines in the green part of Fig-\\nure 3, and detailed in the documentation. We also provide\\nexamples of prompts used by these operations and a corre-\\nsponding GRS in the red part of Figure 3.\\n4' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 3}\n",
      "page_content='Goal: Build a prompt\\nto be sent to the LLMLegend Architecture overview\\nExample prompts and the Graph Reasoning State for the sorting use case (some examples within each prompt are omitted due to space constraints)\\nParser\\nGoal: Extract\\ninformation from\\nLLM thought Goal: Assess the\\nquality of the\\nLLM\\'s solution\\nControllerGoal: Initiate, coordinate, manage,\\nand progress the GoT executionExternal entity Prompt Thought\\nThought stateScore\\nOperation\\nThought state + its\\nassociated operationsThought state\\n+ thought\\'s scoreDependencyModule of the\\nGoT framework Graph of\\nOperations\\nGoal: Specify\\nLLM thought\\ntransformations\\nGraph Reasoning State\\nGoal: Maintain\\nthe ongoing LLM\\nreasoning process\\nUser\\nGoal: Indicate the\\ntop-scoring thoughts\\nGraph of Operations enables seamless specification of not only\\nGoT, but also existing schemes such as CoT, CoT-SC, ToT\\nAPI for Prompter (extensible)\\n➡ Generate(t,k) //generate a prompt for k new thoughts, using thought t➡ //LLM params: model used, temperature, max tokens, api key, org, ...\\n➡ //LLM cost features: prompt token cost, response token cost, ...\\n➡ //Instances of Prompter + Parser + Graph of Operations,\\n➡ //Any additional input parameters (e.g., numbers to be sorted).\\n//Each of the above routines is responsible for parsing an LLM thought\\n//to a corresponding Prompter routine (e.g., ParseScore parses Score).➡ Score(t) //score thought t\\n➡ Validate(t) //generate a prompt to validate the correctness of thought t➡ ValidateAndImprove(t) //generate a prompt to enhance thought t,\\n➡ Aggregate(t1,...,tk) //generate a prompt to combine thoughts t1, ..., tk API for Controller\\nAPI for Parser (extensible)\\nParseGenerate, ParseImprove, ParseScore,\\nParseAggregate, ParseValidate, ...➡ Generate, Aggregate, Score, ... //see Prompter API\\n➡ KeepBest(N) //preserves N best scoring thoughts\\n➡ Repeat(k) //Repeat a given operation k times, generating k thoughts.\\n    //For example, this enables \"Aggregate\" to generate multiple outcomes\\n    //of the combination operation. Each such thought is maintained \\n   //within the Graph Reasoning State and scored individually.Available operations when building the GoO (extensible)\\nSpecifying the Structure of the Graph of Operations (GoO)Ranking Scoring &\\nvalidationPrompter\\nLLM\\nHuman\\nor LLM\\nGray block\\nBlue block\\nA prompt used by\\nAggregate(t1,t2)+Repeat(k=3)+KeepBest(N=1)\\n<Instruction> Merge the following 2 sorted lists of length {length1} each, \\ninto one sorted list of length {length2} using a merge sort style approach.\\nOnly output the final merged list without any additional text or thoughts!\\n</Instruction>\\n<Approach>\\nTo merge the two lists in a merge-sort style approach, follow these steps:\\n1. Compare the first element of both lists.\\n2. Append the smaller element to the merged list and move to the next \\nelement in the list from which the smaller element came.\\n3. Repeat steps 1 and 2 until one of the lists is empty.\\n4. Append the remaining elements of the non-empty list to the merged list.\\n</Approach>\\nMerge the following two lists into one sorted list:\\n1: {input1}\\n2: {input2}\\nMerged list:\\nThis prompt is used by an operation Aggregate where the aggregation factor is \\nk = 2 (2 input thoughts, t1 and t2, are aggregated). This is repeated by GoT 3 times, \\nto maximize quality. Finally, the best result is selected. Note that, in this example, \\nthe prompt explicitly requests the merge operation only. All the remaining opera-\\ntions are specified in the GoO and are handled by the underlying GoT framework.\\nThe input\\nthoughts t1, t2\\n3Initial/system prompt (optional)\\nHello. I want to sort the following input sequence of numbers: {input}I\\n1 2 3I\\n4Improve(t)+Repeat(k=4)\\n<Instruction> The following two lists represent an unsorted list of numbers \\nand a sorted variant of that list. The sorted variant is not correct. Fix the \\nsorted variant so that it is correct. Make sure that the output list is sorted in\\nascending order, has the same number of elements as the input list ({length}),\\nand contains the same elements as the input list. </Instruction>\\n<Approach>\\nTo fix the incorrectly sorted list follow these steps:\\n1. For each number from 0 to 9, compare the frequency of that number in the\\nincorrectly sorted list to the frequency of that number in the input list.\\n2. Iterate through the incorrectly sorted list and add or remove numbers as\\nneeded to make the frequency of each number in the incorrectly sorted list\\nmatch the frequency of that number in the input list.\\n</Approach>\\n<Examples>\\nInput: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9]\\nIncorrectly Sorted: [0, 0, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 7, 7, 8, 8, 9, 9, 9, 9]\\nReason: The incorrectly sorted list contains four extra 0s, two extra 4s and\\nthree extra 9s and is missing two 2s.\\nOutput: [0, 1, 2, 2, 2, 2, 3, 3, 4, 5, 5, 7, 7, 8, 8, 9] \\n    \\nInput: [6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9, 2, 4, 9, 0, 7, 6, 5, 6, 6, 2, 8,\\n3, 9, 5, 6, 1]\\nIncorrectly Sorted: [0, 1, 1, 2, 2, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7,\\n7, 7, 8, 8, 9, 9, 9, 9, 9]\\nReason: The incorrectly sorted list contains two extra 4s and is missing two\\n6s and one 9.\\nOutput: [0, 1, 1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9,\\n9, 9, 9, 9, 9]\\n</Examples>\\nInput: {input}\\nIncorrectly Sorted: {incorrectly_sorted}A prompt used by\\n...\\n...This prompt is used by an operation\\nImprove(t), which enhances a given thought t\\nusing information provided in another thought.\\nDepending on how the Improve + Repeat \\noperation is implemented by the user within\\nGoT, it can either generate a number of new \\nthoughts in GRS (the upper graph on the right), \\nsimilar to Generate + Repeat, or may refine \\nthe same thought in GRS (the lower graph on \\nthe right), chaining k=4 refinement iterations together.\\n4\\nThe input\\nthought tA prompt used by\\nGenerate(t,k=4)\\n<Instruction> Split the following list of 64 numbers into 4 lists of 16\\nnumbers each, the first list should contain the first 16 numbers, the\\nsecond list the second 16 numbers, the third list the third 16 numbers\\nand the fourth list the fourth 16 numbers. Only output the final 4 lists\\nin the following format without any additional text or thoughts!\\n{{\\n    \"List 1\": [3, 4, 3, 5, 7, 8, 1, ...],\\n    \"List 2\": [2, 9, 2, 4, 7, 1, 5, ...],\\n    \"List 3\": [6, 9, 8, 1, 9, 2, 4, ...],\\n    \"List 4\": [9, 0, 7, 6, 5, 6, 6, ...]\\n}} </Instruction>\\n<Example>\\nInput: [3, 1, 9, 3, 7, 5, 5, 4, 8, 1, 5, 3, 3, 2, 3, 0, 9, 7, 2, 2, 4, 4, 8, 5, 0, \\n8, 7, 3, 3, 8, 7, 0, 9, 5, 1, 6, 7, 6, 8, 9, 0, 3, 0, 6, 3, 4, 8, 0, 6, 9, 8, 4, 1, \\n2, 9, 0, 4, 8, 8, 9, 9, 8, 5, 9]\\nOutput:\\n{{\\n    \"List 1\": [3, 1, 9, 3, 7, 5, 5, 4, 8, 1, 5, 3, 3, 2, 3, 0],\\n    \"List 2\": [9, 7, 2, 2, 4, 4, 8, 5, 0, 8, 7, 3, 3, 8, 7, 0],\\n    \"List 3\": [9, 5, 1, 6, 7, 6, 8, 9, 0, 3, 0, 6, 3, 4, 8, 0],\\n    \"List 4\": [6, 9, 8, 4, 1, 2, 9, 0, 4, 8, 8, 9, 9, 8, 5, 9]\\n}}\\n</Example>\\nInput: {input}\\nThis prompt is used by an operation Generate where\\nthe branching factor is k = 4. Four new thoughts are\\nconstructed based on the LLM reply to this prompt.The input\\nthought t1Generate(t,k=1)+Repeat(k=4) A prompt used by\\n<Instruction> Sort the following list of numbers in ascending order.\\nOutput only the sorted list of numbers, no additional text. </Instruction>\\n<Example>\\nInput: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, 5, 6, 6, 4, 4, 5, \\n2, 0, 9, 3, 3, 9, 2, 1]\\nOutput: [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, \\n6, 6, 7, 7, 8, 8, 9, 9, 9]\\n</Example>\\nInput: {input}\\nThe input\\nthought t\\nThis prompt is used by an operation Generate where the\\nbranching factor is k=1, which means, only one thought is\\ngenerated. However, as we chain it with the operation Repeat\\nwith k=4, the underlying GoT framework ensures that Generate\\nexecutes 4 times and results in 4 separate thoughts. Note that, from the graph\\ntheory perspective, the GRS is identical to that in the operation Generate(t, k=4).\\nThe difference between these two is that Generate(t, k=4) gives the user more \\ncontrol over how these multiple thoughts are constructed, while Generate(t, \\nk=1)+Repeat(k=4) is less flexible but more easy to use. Moreover, with Repeat \\none has 4 context-isolated responses from the LLM for identical prompts, \\nwhereas without Repeat there is only one context where all 4 thoughts are\\ngenerated and must be explicitly handled in a single prompt/session.\\n2\\nFigure 3: The system architecture of GoT, and the APIs of respective modules. The user can straightforwardly extend the design\\ntowards new prompting schemes, experiment with novel thought transformations, and plug in different LLMs. The blue part of\\nthe figure contains the architecture overview, the green part lists the API, and the red part contains example prompts together\\nwith a GRS and operations involved.\\n5' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 4}\n",
      "page_content='5 Example Use Cases\\nWe now describe several use cases of GoT. We detail one\\nuse case (sorting) and summarize the others.\\n5.1 Sorting\\nWe focus on the decomposition of the sorting use case and\\nGraph of Operations, which are central for implementing\\nand executing any workload within GoT.\\nWe consider sorting numbers 0–9 with duplicates. The\\nconsidered LLMs are unable to sort a sequence of such num-\\nbers correctly beyond a certain length consistently because\\nduplicate counts do not match.\\nIn GoT, we employ merge-based sorting: First, one de-\\ncomposes the input sequence of numbers into subarrays.\\nThen, one sorts these subarrays individually, and then re-\\nspectively merges them into a final solution. Figure 4 illus-\\ntrates this use case together with its graph decomposition.\\nHere, an LLM thought is a sequence of sorted numbers.\\nTo score an outcome, denote an input sequence with\\n[a1, a2, ..., a n]and an output one with [b1, b2, ..., b m]. We\\nuse the following score that determines “the scope” of er-\\nrors:\\nerror-scope =X+Y\\nwhere p∈ {1, ..., m},q∈ {1, ..., n}, and\\nX=m−1X\\ni=1sgn(max( bi−bi+1,0)),\\nY=9X\\ni=0| |{bp:bp=i}| − |{ aq:aq=i}| |\\nHere, Xindicates how many consecutive pairs of num-\\nbers are incorrectly sorted. If two numbers iandi+ 1\\nare incorrectly sorted (i.e., bi> bi+1), then the expression\\nwithin the summation returns 1, increasing the error score\\nby one. For two numbers correctly sorted, this expression\\namounts to 0. Then, Ydetermines how well a given output\\nsequence preserves the frequency of output numbers. Specif-\\nically, for each considered number x(x∈ {0, ...,9}), we\\nobtain the difference between the count of input elements\\nbeing equal to x, vs. the count of output elements equal\\ntox. For an output sequence perfectly preserving the fre-\\nquency of x, this would amount to 0. Any single “devia-\\ntion” in this count, increases the “error scope” by 1. We\\nthen sum this over all considered values of x. When plot-\\nting this score, to improve the clarity of plots, we addition-\\nally apply clipping min( error-scope , n), as some baselines\\n(IO, CoT) result in large numbers of outliers with high er-\\nror scope. Finally, to use a “positive score” describing “the\\nscope of correctly sorted” elements, one can use the value\\nmax( n−error-scope ,0).\\n5.2 Set Operations\\nMoreover, we also consider set operations, focusing on set\\nintersection. They have numerous applications (particularly\\nset intersection) in problems ranging from genome or docu-\\nment comparisons to pattern matching [9–11, 20, 27, 38, 50,\\n.....\\n.......... .....1 4  ...  4 316 numbers\\n8 2  ...  1 316 numbers\\n1 1  ...  4 2 1 9  ...  5 416 numbers\\n16 numbers\\nSort\\nPartial solutionGraph of Operations (GoO) for sorting 64 numbers\\nPartial solution Partial solution Partial solution\\nk = 3Generate(k)\\nScoreSort\\nGenerate(k)\\nSort\\nGenerate(k)\\n1 2  ...  7 816 numbers\\n1 1  ...  5 716 numbers\\nPartial solution Partial solution\\n1 2  ...  4 816 numbers\\nPartial solution\\n1 2  ...  7 816 numbers\\n1 1  ...  5 716 numbers\\nPartial solution Partial solution\\n1 2 ... 4 816 numbers\\nPartial solution\\nScore: 78% Score: 86%\\nKeepBest(N)\\nKeep the best\\nscored thoughtsN = 1\\nMerge into a 32\\nelement subarray\\nAggregate(k)\\nk = 10k = 3 k = 3\\nAssess how well each sequence is sorted\\nHow do we score?64 numbers\\n1 4 6 2 4  ...  9 8 7 5 4\\nSplitting into four\\n16-element chunksGenerate(k) k = 1\\nInput\\nSort\\nGenerate(k)\\nk = 3\\nScore: 100%\\n1 2  ...  4 816 numbers\\nPartial solution\\nScore: 100%1 3  ...  4 616 numbers\\nPartial solution\\nScore: 97%..... .....\\n.....1 1  ...  8 932 numbers\\nPartial solution\\nScore: 100%1 1  ...  6 832 numbers\\nPartial solution\\nScore: 97%\\nMerge into a 64\\nelement array\\nAggregate(k)\\nk = 10S\\nScoreS\\nScoreS\\nScoreS\\nScore\\nK\\nG\\nScoreG\\nScoreScore ScoreK K K\\nAG\\nKA\\nAScore\\nScore\\nK KK KKG\\nS\\nAKGLegend\\nGenerateDetails of the highlighted\\npart of GoO are below \\nDetails of the highlighted part of the GoO from above\\nThe first Generate\\nsplits the 64-element\\ninput array into four\\n16-element chunks.\\nSorting is implemented within\\nthe Generate operation. Here,\\nk=3 means that, for each 16\\nelement chunk, we generate\\nthree different sortings. \\nHere, N=1 means that we\\nmaintain a single best\\nsorting outcome out of\\nthe three input ones.\\nHere, k=10 means that we try 10 different\\naggregations of the two input 16-element subarrays.To obtain the score, for every\\nnumber 0 - 9, we get the\\ndifference between the input\\nand the sorted list, and we sum\\nall 10 values. Zero indicates\\ncorrectly sorted. To show\\n\"the higher the better\", we do\\nmax(input_length - score, 0)Note that this is an example graph decomposition. The structure\\nof connections between all operations can be arbitrarily modified.\\nSort\\nKeepBest\\nAggregateFigure 4: An example graph decomposition of the sorting\\nuse case in GoT. All used operations (Generate, Aggregate,\\nScore, KeepBest) are described in Figure 3.\\n6' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 5}\n",
      "page_content='58]. Set intersection of two sets is implemented similarly as\\nthe sorting. The second input set is split into subsets and the\\nintersection of those subsets with the first input set is deter-\\nmined with the help of the LLM. Afterwards the resulting\\nintersection sets are aggregated for the final results. For the\\nevaluation we use different set sizes of 32, 64 and 128 el-\\nements and we vary the number of elements found in both\\nsets to be between 25% and 75%.\\nOur score indicates the total number of missing or in-\\ncorrectly included elements in the final intersection. Specif-\\nically, denote two input sets with A= [a1, a2, ..., a n]\\nandB= [b1, b2, ..., b n], and the output set with C=\\n[c1, c2, ..., c m]. Then,\\nerror-scope =X1+X2+Xd\\nwhere X1=|C\\\\(A∩B)|are the number of elements in C\\nthat are not supposed to be there, X2=|(A∩B)\\\\C|are the\\nnumber of elements missing from C, and Xdis the number\\nof duplicates in C(because the LLM expresses the set as a\\nlist in natural language). Finally, to use a “positive score”\\ndescribing “the scope of correctly computed” elements, one\\ncan use the value max( n−error-scope ,0).\\n5.3 Keyword Counting\\nKeyword counting finds the frequency of keywords in a\\ngiven category (countries in our example implementation)\\nwithin the input text. GoT splits the input text into multiple\\npassages, counts the keywords in each passage and aggre-\\ngates the subresults. The number of passages is configurable\\nand can also be left to the LLM, making it possible to treat\\neach sentence as a separate passage. Here, to score a thought,\\nwe first – for each keyword – derive the absolute difference\\nbetween the computed count and the correct one. We then\\nsum all these differences to get the final score.\\n5.4 Document Merging\\nFinally, we also provide document merging. Here, the goal\\nis to generate a new Non-Disclosure Agreement (NDA) doc-\\nument based on several input ones that partially overlap\\nin terms of their contents. The goal is to ensure minimal\\namount of duplication, while maximizing information reten-\\ntion. Document merging is broadly applicable in, e.g., legal\\nprocedures, where multiple sources of information have to\\nbe combined into a single document or article. To score a\\nsolution, we query the LLM for two values (3 times for each\\nvalue, and take the average). The first value corresponds to\\nthe solution redundancy (10 indicates no redundancy, 0 im-\\nplies at least half the information is redundant), the second\\nvalue stands for information retention (10 indicates all infor-\\nmation is retained, 0 says that none is retained). We compute\\nthe harmonic mean of these values.\\n6 The Latency-Volume Tradeoff\\nWe now show that GoT improves upon previous prompting\\nschemes in terms of the tradeoff between latency (number of\\nhops in the graph of thoughts to reach a given final thought)\\nandvolume . We define volume – for a given thought t– asthe number of preceding LLM thoughts that could have im-\\npacted t. Formally, the volume of tis the number of thoughts\\nfrom which there exists a path to tin the graph of thoughts.\\nWe assume that outputting a single thought costs O(1)time\\nand fix the total cost to Θ(n)for each prompting scheme.\\nThe structure of the schemes is as follows. CoT-SC con-\\nsists of kindependent chains originating from a single start-\\ning thought. ToT is a complete k-ary tree. Finally, in GoT, a\\ncomplete k-ary tree is joined at its leaves with a “mirrored”\\nk-ary tree of the same size but with its edges reversed.\\nThe analysis is detailed in Table 2. CoT offers a large vol-\\nume of up to N, but at the cost of a high latency of N. CoT-\\nSC reduces the latency by a factor of k(which corresponds\\nto its branching factor), but it simultaneously decreases the\\nvolume by kas well. ToT offers a latency of logkNbut\\nalso has low volume. GoT is the only scheme to come with\\nboth a low latency of logkNand a high volume N. This\\nis enabled by the fact that GoT harnesses aggregations of\\nthoughts, making it possible to reach the final thought from\\nany other intermediate thought in the graph decomposition.\\nScheme Latency Volume\\nChain-of-Thought (CoT) N N\\nSelf-Consistency with CoT (CoT-SC) N/k N/k\\nTree of Thoughts (ToT) logkN O (logkN)\\nGraph of Thoughts (GoT) logkN N\\nTable 2: Comparison of prompting schemes, with respect\\nto their fundamental tradeoff between latency and volume.\\nGoT offers the best tradeoff.\\n7 Evaluation\\nWe show the advantages of GoT over the state of the art. We\\nfocus on comparing GoT to ToT, as it was shown to consis-\\ntently outperform other schemes. Still, for a broad compari-\\nson, we also experiment with IO, CoT, and CoT-SC. As our\\nanalysis results in a large evaluation space, we present rep-\\nresentative results and omit data that does not bring relevant\\ninsights (e.g., CoT-SC).\\n7.1 Evaluation Methodology\\nWe use 100 input samples for each task and comparison\\nbaseline. We set the temperature to 1.0 and use a 4k con-\\ntext size unless stated otherwise. For each experiment, we\\nfix the numbers of thoughts in respective schemes to achieve\\nsimilar costs in each experiment.\\nParameters We experiment extensively with the branch-\\ning factor kand the number of levels Lto ensure that we\\ncompare GoT to cost-effective and advantageous configu-\\nrations. We plot two variants of ToT: one with higher k\\nand lower depth (ToT), the other with lower kbut higher L\\n(ToT2). We usually aim to achieve a sweet spot in the trade-\\noff between sparser generation rounds (lower k) vs. more\\nrounds (larger L). Usually more responses per round is more\\nexpensive (e.g., 80 vs. 60 total responses for Figure 7 but $6\\nvs. $3 costs). We also try different problem sizes P(e.g., in\\nsorting, Pstates how many numbers are to be sorted).\\n7' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 6}\n",
      "page_content='IOCoT ToTToT2 GoT0246810121416#incorrectly sorted elements; the lower the better\\n32 elements\\n0.00.20.40.60.81.01.21.41.6\\nIOCoT ToTToT2 GoT0481216202428323640444852566064\\n64 elements\\n0.00.30.60.91.21.51.82.12.42.73.03.33.63.94.24.54.8\\nIOCoT ToTToT2 GoT081624324048566472808896104112120128\\n128 elements\\n012345678910111213141516\\nTotal Cost ($); the lower the betterL=2\\nk=20\\nL=3\\nk=10GoT: Figure 4 & Appendix\\nclipped\\nL=4\\nk=20L=7\\nk=10GoT: Figure 4\\n& Appendixclipped\\nL=4\\nk=20\\nL=10\\nk=10GoT:\\nFigure 4\\n&\\nAppendixFigure 5: Number of errors and cost in sorting tasks with ChatGPT-3.5. Landkindicate the structure of ToT (see Sections 3.2\\nand 6).\\nUsed LLMs Due to budget restrictions, we focus on GPT-\\n3.5. We also experimented with Llama-2, but it was usually\\nworse than GPT-3.5 and also much slower to run, making it\\ninfeasible to obtain enough samples.\\n7.2 Analysis of GoT’s Advantages\\nThe results of the analysis are in Figure 5 (sorting), 6 (set\\nintersection), 7 (keyword counting), and 8 (document merg-\\ning); see Section 5 for the description of specific use cases.\\nOverall, GoT improves the quality of outcomes over all the\\nconsidered baselines and it reduces inference costs com-\\npared to ToT .\\nGoT vs. ToT GoT improves upon ToT and ToT2 by a\\nlarge margin over all the considered problem instances. ToT\\nusually comes with somewhat higher quality than ToT2, but\\nsimultaneously much higher costs. GoT’s costs are always\\nlower than ToT, and comparable (in some cases lower, in\\nothers higher) to ToT2. For example, it reduces median er-\\nror by ≈62%, thereby achieving a higher quality of sorting,\\nforP= 128 in comparison to ToT while ensuring >31%\\ncost reductions. These advantages are due to GoT’s ability to\\ndecompose complex tasks into simpler subtasks, solve these\\nsubtasks independently, and then incrementally merge these\\noutcomes into the final result.\\nGoT vs. IO and CoT GoT consistently delivers much\\nhigher quality of outcomes than IO/CoT. For example, for\\nsorting ( P= 64 ), GoT’s median error is ≈65% and ≈83%\\nlower than, respectively, CoT and IO. Yet, the costs of GoT\\n– and ToT – are much higher than in IO and CoT. This is\\nmostly due to our configuration of CoT, where we do not ar-\\ntificially inflate the lengths of the chains of reasoning if this\\ndoes not improve the outcomes. The higher costs of GoT and\\nToT are driven by knew thoughts built for each Generate\\noperation; these multiple thoughts are one of the reasons for\\nGoT’s superiority in quality.\\nIncreasing Complexity of Tackled Problems Most im-\\nportantly, the advantages of GoT in the quality increase for\\nall the baselines with the growing size of the problem P. Forexample, in sorting, while for P= 32 GoT only negligibly\\nimproves upon ToT2, its median error count becomes lower\\nby≈61% for P= 64 and≈69% for P= 128 . The quar-\\ntiles also become respectively better. The results for other\\nschemes also follow the intuition; for example, IO becomes\\nconsistently worse with the increasing P, which is expected\\nas a single thought is unlikely to solve a large problem in-\\nstance. Overall, this analysis illustrates that GoT is indeed\\nwell-suited for elaborate problem cases , as the execution\\nschedules usually become more complex with the growing\\nproblem sizes.\\n7.3 Discussion on Task Decomposition\\nWhen splitting a task into subtasks and then solving these\\nsubtasks, the size of responses and the input (in tokens) are\\nreduced proportionally to the degree of the task decomposi-\\ntion. However, the “static” part of the prompt (i.e., few-shot\\nexamples) may become a significant overhead (see GoT4 to\\nGoT8 in Figure 7). Here, we observe that these few-shot ex-\\namples can usually also be reduced in size (e.g., the passages\\nused to demonstrate keyword counting can also be made\\nsmaller and still be indicative of the actual input size), thus\\nactively working towards decreasing the cost (e.g., see the\\ndifference between GoT8 and GoTx in Figure 7).\\nThe overall goal when conducting graph decomposition is\\nto break down a task to the point, where the LLM can solve\\nit correctly for the majority of time using a single prompt\\n(or with a few additional improvement steps). This signifi-\\ncantly lowers the number of improvement/refinement steps\\nneeded during the later stages of the graph exploration. Fur-\\nthermore, as indicated by our results, combining or concate-\\nnating subresults is usually an easier task than solving large\\ntask instances from scratch. Hence, the LLM is often suc-\\ncessful when aggregating the final solution.\\n8 Related Work\\nWe summarize relations between GoT and related work.\\n8' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 7}\n",
      "page_content='IOCoT T oTT oT2GoT024681012141618#incorrect elements; the lower the better\\n7 6 31 29 4332 elements\\n0.00.20.40.60.81.01.21.41.61.8\\nIOCoT ToTToT2 GoT048121620242832\\n0 0 0 0 464 elements\\n0.00.61.21.82.43.03.64.24.8\\nIOCoT ToTToT2 GoT0816243240485664728088\\n0 0 0 0 0128 elements\\n01234567891011\\nTotal Cost ($); the lower the betterL=2\\nk=20Solved \\ncorrectly:\\nL=7\\nk=10\\nL=4\\nk=25\\nL=9\\nk=10L=3\\nk=10L=4\\nk=20GoT: Appendix GoT: Appendix GoT: AppendixFigure 6: Number of errors and cost in set intersection tasks with ChatGPT-3.5. Landkindicate the structure of ToT (see\\nSections 3.2 and 6).\\nIO CoT ToT ToT2 GoT4 GoT8 GoTx05101520253035Number of errors; the lower the better\\n0 0 1 0 8 7 25\\n012345678\\nTotal Cost ($); the lower the betterSamples solved\\ncorrectly\\nSplits the input text into 4 passages, counts\\nkeywords in each one, aggregates the sub-\\nresults always 2 at a time\\nL=4\\nk=20\\nL=6\\nk=10Splits the\\ninput into\\nsentences\\n(each input\\nhas 12-19\\nsentences)As GoT4, but splits the\\ninput text into 8 passages\\nFigure 7: Number of errors and cost in keyword counting\\nwith ChatGPT-3.5. Landkindicate the structure of ToT (see\\nSections 3.2 and 6).\\n8.1 Prompting Paradigms & Approaches\\nWe detail different prompting paradigms in Section 1 and\\nTable 1. There are numerous other works related to prompt-\\ning. We now briefly summarize selected most related ones;\\nmore extensive descriptions can be found in dedicated sur-\\nveys [34, 40, 69, 70]. Wang et al. proposed Plan-and-\\nSolve, an approach to enhance CoT with an explicit plan-\\nning stage [66]. Using complexity-based criteria to enhance\\nprompting within a CoT was designed by Fu et al. [29, 67].\\nThe self-taught reasoner (STaR) [80] generates several chain\\nof thoughts, and selects the ones that are valid. Similarly, a\\nscheme by Shum et al. [61] generates a pool of CoT candi-\\ndates, and selects the best candidate based on whether the\\ncandidates match the ground truth and on a policy gradient-\\nbased method. Automatic prompt generation overcomes the\\nIO CoT ToT GoT GoT202468Score (out of 10); the higher the better\\n03691215\\nTotal Cost ($); the lower the betterL=3\\nk=10Aggregation of fully\\nmerged NDAs\\nAggregation\\nof partially\\nmerged\\nNDAsFigure 8: Score and cost in document merging with\\nChatGPT-3.5. Landkindicate the structure of ToT (see Sec-\\ntions 3.2 and 6). Number of samples: 50; context size: 16k\\ntokens.\\nissues of scaling in CoT [41, 42, 59]. Zhou et al. pro-\\npose to harness selecting the best prompt out of a candidate\\nset [84]. Skeleon-of-Thought [47] generates at first a num-\\nber of skeleton answers (brief bullet points of 3 to 5 words)\\nand expands on these points in parallel in a second step.\\nFinally, in prompt chaining, one cascades different LLMs.\\nThis enables prompting different LLMs via different con-\\ntexts, enabling more powerful reasoning [21, 23, 48, 51, 72,\\n73, 73]. GoT is orthogonal to this class of schemes, as it\\nfocuses on a single context capabilities.\\n8.2 Self-Reflection & Self-Evaluation\\nSelf-reflection and self-evaluation were introduced re-\\ncently [45, 49, 60, 75, 85]. They are used to enhance dif-\\nferent tasks, for example for code generation [17] or com-\\n9' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 8}\n",
      "page_content='puter operation tasks [39]. In GoT, we partially rely on\\nself-evaluation when taking decisions on how to expand the\\ngraph of thoughts within a prompt.\\n8.3 LLMs & Planning\\nThere are many works recently on how to plan complex\\ntasks with LLMs [36, 37, 68, 76, 78, 81]. GoT could be seen\\nas a generic framework that could potentially be used to en-\\nhance such schemes, by offering a paradigm for generating\\ncomplex graph-based plans.\\n8.4 Graphs and Graph Computing\\nGraphs have become an immensely popular and important\\npart of the general computing landscape [31, 32, 44, 46, 56].\\nRecently, there has been a growing interest in domains\\nsuch as graph databases [2–4, 7, 55], graph pattern match-\\ning [8, 10, 11, 18, 25, 62], graph streaming [1, 22, 26],\\nand graph machine learning as well as graph neural net-\\nworks [5, 6, 12, 16, 30, 33, 33, 57, 74, 82, 83]. The graph\\nabstraction has been fruitful for many modern research do-\\nmains, such as social sciences (e.g., studying human inter-\\nactions), bioinformatics (e.g., analyzing protein structures),\\nchemistry (e.g., designing chemical compounds), medicine\\n(e.g., drug discovery), cybersecurity (e.g., identifying in-\\ntruder machines), healthcare (e.g., exposing groups of peo-\\nple who submit fraudulent claims), web graph analysis (e.g.,\\nproviding accurate search services), entertainment services\\n(e.g., predicting movie popularity), linguistics (e.g., model-\\ning relationships between words), transportation (e.g., find-\\ning efficient routes), physics (e.g., understanding phase tran-\\nsitions and critical phenomena), and many others [15, 20,\\n35, 38, 44]. In this work, we harness the graph abstraction\\nas a key mechanism that enhances prompting capabilities in\\nLLMs.\\n9 Conclusion\\nPrompt engineering is one of the central new domains of\\nthe large language model (LLM) research. It enables using\\nLLMs efficiently, without any model updates. However, de-\\nsigning effective prompts is a challenging task.\\nIn this work, we propose Graph of Thoughts (GoT), a new\\nparadigm that enables the LLM to solve different tasks effec-\\ntively without any model updates. The key idea is to model\\nthe LLM reasoning as an arbitrary graph, where thoughts\\nare vertices and dependencies between thoughts are edges.\\nThis enables novel transformations of thoughts, such as ag-\\ngregation. Human’s task solving is often non-linear, and it\\ninvolves combining intermediate solutions into final ones,\\nor changing the flow of reasoning upon discovering new in-\\nsights. GoT reflects this with its graph structure.\\nGoT outperforms other prompting schemes, for example\\nensuring 62% increase in the quality of sorting over ToT,\\nwhile simultaneously reducing costs by >31%. We also pro-\\npose a novel metric for a prompting scheme, the volume of\\na thought, to indicate the scope of information that a given\\nLLM output could carry with it, where GoT also excels. This\\nprovides a step towards more principled prompt engineering.The graph abstraction has been the foundation of several\\nsuccessful designs in computing and AI over last decades,\\nfor example AlphaFold for protein predictions. Our work\\nharnesses it within the realm of prompt engineering.\\nAcknowledgements\\nWe thank Hussein Harake, Colin McMurtrie, Mark Klein, An-\\ngelo Mangili, and the whole CSCS team granting access to the\\nAult and Daint machines, and for their excellent technical sup-\\nport. We thank Timo Schneider for help with infrastructure at\\nSPCL. This project received funding from the European Re-\\nsearch Council (Project PSAP, No. 101002047), and the European\\nHigh-Performance Computing Joint Undertaking (JU) under grant\\nagreement No. 955513 (MAELSTROM). This project was sup-\\nported by the ETH Future Computing Laboratory (EFCL), financed\\nby a donation from Huawei Technologies. This project received\\nfunding from the European Union’s HE research and innovation\\nprogramme under the grant agreement No. 101070141 (Project\\nGLACIATION).\\nReferences\\n[1] Besta, M.; Fischer, M.; Kalavri, V .; Kapralov, M.; and\\nHoefler, T. 2023. Practice of Streaming Processing\\nof Dynamic Graphs: Concepts, Models, and Systems.\\nIEEE Transactions on Parallel and Distributed Sys-\\ntems, 34(6): 1860–1876.\\n[2] Besta, M.; Gerstenberger, R.; Blach, N.; Fischer, M.;\\nand Hoefler, T. 2023. GDI: A Graph Database Inter-\\nface Standard. https://github.com/spcl/GDI-RMA. Ac-\\ncessed: 2023-09-05.\\n[3] Besta, M.; Gerstenberger, R.; Fischer, M.; Podstawski,\\nM.; Blach, N.; Egeli, B.; Mitenkov, G.; Chlapek, W.;\\nMichalewicz, M.; Niewiadomski, H.; M ¨uller, J.; and\\nHoefler, T. 2023. The Graph Database Interface: Scal-\\ning Online Transactional and Analytical Graph Work-\\nloads to Hundreds of Thousands of Cores. In Proceed-\\nings of the International Conference for High Perfor-\\nmance Computing, Networking, Storage and Analysis ,\\nSC ’23. ACM.\\n[4] Besta, M.; Gerstenberger, R.; Peter, E.; Fischer, M.;\\nPodstawski, M.; Barthels, C.; Alonso, G.; and Hoefler,\\nT. 2023. Demystifying Graph Databases: Analysis and\\nTaxonomy of Data Organization, System Designs, and\\nGraph Queries. ACM Comput. Surv. , 56(2).\\n[5] Besta, M.; Grob, R.; Miglioli, C.; Bernold, N.;\\nKwa ´sniewski, G.; Gjini, G.; Kanakagiri, R.; Ashkboos,\\nS.; Gianinazzi, L.; Dryden, N.; and Hoefler, T. 2022.\\nMotif Prediction with Graph Neural Networks. In\\nProceedings of the 28th ACM SIGKDD Conference\\non Knowledge Discovery and Data Mining , KDD ’22,\\n35–45.\\n[6] Besta, M.; and Hoefler, T. 2022. Parallel and Dis-\\ntributed Graph Neural Networks: An In-Depth Concur-\\nrency Analysis. arXiv:2205.09702.\\n[7] Besta, M.; Iff, P.; Scheidl, F.; Osawa, K.; Dryden, N.;\\nPodstawski, M.; Chen, T.; and Hoefler, T. 2022. Neural\\nGraph Databases. In Proceedings of the First Learning\\non Graphs Conference , volume 198 of Proceedings of\\nMachine Learning Research , 31:1–31:38. PMLR.\\n10' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 9}\n",
      "page_content='[8] Besta, M.; Kanakagiri, R.; Kwa ´sniewski, G.;\\nAusavarungnirun, R.; Ber ´anek, J.; Kanellopoulos,\\nK.; Janda, K.; V onarburg-Shmaria, Z.; Gianinazzi,\\nL.; Stefan, I.; Luna, J. G.; Golinowski, J.; Copik,\\nM.; Kapp-Schwoerer, L.; Di Girolamo, S.; Blach,\\nN.; Konieczny, M.; Mutlu, O.; and Hoefler, T. 2021.\\nSISA: Set-Centric Instruction Set Architecture for\\nGraph Mining on Processing-in-Memory Systems. In\\nProceedings of the 54th Annual IEEE/ACM Interna-\\ntional Symposium on Microarchitecture , MICRO ’21,\\n282–297.\\n[9] Besta, M.; Kanakagiri, R.; Mustafa, H.; Karasikov,\\nM.; R ¨atsch, G.; Hoefler, T.; and Solomonik, E. 2020.\\nCommunication-Efficient Jaccard Similarity for High-\\nPerformance Distributed Genome Comparisons. In\\nProceedings of the IEEE International Parallel and\\nDistributed Processing Symposium , IPDPS ’20, 1122–\\n1132.\\n[10] Besta, M.; Miglioli, C.; Labini, P. S.; T ˇetek, J.; Iff, P.;\\nKanakagiri, R.; Ashkboos, S.; Janda, K.; Podstawski,\\nM.; Kwa ´sniewski, G.; Gleinig, N.; Vella, F.; Mutlu, O.;\\nand Hoefler, T. 2022. ProbGraph: High-Performance\\nand High-Accuracy Graph Mining with Probabilistic\\nSet Representations. In Proceedings of the Interna-\\ntional Conference on High Performance Computing,\\nNetworking, Storage and Analysis , SC ’22. IEEE.\\n[11] Besta, M.; V onarburg-Shmaria, Z.; Schaffner, Y .;\\nSchwarz, L.; Kwa ´sniewski, G.; Gianinazzi, L.; Be-\\nranek, J.; Janda, K.; Holenstein, T.; Leisinger, S.;\\nTatkowski, P.; Ozdemir, E.; Balla, A.; Copik, M.; Lin-\\ndenberger, P.; Konieczny, M.; Mutlu, O.; and Hoe-\\nfler, T. 2021. GraphMineSuite: Enabling High-\\nPerformance and Programmable Graph Mining Algo-\\nrithms with Set Algebra. Proc. VLDB Endow. , 14(11):\\n1922–1935.\\n[12] Bronstein, M. M.; Bruna, J.; LeCun, Y .; Szlam, A.; and\\nVandergheynst, P. 2017. Geometric Deep Learning:\\nGoing beyond Euclidean data. IEEE Signal Process-\\ning Magazine , 34(4): 18–42.\\n[13] Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Ka-\\nplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam,\\nP.; Sastry, G.; Askell, A.; Agarwal, S.; Herbert-V oss,\\nA.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.;\\nZiegler, D.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.;\\nSigler, E.; Litwin, M.; Gray, S.; Chess, B.; Clark, J.;\\nBerner, C.; McCandlish, S.; Radford, A.; Sutskever, I.;\\nand Amodei, D. 2020. Language Models are Few-Shot\\nLearners. In Advances in Neural Information Process-\\ning Systems (NeurIPS ’20) , volume 33, 1877–1901.\\nCurran Associates.\\n[14] Bubeck, S.; Chandrasekaran, V .; Eldan, R.; Gehrke,\\nJ.; Horvitz, E.; Kamar, E.; Lee, P.; Lee, Y . T.; Li,\\nY .; Lundberg, S.; Nori, H.; Palangi, H.; Ribeiro,\\nM. T.; and Zhang, Y . 2023. Sparks of Artificial\\nGeneral Intelligence: Early experiments with GPT-4.\\narXiv:2303.12712.\\n[15] Chakrabarti, D.; and Faloutsos, C. 2006. Graph Min-ing: Laws, Generators, and Algorithms. ACM Comput.\\nSurv. , 38(1).\\n[16] Chami, I.; Abu-El-Haija, S.; Perozzi, B.; R ´e, C.;\\nand Murphy, K. 2020. Machine Learning on\\nGraphs: A Model and Comprehensive Taxonomy.\\narXiv:2005.03675.\\n[17] Chen, X.; Lin, M.; Sch ¨arli, N.; and Zhou, D. 2023.\\nTeaching Large Language Models to Self-Debug.\\narXiv:2304.05128.\\n[18] Cheng, J.; Yu, J. X.; Ding, B.; Philip, S. Y .; and Wang,\\nH. 2008. Fast Graph Pattern Matching. In Proceedings\\nof the IEEE 24th International Conference on Data En-\\ngineering , ICDE ’08, 913–922.\\n[19] Chowdhery, A.; Narang, S.; Devlin, J.; Bosma,\\nM.; Mishra, G.; Roberts, A.; Barham, P.; Chung,\\nH. W.; Sutton, C.; Gehrmann, S.; Schuh, P.; Shi, K.;\\nTsvyashchenko, S.; Maynez, J.; Rao, A.; Barnes, P.;\\nTay, Y .; Shazeer, N.; Prabhakaran, V .; Reif, E.; Du,\\nN.; Hutchinson, B.; Pope, R.; Bradbury, J.; Austin, J.;\\nIsard, M.; Gur-Ari, G.; Yin, P.; Duke, T.; Levskaya,\\nA.; Ghemawat, S.; Dev, S.; Michalewski, H.; Garcia,\\nX.; Misra, V .; Robinson, K.; Fedus, L.; Zhou, D.; Ip-\\npolito, D.; Luan, D.; Lim, H.; Zoph, B.; Spiridonov,\\nA.; Sepassi, R.; Dohan, D.; Agrawal, S.; Omernick,\\nM.; Dai, A. M.; Pillai, T. S.; Pellat, M.; Lewkowycz,\\nA.; Moreira, E.; Child, R.; Polozov, O.; Lee, K.; Zhou,\\nZ.; Wang, X.; Saeta, B.; Diaz, M.; Firat, O.; Catasta,\\nM.; Wei, J.; Meier-Hellstern, K.; Eck, D.; Dean, J.;\\nPetrov, S.; and Fiedel, N. 2022. PaLM: Scaling Lan-\\nguage Modeling with Pathways. arXiv:2204.02311.\\n[20] Cook, D. J.; and Holder, L. B., eds. 2006. Mining\\nGraph Data . John Wiley & Sons.\\n[21] Creswell, A.; Shanahan, M.; and Higgins, I. 2022.\\nSelection-Inference: Exploiting Large Language\\nModels for Interpretable Logical Reasoning.\\narXiv:2205.09712.\\n[22] Dhulipala, L.; Blelloch, G. E.; and Shun, J. 2019. Low-\\nLatency Graph Streaming Using Compressed Purely-\\nFunctional Trees. In Proceedings of the 40th ACM\\nSIGPLAN Conference on Programming Language De-\\nsign and Implementation , PLDI ’19, 918–934.\\n[23] Dohan, D.; Xu, W.; Lewkowycz, A.; Austin, J.; Bieber,\\nD.; Lopes, R. G.; Wu, Y .; Michalewski, H.; Saurous,\\nR. A.; Sohl-Dickstein, J.; Murphy, K.; and Sutton, C.\\n2022. Language Model Cascades. In Beyond Bayes:\\nPaths Towards Universal Reasoning Systems , Work-\\nshop at ICML ’22.\\n[24] Drori, I.; Zhang, S.; Shuttleworth, R.; Tang, L.; Lu, A.;\\nKe, E.; Liu, K.; Chen, L.; Tran, S.; Cheng, N.; Wang,\\nR.; Singh, N.; Patti, T. L.; Lynch, J.; Shporer, A.;\\nVerma, N.; Wu, E.; and Strang, G. 2022. A neural net-\\nwork solves, explains, and generates university math\\nproblems by program synthesis and few-shot learning\\nat human level. Proceedings of the National Academy\\nof Sciences , 119(32): e2123433119.\\n[25] Fan, W.; Li, J.; Ma, S.; Tang, N.; Wu, Y .; and Wu,\\nY . 2010. Graph Pattern Matching: From Intractable\\n11' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 10}\n",
      "page_content='to Polynomial Time. Proc. VLDB Endow. , 3(1–2):\\n264–275.\\n[26] Feng, G.; Meng, X.; and Ammar, K. 2015. DIS-\\nTINGER: A distributed graph data structure for mas-\\nsive dynamic graph processing. In Proccedings of the\\nIEEE International Conference on Big Data , Big Data\\n’15, 1814–1822.\\n[27] Friggeri, A.; Chelius, G.; and Fleury, E. 2011. Trian-\\ngles to Capture Social Cohesion. In Proceedings of\\nthe IEEE Third International Conference on Privacy,\\nSecurity, Risk and Trust and IEEE Third International\\nConference on Social Computing , PASSAT/SocialCom\\n’11, 258–265.\\n[28] Friston, K. 2008. Hierarchical Models in the Brain.\\nPLOS Computational Biology , 4(11): 1–24.\\n[29] Fu, Y .; Peng, H.; Sabharwal, A.; Clark, P.; and Khot,\\nT. 2022. Complexity-Based Prompting for Multi-Step\\nReasoning. arXiv:2210.00720.\\n[30] Gianinazzi, L.; Fries, M.; Dryden, N.; Ben-Nun, T.;\\nBesta, M.; and Hoefler, T. 2021. Learning Combina-\\ntorial Node Labeling Algorithms. arXiv:2106.03594.\\n[31] Gregor, D.; and Lumsdaine, A. 2005. Lifting Sequen-\\ntial Graph Algorithms for Distributed-Memory Parallel\\nComputation. SIGPLAN Not. , 40(10): 423–437.\\n[32] Gregor, D.; and Lumsdaine, A. 2005. The Parallel\\nBGL: A generic library for distributed graph compu-\\ntations. Parallel Object-Oriented Scientific Computing\\n(POOSC) .\\n[33] Hamilton, W. L.; Ying, R.; and Leskovec, J. 2017. Rep-\\nresentation Learning on Graphs: Methods and Appli-\\ncations. Bulletin of the Technical Committee on Data\\nEngineering , 40(3): 52–74.\\n[34] Hartmann, M.; and Sonntag, D. 2022. A survey on\\nimproving NLP models with human explanations. In\\nProceedings of the First Workshop on Learning with\\nNatural Language Supervision , 40–47. Association for\\nComputational Linguistics.\\n[35] Horv ´ath, T.; G ¨artner, T.; and Wrobel, S. 2004. Cyclic\\nPattern Kernels for Predictive Graph Mining. In Pro-\\nceedings of the Tenth ACM SIGKDD International\\nConference on Knowledge Discovery and Data Min-\\ning, KDD ’04, 158–167.\\n[36] Huang, W.; Abbeel, P.; Pathak, D.; and Mordatch, I.\\n2022. Language Models as Zero-Shot Planners: Ex-\\ntracting Actionable Knowledge for Embodied Agents.\\nInProceedings of the 39th International Conference\\non Machine Learning , volume 162 of Proceedings of\\nMachine Learning Research , 9118–9147. PMLR.\\n[37] Huang, W.; Xia, F.; Xiao, T.; Chan, H.; Liang, J.; Flo-\\nrence, P.; Zeng, A.; Tompson, J.; Mordatch, I.; Cheb-\\notar, Y .; Sermanet, P.; Brown, N.; Jackson, T.; Luu,\\nL.; Levine, S.; Hausman, K.; and Ichter, B. 2022. In-\\nner Monologue: Embodied Reasoning through Plan-\\nning with Language Models. arXiv:2207.05608.\\n[38] Jiang, C.; Coenen, F.; and Zito, M. 2013. A survey of\\nfrequent subgraph mining algorithms. The Knowledge\\nEngineering Review , 28(1): 75–105.[39] Kim, G.; Baldi, P.; and McAleer, S. 2023. Language\\nModels can Solve Computer Tasks. arXiv:2303.17491.\\n[40] Lertvittayakumjorn, P.; and Toni, F. 2021.\\nExplanation-Based Human Debugging of NLP\\nModels: A Survey. Transactions of the Association for\\nComputational Linguistics , 9: 1508–1528.\\n[41] Lester, B.; Al-Rfou, R.; and Constant, N. 2021. The\\nPower of Scale for Parameter-Efficient Prompt Tun-\\ning. In Proceedings of the Conference on Empiri-\\ncal Methods in Natural Language Processing , EMNLP\\n’21, 3045–3059. Association for Computational Lin-\\nguistics.\\n[42] Li, X. L.; and Liang, P. 2021. Prefix-Tuning:\\nOptimizing Continuous Prompts for Generation.\\narXiv:2101.00190.\\n[43] Long, J. 2023. Large Language Model Guided Tree-\\nof-Thought. arXiv:2305.08291.\\n[44] Lumsdaine, A.; Gregor, D.; Hendrickson, B.; and\\nBerry, J. 2007. Challenges in Parallel Graph Process-\\ning. Parallel Processing Letters , 17(1): 5–20.\\n[45] Madaan, A.; Tandon, N.; Gupta, P.; Hallinan, S.; Gao,\\nL.; Wiegreffe, S.; Alon, U.; Dziri, N.; Prabhumoye, S.;\\nYang, Y .; Gupta, S.; Majumder, B. P.; Hermann, K.;\\nWelleck, S.; Yazdanbakhsh, A.; and Clark, P. 2023.\\nSelf-Refine: Iterative Refinement with Self-Feedback.\\narXiv:2303.17651.\\n[46] Malewicz, G.; Austern, M. H.; Bik, A. J.; Dehnert,\\nJ. C.; Horn, I.; Leiser, N.; and Czajkowski, G. 2010.\\nPregel: A System for Large-Scale Graph Processing. In\\nProceedings of the International Conference on Man-\\nagement of Data , SIGMOD ’10, 135–146. ACM.\\n[47] Ning, X.; Lin, Z.; Zhou, Z.; Wang, Z.; Yang, H.; and\\nWang, Y . 2023. Skeleton-of-Thought: Large Language\\nModels Can Do Parallel Decoding. arXiv:2307.15337.\\n[48] Nye, M.; Andreassen, A. J.; Gur-Ari, G.; Michalewski,\\nH.; Austin, J.; Bieber, D.; Dohan, D.; Lewkowycz, A.;\\nBosma, M.; Luan, D.; Sutton, C.; and Odena, A. 2021.\\nShow Your Work: Scratchpads for Intermediate Com-\\nputation with Language Models. arXiv:2112.00114.\\n[49] Paul, D.; Ismayilzada, M.; Peyrard, M.; Borges, B.;\\nBosselut, A.; West, R.; and Faltings, B. 2023. RE-\\nFINER: Reasoning Feedback on Intermediate Repre-\\nsentations. arXiv:2304.01904.\\n[50] Prat-P ´erez, A.; Dominguez-Sal, D.; Brunat, J. M.; and\\nLarriba-Pey, J.-L. 2012. Shaping Communities out\\nof Triangles. In Proceedings of the 21st ACM Inter-\\nnational Conference on Information and Knowledge\\nManagement , CIKM ’12, 1677–1681.\\n[51] Qiao, S.; Ou, Y .; Zhang, N.; Chen, X.; Yao, Y .; Deng,\\nS.; Tan, C.; Huang, F.; and Chen, H. 2023. Reasoning\\nwith Language Model Prompting: A Survey. In Pro-\\nceedings of the 61st Annual Meeting of the Association\\nfor Computational Linguistics , ACL ’23, 5368–5393.\\nAssociation for Computational Linguistics.\\n[52] qrdlgit. 2023. graph-of-thoughts Repository. https:\\n//github.com/qrdlgit/graph-of-thoughts. Accessed:\\n2023-10-11.\\n12' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 11}\n",
      "page_content='[53] Radford, A.; Narasimhan, K.; Salimans, T.; and\\nSutskever, I. 2018. Improving Language Understand-\\ning by Generative Pre-Training. https://openai.com/\\nresearch/language-unsupervised. Accessed: 2023-09-\\n06.\\n[54] Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.;\\nand Sutskever, I. 2019. Language Models are Unsuper-\\nvised Multitask Learners. https://openai.com/research/\\nbetter-language-models. Accessed: 2023-09-06.\\n[55] Robinson, I.; Webber, J.; and Eifrem, E. 2015. Graph\\nDatabases: New Opportunities for Connected Data .\\nO’Reilly Media, 2nd edition.\\n[56] Sakr, S.; Bonifati, A.; V oigt, H.; Iosup, A.; Ammar, K.;\\nAngles, R.; Aref, W.; Arenas, M.; Besta, M.; Boncz,\\nP. A.; Daudjee, K.; Valle, E. D.; Dumbrava, S.; Har-\\ntig, O.; Haslhofer, B.; Hegeman, T.; Hidders, J.; Hose,\\nK.; Iamnitchi, A.; Kalavri, V .; Kapp, H.; Martens, W.;\\n¨Ozsu, M. T.; Peukert, E.; Plantikow, S.; Ragab, M.; Ri-\\npeanu, M. R.; Salihoglu, S.; Schulz, C.; Selmer, P.; Se-\\nqueda, J. F.; Shinavier, J.; Sz ´arnyas, G.; Tommasini,\\nR.; Tumeo, A.; Uta, A.; Varbanescu, A. L.; Wu, H.-\\nY .; Yakovets, N.; Yan, D.; and Yoneki, E. 2021. The\\nFuture is Big Graphs: A Community View on Graph\\nProcessing Systems. Commun. ACM , 64(9): 62–71.\\n[57] Scarselli, F.; Gori, M.; Tsoi, A. C.; Hagenbuchner, M.;\\nand Monfardini, G. 2008. The Graph Neural Network\\nModel. IEEE Transactions on Neural Networks , 20(1):\\n61–80.\\n[58] Schaeffer, S. E. 2007. Graph clustering. Computer\\nScience Review , 1(1): 27–64.\\n[59] Shin, T.; Razeghi, Y .; Logan IV , R. L.; Wallace, E.;\\nand Singh, S. 2020. AutoPrompt: Eliciting Knowledge\\nfrom Language Models with Automatically Generated\\nPrompts. arXiv:2010.15980.\\n[60] Shinn, N.; Labash, B.; and Gopinath, A. 2023. Re-\\nflexion: Language Agents with Verbal Reinforcement\\nLearning. arXiv:2303.11366.\\n[61] Shum, K.; Diao, S.; and Zhang, T. 2023. Automatic\\nPrompt Augmentation and Selection with Chain-of-\\nThought from Labeled Data. arXiv:2302.12822.\\n[62] Teixeira, C. H. C.; Fonseca, A. J.; Serafini, M.;\\nSiganos, G.; Zaki, M. J.; and Aboulnaga, A. 2015.\\nArabesque: A System for Distributed Graph Mining.\\nInProceedings of the 25th Symposium on Operating\\nSystems Principles , SOSP ’15, 425–440. ACM.\\n[63] Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.;\\nLachaux, M.-A.; Lacroix, T.; Rozi `ere, B.; Goyal,\\nN.; Hambro, E.; Azhar, F.; Rodriguez, A.; Joulin,\\nA.; Grave, E.; and Lample, G. 2023. LLaMA:\\nOpen and Efficient Foundation Language Models.\\narXiv:2302.13971.\\n[64] Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Alma-\\nhairi, A.; Babaei, Y .; Bashlykov, N.; Batra, S.; Bhar-\\ngava, P.; Bhosale, S.; Bikel, D.; Blecher, L.; Ferrer,\\nC. C.; Chen, M.; Cucurull, G.; Esiobu, D.; Fernandes,\\nJ.; Fu, J.; Fu, W.; Fuller, B.; Gao, C.; Goswami, V .;\\nGoyal, N.; Hartshorn, A.; Hosseini, S.; Hou, R.; Inan,H.; Kardas, M.; Kerkez, V .; Khabsa, M.; Kloumann,\\nI.; Korenev, A.; Koura, P. S.; Lachaux, M.-A.; Lavril,\\nT.; Lee, J.; Liskovich, D.; Lu, Y .; Mao, Y .; Martinet,\\nX.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y .;\\nPoulton, A.; Reizenstein, J.; Rungta, R.; Saladi, K.;\\nSchelten, A.; Silva, R.; Smith, E. M.; Subramanian,\\nR.; Tan, X. E.; Tang, B.; Taylor, R.; Williams, A.;\\nKuan, J. X.; Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y .; Fan,\\nA.; Kambadur, M.; Narang, S.; Rodriguez, A.; Sto-\\njnic, R.; Edunov, S.; and Scialom, T. 2023. Llama\\n2: Open Foundation and Fine-Tuned Chat Models.\\narXiv:2307.09288.\\n[65] Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.;\\nJones, L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I.\\n2017. Attention is All you Need. In Advances in Neu-\\nral Information Processing Systems (NIPS ’17) , vol-\\nume 30. Curran Associates.\\n[66] Wang, L.; Xu, W.; Lan, Y .; Hu, Z.; Lan, Y .; Lee, R.\\nK.-W.; and Lim, E.-P. 2023. Plan-and-Solve Prompt-\\ning: Improving Zero-Shot Chain-of-Thought Reason-\\ning by Large Language Models. In Proceedings of the\\n61st Annual Meeting of the Association for Computa-\\ntional Linguistics , ACL ’23, 2609–2634. Association\\nfor Computational Linguistics.\\n[67] Wang, X.; Wei, J.; Schuurmans, D.; Le, Q. V .; Chi,\\nE. H.; Narang, S.; Chowdhery, A.; and Zhou, D. 2023.\\nSelf-Consistency Improves Chain of Thought Rea-\\nsoning in Language Models. In Proceedings of the\\nEleventh International Conference on Learning Rep-\\nresentations , ICLR ’23.\\n[68] Wang, Z.; Cai, S.; Chen, G.; Liu, A.; Ma, X.; and\\nLiang, Y . 2023. Describe, Explain, Plan and Select:\\nInteractive Planning with Large Language Models En-\\nables Open-World Multi-Task Agents. In Advances in\\nNeural Information Processing Systems (NeurIPS ’23) ,\\nvolume 36. Curran Associates.\\n[69] Wang, Z.; Zhang, G.; Yang, K.; Shi, N.; Zhou, W.;\\nHao, S.; Xiong, G.; Li, Y .; Sim, M. Y .; Chen, X.;\\nZhu, Q.; Yang, Z.; Nik, A.; Liu, Q.; Lin, C.; Wang,\\nS.; Liu, R.; Chen, W.; Xu, K.; Liu, D.; Guo, Y .; and\\nFu, J. 2023. Interactive Natural Language Processing.\\narXiv:2305.13246.\\n[70] Wang, Z. J.; Choi, D.; Xu, S.; and Yang, D. 2021.\\nPutting Humans in the Natural Language Processing\\nLoop: A Survey. In Proceedings of the First Work-\\nshop on Bridging Human-Computer Interaction and\\nNatural Language Processing , 47–52. Association for\\nComputational Linguistics.\\n[71] Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Chi,\\nE.; Le, Q.; and Zhou, D. 2022. Chain-of-Thought\\nPrompting Elicits Reasoning in Large Language Mod-\\nels. arXiv:2201.11903.\\n[72] Wu, T.; Jiang, E.; Donsbach, A.; Gray, J.; Molina, A.;\\nTerry, M.; and Cai, C. J. 2022. PromptChainer: Chain-\\ning Large Language Model Prompts through Visual\\nProgramming. In Extended Abstracts of the Confer-\\nence on Human Factors in Computing Systems , CHI\\nEA ’22. ACM.\\n13' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 12}\n",
      "page_content='[73] Wu, T.; Terry, M.; and Cai, C. J. 2022. AI Chains:\\nTransparent and Controllable Human-AI Interaction\\nby Chaining Large Language Model Prompts. In Pro-\\nceedings of the Conference on Human Factors in Com-\\nputing Systems , CHI ’22. ACM.\\n[74] Wu, Z.; Pan, S.; Chen, F.; Long, G.; Zhang, C.; and Yu,\\nP. S. 2021. A Comprehensive Survey on Graph Neural\\nNetworks. IEEE Transactions on Neural Networks and\\nLearning Systems , 32(1): 4–24.\\n[75] Xie, Y .; Kawaguchi, K.; Zhao, Y .; Zhao, X.; Kan, M.-\\nY .; He, J.; and Xie, Q. 2023. Self-Evaluation Guided\\nBeam Search for Reasoning. In Advances in Neural\\nInformation Processing Systems (NeurIPS ’23) , vol-\\nume 36. Curran Associates.\\n[76] Yang, S.; Nachum, O.; Du, Y .; Wei, J.; Abbeel, P.; and\\nSchuurmans, D. 2023. Foundation Models for Deci-\\nsion Making: Problems, Methods, and Opportunities.\\narXiv:2303.04129.\\n[77] Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.;\\nCao, Y .; and Narasimhan, K. R. 2023. Tree of\\nThoughts: Deliberate Problem Solving with Large\\nLanguage Models. In Advances in Neural Information\\nProcessing Systems (NeurIPS ’23) , volume 36. Curran\\nAssociates.\\n[78] Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.;\\nNarasimhan, K. R.; and Cao, Y . 2023. ReAct: Syner-\\ngizing Reasoning and Acting in Language Models. In\\nProceedings of the Eleventh International Conference\\non Learning Representations , ICLR ’23.\\n[79] Yao, Y .; Li, Z.; and Zhao, H. 2023. Beyond Chain-\\nof-Thought, Effective Graph-of-Thought Reasoning in\\nLarge Language Models. arXiv:2305.16582.\\n[80] Zelikman, E.; Wu, Y .; Mu, J.; and Goodman, N. 2022.\\nSTaR: Bootstrapping Reasoning With Reasoning. In\\nAdvances in Neural Information Processing Systems\\n(NeurIPS ’22) , volume 35, 15476–15488. Curran As-\\nsociates.\\n[81] Zhang, S.; Chen, Z.; Shen, Y .; Ding, M.; Tenenbaum,\\nJ. B.; and Gan, C. 2023. Planning with Large Lan-\\nguage Models for Code Generation. In Proceedings\\nof the Eleventh International Conference on Learning\\nRepresentations , ICLR ’23.\\n[82] Zhang, Z.; Cui, P.; and Zhu, W. 2022. Deep Learning\\non Graphs: A Survey. IEEE Transactions on Knowl-\\nedge and Data Engineering , 34(1): 249–270.\\n[83] Zhou, J.; Cui, G.; Hu, S.; Zhang, Z.; Yang, C.; Liu,\\nZ.; Wang, L.; Li, C.; and Sun, M. 2020. Graph neural\\nnetworks: A review of methods and applications. AI\\nOpen , 1: 57–81.\\n[84] Zhou, Y .; Muresanu, A. I.; Han, Z.; Paster, K.;\\nPitis, S.; Chan, H.; and Ba, J. 2022. Large Lan-\\nguage Models Are Human-Level Prompt Engineers.\\narXiv:2211.01910.\\n[85] Zhu, X.; Wang, J.; Zhang, L.; Zhang, Y .; Huang, Y .;\\nGan, R.; Zhang, J.; and Yang, Y . 2023. Solving Math\\nWord Problems via Cooperative Reasoning inducedLanguage Models. In Proceedings of the 61st Annual\\nMeeting of the Association for Computational Linguis-\\ntics, ACL ’23, 4471–4485. Association for Computa-\\ntional Linguistics.\\n14' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 13}\n",
      "page_content='A Positive Score Evaluation\\nThe following figures plot the same data as Figures 5 and 6\\nrespectively, however use the ”positive score” described in\\nSections 5.1 and 5.2.\\nIOCoT ToTToT2 GoT0481216202428323640444852566064\\n64 elements\\n0.00.30.60.91.21.51.82.12.42.73.03.33.63.94.24.54.8\\nIOCoT ToTToT2 GoT081624324048566472808896104112120128\\n128 elements\\n012345678910111213141516\\nTotal Cost ($); the lower the better\\nIOCoT ToTToT2 GoT161820222426283032#correct elements; the higher the better\\n32 elements\\n0.00.20.40.60.81.01.21.41.6L=2\\nk=20\\nL=3\\nk=10GoT: Figure 4 GoT: Figure 4 GoT: Figure 4\\nL=4\\nk=20L=7\\nk=10L=4\\nk=20\\nL=10\\nk=10\\nFigure 9: Accuracy and cost in sorting tasks with ChatGPT-\\n3.5.Landkindicate the structure of ToT (see Sections 3.2\\nand 6).\\nIOCoT ToTToT2 GoT8101214161820222426283032#correct elements; the higher the better\\n7 6 31 29 4332 elements\\n0.00.20.40.60.81.01.21.41.61.82.02.22.4\\nIOCoT ToTToT2 GoT16202428323640444852566064\\n0 0 0 0 464 elements\\n0.00.20.40.60.81.01.21.41.61.82.02.22.4\\nIOCoT ToTToT2 GoT081624324048566472808896104112120128\\n0 0 0 0 0128 elements\\n0.00.51.01.52.02.53.03.54.04.55.05.56.06.57.07.58.0\\nTotal Cost ($); the lower the betterL=2\\nk=20\\nL=3\\nk=10Samples\\nsolved\\ncorrectly:\\nL=4\\nk=20L=7\\nk=10L=4\\nk=25L=9\\nk=10\\nFigure 10: Accuracy and cost in set intersection with\\nChatGPT-3.5. Landkindicate the structure of ToT (see Sec-\\ntions 3.2 and 6).\\nB Example Prompts - Sorting\\nWe present the prompts only for the sorting of 32-element\\nlists, as those for 64-element and 128-element lists are iden-\\ntical, except for the split prompt where the number of ele-\\nments in the one-shot example matches the problem size.\\nFor sorting, we employ three distinct types of operations\\nthat interact with the LLM, each with its corresponding\\nprompts. First, there is the Generate operation, utilizing the\\nsort prompt to guide the LLM in sorting a provided list of\\nvalues, and the split prompt to direct the LLM to split a spec-\\nified list into a designated number of sublists. Next, the Im-\\nprove operation employs the improve prompt to instruct the\\nLLM to refine a sorted list if it detects mistakes. Finally, the\\nAggregate operation leverages the merge prompt to guide\\nthe LLM in merging two pre-sorted lists into a single sorted\\nlist.\\nFirst, we present the prompt stubs (Table 3), serving as\\ntemplates to dynamically generate appropriate prompts at\\nruntime. For clarity, we display their corresponding few-shot\\nexamples separately in Table 4. Following this, we outlinethe LLM interactions throughout the process of solving the\\nsorting use case (Table 5 - Table 9).\\n15' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 14}\n",
      "page_content='Table 3: Prompt stubs for the sorting tasks; parameters in single curly brackets will be substituted at runtime.\\nsort prompt: <Instruction >Sort the following list of numbers in ascending order. Output only the sorted list of numbers,\\nno additional text. </Instruction >\\n<Examples >See Table 4 </Examples >\\nInput:{input list}\\nsplit prompt (32 elements): <Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first\\nlist should contain the first 16 numbers and the second list the second 16 numbers.\\nOnly output the final 2 lists in the following format without any additional text or thoughts!:\\n{{\\n\"List 1\": [3, 4, 3, 5, 7, 8, 1, ...],\\n\"List 2\": [2, 9, 2, 4, 7, 1, 5, ...]\\n}}\\n</Instruction >\\n<Examples >See Table 4 </Examples >\\nInput:{input list}\\nimprove prompt: <Instruction >The following two lists represent an unsorted list of numbers and a sorted variant of that\\nlist. The sorted variant is not correct. Fix the sorted variant so that it is correct. Make sure that the output list is sorted in\\nascending order, has the same number of elements as the input list ( {length}), and contains the same elements as the input\\nlist.</Instruction >\\n<Approach >\\nTo fix the incorrectly sorted list follow these steps:\\n1. For each number from 0 to 9, compare the frequency of that number in the incorrectly sorted list to the frequency of that\\nnumber in the input list.\\n2. Iterate through the incorrectly sorted list and add or remove numbers as needed to make the frequency of each number in\\nthe incorrectly sorted list match the frequency of that number in the input list.\\n</Approach >\\n<Examples >See Table 4 </Examples >\\nInput:{input list}\\nIncorrectly Sorted: {sorted list}\\nmerge prompt: <Instruction >Merge the following 2 sorted lists of length {length}each, into one sorted list of length\\n{length combined }using a merge sort style approach. Only output the final merged list without any additional text or\\nthoughts!: </Instruction >\\n<Approach >\\nTo merge the two lists in a merge-sort style approach, follow these steps:\\n1. Compare the first element of both lists.\\n2. Append the smaller element to the merged list and move to the next element in the list from which the smaller element\\ncame.\\n3. Repeat steps 1 and 2 until one of the lists is empty.\\n4. Append the remaining elements of the non-empty list to the merged list.\\n</Approach >\\nMerge the following two lists into one sorted list:\\n1.{input list1}\\n2.{input list2}\\nMerged list:\\n16' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 15}\n",
      "page_content='Table 4: Few-shot examples for each prompt used for the sorting tasks; some lists are truncated for brevity.\\nsort prompt:\\n<Examples >\\nInput: [5, 1, 0, 1, 2, 0, 4, 8, 1, 9, 5, 1, 3, 3, 9, 7]\\nOutput: [0, 0, 1, 1, 1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 9, 9]\\nInput: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, . . .(Omitted 14/32 numbers) ]\\nOutput: [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, . . .(Omitted 14/32 numbers) ]\\nInput: [4, 4, 9, 7, 9, 7, 0, 0, 4, 9, 1, 7, 9, 5, 8, 7, 5, 6, . . .(Omitted 46/64 numbers) ]\\nOutput: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, . . .(Omitted 46/64 numbers) ]\\n</Examples >\\nsplit prompt (32 elements):\\n<Examples >\\nInput: [9, 6, 7, 7, 2, 0, 2, 2, 3, 5, 0, 9, 2, 2, 4, 4, 5, 2, . . .(Omitted 14/32 numbers) ]\\nOutput:\\n{{\\n\"List 1\": [9, 6, 7, 7, 2, 0, 2, 2, 3, 5, 0, 9, 2, 2, 4, 4],\\n\"List 2\": [5, 2, 5, 1, 2, 8, 3, 8, 3, 9, 6, 0, 4, 2, 2, 3]\\n}}\\n</Examples >\\nimprove prompt:\\n<Examples >\\nInput: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9]\\nIncorrectly Sorted: [0, 0, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 7, 7, 8, 8, 9, 9, 9, 9]\\nReason: The incorrectly sorted list contains four extra 0s, two extra 4s and three extra 9s and is\\nmissing two 2s.\\nOutput: [0, 1, 2, 2, 2, 2, 3, 3, 4, 5, 5, 7, 7, 8, 8, 9]\\nInput: [6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9, 2, 4, . . .(Omitted 14/32 numbers) ]\\nIncorrectly Sorted: [0, 1, 1, 2, 2, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, . . .(Omitted 14/32 numbers) ]\\nReason: The incorrectly sorted list contains two extra 4s and is missing two 6s and one 9.\\nOutput: [0, 1, 1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, . . .(Omitted 14/32 numbers) ]\\nInput: [4, 4, 9, 7, 9, 7, 0, 0, 4, 9, 1, 7, 9, 5, 8, 7, 5, 6, . . .(Omitted 46/64 numbers) ]\\nIncorrectly Sorted: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, . . .(Omitted 46/64 numbers) ]\\nReason: The incorrectly sorted list contains one extra 8 and is missing two 2s, one 3, three 4s, two\\n5s, one 6, six 7s and one 9.\\nOutput: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, . . .(Omitted 46/64 numbers) ]\\n</Examples >\\nmerge prompt: -\\n17' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 16}\n",
      "page_content='Table 5: Sorting of a 32 element list: Execution plan ( GoO )\\nGoO:\\n1. Split the input list into two sub-lists of equal size (split prompt)\\n2. For each sub-list: Sort the sub-list (sort prompt) five times; score each sort attempt; keep the best\\n3. Merge the sorted sub-lists into one fully sorted list (merge prompt) 10 times; score each merge attempt; keep the best\\n4. Fix any potential mistakes in the sorted list (improve prompt) 10 times; score each improvement attempt; keep the best\\nTable 6: Sorting of a 32 element list: Step 1 (Prompt/Response)\\nStep 1 – Prompt:\\n<Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first list should contain the first 16\\nnumbers and the second list the second 16 numbers.\\nOnly output the final 2 lists in the following format without any additional text or thoughts!:\\n{{\\n\"List 1\": [3, 4, 3, 5, 7, 8, 1, ...],\\n\"List 2\": [2, 9, 2, 4, 7, 1, 5, ...]\\n}}\\n</Instruction >\\n<Examples >See Table 4 </Examples >\\nInput: [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1, 0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\\nStep 1 – Response (Fully Correct):\\n{{\\n\"List 1\": [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1],\\n\"List 1\": [0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\\n}}\\n18' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 17}\n",
      "page_content='Table 7: Sorting of a 32 element list: Step 2 (Prompts/Responses)\\nStep 2a – Prompt:\\n<Instruction >Sort the following list of numbers in ascending order. Output only the sorted list of numbers, no additional\\ntext.</Instruction >\\n<Examples >See Table 4 </Examples >\\nInput: [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1]\\nStep 2a – 5 Responses:\\n1.[0, 0, 1, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (Fully Correct)\\n2.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\\n3.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\\n4.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\\n5.[0, 0, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9] (1 Error - Missing one 1)\\nStep 2b – Prompt:\\n<Instruction >Sort the following list of numbers in ascending order. Output only the sorted list of numbers, no additional\\ntext.</Instruction >\\n<Examples >See Table 4 </Examples >\\nInput: [0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\\nStep 2b – 5 Responses:\\n1.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\\n2.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\\n3.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\\n4.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 8, 9] (Fully Correct)\\n5.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 9] (1 Error - Missing one 6)\\n19' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 18}\n",
      "page_content='Table 8: Sorting of a 32 element list: Step 3 (Prompt/Responses)\\nStep 3 – Prompt:\\n<Instruction >Merge the following 2 sorted lists of length 16 each, into one sorted list of length 32 using a merge sort style\\napproach. Only output the final merged list without any additional text or thoughts!: </Instruction >\\n<Approach >\\nTo merge the two lists in a merge-sort style approach, follow these steps:\\n1. Compare the first element of both lists.\\n2. Append the smaller element to the merged list and move to the next element in the list from which the smaller element\\ncame.\\n3. Repeat steps 1 and 2 until one of the lists is empty.\\n4. Append the remaining elements of the non-empty list to the merged list.\\n</Approach >\\nMerge the following two lists into one sorted list:\\n1.[0, 0, 1, 1, 1, 1, 1, 1, 2, 3, 3, 4, 5, 7, 8, 9]\\n2.[0, 1, 2, 2, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 8, 9]\\nMerged list:\\nStep 3 – 10 Responses:\\n1.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and one 5)\\n2.[0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing two 1s)\\n3.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and got one extra 6)\\n4.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9]\\n(3 Errors - Missing one 1, one 9 and got one extra 6)\\n5.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and got one extra 6)\\n6.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and one 5)\\n7.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and got one extra 6)\\n8.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(1 Error - Missing one 1)\\n9.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(1 Error - Missing one 1)\\n10.[0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n(2 Errors - Missing one 1 and one 5)\\n20' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 19}\n",
      "page_content='Table 9: Sorting of a 32 element list: Step 4 (Prompt/Responses)\\nStep 4 – Prompt:\\n<Instruction >The following two lists represent an unsorted list of numbers and a sorted variant of that list. The sorted\\nvariant is not correct. Fix the sorted variant so that it is correct. Make sure that the output list is sorted in ascending order,\\nhas the same number of elements as the input list (32), and contains the same elements as the input list. </Instruction >\\n<Approach >\\nTo fix the incorrectly sorted list follow these steps:\\n1. For each number from 0 to 9, compare the frequency of that number in the incorrectly sorted list to the frequency of that\\nnumber in the input list.\\n2. Iterate through the incorrectly sorted list and add or remove numbers as needed to make the frequency of each number in\\nthe incorrectly sorted list match the frequency of that number in the input list.\\n</Approach >\\n<Examples >See Table 4 </Examples >\\nInput: [8, 7, 1, 1, 1, 1, 3, 3, 0, 9, 4, 1, 0, 2, 5, 1, 0, 5, 6, 7, 1, 4, 5, 9, 4, 6, 2, 5, 8, 6, 2, 6]\\nIncorrectly Sorted: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8,\\n8, 9, 9]\\nStep 4 – 10 Responses:\\n1. Reason: The incorrectly sorted list is missing two 0s, one 3, one 4, one 6 and one\\n9. The incorrectly sorted list also contains one extra 1, one extra 2, and one extra 5.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 5, 5, 5,\\n6, 6, 6, 6, 7, 7, 8, 8, 9, 9] 4 Errors - Missing one 1, two 4s and one 5\\nNote: The output list has the same number of elements as the input list, is sorted in ascending order, and con-\\ntains the same elements as the input list.\\n2.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7,\\n8, 8, 9, 9] 1 Error - One extra 6\\n3.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6,\\n7, 7, 7, 8, 8, 8, 9, 9, 9] 6 Errors - One extra 2, 5, 6, 7, 8 and 9\\n4. Reason: The incorrectly sorted list is missing two 9s and one 0.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7,\\n7, 8, 8, 9, 9, 9, 9] 3 Errors - Missing one 1 and has two extra 9s\\n5. Reason: The incorrectly sorted list is missing one 0, one 3, one 4, four 6s, and one 9.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\\n6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 9] 10 Errors - Missing one 1, 2, has four extra 6s, one extra 7, 8 and two extra 9s\\n6.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6,\\n7, 7, 7, 7, 8, 8, 8, 9, 9, 9, 9] 8 Errors - Has one extra 2, 3, 6, two extra 7s, one extra 8 and two extra 9s\\n7.Output: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8,\\n8, 9, 9] 2 Errors - Missing one 1 and has one extra 4\\n8. Reason: The incorrectly sorted list is missing three 0s, two 3s, two 4s, one 5, two 6s, and one 9.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6,\\n6, 7, 7, 8, 8, 9] 5 Errors - Missing one 1, 9, has one extra 3 and two extra 6s\\n9. Reason: The incorrectly sorted list is missing one 0, three 2s, two 3s, two 4s, three 5s, two 6s, one 7, and one 9.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 5, 6,\\n6, 6, 6, 6, 7, 8, 8, 9, 9] 8 Errors - Missing one 1, one 7, has two extra 2s, two extra 3s, one extra 5 and 6\\n10.Reason: The incorrectly sorted list is missing three 1s, one 3, one 4, two 5s, one 6, one 7, one 8, and one 9.\\nOutput: [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7,\\n7, 8, 8, 9, 9] (Fully Correct)\\nFinal Result (Correctly Sorted):\\n[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9]\\n21' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 20}\n",
      "page_content='C Example Prompts - Set Intersection\\nWe present the prompts only for the intersection of two 32-\\nelement sets, as those for 64-element and 128-element sets\\nare identical, except for the split prompt where the size of\\nthe split is adjusted proportionally.\\nFor set intersection, we employ two distinct types of op-\\nerations that interact with the LLM, each with its corre-\\nsponding prompts. First, there is the Generate operation,\\nutilizing the intersect prompt to guide the LLM in inter-\\nsecting two input sets, and the split prompt to direct the\\nLLM to split a specified set into a designated number of dis-\\ntinct subsets. Second, the Aggregate operation leverages the\\nmerge prompt to guide the LLM in combining two sets into\\none.\\nFirst, we present the prompt stubs (Table 10), serving as\\ntemplates to dynamically generate appropriate prompts at\\nruntime. For clarity, we display their corresponding few-shot\\nexamples separately in Table 11. Following this, we outline\\nthe LLM interactions throughout a complete set intersection\\nprocess (Table 12 - Table 15).\\n22' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 21}\n",
      "page_content='Table 10: Prompt stubs for the set intersection tasks; parameters in single curly brackets will be substituted at runtime.\\nintersect prompt: <Instruction >Find the intersection of two sets of numbers. Output only the set of numbers that are\\npresent in both sets, no additional text. </Instruction >\\n<Examples >See Table 11 </Examples >\\nInput Set 1: {set1}\\nInput Set 2: {set2}\\nsplit prompt (32 elements): <Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first\\nlist should contain the first 16 numbers and the second list the second 16 numbers.\\nOnly output the 2 lists in the following format without any additional text or thoughts!\\n{{\\n\"List 1\": [13, 16, 30, 6, 21, 7, 31, ...],\\n\"List 2\": [25, 24, 10, 4, 27, 0, 14, ...]\\n}}\\n</Instruction >\\n<Examples >See Table 11 </Examples >\\nInput:{input}\\nmerge prompt: <Instruction >Merge the following 2 lists into one list by appending the second list to the first list.\\nOnly output the final list without any additional text or thoughts! </Instruction >\\nList 1: {input1}\\nList 2: {input2}\\n23' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 22}\n",
      "page_content='Table 11: Few-shot examples for each prompt used for the set intersection tasks; some lists are truncated for brevity.\\nintersect prompt:\\n<Examples >\\nInput Set 1: [13, 16, 30, 6, 21, 7, 31, 15, 11, 1, 24, 10, 9, 3, 20, 8]\\nInput Set 2: [25, 24, 10, 4, 27, 0, 14, 12, 8, 2, 29, 20, 17, 19, 26, 23]\\nOutput: [24, 10, 20, 8]\\nInput Set 1: [26, 40, 42, 57, 15, 31, 5, 32, 11, 4, 24, 28, 51, 54, . . .(Omitted 18/32 numbers) ]\\nInput Set 2: [16, 60, 36, 48, 0, 15, 5, 19, 46, 24, 1, 6, 61, 10, . . .(Omitted 18/32 numbers) ]\\nOutput: [40, 15, 5, 24, 35, 59, 16, 63]\\nInput Set 1: [115, 61, 35, 103, 90, 117, 86, 44, 63, 45, 40, 30, 74, 33, . . .(Omitted 50/64 numbers) ]\\nInput Set 2: [13, 35, 20, 96, 34, 18, 47, 127, 126, 9, 21, 16, 77, 22, . . .(Omitted 50/64 numbers) ]\\nOutput: [115, 35, 90, 117, 63, 40, 30, 33, 15, 89, 50, 12, 2, 84, 7, 57, 96]\\n</Examples >\\nsplit prompt (32 elements):\\n<Examples >\\nInput: [26, 40, 42, 57, 15, 31, 5, 32, 11, 4, 24, 28, 51, 54, . . .(Omitted 18/32 numbers) ]\\nOutput:\\n{{\\n\"List 1\": [26, 40, 42, 57, 15, 31, 5, 32, 11, 4, 24, 28, 51, 54, 12, 22],\\n\"List 2\": [33, 35, 7, 13, 2, 59, 8, 23, 43, 16, 29, 55, 25, 63, 21, 18]\\n}}\\n</Examples >\\nmerge prompt: -\\nTable 12: Intersection of two 32-element sets: Execution plan ( GoO )\\nGoO:\\n1. Split the second input set into two sub-sets of equal size (split prompt)\\n2. For each sub-set: Intersect the sub-set with the first input set (intersect prompt) five times; score each sort attempt; keep\\nthe best\\n3. Merge the resulting intersections into one full intersection set (merge prompt) 10 times; score each merge attempt; keep\\nthe best\\n24' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 23}\n",
      "page_content='Table 13: Intersection of two 32-element sets: Step 1 (Prompt/Response)\\nStep 1 – Prompt:\\n<Instruction >Split the following list of 32 numbers into 2 lists of 16 numbers each, the first list should contain the first 16\\nnumbers and the second list the second 16 numbers.\\nOnly output the 2 lists in the following format without any additional text or thoughts!\\n{{\\n\"List 1\": [13, 16, 30, 6, 21, 7, 31, ...],\\n\"List 2\": [25, 24, 10, 4, 27, 0, 14, ...]\\n}}\\n</Instruction >\\n<Examples >See Table 11 </Examples >\\nInput: [31, 11, 4, 63, 38, 58, 59, 24, 61, 14, 32, 39, 27, 46, 48, 19, 52, 57, 50, 56, 3, 2, 53, 29,\\n5, 37, 62, 41, 36, 12, 49, 16]\\nStep 1 – Response (Fully Correct):\\n{{\\n\"List 1\": [31, 11, 4, 63, 38, 58, 59, 24, 61, 14, 32, 39, 27, 46, 48, 19],\\n\"List 1\": [52, 57, 50, 56, 3, 2, 53, 29, 5, 37, 62, 41, 36, 12, 49, 16]\\n}}\\n25' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 24}\n",
      "page_content='Table 14: Intersection of two 32-element sets: Step 2 (Prompts/Responses)\\nStep 2a – Prompt:\\n<Instruction >Find the intersection of two sets of numbers. Output only the set of numbers that are present in both sets, no\\nadditional text. </Instruction >\\n<Examples >See Table 11 </Examples >\\nInput Set 1: [11, 60, 1, 49, 21, 33, 14, 56, 54, 15, 23, 40, 45, 22, 7, 28, 20, 46, 51, 6, 34, 37, 3,\\n50, 17, 8, 25, 0, 35, 47, 18, 19]\\nInput Set 2: [31, 11, 4, 63, 38, 58, 59, 24, 61, 14, 32, 39, 27, 46, 48, 19]\\nStep 2a – 5 Responses:\\n1.[11, 14, 46, 14, 19] (1 Error - Duplicated 14)\\n2.Output: [11, 14, 46, 19] (Fully Correct)\\n3.[11, 14, 46, 14, 19] (1 Error - Duplicated 14)\\n4.[11, 14, 46, 19] (Fully Correct)\\n5.[11, 14, 46, 14, 19] (1 Error - Duplicated 14)\\nStep 2b – Prompt:\\n<Instruction >Find the intersection of two sets of numbers. Output only the set of numbers that are present in both sets, no\\nadditional text. </Instruction >\\n<Examples >See Table 11 </Examples >\\nInput Set 1: [11, 60, 1, 49, 21, 33, 14, 56, 54, 15, 23, 40, 45, 22, 7, 28, 20, 46, 51, 6, 34, 37, 3,\\n50, 17, 8, 25, 0, 35, 47, 18, 19]\\nInput Set 2: [52, 57, 50, 56, 3, 2, 53, 29, 5, 37, 62, 41, 36, 12, 49, 16]\\nStep 2b – 5 Responses:\\n1.[50, 56, 49] (2 Errors - Missing 3 and 37)\\n2.[50, 56, 37, 49] (1 Error - Missing 3)\\n3.[56, 49, 37, 3, 50] (Fully Correct)\\n4.[50, 56, 37, 49] (1 Error - Missing 3)\\n5.[50, 56, 37, 49] (1 Error - Missing 3)\\n26' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 25}\n",
      "page_content='Table 15: Intersection of two 32-element sets: Step 3 (Prompt/Responses)\\nStep 3 – Prompt:\\n<Instruction >Merge the following 2 lists into one list by appending the second list to the first list.\\nOnly output the final list without any additional text or thoughts! </Instruction >\\nList 1: [11, 14, 46, 19]\\nList 2: [56, 49, 37, 3, 50]\\nStep 3 – 10 Responses:\\n1.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n2.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n3.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n4.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n5.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n6.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n7.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n8.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n9.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\n10.[11, 14, 46, 19, 56, 49, 37, 3, 50] (Fully Correct)\\nFinal Result (Correct Intersection):\\n[11, 14, 46, 19, 56, 49, 37, 3, 50]\\n27' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 26}\n",
      "page_content='D Example Prompts - Keyword Counting\\nWe present the prompts only for GoT4 of the keyword count-\\ning task, as those used for GoT8 andGoTx are identical, ex-\\ncept for minor differences in the split prompt where the size\\nof the split is adjusted.\\nFor keyword counting, we employ three distinct types of\\noperations that interact with the LLM, each with its corre-\\nsponding prompts. First, there is the Generate operation,\\nutilizing the count prompt to guide the LLM in counting the\\nkeywords in a text, and the split prompt to direct the LLM\\nto split a given text into a number of passages. Next, the Ag-\\ngregate operation leverages the merge prompt to guide the\\nLLM in merging two dictionaries of counted keywords into\\none. Finally, the ValidateAndImprove operation employs\\ntheimprove merge prompt to instruct the LLM to correct\\nmistakes that were made in a previous Aggregate operation.\\nWe present the prompt stubs (Table 16 - Table 17), serving\\nas templates to dynamically generate appropriate prompts at\\nruntime. For clarity, we display their corresponding few-shot\\nexamples separately in Table 18 and Table 19. Following\\nthis, we outline the LLM interactions throughout a complete\\nkeyword counting process (Table 20 - Table 28).\\n28' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 27}\n",
      "page_content='Table 16: Prompt stubs for the keyword counting task; parameters in single curly brackets will be substituted at runtime.\\ncount prompt: <Instruction >Count the frequency of how many times each country is explicitly named in the input text.\\nYou can generate any intermedate lists and states, but the final output should only contain the frequency of each country that\\nappears at least once in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each\\ncountry in the output as in the input text):\\n{{\\n\"country1\": frequency1,\\n\"country2\": frequency2,\\n. . .\\n}}\\n</Instruction >\\n<Approach >\\nTo count the frequency for each country follow these steps:\\n1. Split the input passage into four paragraphs of similar length.\\n2. Count the frequency of each country in each paragraph.\\n3. Combine the frequencies of each country from each paragraph by adding them together.\\n</Approach >\\n<Examples >See Table 18 </Examples >\\nInput:{input text}\\nsplit prompt: <Instruction >Split the following input text into 4 paragraphs of approximately same length.\\nOnly output the final 4 paragraphs in the following format without any additional text or thoughts:\\n{{\\n\"Paragraph 1\": \"Some paragraph text . . .\",\\n\"Paragraph 2\": \"Some paragraph text . . .\",\\n\"Paragraph 3\": \"Some paragraph text . . .\",\\n\"Paragraph 4\": \"Some paragraph text . . .\"\\n}}\\n</Instruction >\\n<Example >See Table 19 </Example >\\nInput:{input text}\\n29' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 28}\n",
      "page_content='Table 17: Prompt stubs for the keyword counting task continued ; parameters in single curly brackets will be substituted at\\nruntime.\\nmerge prompt: <Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text,\\ninto a single dictionary. Simply add the frequencies together for each country and if a country is not present in one of the\\ndictionaries, add it to the final dictionary with the frequency from the other dictionary.\\nOnly output the final merged dictionary without any additional text or thoughts! </Instruction >\\n<Approach >\\nTo combine the 2 dictionaries into single one, follow these steps:\\n1. Create a new dictionary to store the combined frequencies.\\n2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\\n3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\\nalready present, add the frequency to the existing value.\\n</Approach >\\nCombine the following 2 dictionaries into a single dictionary:\\n{dictionary 1}\\n{dictionary 2}\\nCombined Output:\\nimprove merge prompt: <Instruction >The following 2 dictionaries were combined into the third dictionary below. How-\\never, some mistakes occured and the third dictionary is incorrect. Please fix the third dictionary so that it contains the correct\\nfrequencies for each country. The correct frequencies are the sum of the frequencies from the first 2 dictionaries. If a country\\nis not present in one of the dictionaries, add it to the final dictionary with the frequency from the other dictionary.\\n</Instruction >\\n<Example >See Table 19 </Example >\\nDictionary 1: {dictionary 1}\\nDictionary 2: {dictionary 2}\\nIncorrectly Combined Dictionary: {dictionary incorrect }\\nOutput:\\n30' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 29}\n",
      "page_content='Table 18: Few-shot examples for count prompt used for the keyword counting task; some paragraphs and dictionaries are\\ntruncated and formatting is slightly adjusted for brevity.\\ncount prompt:\\n<Examples >\\nInput: Alexandra boarded the first flight of her grand journey, starting from Canada. With a globe-trotting ... (Omitted)\\nParagraphs:\\nAlexandra boarded the first flight of her grand journey, starting from Canada. With a globe-trotting itinerary ... (Omitted)\\nHer first stop was Mexico, where she marveled at the Mayan ruins. From there, she explored the rainforests ... (Omitted)\\nSublist frequencies:\\n{{\"Canada\": 1 }}\\n{{\"Mexico\": 1, \"Brazil\": 1, \"Argentina\": 1 }}\\nOutput: {{\"Canada\": 1, \"Mexico\": 1, \"Brazil\": 1, \"Argentina\": 1 }}\\nInput: The adventure led him to the peaks of Peru where he trekked to see the mysteries of Machu Picchu ... (Omitted)\\nParagraphs:\\nThe adventure led him to the peaks of Peru where he trekked to see the mysteries of Machu Picchu. He then ... (Omitted)\\nA quick detour to Uruguay and Paraguay allowed him to experience the vibrancy of the local cultures before ... (Omitted)\\nSublists:\\n{{\"Peru\": 1, \"Chile\": 1 }}\\n{{\"Uruguay\": 1, \"Paraguay\": 1, \"Canada\": 1, \"Peru\": 1, \"Brazil\": 1, \"Mexico\": 1 }}\\nOutput: {{\"Peru\": 2, \"Chile\": 1, \"Uruguay\": 1, \"Paraguay\": 1, \"Canada\": 1, \"Brazil\": 1, \"Mexico\": 1 }}\\nInput: Journeying westward, she admired the art in Italy and sipped coffee in France. The music of ... (Omitted)\\nParagraphs:\\nJourneying westward, she admired the art in Italy and sipped coffee in France.\\nThe music of Spain and the history of Greece deepened her love for Europe. The Nordic beauty of Norway, ... (Omitted)\\nShe danced in Ireland, explored castles in Scotland, and marveled at the architecture in Germany and Russia.\\nItaly, Norway, Sweden and Germany will always stay her favourite destinations to visit.\\nSublists:\\n{{\"Italy\": 1, \"France\": 1 }}\\n{{\"Spain\": 1, \"Greece\": 1, \"Norway\": 1, \"Sweden\": 1, \"Finland\": 1, \"Denmark\": 1 }}\\n{{\"Ireland\": 1, \"Scotland\": 1, \"Germany\": 1, \"Russia\": 1 }}\\n{{\"Italy\": 1, \"Norway\": 1, \"Sweden\": 1, \"Germany\": 1 }}\\nOutput: {{\"Italy\": 2, \"France\": 1, \"Spain\": 1, \"Greece\": 1, \"Norway\": 2, \"Sweden\": 2, . . .(Omitted) }}\\n</Examples >\\n31' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 30}\n",
      "page_content='Table 19: Few-shot examples for split,merge andimprove merge prompts used for the keyword counting task; some para-\\ngraphs and dictionaries are truncated and formatting is slightly adjusted for brevity.\\nsplit prompt:\\n<Examples >\\nInput: Journeying westward, she admired the art in Italy and sipped coffee in France. The music of Spain and the history of\\nGreece deepened her love for Europe. The Nordic beauty of Norway, Sweden, Finland, and Denmark took her breath away.\\nShe danced in Ireland, explored castles in Scotland, and marveled at the architecture in Germany and Russia. Italy, Norway,\\nSweden and Germany will always stay her favourite destinations to visit.\\nOutput:\\n{{\\n\"Paragraph 1\": \"Journeying westward, she admired the art in Italy and sipped coffee in France. \",\\n\"Paragraph 2\": \"The music of Spain and the history of Greece deepened her love for . . .(Omitted)”,\\n\"Paragraph 3\": \"She danced in Ireland, explored castles in Scotland, and marveled . . .(Omitted)”,\\n\"Paragraph 4\": \"Italy, Norway, Sweden and Germany will always stay her favourite . . .(Omitted)”\\n}}\\n</Examples >\\nmerge prompt: -\\nimprove merge prompt:\\n<Example >\\nDictionary 1: {{\"Peru\": 2, \"Chile\": 1, \"Uruguay\": 1, \"Paraguay\": 1 }}\\nDictionary 2: {{\"Peru\": 1, \"Argentina\": 1, \"Canada\": 1, \"Chile\": 3, \"Germany\": 2 }}\\nIncorrectly Combined Dictionary:\\n{{\"Peru\": 3, \"Chile\": 2, \"Uruguay\": 1, \"Paraguay\": 1, \"Argentina\": 1, \"Chile\": 3, \"Germany\": 2 }}\\nOutput:\\n{{\"Peru\": 3, \"Chile\": 4, \"Uruguay\": 1, \"Paraguay\": 1, \"Argentina\": 1, \"Canada\": 1, \"Germany\": 2 }}\\n</Example >\\nTable 20: Keyword counting for an example 4-passage split (GoT4): Execution plan ( GoO )\\nGoO:\\n1. Split the input text into four paragraphs of roughly equal size (split prompt)\\n2. For each paragraph: Count the occurrences of individual countries (count prompt) 10 times; score each counting attempt;\\nkeep the best\\n3. Merge the country counts into one dictionary (merge prompt) 3 times; validate and improve invalid merge attempts\\n(improve merge prompt) up to 3 attempts each; score; keep the best\\n32' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 31}\n",
      "page_content='Table 21: Keyword counting for an example 4-passage split (GoT4): Step 1 (Prompt/Response)\\nStep 1 – Prompt:\\n<Instruction >Split the following input text into 4 paragraphs of approximately same length.\\nOnly output the final 4 paragraphs in the following format without any additional text or thoughts:\\n{{\\n\"Paragraph 1\": \"Some paragraph text . . .\",\\n\"Paragraph 2\": \"Some paragraph text . . .\",\\n\"Paragraph 3\": \"Some paragraph text . . .\",\\n\"Paragraph 4\": \"Some paragraph text . . .\"\\n}}\\n</Instruction >\\n<Example >See Table 19 </Example >\\nInput: My friend, Alex from Peru , once recounted his journey to Argentina where he learned about the strong cultural ties\\nbetween Argentina and Brazil due to their shared history. He spoke fondly of his time in Argentina and Brazil, marveling at\\nthe similar music, dance, and culinary traditions that seamlessly bridged the borders of these countries. It reminded me\\nof a documentary I’d watched about the ancient Silk Road that spanned across Iran and China. It touched upon the shared\\nhistorical narratives of Iran and China, highlighting how goods, ideas, and culture flowed between these two countries for\\ncenturies. Intriguingly, the documentary also brought up some parallels between this eastern route and the vibrant exchange\\nbetween Italy and France during the Renaissance. The cultural and intellectual bonds between Italy and France were indeed\\nprofound, just as the resilient trade relations that existed between the United States and Canada. The United States\\nand Canada, apart from their geographical proximity, shared an economic bond that strongly influenced their policies\\nand international standing. Similarly, the ties between Australia and New Zealand shed light on their gestalt identity in the\\nPacific region. Despite their unique characteristics, Australia and New Zealand were often viewed as a single entity due to\\ntheir remarkably similar backgrounds in terms of culture, language, and colonial history. Inspired by these chronicles of\\ninterconnectedness, I decided to delve deeper into history and found a fascinating account of how Ukraine and Poland had\\ninfluenced each other through years of coexistence. Despite their tumultuous past , Ukraine and Poland shared a cultural\\ntapestry that was deeply woven into their histories. It was quite similar to the complex relationship between North Korea\\nand South Korea, which, despite their political differences, shared common heritage and traditions. Thus, from Argentina to\\nSouth Korea, the world was an intricate web of countries intertwined with each other through shared histories, cultures, and\\nsometimes, shared destinies.\\nStep 1 – Response (Fully Correct):\\n{{\\n\"Paragraph 1\": \"My friend, Alex from Peru ... (Omitted) ... bridged the borders of these countries.\",\\n\"Paragraph 2\": \"It reminded me of a ... (Omitted) ... between the United States and Canada.\",\\n\"Paragraph 3\": \"The United States and Canada, apart ... (Omitted) ... through years of coexistence.\",\\n\"Paragraph 4\": \"Despite their tumultuous past ... (Omitted) ... and sometimes, shared destinies.\"\\n}}\\n33' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 32}\n",
      "page_content='Table 22: Keyword counting for an example 4-passage split (GoT4): Step 2a (Prompt/Responses)\\nStep 2a – Prompt:\\n<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\\nany intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\\nonce in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\\noutput as in the input text):\\n{{\\n\"country1\": frequency1,\\n\"country2\": frequency2,\\n. . .\\n}}\\n</Instruction >\\n<Approach >\\nTo count the frequency for each country follow these steps:\\n1. Split the input passage into four paragraphs of similar length.\\n2. Count the frequency of each country in each paragraph.\\n3. Combine the frequencies of each country from each paragraph by adding them together.\\n</Approach >\\n<Examples >See Table 18 </Examples >\\nInput: My friend, Alex from Peru, once recounted his journey to Argentina where he learned about the strong cultural ties\\nbetween Argentina and Brazil due to their shared history. He spoke fondly of his time in Argentina and Brazil, marveling at\\nthe similar music, dance, and culinary traditions that seamlessly bridged the borders of these countries.\\nStep 2a – 10 Responses:\\n1.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n2.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\\n3.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\\n4.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n5.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\\n6.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}(1 Error - Missing one ”Argentina”)\\n7.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n8.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n9.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n10.{{\"Peru\": 1, \"Argentina\": 1, \"Brazil\": 1 }}(3 Errors - Missing two ”Argentina” and one ”Brazil”)\\n34' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 33}\n",
      "page_content='Table 23: Keyword counting for an example 4-passage split (GoT4): Step 2b (Prompt/Responses)\\nStep 2b – Prompt:\\n<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\\nany intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\\nonce in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\\noutput as in the input text):\\n{{\\n\"country1\": frequency1,\\n\"country2\": frequency2,\\n. . .\\n}}\\n</Instruction >\\n<Approach >\\nTo count the frequency for each country follow these steps:\\n1. Split the input passage into four paragraphs of similar length.\\n2. Count the frequency of each country in each paragraph.\\n3. Combine the frequencies of each country from each paragraph by adding them together.\\n</Approach >\\n<Examples >See Table 18 </Examples >\\nInput: It reminded me of a documentary I’d watched about the ancient Silk Road that spanned across Iran and China. It\\ntouched upon the shared historical narratives of Iran and China, highlighting how goods, ideas, and culture flowed between\\nthese two countries for centuries. Intriguingly, the documentary also brought up some parallels between this eastern route\\nand the vibrant exchange between Italy and France during the Renaissance. The cultural and intellectual bonds between Italy\\nand France were indeed profound, just as the resilient trade relations that existed between the United States and Canada.\\nStep 2b – 10 Responses:\\n1.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n2.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n3.{{\"Iran\": 3, \"China\": 2, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(3 Errors - Surplus of one ”Iran”, missing one ”Italy” and one ”France”)\\n4.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n5.{{\"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(2 Errors - Missing one ”Italy” and one ”France”)\\n6.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n7.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n8.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n9.{{\"Iran\": 1, \"China\": 1, \"Italy\": 1, \"France\": 1, \"United States\": 1, \"Canada\": 1 }}\\n(4 Errors - Missing one ”Iran”, one ”China”, one ”Italy” and one ”France”)\\n10.{{\"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United States\": 1, \"Canada\": 1 }}\\n(1 Error - Missing one ”Italy”)\\n35' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 34}\n",
      "page_content='Table 24: Keyword counting for an example 4-passage split (GoT4): Step 2c (Prompt/Responses)\\nStep 2c – Prompt:\\n<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\\nany intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\\nonce in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\\noutput as in the input text):\\n{{\\n\"country1\": frequency1,\\n\"country2\": frequency2,\\n. . .\\n}}\\n</Instruction >\\n<Approach >\\nTo count the frequency for each country follow these steps:\\n1. Split the input passage into four paragraphs of similar length.\\n2. Count the frequency of each country in each paragraph.\\n3. Combine the frequencies of each country from each paragraph by adding them together.\\n</Approach >\\n<Examples >See Table 18 </Examples >\\nInput: The United States and Canada, apart from their geographical proximity, shared an economic bond that strongly\\ninfluenced their policies and international standing. Similarly, the ties between Australia and New Zealand shed light on\\ntheir gestalt identity in the Pacific region. Despite their unique characteristics, Australia and New Zealand were often viewed\\nas a single entity due to their remarkably similar backgrounds in terms of culture, language, and colonial history. Inspired\\nby these chronicles of interconnectedness, I decided to delve deeper into history and found a fascinating account of how\\nUkraine and Poland had influenced each other through years of coexistence.\\nStep 2c – 10 Responses:\\n1.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n2.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n3.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Australia and New Zealand\":\\n1, \"Ukraine\": 1, \"Poland\": 1 }}\\n(3 Errors - Missing one ”Australia, one ”New Zealand” and surplus of one ”Australia and New Zealand”)\\n4.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n5.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Australia and New Zealand\":\\n1, \"Ukraine\": 1, \"Poland\": 1 }}\\n(3 Errors - Missing one ”Australia, one ”New Zealand” and surplus of one ”Australia and New Zealand”)\\n6.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Ukraine\": 1, \"Poland\": 1 }}\\n(2 Errors - Missing one ”Australia” and one ”New Zealand”)\\n7.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n8.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 1, \"New Zealand\": 1, \"Ukraine\": 1, \"Poland\": 1 }}\\n(2 Errors - Missing one ”Australia” and one ”New Zealand”)\\n9.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n10.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n(Fully Correct)\\n36' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 35}\n",
      "page_content='Table 25: Keyword counting for an example 4-passage split (GoT4): Step 2d (Prompt/Responses)\\nStep 2d – Prompt:\\n<Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can generate\\nany intermedate lists and states, but the final output should only contain the frequency of each country that appears at least\\nonce in the following json format, prefixed with ”Output: ” (make sure to keep the same spelling for each country in the\\noutput as in the input text):\\n{{\\n\"country1\": frequency1,\\n\"country2\": frequency2,\\n. . .\\n}}\\n</Instruction >\\n<Approach >\\nTo count the frequency for each country follow these steps:\\n1. Split the input passage into four paragraphs of similar length.\\n2. Count the frequency of each country in each paragraph.\\n3. Combine the frequencies of each country from each paragraph by adding them together.\\n</Approach >\\n<Examples >See Table 18 </Examples >\\nInput: Despite their tumultuous past, Ukraine and Poland shared a cultural tapestry that was deeply woven into their histo-\\nries. It was quite similar to the complex relationship between North Korea and South Korea, which, despite their political\\ndifferences, shared common heritage and traditions. Thus, from Argentina to South Korea, the world was an intricate web of\\ncountries intertwined with each other through shared histories, cultures, and sometimes, shared destinies.\\nStep 2d – 10 Responses:\\n1.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n2.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n3.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n4.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n5.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n6.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n7.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n8.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n9.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n10.{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Fully Correct)\\n37' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 36}\n",
      "page_content='Table 26: Keyword counting for an example 4-passage split (GoT4): Step 3a (Prompt/Responses)\\nStep 3a – Prompt:\\n<Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text, into a single\\ndictionary. Simply add the frequencies together for each country and if a country is not present in one of the dictionaries,\\nadd it to the final dictionary with the frequency from the other dictionary.\\nOnly output the final merged dictionary without any additional text or thoughts! </Instruction >\\n<Approach >\\nTo combine the 2 dictionaries into single one, follow these steps:\\n1. Create a new dictionary to store the combined frequencies.\\n2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\\n3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\\nalready present, add the frequency to the existing value.\\n</Approach >\\nCombine the following 2 dictionaries into a single dictionary:\\n{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2 }}\\n{{\"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United States\": 1, \"Canada\": 1 }}\\nCombined Output:\\nStep 3a – 3 Responses:\\n1.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 1, \"Canada\": 1 }}(Valid - No Improvement) (2 Errors - from counting)\\n2.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 1, \"Canada\": 1 }}(Valid - No Improvement) (2 Errors - from counting)\\n3.{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 1, \"Canada\": 1 }}(Valid - No Improvement) (2 Errors - from counting)\\n38' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 37}\n",
      "page_content='Table 27: Keyword counting for an example 4-passage split (GoT4): Step 3b (Prompt/Responses)\\nStep 3b – Prompt:\\n<Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text, into a single\\ndictionary. Simply add the frequencies together for each country and if a country is not present in one of the dictionaries,\\nadd it to the final dictionary with the frequency from the other dictionary.\\nOnly output the final merged dictionary without any additional text or thoughts! </Instruction >\\n<Approach >\\nTo combine the 2 dictionaries into single one, follow these steps:\\n1. Create a new dictionary to store the combined frequencies.\\n2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\\n3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\\nalready present, add the frequency to the existing value.\\n</Approach >\\nCombine the following 2 dictionaries into a single dictionary:\\n{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 1, \"Poland\": 1 }}\\n{{\"Ukraine\": 1, \"Poland\": 1, \"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}\\nCombined Output:\\nStep 3b – 3 Responses:\\n1.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\\n\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Valid - No Improvement) (Fully Correct)\\n2.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\\n\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Valid - No Improvement) (Fully Correct)\\n3.{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\\n\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}(Valid - No Improvement) (Fully Correct)\\n39' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 38}\n",
      "page_content='Table 28: Keyword counting for an example 4-passage split (GoT4): Step 3c (Prompt/Responses)\\nStep 3c – Prompt:\\n<Instruction >Combine the following 2 dictionaries, each containing the frequency of countries in a text, into a single\\ndictionary. Simply add the frequencies together for each country and if a country is not present in one of the dictionaries,\\nadd it to the final dictionary with the frequency from the other dictionary.\\nOnly output the final merged dictionary without any additional text or thoughts! </Instruction >\\n<Approach >\\nTo combine the 2 dictionaries into single one, follow these steps:\\n1. Create a new dictionary to store the combined frequencies.\\n2. Iterate through the keys of the first dictionary and add the frequency of each country to the new dictionary.\\n3. Iterate through the keys of the second dictionary and add the frequency of each country to the new dictionary and if it is\\nalready present, add the frequency to the existing value.\\n</Approach >\\nCombine the following 2 dictionaries into a single dictionary:\\n{{\"Peru\": 1, \"Argentina\": 2, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 1, \"Canada\": 1 }}\\n{{\"United States\": 1, \"Canada\": 1, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2,\\n\"North Korea\": 1, \"South Korea\": 2, \"Argentina\": 1 }}\\nCombined Output:\\nStep 3c – 3 Responses:\\n1.{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North\\nKorea\": 1, \"South Korea\": 2 }}(Valid - No Improvement) (2 Errors - from counting)\\n2.{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North\\nKorea\": 1, \"South Korea\": 2 }}(Valid - No Improvement) (2 Errors - from counting)\\n3.{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North\\nKorea\": 1, \"South Korea\": 2 }}(Valid - No Improvement) (2 Errors - from counting)\\nFinal Result (2 Errors):\\n{{\"Peru\": 1, \"Argentina\": 3, \"Brazil\": 2, \"Iran\": 2, \"China\": 2, \"Italy\": 1, \"France\": 2, \"United\\nStates\": 2, \"Canada\": 2, \"Australia\": 2, \"New Zealand\": 2, \"Ukraine\": 2, \"Poland\": 2, \"North Korea\":\\n1, \"South Korea\": 2 }}\\n40' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 39}\n",
      "page_content='E Example Prompts - Document Merging\\nWe present the prompts only for GoTof the document merg-\\ning task, as GoT2 only differs in the fact that it merges the\\n4 NDAs in 2 steps rather than 1. For document merging, we\\nemploy four distinct types of operations that interact with the\\nLLM, each with its corresponding prompts. First, there is the\\nGenerate operation, utilizing the merge prompt to instruct\\nthe LLM to merge the 4 NDAs into 1. Second, the Score\\noperations instructs the LLM to score a given merged NDA\\nusing the score prompt . Next, the Aggregate operation em-\\nploys the aggregate prompt to instruct the LLM to aggregate\\nmultiple merge attempts into a single, better one. Finally, the\\nImprove operation leverages the improve prompt to instruct\\nthe LLM to improve a merged NDA.\\nFirst, we present the prompt stubs (Table 29 - Table 30),\\nserving as templates to dynamically generate appropriate\\nprompts at runtime. Following this, we outline the LLM in-\\nteractions throughout a complete merging process (Table 31\\n- Table 49). However, instead of displaying each input/gen-\\nerated NDA in every prompt/response, we present the 4 in-\\nput NDAs in Table 31 - Table 33 and the final merged NDA\\nin Table 49. Furthermore, as scoring is done using the LLM\\nas well, we will present these interactions for the best per-\\nforming merged NDAs (Tables 39 - 40 and Tables 47 - 48).\\nLastly, most responses are limited to a few lines only, as\\nthey don’t offer any further insights and would otherwise\\nspan multiple pages. However, we refer the interested reader\\nto the results in the corresponding code repository2for full\\nlogs and further examples.\\n2https://github.com/spcl/graph-of-thoughts\\n41' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 40}\n",
      "page_content='Table 29: Prompt stubs for the document merging task; parameters in single curly brackets will be substituted at runtime.\\nmerge prompt: Merge the following 4 NDA documents <Doc1>-<Doc4>into a single NDA, maximizing retained\\ninformation and minimizing redundancy. Output only the created NDA between the tags <Merged >and</Merged >,\\nwithout any additional text.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>{doc1}</Doc1 >\\n<Doc2>{doc2}</Doc2 >\\n<Doc3>{doc3}</Doc3 >\\n<Doc4>{doc4}</Doc4 >\\nscore prompt: The following NDA <S>merges NDAs <Doc1>-<Doc4>.\\nPlease score the merged NDA <S>in terms of how much redundant information is contained, independent of the original\\nNDAs, as well as how much information is retained from the original NDAs.\\nA score of 10 for redundancy implies that absolutely no information is redundant, while a score of 0 implies that at least half\\nof the information is redundant (so everything is at least mentioned twice).\\nA score of 10 for retained information implies that all information from the original NDAs is retained, while a score of 0\\nimplies that no information is retained.\\nYou may provide reasoning for your scoring, but the final score for redundancy should be between the tags <Redundancy >\\nand</Redundancy >, and the final score for retained information should be between the tags <Retained >and</Retained >,\\nwithout any additional text within any of those tags.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>{doc1}</Doc1 >\\n<Doc2>{doc2}</Doc2 >\\n<Doc3>{doc3}</Doc3 >\\n<Doc4>{doc4}</Doc4 >\\nHere is the merged NDA <S>:\\n<S>{s}</S>\\naggregate prompt: The following NDAs <S1>-<S{num ndas summaries }>each merge the initial NDAs <Doc1>-\\n<Doc4>.\\nCombine the merged NDAs <S1>-<S{num ndas summaries }>into a new one, maximizing their advantages and overall\\ninformation retention, while minimizing redundancy.\\nOutput only the new NDA between the tags <Merged >and</Merged >, without any additional text.\\nHere are the original NDAs <Doc1>-<Doc4>:\\n<Doc1>{doc1}</Doc1 >\\n<Doc2>{doc2}</Doc2 >\\n<Doc3>{doc3}</Doc3 >\\n<Doc4>{doc4}</Doc4 >\\nHere are the merged NDAs <S1>-<S{num ndas summaries }>:\\n<S1>{s1}</S1>\\n. . .\\n<S{num ndas summaries }>{s{num ndas summaries }}</S{num ndas summaries }>\\n42' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 41}\n",
      "page_content='Table 30: Prompt stubs for the document merging task continued ; parameters in single curly brackets will be substituted at\\nruntime.\\nimprove prompt: The following NDA <S>merges initial NDAs <Doc1>-<Doc4>.\\nPlease improve the merged NDA <S>by adding more information and removing redundancy. Output only the improved\\nNDA, placed between the tags <Merged >and</Merged >, without any additional text.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>{doc1}</Doc1 >\\n<Doc2>{doc2}</Doc2 >\\n<Doc3>{doc3}</Doc3 >\\n<Doc4>{doc4}</Doc4 >\\nHere is the merged NDA <S>:\\n<S>{s}</S>\\n43' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 42}\n",
      "page_content='Table 31: Input NDA 1 and 2\\n<Doc1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n3. ”Confidential Information” includes all potentially commercially valuable information, specifically software development\\ntactics, processes, and in-house research results.\\n4. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\\ndisclose it without consent.\\n5. Breach penalties include injunctive relief, other remedies, and a $200,000 fee per breach.\\n6. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\\nenforcement doesn’t imply waiver.\\n7. The Agreement is under the laws of [State].\\n8. Signed by [Your Company Name] and [Recipient Name] at the above date.\\n</Doc1 >\\n<Doc2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n1. Purpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\\nfor [Purpose].\\n2. Confidential Information: Defined as all non-public reports, data, designs, and other materials provided by the Disclosing\\nParty to the Receiving Party.\\n3. Receiving Party’s Obligations:\\na. Use, reproduce, or distribute the confidential information only for the agreed purpose.\\nb. Restrict access to the information to necessary parties, ensuring they abide by strict confidentiality.\\nc. Return or destroy all confidential information upon request or at the end of the agreement.\\n4. Exclusions: Information will not be classified as confidential if it is already known to the Receiving Party, publicly known,\\nor independently developed by the Receiving Party.\\n5. Non-Competition: The Receiving Party will not engage in any competing business against the Disclosing Party during\\nthe agreement and one year after its termination.\\n6. Term and Termination: The agreement is valid for [e.g., ”two years”], unless terminated earlier with [e.g., ”30 days”]\\nwritten notice. The Receiving Party’s non-disclosure and non-competition obligations persist post-termination.\\n7. General Provisions:\\na. Governing Law: [Your State]’s laws apply.\\nb. Amendments: Only valid if written and signed by both parties.\\nc. Entire Agreement: This contract overrules previous related agreements.\\nSigned as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party.\\n</Doc2 >\\n44' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 43}\n",
      "page_content='Table 32: Input NDA 3\\n<Doc3>\\nCONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\\nObjective:\\nTo safeguard classified data during talks of a potential technological alliance.\\nSpecification of Protected Information:\\nParticularly:\\na. System designs and architectural schematics.\\nb. Proprietary computational algorithms.\\nReceiver’s Obligations:\\na. Maintain strict non-disclosure using best practices.\\nb. Employ solely for the aforementioned aim.\\nc. No unveiling without explicit authorization.\\nViolation Ramifications:\\nA charge of $280,000 for every infringement, plus possible legal proceedings.\\nGeneral Terms:\\nBinding for both parties and any successors. This encapsulates the entire accord.\\nLegal Reference:\\nGoverned as per [State]’s legal framework.\\nAttestation:\\nDuly signed on [Date].\\n[AquaBlue Innovations] [PineTree Solutions]\\n</Doc3 >\\n45' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 44}\n",
      "page_content='Table 33: Input NDA 4\\n<Doc4>\\nSECRECY & DISCLOSURE AGREEMENT\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\\norganization.\\nAim:\\nTo protect exclusive insights amidst dialogues for a technological partnership.\\nCategorization of Sensitive Data:\\nIncludes:\\na. Internal software blueprints.\\nb. Intellectual property awaiting patents.\\nCommitments of Recipient:\\na. Uphold confidentiality, ensuring data integrity.\\nb. Utilize strictly for collaborative ventures.\\nc. No exposure without prior consensus.\\nRepercussions for Non-Compliance:\\n$295,000 fine for each transgression, and the option for legal recourse.\\nOverall Provisions:\\nLegally enforceable for signatories and successors. Complete and sole agreement.\\nJuridical Standpoint:\\nUnder the auspices of [State] laws.\\nRatification:\\nConfirmed and endorsed on [Date].\\n[AquaBlue Innovations] [PineTree Solutions]\\n</Doc4 >\\nTable 34: Merging 4 example NDAs: Execution plan ( GoO )\\nGoO:\\n1. Merge the 4 NDAs into a single one 5 times; Score each attempt and keep the best 3\\n2. Aggregate the merge attempts into a single one 5 times; Score each aggregation attempt and keep the overall best attempt\\n(including Step 1)\\n3. Improve the merged NDA 10 times; Score each and keep the best\\n46' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 45}\n",
      "page_content='Table 35: Merging 4 example NDAs: Step 1 (Prompt)\\nMerge the following 4 NDA documents <Doc1>-<Doc4>into a single NDA, maximizing retained information and\\nminimizing redundancy. Output only the created NDA between the tags <Merged >and</Merged >, without any additional\\ntext.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted, see Table 31)\\n</Doc1 >\\n<Doc2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n1. Purpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\\nfor [Purpose].\\n. . .(Omitted, see Table 31)\\n</Doc2 >\\n<Doc3>\\nCONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\\nObjective:\\nTo safeguard classified data during talks of a potential . . .(Omitted, see Table 32)\\n</Doc3 >\\n<Doc4>\\nSECRECY & DISCLOSURE AGREEMENT\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\\norganization.\\nAim:\\nTo protect exclusive insights amidst . . .(Omitted, see Table 33)\\n</Doc4 >\\n47' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 46}\n",
      "page_content='Table 36: Merging 4 example NDAs; we only present the highest scoring response fully in Tables 37-38: Step 1 (Responses)\\nNote that due to the shortening of responses, the appear to be equal, but small differences can be found when observing\\nthe fully generated summaries. The only small differences are reflected in the very similar scores (see Table 39-40 for the\\nscoring of the best response).\\nResponse (1/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.60\\nResponse (2/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted, see Tables 37 - 38)\\nScore: 6.87\\nResponse (3/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.60\\nResponse (4/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 5.78\\nResponse (5/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.50\\n48' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 47}\n",
      "page_content='Table 37: Merging 4 example NDAs: Step 1 (Highest Scoring Response Part 1)\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n3. ”Confidential Information” includes all potentially commercially valuable information, specifically software development\\ntactics, processes, and in-house research results.\\n4. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\\ndisclose it without consent.\\n5. Breach penalties include injunctive relief, other remedies, and a $200,000 fee per breach.\\n6. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\\nenforcement doesn’t imply waiver.\\n7. The Agreement is under the laws of [State].\\n8. Signed by [Your Company Name] and [Recipient Name] at the above date.\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\nPurpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\\nfor [Purpose].\\nConfidential Information: Defined as all non-public reports, data, designs, and other materials provided by the Disclosing\\nParty to the Receiving Party.\\nReceiving Party’s Obligations:\\na. Use, reproduce, or distribute the confidential information only for the agreed purpose.\\nb. Restrict access to the information to necessary parties, ensuring they abide by strict confidentiality.\\nc. Return or destroy all confidential information upon request or at the end of the agreement.\\nExclusions: Information will not be classified as confidential if it is already known to the Receiving Party, publicly known,\\nor independently developed by the Receiving Party.\\nNon-Competition: The Receiving Party will not engage in any competing business against the Disclosing Party during the\\nagreement and one year after its termination.\\nTerm and Termination: The agreement is valid for [e.g., ”two years”], unless terminated earlier with [e.g., ”30 days”] written\\nnotice. The Receiving Party’s non-disclosure and non-competition obligations persist post-termination.\\nGeneral Provisions:\\na. Governing Law: [Your State]’s laws apply.\\nb. Amendments: Only valid if written and signed by both parties.\\nc. Entire Agreement: This contract overrules previous related agreements.\\nSigned as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party.\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\\nObjective:\\nTo safeguard classified data during talks of a potential technological alliance.\\n49' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 48}\n",
      "page_content='Table 38: Merging 4 example NDAs: Step 1 (Highest Scoring Response Part 2)\\nSpecification of Protected Information:\\nParticularly:\\na. System designs and architectural schematics.\\nb. Proprietary computational algorithms.\\nReceiver’s Obligations:\\na. Maintain strict non-disclosure using best practices.\\nb. Employ solely for the aforementioned aim.\\nc. No unveiling without explicit authorization.\\nViolation Ramifications:\\nA charge of $280,000 for every infringement, plus possible legal proceedings.\\nGeneral Terms:\\nBinding for both parties and any successors. This encapsulates the entire accord.\\nLegal Reference:\\nGoverned as per [State]’s legal framework.\\nAttestation:\\nDuly signed on [Date].\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\\norganization.\\nAim:\\nTo protect exclusive insights amidst dialogues for a technological partnership.\\nCategorization of Sensitive Data:\\nIncludes:\\na. Internal software blueprints.\\nb. Intellectual property awaiting patents.\\nCommitments of Recipient:\\na. Uphold confidentiality, ensuring data integrity.\\nb. Utilize strictly for collaborative ventures.\\nc. No exposure without prior consensus.\\nRepercussions for Non-Compliance:\\n$295,000 fine for each transgression, and the option for legal recourse.\\nOverall Provisions:\\nLegally enforceable for signatories and successors. Complete and sole agreement.\\nJuridical Standpoint:\\nUnder the auspices of [State] laws.\\nRatification:\\nConfirmed and endorsed on [Date].\\n50' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 49}\n",
      "page_content='Table 39: Merging 4 example NDAs: Step 1 (Scoring Example – Prompt)\\nPlease score the merged NDA <S>in terms of how much redundant information is contained, independent of the original\\nNDAs, as well as how much information is retained from the original NDAs.\\nA score of 10 for redundancy implies that absolutely no information is redundant, while a score of 0 implies that at least half\\nof the information is redundant (so everything is at least mentioned twice).\\nA score of 10 for retained information implies that all information from the original NDAs is retained, while a score of 0\\nimplies that no information is retained.\\nYou may provide reasoning for your scoring, but the final score for redundancy should be between the tags <Redundancy >\\nand</Redundancy >, and the final score for retained information should be between the tags <Retained >and</Retained >,\\nwithout any additional text within any of those tags.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted, see Table 31)\\n</Doc1 >\\n<Doc2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n. . .(Omitted, see Table 31)\\n</Doc2 >\\n<Doc3>\\nCONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and . . .(Omitted, see Table 32)\\n</Doc3 >\\n<Doc4>\\nSECRECY & DISCLOSURE AGREEMENT\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and . . .(Omitted, see Table 33)\\n</Doc4 >\\nHere is the summary NDA <S>:\\n<S>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted, see Tables 37-38)\\n</S>\\n51' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 50}\n",
      "page_content='Table 40: Merging 4 example NDAs: Step 1 (Scoring Example – Responses)\\nResponse (1/3):\\n<Redundancy >5</Redundancy >\\n<Retained >10</Retained >\\nReasoning:\\nIn terms of redundancy, there is some overlap in the information contained in the NDAs, such as the definition of ”Confiden-\\ntial Information” and the obligations of the receiving party. However, there are also some unique details in each NDA, such\\nas the specific purpose of information sharing and the penalties for breach. Overall, there is a moderate level of redundancy\\nin the merged NDA.\\nIn terms of retained information, all the key elements from the original NDAs are included in the merged NDA. This\\nincludes the agreement between the parties, the purpose of information sharing, the definition of confidential information,\\nthe obligations of the receiving party, the exclusions for confidential information, non-competition clauses, the term and\\ntermination of the agreement, and the general provisions. Therefore, the merged NDA retains all the important information\\nfrom the original NDAs.\\nResponse (2/3):\\n<Redundancy >8</Redundancy >\\n<Retained >10</Retained >\\nReasoning:\\nThe merged NDA <S>contains multiple redundant sections from the original NDAs. For example, the introductory sections,\\nsuch as the agreement between the parties and the purpose of information sharing, are repeated multiple times. Additionally,\\nsections related to the definition of confidential information, the recipient’s obligations, exclusions, non-competition, term\\nand termination, and general provisions are also redundantly included.\\nHowever, in terms of retained information, the merged NDA retains all the key elements from the original NDAs, including\\nthe parties involved, the objective, specification of protected information, recipient’s obligations, violation ramifications,\\ngeneral terms, legal reference, and attestation. Overall, while there is redundancy in the merged NDA, it successfully retains\\nall the necessary information from the original NDAs.\\nResponse (3/3):\\n<Redundancy >3</Redundancy >\\nThe merged NDA contains some redundancy. There are three sections that have overlapping information between the original\\nNDAs. These sections include:\\n1. The agreement between the parties (Section 1 in Doc1 and the beginning of Doc2)\\n2. Information sharing and the purpose of the NDA (Section 2 in both Doc1 and Doc2)\\n3. General provisions such as governing law and amendments (Section 7 in Doc1 and Doc2)\\n<Retained >9</Retained >\\nThe merged NDA retains a significant amount of information from the original NDAs. It includes all key clauses and provi-\\nsions, such as the definition of confidential information, the obligations of the receiving party, exclusions, non-competition,\\nand general provisions. Only a few minor details, such as specific penalties and fine amounts, are not retained in the merged\\nNDA. Overall, the merged NDA effectively combines the essential elements from the original NDAs.\\nNote: Remember to remove the reasoning from between the tags when providing the final scores.\\nFinal Overall Score (Harmonic Mean of Averages):\\n6.87\\n52' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 51}\n",
      "page_content='Table 41: Merging 4 example NDAs; Note that S1-S3 are the three best scoring merge attemps from the previous step: Step 2\\n(Prompt)\\nThe following NDAs <S1>-<S3>each merge the initial NDAs <Doc1>-<Doc4>.\\nCombine the merged NDAs <S1>-<S3>into a new one, maximizing their advantages and overall information retention,\\nwhile minimizing redundancy.\\nOutput only the new NDA between the tags <Merged >and</Merged >, without any additional text.\\nHere are the original NDAs <Doc1>-<Doc4>:\\n<Doc1>\\n. . .(Omitted, see Table 31)\\n</Doc1 >\\n<Doc2>\\n. . .(Omitted, see Table 31)\\n</Doc2 >\\n<Doc3>\\n. . .(Omitted, see Table 32)\\n</Doc3 >\\n<Doc4>\\n. . .(Omitted, see Table 33)\\n</Doc4 >\\nHere are the merged NDAs <S1>-<S3>:\\n<S1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted)\\n</S1>\\n<S2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted, see Tables 37-38)\\n</S2>\\n<S3>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted)\\n</S3>\\n53' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 52}\n",
      "page_content='Table 42: Merging 4 example NDAs: Step 2 (Responses)\\nFor this run, none of the responses improve upon the previous best and thus will all be discarded by the next step. For that\\nreason and due to their long length, we do not present them fully and exclude their scoring.\\nResponse (1/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.50\\nResponse (2/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted)\\nScore: 5.62\\nResponse (3/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.60\\nResponse (4/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.15\\nResponse (5/5):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.22\\n54' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 53}\n",
      "page_content='Table 43: Merging 4 example NDAs: Step 3 (Prompt)\\nThe following NDA <S>merges initial NDAs <Doc1>-<Doc4>.\\nPlease improve the merged NDA <S>by adding more information and removing redundancy. Output only the improved\\nNDA, placed between the tags <Merged >and</Merged >, without any additional text.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted, see Table 31)\\n</Doc1 >\\n<Doc2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n1. Purpose: The Disclosing Party will disclose confidential information related to [Topic of Research] to the Receiving Party\\nfor [Purpose].\\n. . .(Omitted, see Table 31)\\n</Doc2 >\\n<Doc3>\\nCONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and [PineTree Solutions], a registered entity.\\nObjective:\\nTo safeguard classified data during talks of a potential . . .(Omitted, see Table 32)\\n</Doc3 >\\n<Doc4>\\nSECRECY & DISCLOSURE AGREEMENT\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and [PineTree Solutions], a licensed\\norganization.\\nAim:\\nTo protect exclusive insights amidst . . .(Omitted, see Table 33)\\n</Doc4 >\\nHere is the summary NDA <S>:\\n<S>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted, see Tables 37-38)\\n</S>\\n55' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 54}\n",
      "page_content='Table 44: Merging 4 example NDAs; we only present the highest scoring response fully in Table 46: Step 3 (Responses Part\\n1)\\nResponse (1/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.35\\nResponse (2/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.35\\nResponse (3/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date], for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, specifically software develop-\\nment tactics, processes, in-house research results, system designs, architectural schematics, proprietary computational\\nalgorithms, internal software blueprints, and intellectual property awaiting patents.\\n. . .(Omitted)\\nScore: 6.87\\nResponse (4/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\\ntactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\\nrithms, internal software blueprints, and intellectual property awaiting patents.\\n. . .(Omitted, see Table 46))\\nScore: 7.78\\nResponse (5/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.43\\n56' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 55}\n",
      "page_content='Table 45: Merging 4 example NDAs; we only present the highest scoring response fully in Table 46: Step 3 (Responses Part\\n2)\\nResponse (6/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.35\\nResponse (7/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, specifically software develop-\\nment tactics, processes, in-house research results, system designs, architectural schematics, proprietary computational\\nalgorithms, internal software blueprints, and intellectual property awaiting patents.\\n. . .(Omitted)\\nScore: 6.70\\nResponse (8/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes potentially commercially valuable information, such as software development tac-\\ntics, processes, in-house research results, non-public reports, data, designs, and other materials provided by the Disclosing\\nParty.\\n. . .(Omitted)\\nScore: 5.33\\nResponse (9/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n2. Information sharing for the purpose of [specific project or purpose], including [Topic of Research].\\n. . .(Omitted)\\nScore: 7.30\\nResponse (10/10):\\n<Merged >\\nNON-DISCLOSURE AGREEMENT (NDA)\\nAgreement between [Your Company Name] and [Recipient Name] on [Date].\\nInformation sharing for the purpose of [specific project or purpose].\\n. . .(Omitted)\\nScore: 6.40\\n57' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 56}\n",
      "page_content='Table 46: Merging 4 example NDAs: Step 3 (Highest Scoring Response)\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\\ntactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\\nrithms, internal software blueprints, and intellectual property awaiting patents.\\n3. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\\ndisclose it without consent.\\n4. Breach penalties include injunctive relief, other remedies, and a fine per breach (e.g., $200,000 or $280,000 for each\\ninfringement, depending on the agreement).\\n5. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\\nenforcement doesn’t imply waiver.\\n6. The Agreement is under the laws of [State] and is valid for a specified period (e.g., two years) unless terminated earlier\\nwith written notice (e.g., 30 days).\\n7. The Receiving Party agrees not to engage in any competing business against the Disclosing Party during the agreement\\nand a specified period after its termination (e.g., one year).\\n8. The Agreement can only be amended if written and signed by both parties, and overrules previous related agreements.\\n9. The Agreement is legally enforceable and binding for signatories and successors.\\n10. The Agreement is governed by the laws of [State].\\nSigned as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party, along\\nwith the other parties involved.\\n58' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 57}\n",
      "page_content='Table 47: Merging 4 example NDAs: Step 3 (Scoring Example – Prompt)\\nPlease score the merged NDA <S>in terms of how much redundant information is contained, independent of the original\\nNDAs, as well as how much information is retained from the original NDAs.\\nA score of 10 for redundancy implies that absolutely no information is redundant, while a score of 0 implies that at least half\\nof the information is redundant (so everything is at least mentioned twice).\\nA score of 10 for retained information implies that all information from the original NDAs is retained, while a score of 0\\nimplies that no information is retained.\\nYou may provide reasoning for your scoring, but the final score for redundancy should be between the tags <Redundancy >\\nand</Redundancy >, and the final score for retained information should be between the tags <Retained >and</Retained >,\\nwithout any additional text within any of those tags.\\nHere are NDAs <Doc1>-<Doc4>:\\n<Doc1>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date].\\n. . .(Omitted, see Table 31)\\n</Doc1 >\\n<Doc2>\\nNON-DISCLOSURE AGREEMENT (NDA)\\nEffective from [Effective Date], this NDA involves [Your Company Name] (”Disclosing Party”), and [Recipient Name]\\n(”Receiving Party”).\\n. . .(Omitted, see Table 31)\\n</Doc2 >\\n<Doc3>\\nCONFIDENTIALITY & NON-DISCLOSURE AGREEMENT\\nEntities Involved:\\nEffective [Date], between [AquaBlue Innovations], established in [State], and . . .(Omitted, see Table 32)\\n</Doc3 >\\n<Doc4>\\nSECRECY & DISCLOSURE AGREEMENT\\nContracting Parties:\\nDated [Date], drawn between [AquaBlue Innovations], a [State]-based corporation, and . . .(Omitted, see Table 33)\\n</Doc4 >\\nHere is the summary NDA <S>:\\n<S>\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\\ntactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\\nrithms, internal software blueprints, and intellectual property awaiting patents.\\n. . .(Omitted, see Table 46)\\n</S>\\n59' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 58}\n",
      "page_content='Table 48: Merging 4 example NDAs: Step 3 (Scoring Example – Responses)\\nResponse (1/3):\\n<Redundancy >5</Redundancy >\\n<Retained >8</Retained >\\nReasoning:\\nThe merged NDA <S>retains most of the information from the original NDAs, combining relevant clauses and terms\\ninto a single comprehensive agreement. However, some redundancy is present as similar information is mentioned multiple\\ntimes, such as the definition of ”Confidential Information” and the obligations of the receiving party. Additionally, some\\nspecific details from the original NDAs are not included in the merged NDA, such as the exclusion criteria in Doc2 and the\\nprovisions for non-competition in Doc3 and Doc4. Nonetheless, the merged NDA captures the essence of the original NDAs\\nand includes all key information necessary for a non-disclosure agreement.\\nResponse (2/3):\\n<Redundancy >8</Redundancy >\\n<Retained >10</Retained >\\nReasoning:\\nThe merged NDA <S>retains all the key information from the original NDAs, including the purpose of the agreement,\\nthe definition of confidential information, the obligations of the receiving party, breach penalties, applicability to parties and\\nsuccessors, governing law, and signature requirements.\\nThere is some redundant information, such as the inclusion of system designs, architectural schematics, proprietary com-\\nputational algorithms, internal software blueprints, and intellectual property awaiting patents from both Doc3 and Doc4.\\nHowever, this redundancy is minor and does not significantly impact the overall usefulness of the NDA.\\nOverall, the merged NDA <S>retains all important information while minimizing redundancy, making it highly effective\\nin conveying the necessary terms and obligations of the agreement. Therefore, it receives a score of 8 for redundancy and a\\nscore of 10 for retained information.\\nResponse (3/3):\\n<Redundancy >7</Redundancy >\\n<Retained >10</Retained >\\nReasoning:\\nThe merged NDA <S>contains some redundant information, such as the definition of ”Confidential Information” and the\\nobligations of the receiving party. However, it retains all the important information from the original NDAs, including the\\npurpose of the agreement, the specific types of confidential information, the breach penalties, the applicability to parties and\\nsuccessors, the governing law, and the provisions regarding non-competition, amendment, and termination. Additionally, it\\nincorporates the additional information about the agreement’s validity period and the option for legal recourse in case of\\nnon-compliance. Therefore, the merged NDA <S>scores a 7 for redundancy and a 10 for retained information.\\nFinal Overall Score (Harmonic Mean of Averages):\\n7.78\\n60' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 59}\n",
      "page_content='Table 49: Merging 4 example NDAs: Final Merged NDA\\nNON-DISCLOSURE AGREEMENT (NDA)\\n1. Agreement between [Your Company Name] and [Recipient Name] on [Date] for the purpose of [specific project or\\npurpose].\\n2. ”Confidential Information” includes all potentially commercially valuable information, such as software development\\ntactics, processes, in-house research results, system designs, architectural schematics, proprietary computational algo-\\nrithms, internal software blueprints, and intellectual property awaiting patents.\\n3. Receiving party is obligated to protect the Confidential Information, use it solely for the disclosed purpose, and not\\ndisclose it without consent.\\n4. Breach penalties include injunctive relief, other remedies, and a fine per breach (e.g., $200,000 or $280,000 for each\\ninfringement, depending on the agreement).\\n5. The Agreement applies to the Parties and their successors and assigns. It contains all related agreements and lack of\\nenforcement doesn’t imply waiver.\\n6. The Agreement is under the laws of [State] and is valid for a specified period (e.g., two years) unless terminated earlier\\nwith written notice (e.g., 30 days).\\n7. The Receiving Party agrees not to engage in any competing business against the Disclosing Party during the agreement\\nand a specified period after its termination (e.g., one year).\\n8. The Agreement can only be amended if written and signed by both parties, and overrules previous related agreements.\\n9. The Agreement is legally enforceable and binding for signatories and successors.\\n10. The Agreement is governed by the laws of [State].\\nSigned as of the Effective Date by [Your Company Name] - Disclosing Party [Recipient Name] - Receiving Party, along\\nwith the other parties involved.\\n61' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 60}\n",
      "page_content='F Evaluation - GoT Configurations\\nWe detail the concrete operations that GoT was configured\\nwith to solve the set intersection and sorting use cases.\\nListing 1: GoT configuration for the set intersection use case\\nwith 32 elements\\n1Generate (k =1) # Split second set into two halves of 16 elements\\n2foreach subset :\\n3 Generate (k =5) # Determine intersected subset of subset and\\nfirst input set\\n4 Score (k =1) # Score locally the intersected subsets\\n5 KeepBestN (1) # Keep the best intersected subset\\n6Aggregate (10) # Merge both intersected subsets\\n7Score (k =1) # Score locally the intersected result sets\\n8KeepBestN (1) # Keep the best result\\n9GroundTruth () # Compare to precomputed result\\nListing 2: GoT configuration for the set intersection use case\\nwith 64 elements\\n1Generate (k =1) # Split second set into four parts of 16 elements\\n2foreach subset :\\n3 Generate (k =5) # Determine intersected subset of subset and\\nfirst input set\\n4 Score (k =1) # Score locally the intersected subsets\\n5 KeepBestN (1) # Keep the best intersected subset\\n6merge step 1:\\n7 Aggregate (10) # Merge intersected subsets 1 and 2\\n8 Score (k =1) # Score locally the intersected result sets\\n9 KeepBestN (1) # Keep the best result\\n10merge step 2:\\n11 Aggregate (10) # Merge intersected subsets 3 and 4\\n12 Score (k =1) # Score locally the intersected result sets\\n13 KeepBestN (1) # Keep the best result\\n14final merge :\\n15 Aggregate (10) # Merge intermediate intersected subsets from\\nmerge step 1 and 2\\n16 Score (k =1) # Score locally the intersected result sets\\n17 KeepBestN (1) # Keep the best result\\n18GroundTruth () # Compare to precomputed result\\nListing 3: GoT configuration for the set intersection use case\\nwith 128 elements\\n1Generate (k =1) # Split second set into eight parts of 16\\nelements\\n2foreach subset :\\n3 Generate (k =5) # Determine intersected subset of subset and\\nfirst input set\\n4 Score (k =1) # Score locally the intersected subsets\\n5 KeepBestN (1) # Keep the best intersected subset\\n6merge step 1:\\n7 Aggregate (5) # Merge intersected subsets 1 and 2\\n8 Score (k =1) # Score locally the intersected result sets\\n9 KeepBestN (1) # Keep the best result\\n10merge step 2:\\n11 Aggregate (5) # Merge intersected subsets 3 and 4\\n12 Score (k =1) # Score locally the intersected result sets\\n13 KeepBestN (1) # Keep the best result\\n14merge step 3:\\n15 Aggregate (5) # Merge intersected subsets 5 and 6\\n16 Score (k =1) # Score locally the intersected result sets\\n17 KeepBestN (1) # Keep the best result\\n18merge step 4:\\n19 Aggregate (5) # Merge intersected subsets 7 and 8\\n20 Score (k =1) # Score locally the intersected result setsListing 4: GoT configuration for the set intersection use case\\nwith 128 elements (cont.)\\n21 KeepBestN (1) # Keep the best result\\n22merge step 5:\\n23 Aggregate (5) # Merge intermediate intersected subsets from\\nmerge step 1 and 2\\n24 Score (k =1) # Score locally the intersected result sets\\n25 KeepBestN (1) # Keep the best result\\n26merge step 6:\\n27 Aggregate (5) # Merge intermediate intersected subsets from\\nmerge step 3 and 4\\n28 Score (k =1) # Score locally the intersected result sets\\n29 KeepBestN (1) # Keep the best result\\n30final merge :\\n31 Aggregate (5) # Merge intermediate intersected subsets from\\nmerge step 5 and 6\\n32 Score (k =1) # Score locally the intersected result sets\\n33 KeepBestN (1) # Keep the best result\\n34GroundTruth () # Compare to precomputed result\\nListing 5: GoT configuration for the sorting use case with 32\\nelements\\n1Generate (k =1) # Split list into two halves of 16 elements\\n2foreach list part :\\n3 Generate (k =5) # Sort list part\\n4 Score (k =1) : # Score partially sorted list\\n5 KeepBestN (1) : # Keep the best partially sorted list\\n6Aggregate (10) # Merge both partially sorted lists\\n7Score (k =1) # Score locally the sorted result lists\\n8KeepBestN (1) # Keep the best result\\n9Generate (k =10) # Try to improve solution\\n10Score (k =1) # Score locally the sorted result lists\\n11KeepBestN (1) # Keep the best result\\n12GroundTruth () # Compare to precomputed result\\nListing 6: GoT configuration for the sorting use case with 64\\nelements\\n1Generate (k =1) # Split list into four parts of 16 elements\\n2foreach list part :\\n3 Generate (k =5) # Sort list part\\n4 Score (k =1) # Score partially sorted list\\n5 KeepBestN (1) # Keep the best partially sorted list\\n6merge step 1:\\n7 Aggregate (10) # Merge partially sorted lists 1 and 2\\n8 Score (k =1) # Score locally the partially sorted result lists\\n9 KeepBestN (1) # Keep the best result\\n10 Generate (k =5) # Try to improve the partial solution\\n11 Score (k =1) # Score locally the partially sorted result lists\\n12 KeepBestN (1) # Keep the best result\\n13merge step 2:\\n14 Aggregate (10) # Merge partially sorted lists 3 and 4\\n15 Score (k =1) # Score locally the partially sorted result lists\\n16 KeepBestN (1) # Keep the best result\\n17 Generate (k =5) # Try to improve the partial solution\\n18 Score (k =1) # Score locally the partially sorted result lists\\n19 KeepBestN (1) # Keep the best result\\n20final merge :\\n21 Aggegrate (10) # Merge partially sorted lists from merge step\\n1 and 2\\n22 Score (k =1) # Score locally the sorted result lists\\n23 KeepBestN (1) # Keep the best result\\n24 Generate (k =10) # Try to improve solution\\n25 Score (k =1) # Score locally the sorted result lists\\n26 KeepBestN (1) # Keep the best result\\n27GroundTruth () # Compare to precomputed result\\n62' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 61}\n",
      "page_content='Listing 7: GoT configuration for the sorting use case with\\n128 elements\\n1Generate (k =1) # Split list into eight parts of 16 elements\\n2foreach list part :\\n3 Generate (k =5) # Sort list part\\n4 Score (k =1) # Score partially sorted list\\n5 KeepBestN (1) # Keep the best partially sorted list\\n6merge step 1:\\n7 Aggregate (10) # Merge partially sorted lists 1 and 2\\n8 Score (k =1) # Score locally the partially sorted result lists\\n9 KeepBestN (1) # Keep the best result\\n10 Generate (k =5) # Try to improve the partial solution\\n11 Score (k =1) # Score locally the partially sorted result lists\\n12 KeepBestN (1) # Keep the best result\\n13merge step 2:\\n14 Aggregate (10) # Merge partially sorted lists 3 and 4\\n15 Score (k =1) # Score locally the partially sorted result lists\\n16 KeepBestN (1) # Keep the best result\\n17 Generate (k =5) # Try to improve the partial solution\\n18 Score (k =1) # Score locally the partially sorted result lists\\n19 KeepBestN (1) # Keep the best result\\n20merge step 3:\\n21 Aggregate (10) # Merge partially sorted lists 5 and 6\\n22 Score (k =1) # Score locally the partially sorted result lists\\n23 KeepBestN (1) # Keep the best result\\n24 Generate (k =5) # Try to improve the partial solution\\n25 Score (k =1) # Score locally the partially sorted result lists\\n26 KeepBestN (1) # Keep the best result\\n27merge step 4:\\n28 Aggregate (10) # Merge partially sorted lists 7 and 8\\n29 Score (k =1) # Score locally the partially sorted result lists\\n30 KeepBestN (1) # Keep the best result\\n31 Generate (k =5) # Try to improve the partial solution\\n32 Score (k =1) # Score locally the partially sorted result lists\\n33 KeepBestN (1) # Keep the best result\\n34merge step 5:\\n35 Aggregate (10) # Merge partially sorted lists from merge step\\n1 and 2\\n36 Score (k =1) # Score locally the partially sorted result lists\\n37 KeepBestN (1) # Keep the best result\\n38 Generate (k =5) # Try to improve the partial solution\\n39 Score (k =1) # Score locally the partially sorted result lists\\n40 KeepBestN (1) # Keep the best result\\n41merge step 6:\\n42 Aggregate (10) # Merge partially sorted lists from merge step\\n3 and 4\\n43 Score (k =1) # Score locally the partially sorted result lists\\n44 KeepBestN (1) # Keep the best result\\n45 Generate (k =5) # Try to improve the partial solution\\n46 Score (k =1) # Score locally the partially sorted result lists\\n47 KeepBestN (1 # Keep the best result\\n48final merge :\\n49 Aggregate (10) # Merge partially sorted lists from merge step\\n5 and 6\\n50 Score (k =1) # Score locally the partially sorted result lists\\n51 KeepBestN (1) # Keep the best result\\n52 Generate (k =10) # Try to improve solution\\n53 Score (k =1) # Score locally the sorted result lists\\n54 KeepBestN (1) # Keep the best result\\n55GroundTruth () # Compare to precomputed result\\n63' metadata={'source': 'pdf/Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf', 'page': 62}\n",
      "page_content='Chain-of-Thought Prompting Elicits Reasoning\\nin Large Language Models\\nJason Wei Xuezhi Wang Dale Schuurmans Maarten Bosma\\nBrian Ichter Fei Xia Ed H. Chi Quoc V . Le Denny Zhou\\nGoogle Research, Brain Team\\n{jasonwei,dennyzhou}@google.com\\nAbstract\\nWe explore how generating a chain of thought —a series of intermediate reasoning\\nsteps—signiﬁcantly improves the ability of large language models to perform\\ncomplex reasoning. In particular, we show how such reasoning abilities emerge\\nnaturally in sufﬁciently large language models via a simple method called chain-of-\\nthought prompting , where a few chain of thought demonstrations are provided as\\nexemplars in prompting.\\nExperiments on three large language models show that chain-of-thought prompting\\nimproves performance on a range of arithmetic, commonsense, and symbolic\\nreasoning tasks. The empirical gains can be striking. For instance, prompting a\\nPaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art\\naccuracy on the GSM8K benchmark of math word problems, surpassing even\\nﬁnetuned GPT-3 with a veriﬁer.\\nA: The cafeteria had 23 apples originally. They used 20 to make lunch. So they had 23 - 20 = 3. They bought 6 more apples, so they have 3 + 6 = 9. The answer is 9.Chain-of-Thought PromptingQ: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? A: The answer is 11. Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?A: The answer is 27.Standard Prompting\\nQ: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11. Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?Model Input\\nModel OutputModel OutputModel Input\\nFigure 1: Chain-of-thought prompting enables large language models to tackle complex arithmetic,\\ncommonsense, and symbolic reasoning tasks. Chain-of-thought reasoning processes are highlighted.\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2201.11903v6  [cs.CL]  10 Jan 2023' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 0}\n",
      "page_content='1 Introduction\\nMath Word Problems (GSM8K)020406080100\\n3355\\n1857Solve rate (%)Finetuned GPT-3 175B\\nPrior best\\nPaLM 540B: standard prompting\\nPaLM 540B: chain-of-thought prompting\\nFigure 2: PaLM 540B uses chain-of-\\nthought prompting to achieve new state-\\nof-the-art performance on the GSM8K\\nbenchmark of math word problems.\\nFinetuned GPT-3 and prior best are from\\nCobbe et al. (2021).The NLP landscape has recently been revolutionized by\\nlanguage models (Peters et al., 2018; Devlin et al., 2019;\\nBrown et al., 2020, inter alia ). Scaling up the size of lan-\\nguage models has been shown to confer a range of beneﬁts,\\nsuch as improved performance and sample efﬁciency (Ka-\\nplan et al., 2020; Brown et al., 2020, inter alia ). However,\\nscaling up model size alone has not proved sufﬁcient for\\nachieving high performance on challenging tasks such as\\narithmetic, commonsense, and symbolic reasoning (Rae\\net al., 2021).\\nThis work explores how the reasoning ability of large\\nlanguage models can be unlocked by a simple method\\nmotivated by two ideas. First, techniques for arithmetic\\nreasoning can beneﬁt from generating natural language\\nrationales that lead to the ﬁnal answer. Prior work has\\ngiven models the ability to generate natural language inter-\\nmediate steps by training from scratch (Ling et al., 2017)\\nor ﬁnetuning a pretrained model (Cobbe et al., 2021), in\\naddition to neuro-symbolic methods that use formal lan-\\nguages instead of natural language (Roy and Roth, 2015;\\nChiang and Chen, 2019; Amini et al., 2019; Chen et al.,\\n2019). Second, large language models offer the exciting\\nprospect of in-context few-shot learning via prompting . That is, instead of ﬁnetuning a separate\\nlanguage model checkpoint for each new task, one can simply “prompt” the model with a few\\ninput–output exemplars demonstrating the task. Remarkably, this has been successful for a range of\\nsimple question-answering tasks (Brown et al., 2020).\\nBoth of the above ideas, however, have key limitations. For rationale-augmented training and\\nﬁnetuning methods, it is costly to create a large set of high quality rationales, which is much more\\ncomplicated than simple input–output pairs used in normal machine learning. For the traditional few-\\nshot prompting method used in Brown et al. (2020), it works poorly on tasks that require reasoning\\nabilities, and often does not improve substantially with increasing language model scale (Rae et al.,\\n2021). In this paper, we combine the strengths of these two ideas in a way that avoids their limitations.\\nSpeciﬁcally, we explore the ability of language models to perform few-shot prompting for reasoning\\ntasks, given a prompt that consists of triples: ⟨input, chain of thought , output⟩. Achain of thought is\\na series of intermediate natural language reasoning steps that lead to the ﬁnal output, and we refer to\\nthis approach as chain-of-thought prompting . An example prompt is shown in Figure 1.\\nWe present empirical evaluations on arithmetic, commonsense, and symbolic reasoning benchmarks,\\nshowing that chain-of-thought prompting outperforms standard prompting, sometimes to a striking\\ndegree. Figure 2 illustrates one such result—on the GSM8K benchmark of math word problems\\n(Cobbe et al., 2021), chain-of-thought prompting with PaLM 540B outperforms standard prompting\\nby a large margin and achieves new state-of-the-art performance. A prompting only approach is\\nimportant because it does not require a large training dataset and because a single model checkpoint\\ncan perform many tasks without loss of generality. This work underscores how large language models\\ncan learn via a few examples with natural language data about the task (c.f. automatically learning\\nthe patterns underlying inputs and outputs via a large training dataset).\\n2 Chain-of-Thought Prompting\\nConsider one’s own thought process when solving a complicated reasoning task such as a multi-step\\nmath word problem. It is typical to decompose the problem into intermediate steps and solve each\\nbefore giving the ﬁnal answer: “After Jane gives 2 ﬂowers to her mom she has 10 ...then after she\\ngives 3 to her dad she will have 7 ...so the answer is 7. ” The goal of this paper is to endow language\\nmodels with the ability to generate a similar chain of thought —a coherent series of intermediate\\nreasoning steps that lead to the ﬁnal answer for a problem. We will show that sufﬁciently large\\n2' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 1}\n",
      "page_content='language models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the ﬁnal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model’s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in sufﬁciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speciﬁc ﬁnetuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following ﬁve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input–output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting—Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 2}\n",
      "page_content='Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.Q: Sammy wanted to go to where the people were. Where might he go? Options: (a) race track (b) populated areas (c) desert (d) apartment (e) roadblock A: The answer must be a place with a lot of people. Race tracks, desert, apartments, and roadblocks don\\'t have a lot of people, but populated areas do. So the answer is (b). Q: Yes or no: Would a pear sink in water? A: The density of a pear is about 0.6 g/cm^3, which is less than water. Thus, a pear would float. So the answer is no.Q: The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10 days ago in MM/DD/YYYY?  A: One day after 06/01/1943 is 06/02/1943, so today is 06/02/1943. 10 days before today is 05/23/1943. So the answer is 05/23/1943. Q: Is the following sentence plausible? \"Joao Moutinho caught the screen pass in the NFC championship.\"  A: Joao Moutinho is a soccer player. The NFC championship is part of American football, not soccer. So the answer is no.Q: Take the last letters of the words in “Lady Gaga” and concatenate them. A: The last letter of “Lady” is “y”. The last letter of “Gaga” is “a”. Concatenating them is “ya”. So the answer is ya.Q: A coin is heads up. Maybelle flips the coin. Shalonda does not flip the coin. Is the coin still heads up? A: The coin was flipped by Maybelle. So the coin was flipped 1 time, which is an odd number. The coin started heads up, so after an odd number of flips, it will be tails up. So the answer is no.Math Word Problems (free response)Math Word Problems (multiple choice)CSQA (commonsense)\\nStrategyQADate UnderstandingSports Understanding\\nLast Letter ConcatenationCoin Flip (state tracking)Q: How many keystrokes are needed to type the numbers from 1 to 500?Answer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788 A: There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401 three-digit numbers from 100 to 500. 9 + 90(2) + 401(3) = 1392. The answer is (b).\\nSayCan (Instructing a robot)Human: How would you bring me something that isn’t a fruit? Explanation: the user wants something to eat that isn’t a fruit. An energy bar is not a fruit, so I will bring the user an energy bar.  Plan: 1. find(energy bar) 2. pick(energy bar) 3. find(user) 4. put(energy bar) 5. done().Figure 3: Examples of ⟨input, chain of thought, output ⟩triples for arithmetic, commonsense, and\\nsymbolic reasoning benchmarks. Chains of thought are highlighted. Full prompts in Appendix G.\\nmath word problems, we used this single set of eight chain of thought exemplars for all benchmarks\\nexcept AQuA, which is multiple choice instead of free response. For AQuA, we used four exemplars\\nand solutions from the training set, as given in Appendix Table 21.\\nLanguage models. We evaluate ﬁve large language models. The ﬁrst is GPT-3 (Brown et al.,\\n2020), for which we use text-ada-001, text-babbage-001, text-curie-001, and text-davinci-002, which\\npresumably correspond to InstructGPT models of 350M, 1.3B, 6.7B, and 175B parameters (Ouyang\\net al., 2022).The second is LaMDA (Thoppilan et al., 2022), which has models of 422M, 2B, 8B,\\n68B, and 137B parameters. The third is PaLM , which has models of 8B, 62B, and 540B parameters.\\nThe fourth is UL2 20B (Tay et al., 2022), and the ﬁfth is Codex (Chen et al., 2021, code-davinci-002\\nin the OpenAI API). We sample from the models via greedy decoding (though follow-up work shows\\nchain-of-thought prompting can be improved by taking the majority ﬁnal answer over many sampled\\ngenerations (Wang et al., 2022a)). For LaMDA, we report averaged results over ﬁve random seeds,\\nwhere each seed had a different randomly shufﬂed order of exemplars. As LaMDA experiments\\ndid not show large variance among different seeds, to save compute we report results for a single\\nexemplar order for all other models.\\n3.2 Results\\nThe strongest results of chain-of-thought prompting are summarized in Figure 4, with all experimental\\noutputs for each model collection, model size, and benchmark shown in Table 2 in the Appendix.\\nThere are three key takeaways. First, Figure 4 shows that chain-of-thought prompting is an emergent\\nability of model scale (Wei et al., 2022b). That is, chain-of-thought prompting does not positively\\nimpact performance for small models, and only yields performance gains when used with models of\\n∼100B parameters. We qualitatively found that models of smaller scale produced ﬂuent but illogical\\nchains of thought, leading to lower performance than standard prompting.\\n4' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 3}\n",
      "page_content='0204060GSM8K\\nsolve rate (%)LaMDA GPT PaLMStandard prompting\\nChain-of-thought prompting\\nPrior supervised best\\n020406080SV AMP\\nsolve rate (%)\\n0.4 81370255075100MAWPS\\nsolve rate (%)\\n0.4 7175 862540\\nModel scale (# parameters in billions)\\nFigure 4: Chain-of-thought prompting enables\\nlarge language models to solve challenging math\\nproblems. Notably, chain-of-thought reasoning\\nis an emergent ability of increasing model scale.\\nPrior best numbers are from Cobbe et al. (2021)\\nfor GSM8K, Jie et al. (2022) for SV AMP, and Lan\\net al. (2021) for MAWPS.Second, chain-of-thought prompting has larger\\nperformance gains for more-complicated prob-\\nlems. For instance, for GSM8K (the dataset\\nwith the lowest baseline performance), perfor-\\nmance more than doubled for the largest GPT\\nand PaLM models. On the other hand, for Sin-\\ngleOp, the easiest subset of MAWPS which only\\nrequires a single step to solve, performance im-\\nprovements were either negative or very small\\n(see Appendix Table 3).\\nThird, chain-of-thought prompting via GPT-3\\n175B and PaLM 540B compares favorably to\\nprior state of the art, which typically ﬁnetunes a\\ntask-speciﬁc model on a labeled training dataset.\\nFigure 4 shows how PaLM 540B uses chain-of-\\nthought prompting to achieve new state of the art\\non GSM8K, SV AMP, and MAWPS (though note\\nthat standard prompting already passed the prior\\nbest for SV AMP). On the other two datasets,\\nAQuA and ASDiv, PaLM with chain-of-thought\\nprompting reaches within 2% of the state of the\\nart (Appendix Table 2).\\nTo better understand why chain-of-thought\\nprompting works, we manually examined model-\\ngenerated chains of thought by LaMDA 137B\\nfor GSM8K. Of 50 random examples where the\\nmodel returned the correct ﬁnal answer, all of\\nthe generated chains of thought were also log-\\nically and mathematically correct except two\\nthat coincidentally arrived at the correct answer\\n(see Appendix D.1, and Table 8 for examples\\nof correct model-generated chains of thought).\\nWe also randomly examined 50 random sam-\\nples for which the model gave the wrong answer.\\nThe summary of this analysis is that 46% of the\\nchains of thought were almost correct, barring\\nminor mistakes (calculator error, symbol map-\\nping error, or one reasoning step missing), and that the other 54% of the chains of thought had major\\nerrors in semantic understanding or coherence (see Appendix D.2). To provide a small insight into\\nwhy scaling improves chain-of-thought reasoning ability, we performed a similar analysis of errors\\nmade by PaLM 62B and whether those errors were ﬁxed by scaling to PaLM 540B. The summary\\nis that scaling PaLM to 540B ﬁxes a large portion of one-step missing and semantic understanding\\nerrors in the 62B model (see Appendix A.1).\\n3.3 Ablation Study\\nThe observed beneﬁts of using chain-of-thought prompting raises the natural question of whether the\\nsame performance improvements can be conferred via other types of prompting. Figure 5 shows an\\nablation study with three variations of chain of thought described below.\\nEquation only. One reason for why chain-of-thought prompting might help is that it produces the\\nmathematical equation to be evaluated, and so we test a variation where the model is prompted\\nto output only a mathematical equation before giving the answer. Figure 5 shows that equation\\nonly prompting does not help much for GSM8K, which implies that the semantics of the questions\\nin GSM8K are too challenging to directly translate into an equation without the natural language\\nreasoning steps in chain of thought. For datasets of one-step or two-step problems, however, we ﬁnd\\nthat equation only prompting does improve performance, since the equation can be easily derived\\nfrom the question (see Appendix Table 6).\\n5' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 4}\n",
      "page_content='LaMDA PaLM0204060GSM8K solve rate (%)Standard prompting\\nEquation only\\nVariable compute only\\nReasoning after answer\\nChain-of-thought prompting\\nFigure 5: Ablation study for dif-\\nferent variations of prompting us-\\ning LaMDA 137B and PaLM 540B.\\nResults for other datasets are given\\nin Appendix Table 6 and Table 7.Variable compute only. Another intuition is that chain of\\nthought allows the model to spend more computation (i.e.,\\nintermediate tokens) on harder problems. To isolate the effect\\nof variable computation from chain-of-thought reasoning, we\\ntest a conﬁguration where the model is prompted to output a\\nonly sequence of dots ( ...) equal to the number of characters in\\nthe equation needed to solve the problem. This variant performs\\nabout the same as the baseline, which suggests that variable\\ncomputation by itself is not the reason for the success of chain-\\nof-thought prompting, and that there appears to be utility from\\nexpressing intermediate steps via natural language.\\nChain of thought after answer. Another potential beneﬁt of\\nchain-of-thought prompting could simply be that such prompts\\nallow the model to better access relevant knowledge acquired\\nduring pretraining. Therefore, we test an alternative conﬁgura-\\ntion where the chain of thought prompt is only given after the\\nanswer, isolating whether the model actually depends on the\\nproduced chain of thought to give the ﬁnal answer. This variant\\nperforms about the same as the baseline, which suggests that\\nthe sequential reasoning embodied in the chain of thought is\\nuseful for reasons beyond just activating knowledge.\\n3.4 Robustness of Chain of Thought\\nGSM8K05101520Solve rate (%)Standard prompting\\nChain-of-thought prompting\\n·different annotator (B)\\n·different annotator (C)\\n·intentionally concise style\\n·exemplars from GSM8K ( α)\\n·exemplars from GSM8K ( β)\\n·exemplars from GSM8K ( γ)\\nMAWPS0204060\\nFigure 6: Chain-of-thought prompting\\nhas variance for different prompt exam-\\nples (as expected) but outperforms stan-\\ndard prompting for various annotators as\\nwell as for different exemplars.Sensitivity to exemplars is a key consideration of prompt-\\ning approaches—for instance, varying the permutation of\\nfew-shot exemplars can cause the accuracy of GPT-3 on\\nSST-2 to range from near chance (54.3%) to near state of\\nthe art (93.4%) (Zhao et al., 2021). In this ﬁnal subsec-\\ntion, we evaluate robustness to chains of thought written\\nby different annotators. In addition to the results above,\\nwhich used chains of thought written by an Annotator\\nA, two other co-authors of this paper (Annotators B and\\nC) independently wrote chains of thought for the same\\nfew-shot exemplars (shown in Appendix H). Annotator A\\nalso wrote another chain of thought that was more concise\\nthan the original, following the style of solutions given in\\nCobbe et al. (2021).1\\nFigure 6 shows these results for LaMDA 137B on GSM8K\\nand MAWPS (ablation results for other datasets are given\\nin Appendix Table 6 / Table 7). Although there is variance\\namong different chain of thought annotations, as would be\\nexpected when using exemplar-based prompting (Le Scao\\nand Rush, 2021; Reynolds and McDonell, 2021; Zhao\\net al., 2021), all sets of chain of thought prompts outper-\\nform the standard baseline by a large margin. This result\\nimplies that successful use of chain of thought does not\\ndepend on a particular linguistic style.\\nTo conﬁrm that successful chain-of-thought prompting\\nworks for other sets of exemplars, we also run experiments\\nwith three sets of eight exemplars randomly sampled from the GSM8K training set, an independent\\n1For instance, whereas original chain of thought uses several short sentences ( “’There were originally 9\\ncomputers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is\\n29. ”), the concise chain of thought would read “5 * 4 = 20 new computers were added. So there are 9 + 20 = 29\\nnew computers in the server room now” .\\n6' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 5}\n",
      "page_content='source (examples in this dataset already included reasoning steps like a chain of thought).2Fig-\\nure 6 shows that these prompts performed comparably with our manually written exemplars, also\\nsubstantially outperforming standard prompting.\\nIn addition to robustness to annotators, independently-written chains of thought, different exemplars,\\nand various language models, we also ﬁnd that chain-of-thought prompting for arithmetic reasoning\\nis robust to different exemplar orders and varying numbers of exemplars (see Appendix A.2).\\n4 Commonsense Reasoning\\nAlthough chain of thought is particularly suitable for math word problems, the language-based nature\\nof chain of thought actually makes it applicable to a broad class of commonsense reasoning problems,\\nwhich involve reasoning about physical and human interactions under the presumption of general\\nbackground knowledge. Commonsense reasoning is key for interacting with the world and is still\\nbeyond the reach of current natural language understanding systems (Talmor et al., 2021).\\nBenchmarks. We consider ﬁve datasets covering a diverse range of commonsense reasoning types.\\nThe popular CSQA (Talmor et al., 2019) asks commonsense questions about the world involving\\ncomplex semantics that often require prior knowledge. StrategyQA (Geva et al., 2021) requires\\nmodels to infer a multi-hop strategy to answer questions. We choose two specialized evaluation sets\\nfrom the BIG-bench effort (BIG-bench collaboration, 2021): Date Understanding, which involves\\ninferring a date from a given context, and Sports Understanding, which involves determining whether\\na sentence relating to sports is plausible or implausible. Finally, the SayCan dataset (Ahn et al.,\\n2022) involves mapping a natural language instruction to a sequence of robot actions from a discrete\\nset. Figure 3 shows examples with chain of thought annotations for all datasets.\\nPrompts. We follow the same experimental setup as the prior section. For CSQA and StrategyQA,\\nwe randomly selected examples from the training set and manually composed chains of thought for\\nthem to use as few-shot exemplars. The two BIG-bench tasks do not have training sets, so we selected\\nthe ﬁrst ten examples as exemplars in the evaluation set as few-shot exemplars and report numbers on\\nthe rest of the evaluation set. For SayCan, we use six examples from the training set used in Ahn et al.\\n(2022) and also manually composed chains of thought.\\nResults. Figure 7 highlights these results for PaLM (full results for LaMDA, GPT-3, and different\\nmodel scales are shown in Table 4). For all tasks, scaling up model size improved the performance\\nof standard prompting; chain-of-thought prompting led to further gains, with improvements appear-\\ning to be largest for PaLM 540B. With chain-of-thought prompting, PaLM 540B achieved strong\\nperformance relative to baselines, outperforming the prior state of the art on StrategyQA (75.6% vs\\n69.4%) and outperforming an unaided sports enthusiast on sports understanding (95.4% vs 84%).\\nThese results demonstrate that chain-of-thought prompting can also improve performance on tasks\\nrequiring a range of commonsense reasoning abilities (though note that gain was minimal on CSQA).\\n86254020406080100 Solve rate (%)CSQA\\n8625405060708090StrategyQA\\nStandard prompting\\nChain of thought\\nPrior supervised best\\nHuman\\n862540020406080\\nModel scale (# parameters in billions)Date\\n862540406080100Sports\\n86254020406080100SayCan\\nFigure 7: Chain-of-thought prompting also improves the commonsense reasoning abilities of\\nlanguage models. The language model shown here is PaLM. Prior best numbers are from the\\nleaderboards of CSQA (Talmor et al., 2019) and StrategyQA (Geva et al., 2021) (single-model only,\\nas of May 5, 2022). Additional results using various sizes of LaMDA, GPT-3, and PaLM are shown\\nin Table 4.\\n2We sample examples ≤60tokens to ﬁt into our input context window, and also limit the examples to ≤2\\nsteps to solve for a fair comparison with the eight exemplars that we composed.\\n7' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 6}\n",
      "page_content='5 Symbolic Reasoning\\n0255075100 Solve rate (%)Letter Concat: 2\\n(in domain)Letter Concat: 4\\n(OOD)Standard prompting\\nChain-of-thought prompting\\n8 62 540406080100 Solve rate (%)Coin Flip: 2\\n(in domain)\\n8 62 540\\nModel scale (# parameters in billions)Coin Flip: 4\\n(OOD)\\nFigure 8: Using chain-of-thought\\nprompting facilitates generalization to\\nlonger sequences in two symbolic rea-\\nsoning tasks.Our ﬁnal experimental evaluation considers symbolic rea-\\nsoning, which is simple for humans but potentially chal-\\nlenging for language models. We show that chain-of-\\nthought prompting not only enables language models to\\nperform symbolic reasoning tasks that are challenging in\\nthe standard prompting setting, but also facilitates length\\ngeneralization to inference-time inputs longer than those\\nseen in the few-shot exemplars.\\nTasks. We use the following two toy tasks.\\n•Last letter concatenation. This task asks the model\\nto concatenate the last letters of words in a name (e.g.,\\n“Amy Brown”→“yn” ). It is a more challenging version\\nof ﬁrst letter concatenation, which language models can\\nalready perform without chain of thought.3We generate\\nfull names by randomly concatenating names from the\\ntop one-thousand ﬁrst and last names from name census\\ndata ( https://namecensus.com/ ).\\n•Coin ﬂip. This task asks the model to answer whether a\\ncoin is still heads up after people either ﬂip or don’t ﬂip\\nthe coin (e.g., “A coin is heads up. Phoebe ﬂips the coin.\\nOsvaldo does not ﬂip the coin. Is the coin still heads up?”\\n→“no” ).\\nAs the construction of these symbolic reasoning tasks is\\nwell-deﬁned, for each task we consider an in-domain test\\nset for which examples had the same number of steps as\\nthe training/few-shot exemplars, as well as an out-of-domain (OOD) test set, for which evaluation\\nexamples had more steps than those in the exemplars. For last letter concatenation, the model only\\nsees exemplars of names with two words, and then performs last letter concatenation on names with 3\\nand 4 words.4We do the same for the number of potential ﬂips in the coin ﬂip task. Our experimental\\nsetup uses the same methods and models as in the prior two sections. We again manually compose\\nchains of thought for the few-shot exemplars for each task, which are given in Figure 3.\\nResults. The results of these in-domain and OOD evaluations are shown in Figure 8 for PaLM,\\nwith results for LaMDA shown in Appendix Table 5. With PaLM 540B, chain-of-thought prompting\\nleads to almost 100% solve rates (note that standard prompting already solves coin ﬂip with PaLM\\n540, though not for LaMDA 137B). Note that these in-domain evaluations are “toy tasks” in the\\nsense that perfect solution structures are already provided by the chains of thought in the few-shot\\nexemplars; all the model has to do is repeat the same steps with the new symbols in the test-time\\nexample. And yet, small models still fail—the ability to perform abstract manipulations on unseen\\nsymbols for these three tasks only arises at the scale of 100B model parameters.\\nAs for the OOD evaluations, standard prompting fails for both tasks. With chain-of-thought prompting,\\nlanguage models achieve upward scaling curves (though performance is lower than in the in-domain\\nsetting). Hence, chain-of-thought prompting facilitates length generalization beyond seen chains of\\nthought for language models of sufﬁcient scale.\\n6 Discussion\\nWe have explored chain-of-thought prompting as a simple mechanism for eliciting multi-step rea-\\nsoning behavior in large language models. We ﬁrst saw that chain-of-thought prompting improves\\nperformance by a large margin on arithmetic reasoning, yielding improvements that are much stronger\\nthan ablations and robust to different annotators, exemplars, and language models (Section 3). Next,\\n3We tested 10 common names using GPT-3 davinci and it got all but one correct.\\n4For names of length longer than 2 words, we concatenate multiple ﬁrst and last names together.\\n8' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 7}\n",
      "page_content='experiments on commonsense reasoning underscored how the linguistic nature of chain-of-thought\\nreasoning makes it generally applicable (Section 4). Finally, we showed that for symbolic reasoning,\\nchain-of-thought prompting facilitates OOD generalization to longer sequence lengths (Section 5). In\\nall experiments, chain-of-thought reasoning is elicited simply by prompting an off-the-shelf language\\nmodel. No language models were ﬁnetuned in the process of writing this paper.\\nThe emergence of chain-of-thought reasoning as a result of model scale has been a prevailing theme\\n(Wei et al., 2022b). For many reasoning tasks where standard prompting has a ﬂat scaling curve, chain-\\nof-thought prompting leads to dramatically increasing scaling curves. Chain-of-thought prompting\\nappears to expand the set of tasks that large language models can perform successfully—in other\\nwords, our work underscores that standard prompting only provides a lower bound on the capabilities\\nof large language models. This observation likely raises more questions than it answers—for instance,\\nhow much more can we expect reasoning ability to improve with a further increase in model scale?\\nWhat other prompting methods might expand the range of tasks that language models can solve?\\nAs for limitations, we ﬁrst qualify that although chain of thought emulates the thought processes of\\nhuman reasoners, this does not answer whether the neural network is actually “reasoning,” which\\nwe leave as an open question. Second, although the cost of manually augmenting exemplars with\\nchains of thought is minimal in the few-shot setting, such annotation costs could be prohibitive for\\nﬁnetuning (though this could potentially be surmounted with synthetic data generation, or zero-shot\\ngeneralization). Third, there is no guarantee of correct reasoning paths, which can lead to both correct\\nand incorrect answers; improving factual generations of language models is an open direction for\\nfuture work (Rashkin et al., 2021; Ye and Durrett, 2022; Wiegreffe et al., 2022, inter alia ). Finally,\\nthe emergence of chain-of-thought reasoning only at large model scales makes it costly to serve in\\nreal-world applications; further research could explore how to induce reasoning in smaller models.\\n7 Related Work\\nThis work is inspired by many research areas, which we detail in an extended related work section\\n(Appendix C). Here we describe two directions and associated papers that are perhaps most relevant.\\nThe ﬁrst relevant direction is using intermediate steps to solve reasoning problems. Ling et al. (2017)\\npioneer the idea of using natural language rationales to solve math word problems through a series\\nof intermediate steps. Their work is a remarkable contrast to the literature using formal languages\\nto reason (Roy et al., 2015; Chiang and Chen, 2019; Amini et al., 2019; Chen et al., 2019). Cobbe\\net al. (2021) extend Ling et al. (2017) by creating a larger dataset and using it to ﬁnetune a pretrained\\nlanguage model rather than training a model from scratch. In the domain of program synthesis,\\nNye et al. (2021) leverage language models to predict the ﬁnal outputs of Python programs via\\nﬁrst line-to-line predicting the intermediate computational results, and show that their step-by-step\\nprediction method performs better than directly predicting the ﬁnal outputs.\\nNaturally, this paper also relates closely to the large body of recent work on prompting. Since the\\npopularization of few-shot prompting as given by Brown et al. (2020), several general approaches\\nhave improved the prompting ability of models, such as automatically learning prompts (Lester et al.,\\n2021) or giving models instructions describing a task (Wei et al., 2022a; Sanh et al., 2022; Ouyang\\net al., 2022). Whereas these approaches improve or augment the input part of the prompt (e.g.,\\ninstructions that are prepended to inputs), our work takes the orthogonal direction of augmenting the\\noutputs of language models with a chain of thought.\\n8 Conclusions\\nWe have explored chain-of-thought prompting as a simple and broadly applicable method for enhanc-\\ning reasoning in language models. Through experiments on arithmetic, symbolic, and commonsense\\nreasoning, we ﬁnd that chain-of-thought reasoning is an emergent property of model scale that allows\\nsufﬁciently large language models to perform reasoning tasks that otherwise have ﬂat scaling curves.\\nBroadening the range of reasoning tasks that language models can perform will hopefully inspire\\nfurther work on language-based approaches to reasoning.\\n9' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 8}\n",
      "page_content='Acknowledgements\\nWe thank Jacob Devlin, Claire Cui, Andrew Dai, and Ellie Pavlick for providing feedback on the\\npaper. We thank Jacob Austin, Yuhuai Wu, Henryk Michalewski, Aitor Lewkowycz, Charles Sutton,\\nand Aakanksha Chowdhery for helpful discussions. We thank Sid Maxwell for notifying us about a\\nmistake in the manual error analysis in the original manuscript.\\nReferences\\nMichael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea\\nFinn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, et al. 2022. Do as I can, not as I\\nsay: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691 .\\nAida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh\\nHajishirzi. 2019. MathQA: Towards interpretable math word problem solving with operation-\\nbased formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and\\nShort Papers) , Minneapolis, Minnesota. Association for Computational Linguistics.\\nDaniel Andor, Luheng He, Kenton Lee, and Emily Pitler. 2019. Giving BERT a calculator: Finding\\noperations and arguments with reading comprehension. EMNLP .\\nJacob Andreas, Dan Klein, and Sergey Levine. 2018. Learning with latent language. NAACL .\\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\\nEllen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. 2021. Program synthesis with large language\\nmodels. arXiv preprint arXiv:2108.07732 .\\nBIG-bench collaboration. 2021. Beyond the imitation game: Measuring and extrapolating the\\ncapabilities of language models. In preparation .\\nKaj Bostrom, Xinyu Zhao, Swarat Chaudhuri, and Greg Durrett. 2021. Flexible generation of natural\\nlanguage deductions. EMNLP .\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\\nHerbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,\\nJeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\\nand Dario Amodei. 2020. Language models are few-shot learners. NeurIPS .\\nJonathon Cai, Richard Shin, and Dawn Song. 2017. Making neural programming architectures\\ngeneralize via recursion. ICLR .\\nOana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom. 2018. e-SNLI:\\nNatural language inference with natural language explanations. NeurIPS .\\nHoward Chen, Jacqueline He, Karthik Narasimhan, and Danqi Chen. 2022. Can rationalization\\nimprove robustness? NAACL .\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\\nKaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating\\nlarge language models trained on code. arXiv preprint arXiv:2107.03374 .\\nXinyun Chen, Chen Liang, Adams Wei Yu, Denny Zhou, Dawn Song, and Quoc V . Le. 2019. Neural\\nsymbolic reader: Scalable integration of distributed and symbolic representations for reading\\ncomprehension. ICLR .\\nTing-Rui Chiang and Yun-Nung Chen. 2019. Semantically-aligned equation generation for solving\\nand reasoning math word problems. In Proceedings of the 2019 Conference of the North Ameri-\\ncan Chapter of the Association for Computational Linguistics: Human Language Technologies,\\nVolume 1 (Long and Short Papers) , pages 2656–2668, Minneapolis, Minnesota. Association for\\nComputational Linguistics.\\n10' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 9}\n",
      "page_content='Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over\\nlanguage. IJCAI .\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher\\nHesse, and John Schulman. 2021. Training veriﬁers to solve math word problems. arXiv preprint\\narXiv:2110.14168 .\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of\\ndeep bidirectional transformers for language understanding. NAACL .\\nHonghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, and Denny Zhou. 2019. Neural\\nlogic machines. ICLR .\\nDheeru Dua, Sameer Singh, and Matt Gardner. 2020. Beneﬁts of intermediate annotations in reading\\ncomprehension. ACL.\\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021. Did\\naristotle use a laptop? A question answering benchmark with implicit reasoning strategies. TACL .\\nYuling Gu, Bhavana Dalvi Mishra, and Peter Clark. 2022. DREAM: Uncovering mental models\\nbehind language models. NAACL .\\nBraden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, and Christopher\\nRé. 2018. Training classiﬁers with natural language explanations. ACL.\\nPeter Hase and Mohit Bansal. 2022. When can models learn from explanations? a formal framework\\nfor understanding the roles of explanation data. ACL.\\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song,\\nand Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. arXiv\\npreprint arXiv:2103.03874 .\\nMohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. Learning\\nto solve arithmetic word problems with verb categorization. EMNLP .\\nZhanming Jie, Jierui Li, and Wei Lu. 2022. Learning to reason deductively: Math word problem\\nsolving as complex relation extraction. arXiv preprint arXiv:2203.10316 .\\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child,\\nScott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language\\nmodels. arXiv preprint arXiv:2001.08361 .\\nRik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016.\\nMAWPS: A math word problem repository. NAACL .\\nAndrew K. Lampinen, Ishita Dasgupta, Stephanie C.Y . Chan, Kory Matthewson, Michael Henry\\nTessler, Antonia Creswell, James L. McClelland, Jane X. Wang, and Felix Hill. 2022. Can language\\nmodels learn from explanations in context? arXiv preprint arXiv:2204.02329 .\\nYihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,\\nand Ee-Peng Lim. 2021. MWPToolkit: An open-source framework for deep learning-based math\\nword problem solvers. arXiv preprint arXiv:2109.00799 .\\nTeven Le Scao and Alexander Rush. 2021. How many data points is a prompt worth? NAACL .\\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efﬁcient\\nprompt tuning. EMNLP .\\nIddo Lev, Bill MacCartney, Christopher Manning, and Roger Levy. 2004. Solving logic puzzles:\\nFrom robust processing to precise semantics. Proceedings of the 2nd Workshop on Text Meaning\\nand Interpretation .\\nXiang Lisa Li and Percy Liang. 2021. Preﬁx-tuning: Optimizing continuous prompts for generation.\\nACL.\\n11' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 10}\n",
      "page_content='Zhengzhong Liang, Steven Bethard, and Mihai Surdeanu. 2021. Explainable multi-hop verbal\\nreasoning through internal monologue. NAACL .\\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program induction by rationale\\ngeneration: Learning to solve and explain algebraic word problems. ACL.\\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021.\\nPre-train, prompt, and predict: A systematic survey of prompting methods in natural language\\nprocessing. arXiv preprint arXiv:2107.13586 .\\nBodhisattwa Prasad Majumder, Oana-Maria Camburu, Thomas Lukasiewicz, and Julian McAuley.\\n2021. Rationale-inspired natural language explanations with commonsense. arXiv preprint\\narXiv:2106.13876 .\\nAna Marasovi ´c, Iz Beltagy, Doug Downey, and Matthew E Peters. 2022. Few-shot self-rationalization\\nwith natural language prompts. NAACL Findings .\\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. On faithfulness and\\nfactuality in abstractive summarization. In ACL.\\nShen Yun Miao, Chao Chun Liang, and Keh Yih Su. 2020. A diverse corpus for evaluating and\\ndeveloping English math word problem solvers. ACL.\\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke\\nZettlemoyer. 2022. Rethinking the role of demonstrations: What makes in-context learning work?\\narXiv preprint arXiv:2202.12837 .\\nSharan Narang, Colin Raffel, Katherine Lee, Adam Roberts, Noah Fiedel, and Karishma Malkan.\\n2020. WT5?! Training text-to-text models to explain their predictions. arXiv preprint\\narXiv:2004.14546 .\\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\\nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work:\\nScratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114 .\\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong\\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to\\nfollow instructions with human feedback. arXiv preprint arXiv:2203.02155 .\\nArkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021. Are NLP models really able to solve\\nsimple math word problems? NAACL .\\nMatthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and\\nLuke Zettlemoyer. 2018. Deep contextualized word representations. NAACL .\\nXinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and\\nWeizhu Chen. 2022. Reasoning like program executors. arXiv preprint arXiv:2201.11473 .\\nPiotr Pi˛ ekos, Mateusz Malinowski, and Henryk Michalewski. 2021. Measuring and improving\\nBERT’s mathematical abilities by predicting the order of reasoning. ACL.\\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John\\nAslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling language models:\\nMethods, analysis & insights from training Gopher. arXiv preprint arXiv:2112.11446 .\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi\\nZhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a uniﬁed\\ntext-to-text transformer. Journal of Machine Learning Research , 21:1–67.\\nDheeraj Rajagopal, Vidhisha Balachandran, Eduard H. Hovy, and Yulia Tsvetkov. 2021. SelfExplain:\\nA self-explaining architecture for neural text classiﬁers. EMNLP .\\nNazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain\\nyourself! Leveraging language models for commonsense reasoning. ACL.\\n12' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 11}\n",
      "page_content='Qiu Ran, Yankai Lin, Peng Li, Jie Zhou, and Zhiyuan Liu. 2019. NumNet: Machine reading\\ncomprehension with numerical reasoning. EMNLP .\\nHannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Michael Collins, Dipanjan Das, Slav Petrov,\\nGaurav Singh Tomar, Iulia Turc, and David Reitter. 2021. Measuring attribution in natural language\\ngeneration models. arXiv preprint arXiv:2112.12870 .\\nGabriel Recchia. 2021. Teaching autoregressive language models complex tasks by demonstration.\\narXiv preprint arXiv:2109.02102 .\\nEmily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, and Jason Wei. 2022.\\nA recipe for arbitrary text style transfer with large language models. ACL.\\nLaria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond\\nthe few-shot paradigm. Extended Abstracts of the 2021 CHI Conference on Human Factors in\\nComputing Systems .\\nSubhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. EMNLP .\\nSubhro Roy, Tim Vieira, and Dan Roth. 2015. Reasoning about Quantities in Natural Language.\\nTACL .\\nMohammed Saeed, Naser Ahmadi, Preslav Nakov, and Paolo Papotti. 2021. RuleBERT: Teaching\\nsoft rules to pre-trained language models. EMNLP .\\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai,\\nAntoine Chafﬁn, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2022. Multitask prompted\\ntraining enables zero-shot task generalization. ICLR .\\nJianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, and Qun Liu. 2021.\\nGenerate & rank: A multi-task framework for math word problems. In Findings of the Association\\nfor Computational Linguistics: EMNLP 2021 .\\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A\\nquestion answering challenge targeting commonsense knowledge. NAACL .\\nAlon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, and Jonathan Berant. 2020. Leap-of-\\nthought: Teaching pre-trained models to systematically reason over implicit knowledge. NeurIPS .\\nAlon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and\\nJonathan Berant. 2021. CommonsenseQA 2.0: Exposing the limits of ai through gamiﬁcation.\\nNeurIPS Track on Datasets and Benchmarks .\\nYi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven\\nZheng, Neil Houlsby, and Donald Metzler. 2022. Unifying language learning paradigms. arXiv\\npreprint arXiv:2205.05131 .\\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze\\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. LaMDA: Language models for\\ndialog applications. arXiv preprint arXiv:2201.08239 .\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022a.\\nSelf-consistency improves chain of thought reasoning in language models. arXiv preprint\\narXiv:2203.11171 .\\nYizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana\\nArunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022b.\\nBenchmarking generalization via in-context instructions on 1,600+ language tasks. arXiv preprint\\narXiv:2204.07705 .\\nJason Wei, Maarten Bosma, Vincent Y . Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\\nAndrew M. Dai, and Quoc V . Le. 2022a. Finetuned language models are zero-shot learners. ICLR .\\n13' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 12}\n",
      "page_content='Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,\\nMaarten Bosma, Denny Zhou, Donald Metzler, et al. 2022b. Emergent abilities of large language\\nmodels. Transactions on Machine Learning Research .\\nSarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark Riedl, and Yejin Choi. 2022. Reframing\\nhuman-AI collaboration for generating free-text explanations. NAACL .\\nSarah Wiegreffe and Ana Marasovi ´c. 2021. Teach me to explain: A review of datasets for explainable\\nNLP. NeurIPS .\\nSarah Wiegreffe, Ana Marasovi ´c, and Noah A. Smith. 2021. Measuring association between labels\\nand free-text rationales. EMNLP .\\nTongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and\\nCarrie J Cai. 2022a. PromptChainer: Chaining large language model prompts through visual\\nprogramming. CHI Extended Abstracts .\\nTongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b. AI chains: Transparent and controllable\\nhuman-AI interaction by chaining large language model prompts. CHI.\\nYujun Yan, Kevin Swersky, Danai Koutra, Parthasarathy Ranganathan, and Milad Hashemi. 2020.\\nNeural execution engines: Learning to execute subroutines. NeurIPS .\\nHuihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin, and Xiang Ren. 2021. Reﬁning language models\\nwith compositional explanations. NeurIPS .\\nXi Ye and Greg Durrett. 2022. The unreliability of explanations in few-shot in-context learning.\\narXiv preprint arXiv:2205.03401 .\\nYordan Yordanov, Vid Kocijan, Thomas Lukasiewicz, and Oana-Maria Camburu. 2021. Few-shot\\nout-of-domain transfer learning of natural language explanations. arXiv preprint arXiv:2112.06204 .\\nOmar Zaidan, Jason Eisner, and Christine Piatko. 2007. Using “annotator rationales” to improve\\nmachine learning for text categorization. NAACL .\\nWojciech Zaremba and Ilya Sutskever. 2014. Learning to execute. arXiv preprint arXiv:1410.4615 .\\nEric Zelikman, Yuhuai Wu, and Noah D. Goodman. 2022. STaR: Bootstrapping reasoning with\\nreasoning. arXiv preprint arXiv:2203.14465 .\\nTony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use:\\nImproving few-shot performance of language models. ICML .\\nWangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun, Chenyan Xiong, and\\nJian Tang. 2020. Towards interpretable natural language understanding with explanations as latent\\nvariables. NeurIPS .\\n14' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 13}\n",
      "page_content='Checklist\\n1. For all authors...\\n(a)Do the main claims made in the abstract and introduction accurately reﬂect the paper’s\\ncontributions and scope? [Yes]\\n(b)Did you describe the limitations of your work? [Yes] See Section 6 and Appendix A.2.\\n(c)Did you discuss any potential negative societal impacts of your work? [Yes] We don’t\\nexpect negative societal impacts as a direct result of the contributions in our paper. One\\nconsideration, however, is that generated chain of thought is not always factual, which\\nis noted as a limitation in Appendix D.1 (and note that we do not suggest using such\\nchains of thought in a factual manner or in any real-world scenario).\\n(d)Have you read the ethics review guidelines and ensured that your paper conforms to\\nthem? [Yes]\\n2. If you are including theoretical results...\\n(a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n(b) Did you include complete proofs of all theoretical results? [N/A]\\n3. If you ran experiments...\\n(a)Did you include the code, data, and instructions needed to reproduce the main experi-\\nmental results (either in the supplemental material or as a URL)? [Yes] We included\\ninputs, outputs, and targets for LaMDA and GPT-3 in the supplementary material.\\nAlthough we use proprietary models, we GPT-3 results are fully reproducible. Repro-\\nducibility is further discussed in Appendix E.1.\\n(b)Did you specify all the training details (e.g., data splits, hyperparameters, how they\\nwere chosen)? [Yes] Data splits were speciﬁed, N/A for hyperparams.\\n(c)Did you report error bars (e.g., with respect to the random seed after running exper-\\niments multiple times)? [Yes] Standard deviation for multiple seeds using LaMDA\\n137B, where each seed is a different random order of exemplars, is given in Table 6\\nand Table 7.\\n(d)Did you include the total amount of compute and the type of resources used (e.g., type\\nof GPUs, internal cluster, or cloud provider)? [Yes] Type of resources are described in\\nAppendix E.2, though we did not estimate the total amount of compute.\\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n(a)If your work uses existing assets, did you cite the creators? [Yes] We used two models\\nthat we anonymized based on the recommendation of the NeurIPS chairs. These models\\nwill be cited in the camera-ready version of the paper.\\n(b) Did you mention the license of the assets? [Yes] See Appendix E.3.\\n(c)Did you include any new assets either in the supplemental material or as a URL? [Yes]\\nThe coinﬂip and last letter concatenation datasets are the only new assets, and they are\\ngiven in the Supplementary Materials.\\n(d)Did you discuss whether and how consent was obtained from people whose data you’re\\nusing/curating? [N/A] No human data collected.\\n(e)Did you discuss whether the data you are using/curating contains personally identiﬁable\\ninformation or offensive content? [N/A] No human data collected.\\n5. If you used crowdsourcing or conducted research with human subjects...\\n(a)Did you include the full text of instructions given to participants and screenshots, if\\napplicable? [N/A]\\n(b)Did you describe any potential participant risks, with links to Institutional Review\\nBoard (IRB) approvals, if applicable? [N/A]\\n(c)Did you include the estimated hourly wage paid to participants and the total amount\\nspent on participant compensation? [N/A]\\n15' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 14}\n",
      "page_content='A Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe ﬁnding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer beneﬁts such as improved\\nperformance and sample efﬁciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The “other category” included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters ﬁxed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were ﬁxed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often conﬂated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B ﬁxes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B ﬁxes 12 of them)Other\\n(62B made 7 errors of this type, 540B ﬁxes 4 of them)Types of errors made by a 62B language model:Errors ﬁxed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B ﬁxed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The ﬁrst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires sufﬁcient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a ﬁnal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a ﬁnal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 15}\n",
      "page_content=\"Tracy used a piece of wire 4 feet long to support tomato plants in the garden. The wire was cut into pieces 6 inches long. How many pieces did she obtain?She cut the wire into 6 inch pieces. This means she got 4 * 6 = 24 pieces. The answer is 24. (Incorrect: semantic understanding error)62B Model OutputQuestion540B Model OutputThe wire was 4 feet long. This means it was 4 * 12 = 48 inches long. It was cut into pieces 6 inches long. This means she obtained 48 / 6 = 8 pieces. The answer is 8. (Correct)Tom's ship can travel at 10 miles per hour. He is sailing from 1 to 4 PM. He then travels back at a rate of 6 mph. How long does it take him to get back?He travels from 1 to 4 PM. That means he travels for 3 hours. He travels back at 6 mph. That means he travels for 3 * 6 = 18 miles. The answer is 18. (Incorrect: semantic understanding error)He travels at 10 mph from 1 to 4 PM. This means he travels 3 hours. 3 hours at 10 mph means he travels 3 * 10 = 30 miles. He then travels back at 6 mph. This means he travels 6 miles per hour. He has to travel 30 miles, so it takes him 30 / 6 = 5 hours. The answer is 5. (Correct)Stephen placed an online order for groceries. His final bill came to $40.00. Because this was through a delivery vendor, they tacked on a 25% fee to his final total and charged him $3.00 in delivery fees. Stephen also added a $4.00 tip. After the extra fees, what was the final price of Stephen's groceries?The final price of Stephen's groceries was $40.00. The delivery vendor added 25% to the final total, so the final total was 125% of $40.00. This means the final total was 125% * $40.00 = $50.00. The delivery vendor also charged $3.00 in delivery fees. So the final price of Stephen's groceries was $50.00 + $3.00 = $53.00. The answer is $53.00. (Incorrect: one step missing error)Stephen's bill was $40.00. The delivery vendor added 25% to the bill. This means the bill was increased by 25% of $40.00. This is 0.25 * $40.00 = $10.00. The delivery fee was $3.00. The tip was $4.00. So the total bill was $40.00 + $10.00 + $3.00 + 540b model $4.00 = $57.00. The answer is 57. (Correct)There are four schools competing at a basketball tournament. Each school has sent a girls’ basketball team and a boys’ basketball team and each team has 5 players each. Each school has also sent a coach for each team. In total, how many people have all of the schools sent?There are 4 schools. Each school has sent a girls’ basketball team and a boys’ basketball team. Each team has 5 players each. That means there are 4 * 2 * 5 = 40 players. Each team has a coach. That means there are 40 + 4 = 44 coaches. The answer is 44. (Incorrect: one step missing error)Each school has sent 2 teams, each with 5 players. This means each school has sent 2 * 5 = 10 players. Each school has also sent 2 coaches. This means each school has sent 10 + 2 = 12 people. There are 4 schools, so in total all of the schools have sent 4 * 12 = 48 people. The answer is 48. (Correct)62B Model Output\\n62B Model Output\\n62B Model Output540B Model Output\\n540B Model Output\\n540B Model OutputQuestion\\nQuestion\\nQuestionFigure 10: Examples of semantic understanding and one-step missing errors that were ﬁxed by\\nscaling PaLM from 62B to 540B.\\nA.2 What is the role of prompt engineering?\\nOne of the key considerations of prompting is sensitivity to the exact prompt. There is no shortage\\nof work showing that prompts affect language models in unexpected ways (Min et al., 2022). The\\ngeneral way that we created chain of thought annotations was by taking eight exemplars from the\\ntraining set and decomposing the reasoning process into multiple steps leading to the ﬁnal answer.\\nExamples of chain of thought annotations are provided in Figure 3, with full prompts given in\\nAppendix G. To analyze how sensitive chain of thought is to prompt engineering, we performed\\nrobustness experiments with respect to various factors.\\n•Different annotators. We ﬁrst analyze robustness to three different annotators (Section 3.4 and\\nFigure 6). Although there is notable variance in performance (which we will discuss later), chain\\nof thought performed better than the baseline by a large margin for all three annotators on eight\\ndatasets in arithmetic, commonsense, and symbolic reasoning (Table 6 and Table 7). Similar to the\\nannotation process in Cobbe et al. (2021), annotators were not given speciﬁc instructions about\\n17\" metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 16}\n",
      "page_content='how to write the chain of thought annotations other than to simply write the step-by-step reasoning\\nprocess that led to the ﬁnal answer. Thus, the annotations were written in each annotator’s own\\nlinguistic “chain of thought” writing style.\\n•Annotators without machine learning background. The GSM8K dataset (Cobbe et al., 2021)\\nconveniently provides a training set with reasoning chains written by crowd compute workers,\\nwhich enables us to investigate whether chain of thought still works with reasoning chains from an\\nindependent source without a background in machine learning. So we randomly sampled three sets\\nof eight exemplars with chains of thought from GSM8K. These chain of thought annotations also\\noutperformed the baseline by a large margin for all four arithmetic datasets (Table 6), indicating\\nthat chain of thought is not dependent on a particular set of annotators.\\n•Different exemplars. The different GSM8K exemplars experiment above (Table 6) also shows\\nthat chain-of-thought prompting works for different sets of exemplars. Notably, we test every set of\\nexemplars on all four arithmetic datasets (instead of picking exemplars from the training set for\\neach dataset), which suggests that the exemplars do not necessarily have to come from the same\\ndataset distribution as the test examples.\\n•Different order of exemplars. Prior work has shown that in some cases (e.g., classiﬁcation) even\\nthe order of prompts matter—varying the permutation of few-shot exemplars can cause the accuracy\\nof GPT-3 on SST-2 to range from near chance (54.3%) to near SOTA (93.4%) (Zhao et al., 2021).\\nWe show the standard deviation of performance from different exemplars in Table 6 and Table 7.\\nStandard deviations with respect to prompt order are relatively minimal in almost all cases. The\\none exception is the coin ﬂip task, for which exemplar orders have high standard deviation, likely\\nfor the reason cited in Zhao et al. (2021)—for classiﬁcation, many exemplars of the same category\\nin a row biases the model outputs).\\n•Different number of exemplars. We also found that gains from chain-of-thought prompting\\ngenerally still held when there was a varying number of few-shot exemplars. This is shown for ﬁve\\ndatasets in Figure 11 (we did not have the compute to run this for all datasets). We also found in\\npreliminary experiments that further increasing the number of exemplars in standard prompting\\ndid not lead to signiﬁcant gains (e.g., increasing from 8 to 16 exemplars did not improve the\\nperformance of standard prompting enough to catch up with chain-of-thought prompting).\\n•Different language models. Another interesting question is whether certain prompts that work\\nbetter for one model work better for other large language models. We ﬁnd that with the same\\nprompts, chain-of-thought prompting improves performance across all three models (LaMDA,\\nGPT-3, and PaLM) for all datasets except CSQA and StrategyQA for GPT-3 (Table 1, Table 4,\\nTable 5). The fact that gains from chain of thought did not transfer perfectly among models is\\na limitation; further work could investigate why how different pre-training datasets and model\\narchitectures affect the performance gain from chain-of-thought prompting.\\nPrompt engineering still matters, though. Although the results are relatively robust to the prompt\\nfor arithmetic reasoning, we want to be clear that prompt engineering still does matter, and can\\nimprove performance signiﬁcantly in many cases. Though most chain of thought annotations\\noutperform standard prompting, there is large variation in many cases. For instance, for the coin\\nﬂip task, the performance varied from 99.6% for Annotator A to 71.4% for Annotator C, though\\nboth were above standard prompting = 50.0% (see Table 7). There are even tasks where prompt\\nengineering is a requirement for good performance. In preliminary experiments, we tried using chain\\nof thought to enable language models to reverse the order of a list of 5 items. While two co-authors\\nwere not able to write chain of thought prompts that solved the task despite their best attempts, a third\\nco-author was able to write a chain of thought that perfectly solved the task.\\nHow to generate chain of thought annotations in a robust fashion could be an interesting direction\\nfor future work. For instance, an idea here could be to use a large language model to automatically\\ngenerate chains of thought via prompting (and potentially optimize this over a validation set).\\nA.3 Will chain-of-thought prompting improve performance for my task of interest?\\nWhile chain-of-thought prompting is in principle applicable for any text-to-text task, it is more\\nhelpful for some tasks than others. Based on the experiments in this paper, our intuition is that chain\\nof thought helps the most when three conditions are met: (1) the task is challenging and requires\\n18' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 17}\n",
      "page_content='multi-step reasoning, (2) a large language model is used, and (3) the scaling curve is relatively ﬂat.\\nConversely, the beneﬁts are smaller when one or more of these conditions are not met.\\nThese intuitions are perhaps supported by the arithmetic reasoning results. The performance gain\\nfrom chain-of-thought prompting is largest for PaLM 540B on GSM8K (challenging multi-step\\nproblems, ﬂat scaling curve), which meets these conditions. The performance gain is small for the\\nsubsets of MAWPS that only require one or two steps (SingleOP, SingleEq, and AddSub), for which\\nPaLM 540B already achieves performance of 90% or higher (and it is also generally true that there is\\nless headroom for improvement when performance is already strong).\\nAlthough in this paper we focused on multi-step reasoning tasks (arithmetic, commonsense, and\\nsymbolic), chain-of-thought prompting can potentially be applied to any task for which humans use a\\n“chain of thought” to solve (at least in principle). We leave the empirical evaluation of chain-of-thought\\nprompting on such diverse tasks (e.g., machine translation, etc.) to future work.\\nA.4 Why is prompting with the equation only not enough for some arithmetic reasoning\\ndatasets?\\nPrompting with the equation only as an intermediate step does help on many datasets, especially when\\nthe datasets only require a few reasoning steps (SV AMP, ASDiv, MAWPS). For GSM8K, however,\\nusing the equation only did not improve performance substantially. Based on qualitative analysis, we\\nbelieve that these questions are too semantically challenging for the model to directly translate them\\ninto a math equation. Consider this example from LaMDA 137B:\\nQUESTION :Mike plays ping pong for 40 minutes. In the ﬁrst 20 minutes, he scores 4\\npoints. In the second 20 minutes, he scores 25% more points. How many total points did he\\nscore?\\nEQUATION ONLY (WRONG ANSWER ):(4 + 20 * 0.25) = 6. The answer is 6.\\nCHAIN OF THOUGHT (CORRECT ):Mike played ping pong for 40 minutes. In the ﬁrst\\n20 minutes, he scored 4 points. In the second 20 minutes, he scored 25% more points. So\\nhe scored 25% more in the second 20 minutes. 4 x 1.25 = 5. So he scored 5 points in the\\nsecond 20 minutes. So he scored 9 points in total. The answer is 9.\\nIt is hard for the model to directly translate all of the semantics into a single equation, but chain of\\nthought allows it to better reason about each part of the question via intermediate steps in natural\\nlanguage.\\n19' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 18}\n",
      "page_content='B All Experimental Results\\nThis section contains tables for experimental results for varying models and model sizes, on all\\nbenchmarks, for standard prompting vs. chain-of-thought prompting.\\nFor the arithmetic reasoning benchmarks, some chains of thought (along with the equations produced)\\nwere correct, except the model performed an arithmetic operation incorrectly. A similar observation\\nwas made in Cobbe et al. (2021). Hence, we can further add a Python program as an external\\ncalculator (using the Python eval function) to all the equations in the generated chain of thought.\\nWhen there are multiple equations in a chain of thought, we propagate the external calculator results\\nfrom one equation to the following equations via string matching. As shown in Table 1, we see that\\nadding a calculator signiﬁcantly boosts performance of chain-of-thought prompting on most tasks.\\nTable 1: Chain of thought prompting outperforms standard prompting for various large language\\nmodels on ﬁve arithmetic reasoning benchmarks. All metrics are accuracy (%). Ext. calc.: post-hoc\\nexternal calculator for arithmetic computations only. Prior best numbers are from the following. a:\\nCobbe et al. (2021). b&e: Pi et al. (2022), c: Lan et al. (2021), d: Pi˛ ekos et al. (2021).\\nPrompting GSM8K SV AMP ASDiv AQuA MAWPS\\nPrior best N/A (ﬁnetuning) 55a57.4b75.3c37.9d88.4e\\nUL2 20B Standard 4.1 10.1 16.0 20.5 16.6\\nChain of thought 4.4 (+0.3) 12.5 (+2.4) 16.9 (+0.9) 23.6 (+3.1) 19.1 (+2.5)\\n+ ext. calc 6.9 28.3 34.3 23.6 42.7\\nLaMDA 137B Standard 6.5 29.5 40.1 25.5 43.2\\nChain of thought 14.3 (+7.8) 37.5 (+8.0) 46.6 (+6.5) 20.6 (-4.9) 57.9 (+14.7)\\n+ ext. calc 17.8 42.1 53.4 20.6 69.3\\nGPT-3 175B Standard 15.6 65.7 70.3 24.8 72.7\\n(text-davinci-002) Chain of thought 46.9 (+31.3) 68.9 (+3.2) 71.3 (+1.0) 35.8 (+11.0) 87.1 (+14.4)\\n+ ext. calc 49.6 70.3 71.1 35.8 87.5\\nCodex Standard 19.7 69.9 74.0 29.5 78.7\\n(code-davinci-002) Chain of thought 63.1 (+43.4) 76.4 (+6.5) 80.4 (+6.4) 45.3 (+15.8) 92.6 (+13.9)\\n+ ext. calc 65.4 77.0 80.0 45.3 93.3\\nPaLM 540B Standard 17.9 69.4 72.1 25.2 79.2\\nChain of thought 56.9 (+39.0) 79.0 (+9.6) 73.9 (+1.8) 35.8 (+10.6) 93.3 (+14.2)\\n+ ext. calc 58.6 79.8 72.6 35.8 93.5\\n20' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 19}\n",
      "page_content='Table 2: Standard prompting versus chain of thought prompting on ﬁve arithmetic reasoning bench-\\nmarks. Note that chain of thought prompting is an emergent ability of model scale—it does not\\npositively impact performance until used with a model of sufﬁcient scale.\\nGSM8K SV AMP ASDiv AQuA MAWPS\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 4.1 4.4 10.1 12.5 16.0 16.9 20.5 23.6 16.6 19.1\\nLaMDA 420M 2.6 0.4 2.5 1.6 3.2 0.8 23.5 8.3 3.2 0.9\\n2B 3.6 1.9 3.3 2.4 4.1 3.8 22.9 17.7 3.9 3.1\\n8B 3.2 1.6 4.3 3.4 5.9 5.0 22.8 18.6 5.3 4.8\\n68B 5.7 8.2 13.6 18.8 21.8 23.1 22.3 20.2 21.6 30.6\\n137B 6.5 14.3 29.5 37.5 40.1 46.6 25.5 20.6 43.2 57.9\\nGPT 350M 2.2 0.5 1.4 0.8 2.1 0.8 18.1 8.7 2.4 1.1\\n1.3B 2.4 0.5 1.5 1.7 2.6 1.4 12.6 4.3 3.1 1.7\\n6.7B 4.0 2.4 6.1 3.1 8.6 3.6 15.4 13.4 8.8 3.5\\n175B 15.6 46.9 65.7 68.9 70.3 71.3 24.8 35.8 72.7 87.1\\nCodex - 19.7 63.1 69.9 76.4 74.0 80.4 29.5 45.3 78.7 92.6\\nPaLM 8B 4.9 4.1 15.1 16.8 23.7 25.2 19.3 21.7 26.2 30.5\\n62B 9.6 29.9 48.2 46.7 58.7 61.9 25.6 22.4 61.8 80.3\\n540B 17.9 56.9 69.4 79.0 72.1 73.9 25.2 35.8 79.2 93.3\\nTable 3: Standard prompting versus chain of thought prompting on the four subsets of the MAWPS\\nbenchmark. The point of stratifying the MAWPS benchmark is to show that performance gains are\\nminimal on easy one-step or two-step problems where large language models already achieve high\\nperformance (e.g., SingleOp, SingleEq, and AddSub).\\nSingleOp SingleEq AddSub MultiArith\\nModel standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 24.9 27.2 18.0 20.2 18.5 18.2 5.0 10.7\\nLaMDA 420M 2.8 1.0 2.4 0.4 1.9 0.7 5.8 1.5\\n2B 4.6 4.1 2.4 3.3 2.7 3.2 5.8 1.8\\n8B 8.0 7.0 4.5 4.4 3.4 5.2 5.2 2.4\\n68B 36.5 40.8 23.9 26.0 17.3 23.2 8.732.4\\n137B 73.2 76.2 48.8 58.7 43.0 51.9 7.644.9\\nGPT 350M 3.2 1.8 2.0 0.2 2.0 1.5 2.3 0.8\\n1.3B 5.3 3.0 2.4 1.6 2.3 1.5 2.2 0.5\\n6.7B 13.5 3.9 8.7 4.9 8.6 2.5 4.5 2.8\\n175B 90.9 88.8 82.7 86.6 83.3 81.3 33.8 91.7\\nCodex - 93.1 91.8 86.8 93.1 90.9 89.1 44.0 96.2\\nPaLM 8B 41.8 46.6 29.5 28.2 29.4 31.4 4.215.8\\n62B 87.9 85.6 77.2 83.5 74.7 78.2 7.373.7\\n540B 94.1 94.1 86.5 92.3 93.9 91.9 42.2 94.7\\n21' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 20}\n",
      "page_content='Table 4: Standard prompting versus chain of thought prompting on ﬁve commonsense reasoning\\nbenchmarks. Chain of thought prompting is an emergent ability of model scale—it does not positively\\nimpact performance until used with a model of sufﬁcient scale.\\nCSQA StrategyQA Date Sports SayCan\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 34.2 51.4 59.0 53.3 13.5 14.0 57.9 65.3 20.0 41.7\\nLaMDA 420M 20.1 19.2 46.4 24.9 1.9 1.6 50.0 49.7 7.5 7.5\\n2B 20.2 19.6 52.6 45.2 8.0 6.8 49.3 57.5 8.3 8.3\\n8B 19.0 20.3 54.1 46.8 9.5 5.4 50.0 52.1 28.3 33.3\\n68B 37.0 44.1 59.6 62.2 15.5 18.6 55.2 77.5 35.0 42.5\\n137B 53.6 57.9 62.4 65.4 21.5 26.8 59.5 85.8 43.3 46.6\\nGPT 350M 14.7 15.2 20.6 0.9 4.3 0.9 33.8 41.6 12.5 0.8\\n1.3B 12.0 19.2 45.8 35.7 4.0 1.4 0.0 26.9 20.8 9.2\\n6.7B 19.0 24.0 53.6 50.0 8.9 4.9 0.0 4.4 17.5 35.0\\n175B 79.5 73.5 65.9 65.4 43.8 52.1 69.6 82.4 81.7 87.5\\nCodex - 82.3 77.9 67.1 73.2 49.0 64.8 71.7 98.5 85.8 88.3\\nPaLM 8B 19.8 24.9 55.6 53.5 12.9 13.1 55.1 75.2 34.2 40.0\\n62B 65.4 68.1 58.4 63.4 29.8 44.7 72.1 93.6 65.8 70.0\\n540B 78.1 79.9 68.6 77.8 49.0 65.3 80.5 95.4 80.8 91.7\\nTable 5: Standard prompting versus chain of thought prompting enables length generalization to\\nlonger inference examples on two symbolic manipulation tasks.\\nLast Letter Concatenation Coin Flip (state tracking)\\n2 OOD: 3 OOD: 4 2 OOD: 3 OOD: 4\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 0.6 18.8 0.0 0.2 0.0 0.0 70.4 67.1 51.6 52.2 48.7 50.4\\nLaMDA 420M 0.3 1.6 0.0 0.0 0.0 0.0 52.9 49.6 50.0 50.5 49.5 49.1\\n2B 2.3 6.0 0.0 0.0 0.0 0.0 54.9 55.3 47.4 48.7 49.8 50.2\\n8B 1.5 11.5 0.0 0.0 0.0 0.0 52.9 55.5 48.2 49.6 51.2 50.6\\n68B 4.4 52.0 0.0 0.8 0.0 2.5 56.2 83.2 50.4 69.1 50.9 59.6\\n137B 5.8 77.5 0.034.4 0.013.5 49.0 99.6 50.7 91.0 49.1 74.5\\nPaLM 8B 2.6 18.8 0.0 0.0 0.0 0.2 60.0 74.4 47.3 57.1 50.9 51.8\\n62B 6.8 85.0 0.059.6 0.013.4 91.4 96.8 43.9 91.0 38.3 72.4\\n540B 7.6 99.4 0.294.8 0.063.0 98.1 100.0 49.3 98.6 54.8 90.2\\n22' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 21}\n",
      "page_content='Table 6: Ablation and robustness results for arithmetic reasoning datasets. Chain of thought generally\\noutperforms ablations by a large amount. “Equation only” performs in between standard prompting\\nand chain of thought prompting, as it allows for intermediate reasoning steps via equations but does\\nnot leverage natural language. Chain of thought prompting has variance (as expected) when used\\nwith prompts written by different annotators or when using other exemplars, but still outperforms\\nstandard prompting by a large margin. Standard deviation shown is for different order of few-shot\\nprompting exemplars, with ﬁve different random seeds. Results here are shown for LaMDA 137B, as\\nadditional queries for GPT-3 and PaLM are both limited and expensive.\\nGSM8K SV AMP ASDiv MAWPS\\nStandard prompting 6.5 ±0.4 29.5±0.6 40.1±0.6 43.2±0.9\\nChain of thought prompting 14.3 ±0.4 36.7±0.4 46.6±0.7 57.9±1.5\\nAblations\\n·equation only 5.4 ±0.2 35.1±0.4 45.9±0.6 50.1±1.0\\n·variable compute only 6.4 ±0.3 28.0±0.6 39.4±0.4 41.3±1.1\\n·reasoning after answer 6.1 ±0.4 30.7±0.9 38.6±0.6 43.6±1.0\\nRobustness\\n·different annotator (B) 15.5 ±0.6 35.2±0.4 46.5±0.4 58.2±1.0\\n·different annotator (C) 17.6 ±1.0 37.5±2.0 48.7±0.7 60.1±2.0\\n·intentionally concise style 11.1 ±0.3 38.7±0.8 48.0±0.3 59.6±0.7\\n·exemplars from GSM8K ( α) 12.6 ±0.6 32.8±1.1 44.1±0.9 53.9±1.1\\n·exemplars from GSM8K ( β) 12.7 ±0.5 34.8±1.1 46.9±0.6 60.9±0.8\\n·exemplars from GSM8K ( γ) 12.6 ±0.7 35.6±0.5 44.4±2.6 54.2±4.7\\nTable 7: Ablation and robustness results for four datasets in commonsense and symbolic reasoning.\\nChain of thought generally outperforms ablations by a large amount. Chain of thought prompting has\\nvariance (as expected) when used with prompts written by different annotators or when using other\\nexemplars, but still outperforms standard prompting by a large margin. Standard deviation shown\\nis for different order of few-shot prompting exemplars, with ﬁve different random seeds. Results\\nhere are shown for LaMDA 137B, as additional queries for GPT-3 and PaLM are both limited and\\nexpensive. The exception is that we run SayCan using PaLM here, as the SayCan evaluation set is\\nonly 120 examples and therefore less expensive to run multiple times.\\nCommonsense Symbolic\\nDate Sports SayCan Concat Coin\\nStandard prompting 21.5 ±0.6 59.5±3.0 80.8±1.8 5.8±0.6 49.0±2.1\\nChain of thought prompting 26.8 ±2.1 85.8±1.8 91.7±1.4 77.5±3.8 99.6±0.3\\nAblations\\n·variable compute only 21.3 ±0.7 61.6±2.2 74.2±2.3 7.2±1.6 50.7±0.7\\n·reasoning after answer 20.9 ±1.0 63.0±2.0 83.3±0.6 0.0±0.0 50.2±0.5\\nRobustness\\n·different annotator (B) 27.4 ±1.7 75.4±2.7 88.3±1.4 76.0±1.9 77.5±7.9\\n·different annotator (C) 25.5 ±2.5 81.1±3.6 85.0±1.8 68.1±2.2 71.4±11.1\\n23' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 22}\n",
      "page_content='C Extended Related Work\\nChain-of-thought prompting is a general approach that is inspired by several prior directions: prompt-\\ning, natural language explanations, program synthesis/execution, numeric and logical reasoning, and\\nintermediate language steps.\\nC.1 Prompting\\nThe recent success of large-scale language models has led to growing interest in improving their\\ncapability to perform tasks via prompting (Brown et al. (2020), and see Liu et al. (2021) for a\\nsurvey). This paper falls in the category of general prompting approaches, whereby input prompts are\\noptimized to allow a single large language model to better perform a variety of tasks (Li and Liang,\\n2021; Lester et al., 2021; Reif et al., 2022, inter alia ).\\nOne recent line of work aims to improve the ability of language models to perform a task by providing\\ninstructions that describe the task (Raffel et al., 2020; Wei et al., 2022a; Ouyang et al., 2022; Sanh\\net al., 2022; Wang et al., 2022b). This line of work is related because it also augments input–output\\npairs with meta-data. But whereas an instruction augments the input to a task (instructions are typically\\nprepended to the inputs), chain-of-thought prompting augments the outputs of language models.\\nAnother related direction is sequentially combining the outputs of language models; human–computer\\ninteraction (HCI) work (Wu et al., 2022a,b) has shown that combining sequential generations of\\nlanguage models improves task outcomes in a 20-person user study.\\nC.2 Natural language explanations\\nAnother closely related direction uses natural language explanations (NLEs), often with the goal of\\nimproving model interpretability (Zhou et al., 2020; Wiegreffe and Marasovi ´c, 2021, inter alia ). That\\nline of work typically focuses on natural language inference (Camburu et al., 2018; Yordanov et al.,\\n2021; Bostrom et al., 2021), and produces explanations either simultaneously to or after the ﬁnal\\nprediction (Narang et al., 2020; Majumder et al., 2021; Wiegreffe et al., 2021, 2022). By contrast,\\nthe chain of thought processing considered in this paper occurs before the ﬁnal answer. And while\\nNLE aims mostly to improve neural network interpretability (Rajagopal et al., 2021), the goal of\\nchain-of-thought prompting is to allow models to decompose multi-hop reasoning tasks into multiple\\nsteps—interpretability is just a side effect. Marasovi ´c et al. (2022) show that prompt-based ﬁnetuning\\nwith NLE improves NLI and classiﬁcation performance, though they largely focus on evaluating\\nexplanation plausibility. In comparison, our work focuses on a range of arithmetic, commonsense,\\nand symbolic tasks that require multi-hop reasoning.\\nC.3 Program synthesis and execution\\nUsing intermediate reasoning steps has a long history in program synthesis and execution (Zaremba\\nand Sutskever, 2014, inter alia ). Recent work along in this direction has included a number of\\narchitectural innovations (Cai et al., 2017; Dong et al., 2019; Yan et al., 2020), as well as the use of\\nlarge language models (Chen et al., 2021; Austin et al., 2021). The program execution work closest to\\nours is perhaps Nye et al. (2021), which show that large language models can perform up to 10-digit\\naddition, evaluate polynomials, and execute python programs. Whereas generating a program and\\nthen executing it can be viewed as a type of reasoning, our work generalizes such domain-speciﬁc\\nprimitives to natural language, which is open-domain and relevant to any text-to-text NLP task in\\nprinciple.\\nC.4 Numeric and logical reasoning\\nNumeric and logical reasoning has been a long-studied task in machine learning and natural language\\nprocessing (Lev et al., 2004, inter alia ). Recent work has also aimed to inject numeric reasoning\\nabilities in language models in various ways, such as augmenting BERT with a predeﬁned set of\\nexecutable operations (Andor et al., 2019), including a graph neural network (Ran et al., 2019), and\\nusing specialized training procedures (Pi˛ ekos et al., 2021). Another line of work aims to enable\\nlanguage models to perform logical or formal reasoning, often by verablizing the rules in natural\\nlanguage formal rules using language (Clark et al., 2020; Saeed et al., 2021; Liang et al., 2021).\\n24' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 23}\n",
      "page_content='Perhaps the most-related work here is Recchia (2021), which shows that ﬁnetuning enables longhand\\nmodule operations, which has previously been difﬁcult for performers. Whereas work in this direction\\nis often task-speciﬁc and uses ﬁnetuning, we show that chain-of-thought prompting works for a broad\\nrange of tasks without any ﬁnetuning.\\nC.5 Intermediate language steps\\nExtensive prior work has shown the beneﬁts of endowing neural networks with the ability to produce\\nintermediate steps via training or ﬁnetuning confers various beneﬁts in a range of scenarios. As\\nexamples, it has been shown that natural language intermediate steps can improve performance\\n(Zaidan et al., 2007; Yao et al., 2021; Hase and Bansal, 2022; Gu et al., 2022), improve robustness\\n(Chen et al., 2022), speed up training (Hancock et al., 2018), mitigate bias (Dua et al., 2020), and\\neven help in image and reinforcement learning settings (Andreas et al., 2018). To endow models with\\nthe ability to produce intermediate steps, prior work typically ﬁnetunes models on either manually\\nannotated training datasets (Camburu et al., 2018; Rajani et al., 2019, inter alia ) or generates synthetic\\ndatasets (Talmor et al., 2020; Zelikman et al., 2022). Compared with these training or ﬁnetuning\\nmethods, our work shows that various natural language reasoning abilities can be elicited in off-the-\\nshelf language models of sufﬁcient scale simply via prompting. This prompting setup is important\\nbecause it allows for intermediate step reasoning without a large number of labeled annotations, and\\nbecause a single model can perform a range of reasoning tasks without any gradient updates.\\nD Appendix: Additional Analysis\\nD.1 Correct Chain of Thought Analysis\\nAs mentioned in the main text, we analyze 50 chains of thought from LaMDA 137B that led to\\ncorrect answers in the GSM8K dataset. Of these 50, only one arrived at the correct answer through\\nincorrect reasoning (shown in Table 9: “correct by chance”). The other 49 had correct logic and\\nmath, with examples shown in Table 8. Five had minor imperfections while maintaining coherent and\\nunderstandable logic:\\n• One had underspeciﬁed statements (shown in Table 9: “correct but underspeciﬁed statements”).\\n•One made an unrelated but correct statement (shown in Table 9: “correct but unrelated statement”).\\n•Two had the correct logic but omitted speciﬁc steps in the equation, though it was still understand-\\nable (shown in Table 9: “correct but imperfect equation”).\\n•One had the correct math but inverted the semantics (shown in Table 9: “correct but inverted\\nsemantics”)\\nTable 8: Example of correct chains of thought produced by the model for the GSM8K dataset.\\nQUESTION :James decides to run 3 sprints 3 times a week. He runs 60 meters each sprint. How many total\\nmeters does he run a week?\\nMODEL ANSWER (CORRECT): James decides to run 3 sprints 3 times a week. He runs 60 meters each\\nsprint. So he runs 60 meters x 3 sprints x 3 times a week. That is 60 meters x 9. The answer is 540. ✓\\nQUESTION :Brandon’s iPhone is four times as old as Ben’s iPhone. Ben’s iPhone is two times older than Suzy’s\\niPhone. If Suzy’s iPhone is 1 year old, how old is Brandon’s iPhone?\\nMODEL ANSWER (CORRECT): Brandon’s iPhone is 4 times as old as Ben’s iPhone. Ben’s iPhone is 2\\ntimes older than Suzy’s iPhone. So Brandon’s iPhone is 4 x 2 = 8 times older than Suzy’s iPhone. Suzy’s iPhone\\nis 1 year old. So Brandon’s iPhone is 8 x 1 = 8 years old. The answer is 8. ✓\\nQUESTION :Jean has 30 lollipops. Jean eats 2 of the lollipops. With the remaining lollipops, Jean wants to\\npackage 2 lollipops in one bag. How many bags can Jean ﬁll?\\nMODEL ANSWER (CORRECT): Jean started with 30 lollipops. She ate 2 of them. So she has 28 lollipops\\nleft. She wants to package 2 lollipops in one bag. So she can package 28 / 2 = 14 bags. The answer is 14. ✓\\nAlthough we ﬁnd that chain-of-thought reasoning is mostly correct for math questions where the ﬁnal\\nanswer was correct, this is likely because it is hard to arrive at the correct ﬁnal answer by coincidence\\nfor free response questions. For multiple choice or binary classiﬁcation problems, it was much more\\n25' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 24}\n",
      "page_content='likely that models could arrive at the correct answer via an incorrect reasoning path (e.g., all the\\ncommmonsense reasoning datasets we evaluate). This is a limitation, and future work should perform\\nan analysis of the factuality of such chains of thought.\\nTable 9: Of 50 examples that the model got correct, there were 7 salient cases where the chain of\\nthought the model generated was imperfect. We found the other 43 to be equivalent to what a human\\nwould potentially generate as a ground truth.\\nQUESTION :There are 36 penguins sunbathing in the snow. One-third of them jump in and swim in the ocean.\\nAnother one-third go inside the cave to eat their dinner. How many penguins are still left sunbathing?\\nMODEL ANSWER (CORRECT BY CHANCE ):There are 36 penguins. One-third of them jump in and swim in\\nthe ocean. So that is 12 penguins. Another one-third go inside the cave to eat their dinner. So that is 12 penguins.\\nThe answer is 12.\\nQUESTION :John has 2 houses with 3 bedrooms each. Each bedroom has 2 windows each. There are an\\nadditional 4 windows in each house not connected to bedrooms. How many total windows are there between the\\nhouses?\\nMODEL ANSWER (CORRECT BUT UNDERSPECIFIED STATEMENTS ):There are 2 houses with 3 bedrooms\\neach. Each bedroom has 2 windows each. So there are 2 x 3 = 6 windows in each house. There are an additional\\n4 windows in each house not connected to bedrooms. So there are 4 + 4 = 8 windows in each house. So there are\\n6 x 2 = 12 windows in each house. So there are 12 + 8 = 20 windows in both houses. The answer is 20.\\nQUESTION :If Ann is 9 years old and her brother is twice her age, how old will her brother be in 3 years?\\nMODEL ANSWER (CORRECT BUT UNRELATED STATEMENT ):Ann is 9 years old. Her brother is twice her\\nage. So her brother is 18 years old. In 3 years, she will be 12. So her brother will be 18 + 3 = 21 years old. The\\nanswer is 21.\\nQUESTION :A local gas station is selling gas for $3.00 a gallon. An app company is offering $.20 cashback per\\ngallon if you ﬁll up at this station. If someone buys 10 gallons of gas, how much with their gas be, after the\\ncashback rewards?\\nMODEL ANSWER (CORRECT BUT IMPERFECT EQUATION ):The gas is originally 3 dollars per gallon. If\\nyou buy 10 gallons, that is 3 x 10 = 30 dollars. If you get 20 cents off per gallon, that is 20 x 10 = 2 dollars. So\\nthe total is 30 - 2 = 28 dollars. The answer is 28 dollars.\\nQUESTION :Nissa hires 60 seasonal workers to play elves in her department store’s Santa village. A third of\\nthe elves quit after children vomit on them, then 10 of the remaining elves quit after kids kick their shins. How\\nmany elves are left?\\nMODEL ANSWER (CORRECT BUT IMPERFECT EQUATION ):Nissa hires 60 seasonal workers. A third of\\nthem quit. So 60 - 1/3 = 40 elves are left. Then 10 elves quit. So 40 - 10 = 30 elves are left. The answer is 30\\nelves.\\nQUESTION :Grandma Jones baked 5 apple pies for the ﬁreman’s luncheon. She cut each pie into 8 pieces and\\nset the ﬁve pies out on the buffet table for the guests to serve themselves. At the end of the evening, after the\\nguests had taken and eaten their pieces of pie, there were 14 pieces of pie remaining. How many pieces were\\ntaken by the guests?\\nMODEL ANSWER (CORRECT BUT INVERTED SEMANTICS ):5 pies were baked and cut into 8 pieces each.\\nThe 5 pies were then served to the guests. 8 x 5 = 40 pieces of pie. The guests ate 14 pieces of pie. 40 - 14 = 26\\npieces of pie were left. The answer is 26. ✓\\n26' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 25}\n",
      "page_content='D.2 Incorrect Chain of Thought Analysis\\nWe also manually analyze 50 randomly sampled outputs of the model that were incorrect on GSM8K\\nfor LaMDA 137B. There are many ways that a chain of thought can be incorrect, making the design\\nof error categorization non-trivial. We decided to categorize errors into what changes are needed to\\nmake the chain of thought correct, with the goal of elucidating how the model can be improved in the\\nfuture.\\nWe found that many chains of thought can be made correct with one of the following three classes of\\nmodiﬁcation.\\n•Calculator error only. We found that 8% of the chains of thought were completely correct except\\nfor a calculator error—in other words, applying an external calculator to equations, as done in\\nCobbe et al. (2021), would make the chain of thought correct. An example of this type of error is\\nshown in Table 10: “calculator error only”. Indeed, the solve rate of chain-of-thought prompting\\non for LaMDA 137B GSM8K went up from 14.3% to 17.3% when we added a Python program\\nas an external calculator, as shown in Table 2. Also, 34% of the examples contained calculator\\nerrors in addition to other types of errors. However, we perform the rest of the error categorization\\nindependently of calculator errors.\\n•Symbol mapping error. We next found that 16% percent of the chains of thought were correct\\nexcept for what we call symbol mapping errors. We deﬁne a symbol mapping error as when the\\nchain of thought is correct except for the number symbols, and it could be made totally correct by\\nmodifying only the equations and not the words. As one might argue that they could simply place\\nthe correct ﬁnal equation in any chain of thought, we constrain this category to chains of thought\\nwhere the chain of thought can be modiﬁed to be a completely correct reasoning process (not just\\nﬁnal answer). An example of this error category is shown in Table 10: “symbol mapping error”.\\n•One step missing error. Our next category of error is chains of thought which were correct except\\nthat they were missing a single step. In other words, these chains of thoughts could be rewritten to\\nbe correct by adding in an additional reasoning step that was missed by the model. An example of\\nthis error category is shown in Table 10: “one step missing error”. We found that 22% percent of\\nthe errors fell into this category.\\nTable 10: Example of incorrect chains of thought, categorized as described in Appendix D.2.\\nQUESTION :Dan plants 3 rose bushes. Each rose bush has 25 roses. Each rose has 8 thorns. How many thorns\\nare there total?\\nMODEL ANSWER (INCORRECT ;CALCULATOR ERROR ONLY ):Dan plants 3 rose bushes. Each rose bush\\nhas 25 roses. Each rose has 8 thorns. So 3 x 25 x 8 = 300. The answer is 300. \\x17\\nEXPLANATION FOR ERROR CATEGORY :The produced chain of thought could be made correct just by\\nrunning the equation through an external calculator, instead of asking the model to do the computation.\\nQUESTION :Jill gets paid $20 per hour to teach and $30 to be a cheerleading coach. If she works 50 weeks a\\nyear, 35 hours a week as a teacher and 15 hours a week as a coach, what’s her annual salary?\\nMODEL ANSWER (INCORRECT ;SYMBOL MAPPING ERROR ):Jill gets paid 20 dollars per hour to teach\\nand 30 dollars per hour to be a cheerleading coach. If she works 50 weeks a year, 35 hours a week as a teacher\\nand 15 hours a week as a coach, then she works 50 x 35 = 1750 hours as a teacher and 15 x 30 = 450 hours as a\\ncoach. So she works 1750 + 450 = 2200 hours. She gets paid 20 dollars per hour for 1750 hours and 30 dollars\\nper hour for 450 hours. So her annual salary is 20 x 1750 + 30 x 450 = $36,500. The answer is $36,500. \\x17\\nEXPLANATION FOR ERROR CATEGORY :The model incorrectly mapped “15 x 30” instead of “15 x 50”, and\\nthe chain of thought would be made correct by ﬁxing just that one change (with an external calculator).\\nQUESTION :Kelian has two recipes for preparing dishes, one having 20 instructions and the second one having\\ntwice as many instructions as the ﬁrst one. How many instructions does Kelian have to read to prepare the two\\ndishes?\\nMODEL ANSWER (INCORRECT ;ONE STEP MISSING ERROR ):Kelian has two recipes. One has 20 instruc-\\ntions. The other has twice as many instructions as the ﬁrst one. So the second one has 40 instructions. So Kelian\\nhas to read 40 instructions to prepare the two dishes. The answer is 40. \\x17\\nEXPLANATION FOR ERROR CATEGORY :The model answer could be made correct just adding one additional\\nstep (in this case, adding 20 and 40).\\n27' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 26}\n",
      "page_content='We found that the remaining chains of thought (27 of 50; 54%) would require substantial edits to make\\ninto a correct chain of thought. Almost all cases here involved some error in semantic understanding\\n(see Table 11: “semantic understanding error”), and 8 of the 27 also had incoherent chain of thoughts,\\nmeaning that some statements in the generated chain of thought did not follow from prior ones or\\nviolated basic world knowledge (see Table 11: “incoherent chain of thought error”).\\nTable 11: Example of incorrect chains of thought, categorized as described in Appendix D.2. These\\nchains of thought had multiple mistakes that could not be ﬁxed with minor edits.\\nQUESTION :Gretchen has 110 coins. There are 30 more gold coins than silver coins. How many gold coins\\ndoes Gretchen have?\\nMODEL ANSWER (INCORRECT ;SEMANTIC UNDERSTANDING ERROR ):Gretchen has 110 coins. There\\nare 30 more gold coins than silver coins. So there are 110 - 30 = 80 silver coins. So there are 80 silver coins and\\n110 - 80 = 30 gold coins. The answer is 30. \\x17\\nEXPLANATION FOR ERROR CATEGORY :The model does not understand that 110 coins are in total and that\\nit must solve an equation to get the number of gold and silver coins.\\nQUESTION :In a dance class of 20 students, 20% enrolled in contemporary dance, 25% of the remaining\\nenrolled in jazz dance, and the rest enrolled in hip-hop dance. What percentage of the entire students enrolled in\\nhip-hop dance?\\nMODEL ANSWER (INCORRECT ;INCOHERENT CHAIN OF THOUGHT ERROR ):20% of the students en-\\nrolled in contemporary dance. 25% of the remaining students enrolled in jazz dance. The rest enrolled in hip-hop\\ndance. So the percentage of the entire students enrolled in hip-hop dance is the percentage of the students\\nenrolled in hip-hop dance, minus the percentage of the students enrolled in contemporary dance, minus the\\npercentage of the students enrolled in jazz dance. So the percentage of the entire students enrolled in hip-hop\\ndance is (25 + 20) - (25 + 20) = 100%. The answer is 100%. \\x17\\nEXPLANATION FOR ERROR CATEGORY :This chain of thought is incoherent in that the percent of entire\\nstudents enrolled in hip-hope dance cannot be the percent of student enrolled in hip-hop dance minus another\\nterm.\\nOverall, there are no guarantees that the reasoning processes generated by large language models\\nare coherent or factually correct, as underscored by the recent work evaluating the factuality of\\nlanguage model generations and explanations (Maynez et al., 2020; Rashkin et al., 2021; Ye and\\nDurrett, 2022; Marasovi ´c et al., 2022; Wiegreffe et al., 2022). Incorrect reasoning processes can lead\\nto both incorrect ﬁnal answers as well as accidentally correct ﬁnal answers (with accidentally correct\\nﬁnal answers being more likely for tasks such as binary classiﬁcation as opposed to free response).\\nImproving the factuality of language model generations with respect to context and world knowledge\\nis an important direction open problems in language model research and could also be expected to\\npotentially improve multi-step reasoning abilities of language models. One potential method for\\nimproving the quality of decoding could involve generating multiple reasoning paths and scoring\\neach of them with a veriﬁer, though this requires training the veriﬁer (Cobbe et al., 2021; Shen et al.,\\n2021; Thoppilan et al., 2022).\\nD.3 Additional Robustness Analysis\\nAs the experiments in the main paper use a ﬁxed number of few-shot exemplars (8; as constrained by\\nthe input length of 1024 tokens), we verify that the chain-of-thought prompting is robust to various\\nnumbers of few-shot exemplars. We run experiments for LaMDA 137B, comparing chain-of-thought\\nprompting with standard prompting for the ﬁve datasets where standard prompting had a mostly ﬂat\\nscaling curve (the largest model did not achieve high performance). As shown in Figure 11, the\\nimprovement of chain-of-thought prompting over standard prompting remains robust to varying the\\nnumber of few-shot exemplars in the prompt.\\n28' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 27}\n",
      "page_content='12468051015 Solve rate (%)GSM8K\\n124680204060MultiArith\\n(MAWPS)\\n124680255075100\\nNumber of few-shot exemplarsSports\\nUnderstandingStandard prompting\\nChain of thought prompting\\n124680255075100Coin Flip\\n12340255075100Last Letter\\nConcatenation\\nFigure 11: The improvement of chain of thought prompting over standard prompting appears robust\\nto varying the number of few-shot exemplars in the prompt.\\nTable 12: Summary of math word problem benchmarks we use in this paper with examples. N:\\nnumber of evaluation examples.\\nDataset N Example problem\\nGSM8K 1,319 Josh decides to try ﬂipping a house. He buys a house for $80,000 and then puts\\nin $50,000 in repairs. This increased the value of the house by 150%. How\\nmuch proﬁt did he make?\\nSV AMP 1,000 Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each\\npack. How much do you have to pay to buy each pack?\\nASDiv 2,096 Ellen has six more balls than Marin. Marin has nine balls. How many balls does\\nEllen have?\\nAQuA 254 A car is being driven, in a straight line and at a uniform speed, towards the base\\nof a vertical tower. The top of the tower is observed from the car and, in the\\nprocess, it takes 10 minutes for the angle of elevation to change from 45◦to 60◦.\\nAfter how much more time will this car reach the base of the tower? Answer\\nChoices: (a) 5√\\n3+ 1 (b) 6√\\n3+√\\n2(c) 7√\\n3- 1 (d) 8√\\n3- 2 (e) None of these\\nMAWPS: SingleOp 562 If there are 7 bottle caps in a box and Linda puts 7 more bottle caps inside, how\\nmany bottle caps are in the box?\\nMAWPS: SingleEq 508 Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27\\ndollars. How much did each candy bar cost?\\nMAWPS: AddSub 395 There were 6 roses in the vase. Mary cut some roses from her ﬂower garden.\\nThere are now 16 roses in the vase. How many roses did she cut?\\nMAWPS: MultiArith 600 The school cafeteria ordered 42 red apples and 7 green apples for students\\nlunches. But, if only 9 students wanted fruit, how many extra did the cafeteria\\nend up with?\\n29' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 28}\n",
      "page_content='E Additional Details\\nVersion Control\\nV5→V6. Fixed minor typo in Figure 3.\\nV4→V5. Added Codex and UL2 results. Small changes to writing and style of paper.\\nV3→V4. Fixed typo in Figure 3 and added a couple citations.\\nV2→V3. Added GPT-3 results. Added SV AMP and AQuA eval datasets for math. Added SayCan\\neval for commonsense. Added Extended Related Work section (Appendix C). Added ablations for\\nCommonsense and Symbolic Reasoning (Table 7). Added FAQ section (Appendix A). Added raw\\nresults in Appendix B.\\nV1→V2. Added PaLM results (V1 only had LaMDA).\\nE.1 Reproducibility Statement\\nAs our results make use of two sets of large language models that is not publicly available, we take\\nthe following actions to facilitate reproducibility. First, we provide the exact input prompts for all\\ntasks in Table 20–Table 27 in Appendix G (and emphasize that we do not perform any ﬁnetuning and\\nonly apply prompting to off-the-shelf language models). Second, we conduct experiments using the\\npublicly available GPT-3 API for four model scales text-ada-001, text-babbage-001, text-curie-001,\\ntext-davinci-002). Finally, we make exact inputs, targets, and predictions for LaMDA 137B for each\\ntask available as a zip ﬁle in the supplementary material.\\nE.2 Computational Resources\\nFor all three language models we evaluated, we did prompting-based inference only. No ﬁnetuning\\nwas done for this paper. For inference on LaMDA 137B we use TPU v3 (8x8 conﬁguration, 64 chips\\n/ 128 cores), and for inference on PaLM 540B we use TPU v4 (4x4x12 conﬁguration, 192 chips / 384\\ncores). GPT-3 experiments were done using the public API.5\\nE.3 Dataset Details and Licenses\\nWe list the details and licenses for all arithmetic and commonsense datasets used in this paper. The\\nsymbolic reasoning datasets were created synthetically, as described in Section 4.\\nArithmetic reasoning\\n•Math Word Problem Repository (Koncel-Kedziorski et al., 2016): AddSub (Hosseini\\net al., 2014): https://www.cs.washington.edu/nlp/arithmetic ; MultiArith (Roy\\nand Roth, 2015), license: CC BY 4.0.\\n• ASDiv (Miao et al., 2020): https://github.com/chaochun/nlu-asdiv-dataset .\\n•AQuA (Ling et al., 2017): https://github.com/deepmind/AQuA , license: https://\\ngithub.com/deepmind/AQuA/blob/master/LICENSE .\\n•GSM8K (Cobbe et al., 2021): https://github.com/openai/grade-school-math ,\\nMIT license: https://github.com/openai/grade-school-math/blob/master/\\nLICENSE .\\n•SV AMP (Patel et al., 2021): https://github.com/arkilpatel/SVAMP , MIT license:\\nhttps://github.com/arkilpatel/SVAMP/blob/main/LICENSE .\\nCommonsense reasoning\\n•CSQA (Talmor et al., 2019): https://www.tau-nlp.org/commonsenseqa ,https://\\ngithub.com/jonathanherzig/commonsenseqa .\\n5https://beta.openai.com/docs/api-reference/making-requests\\n30' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 29}\n",
      "page_content='•StrategyQA (Geva et al., 2021): we use the open-domain setting (question-only set)\\nfrom BIG-bench collaboration (2021): https://github.com/google/BIG-bench/\\ntree/main/bigbench/benchmark_tasks/strategyqa . The original dataset is from\\nhttps://github.com/eladsegal/strategyqa , MIT license: https://github.com/\\neladsegal/strategyqa/blob/main/LICENSE .\\n•Date understanding and sports understanding from BIG-Bench (BIG-bench collaboration,\\n2021): Apache License v.2: https://github.com/google/BIG-bench/blob/main/\\nLICENSE .\\n•SayCan (Ahn et al., 2022): SayCan dataset can be accessed at https://say-can.github.\\nio/under CC BY 4.0 license.\\n31' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 30}\n",
      "page_content='F Appendix: Input/Output Examples\\nTable 13: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the\\nletter concatenation task.\\nQUESTION :Take the last letters of the words in “Waldo Schmidt” and concatenate them.\\nMODEL ANSWER (CORRECT): The last letter of “Waldo” is “o”. The last letter of “Schmidt” is “t”.\\nConcatenating them is “ot”. So the answer is ot. ✓\\nQUESTION :Take the last letters of the words in “Daniel Friedman” and concatenate them.\\nMODEL ANSWER (INCORRECT): The last letter of “Daniel” is “l”. The last letter of “Friedman” is “m”.\\nConcatenating them is “lm”. So the answer is lm. \\x17\\nTable 14: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the\\ncoinﬂip task.\\nQUESTION :A coin is heads up. Andree ﬂips the coin. Audrie does not ﬂip the coin. Is the coin still heads up?\\nMODEL ANSWER (CORRECT): The coin was ﬂipped by Andree. So the coin was ﬂipped 1 time, which is\\nan odd number. The coin started heads up, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\n✓\\nQUESTION :A coin is heads up. Kristian does not ﬂip the coin. Dallas does not ﬂip the coin. Is the coin still\\nheads up?\\nMODEL ANSWER (INCORRECT): The coin was ﬂipped by Kristian. So the coin was ﬂipped 1 time, which\\nis an odd number. The coin started heads up, so after an odd number of ﬂips, it will be tails up. So the answer is\\nno.\\x17\\nTable 15: Examples of correct and incorrect chains of thought produced by LaMDA 137B on CSQA.\\nQUESTION :When a person is beginning work, what are they building?\\nAnswer Choices: (a) time (b) accomplishing (c) working (d) momentum (e) tiredness\\nMODEL ANSWER (CORRECT): The answer must be something that is built. Of the above choices, only\\nmomentum is built. So the answer is (d). ✓\\nQUESTION :Where are you likely to ﬁnd a hamburger?\\nAnswer Choices: (a) fast food restaurant (b) pizza (c) ground up dead cows (d) mouth (e) cow carcus\\nMODEL ANSWER (CORRECT): The answer must be a place where hamburgers are found. Of the above\\nchoices, only fast food restaurants serve hamburgers. So the answer is (a). ✓\\nQUESTION :Aside from water and nourishment what does your dog need?\\nAnswer Choices: (a) bone (b) charm (c) petted (d) lots of attention (e) walked\\nMODEL ANSWER (INCORRECT): The answer must be something that a dog needs. Of the above choices,\\nonly bone is something that a dog needs. So the answer is (a). \\x17(Ground truth is (d).)\\nQUESTION :What are you waiting alongside with when you’re in a reception area?\\nAnswer Choices: (a) motel (b) chair (c) hospital (d) people (e) hotels\\nMODEL ANSWER (INCORRECT): The answer must be something that is waiting with you in a reception\\narea. Of the above choices, only people are waiting with you in a reception area. So the answer is (e). \\x17(Ground\\ntruth is (d).)\\n32' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 31}\n",
      "page_content='Table 16: Examples of correct and incorrect chains of thought produced by LaMDA 137B on\\nStrategyQA.\\nQUESTION :Will The Exorcist stimulate limbic system?\\nMODEL ANSWER (CORRECT): The Exorcist is a horror movie. Horror movies are scary. The limbic system\\nis involved in fear. Thus, The Exorcist will stimulate the limbic system. So the answer is yes. ✓\\nQUESTION :Was Jackson Pollock trained by Leonardo da Vinci?\\nMODEL ANSWER (CORRECT): Leonardo da Vinci lived in the 15th century. Jackson Pollock lived in the\\n20th century. Thus, Jackson Pollock could not have been trained by Leonardo da Vinci. So the answer is no. ✓\\nQUESTION :Can Harry Potter book a ﬂight on Asiana Airlines?\\nMODEL ANSWER (INCORRECT): Harry Potter is a ﬁctional character. Thus, Harry Potter can do anything.\\nSo the answer is yes. \\x17(Ground truth is “no”.)\\nQUESTION :Would a sophist use an épée?\\nMODEL ANSWER (INCORRECT): A sophist is a person who is skilled in the art of persuasion. An épée is\\na type of sword. Thus, a sophist could use an épée. So the answer is yes. \\x17(Ground truth is “no”.)\\nTable 17: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Date\\nUnderstanding.\\nQUESTION :May 6, 1992 is like yesterday to Jane, but that is actually ten years ago. What is the date a month\\nago in MM/DD/YYYY?\\nMODEL ANSWER (CORRECT): May 6, 1992 is ten years ago, so today is May 6, 2002. So a month ago will\\nbe April 6, 2002. So the answer is 04/06/2002. ✓\\nQUESTION :This is the last day of 1899. What is the date 24 hours later in MM/DD/YYYY?\\nMODEL ANSWER (CORRECT): Today is 12/31/1899. 24 hours later will be 01/01/1900. So the answer is\\n01/01/1900. ✓\\nQUESTION :Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one\\nweek ago from today in MM/DD/YYYY?\\nMODEL ANSWER (INCORRECT): Tomorrow is 7/9/1972. One week ago from today is 7/2/1972. So the\\nanswer is 7/2/1972. \\x17(Ground truth is 07/01/1972.)\\nQUESTION :Today is the palindrome day of 2020, because the MMDDYYYY format of the date is the same\\nbackwards as forwards. What is the date tomorrow in MM/DD/YYYY?\\nMODEL ANSWER (INCORRECT): Today is 02/29/2020. Tomorrow will be 03/01/2020. So the answer is\\n03/01/2020. \\x17(Ground truth is “02/03/2020”.)\\nTable 18: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Sports\\nUnderstanding.\\nQUESTION :Is the following sentence plausible? “Joao Moutinho was out at third.”\\nMODEL ANSWER (CORRECT): Joao Moutinho is a soccer player. Being out at third is part of baseball, not\\nsoccer. So the answer is no. ✓\\nQUESTION :Is the following sentence plausible? “Malcolm Brogdon eurostepped to the basket in the NBA\\nChampionship.”\\nMODEL ANSWER (CORRECT): Malcolm Brogdon is a basketball player. Eurostepping to the basket is part\\nof basketball. So the answer is yes. ✓\\nQUESTION :Is the following sentence plausible? “Derrick White backhanded a shot.”\\nMODEL ANSWER (INCORRECT): Derrick White is a basketball player. Backhanding a shot is part of\\nbasketball. So the answer is yes. \\x17(Ground truth is “no”, backhanding a shot is part of hockey.)\\nQUESTION :Is the following sentence plausible? “Nazem Kadri was out at home.”\\nMODEL ANSWER (INCORRECT): Nazem Kadri is a hockey player. Being out at home is part of hockey.\\nSo the answer is yes. \\x17(Ground truth is “no”, being out at home is part of baseball.)\\n33' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 32}\n",
      "page_content='Table 19: Examples of correct and incorrect chains of thought produced by PaLM 540B on SayCan\\nrobot planning tasks.\\nQUESTION :I spilled my coke on the table, could you throw it away and then bring me something to help clean?\\nMODEL ANSWER (CORRECT): Explanation: The user has spilled their coke on the table. I will throw away\\nthe coke and then bring the user a sponge. Plan: ﬁnd(coke), pick(coke), ﬁnd(trash), put(coke), ﬁnd(sponge),\\npick(sponge), ﬁnd(table), put(sponge). ✓\\nQUESTION :Could you compost that apple for me?\\nMODEL ANSWER (CORRECT): Explanation: The user would like me to compost the apple. I will move the\\napple to the compost. Plan: ﬁnd(apple), pick(apple), ﬁnd(trash), put(apple). ✓\\nQUESTION :Can you bring me a drink that is not coke?\\nMODEL ANSWER (INCORRECT): Explanation: The user asked me to bring a drink that is not coke, I will\\nbring a sprite. Plan: ﬁnd(sprite), pick(sprite), ﬁnd(user), put(sprite). \\x17(Feasible answers including ﬁnding lime\\nsoda, pepsi, grapefruit soda or water, because there is no sprite in the scene as deﬁned in Table 28.)\\nQUESTION :Can you bring me something salty?\\nMODEL ANSWER (INCORRECT): Explanation: The user would like something salty. There are several\\noptions in the objects list, so I will bring the user a lime soda. Plan: ﬁnd(lime soda), pick(lime soda), ﬁnd(user),\\nput(lime soda). \\x17(Feasible answers including ﬁnding chips. The model misidentify lime soda as salty.)\\n34' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 33}\n",
      "page_content='G Appendix: Full Prompts\\nTable 20: Few-shot exemplars for full chain of thought prompt for math word problems. This set of\\nexemplars was used for all math word problem datasets except AQuA.\\nPROMPT FOR MATH WORD PROBLEMS\\nQ:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA:There are15trees originally. Then there were 21trees aftersome more were planted. Sothere must have\\nbeen 21-15=6. The answer is 6.\\nQ:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA:There areoriginally 3cars. 2more carsarrive. 3+2=5. The answer is 5.\\nQ:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA:Originally, Leah had32choco lates. Hersisterhad42.Sointotalthey had32+42=74.Aftereating35,they\\nhad74-35=39. The answer is 39.\\nQ:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA:Jasonstarted with 20lollipops. Then hehad12aftergivingsome toDenny. Sohegave Denny 20-12=8.\\nThe answer is 8.\\nQ:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA:Shawn started with 5toys. Ifhegot2toys each from hismom anddad, then thatis4more toys. 5+4=9.\\nThe answer is 9.\\nQ:There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA:There were originally 9computers.Foreach of4days, 5more computerswere added. So5*4=20\\ncomputerswere added. 9+20is29. The answer is 29.\\nQ:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA:Michael started with 58golfballs. Afterlosing23ontuesday, hehad58-23=35.Afterlosing2more, he\\nhad35-2=33golfballs. The answer is 33.\\nQ:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA:Olivia had23dollars. 5bagels for3dollarseach willbe5x3=15dollars. Soshehas23-15dollarsleft.23\\n-15is8. The answer is 8.\\n35' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 34}\n",
      "page_content='Table 21: Few-shot exemplars for full chain of thought prompt for AQuA.\\nPROMPT FOR AQ UAALGEBRAIC WORD PROBLEMS\\nQ:John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers\\nis?\\nAnswer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\\nA:If10isadded toeach number,then themean ofthenumbers alsoincreases by10.Sothenewmean would be\\n50. The answer is (a).\\nQ:If a / b = 3/4 and 8a + 5b = 22,then ﬁnd the value of a.\\nAnswer Choices: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e) 7/2\\nA:Ifa/b=3/4,then b=4a/3.So8a+5(4a /3)=22.This simpliﬁesto8a+20a/3=22,which means 44a/3\\n=22.Soaisequal to3/2. The answer is (b).\\nQ:A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then ﬁnd the distance?\\nAnswer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km\\nA:Thedistance thatthepersontraveled would have been 20km/hr *2.5hrs=50km. The answer is (e).\\nQ:How many keystrokes are needed to type the numbers from 1 to 500?\\nAnswer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788\\nA:There are9one-digit numbers from 1to9.There are90two-digit numbers from 10to99.There are401\\nthree -digit numbers from 100to500. 9+90(2) +401(3) =1392. The answer is (b).\\nTable 22: Few-shot exemplars for full chain of thought prompt for the last letter concatenation task.\\nPROMPT FOR LAST LETTER CONCATENATION\\nQ:Take the last letters of the words in \"Elon Musk\" and concatenate them.\\nA:Thelastletterof\"Elon\" is\"n\".Thelastletterof\"Musk\" is\"k\".Concatenatingthem is\"nk\". The answer is nk.\\nQ:Take the last letters of the words in \"Larry Page\" and concatenate them.\\nA:Thelastletterof\"Larry\" is\"y\".Thelastletterof\"Page\" is\"e\".Concatenatingthem is\"ye\". The answer is ye.\\nQ:Take the last letters of the words in \"Sergey Brin\" and concatenate them.\\nA:Thelastletterof\"Sergey\" is\"y\".Thelastletterof\"Brin\" is\"n\".Concatenatingthem is\"yn\". The answer is\\nyn.\\nQ:Take the last letters of the words in \"Bill Gates\" and concatenate them.\\nA:Thelastletterof\"Bill\" is\"l\".Thelastletterof\"Gates\" is\"s\".Concatenatingthem is\"ls\". The answer is ls.\\n36' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 35}\n",
      "page_content='Table 23: Few-shot exemplars for full chain of thought prompt for the coinﬂip task.\\nPROMPT FOR COIN FLIP\\nQ:Q: A coin is heads up. Ka ﬂips the coin. Sherrie ﬂips the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byKaandSherrie.Sothecoin wasﬂipped 2times, which isaneven number.Thecoin\\nstarted heads up,soafteraneven numberofﬂips, itwillstillbeheads up. So the answer is yes.\\nQ:A coin is heads up. Jamey ﬂips the coin. Teressa ﬂips the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byJamey andTeressa. Sothecoin wasﬂipped 2times, which isaneven number.The\\ncoin started heads up,soafteraneven numberofﬂips, itwillstillbeheads up. So the answer is yes.\\nQ:A coin is heads up. Maybelle ﬂips the coin. Shalonda does not ﬂip the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byMaybelle. Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin started\\nheads up,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\\nQ:A coin is heads up. Millicent does not ﬂip the coin. Conception ﬂips the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byConception. Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin\\nstarted heads up,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\\nQ:A coin is heads up. Sal ﬂips the coin. Raymond does not ﬂip the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped bySal.Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin started heads\\nup,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\\nQ:A coin is heads up. Conception ﬂips the coin. Kristian does not ﬂip the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byConception. Sothecoin wasﬂipped 1time, which isanoddnumber.Thecoin\\nstarted heads up,soafteranoddnumberofﬂips, itwillbetails up. So the answer is no.\\nQ:A coin is heads up. Inga does not ﬂip the coin. Elanor does not ﬂip the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped bynoone. Sothecoin wasﬂipped 0times. Thecoin started heads up,anditwasnot\\nﬂipped, soitisstillheads up. So the answer is yes.\\nQ:A coin is heads up. Ryan ﬂips the coin. Shaunda ﬂips the coin. Is the coin still heads up?\\nA:Thecoin wasﬂipped byRyan andShaunda. Sothecoin wasﬂipped 2times, which isaneven number.The\\ncoin started heads up,soafteraneven numberofﬂips, itwillstillbeheads up. So the answer is yes.\\n37' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 36}\n",
      "page_content='Table 24: Few-shot exemplars for full chain of thought prompt for CSQA. There are newlines\\nbetween the answer choices that are omitted in the table for space reasons.\\nPROMPT FOR CSQA\\nQ:What do people use to absorb extra ink from a fountain pen? Answer Choices: (a) shirt pocket (b)\\ncalligrapher’s hand (c) inkwell (d) desk drawer (e) blotter\\nA:Theanswer must beanitem thatcanabsorb ink.Oftheabove choices, only blottersareused toabsorb ink.\\nSo the answer is (e).\\nQ:What home entertainment equipment requires cable?\\nAnswer Choices: (a) radio shack (b) substation (c) television (d) cabinet\\nA:Theanswer must require cable.Oftheabove choices, only television requires cable. So the answer is (c).\\nQ:The fox walked from the city into the forest, what was it looking for? Answer Choices: (a) pretty ﬂowers (b)\\nhen house (c) natural habitat (d) storybook\\nA:Theanswer must besome thing intheforest.Oftheabove choices, only naturalhabitatisintheforest. So the\\nanswer is (b).\\nQ:Sammy wanted to go to where the people were. Where might he go? Answer Choices: (a) populated areas\\n(b) race track (c) desert (d) apartment (e) roadblock\\nA:Theanswer must beaplace with alotofpeople.Oftheabove choices, only populated areashave alotof\\npeople. So the answer is (a).\\nQ:Where do you put your grapes just before checking out? Answer Choices: (a) mouth (b) grocery cart (c)super\\nmarket (d) fruit basket (e) fruit market\\nA:Theanswer should betheplace where grocery items areplaced beforecheck ingout.Oftheabove choices,\\ngrocery cartmakes themost sense forholdinggrocery items. So the answer is (b).\\nQ:Google Maps and other highway and street GPS services have replaced what? Answer Choices: (a) united\\nstates (b) mexico (c) countryside (d) atlas\\nA:Theanswer must besome thing thatused todowhat Google Maps andGPS services do,which istogive\\ndirections. Oftheabove choices, only atlases areused togive directions. So the answer is (d).\\nQ:Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (a) harder (b)\\nanguish (c) bitterness (d) tears (e) sadness\\nA:Theanswer should bethefeelingofsome onegettingdivorced who wasdoingallthework. Oftheabove\\nchoices, theclosestfeelingisbitterness. So the answer is (c).\\n38' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 37}\n",
      "page_content='Table 25: Few-shot exemplars for full chain of thought prompt for StrategyQA.\\nPROMPT FOR STRATEGY QA\\nQ:Do hamsters provide food for any animals?\\nA:Ham sters areprey animals. Prey arefood forpreda tors. Thus, hamsters provide food forsome animals. So\\nthe answer is yes.\\nQ:Could Brooke Shields succeed at University of Pennsylvania?\\nA:Brooke Shields went toPrince tonUniversity. Prince tonUniversityisabout asacademically rigorousasthe\\nUniversityofPenn sylvania.Thus, Brooke Shields could alsosucceed attheUniversityofPenn sylvania. So the\\nanswer is yes.\\nQ:Yes or no: Hydrogen’s atomic number squared exceeds number of Spice Girls?\\nA:Hydrogenhasanatomic numberof1.1squared is1.There are5Spice Girls. Thus, Hydrogen’s atomic\\nnumbersquared islessthan 5. So the answer is no.\\nQ:Yes or no: Is it common to see frost during some college commencements?\\nA:College commence ment ceremonies canhappeninDecember,May, andJune. Decemberisinthewinter,so\\nthere canbefrost. Thus, there could befrost atsome commence ments. So the answer is yes.\\nQ:Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?\\nA:TheWar inVietnam was6months. Thegestationperiod forallama is11months, which ismore than 6\\nmonths. Thus, allama could notgive birth twice duringtheWar inVietnam. So the answer is no.\\nQ:Yes or no: Would a pear sink in water?\\nA:Thedensityofapear isabout 0.6g/cm3,which islessthan water.Objects lessdense than waterﬂoat. Thus,\\napear would ﬂoat. So the answer is no.\\nTable 26: Few-shot exemplars for full chain of thought prompt for Date Understanding.\\nPROMPT FOR DATE UNDERSTANDING\\nQ:2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?\\nA:If2015 iscomingin36hours, then itiscomingin2days. 2days before01/01/2015 is12/30/2014, sotoday\\nis12/30/2014. Sooneweek from todaywillbe01/05/2015. So the answer is 01/05/2015.\\nQ:The ﬁrst day of 2019 is a Tuesday, and today is the ﬁrst Monday of 2019. What is the date today in\\nMM/DD/YYYY?\\nA:Iftheﬁrstdayof2019 wasTues day,then 01/01/2019 wasaTues day.Todayistheﬁrstmonday,would besix\\ndays later. Sotodayis01/07/2019. So the answer is 01/07/2019.\\nQ:The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10\\ndays ago in MM/DD/YYYY?\\nA:One dayafter06/01/1943 is06/02/1943, sotodayis06/02/1943. 10days beforetodayis05/23/1943. So the\\nanswer is 05/23/1943.\\nQ:It is 4/19/1969 today. What is the date 24 hours later in MM/DD/YYYY?\\nA:Todayis04/19/1969. 24hours later isonedayaftertoday, which would be04/20/1969. So the answer is\\n04/20/1969.\\nQ:Jane thought today is 3/11/2002, but today is in fact Mar 12, which is 1 day later. What is the date 24 hours\\nlater in MM/DD/YYYY?\\nA:Todayis03/12/2002. Sothedate 24hours later willbe03/13/2002. So the answer is 03/13/2002.\\nQ:Jane was born on the last day of Feburary in 2001. Today is her 16-year-old birthday. What is the date\\nyesterday in MM/DD/YYYY?\\nA:ThelastdayofFebru aryisthe28th, soJane wasborn on02/28/2001. Todayisher16-year oldbirth day, so\\ntodayis02/28/2017. Soyesterdaywas02/27/2017. So the answer is 02/27/2017.\\n39' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 38}\n",
      "page_content='Table 27: Few-shot exemplars for full chain of thought prompt for Sports Understanding.\\nPROMPT FOR SPORTS UNDERSTANDING\\nQ:Is the following sentence plausible? “Kyle Palmieri was called for slashing.”\\nA:Kyle Palmieri isahockey player. Beingcalled forslash ingispartofhockey. So the answer is yes.\\nQ:Is the following sentence plausible? “Joao Moutinho caught the screen pass in the NFC championship.”\\nA:Joao Moutinho isasoccerplayer. TheNFC cham pionship ispartofAmer icanfootball, notsoccer. So the\\nanswer is no.\\nQ:Is the following sentence plausible? “Carson Wentz set the pick and roll.”\\nA:CarsonWentz isanAmer icanfootballplayer. Pick androllispartofbasketball, notfootball. So the answer\\nis no.\\nQ:Is the following sentence plausible? “Jonas Valanciunas beat the buzzer.”\\nA:Jonas Valan ciunasisabasketballplayer. Beatingthebuzzer ispartofbasketball. So the answer is yes.\\nQ:Is the following sentence plausible? “Jamel Murray was perfect from the line.”\\nA:JamalMurrayisabasketballplayer. Beingperfectfrom thelineispartofbasketball. So the answer is yes.\\nQ:Is the following sentence plausible? “Sam Darnold passed the puck.”\\nA:Sam Darnold isaAmer icanfootballplayer. Passingthepuck ispartofhockey, notAmer icanfootball. So the\\nanswer is no.\\nQ:Is the following sentence plausible? “Draymond Green threw a touchdown.”\\nA:Dray mond Green isanbasketballplayer. Throw ingatouch down ispartoffootball, notbasketball. So the\\nanswer is no.\\nQ:Is the following sentence plausible? “Malcolm Brogdon banked the shot in.”\\nA:Malcolm Brog donisabasketballplayer. Bank ingtheshot inispartofbasketball. So the answer is yes.\\n40' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 39}\n",
      "page_content='Table 28: Few-shot exemplars for full chain of thought prompt for SayCan robot planning tasks.\\nPROMPT FOR SAYCANROBOT PLANNING\\nLocations = [counter, table, user, trash, bowl].\\nObjects = [7up, apple, kettle chips, tea, multigrain chips, coke, lime soda, jalapeno chips, rice chips, orange,\\ngrapefruit soda, pepsi, redbull, energy bar, sponge, water].\\nThe robot can pick up items with pick(object) and put down items with put(object) as well as ﬁnd objects or\\nlocations with ﬁnd(). The robot can only understand the explicit locations and objects listed.\\nHuman : I’m hungry, can you bring me some chips.\\nExplanation :Theuser ishungryandhasasked forchips. There areseveraltypes ofchips avail able, Iwillbring\\ntheuser thekettlechips.\\nPlan : 1. ﬁnd(kettle chips), 2. pick(kettle chips), 3. ﬁnd(user), 4. put(kettle chips), 5. done().\\nHuman : How would you move the grapefruit drink from the table to the counter?\\nExplanation :Theuser hasasked metomove thegrape fruit drink tothecounter.\\nPlan : 1. ﬁnd(grapefruit soda), 2. pick(grapefruit soda), 3. ﬁnd(counter), 4. put(grapefruit soda), 5. done().\\nHuman : How would you bring me some snacks?\\nExplanation :Theuser hasasked forsnacks, Iwillchoose twoitems andbring them. Iwillbring jalapeno chips\\nandanapple.\\nPlan : 1. ﬁnd(jalapeno chips), 2. pick(jalapeno chips), 3. ﬁnd(user), 4. put(jalapeno chips), 5. ﬁnd(apple), 6.\\npick(apple), 7. ﬁnd(user), 8. put(apple), 9. done().\\nHuman : How would you bring me something to eat that isn’t a fruit?\\nExplanation :Theuser hasasked forafood thatisn’t afruit, Iwillbring anenergy bartothem.\\nPlan : 1. ﬁnd(energy bar), 2. pick(energy bar), 3. ﬁnd(user), 4. put(energy bar), 5. done().\\nHuman : How would you put the rice chips in the bowl and then move the tea to the table?\\nExplanation :Theuser hasasked metodotwotasks, Iwilldooneandthen theother.\\nPlan : 1. ﬁnd(rice chips), 2. pick(rice chips), 3. ﬁnd(bowl), 4. put(rice chips), 5. ﬁnd(tea), 6. pick(tea), 7.\\nﬁnd(table), 8. put(tea), 9. done().\\nHuman : How would you throw away a redbull?\\nExplanation :Theuser hasasked metothrow away theredbull, Iwillmove ittothetrash.\\nPlan : 1. ﬁnd(redbull), 2. pick(redbull), 3. ﬁnd(trash), 4. put(redbull), 5. done().\\nHuman : Bring me a drink.\\nExplanation :Theuser hasasked foradrink andthere aremany options. Iwillbring them awater.\\nPlan : 1. ﬁnd(water), 2. pick(water), 3. ﬁnd(user), 4. put(water), 5. done().\\n41' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 40}\n",
      "page_content='H Appendix: Alternate Annotators for MWP\\nTable 29: Few-shot exemplars for full chain of thought prompt for math word problems. These\\nexemplars are the same as in Table 20, except that the chains of thought were written by a different\\nannotator (“Annotator B” instead of “Annotator A”). Annotators were co-authors and familiar with\\nthe goal of chain of thought prompting.\\nPROMPT FOR MATH WORD PROBLEMS\\nQ:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA:There are21trees now andthere are15trees inthebeginning, sothework ersplant 21-15=6trees. The\\nanswer is 6.\\nQ:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA:There are3carsinthebeginning, 2more arrive, sonow there should be3+2=5cars. The answer is 5.\\nQ:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA:Leah had32choco lates andhersisterhad42,intotalthey have 32+42=74choco lates. Afterthey ate35,\\nnow there are74-35=39choco lates. The answer is 39.\\nQ:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA:Jasonstarted with 20lollipops, butnow heonly has12,sohegave Denny 20-12=8lollipops. The answer\\nis 8.\\nQ:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA:Shawn got2toys each from hismom anddad, sohegot2*2=4more, now hewillhave 5+4=9toys. The\\nanswer is 9.\\nQ:There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA:5computerswere installed from mondaytothurs day, sointotal5*4=20computersareinstalled. 9\\ncomputersarethere inthebeginning, sonow there are20+9=29computers. The answer is 29.\\nQ:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA:Michael started with 58golfballs andlost23,sohehas58-23=35.Afterhelost2more, hehas35-2=33\\nballs now. The answer is 33.\\nQ:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA:5bagels for$3each should cost5*3=15dollars. Olivia had$23inthebeginning, sonow shehas23-15=\\n8dollarsleft. The answer is 8.\\n42' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 41}\n",
      "page_content='Table 30: Few-shot exemplars for full chain of thought prompt for math word problems. These\\nexemplars are the same as in Table 20, except that the chains of thought were written by a different\\nannotator (“Annotator C” instead of “Annotator A”).\\nPROMPT FOR MATH WORD PROBLEMS\\nQ:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA:Westart with 15trees. Later wehave 21trees. Thedifference must bethenumberoftrees they planted. So,\\nthey must have planted 21-15=6trees. The answer is 6.\\nQ:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA:There are3carsintheparkinglotalready. 2more arrive. Now there are3+2=5cars. The answer is 5.\\nQ:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA:Leah had32choco lates andLeah’s sisterhad42.That means there were originally 32+42=74choco lates.\\n35have been eaten. Sointotalthey stillhave 74-35=39choco lates. The answer is 39.\\nQ:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA:Jasonhad20lollipops. Since heonly has12now, hemust have given theresttoDenny. Thenumberof\\nlollipops hehasgiven toDenny must have been 20-12=8lollipops. The answer is 8.\\nQ:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA:Hehas5toys. Hegot2from mom, soafterthathehas5+2=7toys. Then hegot2more from dad, soin\\ntotalhehas7+2=9toys. The answer is 9.\\nQ:There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA:There are4days from mondaytothurs day.5computerswere added each day.That means intotal4*5=20\\ncomputerswere added. There were 9computersinthebeginning, sonow there are9+20=29computers. The\\nanswer is 29.\\nQ:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA:Michael initially had58balls. Helost23onTues day, soafterthathehas58-23=35balls. OnWednes day\\nhelost2more sonow hehas35-2=33balls. The answer is 33.\\nQ:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA:Shebought 5bagels for$3each. This means shespent 5*$3=$15onthebagels. Shehad$23inbeginning,\\nsonow shehas$23-$15=$8. The answer is 8.\\n43' metadata={'source': 'pdf/Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'page': 42}\n",
      "page_content='M a s t e r i n g\\nG e n e r a t i v e\\nA I\\na n d\\nP r o m p t\\nE n g i n e e r i n g :\\nA\\nP r a c t i c a l\\nG u i d e\\nf o r\\nD a t a\\nS c i e n t i s t s\\nA s\\nt h e\\nA I - d r i v e n\\ne c o n o m y\\nc o n t i n u e s\\nt o\\ne v o l v e\\na n d\\ne x p a n d ,\\nt h e\\nr o l e\\no f\\np r o m p t\\ne n g i n e e r i n g\\nw i l l\\nb e c o m e\\ni n c r e a s i n g l y\\ns i g n i ﬁ c a n t\\na n d\\nt r a n s f o r m a t i v e\\na c r o s s\\nd i v e r s e\\ns e c t o r s\\na n d\\nd o m a i n s .\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 0}\n",
      "page_content='C o n t e n t s\\nI n t r o d u c t i o n\\nC h a p t e r\\n1 :\\nU n d e r s t a n d i n g\\nG e n e r a t i v e\\nA I\\n1 . 1 .\\nE v o l u t i o n\\no f\\nA I :\\nF r o m\\nr u l e - b a s e d\\nt o\\ng e n e r a t i v e\\nm o d e l s\\n1 . 2 .\\nK e y\\ng e n e r a t i v e\\nA I\\nm o d e l s :\\nR N N s ,\\nL S T M s ,\\nG P T ,\\na n d\\nm o r e\\n1 . 3 .\\nP o p u l a r\\nu s e\\nc a s e s\\nf o r\\ng e n e r a t i v e\\nA I\\nC h a p t e r\\n2 :\\nI n t r o d u c t i o n\\nt o\\nP r o m p t\\nE n g i n e e r i n g\\n2 . 1 .\\nW h a t\\ni s\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nw h y\\ni t\\nm a t t e r s\\n2 . 2 .\\nP r o m p t\\nt y p e s :\\ne x p l i c i t ,\\ni m p l i c i t ,\\na n d\\nc r e a t i v e\\np r o m p t s\\n2 . 3 .\\nB e s t\\nP r a c t i c e s\\nf o r\\nC r a f t i n g\\nE f f e c t i v e\\nP r o m p t s\\nC h a p t e r\\n3 :\\nP r a c t i c a l\\nA p p l i c a t i o n s\\no f\\nP r o m p t\\nE n g i n e e r i n g\\n3 . 1 .\\nI m p r o v i n g\\nN L P\\nT a s k s\\nw i t h\\nC u s t o m\\nP r o m p t s\\n3 . 2 .\\nE n h a n c i n g\\nC r e a t i v i t y\\na n d\\nD i v e r s i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\n3 . 3 .\\nA d d r e s s i n g\\nA I\\nE t h i c s\\na n d\\nB i a s\\nt h r o u g h\\nT h o u g h t f u l\\nP r o m p t\\nE n g i n e e r i n g\\n3 . 4 .\\nP e r s o n a l i z a t i o n\\na n d\\nA d a p t a b i l i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\nC h a p t e r\\n4 :\\nC h a l l e n g e s\\na n d\\nL i m i t a t i o n s\\no f\\nP r o m p t\\nE n g i n e e r i n g\\n4 . 1 .\\nU n d e r s t a n d i n g\\nA I\\nM o d e l\\nL i m i t a t i o n s\\na n d\\nI n h e r e n t\\nB i a s e s\\n4 . 2 .\\nS t r i k i n g\\nt h e\\nR i g h t\\nB a l a n c e\\nb e t w e e n\\nG u i d a n c e\\na n d\\nF l e x i b i l i t y\\n4 . 3 .\\nE n s u r i n g\\nQ u a l i t y\\na n d\\nR e l i a b i l i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\nC h a p t e r\\n5 :\\nF u t u r e\\nD i r e c t i o n s\\na n d\\nE m e r g i n g\\nT r e n d s\\ni n\\nP r o m p t\\nE n g i n e e r i n g\\n5 . 1 .\\nL e v e r a g i n g\\nA d v a n c e d\\nA I\\nM o d e l s\\na n d\\nT e c h n i q u e s\\n5 . 2 .\\nT h e\\nC o n v e r g e n c e\\no f\\nH u m a n\\na n d\\nA I\\nC r e a t i v i t y\\n5 . 3 .\\nT h e\\nR o l e\\no f\\nP r o m p t\\nE n g i n e e r i n g\\ni n\\nt h e\\nA I - D r i v e n\\nE c o n o m y\\nC h a p t e r\\n6 :\\nP r a c t i c a l\\nT i p s\\na n d\\nB e s t\\nP r a c t i c e s\\nf o r\\nP r o m p t\\nE n g i n e e r i n g\\n6 . 1 .\\nG e t t i n g\\nS t a r t e d\\nw i t h\\nP r o m p t\\nE n g i n e e r i n g\\n6 . 2 .\\nB u i l d i n g\\na n\\nE f f e c t i v e\\nP r o m p t\\nE n g i n e e r i n g\\nW o r k f l o w\\n6 . 3 .\\nO v e r c o m i n g\\nC o m m o n\\nC h a l l e n g e s\\ni n\\nP r o m p t\\nE n g i n e e r i n g\\n6 . 4 .\\nM e a s u r i n g\\nt h e\\nS u c c e s s\\no f\\nY o u r\\nP r o m p t\\nE n g i n e e r i n g\\nE f f o r t s\\nC o n c l u s i o n\\nA p p e n d i c e s\\nA .\\nR e c o m m e n d e d\\nb o o k s ,\\na r t i c l e s ,\\na n d\\nb l o g s\\nB :\\nO n l i n e\\nc o m m u n i t i e s\\na n d\\nf o r u m s\\nf o r\\nd i s c u s s i o n s\\na n d\\nc o l l a b o r a t i o n\\n1\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 1}\n",
      "page_content=\"I n t r o d u c t i o n\\nT h e\\nﬁ e l d\\no f\\na r t i ﬁ c i a l\\ni n t e l l i g e n c e\\n( A I )\\nh a s\\nc o m e\\na\\nl o n g\\nw a y\\ns i n c e\\ni t s\\ni n c e p t i o n ,\\nw i t h\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g\\np l a y i n g\\nc r u c i a l\\nr o l e s\\ni n\\ni t s\\na d v a n c e m e n t .\\nA s\\nd a t a\\ns c i e n t i s t s ,\\ni t ' s\\ne s s e n t i a l\\nt o\\ns t a y\\nu p d a t e d\\nw i t h\\nt h e\\nl a t e s t\\nt r e n d s\\na n d\\nt e c h n i q u e s\\nt o\\nu n l o c k\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\nA I\\ni n\\nv a r i o u s\\na p p l i c a t i o n s .\\nT h i s\\ns h o r t\\ne b o o k\\na i m s\\nt o\\np r o v i d e\\na\\nc o m p r e h e n s i v e\\ng u i d e\\no n\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g ,\\ne q u i p p i n g\\nr e a d e r s\\nw i t h\\nt h e\\nk n o w l e d g e\\na n d\\nt o o l s\\nn e c e s s a r y\\nt o\\ne x c e l\\ni n\\nt h e\\nr e a l m\\no f\\nd a t a\\ns c i e n c e .\\nG e n e r a t i v e\\nA I\\ne n c o m p a s s e s\\na\\nr a n g e\\no f\\nm o d e l s\\na n d\\nt e c h n i q u e s\\nd e s i g n e d\\nt o\\ng e n e r a t e\\nn e w\\nd a t a\\nb a s e d\\no n\\ne x i s t i n g\\ni n p u t\\nd a t a .\\nT h e s e\\nm o d e l s\\nh a v e\\nd e m o n s t r a t e d\\ns i g n i ﬁ c a n t\\nc a p a b i l i t i e s\\ni n\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g ,\\ni m a g e\\ng e n e r a t i o n ,\\na n d\\nm o r e .\\nB y\\nu n d e r s t a n d i n g\\nt h e\\nm e c h a n i c s\\na n d\\ni n t r i c a c i e s\\no f\\ng e n e r a t i v e\\nA I ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nh a r n e s s\\ni t s\\np o w e r\\nt o\\nc r e a t e\\ni n n o v a t i v e\\ns o l u t i o n s\\nf o r\\na\\nm u l t i t u d e\\no f\\np r o b l e m s .\\nP r o m p t\\ne n g i n e e r i n g ,\\no n\\nt h e\\no t h e r\\nh a n d ,\\nd e a l s\\nw i t h\\nt h e\\na r t\\no f\\nc r a f t i n g\\ne \\x00 e c t i v e\\np r o m p t s\\nt o\\ng u i d e\\nA I\\nm o d e l s\\ni n\\ng e n e r a t i n g\\nd e s i r e d\\no u t p u t s .\\nA s\\nA I\\nm o d e l s\\nb e c o m e\\nm o r e\\ns o p h i s t i c a t e d ,\\nt h e\\nn e e d\\nf o r\\ne \\x00 c i e n t\\na n d\\np r e c i s e\\np r o m p t\\ne n g i n e e r i n g\\nh a s\\ng r o w n\\nm o r e\\nc r i t i c a l .\\nB y\\nm a s t e r i n g\\nt h i s\\ns k i l l ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nb e t t e r\\nd i r e c t\\nA I\\nm o d e l s\\nt o\\np r o d u c e\\nt a r g e t e d\\nr e s u l t s ,\\nu l t i m a t e l y\\ne n h a n c i n g\\nt h e\\ne \\x00 c a c y\\no f\\nt h e i r\\na p p l i c a t i o n s .\\nT h i s\\ne b o o k\\nw i l l\\nd e l v e\\ni n t o\\nt h e\\nk e y\\nc o n c e p t s ,\\nb e s t\\np r a c t i c e s ,\\na n d\\nr e a l - w o r l d\\na p p l i c a t i o n s\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g .\\nI t\\nw i l l\\ne x p l o r e\\nt h e\\nc a p a b i l i t i e s\\na n d\\nl i m i t a t i o n s\\no f\\np o p u l a r\\nA I\\nm o d e l s ,\\nd e t a i l\\nt h e\\np r o c e s s\\no f\\nd e s i g n i n g\\ne \\x00 e c t i v e\\np r o m p t s ,\\na n d\\nd i s c u s s\\nt h e\\ne t h i c a l\\nc o n s i d e r a t i o n s\\nt h a t\\na r i s e\\nw h e n\\nw o r k i n g\\nw i t h\\nt h e s e\\nt e c h n o l o g i e s .\\nT o\\nf u r t h e r\\ns u p p o r t\\ny o u r\\nl e a r n i n g ,\\nt h e\\nb o o k\\nw i l l\\na l s o\\np r e s e n t\\na\\ns e r i e s\\no f\\nc a s e\\ns t u d i e s ,\\nd e m o n s t r a t i n g\\nt h e\\np r a c t i c a l\\na p p l i c a t i o n s\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g\\ni n\\nv a r i o u s\\ni n d u s t r i e s .\\nB y\\nt h e\\ne n d\\no f\\nt h i s\\ne b o o k ,\\ny o u\\nw i l l\\nh a v e\\ng a i n e d\\na\\ns o l i d\\nu n d e r s t a n d i n g\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g ,\\ne n a b l i n g\\ny o u\\nt o\\na p p l y\\nt h e s e\\nt e c h n i q u e s\\nt o\\ny o u r\\no w n\\np r o j e c t s\\ne \\x00 e c t i v e l y .\\nA s\\nA I\\nc o n t i n u e s\\nt o\\ne v o l v e\\na n d\\ni m p a c t\\no u r\\nw o r l d\\ni n\\nu n p r e c e d e n t e d\\nw a y s ,\\nt h e\\nk n o w l e d g e\\ny o u\\ng a i n\\nf r o m\\nt h i s\\ng u i d e\\nw i l l\\np r o v e\\ni n v a l u a b l e\\ni n\\ny o u r\\nj o u r n e y\\na s\\na\\nd a t a\\ns c i e n t i s t .\\n2\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 2}\n",
      "page_content=\"C h a p t e r\\n1 :\\nU n d e r s t a n d i n g\\nG e n e r a t i v e\\nA I\\nB y\\nu n d e r s t a n d i n g\\nt h e\\ne v o l u t i o n\\no f\\nA I\\na n d\\nt h e\\nm e c h a n i c s\\no f\\ng e n e r a t i v e\\nm o d e l s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nb e t t e r\\nh a r n e s s\\nt h e s e\\nc u t t i n g - e d g e\\nt e c h n o l o g i e s\\nt o\\nc r e a t e\\ni n n o v a t i v e\\ns o l u t i o n s\\nf o r\\na\\nd i v e r s e\\nr a n g e\\no f\\nc h a l l e n g e s .\\n1 . 1 .\\nE v o l u t i o n\\no f\\nA I :\\nF r o m\\nR u l e - B a s e d\\nt o\\nG e n e r a t i v e\\nM o d e l s\\nT h e\\nh i s t o r y\\no f\\na r t i ﬁ c i a l\\ni n t e l l i g e n c e\\nc a n\\nb e\\nt r a c e d\\nb a c k\\nt o\\nt h e\\nm i d - 2 0 t h\\nc e n t u r y\\nw h e n\\nt h e\\nﬁ r s t\\nA I\\nc o n c e p t s\\ne m e r g e d .\\nO v e r\\nt h e\\ny e a r s ,\\nA I\\nh a s\\ne v o l v e d\\nt h r o u g h\\ns e v e r a l\\ns t a g e s ,\\ne a c h\\nm a r k e d\\nb y\\ns i g n i ﬁ c a n t\\na d v a n c e m e n t s\\ni n\\nt e c h n o l o g y\\na n d\\nm e t h o d o l o g y .\\nO n e\\no f\\nt h e\\nm o s t\\nn o t a b l e\\nt r a n s i t i o n s\\ni n\\nA I\\nh a s\\nb e e n\\nt h e\\ns h i f t\\nf r o m\\nr u l e - b a s e d\\ns y s t e m s\\nt o\\ng e n e r a t i v e\\nm o d e l s .\\nI n\\nt h e\\ne a r l y\\nd a y s\\no f\\nA I ,\\nr u l e - b a s e d\\ns y s t e m s\\nw e r e\\nt h e\\np r e d o m i n a n t\\na p p r o a c h .\\nT h e s e\\ns y s t e m s\\nr e l i e d\\no n\\na\\ns e t\\no f\\np r e d e ﬁ n e d\\nr u l e s\\na n d\\nd e c i s i o n\\nt r e e s\\nt o\\np r o c e s s\\ni n p u t\\nd a t a\\na n d\\np r o d u c e\\no u t p u t .\\nW h i l e\\nr u l e - b a s e d\\ns y s t e m s\\nw e r e\\ne \\x00 e c t i v e\\nf o r\\ns i m p l e\\nt a s k s\\na n d\\ns c e n a r i o s\\nw i t h\\nl i m i t e d\\nv a r i a b i l i t y ,\\nt h e y\\ns t r u g g l e d\\nt o\\ns c a l e\\na n d\\na d a p t\\nt o\\nm o r e\\nc o m p l e x\\na n d\\nd y n a m i c\\ns i t u a t i o n s .\\nT h e\\nr i g i d i t y\\no f\\nt h e s e\\ns y s t e m s\\nm a d e\\ni t\\nc h a l l e n g i n g\\nt o\\na c c o u n t\\nf o r\\nt h e\\nv a s t\\na r r a y\\no f\\np o s s i b i l i t i e s\\na n d\\nn u a n c e s\\nf o u n d\\ni n\\nr e a l - w o r l d\\np r o b l e m s .\\nA s\\nA I\\nr e s e a r c h\\np r o g r e s s e d ,\\nm a c h i n e\\nl e a r n i n g\\ne m e r g e d\\na s\\na\\nm o r e\\nﬂ e x i b l e\\na n d\\na d a p t i v e\\na p p r o a c h .\\nM a c h i n e\\nl e a r n i n g\\nm o d e l s\\nl e a r n\\np a t t e r n s\\nf r o m\\nt r a i n i n g\\nd a t a\\na n d\\na p p l y\\nt h o s e\\np a t t e r n s\\nt o\\nm a k e\\np r e d i c t i o n s\\no r\\nd e c i s i o n s .\\nT h i s\\nd a t a - d r i v e n\\na p p r o a c h\\ne n a b l e d\\nA I\\ns y s t e m s\\nt o\\nt a c k l e\\ni n c r e a s i n g l y\\nc o m p l e x\\nt a s k s\\na n d\\nb e t t e r\\ng e n e r a l i z e\\nt o\\nn e w\\ns i t u a t i o n s .\\nG e n e r a t i v e\\nA I\\nr e p r e s e n t s\\nt h e\\nn e x t\\nl e a p\\ni n\\nA I ' s\\ne v o l u t i o n ,\\nb u i l d i n g\\nu p o n\\nm a c h i n e\\nl e a r n i n g ' s\\nf o u n d a t i o n .\\nU n l i k e\\nt r a d i t i o n a l\\nm a c h i n e\\nl e a r n i n g\\nm o d e l s\\nt h a t\\nf o c u s\\no n\\nd i s c r i m i n a t i v e\\nt a s k s — d e t e r m i n i n g\\nt h e\\nm o s t\\nl i k e l y\\no u t p u t\\ng i v e n\\na n\\ni n p u t — g e n e r a t i v e\\nm o d e l s\\na i m\\nt o\\ng e n e r a t e\\nn e w\\nd a t a\\nb a s e d\\no n\\nt h e\\np a t t e r n s\\na n d\\nd i s t r i b u t i o n s\\no b s e r v e d\\ni n\\nt h e\\nt r a i n i n g\\nd a t a .\\nT h i s\\na b i l i t y\\nt o\\nc r e a t e\\nn o v e l\\nd a t a\\na l l o w s\\ng e n e r a t i v e\\nA I\\nt o\\ne x c e l\\ni n\\na\\nw i d e\\nr a n g e\\no f\\na p p l i c a t i o n s ,\\ni n c l u d i n g\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g ,\\ni m a g e\\ns y n t h e s i s ,\\na n d\\nm o r e .\\n3\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 3}\n",
      "page_content=\"S o m e\\no f\\nt h e\\nk e y\\ng e n e r a t i v e\\nA I\\nm o d e l s\\ni n c l u d e :\\n●\\nR e s t r i c t e d\\nB o l t z m a n n\\nM a c h i n e s\\n( R B M s )\\n●\\nV a r i a t i o n a l\\nA u t o e n c o d e r s\\n( V A E s )\\n●\\nG e n e r a t i v e\\nA d v e r s a r i a l\\nN e t w o r k s\\n( G A N s )\\n●\\nR e c u r r e n t\\nN e u r a l\\nN e t w o r k s\\n( R N N s )\\n●\\nL o n g\\nS h o r t - T e r m\\nM e m o r y\\n( L S T M s )\\n●\\nT r a n s f o r m e r s\\nT h e s e\\nm o d e l s\\nh a v e\\nb e e n\\nd e v e l o p e d\\na n d\\nr e ﬁ n e d\\no v e r\\nt h e\\ny e a r s ,\\nl e a d i n g\\nt o\\ni n c r e a s i n g l y\\np o w e r f u l\\na n d\\ns o p h i s t i c a t e d\\nA I\\ns y s t e m s .\\nB y\\nu n d e r s t a n d i n g\\nt h e\\ne v o l u t i o n\\no f\\nA I\\na n d\\nt h e\\nm e c h a n i c s\\no f\\ng e n e r a t i v e\\nm o d e l s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nb e t t e r\\nh a r n e s s\\nt h e s e\\nc u t t i n g - e d g e\\nt e c h n o l o g i e s\\nt o\\nc r e a t e\\ni n n o v a t i v e\\ns o l u t i o n s\\nf o r\\na\\nd i v e r s e\\nr a n g e\\no f\\nc h a l l e n g e s .\\n1 . 2 .\\nK e y\\nG e n e r a t i v e\\nA I\\nM o d e l s :\\nR N N s ,\\nL S T M s ,\\nG P T ,\\na n d\\nM o r e\\nA s\\ng e n e r a t i v e\\nA I\\nh a s\\ne v o l v e d ,\\ns e v e r a l\\nk e y\\nm o d e l s\\nh a v e\\ne m e r g e d ,\\ne a c h\\nw i t h\\ni t s\\no w n\\nu n i q u e\\nc a p a b i l i t i e s\\na n d\\ns t r e n g t h s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\ne x p l o r e\\ns o m e\\no f\\nt h e\\nm o s t\\np r o m i n e n t\\ng e n e r a t i v e\\nA I\\nm o d e l s ,\\ni n c l u d i n g\\nR N N s ,\\nL S T M s ,\\na n d\\nG P T .\\nR e s t r i c t e d\\nB o l t z m a n n\\nM a c h i n e s\\n( R B M s )\\nR B M s\\na r e\\na\\nt y p e\\no f\\nu n s u p e r v i s e d\\nl e a r n i n g\\nm o d e l\\nt h a t\\nc a n\\nl e a r n\\na\\np r o b a b i l i t y\\nd i s t r i b u t i o n\\no v e r\\ni n p u t\\nd a t a .\\nT h e y\\nc o n s i s t\\no f\\nt w o\\nl a y e r s ,\\na\\nv i s i b l e\\nl a y e r\\nt h a t\\nr e p r e s e n t s\\ni n p u t\\nd a t a\\na n d\\na\\nh i d d e n\\nl a y e r\\nt h a t\\nc a p t u r e s\\nl a t e n t\\nf e a t u r e s .\\nR B M s\\nh a v e\\nb e e n\\nu s e d\\nf o r\\nv a r i o u s\\ng e n e r a t i v e\\nt a s k s ,\\ns u c h\\na s\\ni m a g e\\ns y n t h e s i s\\na n d\\nf e a t u r e\\nl e a r n i n g .\\nV a r i a t i o n a l\\nA u t o e n c o d e r s\\n( V A E s )\\nV A E s\\na r e\\na\\nt y p e\\no f\\ng e n e r a t i v e\\nm o d e l\\nt h a t\\nc o m b i n e s\\na s p e c t s\\no f\\nd e e p\\nl e a r n i n g\\na n d\\nB a y e s i a n\\ni n f e r e n c e\\nt o\\nl e a r n\\nc o m p l e x\\nd a t a\\nd i s t r i b u t i o n s .\\nT h e y\\nc o n s i s t\\no f\\na n\\ne n c o d e r ,\\nw h i c h\\nm a p s\\ni n p u t\\nd a t a\\nt o\\na\\nl a t e n t\\ns p a c e ,\\na n d\\na\\nd e c o d e r ,\\nw h i c h\\nr e c o n s t r u c t s\\nd a t a\\nf r o m\\nt h e\\nl a t e n t\\ns p a c e .\\nV A E s\\nh a v e\\nb e e n\\nu s e d\\nf o r\\nv a r i o u s\\ng e n e r a t i v e\\nt a s k s ,\\ni n c l u d i n g\\ni m a g e\\ns y n t h e s i s ,\\nt e x t\\ng e n e r a t i o n ,\\na n d\\ns t y l e\\nt r a n s f e r .\\nG e n e r a t i v e\\nA d v e r s a r i a l\\nN e t w o r k s\\n( G A N s )\\nG A N s\\nc o n s i s t\\no f\\nt w o\\nn e u r a l\\nn e t w o r k s ,\\na\\ng e n e r a t o r\\na n d\\na\\nd i s c r i m i n a t o r ,\\nt h a t\\nc o m p e t e\\na g a i n s t\\ne a c h\\no t h e r\\ni n\\na\\nz e r o - s u m\\ng a m e .\\nT h e\\ng e n e r a t o r\\nc r e a t e s\\ns y n t h e t i c\\nd a t a ,\\nw h i l e\\nt h e\\nd i s c r i m i n a t o r\\n4\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 4}\n",
      "page_content=\"a t t e m p t s\\nt o\\nd i s t i n g u i s h\\nb e t w e e n\\nr e a l\\na n d\\ng e n e r a t e d\\nd a t a .\\nG A N s\\nh a v e\\ns h o w n\\nr e m a r k a b l e\\ns u c c e s s\\ni n\\ng e n e r a t i n g\\nh i g h - q u a l i t y\\ni m a g e s ,\\nm u s i c ,\\na n d\\ne v e n\\nt e x t .\\nR e c u r r e n t\\nN e u r a l\\nN e t w o r k s\\n( R N N s )\\nR N N s\\na r e\\na\\nc l a s s\\no f\\nn e u r a l\\nn e t w o r k s\\nd e s i g n e d\\nt o\\np r o c e s s\\ns e q u e n c e s\\no f\\nd a t a .\\nU n l i k e\\nf e e d f o r w a r d\\nn e t w o r k s ,\\nR N N s\\nh a v e\\na\\nf e e d b a c k\\nl o o p\\nt h a t\\na l l o w s\\nt h e m\\nt o\\nm a i n t a i n\\na n\\ni n t e r n a l\\ns t a t e ,\\nm a k i n g\\nt h e m\\nw e l l - s u i t e d\\nf o r\\nt a s k s\\ni n v o l v i n g\\nt i m e\\ns e r i e s\\no r\\ns e q u e n t i a l\\nd a t a .\\nR N N s\\nh a v e\\nb e e n\\nu s e d\\nf o r\\na\\nv a r i e t y\\no f\\ng e n e r a t i v e\\nt a s k s ,\\ns u c h\\na s\\nt e x t\\ng e n e r a t i o n ,\\ns p e e c h\\ns y n t h e s i s ,\\na n d\\nm u s i c\\nc o m p o s i t i o n .\\nL o n g\\nS h o r t - T e r m\\nM e m o r y\\n( L S T M s )\\nL S T M s\\na r e\\na\\nt y p e\\no f\\nR N N\\ns p e c i ﬁ c a l l y\\nd e s i g n e d\\nt o\\na d d r e s s\\nt h e\\nv a n i s h i n g\\ng r a d i e n t\\np r o b l e m ,\\nw h i c h\\nc a n\\no c c u r\\nw h e n\\nt r a i n i n g\\nR N N s\\no n\\nl o n g\\ns e q u e n c e s .\\nB y\\ni n c o r p o r a t i n g\\nm e m o r y\\nc e l l s\\na n d\\ng a t i n g\\nm e c h a n i s m s ,\\nL S T M s\\nc a n\\ne \\x00 e c t i v e l y\\nl e a r n\\nl o n g - r a n g e\\nd e p e n d e n c i e s\\ni n\\ns e q u e n t i a l\\nd a t a .\\nT h e y\\nh a v e\\nb e e n\\nw i d e l y\\nu s e d\\ni n\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g ,\\ns p e e c h\\nr e c o g n i t i o n ,\\na n d\\no t h e r\\ng e n e r a t i v e\\nt a s k s .\\nT r a n s f o r m e r s\\nT r a n s f o r m e r s\\na r e\\na\\nt y p e\\no f\\nn e u r a l\\nn e t w o r k\\na r c h i t e c t u r e\\nt h a t\\nu t i l i z e s\\ns e l f - a t t e n t i o n\\nm e c h a n i s m s\\nt o\\np r o c e s s\\ni n p u t\\nd a t a .\\nU n l i k e\\nR N N s\\na n d\\nL S T M s ,\\nt r a n s f o r m e r s\\nc a n\\np r o c e s s\\ns e q u e n c e s\\ni n\\np a r a l l e l ,\\nm a k i n g\\nt h e m\\nh i g h l y\\ne \\x00 c i e n t\\nf o r\\nl a r g e - s c a l e\\nt a s k s .\\nG P T\\n( G e n e r a t i v e\\nP r e - t r a i n e d\\nT r a n s f o r m e r )\\ni s\\na\\np o p u l a r\\nt r a n s f o r m e r - b a s e d\\nm o d e l\\nd e v e l o p e d\\nb y\\nO p e n A I ,\\nk n o w n\\nf o r\\ni t s\\ni m p r e s s i v e\\nc a p a b i l i t i e s\\ni n\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g\\na n d\\ng e n e r a t i o n .\\nT h e s e\\ng e n e r a t i v e\\nA I\\nm o d e l s\\no \\x00 e r\\nd a t a\\ns c i e n t i s t s\\na\\np o w e r f u l\\nt o o l b o x\\nf o r\\nt a c k l i n g\\na\\nw i d e\\nr a n g e\\no f\\na p p l i c a t i o n s\\na n d\\nc h a l l e n g e s .\\nB y\\nu n d e r s t a n d i n g\\nt h e\\ns t r e n g t h s\\na n d\\nl i m i t a t i o n s\\no f\\ne a c h\\nm o d e l ,\\ny o u\\nc a n\\nc h o o s e\\nt h e\\nm o s t\\ns u i t a b l e\\na p p r o a c h\\nf o r\\ny o u r\\ns p e c i ﬁ c\\nd a t a\\ns c i e n c e\\np r o j e c t\\na n d\\nh a r n e s s\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I .\\n1 . 3 .\\nP o p u l a r\\nU s e\\nC a s e s\\nf o r\\nG e n e r a t i v e\\nA I\\nG e n e r a t i v e\\nA I\\nh a s\\nd e m o n s t r a t e d\\ns i g n i ﬁ c a n t\\np o t e n t i a l\\ni n\\na\\nw i d e\\nr a n g e\\no f\\na p p l i c a t i o n s ,\\nt h a n k s\\nt o\\ni t s\\na b i l i t y\\nt o\\nc r e a t e\\nn o v e l\\nd a t a\\nb a s e d\\no n\\ne x i s t i n g\\np a t t e r n s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\ne x p l o r e\\ns o m e\\np o p u l a r\\nu s e\\nc a s e s\\nf o r\\ng e n e r a t i v e\\nA I ,\\ns h o w c a s i n g\\ni t s\\nv e r s a t i l i t y\\na n d\\ni m p a c t\\na c r o s s\\nv a r i o u s\\nd o m a i n s .\\n5\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 5}\n",
      "page_content='N a t u r a l\\nL a n g u a g e\\nP r o c e s s i n g\\n( N L P )\\nG e n e r a t i v e\\nA I\\nh a s\\nr e v o l u t i o n i z e d\\nN L P\\nb y\\ne n a b l i n g\\nt h e\\ng e n e r a t i o n\\no f\\nc o h e r e n t\\na n d\\nc o n t e x t u a l l y\\nr e l e v a n t\\nt e x t .\\nA p p l i c a t i o n s\\ni n c l u d e\\nc h a t b o t s ,\\ns u m m a r i z a t i o n ,\\nt r a n s l a t i o n ,\\nc o n t e n t\\ng e n e r a t i o n ,\\na n d\\nm o r e .\\nM o d e l s\\nl i k e\\nG P T\\nh a v e\\nd e m o n s t r a t e d\\ni m p r e s s i v e\\nc a p a b i l i t i e s\\ni n\\ng e n e r a t i n g\\nh u m a n - l i k e\\nt e x t ,\\nm a k i n g\\nt h e m\\ni n v a l u a b l e\\nf o r\\nN L P\\nt a s k s .\\nI m a g e\\nS y n t h e s i s\\na n d\\nE d i t i n g\\nG e n e r a t i v e\\nm o d e l s\\nl i k e\\nG A N s\\na n d\\nV A E s\\nh a v e\\nm a d e\\ns i g n i ﬁ c a n t\\ns t r i d e s\\ni n\\ni m a g e\\ns y n t h e s i s ,\\ne n a b l i n g\\nt h e\\nc r e a t i o n\\no f\\nr e a l i s t i c\\ni m a g e s\\nf r o m\\ns c r a t c h\\no r\\nb a s e d\\no n\\ns p e c i ﬁ c\\na t t r i b u t e s .\\nT h e s e\\nm o d e l s\\nc a n\\na l s o\\nb e\\nu s e d\\nf o r\\ni m a g e - t o - i m a g e\\nt r a n s l a t i o n ,\\ns t y l e\\nt r a n s f e r ,\\na n d\\ni n p a i n t i n g ,\\no \\x00 e r i n g\\nn u m e r o u s\\np o s s i b i l i t i e s\\nf o r\\na r t i s t s ,\\nd e s i g n e r s ,\\na n d\\nr e s e a r c h e r s .\\nM u s i c\\na n d\\nA u d i o\\nG e n e r a t i o n\\nG e n e r a t i v e\\nA I\\nh a s\\nb e e n\\nu s e d\\nt o\\nc r e a t e\\no r i g i n a l\\nm u s i c\\nc o m p o s i t i o n s ,\\ns o u n d\\ne \\x00 e c t s ,\\na n d\\ne v e n\\ns p e e c h\\ns y n t h e s i s .\\nR N N s ,\\nL S T M s ,\\na n d\\nt r a n s f o r m e r s\\nh a v e\\ns h o w n\\np r o m i s e\\ni n\\nc a p t u r i n g\\nt h e\\ns t r u c t u r e\\na n d\\np a t t e r n s\\no f\\nm u s i c ,\\na l l o w i n g\\nf o r\\nt h e\\ng e n e r a t i o n\\no f\\nn e w\\nm e l o d i e s ,\\nh a r m o n i e s ,\\na n d\\nr h y t h m s .\\nD r u g\\nD i s c o v e r y\\na n d\\nM a t e r i a l\\nS c i e n c e\\nG e n e r a t i v e\\nm o d e l s\\nc a n\\nb e\\ne m p l o y e d\\nt o\\ng e n e r a t e\\nn o v e l\\nm o l e c u l a r\\ns t r u c t u r e s\\na n d\\nm a t e r i a l s\\nw i t h\\nd e s i r e d\\np r o p e r t i e s ,\\na c c e l e r a t i n g\\nt h e\\nd r u g\\nd i s c o v e r y\\na n d\\nm a t e r i a l\\nd e s i g n\\np r o c e s s e s .\\nB y\\ne x p l o r i n g\\nt h e\\nv a s t\\ns p a c e\\no f\\nc h e m i c a l\\na n d\\nm a t e r i a l\\nc o m p o s i t i o n s ,\\ng e n e r a t i v e\\nA I\\nc a n\\nh e l p\\ni d e n t i f y\\np r o m i s i n g\\nc a n d i d a t e s\\nf o r\\nf u r t h e r\\ne x p e r i m e n t a t i o n\\na n d\\nt e s t i n g .\\nA n o m a l y\\nD e t e c t i o n\\na n d\\nP a t t e r n\\nR e c o g n i t i o n\\nG e n e r a t i v e\\nA I\\nc a n\\nb e\\nu s e d\\nt o\\nm o d e l\\nt h e\\nu n d e r l y i n g\\nd i s t r i b u t i o n\\no f\\nd a t a ,\\nm a k i n g\\ni t\\np o s s i b l e\\nt o\\ni d e n t i f y\\no u t l i e r s\\na n d\\na n o m a l i e s .\\nT h i s\\nc a p a b i l i t y\\nh a s\\nv a l u a b l e\\na p p l i c a t i o n s\\ni n\\nf r a u d\\nd e t e c t i o n ,\\nn e t w o r k\\ns e c u r i t y ,\\na n d\\nq u a l i t y\\nc o n t r o l ,\\na m o n g\\no t h e r s .\\nD a t a\\nA u g m e n t a t i o n\\nI n\\ns i t u a t i o n s\\nw h e r e\\nd a t a\\ni s\\ns c a r c e\\no r\\ni m b a l a n c e d ,\\ng e n e r a t i v e\\nm o d e l s\\nc a n\\nh e l p\\nc r e a t e\\na d d i t i o n a l\\nt r a i n i n g\\ns a m p l e s ,\\ne n h a n c i n g\\nt h e\\np e r f o r m a n c e\\no f\\nm a c h i n e\\nl e a r n i n g\\na l g o r i t h m s .\\nT h i s\\ni s\\np a r t i c u l a r l y\\nu s e f u l\\ni n\\nd o m a i n s\\nw h e r e\\nd a t a\\nc o l l e c t i o n\\ni s\\ne x p e n s i v e ,\\nt i m e - c o n s u m i n g ,\\no r\\ne t h i c a l l y\\nc h a l l e n g i n g .\\n6\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 6}\n",
      "page_content='S i m u l a t i o n\\na n d\\nS c e n a r i o\\nP l a n n i n g\\nG e n e r a t i v e\\nA I\\nc a n\\nc r e a t e\\ns y n t h e t i c\\nd a t a\\nt o\\ns i m u l a t e\\nv a r i o u s\\ns c e n a r i o s ,\\ne n a b l i n g\\nb u s i n e s s e s\\na n d\\nr e s e a r c h e r s\\nt o\\nt e s t\\nh y p o t h e s e s ,\\ne v a l u a t e\\ns t r a t e g i e s ,\\na n d\\nm a k e\\ni n f o r m e d\\nd e c i s i o n s .\\nT h i s\\nc a n\\nb e\\np a r t i c u l a r l y\\nu s e f u l\\ni n\\nﬁ e l d s\\nl i k e\\nﬁ n a n c e ,\\nl o g i s t i c s ,\\nu r b a n\\np l a n n i n g ,\\na n d\\ne n v i r o n m e n t a l\\ns t u d i e s .\\nT h e s e\\nu s e\\nc a s e s\\nr e p r e s e n t\\nj u s t\\na\\ng l i m p s e\\no f\\nt h e\\np o t e n t i a l\\na p p l i c a t i o n s\\nf o r\\ng e n e r a t i v e\\nA I .\\nA s\\nt h e\\nt e c h n o l o g y\\nc o n t i n u e s\\nt o\\na d v a n c e\\na n d\\nm a t u r e ,\\ni t\\ni s\\nl i k e l y\\nt h a t\\ne v e n\\nm o r e\\ni n n o v a t i v e\\na n d\\nt r a n s f o r m a t i v e\\na p p l i c a t i o n s\\nw i l l\\ne m e r g e ,\\nf u r t h e r\\ns o l i d i f y i n g\\nt h e\\ni m p o r t a n c e\\no f\\ng e n e r a t i v e\\nA I\\ni n\\nt h e\\nr e a l m\\no f\\nd a t a\\ns c i e n c e .\\n7\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 7}\n",
      "page_content=\"C h a p t e r\\n2 :\\nI n t r o d u c t i o n\\nt o\\nP r o m p t\\nE n g i n e e r i n g\\nT h e\\ni m p o r t a n c e\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni s\\nf u r t h e r\\nu n d e r s c o r e d\\nb y\\nt h e\\nr a p i d\\ng r o w t h\\na n d\\na d o p t i o n\\no f\\nt r a n s f o r m e r - b a s e d\\nm o d e l s\\nl i k e\\nG P T ,\\nw h i c h\\na r e\\nh e a v i l y\\nr e l i a n t\\no n\\np r o m p t s\\nt o\\ng e n e r a t e\\no u t p u t s .\\n2 . 1 .\\nW h a t\\nP r o m p t\\nE n g i n e e r i n g\\ni s\\na n d\\nW h y\\ni t\\nM a t t e r s\\nP r o m p t\\ne n g i n e e r i n g\\ni s\\nt h e\\np r o c e s s\\no f\\nc r a f t i n g\\ne \\x00 e c t i v e\\np r o m p t s\\nt o\\ng u i d e\\nA I\\nm o d e l s ,\\np a r t i c u l a r l y\\ng e n e r a t i v e\\nm o d e l s ,\\ni n\\ng e n e r a t i n g\\nt h e\\nd e s i r e d\\no u t p u t s .\\nA\\np r o m p t\\ni s\\na n\\ni n p u t\\ng i v e n\\nt o\\na n\\nA I\\nm o d e l\\nt h a t\\ns e t s\\nt h e\\nc o n t e x t ,\\ng o a l ,\\no r\\nc o n s t r a i n t s\\nf o r\\nt h e\\nm o d e l ' s\\nr e s p o n s e .\\nT h e\\nq u a l i t y\\no f\\na\\np r o m p t\\nc a n\\ns i g n i ﬁ c a n t l y\\ni n ﬂ u e n c e\\nt h e\\nq u a l i t y ,\\nr e l e v a n c e ,\\na n d\\na c c u r a c y\\no f\\nt h e\\nA I - g e n e r a t e d\\no u t p u t .\\nA s\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nb e c o m e\\nm o r e\\ns o p h i s t i c a t e d\\na n d\\nc o m p l e x ,\\nt h e\\nn e e d\\nf o r\\ne \\x00 c i e n t\\na n d\\np r e c i s e\\np r o m p t\\ne n g i n e e r i n g\\ng r o w s\\nm o r e\\nc r i t i c a l .\\nA\\nw e l l - c r a f t e d\\np r o m p t\\nc a n\\nh e l p\\nm a x i m i z e\\nt h e\\np o t e n t i a l\\no f\\nA I\\nm o d e l s\\nb y\\ne n s u r i n g\\nt h a t\\nt h e y\\np r o d u c e\\nt a r g e t e d ,\\nm e a n i n g f u l ,\\na n d\\nc o n t e x t u a l l y\\na p p r o p r i a t e\\nr e s p o n s e s .\\nI n\\nc o n t r a s t ,\\na n\\ni n e \\x00 e c t i v e\\np r o m p t\\nm a y\\nl e a d\\nt o\\na m b i g u o u s ,\\ni r r e l e v a n t ,\\no r\\ne v e n\\nn o n s e n s i c a l\\no u t p u t s .\\nP r o m p t\\ne n g i n e e r i n g\\np l a y s\\na\\nc r u c i a l\\nr o l e\\ni n\\nt h e\\ns u c c e s s\\no f\\nA I\\na p p l i c a t i o n s\\na c r o s s\\nv a r i o u s\\nd o m a i n s ,\\nf r o m\\nc o n t e n t\\ng e n e r a t i o n\\na n d\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g\\nt o\\nd a t a\\na n a l y s i s\\na n d\\nv i s u a l i z a t i o n .\\nB y\\nm a s t e r i n g\\nt h e\\na r t\\no f\\np r o m p t\\ne n g i n e e r i n g ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nb e t t e r\\nd i r e c t\\nA I\\nm o d e l s\\nt o\\na c h i e v e\\ns p e c i ﬁ c\\no b j e c t i v e s ,\\no p t i m i z e\\ns y s t e m\\np e r f o r m a n c e ,\\na n d\\ne n h a n c e\\nt h e\\no v e r a l l\\nu s e r\\ne x p e r i e n c e .\\nT h e\\ni m p o r t a n c e\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni s\\nf u r t h e r\\nu n d e r s c o r e d\\nb y\\nt h e\\nr a p i d\\ng r o w t h\\na n d\\na d o p t i o n\\no f\\nt r a n s f o r m e r - b a s e d\\nm o d e l s\\nl i k e\\nG P T ,\\nw h i c h\\na r e\\nh e a v i l y\\nr e l i a n t\\no n\\np r o m p t s\\nt o\\ng e n e r a t e\\no u t p u t s .\\nG i v e n\\nt h e\\nv a s t\\nc a p a b i l i t i e s\\na n d\\np o t e n t i a l\\na p p l i c a t i o n s\\no f\\nt h e s e\\nm o d e l s ,\\nd e v e l o p i n g\\na\\nd e e p\\nu n d e r s t a n d i n g\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni s\\ne s s e n t i a l\\nf o r\\nd a t a\\ns c i e n t i s t s\\nl o o k i n g\\nt o\\nh a r n e s s\\nt h e\\np o w e r\\no f\\ng e n e r a t i v e\\nA I\\ne \\x00 e c t i v e l y .\\n8\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 8}\n",
      "page_content='2 . 2 .\\nP r o m p t\\nT y p e s :\\nE x p l i c i t ,\\nI m p l i c i t ,\\na n d\\nC r e a t i v e\\nP r o m p t s\\nP r o m p t s\\nc a n\\nb e\\nc a t e g o r i z e d\\ni n t o\\nd i \\x00 e r e n t\\nt y p e s\\nb a s e d\\no n\\nt h e i r\\ns t r u c t u r e ,\\np u r p o s e ,\\na n d\\nt h e\\nl e v e l\\no f\\ng u i d a n c e\\nt h e y\\np r o v i d e\\nt o\\nt h e\\nA I\\nm o d e l .\\nU n d e r s t a n d i n g\\nt h e\\nv a r i o u s\\np r o m p t\\nt y p e s\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\nc r a f t\\ne \\x00 e c t i v e\\np r o m p t s\\nt h a t\\ny i e l d\\nt h e\\nd e s i r e d\\nr e s u l t s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e\\nw i l l\\nd i s c u s s\\nt h r e e\\nc o m m o n\\np r o m p t\\nt y p e s :\\ne x p l i c i t ,\\ni m p l i c i t ,\\na n d\\nc r e a t i v e\\np r o m p t s .\\nE x p l i c i t\\nP r o m p t s\\nE x p l i c i t\\np r o m p t s\\np r o v i d e\\nc l e a r\\na n d\\nd i r e c t\\ni n s t r u c t i o n s\\nt o\\nt h e\\nA I\\nm o d e l ,\\ns p e c i f y i n g\\nt h e\\ne x a c t\\nf o r m a t\\no r\\ni n f o r m a t i o n\\nr e q u i r e d\\ni n\\nt h e\\ng e n e r a t e d\\no u t p u t .\\nT h e s e\\np r o m p t s\\no f t e n\\ni n c l u d e\\nk e y w o r d s\\no r\\np h r a s e s\\nt h a t\\ng u i d e\\nt h e\\nm o d e l\\nt o w a r d s\\na\\ns p e c i ﬁ c\\nr e s p o n s e .\\nF o r\\ne x a m p l e ,\\na n\\ne x p l i c i t\\np r o m p t\\nf o r\\na\\nt r a n s l a t i o n\\nt a s k\\nm i g h t\\nb e ,\\n\" T r a n s l a t e\\nt h e\\nf o l l o w i n g\\nE n g l i s h\\nt e x t\\nt o\\nF r e n c h :\\n\\' T h e\\nw e a t h e r\\ni s\\nn i c e\\nt o d a y . \\' \"\\nE x p l i c i t\\np r o m p t s\\na r e\\ng e n e r a l l y\\ne a s i e r\\nf o r\\nA I\\nm o d e l s\\nt o\\ni n t e r p r e t\\na n d\\nc a n\\nl e a d\\nt o\\nm o r e\\na c c u r a t e\\na n d\\nr e l e v a n t\\nr e s u l t s .\\nH o w e v e r ,\\nt h e y\\nm a y\\ns o m e t i m e s\\nl i m i t\\nt h e\\nm o d e l \\' s\\na b i l i t y\\nt o\\ng e n e r a t e\\nc r e a t i v e\\no r\\nn u a n c e d\\no u t p u t s .\\nI m p l i c i t\\nP r o m p t s\\nI m p l i c i t\\np r o m p t s\\na r e\\nl e s s\\nd i r e c t\\ni n\\nt h e i r\\ni n s t r u c t i o n s ,\\na l l o w i n g\\nt h e\\nA I\\nm o d e l\\nm o r e\\nf r e e d o m\\nt o\\ni n t e r p r e t\\nt h e\\nd e s i r e d\\no u t c o m e .\\nT h e s e\\np r o m p t s\\nr e l y\\no n\\nt h e\\nm o d e l \\' s\\nu n d e r s t a n d i n g\\no f\\nc o n t e x t ,\\nr e l a t i o n s h i p s ,\\no r\\nc o n v e n t i o n s\\nt o\\ng e n e r a t e\\na n\\na p p r o p r i a t e\\nr e s p o n s e .\\nF o r\\ne x a m p l e ,\\na n\\ni m p l i c i t\\np r o m p t\\nf o r\\na\\nt r a n s l a t i o n\\nt a s k\\nm i g h t\\nb e ,\\n\" H o w\\nw o u l d\\ny o u\\ns a y\\n\\' T h e\\nw e a t h e r\\ni s\\nn i c e\\nt o d a y \\'\\ni n\\nF r e n c h ? \"\\nI m p l i c i t\\np r o m p t s\\nc a n\\ne n c o u r a g e\\nA I\\nm o d e l s\\nt o\\nt h i n k\\nm o r e\\nc r e a t i v e l y\\na n d\\ng e n e r a t e\\nm o r e\\nd i v e r s e\\no u t p u t s .\\nH o w e v e r ,\\nt h e y\\nm a y\\na l s o\\ni n c r e a s e\\nt h e\\nr i s k\\no f\\ng e n e r a t i n g\\na m b i g u o u s\\no r\\no \\x00 - t o p i c\\nr e s p o n s e s .\\nC r e a t i v e\\nP r o m p t s\\nC r e a t i v e\\np r o m p t s\\na r e\\nd e s i g n e d\\nt o\\ne n c o u r a g e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nn o v e l ,\\ni m a g i n a t i v e ,\\no r\\nu n c o n v e n t i o n a l\\no u t p u t s .\\nT h e s e\\np r o m p t s\\no f t e n\\ni n v o l v e\\no p e n - e n d e d\\nq u e s t i o n s ,\\ns c e n a r i o s ,\\no r\\nc h a l l e n g e s\\nt h a t\\nr e q u i r e\\nt h e\\nm o d e l\\nt o\\nt h i n k\\nb e y o n d\\ni t s\\nt r a i n i n g\\nd a t a\\na n d\\ne x p l o r e\\nn e w\\ni d e a s\\no r\\np e r s p e c t i v e s .\\nF o r\\ne x a m p l e ,\\na\\nc r e a t i v e\\np r o m p t\\nf o r\\na\\ns t o r y t e l l i n g\\nt a s k\\nm i g h t\\nb e ,\\n\" W r i t e\\na\\ns h o r t\\ns t o r y\\na b o u t\\na\\nw o r l d\\nw h e r e\\nt h e\\nw e a t h e r\\nc h a n g e s\\nb a s e d\\no n\\np e o p l e \\' s\\ne m o t i o n s . \"\\nC r e a t i v e\\np r o m p t s\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\nt a p\\ni n t o\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I ,\\ne n a b l i n g\\nt h e\\nc r e a t i o n\\no f\\nu n i q u e\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nH o w e v e r ,\\nt h e y\\nm a y\\na l s o\\nr e q u i r e\\nm o r e\\ni t e r a t i o n\\na n d\\nﬁ n e - t u n i n g\\nt o\\na c h i e v e\\nt h e\\nd e s i r e d\\nr e s u l t s .\\n9\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 9}\n",
      "page_content=\"B y\\nu n d e r s t a n d i n g\\nt h e\\nd i \\x00 e r e n t\\np r o m p t\\nt y p e s\\na n d\\nt h e i r\\nr e s p e c t i v e\\ns t r e n g t h s\\na n d\\nl i m i t a t i o n s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nc h o o s e\\nt h e\\nm o s t\\na p p r o p r i a t e\\na p p r o a c h\\nf o r\\nt h e i r\\ns p e c i ﬁ c\\nA I\\na p p l i c a t i o n .\\nA d d i t i o n a l l y ,\\nm a s t e r i n g\\nt h e\\na r t\\no f\\nc r a f t i n g\\nv a r i o u s\\np r o m p t\\nt y p e s\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\nh a r n e s s\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\na n d\\no p t i m i z e\\nt h e i r\\np e r f o r m a n c e\\na c r o s s\\na\\nd i v e r s e\\nr a n g e\\no f\\nt a s k s .\\n2 . 3 .\\nB e s t\\nP r a c t i c e s\\nf o r\\nC r a f t i n g\\nE \\x00 e c t i v e\\nP r o m p t s\\nC r e a t i n g\\ne \\x00 e c t i v e\\np r o m p t s\\ni s\\na n\\ne s s e n t i a l\\ns k i l l\\nf o r\\nd a t a\\ns c i e n t i s t s\\nw o r k i n g\\nw i t h\\ng e n e r a t i v e\\nA I\\nm o d e l s .\\nT h e\\nf o l l o w i n g\\nb e s t\\np r a c t i c e s\\nc a n\\nh e l p\\ny o u\\nc r a f t\\np r o m p t s\\nt h a t\\ny i e l d\\na c c u r a t e ,\\nr e l e v a n t ,\\na n d\\nm e a n i n g f u l\\no u t p u t s\\nw h i l e\\nm i n i m i z i n g\\nt h e\\nr i s k\\no f\\ng e n e r a t i n g\\na m b i g u o u s\\no r\\no \\x00 - t o p i c\\nr e s p o n s e s .\\nB e\\nc l e a r\\na n d\\nc o n c i s e\\nE n s u r e\\nt h a t\\ny o u r\\np r o m p t\\ni s\\ne a s y\\nt o\\nu n d e r s t a n d\\na n d\\np r o v i d e s\\nc l e a r\\ni n s t r u c t i o n s\\nf o r\\nt h e\\nA I\\nm o d e l .\\nA v o i d\\nu s i n g\\no v e r l y\\nc o m p l e x\\nl a n g u a g e\\no r\\nu n n e c e s s a r y\\nj a r g o n\\nt h a t\\nm a y\\nc o n f u s e\\nt h e\\nm o d e l .\\nK e e p i n g\\ny o u r\\np r o m p t\\nc o n c i s e\\nc a n\\na l s o\\nh e l p\\nt h e\\nm o d e l\\nf o c u s\\no n\\nt h e\\ne s s e n t i a l\\ni n f o r m a t i o n\\na n d\\ng e n e r a t e\\nm o r e\\na c c u r a t e\\nr e s u l t s .\\nP r o v i d e\\nc o n t e x t\\nI n c l u d i n g\\nc o n t e x t\\ni n\\ny o u r\\np r o m p t\\nc a n\\nh e l p\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nt o w a r d s\\na\\nm o r e\\nr e l e v a n t\\na n d\\na c c u r a t e\\no u t p u t .\\nF o r\\ne x a m p l e ,\\ni f\\ny o u ' r e\\na s k i n g\\nt h e\\nm o d e l\\nt o\\ng e n e r a t e\\na\\ns u m m a r y\\no f\\na n\\na r t i c l e ,\\np r o v i d i n g\\nt h e\\na r t i c l e ' s\\nt i t l e ,\\na u t h o r ,\\na n d\\np u b l i c a t i o n\\nd a t e\\nc a n\\nh e l p\\nt h e\\nm o d e l\\nu n d e r s t a n d\\nt h e\\nc o n t e x t\\na n d\\ng e n e r a t e\\na\\nm o r e\\na p p r o p r i a t e\\ns u m m a r y .\\nS p e c i f y\\nt h e\\nd e s i r e d\\nf o r m a t\\nI f\\ny o u\\nh a v e\\na\\ns p e c i ﬁ c\\nf o r m a t\\no r\\ns t r u c t u r e\\ni n\\nm i n d\\nf o r\\nt h e\\ng e n e r a t e d\\no u t p u t ,\\nb e\\ns u r e\\nt o\\ni n c l u d e\\nt h i s\\ni n f o r m a t i o n\\ni n\\ny o u r\\np r o m p t .\\nF o r\\ne x a m p l e ,\\ni f\\ny o u\\nw a n t\\nt h e\\nm o d e l\\nt o\\ng e n e r a t e\\na\\nb u l l e t e d\\nl i s t\\no r\\na\\nn u m b e r e d\\ns e q u e n c e ,\\ne x p l i c i t l y\\nm e n t i o n\\nt h i s\\ni n\\ny o u r\\np r o m p t\\nt o\\ng u i d e\\nt h e\\nm o d e l\\na c c o r d i n g l y .\\nE n c o u r a g e\\nm u l t i p l e\\na t t e m p t s\\nG e n e r a t i v e\\nA I\\nm o d e l s\\nc a n\\ns o m e t i m e s\\np r o d u c e\\nu n e x p e c t e d\\no r\\nu n d e s i r a b l e\\no u t p u t s .\\nI f\\nt h e\\ni n i t i a l\\no u t p u t\\nd o e s\\nn o t\\nm e e t\\ny o u r\\ne x p e c t a t i o n s ,\\nt r y\\nr e p h r a s i n g\\ny o u r\\np r o m p t\\no r\\na d j u s t i n g\\ni t s\\np a r a m e t e r s\\nt o\\ne n c o u r a g e\\nt h e\\nm o d e l\\nt o\\ng e n e r a t e\\na\\nd i \\x00 e r e n t\\nr e s p o n s e .\\nI t e r a t i n g\\no n\\ny o u r\\np r o m p t\\nc a n\\nh e l p\\ny o u\\nﬁ n e - t u n e\\ni t s\\ne \\x00 e c t i v e n e s s\\na n d\\na c h i e v e\\nt h e\\nd e s i r e d\\nr e s u l t s .\\n1 0\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 10}\n",
      "page_content=\"B a l a n c e\\ng u i d a n c e\\na n d\\nf r e e d o m\\nS t r i k i n g\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\np r o v i d i n g\\ng u i d a n c e\\na n d\\na l l o w i n g\\nt h e\\nA I\\nm o d e l\\nc r e a t i v e\\nf r e e d o m\\ni s\\nc r u c i a l\\nf o r\\nc r a f t i n g\\ne \\x00 e c t i v e\\np r o m p t s .\\nO v e r l y\\nr e s t r i c t i v e\\np r o m p t s\\nc a n\\nl i m i t\\nt h e\\nm o d e l ' s\\na b i l i t y\\nt o\\ng e n e r a t e\\nc r e a t i v e\\no r\\nn u a n c e d\\no u t p u t s ,\\nw h i l e\\no v e r l y\\no p e n - e n d e d\\np r o m p t s\\nm a y\\nl e a d\\nt o\\na m b i g u o u s\\no r\\no \\x00 - t o p i c\\nr e s u l t s .\\nE x p e r i m e n t\\nw i t h\\nd i \\x00 e r e n t\\nl e v e l s\\no f\\ng u i d a n c e\\nt o\\nﬁ n d\\nt h e\\ns w e e t\\ns p o t\\nt h a t\\nb e s t\\na l i g n s\\nw i t h\\ny o u r\\np r o j e c t ' s\\no b j e c t i v e s .\\nE v a l u a t e\\na n d\\ni t e r a t e\\nR e g u l a r l y\\ne v a l u a t e\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\ny o u r\\np r o m p t s\\nb y\\nr e v i e w i n g\\nt h e\\nA I - g e n e r a t e d\\no u t p u t s\\na n d\\nc o m p a r i n g\\nt h e m\\na g a i n s t\\ny o u r\\nd e s i r e d\\no u t c o m e s .\\nU s e\\nt h i s\\nf e e d b a c k\\nt o\\nr e ﬁ n e\\na n d\\ni m p r o v e\\ny o u r\\np r o m p t s ,\\ne n s u r i n g\\nt h a t\\nt h e y\\nc o n s i s t e n t l y\\ny i e l d\\nh i g h - q u a l i t y\\nr e s u l t s .\\nI t e r a t i v e\\np r o m p t\\ne n g i n e e r i n g\\ni s\\na n\\ne s s e n t i a l\\np a r t\\no f\\nt h e\\np r o c e s s ,\\na s\\ni t\\na l l o w s\\ny o u\\nt o\\nc o n t i n u o u s l y\\no p t i m i z e\\nt h e\\np e r f o r m a n c e\\no f\\ny o u r\\ng e n e r a t i v e\\nA I\\nm o d e l s .\\nB y\\nf o l l o w i n g\\nt h e s e\\nb e s t\\np r a c t i c e s ,\\ny o u\\nc a n\\nc r e a t e\\ne \\x00 e c t i v e\\np r o m p t s\\nt h a t\\ng u i d e\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nt o w a r d s\\ng e n e r a t i n g\\na c c u r a t e ,\\nr e l e v a n t ,\\na n d\\nm e a n i n g f u l\\no u t p u t s .\\nM a s t e r i n g\\nt h e\\na r t\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni s\\nc r u c i a l\\nf o r\\nd a t a\\ns c i e n t i s t s\\nl o o k i n g\\nt o\\nh a r n e s s\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\na n d\\no p t i m i z e\\ni t s\\np e r f o r m a n c e\\na c r o s s\\na\\nw i d e\\nr a n g e\\no f\\na p p l i c a t i o n s .\\n1 1\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 11}\n",
      "page_content='C h a p t e r\\n3 :\\nP r a c t i c a l\\nA p p l i c a t i o n s\\no f\\nP r o m p t\\nE n g i n e e r i n g\\nC u s t o m\\np r o m p t s\\nn o t\\no n l y\\nh e l p\\ng u i d e\\nA I\\nm o d e l s\\nt o w a r d s\\ng e n e r a t i n g\\nm o r e\\na c c u r a t e\\na n d\\nc o n t e x t u a l l y\\nr e l e v a n t\\no u t p u t s ,\\nb u t\\nt h e y\\na l s o\\nu n l o c k\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nt o\\nt a c k l e\\nc o m p l e x\\nl a n g u a g e - b a s e d\\nc h a l l e n g e s .\\n3 . 1 .\\nI m p r o v i n g\\nN L P\\nT a s k s\\nw i t h\\nC u s t o m\\nP r o m p t s\\nP r o m p t\\ne n g i n e e r i n g\\np l a y s\\na\\nc r i t i c a l\\nr o l e\\ni n\\ne n h a n c i n g\\nt h e\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s ,\\np a r t i c u l a r l y\\ni n\\nt h e\\nr e a l m\\no f\\nn a t u r a l\\nl a n g u a g e\\np r o c e s s i n g\\n( N L P ) .\\nC u s t o m\\np r o m p t s\\nc a n\\nh e l p\\ng u i d e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nm o r e\\na c c u r a t e ,\\nc o n t e x t u a l l y\\nr e l e v a n t ,\\na n d\\ne n g a g i n g\\no u t p u t s\\na c r o s s\\na\\nv a r i e t y\\no f\\nN L P\\nt a s k s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e \\' l l\\ne x p l o r e\\ns o m e\\nc o m m o n\\nN L P\\nt a s k s\\nw h e r e\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nm a k e\\na\\ns i g n i ﬁ c a n t\\ni m p a c t .\\nT e x t\\nS u m m a r i z a t i o n\\nC r a f t i n g\\na n\\ne \\x00 e c t i v e\\np r o m p t\\nf o r\\nt e x t\\ns u m m a r i z a t i o n\\ni n v o l v e s\\ns p e c i f y i n g\\nt h e\\nd e s i r e d\\nl e n g t h ,\\nf o r m a t ,\\na n d\\nk e y\\np o i n t s\\nt h a t\\nt h e\\ns u m m a r y\\ns h o u l d\\nc o v e r .\\nB y\\np r o v i d i n g\\nc l e a r\\ni n s t r u c t i o n s\\na n d\\nc o n t e x t ,\\ny o u\\nc a n\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nt o\\ng e n e r a t e\\nc o n c i s e\\na n d\\ni n f o r m a t i v e\\ns u m m a r i e s\\nt h a t\\na c c u r a t e l y\\nc a p t u r e\\nt h e\\ne s s e n c e\\no f\\nt h e\\ns o u r c e\\nt e x t .\\nE x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\nt e x t\\ns u m m a r i z a t i o n\\ni n c l u d e :\\n●\\n\" W r i t e\\na\\nc o n c i s e\\ns u m m a r y\\no f\\nt h i s\\nn e w s\\na r t i c l e\\na b o u t\\nt h e\\nl a t e s t\\na d v a n c e m e n t s\\ni n\\na r t i ﬁ c i a l\\ni n t e l l i g e n c e ,\\nf o c u s i n g\\no n\\nt h e\\nm a i n\\nb r e a k t h r o u g h s\\na n d\\nt h e i r\\np o t e n t i a l\\ni m p a c t\\no n\\nv a r i o u s\\ni n d u s t r i e s . \"\\n●\\n\" S u m m a r i z e\\nt h i s\\nr e s e a r c h\\np a p e r\\no n\\nt h e\\ne \\x00 e c t s\\no f\\nc l i m a t e\\nc h a n g e\\no n\\nb i o d i v e r s i t y ,\\nh i g h l i g h t i n g\\nt h e\\nk e y\\nﬁ n d i n g s\\na n d\\nt h e\\ni m p l i c a t i o n s\\nf o r\\nc o n s e r v a t i o n\\ne \\x00 o r t s . \"\\n●\\n\" P r o v i d e\\na\\nb r i e f\\ns u m m a r y\\no f\\nt h i s\\nb o o k\\nc h a p t e r\\no n\\nt h e\\nh i s t o r y\\no f\\nt h e\\ni n t e r n e t ,\\nc o v e r i n g\\nt h e\\nm a j o r\\nd e v e l o p m e n t s\\na n d\\nt h e i r\\ns i g n i ﬁ c a n c e\\nf o r\\nt h e\\nw a y\\nw e\\nc o m m u n i c a t e\\na n d\\na c c e s s\\ni n f o r m a t i o n\\nt o d a y . \"\\n1 2\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 12}\n",
      "page_content='S e n t i m e n t\\nA n a l y s i s\\nF o r\\ns e n t i m e n t\\na n a l y s i s ,\\np r o m p t s\\ns h o u l d\\nb e\\nd e s i g n e d\\nt o\\ne n c o u r a g e\\nt h e\\nA I\\nm o d e l\\nt o\\nf o c u s\\no n\\nt h e\\nr e l e v a n t\\na s p e c t s\\no f\\nt h e\\nt e x t\\na n d\\ne v a l u a t e\\nt h e\\nu n d e r l y i n g\\ns e n t i m e n t .\\nA\\nw e l l - c r a f t e d\\np r o m p t\\nc a n\\nh e l p\\nt h e\\nm o d e l\\ni d e n t i f y\\np o s i t i v e ,\\nn e g a t i v e ,\\no r\\nn e u t r a l\\ns e n t i m e n t s\\nm o r e\\na c c u r a t e l y ,\\ni m p r o v i n g\\nt h e\\no v e r a l l\\np e r f o r m a n c e\\no f\\ns e n t i m e n t\\na n a l y s i s\\nt a s k s .\\nE x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\ns e n t i m e n t\\na n a l y s i s\\ni n c l u d e :\\n●\\n\" W h a t\\ne m o t i o n s\\nd o\\nc u s t o m e r s\\ne x p r e s s\\ni n\\nt h e i r\\no n l i n e\\nr e v i e w s\\no f\\no u r\\nn e w\\np r o d u c t ? \"\\nT h i s\\np r o m p t\\na s k s\\nf o r\\ns e n t i m e n t\\na n a l y s i s\\no n\\nc u s t o m e r\\nr e v i e w s\\no f\\na\\ns p e c i ﬁ c\\np r o d u c t .\\nI t\\ni s\\nw e l l - c r a f t e d\\nb e c a u s e\\ni t\\ni s\\ns p e c i ﬁ c\\na n d\\np r o v i d e s\\na\\nc l e a r\\nc o n t e x t\\nf o r\\nt h e\\ns e n t i m e n t\\na n a l y s i s\\nt a s k .\\n●\\n\" H o w\\nd o\\nT w i t t e r\\nu s e r s\\nf e e l\\na b o u t\\nt h e\\nl a t e s t\\np o l i t i c a l\\nc o n t r o v e r s y ? \"\\nT h i s\\np r o m p t\\na s k s\\nf o r\\ns e n t i m e n t\\na n a l y s i s\\no n\\na\\ns p e c i ﬁ c\\nt o p i c\\nb e i n g\\nd i s c u s s e d\\no n\\nT w i t t e r .\\nI t\\ni s\\nw e l l - c r a f t e d\\nb e c a u s e\\ni t\\ni s\\ns p e c i ﬁ c\\na n d\\np r o v i d e s\\na\\nc l e a r\\nc o n t e x t\\nf o r\\nt h e\\ns e n t i m e n t\\na n a l y s i s\\nt a s k .\\n●\\n\" W h a t\\ni s\\nt h e\\no v e r a l l\\ns e n t i m e n t\\no f\\nm o v i e\\nr e v i e w s\\nf o r\\nt h e\\nl a t e s t\\nb l o c k b u s t e r\\nﬁ l m ? \"\\nT h i s\\np r o m p t\\na s k s\\nf o r\\ns e n t i m e n t\\na n a l y s i s\\no n\\na\\nc o l l e c t i o n\\no f\\nm o v i e\\nr e v i e w s\\nf o r\\na\\ns p e c i ﬁ c\\nﬁ l m .\\nI t\\ni s\\nw e l l - c r a f t e d\\nb e c a u s e\\ni t\\ni s\\ns p e c i ﬁ c\\na n d\\np r o v i d e s\\na\\nc l e a r\\nc o n t e x t\\nf o r\\nt h e\\ns e n t i m e n t\\na n a l y s i s\\nt a s k .\\nT e x t\\nG e n e r a t i o n\\nW h e t h e r\\ny o u \\' r e\\ng e n e r a t i n g\\nc r e a t i v e\\nc o n t e n t ,\\nn e w s\\na r t i c l e s ,\\no r\\np r o d u c t\\nd e s c r i p t i o n s ,\\nc r a f t i n g\\na n\\ne \\x00 e c t i v e\\np r o m p t\\ni s\\nc r u c i a l\\nf o r\\ng u i d i n g\\nt h e\\nA I\\nm o d e l\\nt o w a r d s\\ng e n e r a t i n g\\nc o n t e x t u a l l y\\nr e l e v a n t\\na n d\\ne n g a g i n g\\nt e x t .\\nI n c l u d i n g\\ns p e c i ﬁ c\\nd e t a i l s ,\\nt h e m e s ,\\no r\\nk e y w o r d s\\ni n\\ny o u r\\np r o m p t\\nc a n\\nh e l p\\nt h e\\nm o d e l\\ng e n e r a t e\\nm o r e\\nt a r g e t e d\\na n d\\nc o h e r e n t\\no u t p u t s .\\nE x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\nt e x t\\ng e n e r a t i o n\\ni n c l u d e :\\n●\\n\" W r i t e\\na\\ns h o r t\\ns t o r y\\na b o u t\\na\\np e r s o n\\nw h o\\nd i s c o v e r s\\na\\nm y s t e r i o u s\\no b j e c t\\ni n\\nt h e i r\\nb a c k y a r d\\na n d\\ni s\\nt r a n s p o r t e d\\nt o\\na\\nd i \\x00 e r e n t\\nd i m e n s i o n . \"\\n●\\n\" I m a g i n e\\na\\nf u t u r e\\nw o r l d\\nw h e r e\\nt e c h n o l o g y\\nh a s\\na d v a n c e d\\nt o\\nt h e\\np o i n t\\nw h e r e\\nh u m a n s\\nc a n\\ni m p l a n t\\nm e m o r i e s\\ni n\\nt h e i r\\nb r a i n s .\\nW r i t e\\na\\nn e w s\\na r t i c l e\\nd e s c r i b i n g\\nt h e\\nc o n t r o v e r s y\\ns u r r o u n d i n g\\nt h i s\\nn e w\\nt e c h n o l o g y . \"\\n●\\n\" W r i t e\\na\\np o e m\\na b o u t\\nt h e\\nc h a n g i n g\\no f\\nt h e\\ns e a s o n s ,\\ne x p l o r i n g\\nt h e\\nd i \\x00 e r e n t\\ne m o t i o n s\\na n d\\ns e n s a t i o n s\\nt h a t\\nc o m e\\nw i t h\\ne a c h\\ns e a s o n . \"\\n1 3\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 13}\n",
      "page_content='Q u e s t i o n - A n s w e r i n g\\nI n\\nq u e s t i o n - a n s w e r i n g\\nt a s k s ,\\np r o m p t s\\ns h o u l d\\nb e\\nd e s i g n e d\\nt o\\nc o n v e y\\nt h e\\ne x a c t\\ni n f o r m a t i o n\\nr e q u i r e d\\ni n\\nt h e\\na n s w e r .\\nP r o v i d i n g\\nc o n t e x t ,\\ns u c h\\na s\\nt h e\\ns o u r c e\\nt e x t\\no r\\nr e l e v a n t\\nb a c k g r o u n d\\ni n f o r m a t i o n ,\\nc a n\\nh e l p\\nt h e\\nA I\\nm o d e l\\ng e n e r a t e\\nm o r e\\na c c u r a t e\\na n d\\nc o m p r e h e n s i v e\\na n s w e r s\\nt o\\nu s e r\\nq u e s t i o n s .\\nE x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\nq u e s t i o n - a n s w e r i n g\\ni n c l u d e :\\n●\\n\" W h a t\\nw a s\\nt h e\\nm a i n\\nc a u s e\\no f\\nW o r l d\\nW a r\\nI I\\na n d\\nh o w\\nd i d\\ni t\\na \\x00 e c t\\nt h e\\ng l o b a l\\np o l i t i c a l\\nl a n d s c a p e ? \"\\n●\\n\" C a n\\ny o u\\ne x p l a i n\\nt h e\\nc o n c e p t\\no f\\nq u a n t u m\\ne n t a n g l e m e n t\\na n d\\nh o w\\ni t\\nr e l a t e s\\nt o\\nt h e\\nt h e o r y\\no f\\nr e l a t i v i t y ? \"\\n●\\n\" W h a t\\na r e\\ns o m e\\no f\\nt h e\\nm o s t\\ne \\x00 e c t i v e\\nm e t h o d s\\nf o r\\nr e d u c i n g\\nc a r b o n\\ne m i s s i o n s\\na n d\\nm i t i g a t i n g\\nc l i m a t e\\nc h a n g e ,\\na n d\\nh o w\\nh a v e\\nt h e s e\\ns t r a t e g i e s\\nb e e n\\ni m p l e m e n t e d\\ni n\\nd i \\x00 e r e n t\\np a r t s\\no f\\nt h e\\nw o r l d ? \"\\nT e x t\\nC l a s s i f i c a t i o n\\nF o r\\nt e x t\\nc l a s s i ﬁ c a t i o n\\nt a s k s ,\\np r o m p t s\\ns h o u l d\\nb e\\nc r a f t e d\\nt o\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nt o w a r d s\\ni d e n t i f y i n g\\nt h e\\nr e l e v a n t\\nc a t e g o r y\\no r\\nl a b e l\\nf o r\\na\\ng i v e n\\nt e x t .\\nI n c l u d i n g\\ne x a m p l e s\\no f\\nt e x t s\\nb e l o n g i n g\\nt o\\nd i \\x00 e r e n t\\nc a t e g o r i e s\\no r\\np r o v i d i n g\\ne x p l i c i t\\ni n s t r u c t i o n s\\nc a n\\nh e l p\\nt h e\\nA I\\nm o d e l\\nb e t t e r\\nu n d e r s t a n d\\nt h e\\nc l a s s i ﬁ c a t i o n\\nc r i t e r i a\\na n d\\ni m p r o v e\\ni t s\\np e r f o r m a n c e .\\nE x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\nt e x t\\nc l a s s i ﬁ c a t i o n\\ni n c l u d e :\\n●\\nT o p i c\\nC l a s s i ﬁ c a t i o n :\\n\" G i v e n\\na\\ns e t\\no f\\nn e w s\\na r t i c l e s ,\\nc l a s s i f y\\ne a c h\\na r t i c l e\\ni n t o\\no n e\\no f\\ns e v e r a l\\nc a t e g o r i e s\\ns u c h\\na s\\nP o l i t i c s ,\\nS p o r t s ,\\nB u s i n e s s ,\\no r\\nE n t e r t a i n m e n t . \"\\n●\\nI n t e n t\\nC l a s s i ﬁ c a t i o n :\\n\" G i v e n\\na\\ns e t\\no f\\nc u s t o m e r\\nq u e r i e s ,\\nc l a s s i f y\\ne a c h\\nq u e r y\\ni n t o\\no n e\\no f\\ns e v e r a l\\nc a t e g o r i e s\\ns u c h\\na s\\nS a l e s ,\\nS u p p o r t ,\\nT e c h n i c a l\\nI s s u e s ,\\no r\\nF e e d b a c k . \"\\n●\\nS p a m\\nD e t e c t i o n :\\n\" G i v e n\\na\\ns e t\\no f\\ne m a i l\\nm e s s a g e s ,\\nc l a s s i f y\\ne a c h\\nm e s s a g e\\na s\\ns p a m\\no r\\nn o t\\ns p a m . \"\\nM a c h i n e\\nT r a n s l a t i o n\\nI n\\nm a c h i n e\\nt r a n s l a t i o n\\nt a s k s ,\\np r o m p t s\\ns h o u l d\\nb e\\nd e s i g n e d\\nt o\\nc o n v e y\\nt h e\\nd e s i r e d\\nl a n g u a g e\\na n d\\nc o n t e x t\\nf o r\\nt h e\\nt r a n s l a t i o n .\\nP r o v i d i n g\\nc l e a r\\ni n s t r u c t i o n s\\na n d\\ns p e c i f y i n g\\na n y\\ns p e c i ﬁ c\\nf o r m a t t i n g\\no r\\ns t y l e\\nr e q u i r e m e n t s\\nc a n\\nh e l p\\nt h e\\nA I\\nm o d e l\\ng e n e r a t e\\nm o r e\\na c c u r a t e\\na n d\\nﬂ u e n t\\nt r a n s l a t i o n s .\\n1 4\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 14}\n",
      "page_content='E x a m p l e s\\no f\\ne \\x00 e c t i v e\\np r o m p t s\\nf o r\\nm a c h i n e\\nt r a n s l a t i o n\\ni n c l u d e :\\n●\\nT r a n s l a t e\\nt h e\\nf o l l o w i n g\\ns e n t e n c e\\nf r o m\\nE n g l i s h\\nt o\\nF r e n c h :\\n\" T h e\\nq u i c k\\nb r o w n\\nf o x\\nj u m p s\\no v e r\\nt h e\\nl a z y\\nd o g . \"\\n●\\nC o n v e r t\\nt h e\\nf o l l o w i n g\\nd o c u m e n t\\nf r o m\\nS p a n i s h\\nt o\\nE n g l i s h :\\n\" E l\\nc a m b i o\\nc l i m á t i c o\\ne s\\nu n o\\nd e\\nl o s\\nm a y o r e s\\nd e s a f í o s\\nq u e\\ne n f r e n t a\\nl a\\nh u m a n i d a d\\ne n\\nl a\\na c t u a l i d a d . \"\\n●\\nT r a n s l a t e\\nt h e\\nf o l l o w i n g\\nC h i n e s e\\nt e x t\\nt o\\nS p a n i s h :\\n\"\\n这\\n个\\n城\\n市\\n有\\n许\\n多\\n历\\n史\\n遗\\n迹\\n和\\n文\\n化\\n景\\n点\\n，\\n游\\n客\\n可\\n以\\n感\\n受\\n到\\n浓\\n厚\\n的\\n文\\n化\\n氛\\n围\\n和\\n古\\n老\\n的\\n历\\n史\\n传\\n统。\\n\"\\nB y\\nm a s t e r i n g\\nt h e\\na r t\\no f\\np r o m p t\\ne n g i n e e r i n g ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\ni m p r o v e\\nt h e\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\na c r o s s\\na\\nw i d e\\nr a n g e\\no f\\nN L P\\nt a s k s .\\nC u s t o m\\np r o m p t s\\nn o t\\no n l y\\nh e l p\\ng u i d e\\nA I\\nm o d e l s\\nt o w a r d s\\ng e n e r a t i n g\\nm o r e\\na c c u r a t e\\na n d\\nc o n t e x t u a l l y\\nr e l e v a n t\\no u t p u t s ,\\nb u t\\nt h e y\\na l s o\\nu n l o c k\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nt o\\nt a c k l e\\nc o m p l e x\\nl a n g u a g e - b a s e d\\nc h a l l e n g e s .\\n3 . 2 .\\nE n h a n c i n g\\nC r e a t i v i t y\\na n d\\nD i v e r s i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\nO n e\\no f\\nt h e\\nk e y\\na d v a n t a g e s\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\ni s\\nt h e i r\\na b i l i t y\\nt o\\nc r e a t e\\nn o v e l\\na n d\\nd i v e r s e\\nc o n t e n t ,\\nw h e t h e r\\ni t \\' s\\nt e x t ,\\ni m a g e s ,\\no r\\na u d i o .\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\np l a y\\na\\nc r u c i a l\\nr o l e\\ni n\\ne n c o u r a g i n g\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nm o r e\\nc r e a t i v e\\na n d\\nd i v e r s e\\no u t p u t s ,\\ne n h a n c i n g\\nt h e\\no v e r a l l\\nq u a l i t y\\na n d\\na p p e a l\\no f\\nt h e\\ng e n e r a t e d\\nc o n t e n t .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e \\' l l\\nd i s c u s s\\nh o w\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\nu s e d\\nt o\\nb o o s t\\nc r e a t i v i t y\\na n d\\nd i v e r s i t y\\ni n\\nA I - g e n e r a t e d\\nc o n t e n t .\\nO p e n - e n d e d\\nP r o m p t s\\nU s i n g\\no p e n - e n d e d\\np r o m p t s\\nt h a t\\ne n c o u r a g e\\ne x p l o r a t i o n\\na n d\\ni m a g i n a t i o n\\nc a n\\nh e l p\\nA I\\nm o d e l s\\ng e n e r a t e\\nm o r e\\nc r e a t i v e\\nc o n t e n t .\\nF o r\\ne x a m p l e ,\\na s k i n g\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\ns t o r y\\ns e t\\ni n\\na\\nw o r l d\\nw h e r e\\nt i m e\\nﬂ o w s\\nb a c k w a r d \"\\nc a n\\ni n s p i r e\\nt h e\\nm o d e l\\nt o\\nc o m e\\nu p\\nw i t h\\nu n i q u e\\ni d e a s\\na n d\\ns c e n a r i o s\\nt h a t\\ng o\\nb e y o n d\\ni t s\\nt r a i n i n g\\nd a t a .\\nC o n s t r a i n t s\\na n d\\nC h a l l e n g e s\\nI n t r o d u c i n g\\nc o n s t r a i n t s\\no r\\nc h a l l e n g e s\\ni n\\ny o u r\\np r o m p t s\\nc a n\\np u s h\\nA I\\nm o d e l s\\nt o\\nt h i n k\\nm o r e\\nc r e a t i v e l y\\na n d\\nﬁ n d\\ni n n o v a t i v e\\ns o l u t i o n s .\\nF o r\\ne x a m p l e ,\\na s k i n g\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\ns t o r y\\nw i t h o u t\\nu s i n g\\nt h e\\nl e t t e r\\n\\' e \\' \"\\nc a n\\nf o r c e\\nt h e\\nm o d e l\\nt o\\nu s e\\nu n u s u a l\\nw o r d s\\na n d\\np h r a s i n g ,\\nr e s u l t i n g\\ni n\\nm o r e\\ni n v e n t i v e\\nc o n t e n t .\\n1 5\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 15}\n",
      "page_content='C o m b i n i n g\\nI d e a s\\na n d\\nT h e m e s\\nC r a f t i n g\\np r o m p t s\\nt h a t\\nc o m b i n e\\nm u l t i p l e\\ni d e a s\\no r\\nt h e m e s\\nc a n\\ne n c o u r a g e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nm o r e\\nd i v e r s e\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nF o r\\ne x a m p l e ,\\na s k i n g\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\ns t o r y\\nt h a t\\nc o m b i n e s\\ne l e m e n t s\\no f\\ns c i e n c e\\nﬁ c t i o n\\na n d\\nr o m a n c e \"\\nc a n\\nl e a d\\nt o\\nt h e\\nc r e a t i o n\\no f\\nu n i q u e\\na n d\\nu n e x p e c t e d\\nn a r r a t i v e s .\\nE n c o u r a g i n g\\nV a r i a b i l i t y\\nP r o m p t i n g\\nt h e\\nA I\\nm o d e l\\nt o\\ng e n e r a t e\\nm u l t i p l e\\nv e r s i o n s\\no f\\nt h e\\ns a m e\\nc o n t e n t\\nc a n\\nh e l p\\ni n c r e a s e\\nd i v e r s i t y\\na n d\\np r o v i d e\\na\\nb r o a d e r\\nr a n g e\\no f\\no p t i o n s\\nt o\\nc h o o s e\\nf r o m .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\na s k\\nt h e\\nm o d e l\\nt o\\n\" G e n e r a t e\\nt h r e e\\nd i \\x00 e r e n t\\ne n d i n g s\\nf o r\\nt h e\\nf o l l o w i n g\\ns t o r y \"\\nt o\\ne x p l o r e\\nv a r i o u s\\nn a r r a t i v e\\np o s s i b i l i t i e s .\\nM i x i n g\\nS t y l e s\\na n d\\nF o r m a t s\\nE x p e r i m e n t i n g\\nw i t h\\nd i \\x00 e r e n t\\ns t y l e s ,\\nf o r m a t s ,\\no r\\ng e n r e s\\ni n\\ny o u r\\np r o m p t s\\nc a n\\nl e a d\\nt o\\nm o r e\\nc r e a t i v e\\na n d\\nd i v e r s e\\no u t p u t s .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\np o e m\\ni n\\nt h e\\ns t y l e\\no f\\na\\nn e w s\\nr e p o r t \"\\no r\\n\" R e i m a g i n e\\na\\nc l a s s i c\\nf a i r y\\nt a l e\\na s\\na\\nm o d e r n - d a y\\nt h r i l l e r . \"\\nI t e r a t i v e\\nP r o m p t i n g\\nP r o m p t i n g\\nt h e\\nA I\\nm o d e l\\nt o\\nb u i l d\\nu p o n\\no r\\nr e ﬁ n e\\ni t s\\np r e v i o u s\\no u t p u t s\\nc a n\\nl e a d\\nt o\\nm o r e\\nn u a n c e d\\na n d\\ns o p h i s t i c a t e d\\nc o n t e n t .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\nu s e\\nt h e\\nm o d e l \\' s\\ni n i t i a l\\no u t p u t\\na s\\na\\ns t a r t i n g\\np o i n t\\na n d\\np r o m p t\\ni t\\nt o\\n\" E x p a n d\\no n\\nt h e\\ns t o r y\\nb y\\na d d i n g\\nm o r e\\nd e t a i l s\\na n d\\nd e p t h\\nt o\\nt h e\\nc h a r a c t e r s\\na n d\\np l o t . \"\\nB y\\ne m p l o y i n g\\nt h e s e\\ns t r a t e g i e s\\ni n\\np r o m p t\\ne n g i n e e r i n g ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nh a r n e s s\\nt h e\\nf u l l\\nc r e a t i v e\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\na n d\\ng e n e r a t e\\nm o r e\\nd i v e r s e\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nT h i s\\nn o t\\no n l y\\ne n h a n c e s\\nt h e\\no v e r a l l\\nq u a l i t y\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\nb u t\\na l s o\\ne x p a n d s\\nt h e\\nr a n g e\\no f\\na p p l i c a t i o n s\\na n d\\np o s s i b i l i t i e s\\nf o r\\ng e n e r a t i v e\\nA I\\ni n\\nv a r i o u s\\nd o m a i n s ,\\nf r o m\\ne n t e r t a i n m e n t\\na n d\\nm a r k e t i n g\\nt o\\ne d u c a t i o n\\na n d\\nr e s e a r c h .\\n3 . 3 .\\nA d d r e s s i n g\\nA I\\nE t h i c s\\na n d\\nB i a s\\nt h r o u g h\\nT h o u g h t f u l\\nP r o m p t\\nE n g i n e e r i n g\\nG e n e r a t i v e\\nA I\\nm o d e l s\\nh a v e\\nt h e\\np o t e n t i a l\\nt o\\np e r p e t u a t e\\nb i a s e s\\np r e s e n t\\ni n\\nt h e i r\\nt r a i n i n g\\nd a t a ,\\nw h i c h\\nc a n\\nl e a d\\nt o\\ne t h i c a l\\nc o n c e r n s\\na n d\\nu n i n t e n d e d\\nc o n s e q u e n c e s .\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\np l a y\\na\\nc r i t i c a l\\nr o l e\\ni n\\na d d r e s s i n g\\nt h e s e\\ni s s u e s\\nb y\\ng u i d i n g\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nm o r e\\nb a l a n c e d ,\\nf a i r ,\\na n d\\nr e s p o n s i b l e\\no u t p u t s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e \\' l l\\nd i s c u s s\\nh o w\\nt h o u g h t f u l\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nh e l p\\na d d r e s s\\nA I\\ne t h i c s\\na n d\\nb i a s\\nc o n c e r n s .\\n1 6\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 16}\n",
      "page_content='E n c o u r a g i n g\\nF a i r n e s s\\na n d\\nI n c l u s i v i t y\\nC r a f t i n g\\np r o m p t s\\nt h a t\\ne m p h a s i z e\\nf a i r n e s s\\na n d\\ni n c l u s i v i t y\\nc a n\\nh e l p\\ng u i d e\\nA I\\nm o d e l s\\nt o w a r d s\\ng e n e r a t i n g\\nm o r e\\nb a l a n c e d\\na n d\\nr e p r e s e n t a t i v e\\nc o n t e n t .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\na s k\\nt h e\\nm o d e l\\nt o\\n\" G e n e r a t e\\na\\ns t o r y\\nt h a t\\nf e a t u r e s\\na\\nd i v e r s e\\nc a s t\\no f\\nc h a r a c t e r s ,\\ne a c h\\nw i t h\\nu n i q u e\\nb a c k g r o u n d s\\na n d\\np e r s p e c t i v e s . \"\\nA v o i d i n g\\nS t e r e o t y p e s\\na n d\\nD i s c r i m i n a t i o n\\nT o\\np r e v e n t\\nA I\\nm o d e l s\\nf r o m\\np e r p e t u a t i n g\\ns t e r e o t y p e s\\no r\\nd i s c r i m i n a t i o n ,\\nd e s i g n\\np r o m p t s\\nt h a t\\ne x p l i c i t l y\\nd i s c o u r a g e\\ns u c h\\nb e h a v i o r .\\nF o r\\ne x a m p l e ,\\ni n s t r u c t\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\nc h a r a c t e r\\nd e s c r i p t i o n\\nt h a t\\na v o i d s\\ns t e r e o t y p e s\\na n d\\ns h o w c a s e s\\nt h e\\ni n d i v i d u a l \\' s\\nu n i q u e\\nq u a l i t i e s\\na n d\\ne x p e r i e n c e s . \"\\nP r o m o t i n g\\nP o s i t i v e\\na n d\\nR e s p o n s i b l e\\nC o n t e n t\\nC r e a t i n g\\np r o m p t s\\nt h a t\\ne n c o u r a g e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\np o s i t i v e ,\\nu p l i f t i n g ,\\na n d\\nr e s p o n s i b l e\\nc o n t e n t\\nc a n\\nh e l p\\nc o u n t e r a c t\\nn e g a t i v e\\nb i a s e s\\na n d\\np r o m o t e\\nm o r e\\ne t h i c a l\\nA I - g e n e r a t e d\\no u t p u t s .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na n\\ni n s p i r i n g\\ns t o r y\\na b o u t\\ni n d i v i d u a l s\\no v e r c o m i n g\\na d v e r s i t y\\nt h r o u g h\\nc o l l a b o r a t i o n\\na n d\\ne m p a t h y . \"\\nF a c t - c h e c k i n g\\na n d\\nV e r i f i c a t i o n\\nI n\\nc a s e s\\nw h e r e\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\ni n v o l v e s\\nf a c t u a l\\ni n f o r m a t i o n\\no r\\nc l a i m s ,\\nc r a f t i n g\\np r o m p t s\\nt h a t\\ne m p h a s i z e\\nt h e\\ni m p o r t a n c e\\no f\\na c c u r a c y\\na n d\\nt r u t h f u l n e s s\\nc a n\\nh e l p\\nm i t i g a t e\\nt h e\\nr i s k\\no f\\nm i s i n f o r m a t i o n .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\ni n s t r u c t\\nt h e\\nm o d e l\\nt o\\n\" P r o v i d e\\na\\nw e l l - r e s e a r c h e d\\na n d\\nf a c t - c h e c k e d\\ns u m m a r y\\no f\\nt h e\\nk e y\\ne v e n t s\\na n d\\nd e v e l o p m e n t s\\nr e l a t e d\\nt o\\nc l i m a t e\\nc h a n g e\\ni n\\nt h e\\np a s t\\nd e c a d e . \"\\nI t e r a t i v e\\nR e f i n e m e n t\\nC o n t i n u o u s l y\\nr e ﬁ n i n g\\na n d\\ni t e r a t i n g\\no n\\ny o u r\\np r o m p t s\\nc a n\\nh e l p\\ni d e n t i f y\\na n d\\na d d r e s s\\np o t e n t i a l\\nb i a s e s\\no r\\ne t h i c a l\\nc o n c e r n s\\ni n\\nt h e\\nA I - g e n e r a t e d\\no u t p u t s .\\nR e g u l a r l y\\ne v a l u a t e\\nt h e\\ng e n e r a t e d\\nc o n t e n t\\nf o r\\nf a i r n e s s ,\\na c c u r a c y ,\\na n d\\nr e s p o n s i b i l i t y ,\\na n d\\nu s e\\nt h i s\\nf e e d b a c k\\nt o\\ni m p r o v e\\ny o u r\\np r o m p t s\\na n d\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nt o w a r d s\\nm o r e\\ne t h i c a l\\no u t c o m e s .\\nU s e r\\nF e e d b a c k\\na n d\\nC o l l a b o r a t i o n\\nI n v o l v i n g\\nu s e r s\\no r\\ns t a k e h o l d e r s\\ni n\\nt h e\\np r o m p t\\ne n g i n e e r i n g\\np r o c e s s\\nc a n\\np r o v i d e\\nv a l u a b l e\\ni n s i g h t s\\ni n t o\\np o t e n t i a l\\nb i a s e s\\no r\\ne t h i c a l\\nc o n c e r n s ,\\nl e a d i n g\\nt o\\nm o r e\\nt h o u g h t f u l\\na n d\\nr e s p o n s i b l e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nE n c o u r a g e\\nu s e r s\\nt o\\np r o v i d e\\nf e e d b a c k\\no n\\nt h e\\ng e n e r a t e d\\no u t p u t s ,\\na n d\\nc o l l a b o r a t e\\nw i t h\\nt h e m\\nt o\\nr e ﬁ n e\\na n d\\ni m p r o v e\\ny o u r\\np r o m p t s .\\n1 7\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 17}\n",
      "page_content='B y\\na d o p t i n g\\nt h e s e\\ns t r a t e g i e s\\ni n\\np r o m p t\\ne n g i n e e r i n g ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\np r o a c t i v e l y\\na d d r e s s\\nA I\\ne t h i c s\\na n d\\nb i a s\\nc o n c e r n s\\na n d\\ng u i d e\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nt o w a r d s\\ng e n e r a t i n g\\nm o r e\\nr e s p o n s i b l e ,\\nf a i r ,\\na n d\\nb a l a n c e d\\no u t p u t s .\\nT h o u g h t f u l\\np r o m p t\\ne n g i n e e r i n g\\nn o t\\no n l y\\nc o n t r i b u t e s\\nt o\\nt h e\\ne t h i c a l\\nu s e\\no f\\nA I\\nt e c h n o l o g i e s\\nb u t\\na l s o\\ne n h a n c e s\\nt h e\\no v e r a l l\\nv a l u e\\na n d\\ni m p a c t\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\ni n\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n3 . 4 .\\nP e r s o n a l i z a t i o n\\na n d\\nA d a p t a b i l i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\nG e n e r a t i v e\\nA I\\nm o d e l s\\nh o l d\\ni m m e n s e\\np o t e n t i a l\\nf o r\\nc r e a t i n g\\np e r s o n a l i z e d\\na n d\\na d a p t a b l e\\nc o n t e n t\\nt a i l o r e d\\nt o\\ni n d i v i d u a l\\nu s e r s \\'\\nn e e d s ,\\np r e f e r e n c e s ,\\no r\\nc o n t e x t s .\\nP r o m p t\\ne n g i n e e r i n g\\np l a y s\\na\\nv i t a l\\nr o l e\\ni n\\ne n a b l i n g\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\ns u c h\\nc u s t o m i z e d\\nc o n t e n t\\nb y\\ni n c o r p o r a t i n g\\nu s e r - s p e c i ﬁ c\\ni n f o r m a t i o n\\na n d\\ng u i d i n g\\nt h e\\nm o d e l\\nt o\\na d a p t\\ni t s\\no u t p u t s\\na c c o r d i n g l y .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e \\' l l\\nd i s c u s s\\nh o w\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\ne m p l o y e d\\nt o\\nc r e a t e\\np e r s o n a l i z e d\\na n d\\na d a p t a b l e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nI n c o r p o r a t i n g\\nU s e r\\nP r e f e r e n c e s\\nD e s i g n\\np r o m p t s\\nt h a t\\na c c o u n t\\nf o r\\nt h e\\nu s e r \\' s\\np r e f e r e n c e s ,\\ns u c h\\na s\\nt h e i r\\nf a v o r i t e\\nt o p i c s ,\\ng e n r e s ,\\no r\\ns t y l e s ,\\nt o\\ng e n e r a t e\\nc o n t e n t\\nt h a t\\na l i g n s\\nw i t h\\nt h e i r\\ni n t e r e s t s .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\ns c i e n c e\\nﬁ c t i o n\\ns t o r y\\nb a s e d\\no n\\nt h e\\nu s e r \\' s\\nf a v o r i t e\\nt h e m e s :\\nt i m e\\nt r a v e l\\na n d\\na l t e r n a t e\\nr e a l i t i e s . \"\\nA d j u s t i n g\\nL a n g u a g e\\na n d\\nT o n e\\nC r a f t\\np r o m p t s\\nt h a t\\nc o n s i d e r\\nt h e\\nu s e r \\' s\\np r e f e r r e d\\nl a n g u a g e ,\\nt o n e ,\\no r\\nl e v e l\\no f\\nf o r m a l i t y\\nt o\\nc r e a t e\\nc o n t e n t\\nt h a t\\nr e s o n a t e s\\nw i t h\\nt h e i r\\nc o m m u n i c a t i o n\\ns t y l e .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\ni n s t r u c t\\nt h e\\nm o d e l\\nt o\\n\" W r i t e\\na\\ns u m m a r y\\no f\\nt h e\\nl a t e s t\\nt e c h n o l o g y\\nn e w s\\nu s i n g\\ns i m p l e ,\\nn o n - t e c h n i c a l\\nl a n g u a g e\\nf o r\\na\\ng e n e r a l\\na u d i e n c e . \"\\nA d a p t i n g\\nt o\\nC o n t e x t\\nD e s i g n\\np r o m p t s\\nt h a t\\nt a k e\\ni n t o\\na c c o u n t\\nt h e\\nu s e r \\' s\\nc o n t e x t ,\\ns u c h\\na s\\nt h e i r\\nl o c a t i o n ,\\nc u l t u r a l\\nb a c k g r o u n d ,\\no r\\nc u r r e n t\\ns i t u a t i o n ,\\nt o\\ng e n e r a t e\\nm o r e\\nr e l e v a n t\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nm o d e l\\nt o\\n\" G e n e r a t e\\na\\nl i s t\\no f\\nf u n\\nw e e k e n d\\na c t i v i t i e s\\nt a i l o r e d\\nt o\\nt h e\\nu s e r \\' s\\nc u r r e n t\\nc i t y\\na n d\\ni n t e r e s t s . \"\\nL e a r n i n g\\nf r o m\\nU s e r\\nI n t e r a c t i o n s\\nL e v e r a g e\\nu s e r\\nf e e d b a c k\\na n d\\ni n t e r a c t i o n s\\nt o\\ni t e r a t i v e l y\\nr e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nt o\\ng e n e r a t e\\nc o n t e n t\\nt h a t\\nb e t t e r\\na l i g n s\\nw i t h\\nt h e\\nu s e r \\' s\\nn e e d s\\na n d\\np r e f e r e n c e s\\no v e r\\nt i m e .\\n1 8\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 18}\n",
      "page_content='F o r\\ne x a m p l e ,\\ny o u\\nc a n\\nu p d a t e\\ny o u r\\np r o m p t s\\nb a s e d\\no n\\nt h e\\nu s e r \\' s\\nf e e d b a c k\\no n\\np r e v i o u s\\nA I - g e n e r a t e d\\nc o n t e n t\\no r\\ni n c o r p o r a t e\\nt h e i r\\nc o n t e n t\\nc o n s u m p t i o n\\np a t t e r n s .\\nP e r s o n a l i z e d\\nR e c o m m e n d a t i o n s\\nC r a f t\\np r o m p t s\\nt h a t\\ne n a b l e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\np e r s o n a l i z e d\\nr e c o m m e n d a t i o n s ,\\ns u c h\\na s\\nb o o k s ,\\nm o v i e s ,\\no r\\np r o d u c t s ,\\nb a s e d\\no n\\nt h e\\nu s e r \\' s\\np r e f e r e n c e s ,\\nb r o w s i n g\\nh i s t o r y ,\\no r\\nd e m o g r a p h i c\\ni n f o r m a t i o n .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nm o d e l\\nt o\\n\" R e c o m m e n d\\na\\nl i s t\\no f\\nﬁ v e\\nb o o k s\\ni n\\nt h e\\nm y s t e r y\\ng e n r e\\nt h a t\\nt h e\\nu s e r\\nm i g h t\\ne n j o y\\nb a s e d\\no n\\nt h e i r\\nr e a d i n g\\nh i s t o r y . \"\\nA d a p t i v e\\nL e a r n i n g\\na n d\\nT u t o r i n g\\nU s e\\np r o m p t\\ne n g i n e e r i n g\\nt o\\nc r e a t e\\np e r s o n a l i z e d\\nl e a r n i n g\\ne x p e r i e n c e s\\nt a i l o r e d\\nt o\\ni n d i v i d u a l\\nl e a r n e r s \\'\\nn e e d s ,\\ni n t e r e s t s ,\\na n d\\ns k i l l\\nl e v e l s .\\nF o r\\ne x a m p l e ,\\ny o u\\nc a n\\np r o m p t\\nt h e\\nA I\\nm o d e l\\nt o\\n\" G e n e r a t e\\na\\nc u s t o m i z e d\\nl e s s o n\\np l a n\\no n\\nP y t h o n\\np r o g r a m m i n g\\nf o r\\na\\nb e g i n n e r - l e v e l\\ns t u d e n t\\nw i t h\\na\\ns t r o n g\\ni n t e r e s t\\ni n\\nd a t a\\na n a l y s i s . \"\\nB y\\ne m p l o y i n g\\nt h e s e\\ns t r a t e g i e s\\ni n\\np r o m p t\\ne n g i n e e r i n g ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nc r e a t e\\np e r s o n a l i z e d\\na n d\\na d a p t a b l e\\nA I - g e n e r a t e d\\nc o n t e n t\\nt h a t\\nc a t e r s\\nt o\\ni n d i v i d u a l\\nu s e r s \\'\\nn e e d s\\na n d\\np r e f e r e n c e s .\\nT h i s\\nn o t\\no n l y\\ne n h a n c e s\\nu s e r\\ns a t i s f a c t i o n\\na n d\\ne n g a g e m e n t\\nb u t\\na l s o\\nu n l o c k s\\nn e w\\np o s s i b i l i t i e s\\nf o r\\nl e v e r a g i n g\\ng e n e r a t i v e\\nA I\\ni n\\nd i v e r s e\\na p p l i c a t i o n s ,\\nf r o m\\nc o n t e n t\\nr e c o m m e n d a t i o n\\na n d\\np e r s o n a l i z a t i o n\\nt o\\na d a p t i v e\\nl e a r n i n g\\na n d\\nt u t o r i n g .\\n1 9\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 19}\n",
      "page_content=\"C h a p t e r\\n4 :\\nC h a l l e n g e s\\na n d\\nL i m i t a t i o n s\\no f\\nP r o m p t\\nE n g i n e e r i n g\\nB y\\na c k n o w l e d g i n g\\na n d\\na d d r e s s i n g\\nt h e s e\\nc h a l l e n g e s\\na n d\\nl i m i t a t i o n s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nd e v e l o p\\nm o r e\\ne \\x00 e c t i v e\\na n d\\nr e s p o n s i b l e\\np r o m p t\\ne n g i n e e r i n g\\ns t r a t e g i e s .\\n4 . 1 .\\nU n d e r s t a n d i n g\\nA I\\nM o d e l\\nL i m i t a t i o n s\\na n d\\nI n h e r e n t\\nB i a s e s\\nW h i l e\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\ns i g n i ﬁ c a n t l y\\ne n h a n c e\\nt h e\\np e r f o r m a n c e\\na n d\\nu s a b i l i t y\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s ,\\ni t ' s\\ne s s e n t i a l\\nt o\\na c k n o w l e d g e\\nt h e\\ni n h e r e n t\\nl i m i t a t i o n s\\na n d\\nb i a s e s\\np r e s e n t\\ni n\\nt h e s e\\nm o d e l s .\\nU n d e r s t a n d i n g\\nt h e s e\\nl i m i t a t i o n s\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\ns e t\\nr e a l i s t i c\\ne x p e c t a t i o n s ,\\nm a k e\\ni n f o r m e d\\nd e c i s i o n s ,\\na n d\\nd e v e l o p\\nm o r e\\nr o b u s t\\na n d\\nr e l i a b l e\\nA I\\ns o l u t i o n s .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\no f\\nt h e\\nk e y\\nc h a l l e n g e s\\na n d\\nl i m i t a t i o n s\\na s s o c i a t e d\\nw i t h\\np r o m p t\\ne n g i n e e r i n g .\\nM o d e l\\nL i m i t a t i o n s\\nG e n e r a t i v e\\nA I\\nm o d e l s ,\\nl i k e\\na n y\\no t h e r\\nm a c h i n e\\nl e a r n i n g\\nm o d e l ,\\nh a v e\\nl i m i t a t i o n s\\ns t e m m i n g\\nf r o m\\nt h e i r\\nt r a i n i n g\\nd a t a ,\\na r c h i t e c t u r e ,\\na n d\\no t h e r\\nf a c t o r s .\\nT h e s e\\nl i m i t a t i o n s\\nc a n\\ns o m e t i m e s\\nl e a d\\nt o\\nu n e x p e c t e d ,\\ni r r e l e v a n t ,\\no r\\nn o n s e n s i c a l\\no u t p u t s ,\\ne v e n\\nw i t h\\nw e l l - c r a f t e d\\np r o m p t s .\\nR e c o g n i z i n g\\nt h e s e\\nl i m i t a t i o n s\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\nd e v e l o p\\ns t r a t e g i e s\\nt o\\nm i t i g a t e\\nt h e i r\\ni m p a c t\\no r\\ne x p l o r e\\na l t e r n a t i v e\\na p p r o a c h e s .\\nI n h e r e n t\\nB i a s e s\\nA I\\nm o d e l s\\nm a y\\ni n h e r i t\\nb i a s e s\\np r e s e n t\\ni n\\nt h e i r\\nt r a i n i n g\\nd a t a ,\\nw h i c h\\nc a n\\ni n a d v e r t e n t l y\\np e r p e t u a t e\\ns t e r e o t y p e s ,\\nd i s c r i m i n a t i o n ,\\no r\\nm i s i n f o r m a t i o n .\\nW h i l e\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nh e l p\\na d d r e s s\\ns o m e\\no f\\nt h e s e\\nb i a s e s ,\\ni t ' s\\ne s s e n t i a l\\nt o\\nb e\\na w a r e\\nt h a t\\nb i a s e s\\nm a y\\ns t i l l\\ne m e r g e\\ni n\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nU n p r e d i c t a b i l i t y\\nG e n e r a t i v e\\nA I\\nm o d e l s\\nc a n\\ns o m e t i m e s\\np r o d u c e\\no u t p u t s\\nt h a t\\na r e\\ns u r p r i s i n g\\no r\\nu n e x p e c t e d ,\\ne v e n\\nw i t h\\nc a r e f u l l y\\ne n g i n e e r e d\\np r o m p t s .\\nM a n a g i n g\\nt h i s\\nu n p r e d i c t a b i l i t y\\nc a n\\nb e\\nc h a l l e n g i n g ,\\na n d\\n2 0\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 20}\n",
      "page_content=\"d a t a\\ns c i e n t i s t s\\nm a y\\nn e e d\\nt o\\ni t e r a t e\\na n d\\nr e ﬁ n e\\nt h e i r\\np r o m p t s\\nm u l t i p l e\\nt i m e s\\nt o\\na c h i e v e\\nt h e\\nd e s i r e d\\nr e s u l t s .\\nO v e r f i t t i n g\\nC r a f t i n g\\no v e r l y\\ns p e c i ﬁ c\\no r\\nc o m p l e x\\np r o m p t s\\nc a n\\nl e a d\\nt o\\no v e r ﬁ t t i n g ,\\nw h e r e\\nt h e\\nA I\\nm o d e l\\ng e n e r a t e s\\no u t p u t s\\nt h a t\\na r e\\nt o o\\nn a r r o w l y\\nf o c u s e d\\no r\\na d h e r e n t\\nt o\\nt h e\\np r o m p t ' s\\nc o n s t r a i n t s ,\\nl i m i t i n g\\ni t s\\nc r e a t i v i t y\\no r\\nu s e f u l n e s s .\\nS t r i k i n g\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\ng u i d a n c e\\na n d\\nf r e e d o m\\ni s\\nc r u c i a l\\nf o r\\ne \\x00 e c t i v e\\np r o m p t\\ne n g i n e e r i n g .\\nE v a l u a t i o n\\na n d\\nF e e d b a c k\\nE v a l u a t i n g\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\np r o m p t s\\na n d\\nA I - g e n e r a t e d\\no u t p u t s\\nc a n\\nb e\\nc h a l l e n g i n g ,\\np a r t i c u l a r l y\\nf o r\\ns u b j e c t i v e\\no r\\nc r e a t i v e\\nt a s k s .\\nD e v e l o p i n g\\nr o b u s t\\ne v a l u a t i o n\\nm e t h o d s\\na n d\\ni n c o r p o r a t i n g\\nu s e r\\nf e e d b a c k\\nc a n\\nh e l p\\nd a t a\\ns c i e n t i s t s\\ni t e r a t e\\no n\\nt h e i r\\np r o m p t s\\na n d\\ne n h a n c e\\nt h e\\np e r f o r m a n c e\\no f\\nt h e i r\\nA I\\ns o l u t i o n s .\\nE t h i c a l\\nC o n s i d e r a t i o n s\\nP r o m p t\\ne n g i n e e r i n g\\nr a i s e s\\ne t h i c a l\\nc o n c e r n s ,\\ns u c h\\na s\\nt h e\\np o t e n t i a l\\nt o\\nm a n i p u l a t e\\nu s e r s ,\\ns p r e a d\\nm i s i n f o r m a t i o n ,\\no r\\nr e i n f o r c e\\nb i a s e s .\\nD a t a\\ns c i e n t i s t s\\ns h o u l d\\na p p r o a c h\\np r o m p t\\ne n g i n e e r i n g\\nw i t h\\na\\ns e n s e\\no f\\nr e s p o n s i b i l i t y\\na n d\\nc o n s i d e r\\nt h e\\np o t e n t i a l\\nc o n s e q u e n c e s\\no f\\nt h e i r\\nA I - g e n e r a t e d\\nc o n t e n t .\\nB y\\na c k n o w l e d g i n g\\na n d\\na d d r e s s i n g\\nt h e s e\\nc h a l l e n g e s\\na n d\\nl i m i t a t i o n s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nd e v e l o p\\nm o r e\\ne \\x00 e c t i v e\\na n d\\nr e s p o n s i b l e\\np r o m p t\\ne n g i n e e r i n g\\ns t r a t e g i e s .\\nT h i s\\nu n d e r s t a n d i n g\\nn o t\\no n l y\\nh e l p s\\ni m p r o v e\\nt h e\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nb u t\\na l s o\\nc o n t r i b u t e s\\nt o\\nt h e\\nd e v e l o p m e n t\\no f\\nm o r e\\nr o b u s t ,\\nr e l i a b l e ,\\na n d\\ne t h i c a l\\nA I\\ns o l u t i o n s\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n4 . 2 .\\nS t r i k i n g\\nt h e\\nR i g h t\\nB a l a n c e\\nb e t w e e n\\nG u i d a n c e\\na n d\\nF l e x i b i l i t y\\nO n e\\no f\\nt h e\\nk e y\\nc h a l l e n g e s\\ni n\\np r o m p t\\ne n g i n e e r i n g\\ni s\\nﬁ n d i n g\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\np r o v i d i n g\\ne n o u g h\\ng u i d a n c e\\nt o\\nt h e\\nA I\\nm o d e l\\na n d\\na l l o w i n g\\nf o r\\ns u \\x00 c i e n t\\nﬂ e x i b i l i t y\\nt o\\ng e n e r a t e\\nd i v e r s e\\na n d\\nc r e a t i v e\\no u t p u t s .\\nS t r i k i n g\\nt h i s\\nb a l a n c e\\ni s\\nc r u c i a l\\nf o r\\nm a x i m i z i n g\\nt h e\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nw h i l e\\ne n s u r i n g\\nt h a t\\nt h e i r\\no u t p u t s\\na r e\\nr e l e v a n t ,\\na c c u r a t e ,\\na n d\\ne n g a g i n g .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\ns t r a t e g i e s\\nf o r\\nﬁ n d i n g\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\ng u i d a n c e\\na n d\\nﬂ e x i b i l i t y\\ni n\\np r o m p t\\ne n g i n e e r i n g .\\n2 1\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 21}\n",
      "page_content=\"S t a r t\\nw i t h\\nB r o a d\\nP r o m p t s\\nB e g i n\\nw i t h\\nb r o a d ,\\no p e n - e n d e d\\np r o m p t s\\nt h a t\\na l l o w\\nt h e\\nA I\\nm o d e l\\nt o\\ne x p l o r e\\na\\nw i d e\\nr a n g e\\no f\\ni d e a s\\na n d\\np o s s i b i l i t i e s .\\nT h i s\\na p p r o a c h\\nc a n\\nh e l p\\ny o u\\ng a u g e\\nt h e\\nm o d e l ' s\\nc a p a b i l i t i e s\\na n d\\ni d e n t i f y\\na n y\\nl i m i t a t i o n s\\no r\\nb i a s e s\\ni n\\ni t s\\no u t p u t s .\\nF r o m\\nt h e r e ,\\ny o u\\nc a n\\ni n c r e m e n t a l l y\\nr e ﬁ n e\\nt h e\\np r o m p t\\nt o\\np r o v i d e\\nm o r e\\ng u i d a n c e\\na n d\\ns t r u c t u r e .\\nE x p e r i m e n t\\nw i t h\\nD i f f e r e n t\\nL e v e l s\\no f\\nD e t a i l\\nT r y\\nu s i n g\\nd i \\x00 e r e n t\\nl e v e l s\\no f\\nd e t a i l\\ni n\\ny o u r\\np r o m p t s ,\\nr a n g i n g\\nf r o m\\nv e r y\\ns p e c i ﬁ c\\nt o\\nm o r e\\ng e n e r a l ,\\na n d\\no b s e r v e\\nh o w\\nt h e\\nA I\\nm o d e l\\nr e s p o n d s .\\nT h i s\\ne x p e r i m e n t a t i o n\\nc a n\\nh e l p\\ny o u\\ni d e n t i f y\\nt h e\\no p t i m a l\\nl e v e l\\no f\\ng u i d a n c e\\nr e q u i r e d\\nt o\\ng e n e r a t e\\nt h e\\nd e s i r e d\\no u t p u t s\\nw i t h o u t\\ns a c r i ﬁ c i n g\\nc r e a t i v i t y\\no r\\nd i v e r s i t y .\\nI t e r a t e\\na n d\\nR e f i n e\\nP r o m p t\\ne n g i n e e r i n g\\ni s\\no f t e n\\na n\\ni t e r a t i v e\\np r o c e s s ,\\ni n v o l v i n g\\nt r i a l\\na n d\\ne r r o r\\na s\\ny o u\\nr e ﬁ n e\\na n d\\na d j u s t\\ny o u r\\np r o m p t s\\nt o\\na c h i e v e\\nt h e\\nb e s t\\nr e s u l t s .\\nR e g u l a r l y\\ne v a l u a t e\\nt h e\\nA I - g e n e r a t e d\\no u t p u t s ,\\na n d\\nu s e\\nt h i s\\nf e e d b a c k\\nt o\\nﬁ n e - t u n e\\ny o u r\\np r o m p t s\\na n d\\ns t r i k e\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\ng u i d a n c e\\na n d\\nﬂ e x i b i l i t y .\\nE n c o u r a g e\\nV a r i a b i l i t y\\nD e s i g n\\np r o m p t s\\nt h a t\\ne n c o u r a g e\\nt h e\\nA I\\nm o d e l\\nt o\\ng e n e r a t e\\nm u l t i p l e\\nv a r i a t i o n s\\no r\\ni n t e r p r e t a t i o n s\\no f\\nt h e\\ns a m e\\nc o n t e n t .\\nT h i s\\nc a n\\nh e l p\\ne n s u r e\\nt h a t\\nt h e\\nm o d e l\\nr e m a i n s\\nc r e a t i v e\\na n d\\nd i v e r s e\\nw h i l e\\ns t i l l\\na d h e r i n g\\nt o\\nt h e\\no v e r a l l\\nc o n s t r a i n t s\\na n d\\ng o a l s\\no f\\nt h e\\np r o m p t .\\nL e v e r a g e\\nC o n s t r a i n t s\\na s\\na\\nC r e a t i v e\\nT o o l\\nI n t r o d u c i n g\\nc o n s t r a i n t s\\no r\\nc h a l l e n g e s\\ni n\\ny o u r\\np r o m p t s\\nc a n\\nb e\\na n\\ne \\x00 e c t i v e\\nw a y\\nt o\\ng u i d e\\nt h e\\nA I\\nm o d e l\\nw h i l e\\ne n c o u r a g i n g\\nc r e a t i v e\\np r o b l e m - s o l v i n g .\\nI n s t e a d\\no f\\nv i e w i n g\\nc o n s t r a i n t s\\na s\\nl i m i t a t i o n s ,\\nu s e\\nt h e m\\na s\\nt o o l s\\nt o\\ni n s p i r e\\nt h e\\nA I\\nm o d e l\\nt o\\ng e n e r a t e\\nm o r e\\ni n v e n t i v e\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nC o l l a b o r a t e\\nw i t h\\nU s e r s\\nI n c o r p o r a t e\\nu s e r\\nf e e d b a c k\\na n d\\np r e f e r e n c e s\\ni n t o\\nt h e\\np r o m p t\\ne n g i n e e r i n g\\np r o c e s s ,\\na n d\\nc o l l a b o r a t e\\nw i t h\\nu s e r s\\nt o\\ni d e n t i f y\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\ng u i d a n c e\\na n d\\nﬂ e x i b i l i t y .\\nT h i s\\nc a n\\nh e l p\\ne n s u r e\\nt h a t\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\ni s\\nr e l e v a n t ,\\ne n g a g i n g ,\\na n d\\nt a i l o r e d\\nt o\\nt h e\\nu s e r ' s\\nn e e d s\\na n d\\ne x p e c t a t i o n s .\\n2 2\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 22}\n",
      "page_content=\"B y\\ne m p l o y i n g\\nt h e s e\\ns t r a t e g i e s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\ns t r i k e\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\ng u i d a n c e\\na n d\\nﬂ e x i b i l i t y\\ni n\\np r o m p t\\ne n g i n e e r i n g ,\\nm a x i m i z i n g\\nt h e\\np o t e n t i a l\\no f\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nw h i l e\\ne n s u r i n g\\nt h a t\\nt h e i r\\no u t p u t s\\na r e\\nr e l e v a n t ,\\na c c u r a t e ,\\na n d\\ne n g a g i n g .\\nT h i s\\nd e l i c a t e\\nb a l a n c e\\nn o t\\no n l y\\ne n h a n c e s\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\nb u t\\na l s o\\no p e n s\\nn e w\\no p p o r t u n i t i e s\\nf o r\\nl e v e r a g i n g\\ng e n e r a t i v e\\nA I\\ni n\\nd i v e r s e\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n4 . 3 .\\nE n s u r i n g\\nQ u a l i t y\\na n d\\nR e l i a b i l i t y\\ni n\\nA I - G e n e r a t e d\\nC o n t e n t\\nA s\\nA I - g e n e r a t e d\\nc o n t e n t\\nb e c o m e s\\nm o r e\\np r e v a l e n t ,\\ne n s u r i n g\\ni t s\\nq u a l i t y\\na n d\\nr e l i a b i l i t y\\ni s\\nc r u c i a l\\nf o r\\nm a i n t a i n i n g\\nu s e r\\nt r u s t\\na n d\\nd e l i v e r i n g\\nv a l u e .\\nP r o m p t\\ne n g i n e e r i n g\\np l a y s\\na\\nv i t a l\\nr o l e\\ni n\\ng u i d i n g\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nh i g h - q u a l i t y\\nc o n t e n t ,\\nb u t\\ni t\\na l s o\\np r e s e n t s\\nc h a l l e n g e s\\ni n\\nt e r m s\\no f\\nc o n s i s t e n c y ,\\na c c u r a c y ,\\na n d\\nr e l e v a n c e .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\ns t r a t e g i e s\\nf o r\\no v e r c o m i n g\\nt h e s e\\nc h a l l e n g e s\\na n d\\ne n s u r i n g\\nt h e\\nq u a l i t y\\na n d\\nr e l i a b i l i t y\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\nt h r o u g h\\np r o m p t\\ne n g i n e e r i n g .\\nR i g o r o u s\\nT e s t i n g\\na n d\\nE v a l u a t i o n\\nR e g u l a r l y\\nt e s t\\na n d\\ne v a l u a t e\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nu s i n g\\na\\nc o m b i n a t i o n\\no f\\nq u a n t i t a t i v e\\nm e t r i c s\\na n d\\nq u a l i t a t i v e\\na s s e s s m e n t s .\\nE s t a b l i s h\\nc l e a r\\nb e n c h m a r k s\\na n d\\np e r f o r m a n c e\\nc r i t e r i a\\nt o\\nm e a s u r e\\nt h e\\nq u a l i t y ,\\nr e l e v a n c e ,\\na n d\\na c c u r a c y\\no f\\nt h e\\nc o n t e n t\\na n d\\nu s e\\nt h i s\\nf e e d b a c k\\nt o\\nr e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l s .\\nU s e r\\nF e e d b a c k\\na n d\\nC o l l a b o r a t i o n\\nI n c o r p o r a t e\\nu s e r\\nf e e d b a c k\\ni n t o\\nt h e\\np r o m p t\\ne n g i n e e r i n g\\np r o c e s s\\nt o\\ne n s u r e\\nt h a t\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nm e e t s\\nt h e i r\\nn e e d s ,\\np r e f e r e n c e s ,\\na n d\\ne x p e c t a t i o n s .\\nC o l l a b o r a t e\\nw i t h\\nu s e r s\\nt o\\ni d e n t i f y\\na r e a s\\nf o r\\ni m p r o v e m e n t\\na n d\\ni m p l e m e n t\\nc h a n g e s\\nt o\\ny o u r\\np r o m p t s\\na n d\\nm o d e l s\\na c c o r d i n g l y .\\nC o n t i n u o u s\\nM o d e l\\nI m p r o v e m e n t\\nS t a y\\nu p\\nt o\\nd a t e\\nw i t h\\nt h e\\nl a t e s t\\na d v a n c e m e n t s\\ni n\\nA I\\nr e s e a r c h\\na n d\\ni n c o r p o r a t e\\nn e w\\nt e c h n i q u e s ,\\nm o d e l s ,\\no r\\na p p r o a c h e s\\nt o\\ni m p r o v e\\nt h e\\np e r f o r m a n c e\\na n d\\nr e l i a b i l i t y\\no f\\ny o u r\\ng e n e r a t i v e\\nA I\\ns o l u t i o n s .\\nC o n t i n u o u s l y\\ni t e r a t e\\no n\\na n d\\nr e ﬁ n e\\ny o u r\\nA I\\nm o d e l s\\nb a s e d\\no n\\nu s e r\\nf e e d b a c k ,\\ne v a l u a t i o n\\nr e s u l t s ,\\na n d\\ni n d u s t r y\\nb e s t\\np r a c t i c e s .\\nR o b u s t\\nE r r o r\\nH a n d l i n g\\na n d\\nM o n i t o r i n g\\nD e v e l o p\\nr o b u s t\\ne r r o r\\nh a n d l i n g\\na n d\\nm o n i t o r i n g\\nm e c h a n i s m s\\nt o\\nd e t e c t\\na n d\\na d d r e s s\\np o t e n t i a l\\ni s s u e s\\ni n\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t ,\\ns u c h\\na s\\ni n a c c u r a c i e s ,\\ni n c o n s i s t e n c i e s ,\\no r\\no \\x00 e n s i v e\\nc o n t e n t .\\n2 3\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 23}\n",
      "page_content='I m p l e m e n t\\ns a f e g u a r d s\\na n d\\nﬁ l t e r s\\nt o\\np r e v e n t\\nt h e\\nd i s s e m i n a t i o n\\no f\\nl o w - q u a l i t y\\no r\\nh a r m f u l\\nc o n t e n t\\na n d\\ne n s u r e\\nt h a t\\nA I - g e n e r a t e d\\no u t p u t s\\nm e e t\\ne s t a b l i s h e d\\nq u a l i t y\\ns t a n d a r d s .\\nC l e a r\\nC o m m u n i c a t i o n\\na n d\\nT r a n s p a r e n c y\\nC l e a r l y\\nc o m m u n i c a t e\\nt h e\\nl i m i t a t i o n s\\na n d\\np o t e n t i a l\\nr i s k s\\na s s o c i a t e d\\nw i t h\\nA I - g e n e r a t e d\\nc o n t e n t\\nt o\\nu s e r s ,\\na n d\\nb e\\nt r a n s p a r e n t\\na b o u t\\nh o w\\nt h e\\nc o n t e n t\\ni s\\nc r e a t e d ,\\ne v a l u a t e d ,\\na n d\\nr e ﬁ n e d .\\nT h i s\\nt r a n s p a r e n c y\\nc a n\\nh e l p\\nm a n a g e\\nu s e r\\ne x p e c t a t i o n s ,\\nb u i l d\\nt r u s t ,\\na n d\\np r o m o t e\\nr e s p o n s i b l e\\nu s e\\no f\\nA I - g e n e r a t e d\\nc o n t e n t .\\nM u l t i m o d a l\\nV a l i d a t i o n\\nW h e n\\np o s s i b l e ,\\nl e v e r a g e\\nm u l t i m o d a l\\nv a l i d a t i o n\\na p p r o a c h e s ,\\ns u c h\\na s\\nc o m b i n i n g\\nt e x t ,\\ni m a g e s ,\\na n d\\no t h e r\\nd a t a\\ns o u r c e s ,\\nt o\\ne n h a n c e\\nt h e\\nr e l i a b i l i t y\\na n d\\na c c u r a c y\\no f\\nA I - g e n e r a t e d\\nc o n t e n t .\\nT h i s\\nc a n\\nh e l p\\np r o v i d e\\na d d i t i o n a l\\nc o n t e x t\\na n d\\ns u p p o r t\\nf o r\\nt h e\\ng e n e r a t e d\\nc o n t e n t ,\\ni n c r e a s i n g\\ni t s\\no v e r a l l\\nq u a l i t y\\na n d\\nt r u s t w o r t h i n e s s .\\nB y\\na d o p t i n g\\nt h e s e\\ns t r a t e g i e s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\no v e r c o m e\\nt h e\\nc h a l l e n g e s\\na s s o c i a t e d\\nw i t h\\ne n s u r i n g\\nq u a l i t y\\na n d\\nr e l i a b i l i t y\\ni n\\nA I - g e n e r a t e d\\nc o n t e n t\\na n d\\nd e l i v e r\\nm o r e\\nc o n s i s t e n t ,\\na c c u r a t e ,\\na n d\\nr e l e v a n t\\no u t p u t s\\nt h r o u g h\\np r o m p t\\ne n g i n e e r i n g .\\nT h i s\\nc o m m i t m e n t\\nt o\\nq u a l i t y\\na n d\\nr e l i a b i l i t y\\nn o t\\no n l y\\ne n h a n c e s\\nu s e r\\nt r u s t\\na n d\\ns a t i s f a c t i o n\\nb u t\\na l s o\\nc o n t r i b u t e s\\nt o\\nt h e\\nb r o a d e r\\na d o p t i o n\\na n d\\ns u c c e s s\\no f\\ng e n e r a t i v e\\nA I\\nt e c h n o l o g i e s\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n2 4\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 24}\n",
      "page_content=\"C h a p t e r\\n5 :\\nF u t u r e\\nD i r e c t i o n s\\na n d\\nE m e r g i n g\\nT r e n d s\\ni n\\nP r o m p t\\nE n g i n e e r i n g\\nT h e s e\\ne m e r g i n g\\nt r e n d s\\na n d\\nf u t u r e\\nd i r e c t i o n s\\nn o t\\no n l y\\np r o m i s e\\nt o\\ne n h a n c e\\nt h e\\nc a p a b i l i t i e s\\na n d\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\ns y s t e m s\\nb u t\\na l s o\\nc o n t r i b u t e\\nt o\\nt h e\\nb r o a d e r\\na d o p t i o n\\na n d\\ns u c c e s s\\no f\\nA I\\nt e c h n o l o g i e s\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n5 . 1 .\\nL e v e r a g i n g\\nA d v a n c e d\\nA I\\nM o d e l s\\na n d\\nT e c h n i q u e s\\nA s\\nA I\\nr e s e a r c h\\nc o n t i n u e s\\nt o\\na d v a n c e ,\\nn e w\\nm o d e l s ,\\nt e c h n i q u e s ,\\na n d\\na p p r o a c h e s\\na r e\\nb e i n g\\nd e v e l o p e d\\nt h a t\\nc a n\\ne n h a n c e\\nt h e\\nc a p a b i l i t i e s\\na n d\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\ns y s t e m s .\\nT h e s e\\na d v a n c e m e n t s\\nh o l d\\nt h e\\np o t e n t i a l\\nt o\\nr e v o l u t i o n i z e\\np r o m p t\\ne n g i n e e r i n g\\na n d\\ne n a b l e\\ne v e n\\nm o r e\\ns o p h i s t i c a t e d ,\\nc r e a t i v e ,\\na n d\\ne \\x00 e c t i v e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\ne x p l o r e\\ns o m e\\no f\\nt h e\\ne m e r g i n g\\nt r e n d s\\na n d\\nf u t u r e\\nd i r e c t i o n s\\ni n\\np r o m p t\\ne n g i n e e r i n g\\nt h a t\\nl e v e r a g e\\nt h e s e\\na d v a n c e d\\nA I\\nm o d e l s\\na n d\\nt e c h n i q u e s .\\nF i n e - T u n i n g\\na n d\\nT r a n s f e r\\nL e a r n i n g\\nF i n e - t u n i n g\\np r e - t r a i n e d\\nA I\\nm o d e l s\\no n\\nd o m a i n - s p e c i ﬁ c\\nd a t a s e t s\\nc a n\\nh e l p\\ni m p r o v e\\nt h e i r\\np e r f o r m a n c e\\na n d\\nr e l e v a n c e\\nf o r\\ns p e c i ﬁ c\\nt a s k s\\no r\\ni n d u s t r i e s .\\nT h i s\\na p p r o a c h\\nc a n\\ne n h a n c e\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\np r o m p t\\ne n g i n e e r i n g\\nb y\\ne n a b l i n g\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nc o n t e n t\\nt h a t\\ni s\\nm o r e\\nt a i l o r e d\\nt o\\nt h e\\nu s e r ' s\\nn e e d s\\na n d\\nc o n t e x t .\\nM u l t i - m o d a l\\nA I\\nM o d e l s\\nT h e\\ni n t e g r a t i o n\\no f\\nm u l t i - m o d a l\\nA I\\nm o d e l s ,\\nc a p a b l e\\no f\\np r o c e s s i n g\\na n d\\ng e n e r a t i n g\\nc o n t e n t\\na c r o s s\\nd i \\x00 e r e n t\\nm o d a l i t i e s\\n( e . g . ,\\nt e x t ,\\ni m a g e s ,\\na u d i o ) ,\\nc a n\\ne x p a n d\\nt h e\\ns c o p e\\na n d\\nc a p a b i l i t i e s\\no f\\np r o m p t\\ne n g i n e e r i n g .\\nT h e s e\\nm o d e l s\\nc a n\\ng e n e r a t e\\nm o r e\\ne n g a g i n g\\na n d\\ni m m e r s i v e\\nc o n t e n t\\nb y\\nc o m b i n i n g\\nt e x t\\nw i t h\\nv i s u a l s ,\\na u d i o ,\\no r\\no t h e r\\nf o r m s\\no f\\nm e d i a .\\n2 5\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 25}\n",
      "page_content=\"C o n t e x t u a l\\nA I\\na n d\\nM e m o r y\\nM e c h a n i s m s\\nI n c o r p o r a t i n g\\nc o n t e x t u a l\\nA I\\nm o d e l s\\na n d\\nm e m o r y\\nm e c h a n i s m s\\nc a n\\nh e l p\\ng e n e r a t i v e\\nA I\\ns y s t e m s\\nb e t t e r\\nu n d e r s t a n d\\na n d\\na d a p t\\nt o\\nt h e\\nu s e r ' s\\nc o n t e x t ,\\nh i s t o r y ,\\na n d\\np r e f e r e n c e s .\\nT h i s\\nc a n\\nl e a d\\nt o\\nm o r e\\np e r s o n a l i z e d ,\\nr e l e v a n t ,\\na n d\\ne n g a g i n g\\nA I - g e n e r a t e d\\nc o n t e n t\\nt h r o u g h\\np r o m p t\\ne n g i n e e r i n g .\\nA c t i v e\\nL e a r n i n g\\na n d\\nU s e r\\nI n t e r a c t i o n\\nE m p l o y i n g\\na c t i v e\\nl e a r n i n g\\nt e c h n i q u e s ,\\nw h e r e\\nt h e\\nA I\\nm o d e l\\ni t e r a t i v e l y\\nr e ﬁ n e s\\ni t s\\nu n d e r s t a n d i n g\\na n d\\np e r f o r m a n c e\\nb a s e d\\no n\\nu s e r\\nf e e d b a c k\\na n d\\ni n t e r a c t i o n s ,\\nc a n\\nh e l p\\ni m p r o v e\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\np r o m p t\\ne n g i n e e r i n g .\\nT h i s\\na p p r o a c h\\ne n a b l e s\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nc o n t e n t\\nt h a t\\ni s\\nb e t t e r\\na l i g n e d\\nw i t h\\nu s e r\\nn e e d s\\na n d\\np r e f e r e n c e s\\no v e r\\nt i m e .\\nC o l l a b o r a t i v e\\nA I\\nS y s t e m s\\nD e v e l o p i n g\\nA I\\ns y s t e m s\\nt h a t\\nc a n\\nc o l l a b o r a t e\\nw i t h\\nh u m a n\\nu s e r s\\ni n\\nr e a l - t i m e ,\\ns u c h\\na s\\nc o - w r i t i n g\\no r\\nc o - d e s i g n i n g ,\\nc a n\\nu n l o c k\\nn e w\\np o s s i b i l i t i e s\\nf o r\\np r o m p t\\ne n g i n e e r i n g .\\nT h e s e\\nc o l l a b o r a t i v e\\nA I\\ns y s t e m s\\nc a n\\nh e l p\\nu s e r s\\ng e n e r a t e\\nc o n t e n t\\nm o r e\\ne \\x00 e c t i v e l y ,\\ne \\x00 c i e n t l y ,\\na n d\\nc r e a t i v e l y\\nb y\\nl e v e r a g i n g\\nt h e\\ns t r e n g t h s\\no f\\nb o t h\\nh u m a n s\\na n d\\nA I\\nm o d e l s .\\nE t h i c a l\\nA I\\na n d\\nF a i r n e s s - a w a r e\\nP r o m p t\\nE n g i n e e r i n g\\nA s\\ne t h i c a l\\nc o n s i d e r a t i o n s\\nb e c o m e\\ni n c r e a s i n g l y\\ni m p o r t a n t\\ni n\\nA I\\nr e s e a r c h\\na n d\\nd e v e l o p m e n t ,\\ni n c o r p o r a t i n g\\nf a i r n e s s - a w a r e\\na n d\\ne t h i c a l\\np r i n c i p l e s\\ni n t o\\np r o m p t\\ne n g i n e e r i n g\\nw i l l\\nb e\\nc r u c i a l .\\nT h i s\\nc a n\\nh e l p\\ne n s u r e\\nt h a t\\nA I - g e n e r a t e d\\nc o n t e n t\\ni s\\nn o t\\no n l y\\na c c u r a t e\\na n d\\ne n g a g i n g\\nb u t\\na l s o\\nf a i r ,\\ni n c l u s i v e ,\\na n d\\nr e s p o n s i b l e .\\nB y\\ne m b r a c i n g\\nt h e s e\\na d v a n c e d\\nA I\\nm o d e l s\\na n d\\nt e c h n i q u e s ,\\nd a t a\\ns c i e n t i s t s\\nc a n\\nd r i v e\\nt h e\\ne v o l u t i o n\\no f\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nu n l o c k\\nn e w\\np o s s i b i l i t i e s\\nf o r\\nA I - g e n e r a t e d\\nc o n t e n t .\\nT h e s e\\ne m e r g i n g\\nt r e n d s\\na n d\\nf u t u r e\\nd i r e c t i o n s\\nn o t\\no n l y\\np r o m i s e\\nt o\\ne n h a n c e\\nt h e\\nc a p a b i l i t i e s\\na n d\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\ns y s t e m s\\nb u t\\na l s o\\nc o n t r i b u t e\\nt o\\nt h e\\nb r o a d e r\\na d o p t i o n\\na n d\\ns u c c e s s\\no f\\nA I\\nt e c h n o l o g i e s\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n5 . 2 .\\nT h e\\nC o n v e r g e n c e\\no f\\nH u m a n\\na n d\\nA I\\nC r e a t i v i t y\\nA s\\nA I - g e n e r a t e d\\nc o n t e n t\\nb e c o m e s\\nm o r e\\ns o p h i s t i c a t e d\\na n d\\nc a p a b l e ,\\nt h e\\nc o n v e r g e n c e\\no f\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\np r e s e n t s\\ne x c i t i n g\\no p p o r t u n i t i e s\\nf o r\\nt h e\\nf u t u r e\\no f\\np r o m p t\\ne n g i n e e r i n g .\\nT h e\\ns y n e r g y\\nb e t w e e n\\nh u m a n\\ni n t u i t i o n\\na n d\\nA I ' s\\nc o m p u t a t i o n a l\\np o w e r\\nc a n\\nl e a d\\nt o\\ni n n o v a t i v e\\na n d\\nt r a n s f o r m a t i v e\\na p p l i c a t i o n s\\ni n\\nc o n t e n t\\ng e n e r a t i o n ,\\nc r e a t i v i t y ,\\na n d\\np r o b l e m - s o l v i n g .\\nI n\\nt h i s\\n2 6\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 26}\n",
      "page_content=\"s e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\no f\\nt h e\\nw a y s\\ni n\\nw h i c h\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\nc a n\\nc o n v e r g e\\ni n\\nt h e\\nc o n t e x t\\no f\\np r o m p t\\ne n g i n e e r i n g .\\nH u m a n - A I\\nC o l l a b o r a t i o n\\nD e v e l o p i n g\\nA I\\ns y s t e m s\\nt h a t\\nw o r k\\na l o n g s i d e\\nh u m a n s\\na s\\np a r t n e r s\\nc a n\\ne n a b l e\\nn e w\\nf o r m s\\no f\\nc r e a t i v e\\nc o l l a b o r a t i o n .\\nB y\\nl e v e r a g i n g\\nt h e\\nc o m p l e m e n t a r y\\ns t r e n g t h s\\no f\\nh u m a n\\ni n t u i t i o n ,\\ne x p e r t i s e ,\\na n d\\nc r e a t i v i t y\\nw i t h\\nA I ' s\\nc o m p u t a t i o n a l\\np o w e r\\na n d\\np a t t e r n\\nr e c o g n i t i o n ,\\nt h i s\\np a r t n e r s h i p\\nc a n\\nl e a d\\nt o\\nn o v e l\\na n d\\ni n n o v a t i v e\\ni d e a s\\na n d\\ns o l u t i o n s .\\nA u g m e n t i n g\\nH u m a n\\nC r e a t i v i t y\\nA I - g e n e r a t e d\\nc o n t e n t\\nc a n\\ns e r v e\\na s\\na\\nv a l u a b l e\\nr e s o u r c e\\nf o r\\ni n s p i r i n g\\na n d\\na u g m e n t i n g\\nh u m a n\\nc r e a t i v i t y .\\nB y\\np r o v i d i n g\\nd i v e r s e\\ni d e a s ,\\np e r s p e c t i v e s ,\\na n d\\ns u g g e s t i o n s ,\\nA I\\nm o d e l s\\nc a n\\nh e l p\\nh u m a n s\\no v e r c o m e\\nc r e a t i v e\\nb l o c k s ,\\ne x p l o r e\\nn e w\\nd i r e c t i o n s ,\\no r\\nr e ﬁ n e\\nt h e i r\\ni d e a s .\\nC r e a t i v e\\nE d u c a t i o n\\na n d\\nT r a i n i n g\\nG e n e r a t i v e\\nA I\\nm o d e l s\\nc a n\\np l a y\\na\\np i v o t a l\\nr o l e\\ni n\\nc r e a t i v e\\ne d u c a t i o n\\na n d\\nt r a i n i n g\\nb y\\np r o v i d i n g\\np e r s o n a l i z e d\\nl e a r n i n g\\ne x p e r i e n c e s ,\\ni n t e r a c t i v e\\ns i m u l a t i o n s ,\\na n d\\na d a p t i v e\\nf e e d b a c k .\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\ne m p l o y e d\\nt o\\nd e s i g n\\ne d u c a t i o n a l\\nc o n t e n t\\nt h a t\\nn u r t u r e s\\na n d\\ne n h a n c e s\\nh u m a n\\nc r e a t i v i t y ,\\nc r i t i c a l\\nt h i n k i n g ,\\na n d\\np r o b l e m - s o l v i n g\\ns k i l l s .\\nT h e\\nD e m o c r a t i z a t i o n\\no f\\nC r e a t i v i t y\\nA s\\nA I - g e n e r a t e d\\nc o n t e n t\\nb e c o m e s\\nm o r e\\na c c e s s i b l e\\na n d\\na \\x00 o r d a b l e ,\\ni t\\nc a n\\nh e l p\\nd e m o c r a t i z e\\nc r e a t i v i t y\\nb y\\ne m p o w e r i n g\\ni n d i v i d u a l s\\na n d\\no r g a n i z a t i o n s\\nw i t h\\nl i m i t e d\\nr e s o u r c e s\\nt o\\ng e n e r a t e\\nh i g h - q u a l i t y\\nc o n t e n t ,\\ne x p l o r e\\nn e w\\ni d e a s ,\\no r\\ns o l v e\\nc o m p l e x\\np r o b l e m s .\\nE t h i c a l\\na n d\\nR e s p o n s i b l e\\nC r e a t i v i t y\\nT h e\\nc o n v e r g e n c e\\no f\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\nr a i s e s\\ne t h i c a l\\nq u e s t i o n s\\na n d\\nc h a l l e n g e s .\\nB y\\nf o s t e r i n g\\no p e n\\nd i a l o g u e ,\\nc o l l a b o r a t i o n ,\\na n d\\nr e s p o n s i b l e\\nA I\\np r a c t i c e s ,\\nw e\\nc a n\\ne n s u r e\\nt h a t\\nt h e\\nc o m b i n e d\\np o t e n t i a l\\no f\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\ni s\\nh a r n e s s e d\\nf o r\\nt h e\\ng r e a t e r\\ng o o d\\na n d\\nt h e\\nd e v e l o p m e n t\\no f\\na\\nm o r e\\ni n c l u s i v e\\na n d\\ne q u i t a b l e\\ns o c i e t y .\\nC r o s s - d i s c i p l i n a r y\\nI n n o v a t i o n s\\nT h e\\ni n t e g r a t i o n\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\na n d\\np r o m p t\\ne n g i n e e r i n g\\na c r o s s\\nv a r i o u s\\nd i s c i p l i n e s ,\\ns u c h\\na s\\na r t ,\\ns c i e n c e ,\\nt e c h n o l o g y ,\\na n d\\nh u m a n i t i e s ,\\nc a n\\nl e a d\\nt o\\ng r o u n d b r e a k i n g\\ni n n o v a t i o n s\\na n d\\nd i s c o v e r i e s .\\nB y\\nb r e a k i n g\\nd o w n\\nt r a d i t i o n a l\\nb o u n d a r i e s\\na n d\\nf o s t e r i n g\\nc r o s s - d i s c i p l i n a r y\\nc o l l a b o r a t i o n ,\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\nc a n\\nt o g e t h e r\\nd r i v e\\nt r a n s f o r m a t i v e\\np r o g r e s s .\\n2 7\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 27}\n",
      "page_content=\"B y\\ne m b r a c i n g\\nt h e\\nc o n v e r g e n c e\\no f\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y ,\\nw e\\nc a n\\nu n l o c k\\nn e w\\np o s s i b i l i t i e s\\nf o r\\nt h e\\nf u t u r e\\no f\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nt h e\\nb r o a d e r\\nl a n d s c a p e\\no f\\nc o n t e n t\\ng e n e r a t i o n ,\\nc r e a t i v i t y ,\\na n d\\np r o b l e m - s o l v i n g .\\nT h i s\\ns y n e r g y\\nn o t\\no n l y\\np r o m i s e s\\nt o\\ne n h a n c e\\nt h e\\nc a p a b i l i t i e s\\na n d\\np e r f o r m a n c e\\no f\\ng e n e r a t i v e\\nA I\\ns y s t e m s\\nb u t\\na l s o\\nc o n t r i b u t e s\\nt o\\nt h e\\nd e v e l o p m e n t\\no f\\nm o r e\\ni n n o v a t i v e ,\\ni n c l u s i v e ,\\na n d\\ne q u i t a b l e\\ns o l u t i o n s\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\na n d\\nd o m a i n s .\\n5 . 3 .\\nT h e\\nR o l e\\no f\\nP r o m p t\\nE n g i n e e r i n g\\ni n\\nt h e\\nA I - D r i v e n\\nE c o n o m y\\nA s\\nA I\\nt e c h n o l o g i e s\\nc o n t i n u e\\nt o\\na d v a n c e\\na n d\\nr e s h a p e\\nv a r i o u s\\na s p e c t s\\no f\\nt h e\\ng l o b a l\\ne c o n o m y ,\\nt h e\\nr o l e\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni s\\np o i s e d\\nt o\\ng r o w\\ni n\\ni m p o r t a n c e\\na n d\\ni m p a c t .\\nF r o m\\nc o n t e n t\\ng e n e r a t i o n\\nt o\\nd e c i s i o n - m a k i n g ,\\nA I - d r i v e n\\ns o l u t i o n s\\na r e\\ni n c r e a s i n g l y\\nb e c o m i n g\\na\\nk e y\\nc o m p o n e n t\\no f\\nb u s i n e s s e s ,\\ng o v e r n m e n t s ,\\na n d\\no r g a n i z a t i o n s\\nw o r l d w i d e .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\nh o w\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\np l a y\\na\\nc r u c i a l\\nr o l e\\ni n\\nt h e\\nA I - d r i v e n\\ne c o n o m y\\na n d\\ne n a b l e\\nm o r e\\ne \\x00 e c t i v e ,\\ne \\x00 c i e n t ,\\na n d\\ni n n o v a t i v e\\ns o l u t i o n s\\na c r o s s\\nd i v e r s e\\ns e c t o r s .\\nE n h a n c i n g\\nB u s i n e s s\\nC o m m u n i c a t i o n s\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\nr e v o l u t i o n i z e\\nb u s i n e s s\\nc o m m u n i c a t i o n s\\nb y\\ng e n e r a t i n g\\np e r s o n a l i z e d ,\\ne n g a g i n g ,\\na n d\\nh i g h - q u a l i t y\\nc o n t e n t\\nt a i l o r e d\\nt o\\ns p e c i ﬁ c\\na u d i e n c e s ,\\nc h a n n e l s ,\\no r\\no b j e c t i v e s .\\nF r o m\\nm a r k e t i n g\\na n d\\na d v e r t i s i n g\\nt o\\nc u s t o m e r\\ns u p p o r t\\na n d\\ni n t e r n a l\\nc o m m u n i c a t i o n s ,\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nh e l p\\no r g a n i z a t i o n s\\no p t i m i z e\\nt h e i r\\nm e s s a g i n g\\na n d\\nr e a c h .\\nA c c e l e r a t i n g\\nR e s e a r c h\\na n d\\nD e v e l o p m e n t\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\nu t i l i z e d\\nt o\\ns y n t h e s i z e\\nv a s t\\na m o u n t s\\no f\\ni n f o r m a t i o n ,\\ng e n e r a t e\\ni n s i g h t s ,\\na n d\\ni d e n t i f y\\nt r e n d s ,\\np a t t e r n s ,\\no r\\no p p o r t u n i t i e s .\\nT h i s\\nc a n\\ne n a b l e\\nr e s e a r c h e r s\\na n d\\no r g a n i z a t i o n s\\nt o\\na c c e l e r a t e\\nt h e i r\\nR & D\\np r o c e s s e s ,\\nm a k e\\nm o r e\\ni n f o r m e d\\nd e c i s i o n s ,\\na n d\\nd r i v e\\ni n n o v a t i o n\\na c r o s s\\nv a r i o u s\\nd o m a i n s .\\nP e r s o n a l i z i n g\\nC u s t o m e r\\nE x p e r i e n c e s\\nB y\\ng e n e r a t i n g\\np e r s o n a l i z e d\\nc o n t e n t\\na n d\\nr e c o m m e n d a t i o n s\\nb a s e d\\no n\\nu s e r\\np r e f e r e n c e s ,\\nb e h a v i o r ,\\no r\\nc o n t e x t ,\\np r o m p t\\ne n g i n e e r i n g\\nc a n\\nh e l p\\nb u s i n e s s e s\\na n d\\no r g a n i z a t i o n s\\nd e l i v e r\\nm o r e\\nr e l e v a n t ,\\ne n g a g i n g ,\\na n d\\nv a l u a b l e\\nc u s t o m e r\\ne x p e r i e n c e s\\na c r o s s\\nd i v e r s e\\nc h a n n e l s\\na n d\\nt o u c h p o i n t s .\\n2 8\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 28}\n",
      "page_content=\"D e m o c r a t i z i n g\\nA c c e s s\\nt o\\nE x p e r t i s e\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\ne m p l o y e d\\nt o\\ng e n e r a t e\\ne x p e r t\\nk n o w l e d g e ,\\ng u i d a n c e ,\\no r\\na d v i c e\\ni n\\na\\nw i d e\\nr a n g e\\no f\\nﬁ e l d s ,\\nm a k i n g\\ns p e c i a l i z e d\\ne x p e r t i s e\\nm o r e\\na c c e s s i b l e\\na n d\\na \\x00 o r d a b l e\\nf o r\\ni n d i v i d u a l s ,\\nb u s i n e s s e s ,\\na n d\\nc o m m u n i t i e s\\nw o r l d w i d e .\\nS u p p o r t i n g\\nP o l i c y - m a k i n g\\na n d\\nG o v e r n a n c e\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\np l a y\\na\\nc r i t i c a l\\nr o l e\\ni n\\np o l i c y - m a k i n g\\na n d\\ng o v e r n a n c e\\nb y\\ng e n e r a t i n g\\ne v i d e n c e - b a s e d\\ni n s i g h t s ,\\nf o r e c a s t s ,\\no r\\nr e c o m m e n d a t i o n s .\\nT h i s\\nc a n\\nh e l p\\ng o v e r n m e n t s\\na n d\\no r g a n i z a t i o n s\\nm a k e\\nm o r e\\ni n f o r m e d ,\\ne \\x00 e c t i v e ,\\na n d\\ne q u i t a b l e\\nd e c i s i o n s\\nt h a t\\nb e t t e r\\ns e r v e\\nt h e\\nn e e d s\\na n d\\ni n t e r e s t s\\no f\\nt h e i r\\nc o n s t i t u e n t s .\\nF o s t e r i n g\\nC r e a t i v i t y\\na n d\\nI n n o v a t i o n\\nT h e\\nc o m b i n a t i o n\\no f\\nh u m a n\\na n d\\nA I\\nc r e a t i v i t y\\nc a n\\nl e a d\\nt o\\ng r o u n d b r e a k i n g\\ni n n o v a t i o n s\\na n d\\nd i s c o v e r i e s\\na c r o s s\\nv a r i o u s\\nd i s c i p l i n e s ,\\na s\\nd i s c u s s e d\\ni n\\nS e c t i o n\\n5 . 2 .\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\na c t\\na s\\na\\nc a t a l y s t\\nf o r\\nc r e a t i v i t y ,\\ne n a b l i n g\\ni n d i v i d u a l s\\na n d\\no r g a n i z a t i o n s\\nt o\\ne x p l o r e\\nn e w\\ni d e a s ,\\nc h a l l e n g e\\na s s u m p t i o n s ,\\na n d\\np u s h\\nt h e\\nb o u n d a r i e s\\no f\\nw h a t ' s\\np o s s i b l e .\\nA d d r e s s i n g\\nG l o b a l\\nC h a l l e n g e s\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\nb e\\nh a r n e s s e d\\nt o\\ng e n e r a t e\\ns o l u t i o n s ,\\ns t r a t e g i e s ,\\no r\\ni d e a s\\nt o\\na d d r e s s\\nc o m p l e x\\ng l o b a l\\nc h a l l e n g e s ,\\ns u c h\\na s\\nc l i m a t e\\nc h a n g e ,\\np o v e r t y ,\\no r\\ni n e q u a l i t y .\\nB y\\nl e v e r a g i n g\\nA I - g e n e r a t e d\\nc o n t e n t\\na n d\\ni n s i g h t s ,\\nw e\\nc a n\\nd e v e l o p\\nm o r e\\ne \\x00 e c t i v e ,\\ns c a l a b l e ,\\na n d\\ns u s t a i n a b l e\\na p p r o a c h e s\\nt o\\nt a c k l i n g\\np r e s s i n g\\ns o c i e t a l\\ni s s u e s .\\nA s\\nt h e\\nA I - d r i v e n\\ne c o n o m y\\nc o n t i n u e s\\nt o\\ne v o l v e\\na n d\\ne x p a n d ,\\nt h e\\nr o l e\\no f\\np r o m p t\\ne n g i n e e r i n g\\nw i l l\\nb e c o m e\\ni n c r e a s i n g l y\\ns i g n i ﬁ c a n t\\na n d\\nt r a n s f o r m a t i v e\\na c r o s s\\nd i v e r s e\\ns e c t o r s\\na n d\\nd o m a i n s .\\nB y\\ne m b r a c i n g\\np r o m p t\\ne n g i n e e r i n g\\na n d\\ni t s\\np o t e n t i a l ,\\nw e\\nc a n\\ne n a b l e\\nm o r e\\ne \\x00 e c t i v e ,\\ne \\x00 c i e n t ,\\na n d\\ni n n o v a t i v e\\ns o l u t i o n s\\nt h a t\\nd r i v e\\np r o g r e s s ,\\ne n h a n c e\\nw e l l - b e i n g ,\\na n d\\nc r e a t e\\na\\nm o r e\\np r o s p e r o u s\\na n d\\ne q u i t a b l e\\nf u t u r e\\nf o r\\na l l .\\n2 9\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 29}\n",
      "page_content=\"C h a p t e r\\n6 :\\nP r a c t i c a l\\nT i p s\\na n d\\nB e s t\\nP r a c t i c e s\\nf o r\\nP r o m p t\\nE n g i n e e r i n g\\nB y\\nf o l l o w i n g\\nt h e s e\\np r a c t i c a l\\nt i p s\\na n d\\nb e s t\\np r a c t i c e s ,\\ny o u\\nc a n\\ng e t\\ns t a r t e d\\nw i t h\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nh a r n e s s\\ni t s\\np o t e n t i a l\\nt o\\nc r e a t e\\nh i g h - q u a l i t y ,\\ne n g a g i n g ,\\na n d\\ne \\x00 e c t i v e\\nA I - g e n e r a t e d\\nc o n t e n t .\\n6 . 1 .\\nG e t t i n g\\nS t a r t e d\\nw i t h\\nP r o m p t\\nE n g i n e e r i n g\\nF o r\\nd a t a\\ns c i e n t i s t s\\na n d\\np r a c t i t i o n e r s\\nl o o k i n g\\nt o\\nh a r n e s s\\nt h e\\np o w e r\\no f\\np r o m p t\\ne n g i n e e r i n g\\nf o r\\ng e n e r a t i v e\\nA I\\na p p l i c a t i o n s ,\\ng e t t i n g\\ns t a r t e d\\nc a n\\ns e e m\\nd a u n t i n g .\\nH o w e v e r ,\\nb y\\nf o l l o w i n g\\ns o m e\\np r a c t i c a l\\nt i p s\\na n d\\nb e s t\\np r a c t i c e s ,\\ny o u\\nc a n\\nb e g i n\\nl e v e r a g i n g\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 e c t i v e l y\\na n d\\ne \\x00 c i e n t l y .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\np r o v i d e\\ng u i d a n c e\\no n\\nh o w\\nt o\\ng e t\\ns t a r t e d\\nw i t h\\np r o m p t\\ne n g i n e e r i n g\\na n d\\ne n s u r e\\na\\ns u c c e s s f u l\\ni m p l e m e n t a t i o n .\\nU n d e r s t a n d\\nY o u r\\nA I\\nM o d e l\\nB e f o r e\\nd i v i n g\\ni n t o\\np r o m p t\\ne n g i n e e r i n g ,\\nf a m i l i a r i z e\\ny o u r s e l f\\nw i t h\\nt h e\\nA I\\nm o d e l\\ny o u ' r e\\nw o r k i n g\\nw i t h ,\\ni t s\\nc a p a b i l i t i e s ,\\na n d\\ni t s\\nl i m i t a t i o n s .\\nU n d e r s t a n d i n g\\nt h e\\nm o d e l ' s\\na r c h i t e c t u r e ,\\np r e - t r a i n i n g\\nd a t a ,\\na n d\\nﬁ n e - t u n i n g\\nm e t h o d s\\nc a n\\nh e l p\\ny o u\\nc r a f t\\nb e t t e r\\np r o m p t s\\na n d\\na n t i c i p a t e\\np o t e n t i a l\\ni s s u e s .\\nD e f i n e\\nC l e a r\\nO b j e c t i v e s\\nE s t a b l i s h\\nc l e a r\\no b j e c t i v e s\\nf o r\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t ,\\nc o n s i d e r i n g\\nf a c t o r s\\ns u c h\\na s\\nt h e\\nt a r g e t\\na u d i e n c e ,\\ni n t e n d e d\\np u r p o s e ,\\na n d\\nd e s i r e d\\no u t c o m e .\\nT h e s e\\no b j e c t i v e s\\nw i l l\\ng u i d e\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s\\na n d\\nh e l p\\ne n s u r e\\nt h e\\ng e n e r a t e d\\nc o n t e n t\\ni s\\nr e l e v a n t ,\\ne n g a g i n g ,\\na n d\\ne \\x00 e c t i v e .\\nS t a r t\\nS i m p l e\\nB e g i n\\nw i t h\\ns i m p l e ,\\no p e n - e n d e d\\np r o m p t s\\nt o\\ng a u g e\\nt h e\\nA I\\nm o d e l ' s\\nc a p a b i l i t i e s\\na n d\\ni d e n t i f y\\na n y\\nl i m i t a t i o n s\\no r\\nb i a s e s\\ni n\\ni t s\\no u t p u t s .\\nF r o m\\nt h e r e ,\\ny o u\\nc a n\\ni n c r e m e n t a l l y\\nr e ﬁ n e\\nt h e\\np r o m p t\\nt o\\np r o v i d e\\nm o r e\\ng u i d a n c e\\na n d\\ns t r u c t u r e\\nb a s e d\\no n\\nt h e\\nm o d e l ' s\\np e r f o r m a n c e\\na n d\\ny o u r\\no b j e c t i v e s .\\n3 0\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 30}\n",
      "page_content=\"I t e r a t e\\na n d\\nE x p e r i m e n t\\nP r o m p t\\ne n g i n e e r i n g\\ni s\\no f t e n\\na n\\ni t e r a t i v e\\np r o c e s s ,\\ni n v o l v i n g\\nt r i a l\\na n d\\ne r r o r\\na s\\ny o u\\nr e ﬁ n e\\na n d\\na d j u s t\\ny o u r\\np r o m p t s\\nt o\\na c h i e v e\\nt h e\\nb e s t\\nr e s u l t s .\\nE x p e r i m e n t\\nw i t h\\nd i \\x00 e r e n t\\np r o m p t\\ns t r u c t u r e s ,\\ng u i d a n c e\\nl e v e l s ,\\na n d\\nc o n t e x t\\nt o\\ni d e n t i f y\\nt h e\\no p t i m a l\\na p p r o a c h\\nf o r\\ny o u r\\ns p e c i ﬁ c\\na p p l i c a t i o n .\\nE v a l u a t e\\na n d\\nM o n i t o r\\nR e g u l a r l y\\ne v a l u a t e\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nu s i n g\\na\\nc o m b i n a t i o n\\no f\\nq u a n t i t a t i v e\\nm e t r i c s\\na n d\\nq u a l i t a t i v e\\na s s e s s m e n t s .\\nE s t a b l i s h\\nc l e a r\\nb e n c h m a r k s\\na n d\\np e r f o r m a n c e\\nc r i t e r i a\\nt o\\nm e a s u r e\\nt h e\\nq u a l i t y ,\\nr e l e v a n c e ,\\na n d\\na c c u r a c y\\no f\\nt h e\\nc o n t e n t ,\\na n d\\nu s e\\nt h i s\\nf e e d b a c k\\nt o\\nr e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l .\\nC o l l a b o r a t e\\na n d\\nL e a r n\\nf r o m\\nO t h e r s\\nP r o m p t\\ne n g i n e e r i n g\\ni s\\na\\ng r o w i n g\\nﬁ e l d ,\\nw i t h\\na\\nv i b r a n t\\nc o m m u n i t y\\no f\\nr e s e a r c h e r s\\na n d\\np r a c t i t i o n e r s\\ns h a r i n g\\ni n s i g h t s ,\\nt e c h n i q u e s ,\\na n d\\nb e s t\\np r a c t i c e s .\\nE n g a g e\\nw i t h\\nt h e\\nc o m m u n i t y ,\\nl e a r n\\nf r o m\\no t h e r s '\\ne x p e r i e n c e s ,\\na n d\\nc o l l a b o r a t e\\no n\\np r o j e c t s\\nt o\\nc o n t i n u o u s l y\\ni m p r o v e\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ns k i l l s\\na n d\\nk n o w l e d g e .\\nB e\\nM i n d f u l\\no f\\nE t h i c s\\na n d\\nR e s p o n s i b i l i t y\\nA s\\ny o u\\nd e v e l o p\\nA I - g e n e r a t e d\\nc o n t e n t ,\\na l w a y s\\nb e\\nm i n d f u l\\no f\\nt h e\\ne t h i c a l\\ni m p l i c a t i o n s\\na n d\\np o t e n t i a l\\nr i s k s\\na s s o c i a t e d\\nw i t h\\ny o u r\\nw o r k .\\nE n s u r e\\nt h a t\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l s\\na d h e r e\\nt o\\ne t h i c a l\\ng u i d e l i n e s\\na n d\\nr e s p o n s i b l e\\nA I\\np r a c t i c e s ,\\na n d\\ns t r i v e\\nt o\\nc r e a t e\\nc o n t e n t\\nt h a t\\ni s\\nf a i r ,\\ni n c l u s i v e ,\\na n d\\nr e s p e c t f u l .\\nB y\\nf o l l o w i n g\\nt h e s e\\np r a c t i c a l\\nt i p s\\na n d\\nb e s t\\np r a c t i c e s ,\\ny o u\\nc a n\\ng e t\\ns t a r t e d\\nw i t h\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nh a r n e s s\\ni t s\\np o t e n t i a l\\nt o\\nc r e a t e\\nh i g h - q u a l i t y ,\\ne n g a g i n g ,\\na n d\\ne \\x00 e c t i v e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nA s\\ny o u\\ng a i n\\ne x p e r i e n c e\\na n d\\ne x p e r t i s e ,\\ny o u ' l l\\nb e\\nb e t t e r\\ne q u i p p e d\\nt o\\nt a c k l e\\nm o r e\\nc o m p l e x\\na p p l i c a t i o n s\\na n d\\nc h a l l e n g e s ,\\nd r i v i n g\\ni n n o v a t i o n\\na n d\\np r o g r e s s\\ni n\\nt h e\\nr a p i d l y\\ne v o l v i n g\\nﬁ e l d\\no f\\ng e n e r a t i v e\\nA I .\\n6 . 2 .\\nB u i l d i n g\\na n\\nE \\x00 e c t i v e\\nP r o m p t\\nE n g i n e e r i n g\\nW o r k ﬂ o w\\nD e v e l o p i n g\\na\\ns t r u c t u r e d\\na n d\\ne \\x00 c i e n t\\np r o m p t\\ne n g i n e e r i n g\\nw o r k ﬂ o w\\ni s\\ne s s e n t i a l\\nf o r\\nc r e a t i n g\\nh i g h - q u a l i t y\\nA I - g e n e r a t e d\\nc o n t e n t\\nc o n s i s t e n t l y .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\nt h e\\nk e y\\nc o m p o n e n t s\\no f\\na n\\ne \\x00 e c t i v e\\np r o m p t\\ne n g i n e e r i n g\\nw o r k ﬂ o w\\na n d\\np r o v i d e\\np r a c t i c a l\\nt i p s\\no n\\nh o w\\nt o\\ns t r e a m l i n e\\na n d\\no p t i m i z e\\ny o u r\\np r o c e s s e s .\\n3 1\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 31}\n",
      "page_content=\"P l a n n i n g\\na n d\\nR e s e a r c h\\nS t a r t\\nb y\\nc o n d u c t i n g\\nt h o r o u g h\\nr e s e a r c h\\no n\\ny o u r\\nt o p i c ,\\nt a r g e t\\na u d i e n c e ,\\na n d\\nt h e\\nA I\\nm o d e l\\ny o u ' l l\\nb e\\nu s i n g .\\nT h i s\\nr e s e a r c h\\nw i l l\\nh e l p\\ny o u\\ni d e n t i f y\\nt h e\\nm o s t\\nr e l e v a n t\\ni n f o r m a t i o n ,\\nt r e n d s ,\\na n d\\ni n s i g h t s ,\\na n d\\nl a y\\nt h e\\ng r o u n d w o r k\\nf o r\\nc r a f t i n g\\ne \\x00 e c t i v e\\np r o m p t s .\\nO b j e c t i v e\\nS e t t i n g\\nD e ﬁ n e\\nc l e a r\\no b j e c t i v e s\\nf o r\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t ,\\nt a k i n g\\ni n t o\\nc o n s i d e r a t i o n\\nf a c t o r s\\ns u c h\\na s\\np u r p o s e ,\\na u d i e n c e ,\\na n d\\nd e s i r e d\\no u t c o m e s .\\nU s e\\nt h e s e\\no b j e c t i v e s\\na s\\na\\ng u i d e\\nt h r o u g h o u t\\nt h e\\np r o m p t\\ne n g i n e e r i n g\\np r o c e s s\\nt o\\ne n s u r e\\nt h a t\\nt h e\\ng e n e r a t e d\\nc o n t e n t\\ni s\\na l i g n e d\\nw i t h\\ny o u r\\ng o a l s .\\nD r a f t i n g\\nI n i t i a l\\nP r o m p t s\\nB a s e d\\no n\\ny o u r\\nr e s e a r c h\\na n d\\no b j e c t i v e s ,\\nd r a f t\\na\\ns e t\\no f\\ni n i t i a l\\np r o m p t s\\nt h a t\\np r o v i d e\\ng u i d a n c e\\na n d\\nc o n t e x t\\nf o r\\nt h e\\nA I\\nm o d e l .\\nS t a r t\\ns i m p l e ,\\na n d\\ni t e r a t i v e l y\\nr e ﬁ n e\\nt h e\\np r o m p t s\\na s\\nn e e d e d\\nt o\\ni m p r o v e\\nt h e\\nq u a l i t y\\na n d\\nr e l e v a n c e\\no f\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t .\\nT e s t i n g\\na n d\\nE v a l u a t i o n\\nT e s t\\ny o u r\\ni n i t i a l\\np r o m p t s\\nu s i n g\\nt h e\\nA I\\nm o d e l\\na n d\\ne v a l u a t e\\nt h e\\ng e n e r a t e d\\nc o n t e n t\\nb a s e d\\no n\\ne s t a b l i s h e d\\nb e n c h m a r k s\\na n d\\np e r f o r m a n c e\\nc r i t e r i a .\\nI d e n t i f y\\na n y\\ni s s u e s ,\\nb i a s e s ,\\no r\\ni n a c c u r a c i e s\\ni n\\nt h e\\nc o n t e n t ,\\na n d\\nu s e\\nt h i s\\nf e e d b a c k\\nt o\\nr e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\ni m p r o v e\\nt h e\\nA I\\nm o d e l ' s\\np e r f o r m a n c e .\\nI t e r a t i o n\\na n d\\nR e f i n e m e n t\\nP r o m p t\\ne n g i n e e r i n g\\ni s\\na n\\ni t e r a t i v e\\np r o c e s s ,\\ns o\\nc o n t i n u a l l y\\nr e ﬁ n e\\na n d\\na d j u s t\\ny o u r\\np r o m p t s\\nb a s e d\\no n\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t ' s\\np e r f o r m a n c e\\na n d\\nf e e d b a c k .\\nE x p e r i m e n t\\nw i t h\\nd i \\x00 e r e n t\\np r o m p t\\ns t r u c t u r e s ,\\ng u i d a n c e\\nl e v e l s ,\\na n d\\nc o n t e x t\\nt o\\no p t i m i z e\\nt h e\\nq u a l i t y\\na n d\\nr e l e v a n c e\\no f\\nt h e\\ng e n e r a t e d\\nc o n t e n t .\\nM o n i t o r i n g\\na n d\\nM a i n t e n a n c e\\nR e g u l a r l y\\nm o n i t o r\\nt h e\\np e r f o r m a n c e\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\na n d\\nt h e\\ne \\x00 e c t i v e n e s s\\no f\\ny o u r\\np r o m p t s .\\nK e e p\\nt r a c k\\no f\\na n y\\nc h a n g e s\\ni n\\nt h e\\nt a r g e t\\na u d i e n c e ,\\nt o p i c ,\\no r\\nA I\\nm o d e l ,\\na n d\\na d j u s t\\ny o u r\\np r o m p t s\\na c c o r d i n g l y\\nt o\\nm a i n t a i n\\nc o n t e n t\\nq u a l i t y\\na n d\\nr e l e v a n c e .\\nC o l l a b o r a t i o n\\na n d\\nC o n t i n u o u s\\nL e a r n i n g\\nC o l l a b o r a t e\\nw i t h\\no t h e r\\nd a t a\\ns c i e n t i s t s ,\\nr e s e a r c h e r s ,\\na n d\\np r a c t i t i o n e r s\\nt o\\ns h a r e\\ni n s i g h t s ,\\nt e c h n i q u e s ,\\na n d\\nb e s t\\np r a c t i c e s .\\nS t a y\\nu p\\nt o\\nd a t e\\nw i t h\\nt h e\\nl a t e s t\\na d v a n c e m e n t s\\ni n\\nA I\\nr e s e a r c h\\na n d\\n3 2\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 32}\n",
      "page_content=\"p r o m p t\\ne n g i n e e r i n g ,\\na n d\\nc o n t i n u o u s l y\\ni m p r o v e\\ny o u r\\ns k i l l s\\na n d\\nk n o w l e d g e\\nt o\\ns t a y\\na h e a d\\ni n\\nt h e\\nﬁ e l d .\\nB y\\nb u i l d i n g\\na n\\ne \\x00 e c t i v e\\np r o m p t\\ne n g i n e e r i n g\\nw o r k ﬂ o w ,\\ny o u\\nc a n\\ns t r e a m l i n e\\ny o u r\\np r o c e s s e s ,\\ne n h a n c e\\nt h e\\nq u a l i t y\\na n d\\nr e l e v a n c e\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t ,\\na n d\\ne n s u r e\\nt h a t\\ny o u r\\np r o j e c t s\\na r e\\na l i g n e d\\nw i t h\\ny o u r\\no b j e c t i v e s\\na n d\\ng o a l s .\\nT h i s\\ns t r u c t u r e d\\na p p r o a c h\\nn o t\\no n l y\\nh e l p s\\ny o u\\nc r e a t e\\ne n g a g i n g\\na n d\\ne \\x00 e c t i v e\\nc o n t e n t\\nb u t\\na l s o\\nc o n t r i b u t e s\\nt o\\ny o u r\\nl o n g - t e r m\\ns u c c e s s\\na n d\\ng r o w t h\\ni n\\nt h e\\nr a p i d l y\\ne v o l v i n g\\nﬁ e l d\\no f\\ng e n e r a t i v e\\nA I .\\n6 . 3 .\\nO v e r c o m i n g\\nC o m m o n\\nC h a l l e n g e s\\ni n\\nP r o m p t\\nE n g i n e e r i n g\\nP r o m p t\\ne n g i n e e r i n g\\nc a n\\np r e s e n t\\na\\nv a r i e t y\\no f\\nc h a l l e n g e s ,\\nf r o m\\na d d r e s s i n g\\nA I\\nm o d e l\\nl i m i t a t i o n s\\nt o\\nc r a f t i n g\\ne \\x00 e c t i v e\\np r o m p t s\\nt h a t\\ng e n e r a t e\\nt h e\\nd e s i r e d\\nc o n t e n t .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\nc o m m o n\\nc h a l l e n g e s\\ni n\\np r o m p t\\ne n g i n e e r i n g\\na n d\\np r o v i d e\\np r a c t i c a l\\nt i p s\\no n\\nh o w\\nt o\\no v e r c o m e\\nt h e m .\\nD e a l i n g\\nw i t h\\nA I\\nM o d e l\\nL i m i t a t i o n s\\nA I\\nm o d e l s\\nm a y\\nh a v e\\nl i m i t a t i o n s\\ni n\\nt h e i r\\nu n d e r s t a n d i n g\\no f\\nc e r t a i n\\nt o p i c s ,\\nc o n t e x t s ,\\no r\\nn u a n c e s .\\nT o\\na d d r e s s\\nt h e s e\\nl i m i t a t i o n s ,\\ny o u\\nc a n\\ne x p e r i m e n t\\nw i t h\\nd i \\x00 e r e n t\\np r o m p t\\ns t r u c t u r e s ,\\nﬁ n e - t u n e\\nt h e\\nA I\\nm o d e l\\no n\\nd o m a i n - s p e c i ﬁ c\\nd a t a ,\\no r\\nc o m b i n e\\nt h e\\no u t p u t s\\no f\\nm u l t i p l e\\nA I\\nm o d e l s\\nt o\\ne n h a n c e\\nt h e\\ng e n e r a t e d\\nc o n t e n t ' s\\nq u a l i t y .\\nH a n d l i n g\\nA I\\nM o d e l\\nB i a s\\nA I\\nm o d e l s\\nc a n\\ns o m e t i m e s\\ne x h i b i t\\nb i a s e s\\np r e s e n t\\ni n\\nt h e i r\\nt r a i n i n g\\nd a t a .\\nT o\\nm i t i g a t e\\nt h e s e\\nb i a s e s ,\\ny o u\\nc a n\\ne m p l o y\\nt e c h n i q u e s\\ns u c h\\na s\\nb i a s - a w a r e\\np r o m p t\\ne n g i n e e r i n g\\no r\\nl e v e r a g e\\ne x t e r n a l\\nt o o l s\\na n d\\nr e s o u r c e s\\nt o\\ni d e n t i f y\\na n d\\nc o r r e c t\\nb i a s e d\\no u t p u t s .\\nS t r i k i n g\\nt h e\\nR i g h t\\nB a l a n c e\\no f\\nG u i d a n c e\\nF i n d i n g\\nt h e\\nr i g h t\\nb a l a n c e\\nb e t w e e n\\np r o v i d i n g\\nt o o\\nm u c h\\no r\\nt o o\\nl i t t l e\\ng u i d a n c e\\ni n\\np r o m p t s\\nc a n\\nb e\\nc h a l l e n g i n g .\\nT o\\ns t r i k e\\nt h e\\nr i g h t\\nb a l a n c e ,\\ne x p e r i m e n t\\nw i t h\\nv a r y i n g\\nl e v e l s\\no f\\ns p e c i ﬁ c i t y ,\\nc o n t e x t ,\\na n d\\nc o n s t r a i n t\\ni n\\ny o u r\\np r o m p t s ,\\na n d\\ni t e r a t i v e l y\\nr e ﬁ n e\\nt h e m\\nb a s e d\\no n\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t ' s\\np e r f o r m a n c e\\na n d\\ny o u r\\no b j e c t i v e s .\\nE n s u r i n g\\nC o n t e n t\\nQ u a l i t y\\na n d\\nR e l e v a n c e\\nE n s u r i n g\\nt h a t\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nm e e t s\\ny o u r\\nq u a l i t y\\na n d\\nr e l e v a n c e\\nc r i t e r i a\\nc a n\\nb e\\na\\nd a u n t i n g\\nt a s k .\\nE s t a b l i s h\\nc l e a r\\nb e n c h m a r k s\\na n d\\np e r f o r m a n c e\\nc r i t e r i a ,\\na n d\\nu s e\\na\\nc o m b i n a t i o n\\no f\\n3 3\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 33}\n",
      "page_content=\"q u a n t i t a t i v e\\nm e t r i c s\\na n d\\nq u a l i t a t i v e\\na s s e s s m e n t s\\nt o\\ne v a l u a t e\\nt h e\\nc o n t e n t .\\nR e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l\\na c c o r d i n g l y\\nt o\\ni m p r o v e\\nt h e\\nc o n t e n t ' s\\nq u a l i t y\\na n d\\nr e l e v a n c e .\\nO v e r c o m i n g\\nC r e a t i v e\\nB l o c k s\\nA I - g e n e r a t e d\\nc o n t e n t\\nm a y\\ns o m e t i m e s\\nl a c k\\nc r e a t i v i t y\\no r\\nf a l l\\ns h o r t\\no f\\ny o u r\\ne x p e c t a t i o n s .\\nI n\\ns u c h\\nc a s e s ,\\nc o n s i d e r\\ne x p e r i m e n t i n g\\nw i t h\\nm o r e\\no p e n - e n d e d\\np r o m p t s ,\\nl e v e r a g i n g\\nm u l t i - m o d a l\\nA I\\nm o d e l s ,\\no r\\nc o m b i n i n g\\nt h e\\no u t p u t s\\no f\\nm u l t i p l e\\nA I\\nm o d e l s\\nt o\\ng e n e r a t e\\nm o r e\\nc r e a t i v e\\na n d\\ne n g a g i n g\\nc o n t e n t .\\nA d d r e s s i n g\\nE t h i c a l\\nC o n c e r n s\\nP r o m p t\\ne n g i n e e r i n g\\nr a i s e s\\ne t h i c a l\\nq u e s t i o n s\\na n d\\nc h a l l e n g e s ,\\ns u c h\\na s\\nf a i r n e s s ,\\ni n c l u s i v i t y ,\\na n d\\nr e s p o n s i b i l i t y .\\nT o\\na d d r e s s\\nt h e s e\\nc o n c e r n s ,\\ne n s u r e\\nt h a t\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l s\\na d h e r e\\nt o\\ne t h i c a l\\ng u i d e l i n e s\\na n d\\nr e s p o n s i b l e\\nA I\\np r a c t i c e s ,\\na n d\\ns t r i v e\\nt o\\nc r e a t e\\nc o n t e n t\\nt h a t\\ni s\\nf a i r ,\\ni n c l u s i v e ,\\na n d\\nr e s p e c t f u l .\\nB y\\nu n d e r s t a n d i n g\\na n d\\na d d r e s s i n g\\nt h e s e\\nc o m m o n\\nc h a l l e n g e s\\ni n\\np r o m p t\\ne n g i n e e r i n g ,\\ny o u\\nc a n\\nc r e a t e\\nm o r e\\ne \\x00 e c t i v e ,\\ne n g a g i n g ,\\na n d\\nh i g h - q u a l i t y\\nA I - g e n e r a t e d\\nc o n t e n t .\\nA s\\ny o u\\nc o n t i n u e\\nt o\\nr e ﬁ n e\\ny o u r\\ns k i l l s\\na n d\\no v e r c o m e\\nt h e s e\\nc h a l l e n g e s ,\\ny o u ' l l\\nb e\\nb e t t e r\\ne q u i p p e d\\nt o\\nh a r n e s s\\nt h e\\nf u l l\\np o t e n t i a l\\no f\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nd r i v e\\ni n n o v a t i o n\\ni n\\nt h e\\nr a p i d l y\\ne v o l v i n g\\nﬁ e l d\\no f\\ng e n e r a t i v e\\nA I .\\n6 . 4 .\\nM e a s u r i n g\\nt h e\\nS u c c e s s\\no f\\nY o u r\\nP r o m p t\\nE n g i n e e r i n g\\nE \\x00 o r t s\\nT o\\ne n s u r e\\nt h a t\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s\\na r e\\ns u c c e s s f u l ,\\ni t ' s\\nc r u c i a l\\nt o\\ne s t a b l i s h\\nc l e a r\\nm e t r i c s\\na n d\\nb e n c h m a r k s\\nf o r\\ne v a l u a t i n g\\nt h e\\np e r f o r m a n c e\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t .\\nI n\\nt h i s\\ns e c t i o n ,\\nw e ' l l\\nd i s c u s s\\ns o m e\\nk e y\\np e r f o r m a n c e\\ni n d i c a t o r s\\n( K P I s )\\na n d\\nb e s t\\np r a c t i c e s\\nf o r\\nm e a s u r i n g\\nt h e\\ns u c c e s s\\no f\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s .\\nC o n t e n t\\nQ u a l i t y\\nM e t r i c s\\nA s s e s s\\nt h e\\nq u a l i t y\\no f\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nc o n s i d e r i n g\\nf a c t o r s\\ns u c h\\na s\\nc o h e r e n c e ,\\nc o n s i s t e n c y ,\\ng r a m m a t i c a l\\nc o r r e c t n e s s ,\\na n d\\nr e a d a b i l i t y .\\nU t i l i z e\\nt o o l s\\nl i k e\\nr e a d a b i l i t y\\ns c o r e s ,\\ng r a m m a r\\nc h e c k e r s ,\\no r\\nh u m a n\\ne v a l u a t i o n\\nt o\\ne n s u r e\\nt h a t\\ny o u r\\nc o n t e n t\\nm e e t s\\ny o u r\\nq u a l i t y\\ns t a n d a r d s .\\n3 4\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 34}\n",
      "page_content=\"C o n t e n t\\nR e l e v a n c e\\nM e t r i c s\\nE v a l u a t e\\nt h e\\nr e l e v a n c e\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nd e t e r m i n i n g\\nh o w\\nw e l l\\ni t\\na l i g n s\\nw i t h\\ny o u r\\no b j e c t i v e s ,\\nt a r g e t\\na u d i e n c e ,\\na n d\\ni n t e n d e d\\np u r p o s e .\\nU s e\\na\\nc o m b i n a t i o n\\no f\\nq u a l i t a t i v e\\na s s e s s m e n t s ,\\nu s e r\\nf e e d b a c k ,\\na n d\\nc o n t e n t\\ne n g a g e m e n t\\nm e t r i c s\\n( e . g . ,\\nc l i c k - t h r o u g h\\nr a t e s ,\\nc o n v e r s i o n s ,\\no r\\nt i m e\\ns p e n t )\\nt o\\ng a u g e\\nr e l e v a n c e .\\nC o n t e n t\\nN o v e l t y\\na n d\\nC r e a t i v i t y\\nM e t r i c s\\nM e a s u r e\\nt h e\\nn o v e l t y\\na n d\\nc r e a t i v i t y\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nc o n s i d e r i n g\\nf a c t o r s\\ns u c h\\na s\\nu n i q u e n e s s ,\\no r i g i n a l i t y ,\\na n d\\nu n e x p e c t e d n e s s .\\nY o u\\nc a n\\nu s e\\nt o o l s\\nl i k e\\np l a g i a r i s m\\nc h e c k e r s ,\\ns i m i l a r i t y\\ns c o r e s ,\\no r\\nh u m a n\\ne v a l u a t i o n\\nt o\\na s s e s s\\nt h e\\nn o v e l t y\\na n d\\nc r e a t i v i t y\\no f\\ny o u r\\nc o n t e n t .\\nC o n t e n t\\nA c c u r a c y\\nM e t r i c s\\nE v a l u a t e\\nt h e\\na c c u r a c y\\no f\\nt h e\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nc o m p a r i n g\\ni t\\nt o\\nr e l i a b l e\\ns o u r c e s ,\\ng r o u n d\\nt r u t h ,\\no r\\ne x p e r t\\nk n o w l e d g e .\\nU s e\\na\\nc o m b i n a t i o n\\no f\\nq u a n t i t a t i v e\\nm e t r i c s\\n( e . g . ,\\nf a c t - c h e c k i n g\\ns c o r e s )\\na n d\\nq u a l i t a t i v e\\na s s e s s m e n t s\\nt o\\ne n s u r e\\ny o u r\\nc o n t e n t\\ni s\\na c c u r a t e\\na n d\\nt r u s t w o r t h y .\\nU s e r\\nS a t i s f a c t i o n\\nM e t r i c s\\nA s s e s s\\nu s e r\\ns a t i s f a c t i o n\\nw i t h\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nc o l l e c t i n g\\nf e e d b a c k\\nt h r o u g h\\ns u r v e y s ,\\nr a t i n g s ,\\no r\\nc o m m e n t s .\\nA n a l y z e\\nt h i s\\nf e e d b a c k\\nt o\\ni d e n t i f y\\na r e a s\\nf o r\\ni m p r o v e m e n t\\na n d\\nr e ﬁ n e\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l\\na c c o r d i n g l y .\\nE f f i c i e n c y\\nM e t r i c s\\nE v a l u a t e\\nt h e\\ne \\x00 c i e n c y\\no f\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s\\nb y\\nc o n s i d e r i n g\\nf a c t o r s\\ns u c h\\na s\\nt h e\\nt i m e\\nt a k e n\\nt o\\ng e n e r a t e\\nc o n t e n t ,\\nt h e\\nn u m b e r\\no f\\ni t e r a t i o n s\\nr e q u i r e d ,\\na n d\\nt h e\\nc o s t\\no f\\nA I\\nm o d e l\\nu s a g e .\\nU s e\\nt h e s e\\nm e t r i c s\\nt o\\no p t i m i z e\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\nw o r k ﬂ o w\\na n d\\ne n s u r e\\nt h a t\\ny o u ' r e\\ng e n e r a t i n g\\nh i g h - q u a l i t y\\nc o n t e n t\\ni n\\na\\nc o s t - e \\x00 e c t i v e\\na n d\\nt i m e l y\\nm a n n e r .\\nA d a p t a b i l i t y\\nM e t r i c s\\nA s s e s s\\nt h e\\na d a p t a b i l i t y\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\nb y\\nc o n s i d e r i n g\\nh o w\\nw e l l\\ni t\\nc a n\\nb e\\nr e p u r p o s e d\\no r\\nr e u s e d\\na c r o s s\\nd i \\x00 e r e n t\\nc h a n n e l s ,\\nf o r m a t s ,\\no r\\nc o n t e x t s .\\nT r a c k\\nt h e\\np e r f o r m a n c e\\no f\\ny o u r\\nc o n t e n t\\na c r o s s\\nv a r i o u s\\na p p l i c a t i o n s\\nt o\\ng a u g e\\ni t s\\nv e r s a t i l i t y\\na n d\\na d a p t a b i l i t y .\\nB y\\ne s t a b l i s h i n g\\nc l e a r\\nK P I s\\na n d\\nb e n c h m a r k s\\nf o r\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s ,\\ny o u\\nc a n\\ne \\x00 e c t i v e l y\\nm e a s u r e\\nt h e\\ns u c c e s s\\no f\\ny o u r\\nA I - g e n e r a t e d\\nc o n t e n t\\na n d\\ne n s u r e\\nt h a t\\ni t\\nm e e t s\\ny o u r\\nq u a l i t y ,\\nr e l e v a n c e ,\\na n d\\np e r f o r m a n c e\\nc r i t e r i a .\\nT h i s\\nd a t a - d r i v e n\\na p p r o a c h\\nn o t\\no n l y\\nh e l p s\\ny o u\\n3 5\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 35}\n",
      "page_content='o p t i m i z e\\ny o u r\\np r o m p t s\\na n d\\nA I\\nm o d e l\\nb u t\\na l s o\\ne n a b l e s\\ny o u\\nt o\\nc o n t i n u o u s l y\\ni m p r o v e\\ny o u r\\np r o m p t\\ne n g i n e e r i n g\\ns k i l l s\\na n d\\nd r i v e\\ni n n o v a t i o n\\ni n\\nt h e\\nr a p i d l y\\ne v o l v i n g\\nﬁ e l d\\no f\\ng e n e r a t i v e\\nA I .\\n3 6\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 36}\n",
      "page_content=\"C o n c l u s i o n\\nI n\\nt h i s\\ns h o r t\\ne b o o k ,\\nw e\\nh a v e\\ne x p l o r e d\\nt h e\\nf a s c i n a t i n g\\nw o r l d\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g ,\\nd e l v i n g\\ni n t o\\nk e y\\nc o n c e p t s ,\\nb e s t\\np r a c t i c e s ,\\na n d\\np o t e n t i a l\\nf u t u r e\\nt r e n d s\\ni n\\nt h i s\\nr a p i d l y\\ne v o l v i n g\\nﬁ e l d .\\nA s\\nA I\\nt e c h n o l o g i e s\\nc o n t i n u e\\nt o\\na d v a n c e\\na n d\\nr e s h a p e\\nv a r i o u s\\na s p e c t s\\no f\\no u r\\nl i v e s ,\\nt h e\\nr o l e\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni n\\ne n h a n c i n g\\nt h e\\nq u a l i t y ,\\nr e l e v a n c e ,\\na n d\\nc r e a t i v i t y\\no f\\nA I - g e n e r a t e d\\nc o n t e n t\\nw i l l\\ng r o w\\ni n c r e a s i n g l y\\ns i g n i ﬁ c a n t .\\nR e c a p\\no f\\nk e y\\nc o n c e p t s\\na n d\\nb e s t\\np r a c t i c e s :\\n●\\nW e\\nh a v e\\nc o v e r e d\\nt h e\\nf u n d a m e n t a l s\\no f\\ng e n e r a t i v e\\nA I\\na n d\\nt h e\\ni m p o r t a n c e\\no f\\np r o m p t\\ne n g i n e e r i n g\\ni n\\ng u i d i n g\\nA I\\nm o d e l s\\nt o\\np r o d u c e\\nh i g h - q u a l i t y\\nc o n t e n t\\n●\\nW e\\nh a v e\\nd i s c u s s e d\\nd i \\x00 e r e n t\\nt y p e s\\no f\\np r o m p t s ,\\nt e c h n i q u e s\\nf o r\\np r o m p t\\ne n g i n e e r i n g ,\\na n d\\np r a c t i c a l\\nt i p s\\nt o\\nc r e a t e\\na n\\ne \\x00 e c t i v e\\np r o m p t\\ne n g i n e e r i n g\\nw o r k ﬂ o w\\n●\\nW e\\nh a v e\\ne x a m i n e d\\nc o m m o n\\nc h a l l e n g e s\\na n d\\ne t h i c a l\\nc o n s i d e r a t i o n s ,\\na s\\nw e l l\\na s\\nv a r i o u s\\nm e t r i c s\\nf o r\\nm e a s u r i n g\\nt h e\\ns u c c e s s\\no f\\np r o m p t\\ne n g i n e e r i n g\\ne \\x00 o r t s\\nF u t u r e\\nt r e n d s\\ni n\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g :\\n●\\nA s\\ng e n e r a t i v e\\nA I\\nm o d e l s\\nb e c o m e\\nm o r e\\ns o p h i s t i c a t e d\\na n d\\nc a p a b l e ,\\np r o m p t\\ne n g i n e e r i n g\\nw i l l\\nc o n t i n u e\\nt o\\ne v o l v e ,\\nu n l o c k i n g\\nn e w\\np o s s i b i l i t i e s\\na n d\\na p p l i c a t i o n s\\na c r o s s\\nd i v e r s e\\ns e c t o r s\\n●\\nF r o m\\ne n h a n c i n g\\nb u s i n e s s\\nc o m m u n i c a t i o n s\\na n d\\np e r s o n a l i z i n g\\nc u s t o m e r\\ne x p e r i e n c e s\\nt o\\nf o s t e r i n g\\nc r e a t i v i t y\\na n d\\na d d r e s s i n g\\ng l o b a l\\nc h a l l e n g e s ,\\np r o m p t\\ne n g i n e e r i n g\\nw i l l\\np l a y\\na\\nc r i t i c a l\\nr o l e\\ni n\\nl e v e r a g i n g\\nA I - g e n e r a t e d\\nc o n t e n t\\nt o\\nd r i v e\\np r o g r e s s\\na n d\\ni n n o v a t i o n\\nI n\\nc o n c l u s i o n ,\\nw e\\ne n c o u r a g e\\ny o u ,\\nt h e\\nr e a d e r ,\\nt o\\ne x p e r i m e n t\\nw i t h\\na n d\\ni n n o v a t e\\ni n\\nt h e\\nr e a l m\\no f\\np r o m p t\\ne n g i n e e r i n g .\\nA s\\ny o u\\nd e l v e\\nd e e p e r\\ni n t o\\nt h i s\\nﬁ e l d ,\\nh a r n e s s\\ny o u r\\nc r e a t i v i t y ,\\nc o l l a b o r a t e\\nw i t h\\no t h e r s ,\\na n d\\np u s h\\nt h e\\nb o u n d a r i e s\\no f\\nw h a t ' s\\np o s s i b l e .\\nB y\\nd o i n g\\ns o ,\\ny o u\\nw i l l\\nn o t\\no n l y\\nc o n t r i b u t e\\nt o\\nt h e\\na d v a n c e m e n t\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g\\nb u t\\na l s o\\nc r e a t e\\na\\nm o r e\\np r o s p e r o u s ,\\ne q u i t a b l e ,\\na n d\\ns u s t a i n a b l e\\nf u t u r e\\nf o r\\na l l .\\nA r m e d\\nw i t h\\nt h e\\nk n o w l e d g e\\na n d\\ni n s i g h t s\\ns h a r e d\\ni n\\nt h i s\\ne b o o k ,\\nw e\\nh o p e\\ny o u\\na r e\\ni n s p i r e d\\nt o\\ne x p l o r e\\nt h e\\ni n c r e d i b l e\\np o t e n t i a l\\no f\\np r o m p t\\ne n g i n e e r i n g\\na n d\\nu n l o c k\\nn e w\\no p p o r t u n i t i e s\\nf o r\\ni n n o v a t i o n\\na n d\\ng r o w t h\\ni n\\nt h e\\ne v e r - e x p a n d i n g\\nw o r l d\\no f\\ng e n e r a t i v e\\nA I .\\n3 7\\n\" metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 37}\n",
      "page_content='A p p e n d i x\\nA :\\nR e c o m m e n d e d\\nB o o k s ,\\nA r t i c l e s ,\\na n d\\nB l o g s\\nT o\\nf u r t h e r\\ne x p a n d\\ny o u r\\nk n o w l e d g e\\na n d\\nu n d e r s t a n d i n g\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g ,\\nw e\\nh a v e\\nc o m p i l e d\\na\\nl i s t\\no f\\nr e c o m m e n d e d\\nb o o k s ,\\na r t i c l e s ,\\na n d\\nc o u r s e s\\nt h a t\\nc a n\\np r o v i d e\\na d d i t i o n a l\\ni n s i g h t s ,\\np r a c t i c a l\\ne x a m p l e s ,\\na n d\\ng u i d a n c e .\\nB o o k s :\\n●\\n\" D e e p\\nL e a r n i n g \"\\nb y\\nI a n\\nG o o d f e l l o w ,\\nY o s h u a\\nB e n g i o ,\\na n d\\nA a r o n\\nC o u r v i l l e\\n●\\n\" G e n e r a t i v e\\nD e e p\\nL e a r n i n g :\\nT e a c h i n g\\nM a c h i n e s\\nt o\\nP a i n t ,\\nW r i t e ,\\nC o m p o s e ,\\na n d\\nP l a y \"\\nb y\\nD a v i d\\nF o s t e r\\n●\\n\" H a n d s - O n\\nM a c h i n e\\nL e a r n i n g\\nw i t h\\nS c i k i t - L e a r n ,\\nK e r a s\\na n d\\nT e n s o r F l o w \"\\nb y\\nA u r é l i e n\\nG é r o n\\n●\\n\" P a t t e r n\\nR e c o g n i t i o n\\na n d\\nM a c h i n e\\nL e a r n i n g \"\\nb y\\nC h r i s t o p h e r\\nM .\\nB i s h o p\\n●\\n\" H u m a n\\nC o m p a t i b l e :\\nA r t i ﬁ c i a l\\nI n t e l l i g e n c e\\na n d\\nt h e\\nP r o b l e m\\no f\\nC o n t r o l \"\\nb y\\nS t u a r t\\nR u s s e l l\\nA r t i c l e s :\\n●\\n\" T h e\\nI l l u s t r a t e d\\nG P T - 2\\n( V i s u a l i z i n g\\nT r a n s f o r m e r\\nL a n g u a g e\\nM o d e l s ) \"\\nb y\\nJ a y\\nA l a m m a r\\n●\\n\" T h e\\nA n n o t a t e d\\nG P T - 3 \"\\nb y\\nJ o n a t h a n\\nH u i\\n●\\n\" B e t t e r\\nL a n g u a g e\\nM o d e l s\\na n d\\nT h e i r\\nI m p l i c a t i o n s \"\\nb y\\nO p e n A I\\n●\\n\" L a n g u a g e\\nM o d e l s\\na r e\\nF e w - S h o t\\nL e a r n e r s \"\\nb y\\nO p e n A I\\n●\\n\" B u i l d i n g\\nA I\\nA p p l i c a t i o n s\\nw i t h\\nO p e n A I \\' s\\nG P T - 3 :\\nA\\nP r a c t i c a l\\nG u i d e \"\\nb y\\nH a r r i s o n\\nK i n s l e y\\nO n l i n e\\nC o u r s e s :\\n●\\nC o u r s e r a :\\n\" D e e p\\nL e a r n i n g\\nS p e c i a l i z a t i o n \"\\nb y\\nA n d r e w\\nN g\\n●\\nC o u r s e r a :\\n\" N a t u r a l\\nL a n g u a g e\\nP r o c e s s i n g\\nS p e c i a l i z a t i o n \"\\nb y\\nN a t i o n a l\\nR e s e a r c h\\nU n i v e r s i t y\\nH i g h e r\\nS c h o o l\\no f\\nE c o n o m i c s\\n●\\nf a s t . a i :\\n\" P r a c t i c a l\\nD e e p\\nL e a r n i n g\\nf o r\\nC o d e r s \"\\n●\\ne d X :\\n\" C S 2 2 4 N :\\nN a t u r a l\\nL a n g u a g e\\nP r o c e s s i n g\\nw i t h\\nD e e p\\nL e a r n i n g \"\\nb y\\nS t a n f o r d\\n●\\nM I T\\nO p e n C o u r s e W a r e :\\n\" 6 . S 1 9 1 :\\nI n t r o d u c t i o n\\nt o\\nD e e p\\nL e a r n i n g \"\\nb y\\nM I T\\nO n l i n e\\nR e s o u r c e s\\na n d\\nB l o g s :\\n●\\nO p e n A I\\nB l o g\\n(\\nh t t p s : / / o p e n a i . c o m / b l o g /\\n)\\n●\\nG o o g l e\\nA I\\nB l o g\\n(\\nh t t p s : / / a i . g o o g l e b l o g . c o m /\\n)\\n●\\nD i s t i l l\\n(\\nh t t p s : / / d i s t i l l . p u b /\\n)\\n●\\nM a c h i n e\\nL e a r n i n g\\nM a s t e r y\\n(\\nh t t p s : / / m a c h i n e l e a r n i n g m a s t e r y . c o m /\\n)\\n3 8\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 38}\n",
      "page_content='T h e s e\\nr e s o u r c e s\\nw i l l\\nh e l p\\ny o u\\nd e e p e n\\ny o u r\\nu n d e r s t a n d i n g\\no f\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g ,\\ns t a y\\nu p d a t e d\\no n\\nt h e\\nl a t e s t\\na d v a n c e m e n t s\\na n d\\nb r e a k t h r o u g h s\\ni n\\nt h e\\nﬁ e l d ,\\na n d\\ne n h a n c e\\ny o u r\\ns k i l l s\\na n d\\ne x p e r t i s e .\\nB y\\nc o n t i n u a l l y\\nl e a r n i n g ,\\ne x p e r i m e n t i n g ,\\na n d\\nc o l l a b o r a t i n g ,\\ny o u\\nw i l l\\nb e\\nw e l l - e q u i p p e d\\nt o\\nt h r i v e\\ni n\\nt h e\\ne x c i t i n g\\na n d\\nr a p i d l y\\ne v o l v i n g\\nw o r l d\\no f\\ng e n e r a t i v e\\nA I .\\n3 9\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 39}\n",
      "page_content='A p p e n d i x\\nB :\\nO n l i n e\\nC o m m u n i t i e s\\na n d\\nF o r u m s\\nf o r\\nD i s c u s s i o n s\\na n d\\nC o l l a b o r a t i o n\\nE n g a g i n g\\nw i t h\\no n l i n e\\nc o m m u n i t i e s\\na n d\\nf o r u m s\\ni s\\na n\\ne x c e l l e n t\\nw a y\\nt o\\nl e a r n ,\\ns h a r e\\ni d e a s ,\\na n d\\nc o l l a b o r a t e\\nw i t h\\no t h e r s\\nw h o\\na r e\\ni n t e r e s t e d\\ni n\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g .\\nH e r e\\ni s\\na\\nl i s t\\no f\\np o p u l a r\\no n l i n e\\np l a t f o r m s\\nw h e r e\\ny o u\\nc a n\\nd i s c u s s ,\\na s k\\nq u e s t i o n s ,\\na n d\\nc o n n e c t\\nw i t h\\nl i k e - m i n d e d\\ni n d i v i d u a l s\\na n d\\ne x p e r t s\\ni n\\nt h e\\nﬁ e l d .\\nA I\\nS t a c k\\nE x c h a n g e\\n(\\nh t t p s : / / a i . s t a c k e x c h a n g e . c o m /\\n)\\nA\\nq u e s t i o n\\na n d\\na n s w e r\\np l a t f o r m\\nf o r\\np e o p l e\\ni n t e r e s t e d\\ni n\\nA I\\nc o n c e p t s ,\\nr e s e a r c h ,\\na n d\\na p p l i c a t i o n s .\\nA s k\\nq u e s t i o n s ,\\np r o v i d e\\na n s w e r s ,\\no r\\nb r o w s e\\nt h r o u g h\\ne x i s t i n g\\nd i s c u s s i o n s\\nt o\\ne n h a n c e\\ny o u r\\nk n o w l e d g e .\\nM a c h i n e\\nL e a r n i n g\\nS u b r e d d i t\\n(\\nh t t p s : / / w w w . r e d d i t . c o m / r / M a c h i n e L e a r n i n g /\\n)\\nA\\np o p u l a r\\ns u b r e d d i t\\nf o r\\nd i s c u s s i n g\\nt o p i c s\\nr e l a t e d\\nt o\\nm a c h i n e\\nl e a r n i n g ,\\nd e e p\\nl e a r n i n g ,\\na n d\\ng e n e r a t i v e\\nA I .\\nS h a r e\\ny o u r\\np r o j e c t s ,\\na s k\\nq u e s t i o n s ,\\na n d\\ne n g a g e\\nw i t h\\na\\nd i v e r s e\\nc o m m u n i t y\\no f\\nl e a r n e r s ,\\nr e s e a r c h e r s ,\\na n d\\np r o f e s s i o n a l s .\\nA I\\ns e c t i o n\\no n\\na r X i v\\n(\\nh t t p s : / / a r x i v . o r g / l i s t / c s . A I / r e c e n t\\n)\\nA\\nr e p o s i t o r y\\no f\\np r e p r i n t s\\nf o r\\nA I\\nr e s e a r c h\\np a p e r s .\\nB r o w s e\\nt h e\\nl a t e s t\\nr e s e a r c h ,\\np r o v i d e\\nf e e d b a c k ,\\na n d\\ne n g a g e\\ni n\\nd i s c u s s i o n s\\nw i t h\\no t h e r\\nr e s e a r c h e r s\\na n d\\np r a c t i t i o n e r s .\\nD e e p\\nL e a r n i n g\\nS u b r e d d i t\\n(\\nh t t p s : / / w w w . r e d d i t . c o m / r / d e e p l e a r n i n g /\\n)\\nA\\ns u b r e d d i t\\nd e d i c a t e d\\nt o\\nd e e p\\nl e a r n i n g\\na n d\\ni t s\\na p p l i c a t i o n s ,\\ni n c l u d i n g\\ng e n e r a t i v e\\nA I .\\nS h a r e\\nr e s o u r c e s ,\\na s k\\nq u e s t i o n s ,\\na n d\\nc o l l a b o r a t e\\nw i t h\\na\\nv i b r a n t\\nc o m m u n i t y\\no f\\ne n t h u s i a s t s\\na n d\\np r o f e s s i o n a l s .\\nO p e n A I\\nC o m m u n i t y\\n(\\nh t t p s : / / c o m m u n i t y . o p e n a i . c o m /\\n)\\nA n\\no \\x00 c i a l\\nf o r u m\\nf o r\\nO p e n A I ,\\nw h e r e\\nu s e r s\\nc a n\\nd i s c u s s\\nv a r i o u s\\nt o p i c s\\nr e l a t e d\\nt o\\nA I\\nr e s e a r c h\\na n d\\na p p l i c a t i o n s ,\\ni n c l u d i n g\\nG P T\\nm o d e l s\\na n d\\np r o m p t\\ne n g i n e e r i n g .\\nC o n n e c t\\nw i t h\\no t h e r\\nA I\\ne n t h u s i a s t s ,\\ns h a r e\\ny o u r\\np r o j e c t s ,\\na n d\\nl e a r n\\nf r o m\\ne x p e r t s .\\nD a t a\\nS c i e n c e\\nS t a c k\\nE x c h a n g e\\n(\\nh t t p s : / / d a t a s c i e n c e . s t a c k e x c h a n g e . c o m /\\n)\\nA\\nq u e s t i o n\\na n d\\na n s w e r\\np l a t f o r m\\nf o r\\nd a t a\\ns c i e n c e\\np r o f e s s i o n a l s ,\\nr e s e a r c h e r s ,\\na n d\\ne n t h u s i a s t s .\\nA s k\\nq u e s t i o n s ,\\np r o v i d e\\na n s w e r s ,\\no r\\nb r o w s e\\nt h r o u g h\\ne x i s t i n g\\nd i s c u s s i o n s\\nt o\\nd e e p e n\\ny o u r\\nu n d e r s t a n d i n g\\no f\\nd a t a\\ns c i e n c e ,\\nm a c h i n e\\nl e a r n i n g ,\\na n d\\nA I .\\n4 0\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 40}\n",
      "page_content='B y\\np a r t i c i p a t i n g\\ni n\\nt h e s e\\no n l i n e\\nc o m m u n i t i e s\\na n d\\nf o r u m s ,\\ny o u\\nc a n\\ne x p a n d\\ny o u r\\nn e t w o r k ,\\ns h a r e\\ny o u r\\nk n o w l e d g e ,\\na n d\\nc o l l a b o r a t e\\nw i t h\\no t h e r s\\nw h o\\ns h a r e\\ny o u r\\np a s s i o n\\nf o r\\ng e n e r a t i v e\\nA I\\na n d\\np r o m p t\\ne n g i n e e r i n g .\\nT h e s e\\np l a t f o r m s\\np r o v i d e\\ni n v a l u a b l e\\no p p o r t u n i t i e s\\nt o\\nl e a r n\\nf r o m\\ne x p e r t s ,\\ns t a y\\nu p d a t e d\\no n\\nt h e\\nl a t e s t\\na d v a n c e m e n t s ,\\na n d\\nc o n t r i b u t e\\nt o\\nt h e\\ng r o w t h\\na n d\\ni n n o v a t i o n\\no f\\nt h e\\nﬁ e l d .\\n4 1\\n' metadata={'source': 'pdf/Master Prompt Engineering.pdf', 'page': 41}\n",
      "page_content='Tree of Thoughts: Deliberate Problem Solving\\nwith Large Language Models\\nShunyu Yao\\nPrinceton UniversityDian Yu\\nGoogle DeepMindJeffrey Zhao\\nGoogle DeepMindIzhak Shafran\\nGoogle DeepMind\\nThomas L. Grifﬁths\\nPrinceton UniversityYuan Cao\\nGoogle DeepMindKarthik Narasimhan\\nPrinceton University\\nAbstract\\nLanguage models are increasingly being deployed for general problem solving\\nacross a wide range of tasks, but are still conﬁned to token-level, left-to-right\\ndecision-making processes during inference. This means they can fall short in\\ntasks that require exploration, strategic lookahead, or where initial decisions play\\na pivotal role. To surmount these challenges, we introduce a new framework for\\nlanguage model inference, “Tree of Thoughts” (ToT), which generalizes over the\\npopular “Chain of Thought” approach to prompting language models, and enables\\nexploration over coherent units of text (“thoughts”) that serve as intermediate steps\\ntoward problem solving. ToT allows LMs to perform deliberate decision making\\nby considering multiple different reasoning paths and self-evaluating choices to\\ndecide the next course of action, as well as looking ahead or backtracking when\\nnecessary to make global choices. Our experiments show that ToT signiﬁcantly\\nenhances language models’ problem-solving abilities on three novel tasks requiring\\nnon-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.\\nFor instance, in Game of 24, while GPT-4 with chain-of-thought prompting only\\nsolved 4% of tasks, our method achieved a success rate of 74%. Code repo with all\\nprompts: https://github.com/ysymyth/tree-of-thought-llm .\\n1 Introduction\\nOriginally designed to generate text, scaled-up versions of language models (LMs) such as GPT [ 22,\\n23,1,20] and PaLM [ 5] have been shown to be increasingly capable of performing an ever wider\\nrange of tasks requiring mathematical, symbolic, commonsense, and knowledge reasoning. It is\\nperhaps surprising that underlying all this progress is still the original autoregressive mechanism for\\ngenerating text, which makes token-level decisions one by one and in a left-to-right fashion. Is such\\na simple mechanism sufﬁcient for a LM to be built toward a general problem solver? If not, what\\nproblems would challenge the current paradigm, and what should be alternative mechanisms?\\nThe literature on human cognition provides some clues to answer these questions. Research on “dual\\nprocess” models suggests that people have two modes in which they engage with decisions – a fast,\\nautomatic, unconscious mode (“System 1”) and a slow, deliberate, conscious mode (“System 2”)\\n[27,28,13,12]. These two modes have previously been connected to a variety of mathematical\\nmodels used in machine learning. For example, research on reinforcement learning in humans and\\nother animals has explored the circumstances under which they engage in associative “model free”\\nlearning or more deliberative “model based” planning [ 6]. The simple associative token-level choices\\nof LMs are also reminiscent of “System 1”, and thus might beneﬁt from augmentation by a more\\ndeliberate “System 2” planning process that (1) maintains and explores diverse alternatives for current\\nPreprint. Under review.arXiv:2305.10601v1  [cs.CL]  17 May 2023' metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 0}\n",
      "page_content='GĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜʱÊʲˤGjʱæʲˤ\\x1dĵÉGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x1dĵÉˁ\\x92\\x1dʟʟʟʟaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉĵÉˤʱĵũŗŝʲʟʟʟʟʟʟˤˤʝˤƛĎĵũĈĎƜ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0c0DUN\\x03GLIIHUHQFH\\x03E\\\\\\x03FRORU\\nGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\njũƜŔũƜGĮŔũƜ\\nˤjũƜŔũƜʱçʲˤ\\x92òĦƙˤ\\x1dĵĮŝƓŝŤòĮçƆˤƀƓƜĎˤ\\x1dĵÉˤʱ\\x1dĵÉˁ\\x92\\x1dʲaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\\nˤjũƜŔũƜʱíʲˤÉŗòòˤĵƙˤ\\x9aĎĵũĈĎŤŝˤʱÉĵÉʲʟʟʟʟʟʟʟʟʟʟˤˤƛĎĵũĈĎƜ\\nʱçʲˤ\\x1dĎÊđĮˤĵƙˤ\\x9aĎĵũĈĎƜˤ\\x89ŗĵĭŔƜđĮĈˤʱ\\x1dĵÉʲʱÊʲˤGĮŔũƜˁjũƜŔũƜˤ\\x89ŗĵĭŔƜđĮĈˤʱGjʲFigure 1: Schematic illustrating various approaches to problem solving with LLMs. Each rectangle\\nbox represents a thought , which is a coherent language sequence that serves as an intermediate\\nstep toward problem solving. See concrete examples of how thoughts are generated, evaluated, and\\nsearched in Figures 2,4,6.\\nchoices instead of just picking one, and (2) evaluates its current status and actively looks ahead or\\nbacktracks to make more global decisions.\\nTo design such a planning process, we return to the origins of artiﬁcial intelligence (and cognitive\\nscience), drawing inspiration from the planning processes explored by Newell, Shaw, and Simon\\nstarting in the 1950s [ 18,19]. Newell and colleagues characterized problem solving [ 18] as search\\nthrough a combinatorial problem space, represented as a tree. We thus propose the Tree of Thoughts\\n(ToT) framework for general problem solving with language models. As Figure 1 illustrates, while\\nexisting methods (detailed below) sample continuous language sequences for problem solving, ToT\\nactively maintains a tree of thoughts, where each thought is a coherent language sequence that serves\\nas an intermediate step toward problem solving (Table 1). Such a high-level semantic unit allows the\\nLM to self-evaluate the progress different intermediate thoughts make towards solving the problem\\nthrough a deliberate reasoning process that is also instantiated in language (Figures 2,4,6). This\\nimplementation of search heuristics via LM self-evaluation and deliberation is novel, as previous\\nsearch heuristics are either programmed or learned. Finally, we combine this language-based\\ncapability to generate and evaluate diverse thoughts with search algorithms, such as breadth-ﬁrst\\nsearch (BFS) or depth-ﬁrst search (DFS), which allow systematic exploration of the tree of thoughts\\nwith lookahead and backtracking.\\nEmpirically, we propose three new problems that challenge existing LM inference methods even with\\nthe state-of-the-art language model, GPT-4 [ 20]: Game of 24, Creative Writing, and Crosswords\\n(Table 1). These tasks require deductive, mathematical, commonsense, lexical reasoning abilities,\\nand a way to incorporate systematic planning or search. We show ToT obtains superior results on\\nall three tasks by being general and ﬂexible enough to support different levels of thoughts, different\\nways to generate and evaluate thoughts, and different search algorithms that adapt to the nature of\\ndifferent problems. We also analyze how such choices affect model performances via systematic\\nablations and discuss future directions to better train and use LMs.\\n2 Background\\nWe ﬁrst formalize some existing methods that use large language models for problem-solving,\\nwhich our approach is inspired by and later compared with. We use pθto denote a pre-trained LM\\nwith parameters θ, and lowercase letters x,y,z,s,···to denote a language sequence , i.e.x=\\n(x[1],···,x[n])where eachx[i]is a token, so that pθ(x) =∏n\\ni=1pθ(x[i]|x[1...i]). We use uppercase\\nlettersS,···to denote a collection of language sequences.\\nInput-output (IO) prompting is the most common way to turn a problem input xinto outputywith\\nLM:y∼pθ(y|promptIO(x)), where promptIO(x)wraps inputxwith task instructions and/or few-\\nshot input-output examples. For simplicity, let us denote pprompt\\nθ(output|input ) =pθ(output|\\nprompt (input )), so that IO prompting can be formulated as y∼pIO\\nθ(y|x).\\n2' metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 1}\n",
      "page_content='Chain-of-thought (CoT) prompting [35] was proposed to address cases where the mapping of\\ninputxto outputyis non-trivial (e.g. when xis a math question and yis the ﬁnal numerical answer).\\nThe key idea is to introduce a chain of thoughtsz1,···,znto bridgexandy, where each ziis a\\ncoherent language sequence that serves as a meaningful intermediate step toward problem solving\\n(e.g.zicould be an intermediate equation for math QA). To solve problems with CoT, each thought\\nzi∼pCoT\\nθ(zi|x,z1···i−1)is sampled sequentially, then the output y∼pCoT\\nθ(y|x,z1···n). In\\npractice, [z1···n,y]∼pCoT\\nθ(z1···n,y|x)is sampled as a continuous language sequence, and the\\ndecomposition of thoughts (e.g. is each zia phrase, a sentence, or a paragraph) is left ambiguous.\\nSelf-consistency with CoT (CoT-SC) [33] is an ensemble approach that samples ki.i.d. chains\\nof thought: [z(i)\\n1···n,y(i)]∼pCoT\\nθ(z1···n,y|x) (i= 1···k), then returns the most frequent output:\\narg maxy#{i|y(i)=y}. CoT-SC improves upon CoT, because there are generally different\\nthought processes for the same problem (e.g. different ways to prove the same theorem), and the\\noutput decision can be more faithful by exploring a richer set of thoughts. However, within each\\nchain there is no local exploration of different thought steps, and the “most frequent” heuristic only\\napplies when the output space is limited (e.g. multi-choice QA).\\n3 Tree of Thoughts: Deliberate Problem Solving with LM\\nA genuine problem-solving process involves the repeated use of available informa-\\ntion to initiate exploration, which discloses, in turn, more information until a way\\nto attain the solution is ﬁnally discovered.—— Newell et al. [18]\\nResearch on human problem-solving suggests that people search through a combinatorial problem-\\nspace – a tree where the nodes represent partial solutions, and the branches correspond to operators\\nthat modify them [ 18,19]. Which branch to take is determined by heuristics that help to navigate the\\nproblem-space and guide the problem-solver towards a solution. This perspective highlights two key\\nshortcomings of existing approaches that use LMs to solve general problems: 1) Locally, they do not\\nexplore different continuations within a thought process – the branches of the tree. 2) Globally, they\\ndo not incorporate any type of planning, lookahead, or backtracking to help evaluate these different\\noptions – the kind of heuristic-guided search that seems characteristic of human problem-solving.\\nTo address these shortcomings, we introduce Tree of Thoughts (ToT) , a paradigm that allows LMs to\\nexplore multiple reasoning paths over thoughts (Figure 1(c)). ToT frames any problem as a search\\nover a tree, where each node is a states= [x,z1···i]representing a partial solution with the input and\\nthe sequence of thoughts so far. A speciﬁc instantiation of ToT involves answering four questions:\\n1. How to decompose the intermediate process into thought steps; 2. How to generate potential\\nthoughts from each state; 3. How to heuristically evaluate states; 4. What search algorithm to use.\\n1. Thought decomposition. While CoT samples thoughts coherently without explicit decomposition,\\nToT leverages problem properties to design and decompose intermediate thought steps. As Table 1\\nshows, depending on different problems, a thought could be a couple of words (Crosswords), a line of\\nequation (Game of 24), or a whole paragraph of writing plan (Creative Writing). In general, a thought\\nshould be “small” enough so that LMs can generate promising and diverse samples (e.g. generating\\na whole book is usually too “big” to be coherent), yet “big” enough so that LMs can evaluate its\\nprospect toward problem solving (e.g. generating one token is usually too “small” to evaluate).\\n2. Thought generator G(pθ,s,k).Given a tree state s= [x,z1···i], we consider two strategies to\\ngeneratekcandidates for the next thought step:\\n(a)Sample i.i.d. thoughts from a CoT prompt (Creative Writing, Figure 4): z(j)∼\\npCoT\\nθ(zi+1|s) =pCoT\\nθ(zi+1|x,z1···i) (j= 1···k). This works better when the thought\\nspace is rich (e.g. each thought is a paragraph), and i.i.d. samples lead to diversity;\\n(b)Propose thoughts sequentially using a “propose prompt” (Game of 24, Figure 2; Crosswords,\\nFigure 6): [z(1),···,z(k)]∼ppropose\\nθ(z(1···k)\\ni+1|s). This works better when the thought\\nspace is more constrained (e.g. each thought is just a word or a line), so proposing different\\nthoughts in the same context avoids duplication.\\n3. State evaluator V(pθ,S).Given a frontier of different states, the state evaluator evaluates the\\nprogress they make towards solving the problem, serving as a heuristic for the search algorithm\\nto determine which states to keep exploring and in which order. While heuristics are a standard\\napproach to solving search problems, they are typically either programmed (e.g. DeepBlue [ 3]) or\\n3' metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 2}\n",
      "page_content='learned (e.g. AlphaGo [ 26]). We propose a third alternative, by using the LM to deliberately reason\\nabout states. When applicable, such a deliberate heuristic can be more ﬂexible than programmed\\nrules, and more sample-efﬁcient than learned models. Similar to the thought generator, we consider\\ntwo strategies to evaluate states either independently or together:\\n(a)Value each state independently: V(pθ,S)(s)∼pvalue\\nθ(v|s)∀s∈S, where a value\\nprompt reasons about the state sto generate a scalar value v(e.g. 1-10) or a classiﬁca-\\ntion (e.g. sure/likely/impossible) that could be heuristically turned into a value. The basis\\nof such evaluative reasoning can vary across problems and thought steps. In this work, we\\nexplore evaluation via few lookahead simulations (e.g. quickly conﬁrm that 5, 5, 14 can\\nreach 24 via 5 + 5 + 14, or “hot l” can mean “inn” via ﬁlling “e” in “ ”) plus commonsense\\n(e.g. 1 2 3 are too small to reach 24, or no word can start with “tzxc”). While the former\\nmight promote “good” states, the latter could help eliminate “bad” states. Such valuations\\ndo not need to be perfect, and only need to be approximately\\n(b)Vote across states: V(pθ,S)(s) =1[s=s∗], where a “good” state s∗∼pvote\\nθ(s∗|S)is\\nvoted out based on deliberately comparing different states in Sin a vote prompt. When\\nproblem success is harder to directly value (e.g. passage coherency), it is natural to to instead\\ncompare different partial solutions and vote for the most promising one. This is similar\\nin spirit to a “step-wise” self-consistency strategy, i.e. cast “which state to explore” as a\\nmulti-choice QA, and use LM samples to vote for it.\\nFor both strategies, we could prompt the LM multiple times to aggregate the value or vote results to\\ntrade time/resource/cost for more faithful/robust heuristics.\\nAlgorithm 1 ToT-BFS(x,pθ,G,k,V,T,b )\\nRequire: Inputx, LMpθ, thought generator G()\\n& size limitk, states evaluator V(), step limitT,\\nbreadth limit b.\\nS0←{x}\\nfort= 1,···,Tdo\\nS′\\nt←{[s,z]|s∈St−1,zt∈G(pθ,s,k)}\\nVt←V(pθ,S′\\nt)\\nSt←arg maxS⊂S′\\nt,|S|=b∑\\ns∈SVt(s)\\nend for\\nreturnG(pθ,arg maxs∈STVT(s),1)Algorithm 2 ToT-DFS(s,t,pθ,G,k,V,T,v th)\\nRequire: Current state s, stept, LMpθ, thought\\ngeneratorG()and size limit k, states evaluator\\nV(), step limitT, thresholdvth\\nift>T then record output G(pθ,s,1)\\nend if\\nfors′∈G(pθ,s,k)do⊿sorted candidates\\nifV(pθ,{s′})(s)>vthres then⊿pruning\\nDFS(s′,t+ 1)\\nend if\\nend for\\n4. Search algorithm. Finally, within the ToT framework, one can plug and play different search\\nalgorithms depending on the tree structure. We explore two relatively simple search algorithms and\\nleave more advanced ones (e.g. A* [9], MCTS [2]) for future work:\\n(a)Breadth-ﬁrst search (BFS) (Algorithm 1) maintains a set of the bmost promising states\\nper step. This is used for Game of 24 and Creative Writing where the tree depth is limit\\n(T≤3), and initial thought steps can be evaluated and pruned to a small set ( b≤5).\\n(b)Depth-ﬁrst search (DFS) (Algorithm 2) explores the most promising state ﬁrst, until the\\nﬁnal output is reached ( t > T ), or the state evaluator deems it impossible to solve the\\nproblem from the current s(V(pθ,{s})(s)≤vthfor a value threshold vth). In the latter\\ncase, the subtree from sispruned to trade exploration for exploitation. In both cases, DFS\\nbacktracks to the parent state of sto continue exploration.\\nConceptually, ToT has several beneﬁts as a method for general problem-solving with LMs: (1) Gener-\\nality. IO, CoT, CoT-SC, and self-reﬁnement can be seen as special cases of ToT (i.e. trees of limited\\ndepth and breadth; Figure 1). (2) Modularity. The base LM, as well as the thought decomposition,\\ngeneration, evaluation, and search procedures can all be varied independently. (3) Adaptability .\\nDifferent problem properties, LM capabilities, and resource constraints can be accommodated. (4)\\nConvenience. No extra training is needed, just a pre-trained LM is sufﬁcient. The next section will\\nshow how these conceptual beneﬁts translate to strong empirical performance in different problems.\\n4 Experiments\\nWe propose three tasks that are hard even when sampling from the state-of-the-art language model,\\nGPT-4 [ 20], using standard IO prompting or chain-of-thought (CoT) prompting. We show how\\n4' metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 3}\n",
      "page_content='Game of 24 Creative Writing 5x5 Crosswords\\nInput 4 numbers (4 9 10 13) 4 random sentences 10 clues (h1. presented;..)\\nOutput An equation to reach 24\\n(13-9)*(10-4)=24A passage of 4 paragraphs\\nending in the 4 sentences5x5 letters: SHOWN;\\nWIRRA; A V AIL; ...\\nThoughts 3 intermediate equations\\n(13-9=4 (left 4,4,10); 10-\\n4=6 (left 4,6); 4*6=24)A short writing plan\\n(1. Introduce a book that\\nconnects...)Words to ﬁll in for clues:\\n(h1. shown; v5. naled; ...)\\n#ToT steps 3 1 5-10 (variable)\\nTable 1: Task overview. Input, output, thought examples are in blue.\\ndeliberate search in trees of thoughts (ToT) produces better results, and more importantly, interesting\\nand promising new ways to use language models to solve problems requiring search or planning.\\nUnless otherwise stated, we perform experiments using a Chat Completion mode GPT-41with a\\nsampling temperature of 0.7.\\n4.1 Game of 24\\nGame of 24 is a mathematical reasoning challenge, where the goal is to use 4 numbers and basic\\narithmetic operations (+-*/) to obtain 24. For example, given input “4 9 10 13”, a solution output\\ncould be “(10 - 4) * (13 - 9) = 24”.\\nʳĵĮòˤòƅÊĭŔĦòʴˤGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀ\\x89ĵŝŝđæĦòˤĮòƅƜˤŝŤòŔŝʝˤˤˤ3URSRVH\\x033URPSWʁˤ̌ˤʆˤ̐ˤɾʀˤʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˤˊˤʁˤ̐ˤʃˤʱĦòƙƜʝˤʃˤʆˤɾʀʲʳʛʛʛĭĵŗòˤĦđĮòŝʟʴ7KRXJKW\\x03*HQHUDWLRQ/0)ſÊĦũÊŤòˤđƙˤĈƓſòĮˤĮũĭæòŗŝˤçÊĮˤŗòÊçĎˤɿʁˤʱŝũŗòʫĦđģòĦƆʫđĭŔĵŝŝđæĦòʲɾɽˤɾʁʝˤɾɽˤ̌ˤɾʁˤ̐ˤɿʁʛˤŝũŗòʳĭĵŗòˤòƅÊĭŔĦòŝʴɾɽˤɾʀˤɾʀ9DOXH\\x033URPSWʱɾʀˤˊˤɾɽʲˤʦˤɾʀˤ̐ˤʀˤʦˤɾʀˤ̐ˤʀʆɾɽˤ̌ˤɾʀˤ̌ˤɾʀˤ̐ˤʀʃ\\x9aĎòŗòˤƓŝˤĮĵˤƀÊƆˤƘĵˤĵæŤÊđĮˤɿʁˤƀƓƜĎˤƛĎòŝòˤĮũĭæòŗŝʛˤđĭŔĵŝŝđæĦò7KRXJKW\\x03(YDOXDWLRQʱæʲʱçʲ/0GĮŔũƜʝˤʁˤʆˤɾɽˤɾʀʁ̌ʆ̐ɾʀʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˁʁ̐ʃʱĦòƙƜʝˤʃˤʆˤɾʀʲʟʟɾʀˁʃ̐ʄʱĦòƙƜʝˤʄˤʆʲɾʀˁʆ̐ʁʱĦòƙƜʝˤʁˤʃʲʟʟʁʦʃ̐ɿʁʱĦòƙƜʝˤɿʁʲʁ̌ʃ̐ɾɽʱĦòƙƜʝˤɾɽʲʟʟʱÊʲ\\nʳĵĮòˤòƅÊĭŔĦòʴˤGĮŔũƜʝˤʁˤʆˤɾɽˤɾʀ\\x89ĵŝŝđæĦòˤĮòƅƜˤŝŤòŔŝʝˤˤˤ\\x0bD\\x0c\\x033URSRVH\\x033URPSWʁˤ̌ˤʆˤ̐ˤɾʀˤʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˤˊˤʁˤ̐ˤʃˤʱĦòƙƜʝˤʃˤʆˤɾʀʲʳʛʛʛĭĵŗòˤĦđĮòŝʟʴ7KRXJKW\\x03*HQHUDWLRQ/0)ſÊĦũÊŤòˤđƙˤĈƓſòĮˤĮũĭæòŗŝˤçÊĮˤŗòÊçĎˤɿʁˤʱŝũŗòʫĦđģòĦƆʫđĭŔĵŝŝđæĦòʲɾɽˤɾʁʝˤɾɽˤ̌ˤɾʁˤ̐ˤɿʁʛˤŝũŗòʳĭĵŗòˤòƅÊĭŔĦòŝʴɾɽˤɾʀˤɾʀ\\x0bE\\x0c\\x039DOXH\\x033URPSWʱɾʀˤˊˤɾɽʲˤʦˤɾʀˤ̐ˤʀˤʦˤɾʀˤ̐ˤʀʆɾɽˤ̌ˤɾʀˤ̌ˤɾʀˤ̐ˤʀʃˤ\\x9aĎòŗòˤƓŝˤĮĵˤƀÊƆˤƘĵˤĵæŤÊđĮˤɿʁˤƀƓƜĎˤƛĎòŝòˤæƓĈˤĮũĭæòŗŝʛˤđĭŔĵŝŝđæĦò7KRXJKW\\x03(YDOXDWLRQ/0GĮŔũƜʝˤʁˤʆˤɾɽˤɾʀʁ̌ʆ̐ɾʀʱĦòƙƜʝˤɾɽˤɾʀˤɾʀʲɾɽˁʁ̐ʃʱĦòƙƜʝˤʃˤʆˤɾʀʲʟʟɾʀˁʃ̐ʄʱĦòƙƜʝˤʄˤʆʲɾʀˁʆ̐ʁʱĦòƙƜʝˤʁˤʃʲʟʟʁʦʃ̐ɿʁʱĦòƙƜʝˤɿʁʲʁ̌ʃ̐ɾɽʱĦòƙƜʝˤɾɽʲʟʟ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0c0DUN\\x03GLII\\x03SURPSW\\x03ZLWK\\x03FRORU\\nFigure 2: ToT in a game of 24. The LM is prompted for (a) thought generation and (b) valuation.\\nTask Setup. We scrape data from 4nums.com, which has 1,362 games that are sorted from easy to\\nhard by human solving time, and use a subset of relatively hard games indexed 901-1,000 for testing.\\nFor each task, we consider the output as success if it is a valid equation that equals 24 and uses the\\ninput numbers each exactly once. We report the success rate across 100 games as the metric.\\nBaselines. We use a standard input-output (IO) prompt with 5 in-context examples. For chain-of-\\nthought (CoT) prompting, we augment each input-output pair with 3 intermediate equations, each\\noperating on two remaining numbers. For example, given input “4 9 10 13”, the thoughts could be\\n“13 - 9 = 4 (left: 4 4 10); 10 - 4 = 6 (left: 4 6); 4 * 6 = 24 (left: 24)”. For each game, we sample IO\\nand CoT prompting for 100 times for average performance. We also consider a CoT self-consistency\\nbaseline, which takes the majority output from 100 CoT samples, and an iterative-reﬁne approach on\\ntop of an IO sample for at most 10iterations. At each iteration, the LM is conditioned on all previous\\nhistory to “reﬂect on your mistakes and generate a reﬁned answer” if the output is incorrect. Note\\nthat it uses groundtruth feedback signals about equation correctness.\\nToT Setup. To frame Game of 24 into ToT, it is natural to decompose the thoughts into 3 steps,\\neach an intermediate equation. As shown in Figure 2(a), at each tree node, we exact the “left”\\nnumbers and prompt the LM to propose some possible next steps. The same “propose prompt” is\\nused for all 3 thought steps, though it only has one example with 4 input numbers. We perform a\\nbreadth-ﬁrst search (BFS) in ToT, where at each step we keep the best b= 5candidates. To perform\\ndeliberate BFS in ToT, as shown in Figure 2(b), we prompt LM to evaluate each thought candidate as\\n“sure/maybe/impossible” with regard to reaching 24. The aim is to promote correct partial solutions\\nthat can be verdicted within few lookahead trials, and eliminate impossible partial solutions based on\\n“too big/small” commonsense, and keep the rest “maybe”. We sample values 3times for each thought.\\n1Experiments were done between May 5-16, 2023.\\n5' metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 4}\n",
      "page_content='Method Success\\nIO prompt 7.3%\\nCoT prompt 4.0%\\nCoT-SC (k=100) 9.0%\\nToT (ours) (b=1) 45%\\nToT (ours) (b=5) 74%\\nIO + Reﬁne (k=10) 27%\\nIO(best of 100) 33%\\nCoT (best of 100) 49%\\nTable 2: Game of 24 Results.\\n0 25 50 75 1000.20.40.6(a) Success rate with nodes visited\\nIO (best of k)\\nCoT (best of k)\\nToT (b=1...5)\\n1 2 3 4Correct0.00.20.40.6(b) Samples failed at each step\\nCoT\\nToT (b=5) Figure 3: Game of 24 (a) scale analysis & (b) error analysis.\\nResults. As shown in Table 2, IO, CoT, and CoT-SC prompting methods perform badly on the task,\\nachieving only 7.3%, 4.0%, and 9.0% success rates. In contrast, ToT with a breadth of b= 1already\\nachieves a success rate of 45%, whileb= 5 achieves 74%. We also consider an oracle setup for\\nIO/CoT, by calculating the success rate using best of ksamples (1≤k≤100) . To compare IO/CoT\\n(best of k) with ToT, we consider calculating the tree nodes visited per task in ToT across b= 1···5,\\nand map the 5 success rates in Figure 3(a), treating IO/CoT (best of k) as visitingknodes in a bandit.\\nNot surprisingly, CoT scales better than IO, and best of 100 CoT samples achieve a success rate of\\n49%, but still much worse than exploring more nodes in ToT ( b>1).\\nError Analysis. Figure 3(b) breaks down at which step CoT and ToT samples fail the task, i.e. the\\nthought (in CoT) or all bthoughts (in ToT) are invalid or impossible to reach 24. Notably, around\\n60% of CoT samples already failed the task after generating the ﬁrst step, or equivalently, the ﬁrst\\nthree words (e.g. “ 4 + 9 ”). This highlights the issues with direct left-to-right decoding.\\n4.2 Creative writing\\nNext, we invent a creative writing task where the input is 4 random sentences and the output should\\nbe a coherent passage with 4 paragraphs that end in the 4 input sentences respectively. Such a task is\\nopen-ended and exploratory, and challenges creative thinking as well as high-level planning.\\nTask setup. We sample random sentences from randomwordgenerator.com to form 100 inputs, and\\nthere is no groundtruth passage for each input constraint. As we ﬁnd that GPT-4 can follow the\\ninput constraints most of the time, we focus on evaluating passage coherency in two ways: using a\\nGPT-4 zero-shot prompt to provide a 1-10 scalar score, or using human judgments to compare pairs\\nof outputs from different methods. For the former, we sample 5 scores and average them for each task\\noutput, and we ﬁnd these 5 scores usually consistent, with a standard deviation of around 0.56on\\naverage across outputs. For the latter, we employ a subset of the authors in a blind study to compare\\nthe coherency of CoT vs. ToT generated passage pairs, where the order of passages is random ﬂipped\\nover 100 inputs.\\nBaselines. Given the creative nature of the task, both IO and CoT prompts are zero-shot. While the\\nformer prompts the LM to directly generate a coherent passage given input constraints, the latter\\nprompts the LM to ﬁrst make a brief plan then write the passage, i.e. the plan serves as the intermediate\\nthought step. We generate 10 IO and CoT samples per task. We also consider an iterative-reﬁne\\n(k≤5) method on top of a random IO sample for each task, where the LM is conditioned on input\\nconstraints and the last generated passage to decide if the passage is already “perfectly coherent”,\\nand if not generate a reﬁned one.\\nToT setup. We build a ToT with depth 2 (and only 1 intermediate thought step) — the LM ﬁrst\\ngeneratesk= 5plans and votes for the best one (Figure 4), then similarly generate k= 5passages\\nbased on the best plan then vote for the best one. Here the breadth limit b= 1, as only one choice is\\nkept per step. A simple zero-shot vote prompt (“analyze choices below, then conclude which is most\\npromising for the instruction”) is used to sample 5 votes at both steps.\\nResults. Figure 5(a) shows average GPT-4 scores across 100 tasks, where ToT (7.56) is deemed to\\ngenerate more coherent passages than IO (6.19) and CoT (6.93) on average. While such an automatic\\nmetric might be noisy, Figure 5(b) conﬁrms the ﬁnding by showing that humans prefer ToT over\\nCoT in 41 out of 100 passage pairs, while only prefer CoT over ToT in 21 (other 38 pairs are found\\n“similarly coherent”). Lastly, iterative-reﬁne is more effective on this natural language task, where\\n6' metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 5}\n",
      "page_content='µŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤ\\x9aĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤ\\x92ƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤ\\x9aĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\\x1dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤ\\x89ĦÊĮŝʱʀˤĭĵŗòˤĵĭƓƜŤòíʲʱçʲˤ´ĵŤòŝ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱɽʫʂˤſĵŤòŝʲ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝʟˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛʱʀʫʂˤſĵŤòŝʲʟɾɿGĮŔũƜ\\x89ĦÊĮˤɾ\\x89ĦÊĮˤɿʟʟ\\x89ÊŝŝÊĈòɾ\\x89ÊŝŝÊĈòɿʟʟ)L[\\x03FRORU\\x03\\x0bE\\\\\\x03<XTLDQ\\x0cµŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤ\\x9aĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮƜŗĵíũçòˤÊĮíˤòƅŔĦÊđĮˤƛĎòˤƘòçĎĮƓŖũòˤĵƙˤíĵđĮĈˤÊˤĎÊĮíŝŤÊĮíˤɿʛˤ\\x92ƀƓŤçĎˤƘĵˤÊˤŝŤĵŗƆˤÊæĵũƜˤÊĮˤÊŝƜŗĵĮÊũƜ˙ŝˤƚđŗŝƜˤƛđĭòˤđĮˤŝŔÊçòˤʀʛˤ#òŝçŗđæòˤÊˤŝƓƜũÊƜƓĵĮˤƀĎòŗòˤÊˤƀĵĭÊĮˤũŝòŝˤŝƓĈĮˤĦÊĮĈũÊĈòˤƘĵˤÊſĵƓíˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤʁʛˤ\\x9aĎòˤƚđĮÊĦˤŔÊŗÊĈŗÊŔĎˤòƅŔĦÊđĮŝˤĎĵƀˤòſòŗƆĵĮòˤĎÊŝˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵƜĎòŗŝɾʛˤGĮƜŗĵíũçƜƓĵĮˤƘĵˤÊĮˤũĮũŝũÊĦˤŝòĦƙˊĎòĦŔˤæĵĵģʜˤĭòĮƜƓĵĮđĮĈˤÊˤĎÊĮíŝŤÊĮíˤÊŝˤÊˤĭòŤÊŔĎĵŗˤƗĵŗˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʛˤɿʛˤ#ƓŝçũŝŝˤƛĎòˤũĮòƅŔòçŤòíˤƛĎđĮĈŝˤĦòÊŗĮòíˤƚŗĵĭˤÊŝƜŗĵĮÊũŤŝʜˤđĮçĦũíđĮĈˤƛĎòˤŝĭòĦĦˤĵƙˤŝŔÊçòʛˤʀʛˤ#òŝçŗđæòˤÊˤƀĵĭÊĮ˙ŝˤçĦòſòŗˤƘÊçƜƓçˤƗĵŗˤÊſĵƓíđĮĈˤũĮƀÊĮŤòíˤÊƜŤòĮƜƓĵĮˤÊƜˤÊˤæÊŗʛˤʁʛˤ\\x1dĵĮŤòĭŔĦÊŤòˤĎĵƀˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮŝˤĵƙˤĵĮòŝòĦƙˤçÊĮˤŝĎÊŔòˤĵĮò˙ŝˤƓíòĮƜƓŤƆʛʱÊʲˤGĮŔũƜʱæʲˤ\\x89ĦÊĮŝʱçʲˤ´ĵŤòŝ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛGĮŔũƜ\\x89ĦÊĮˤɾˤ\\x89ĦÊĮˤɿˤˤʟʟ\\x89ÊŝŝÊĈòɾ\\x89ÊŝŝÊĈòɿʟʟɽʫʂˤſĵŤòŝ\\x89ĦÊĮˤɾˤˤˤʟʛʟʛɾʟʛɿʟʟʀʫʂˤſĵŤòŝ\\x89ĦÊĮˤʀˁʂˤˤˤ8VH\\x03UHG\\x12JUHHQ\\x03WR\\x03VKRZ\\x03ILQDO\\x03FKRLFH\\nĮʫʂˤſĵŤòŝ\\x89ĦÊĮˤɿˤˤˤ\\n\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛ\\x01ĮÊĦƆƏđĮĈˤòÊçĎˤçĎĵƓçòˤđĮˤíòŤÊƓĦʝˤˤ\\x1dĎĵƓçòˤɾʜˤƀĎƓĦòˤđĮçĵŗŔĵŗÊƜđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝʜˤŝòòĭŝˤƘĵˤĦÊçģˤÊˤçĦòÊŗˤçĵĮĮòçƜƓĵĮˤæòŤƀòòĮˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤʳʛʛʛʴˤ\\x1dĎĵƓçòˤɿˤĵƙćòŗŝˤÊĮˤđĮŤòŗòŝƜđĮĈˤŔòŗŝŔòçƜƓſòˤæƆˤũŝđĮĈˤƛĎòˤŗòŖũđŗòíˤòĮíˤŝòĮŤòĮçòŝˤƘĵˤŔŗòŝòĮƜˤÊˤŝòĦƙˊĎòĦŔˤæĵĵģ˙ŝˤçĵĮŤòĮƜʛˤGƜˤçĵĮĮòçŤŝˤƛĎòˤŔÊŗÊĈŗÊŔĎŝˤƀƓƜĎˤƛĎòˤƛĎòĭòˤĵƙˤŝòĦƙˊđĭŔŗĵſòĭòĮƜˤÊĮíˤòĭæŗÊçđĮĈˤçĎÊĦĦòĮĈòŝʜˤĭÊģđĮĈˤƗĵŗˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòʛˤˤʳʛʛʛʴˤ\\x9aĎòˤæòŝƜˤçĎĵƓçòˤƓŝˤɿʛFigure 4: A step of deliberate search in a randomly picked Creative Writing task. Given the input, the\\nLM samples 5 different plans, then votes 5 times to decide which plan is best. The majority choice is\\nused to consequently write the output passage with the same sample-vote procedure.\\nIO CoT ToT IO\\n+refineToT\\n+refine468\\n(a) GPT-4 coherency scores\\nCoT > ToT Similar ToT > CoT010203040\\n213841(b) Human coherency comparison\\nFigure 5: Creative Writing results.Method Success Rate (%)\\nLetter Word Game\\nIO 38.7 14 0\\nCoT 40.6 15.6 1\\nToT (ours) 78 60 20\\n+best state 82.4 67.5 35\\n-prune 65.4 41.5 5\\n-backtrack 54.6 20 5\\nTable 3: Mini Crosswords results.\\nit improves IO coherency score from 6.19 to 7.67, and ToT coherency score from 7.56 to 7.91. We\\nbelieve it could be thought of as a third approach to thought generation in the ToT framework, where\\nnew thoughts can arise from reﬁning old thoughts instead of i.i.d. or sequentially generated.\\n4.3 Mini Crosswords\\nIn Game of 24 and Creative Writing, ToT is relatively shallow — at most 3 thought steps are needed\\nto reach the ﬁnal output. Here we explore 5×5mini crosswords as a harder search problem involving\\nnatural language. Again, the goal is not just to solve the task, as more general crosswords can be\\nreadily solved with specialized NLP pipelines [ 31] that leverages large-scale retrieval instead of LM.\\nRather, we aim to explore the limit of LM as a general problem solver that explores its own thoughts\\nand guides its own exploration with deliberate reasoning as heuristics.\\nTask Setup. We scrape data from GooBix, which contains 156 games of 5×5mini crosswords. As\\nwe observe adjacent games contain similar clues, we use 20 games with indices 1,6,···,91,96for\\ntesting, and games 136,141,146,151,156for prompting. For each task, the input describes the 5\\nhorizontal clues and 5 vertical clues, and the output should be a board of 5×5 = 25 letters to solve\\nthe crosswords. For evaluation, we consider three levels of success: the portion of correct letters (25\\nper game), words (10 per game), and games.\\nBaselines. We provide 5 example input-output pairs in the IO prompt, and in the CoT prompt\\nadditionally include intermediate words in the order h1..5 then v1..5. We run each prompt for 10\\nsamples and average the results.\\nToT Setup. We leverage a depth-ﬁrst search (Algorithm 2) that keeps exploring the most promising\\nsubsequent word clue until the state is no longer promising, then backtrack to the parent state to\\nexplore alternative thoughts. To make search tractable, subsequent thoughts are constrained not to\\nchange any ﬁlled words or letters, so that the ToT has at most 10 intermediate steps. For thought\\ngeneration, at each state we translate all existing thoughts (e.g. “h2.motor; h1.tasks” for the state\\nin Figure 6(a)) into letter constraints for remaining clues (e.g. “v1.To heap: tm ;...”) and prompt\\na proposal prompt 5times to come up with candidates for where and what to ﬁll in the next word.\\nImportantly, we also prompt the LM to give a conﬁdence level for different thoughts, and aggregate\\n7' metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 6}\n",
      "page_content='>\\x0b\\nY\\x16\\x11\\x03HORSH\\n\\x0f\\x03\\x16\\x11\\x15\\x0c\\x0f\\x03\\x0b\\nK\\x15\\x11\\x03YDOXH\\n\\x0f\\x03\\x15\\x11\\x13\\x0c\\x0f\\x03\\x0b\\nK\\x14\\x11\\x03SDUFK\\n\\x0f\\x03\\x14\\x11\\x1c\\x0c\\x0f\\x03\\x0b\\nY\\x18\\x11\\x03FRYHW\\n\\x0f\\x03\\x13\\x11\\x19\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x13\\x14\\x0c\\x0f\\x03\\x0b\\nK\\x15\\x11\\x03PHULW\\n\\x0f\\x03\\x13\\x11\\x17\\x0c\\x0f\\x03\\x0b\\nY\\x14\\x11\\x03DOORZ\\n\\x0f\\x03\\x13\\x11\\x15\\x0c\\x0f\\x03\\x0b\\nY\\x15\\x11\\x03JULQG\\n\\x0f\\x03\\x13\\x11\\x14\\x0c\\x0f\\x03\\x0b\\nK\\x17\\x11\\x03OHSHU\\n\\x0f\\x03\\x13\\x11\\x14\\x0c@\\nY\\x16\\x11\\x03HORSH\\n0XOWLSOH\\x03UXQV3DUVH\\x0f\\x03ILOWHU\\x03RXW\\x03QRQ\\x10ILYH\\x10OHWWHU\\x0f\\x03VFRUH\\x0f\\x03DJJUHJDWH\\n&KRRVH\\x03\\x0bVRIW\\x03VHOI\\x10FRQVLVWHQF\\\\\"\\x0c\\x14\\x110D[\\x15\\x110D[\\x03ZLWKRXW\\x03YLRODWH\\x16\\x11\\')6\\nGĮŔũƜˤ\\x1dĦũòŝĎɿʛĭĵŤĵŗĎɾʛƘÊŝģŝĎʁʛŝÊĦĵĮƘÊŝģŝƘÊŝģŝ\\nĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVÊĈĈŗòĈÊŤòſʀʛˤ\\x89ŗòŤòĮƜƓĵũŝʞˤƚĦĵƀòŗƆʝˤˈˈˈˈˈˤŝũŗò6WDWH\\x03(YDOXDWRU\\x03\\x0bRYHU\\x03HDFK\\x03FOXH\\x0cſɾʛˤÉĵˤĎòÊŔʝˤƛĭˈŝˈˤʳʛʛʛʴˤđĭŔĵŝŝđæĦòſʂʛˤ#òŝƓççÊŤĵŗʞˤĭĵŗòˤíŗƆʝˤŝŗˈĮˈˤʳʛʛʛʴˤĭÊƆæòʟʟʱæÊçģƜŗÊçģʲĎʀʛĈŗÊĮíʟʟʱŝũæƜŗòòˤŔŗũĮòíʲĎʁʛˤŝÊĦĵĮĎʀʛˤĈŗÊĮíſʀʛˤŝƜŗđĮĈʟʟ\\')6\\x032UGHUĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮĈˤʱĎƓĈĎʲʟʟ7KRXJKW\\x033URSRVDOVʱÊʲʱæʲƛˤÊˤŝˤģˤŝĭˤĵˤƛˤĵˤŗˈˤˈˤˈˤˈˤˈŝˤÊˤĦˤĵˤĮˈˤˈˤˈˤˈˤˈFigure 6: In Mini Crosswords, (a) how thoughts are proposed and aggregated in a priority queue\\nfor depth-ﬁrst search (DFS), and (b) how a state is evaluated based on the possibility of ﬁlling in\\neach remaining word clue, and pruned if any remaining clue is deemed not possible to ﬁll by the LM.\\nThen DFS backtracks to the parent state and explore the next promising thought for clue.\\nthese across proposals to obtain a sorted list of next thoughts to explore (Figure 6(a)). For state\\nevaluations, we similarly translate each state into letter constraints for remaining clues, then evaluate\\nfor each clue if it is possible to ﬁll given the constraints. If any remaining clue is deemed “impossible”\\nto ﬁll in (e.g. “v1. To heap: tm s”), then the exploration of the state’s subtree is pruned and DFS\\nbacktracks to its parent to explore the next promising thought. We limit DFS search steps to 100, and\\nsimply render the deepest explored state (the ﬁrst explored one if multiple) into the ﬁnal output.\\nResults. As shown in Table 3, IO and CoT prompting methods perform poorly with a word-level\\nsuccess rate less than 16%, while ToT signiﬁcantly improves all metrics, achieving a word-level\\nsuccess rate of 60% and solving 4 out of 20 games. Such an improvement is not surprising, given IO\\nand CoT lack mechanisms to try different clues, make changes to decisions, or backtrack.\\nOracle and ablation studies. When outputting from the oracle best DFS state (instead of the\\nheuristically determined best state) per task, ToT performance is even higher and actually solves\\n7/20 games (Table 3, “+best state”), indicating our simple output heuristics can be readily improved.\\nInterestingly, sometimes when the crosswords game is actually solved, the state evaluator might still\\ndeem some words as “impossible” and prune — possibly because 5×5crosswords by design have\\nsome rare or obselete words that GPT-4 cannot recognize2. Given the state evaluation as a pruning\\nheuristic is imperfect, we also explore ablating the pruning, and ﬁnd the performance generally worse\\n(Table 3, “-prune”). However, it could actually ﬁnd the correct solution for 4/20 games (though only\\noutputting 1 via heuristic), 3 of which are games ToT+pruning cannot solve within 100 steps. Thus,\\nbetter heuristics for DFS pruning are critical for problem solving in this case. Lastly, we conﬁrm the\\nimportance of backtracking by running an ablation that keeps ﬁlling the most promising clue for at\\nmost 20 steps, allowing overwrites. This is similar to a “greedy” BFS search with breadth limit of\\nb= 1, and performs poorly with a word level success of only 20% (Table 3, “-backtrack”).\\n5 Related Work\\nPlanning and decision making. Smart planning and decision making are critical to achieving\\npredeﬁned goals. As they are trained on vast amount of world knowledge and human examples, LMs\\nare known to have already absorbed rich commonsense that makes it possible to propose reasonable\\nplans conditioned on problem setting and environmental states [ 10,39,34,11,32,38,37]. Our\\nproposed Tree-of-Thought approach extends existing planning formulations by considering multiple\\npotentially feasible plans simultaneously at each problem-solving step, and proceeding with the most\\npromising ones. The integration between thought sampling and value feedback organically integrates\\nplanning and decision-making mechanisms, enabling effective search inside a solution tree. On the\\nother hand, traditional decision-making procedures usually require training dedicated reward and\\npolicy models as in reinforcement learning (for example CHAI [ 30]), whereas we use the LM itself\\nto provide the value estimates for decision making.\\n2For example, “agend” is an obsolete form of “agendum”, but GPT-4 deems it a typo for “agenda”. External\\nretrieval or web interaction could augment LM for problem solving under knowledge uncertainty.\\n8' metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 7}\n",
      "page_content='Self-reﬂection. Using LLMs to assess the viability of their own predictions is becoming an in-\\ncreasingly important procedure in problem solving. [ 25,17,21] introduced the “self-reﬂection”\\nmechanism, in which LMs provide feedback to their generation candidates. [ 4] improves LMs code\\ngeneration accuracy by injecting feedback messages generated by the LM itself based on its code\\nexecution results. Similarly, [ 14] also introduces “critic” or review steps over the actions and states,\\ndeciding the next action to take in solving computer operation tasks. Another recent work very\\nrelevant to ours is “self-eval guided decoding” [ 36]. Similar to our method, self-eval decoding\\nalso follows a tree-search procedure with leaves sampled from stochastic beam search decoding,\\nwhich are then evaluated by LLM itself with carefully prepared self-eval prompts. Their approach\\nhowever, uses the PAL formulation [ 7] which represents thoughts as codes, which makes it difﬁcult\\nto tackle challenging tasks like creative writing which we consider in this paper. Our Tree-of-Thought\\nformulation is thus more versatile and handles challenging tasks on which GPT-4 only achieves very\\nlow accuracy with standard prompts.\\nProgram-guided LLM generation. Our proposal is also related to recent advancements that or-\\nganize LM’s behavior with symbolic program guidance. For example [ 24] embeds LMs in an\\nalgorithmic search procedure to help solve problems like question answering step-by-step, in which\\nthe search trees are expanded by relevant paragraphs that might provide answers. This approach\\nhowever differs from ours in that trees are expanded by sampling external paragraphs instead of the\\nLM’s own thoughts, and there is no reﬂection or voting steps. Another approach, LLM+P [ 15], goes\\none step further and delegates the actual planning process to a classical planner.\\nClassical search methods. Last but not least, our approach can be treated as a modern rendition\\nof classical search methods for problem solving. For example it can be considered as a heuristic\\nsearch algorithm like A* [ 8], in which the heuristic at each search node is provided by the LM’s\\nself-assessment. From this perspective, our method is also related to NeuroLogic A*esque decoding\\nproposed in [ 16], which is inspired by A* search but introduces look-ahead heuristics that are\\nefﬁcient for LMs to improve the beam-search or top-k sampling decoding. This method however is\\nconstrained to sentence generation tasks, whereas our framework are designed for complex, multi-step\\nproblem solving guarded by value feedback.\\n6 Discussion\\nLimitations and future directions. Deliberate search such as ToT might not be necessary for\\nmany existing tasks that GPT-4 already excels at, and as an initial step this work only explores\\nthree relatively simple tasks that challenges GPT-4 and calls of better search and planning abilities\\nincorporated with LMs. However, as we begin to deploy LMs for more real-world decision making\\napplications (e.g. coding, data analysis, robotics, etc.), more complex tasks could emerge and present\\nnew opportunities to study these research questions. Also, search methods like ToT requires more\\nresources (e.g. GPT-4 API cost) than sampling methods in order to improve task performances,\\nbut the modular ﬂexibility of ToT allows users to customize such performance-cost tradeoffs, and\\nongoing open-source efforts [ 29] should readily reduce such costs in the near future. Lastly, this work\\nfocuses on using an off-the-shelf LM, and ﬁne-tuning LMs using a ToT-style high-level counterfactual\\ndecision making (e.g. deliberating over potential choices for the next paragraph, instead of predicting\\nthe next token) might present opportunities to enhance the problem-solving capabilities of LMs.\\nBroader impact. ToT is a framework that empowers LMs to more autonomously and intelligently\\nmake decisions and solve problems. While current tasks are limited to reasoning and search problems,\\nfuture applications involving interaction with external environments or humans could bring potential\\ndanger, e.g. facilitating harmful uses of LMs. On the other hand, ToT also improves the interpretability\\nof model decisions and the opportunity for human alignment, as the resulting representations are\\nreadable, high-level language reasoning instead of implicit, low-level token values.\\nConclusion. The associative “System 1” of LMs can be beneﬁcially augmented by a “System 2”\\nbased on searching a tree of possible paths to the solution to a problem. The Tree of Thoughts\\nframework provides a way to translate classical insights about problem-solving into actionable\\nmethods for contemporary LMs. At the same time, LMs address a weakness of these classical\\nmethods, providing a way to solve complex problems that are not easily formalized, such as creative\\nwriting. We see this intersection of LMs with classical approaches to AI as an exciting direction for\\nfuture work.\\n9' metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 8}\n",
      "page_content='References\\n[1]T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,\\nG. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural\\ninformation processing systems , 33:1877–1901, 2020.\\n[2]C. Browne, E. J. Powley, D. Whitehouse, S. M. M. Lucas, P. I. Cowling, P. Rohlfshagen,\\nS. Tavener, D. P. Liebana, S. Samothrakis, and S. Colton. A survey of monte carlo tree search\\nmethods. IEEE Transactions on Computational Intelligence and AI in Games , 4:1–43, 2012.\\n[3]M. Campbell, A. J. Hoane Jr, and F.-h. Hsu. Deep blue. Artiﬁcial intelligence , 134(1-2):57–83,\\n2002.\\n[4]X. Chen, M. Lin, N. Sch ¨arli, and D. Zhou. Teaching large language models to self-debug, 2023.\\n[5]A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W.\\nChung, C. Sutton, S. Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv\\npreprint arXiv:2204.02311 , 2022.\\n[6]N. D. Daw, Y . Niv, and P. Dayan. Uncertainty-based competition between prefrontal and\\ndorsolateral striatal systems for behavioral control. Nature neuroscience , 8(12):1704–1711,\\n2005.\\n[7]L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y . Yang, J. Callan, and G. Neubig. Pal: Program-\\naided language models, 2023.\\n[8]P. E. Hart, N. J. Nilsson, and B. Raphael. A formal basis for the heuristic determination of\\nminimum cost paths. IEEE Transactions on Systems Science and Cybernetics , 4(2):100–107,\\n1968. doi: 10.1109/TSSC.1968.300136.\\n[9]P. E. Hart, N. J. Nilsson, and B. Raphael. A formal basis for the heuristic determination of\\nminimum cost paths. IEEE transactions on Systems Science and Cybernetics , 4(2):100–107,\\n1968.\\n[10] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch. Language models as zero-shot planners:\\nExtracting actionable knowledge for embodied agents, 2022.\\n[11] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch,\\nY . Chebotar, et al. Inner monologue: Embodied reasoning through planning with language\\nmodels. arXiv preprint arXiv:2207.05608 , 2022.\\n[12] D. Kahneman. Thinking, fast and slow . Macmillan, 2011.\\n[13] D. Kahneman, S. Frederick, et al. Representativeness revisited: Attribute substitution in intuitive\\njudgment. Heuristics and biases: The psychology of intuitive judgment , 49(49-81):74, 2002.\\n[14] G. Kim, P. Baldi, and S. McAleer. Language models can solve computer tasks, 2023.\\n[15] B. Liu, Y . Jiang, X. Zhang, Q. Liu, S. Zhang, J. Biswas, and P. Stone. Llm+p: Empowering\\nlarge language models with optimal planning proﬁciency, 2023.\\n[16] X. Lu, S. Welleck, P. West, L. Jiang, J. Kasai, D. Khashabi, R. L. Bras, L. Qin, Y . Yu,\\nR. Zellers, N. A. Smith, and Y . Choi. Neurologic a*esque decoding: Constrained text generation\\nwith lookahead heuristics. In North American Chapter of the Association for Computational\\nLinguistics , 2021.\\n[17] A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe, U. Alon, N. Dziri,\\nS. Prabhumoye, Y . Yang, S. Welleck, B. P. Majumder, S. Gupta, A. Yazdanbakhsh, and P. Clark.\\nSelf-reﬁne: Iterative reﬁnement with self-feedback, 2023.\\n[18] A. Newell, J. C. Shaw, and H. A. Simon. Report on a general problem solving program. In IFIP\\ncongress , volume 256, page 64. Pittsburgh, PA, 1959.\\n[19] A. Newell, H. A. Simon, et al. Human problem solving . Prentice-Hall, 1972.\\n10' metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 9}\n",
      "page_content='[20] OpenAI. Gpt-4 technical report. ArXiv , abs/2303.08774, 2023.\\n[21] D. Paul, M. Ismayilzada, M. Peyrard, B. Borges, A. Bosselut, R. West, and B. Faltings. Reﬁner:\\nReasoning feedback on intermediate representations, 2023.\\n[22] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al. Improving language understanding\\nby generative pre-training. OpenAI blog , 2018.\\n[23] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are\\nunsupervised multitask learners. OpenAI blog , 1(8):9, 2019.\\n[24] I. Schlag, S. Sukhbaatar, A. Celikyilmaz, W. tau Yih, J. Weston, J. Schmidhuber, and X. Li.\\nLarge language model programs, 2023.\\n[25] N. Shinn, B. Labash, and A. Gopinath. Reﬂexion: an autonomous agent with dynamic memory\\nand self-reﬂection, 2023.\\n[26] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker,\\nM. Lai, A. Bolton, et al. Mastering the game of go without human knowledge. nature , 550\\n(7676):354–359, 2017.\\n[27] S. A. Sloman. The empirical case for two systems of reasoning. Psychological bulletin , 119(1):\\n3, 1996.\\n[28] K. E. Stanovich. Who is rational? Studies of individual differences in reasoning . Psychology\\nPress, 1999.\\n[29] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozi `ere, N. Goyal,\\nE. Hambro, F. Azhar, et al. Llama: Open and efﬁcient foundation language models. arXiv\\npreprint arXiv:2302.13971 , 2023.\\n[30] S. Verma, J. Fu, S. Yang, and S. Levine. Chai: A chatbot ai for task-oriented dialogue with\\nofﬂine reinforcement learning. In Proceedings of the 2022 Conference of the North American\\nChapter of the Association for Computational Linguistics: Human Language Technologies ,\\npages 4471–4491, 2022.\\n[31] E. Wallace, N. Tomlin, A. Xu, K. Yang, E. Pathak, M. Ginsberg, and D. Klein. Automated\\ncrossword solving. arXiv preprint arXiv:2205.09665 , 2022.\\n[32] L. Wang, W. Xu, Y . Lan, Z. Hu, Y . Lan, R. K.-W. Lee, and E.-P. Lim. Plan-and-solve prompting:\\nImproving zero-shot chain-of-thought reasoning by large language models, 2023.\\n[33] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, and D. Zhou. Self-consistency improves chain\\nof thought reasoning in language models. arXiv preprint arXiv:2203.11171 , 2022.\\n[34] Z. Wang, S. Cai, A. Liu, X. Ma, and Y . Liang. Describe, explain, plan and select: Interactive\\nplanning with large language models enables open-world multi-task agents, 2023.\\n[35] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D. Zhou. Chain of thought\\nprompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903 , 2022.\\n[36] Y . Xie, K. Kawaguchi, Y . Zhao, X. Zhao, M.-Y . Kan, J. He, and Q. Xie. Decomposition\\nenhances reasoning via self-evaluation guided decoding, 2023.\\n[37] S. Yang, O. Nachum, Y . Du, J. Wei, P. Abbeel, and D. Schuurmans. Foundation models for\\ndecision making: Problems, methods, and opportunities, 2023.\\n[38] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y . Cao. ReAct: Synergizing\\nreasoning and acting in language models. arXiv preprint arXiv:2210.03629 , 2022.\\n[39] S. Zhang, Z. Chen, Y . Shen, M. Ding, J. B. Tenenbaum, and C. Gan. Planning with large\\nlanguage models for code generation. In The Eleventh International Conference on Learning\\nRepresentations , 2023. URL https://openreview.net/forum?id=Lr8cOOtYbfL .\\n11' metadata={'source': 'pdf/Tree of Thoughts- Deliberate Problem Solving with Large Language Models.pdf', 'page': 10}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nSELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT\\nREASONING IN LANGUAGE MODELS\\nXuezhi Wang†‡Jason Wei†Dale Schuurmans†Quoc Le†Ed H. Chi†\\nSharan Narang†Aakanksha Chowdhery†Denny Zhou†§\\n†Google Research, Brain Team\\n‡xuezhiw@google.com ,§dennyzhou@google.com\\nABSTRACT\\nChain-of-thought prompting combined with pre-trained large language models has\\nachieved encouraging results on complex reasoning tasks. In this paper, we propose\\na new decoding strategy, self-consistency , to replace the naive greedy decoding\\nused in chain-of-thought prompting. It ﬁrst samples a diverse set of reasoning paths\\ninstead of only taking the greedy one, and then selects the most consistent answer\\nby marginalizing out the sampled reasoning paths. Self-consistency leverages the\\nintuition that a complex reasoning problem typically admits multiple different ways\\nof thinking leading to its unique correct answer. Our extensive empirical evaluation\\nshows that self-consistency boosts the performance of chain-of-thought prompting\\nwith a striking margin on a range of popular arithmetic and commonsense reasoning\\nbenchmarks, including GSM8K (+17.9%), SV AMP (+11.0%), AQuA (+12.2%),\\nStrategyQA (+6.4%) and ARC-challenge (+3.9%).\\n1 I NTRODUCTION\\nAlthough language models have demonstrated remarkable success across a range of NLP tasks, their\\nability to demonstrate reasoning is often seen as a limitation, which cannot be overcome solely by\\nincreasing model scale (Rae et al., 2021; BIG-bench collaboration, 2021, inter alia ). In an effort\\nto address this shortcoming, Wei et al. (2022) have proposed chain-of-thought prompting , where\\na language model is prompted to generate a series of short sentences that mimic the reasoning\\nprocess a person might employ in solving a task. For example, given the question “If there are 3\\ncars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?” , instead\\nof directly responding with “5”, a language model would be prompted to respond with the entire\\nchain-of-thought: “There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 +\\n2 = 5 cars. The answer is 5. ” . It has been observed that chain-of-thought prompting signiﬁcantly\\nimproves model performance across a variety of multi-step reasoning tasks (Wei et al., 2022).\\nIn this paper, we introduce a novel decoding strategy called self-consistency to replace the greedy\\ndecoding strategy used in chain-of-thought prompting (Wei et al., 2022), that further improves\\nlanguage models’ reasoning performance by a signiﬁcant margin. Self-consistency leverages the\\nintuition that complex reasoning tasks typically admit multiple reasoning paths that reach a correct\\nanswer (Stanovich & West, 2000). The more that deliberate thinking and analysis is required for a\\nproblem (Evans, 2010), the greater the diversity of reasoning paths that can recover the answer.\\nFigure 1 illustrates the self-consistency method with an example. We ﬁrst prompt the language model\\nwith chain-of-thought prompting, then instead of greedily decoding the optimal reasoning path, we\\npropose a “sample-and-marginalize” decoding procedure: we ﬁrst sample from the language model’s\\ndecoder to generate a diverse set of reasoning paths; each reasoning path might lead to a different\\nﬁnal answer, so we determine the optimal answer by marginalizing out the sampled reasoning paths\\nto ﬁnd the most consistent answer in the ﬁnal answer set. Such an approach is analogous to the\\nhuman experience that if multiple different ways of thinking lead to the same answer, one has greater\\nconﬁdence that the ﬁnal answer is correct. Compared to other decoding methods, self-consistency\\navoids the repetitiveness and local-optimality that plague greedy decoding, while mitigating the\\nstochasticity of a single sampled generation.\\n1arXiv:2203.11171v4  [cs.CL]  7 Mar 2023' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 0}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nLanguage \\nmodel Q: If there are 3 cars in the parking \\nlot and 2 more cars arrive, how many \\ncars are in the parking lot?\\nA: There are 3 cars in the parking lot \\nalready. 2 more arrive. Now there are \\n3 + 2 = 5 cars. The answer is 5. \\n…\\nQ: Janet’s ducks lay 16 eggs per day. \\nShe eats three for breakfast every \\nmorning and bakes muffins for her \\nfriends every day with four. She sells \\nthe remainder for $2 per egg. How \\nmuch does she make every day? \\nA:She has 16 - 3 - 4 = 9 eggs \\nleft. So she makes $2 * 9 = \\n$18 per day. Sample a diverse set of \\nreasoning paths\\nShe eats 3 for breakfast, so \\nshe has 16 - 3 = 13 left. Then \\nshe bakes muffins, so she \\nhas 13 - 4 = 9 eggs left. So \\nshe has 9 eggs * $2 = $18. This means she she sells the \\nremainder for $2 * (16 - 4 - 3) \\n= $26 per day. The answer is $18. \\nThe answer is $26. \\nThe answer is $18. The answer is $18.Marginalize out reasoning paths \\nto aggregate final answers Language \\nmodel This means she uses 3 + 4 = 7 eggs every day.  \\nShe sells the remainder for $2 per egg, so in \\ntotal she sells 7 * $2 = $14 per day. \\nThe answer is $14. The answer is $14. Greedy decode\\nFigure 1: The self-consistency method contains three steps: (1) prompt a language model using\\nchain-of-thought (CoT) prompting; (2) replace the “greedy decode” in CoT prompting by sampling\\nfrom the language model’s decoder to generate a diverse set of reasoning paths; and (3) marginalize\\nout the reasoning paths and aggregate by choosing the most consistent answer in the ﬁnal answer set.\\nSelf-consistency is far simpler than prior approaches that either train an additional veriﬁer (Cobbe\\net al., 2021) or train a re-ranker given additional human annotations to improve generation quality\\n(Thoppilan et al., 2022). Instead, self-consistency is entirely unsupervised , works off-the-shelf with\\npre-trained language models, requires no additional human annotation, and avoids any additional\\ntraining, auxiliary models or ﬁne-tuning. Self-consistency also differs from a typical ensemble\\napproach where multiple models are trained and the outputs from each model are aggregated, it acts\\nmore like a “self-ensemble” that works on top of a single language model.\\nWe evaluate self-consistency on a wide range of arithmetic and commonsense reasoning tasks over\\nfour language models with varying scales: the public UL2-20B (Tay et al., 2022) and GPT-3-175B\\n(Brown et al., 2020), and two densely-activated decoder-only language models: LaMDA-137B\\n(Thoppilan et al., 2022) and PaLM-540B (Chowdhery et al., 2022). On all four language models,\\nself-consistency improves over chain-of-thought prompting by a striking margin across all tasks. In\\nparticular, when used with PaLM-540B or GPT-3, self-consistency achieves new state-of-the-art levels\\nof performance across arithmetic reasoning tasks, including GSM8K (Cobbe et al., 2021) (+17.9%\\nabsolute accuracy gains), SV AMP (Patel et al., 2021) (+11.0%), AQuA (Ling et al., 2017) (+12.2%),\\nand across commonsense reasoning tasks such as StrategyQA (Geva et al., 2021) (+6.4%) and ARC-\\nchallenge (Clark et al., 2018) (+3.9%). In additional experiments, we show self-consistency can\\nrobustly boost performance on NLP tasks where adding a chain-of-thought might hurt performance\\ncompared to standard prompting (Ye & Durrett, 2022). We also show self-consistency signiﬁcantly\\noutperforms sample-and-rank, beam search, ensemble-based approaches, and is robust to sampling\\nstrategies and imperfect prompts.\\n2 S ELF-CONSISTENCY OVER DIVERSE REASONING PATHS\\nA salient aspect of humanity is that people think differently. It is natural to suppose that in tasks\\nrequiring deliberate thinking, there are likely several ways to attack the problem. We propose that\\nsuch a process can be simulated in language models via sampling from the language model’s decoder.\\nFor instance, as shown in Figure 1, a model can generate several plausible responses to a math\\nquestion that all arrive at the same correct answer (Outputs 1 and 3). Since language models are not\\nperfect reasoners, the model might also produce an incorrect reasoning path or make a mistake in\\none of the reasoning steps (e.g., in Output 2), but such solutions are less likely to arrive at the same\\nanswer. That is, we hypothesize that correct reasoning processes, even if they are diverse, tend to\\nhave greater agreement in their ﬁnal answer than incorrect processes.\\nWe leverage this intuition by proposing the following self-consistency method. First, a language\\nmodel is prompted with a set of manually written chain-of-thought exemplars (Wei et al., 2022). Next,\\n2' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 1}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nGSM8K MultiArith AQuA SV AMP CSQA ARC-c\\nGreedy decode 56.5 94.7 35.8 79.0 79.0 85.2\\nWeighted avg (unnormalized) 56.3 ±0.0 90.5±0.0 35.8±0.073.0±0.074.8±0.082.3±0.0\\nWeighted avg (normalized) 22.1 ±0.0 59.7±0.0 15.7±0.040.5±0.052.1±0.051.7±0.0\\nWeighted sum (unnormalized) 59.9 ±0.0 92.2±0.0 38.2±0.076.2±0.076.2±0.083.5±0.0\\nWeighted sum (normalized) 74.1 ±0.0 99.3±0.0 48.0±0.086.8±0.080.7±0.088.7±0.0\\nUnweighted sum (majority vote) 74.4 ±0.1 99.3±0.0 48.3±0.586.6±0.180.7±0.188.7±0.1\\nTable 1: Accuracy comparison of different answer aggregation strategies on PaLM-540B.\\nwe sample a set of candidate outputs from the language model’s decoder, generating a diverse set of\\ncandidate reasoning paths. Self-consistency is compatible with most existing sampling algorithms,\\nincluding temperature sampling (Ackley et al., 1985; Ficler & Goldberg, 2017), top- ksampling (Fan\\net al., 2018; Holtzman et al., 2018; Radford et al., 2019), and nucleus sampling (Holtzman et al.,\\n2020). Finally, we aggregate the answers by marginalizing out the sampled reasoning paths and\\nchoosing the answer that is the most consistent among the generated answers.\\nIn more detail, assume the generated answers aiare from a ﬁxed answer set, ai∈A, where\\ni= 1, . . . , m indexes the mcandidate outputs sampled from the decoder. Given a prompt and a\\nquestion, self-consistency introduces an additional latent variable ri, which is a sequence of tokens\\nrepresenting the reasoning path in the i-th output, then couples the generation of (ri,ai)where\\nri→ai, i.e., generating a reasoning path riis optional and only used to reach the ﬁnal answer ai. As\\nan example, consider Output 3 from Figure 1: the ﬁrst few sentences “ She eats 3 for breakfast ... So\\nshe has 9 eggs * $2 = $18. ” constitutes ri, while the answer 18from the last sentence, “ The answer\\nis $18 ”, is parsed as ai.1After sampling multiple (ri,ai)from the model’s decoder, self-consistency\\napplies a marginalization over riby taking a majority vote over ai, i.e., arg maxa∑m\\ni=11(ai=a),\\nor as we deﬁned as the most “consistent” answer among the ﬁnal answer set.\\nIn Table 1, we show the test accuracy over a set of reasoning tasks by using different answer\\naggregation strategies. In addition to majority vote, one can also weight each (ri,ai)byP(ri,ai|\\nprompt ,question )when aggregating the answers. Note to compute P(ri,ai|prompt ,question ), we\\ncan either take the unnormalized probability of the model generating (ri,ai)given (prompt ,question ),\\nor we can normalize the conditional probability by the output length (Brown et al., 2020), i.e.,\\nP(ri,ai|prompt ,question ) = exp1\\nK∑K\\nk=1logP(tk|prompt ,question ,t1,...,tk−1), (1)\\nwhere logP(tk|prompt ,question , t1, . . . , t k−1)is the log probability of generating the k-th token\\ntkin(ri,ai)conditioned on the previous tokens, and Kis the total number of tokens in (ri,ai).\\nIn Table 1, we show that taking the “unweighted sum”, i.e., taking a majority vote directly over ai\\nyields a very similar accuracy as aggregating using the “normalized weighted sum”. We took a closer\\nlook at the model’s output probabilities and found this is because for each (ri,ai), the normalized\\nconditional probabilities P(ri,ai|prompt ,question )are quite close to each other, i.e., the language\\nmodel regards those generations as “similarly likely”.2Additionally, when aggregating the answers,\\nthe results in Table 1 show that the “normalized” weighted sum (i.e., Equation 1) yields a much\\nhigher accuracy compared to its unnormalized counterpart. For completeness, in Table 1 we also\\nreport the results by taking a “weighted average”, i.e., each agets a score of its weighted sum divided\\nby∑m\\ni=11(ai=a), which results in a much worse performance.\\nSelf-consistency explores an interesting space between open-ended text generation and optimal\\ntext generation with a ﬁxed answer. Reasoning tasks typically have ﬁxed answers, which is why\\nresearchers have generally considered greedy decoding approaches (Radford et al., 2019; Wei et al.,\\n2022; Chowdhery et al., 2022). However, we have found that even when the desired answer is ﬁxed,\\nintroducing diversity in the reasoning processes can be highly beneﬁcial; therefore we leverage\\n1The parser is task dependent. For arithmetic reasoning, we parse the ﬁrst numerical part as the ﬁnal answer\\nafter the model generates “The answer is ”. For commonsense reasoning, we parse the full string answer as the\\nﬁnal answer after the model generates “The answer is ”. Most generated outputs have a consistent format of\\n“{Reasoning paths}. The answer is X.” if we prompt the language model in this format.\\n2This also means that the language model is not well calibrated and thus cannot distinguish well between\\ncorrect solutions and wrong solutions, which also explains why additional re-rankers were trained to better judge\\nthe quality of the solutions in previous work (Cobbe et al., 2021; Thoppilan et al., 2022).\\n3' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 2}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nsampling, as commonly used for open-ended text generation (Radford et al., 2019; Brown et al., 2020;\\nThoppilan et al., 2022), to achieve this goal. One should note that self-consistency can be applied\\nonly to problems where the ﬁnal answer is from a ﬁxed answer set, but in principle this approach can\\nbe extended to open-text generation problems if a good metric of consistency can be deﬁned between\\nmultiple generations, e.g., whether two answers agree or contradict each other.\\n3 E XPERIMENTS\\nWe conducted a series of experiments to compare the proposed self-consistency method with existing\\napproaches on a range of reasoning benchmarks. We ﬁnd that self-consistency robustly improves\\nreasoning accuracy for every language model considered, spanning a wide range of model scales.\\n3.1 E XPERIMENT SETUP\\nTasks and datasets. We evaluate self-consistency on the following reasoning benchmarks.3\\n•Arithmetic reasoning . For these tasks, we used the Math Word Problem Repository (Koncel-\\nKedziorski et al., 2016), including AddSub (Hosseini et al., 2014), MultiArith (Roy & Roth,\\n2015), and ASDiv (Miao et al., 2020). We also included AQUA-RAT (Ling et al., 2017), a\\nrecently published benchmark of grade-school-math problems (GSM8K; Cobbe et al., 2021),\\nand a challenge dataset over math word problems (SV AMP; Patel et al., 2021).\\n•Commonsense reasoning . For these tasks, we used CommonsenseQA (Talmor et al., 2019),\\nStrategyQA (Geva et al., 2021), and the AI2 Reasoning Challenge (ARC) (Clark et al., 2018).\\n•Symbolic Reasoning . We evaluate two symbolic reasoning tasks: last letter concatenation (e.g.,\\nthe input is “Elon Musk” and the output should be “nk”), and Coinﬂip (e.g., a coin is heads-up,\\nafter a few ﬂips is the coin still heads-up?) from Wei et al. (2022).\\nLanguage models and prompts. We evaluate self-consistency over four transformer-based lan-\\nguage models with varying scales:\\n•UL2 (Tay et al., 2022) is an encoder-decoder model trained on a mixture of denoisers with 20-\\nbillion parameters. UL2 is completely open-sourced4and has similar or better performance than\\nGPT-3 on zero-shot SuperGLUE, with only 20B parameters and thus is more compute-friendly;\\n•GPT-3 (Brown et al., 2020) with 175-billion parameters. We use two public engines code-davinci-\\n001andcode-davinci-002 from the Codex series (Chen et al., 2021) to aid reproducibility;5\\n•LaMDA-137B (Thoppilan et al., 2022) is a dense left-to-right, decoder-only language model with\\n137-billion parameters, pre-trained on a mixture of web documents, dialog data and Wikipedia;\\n•PaLM-540B (Chowdhery et al., 2022) is a dense left-to-right, decoder-only language model with\\n540-billion parameters, pre-trained on a high quality corpus of 780 billion tokens with ﬁltered\\nwebpages, books, Wikipedia, news articles, source code, and social media conversations.\\nWe perform all experiments in the few-shot setting, without training or ﬁne-tuning the language\\nmodels. For a fair comparison we use the same prompts as in Wei et al. (2022): for all arithmetic\\nreasoning tasks we use the same set of 8 manually written exemplars; for each commonsense\\nreasoning task, 4-7 exemplars are randomly chosen from the training set with manually composed\\nchain-of-thought prompts.6Full details on the prompts used are given in Appendix A.3.\\nSampling scheme. To sample diverse reasoning paths, we followed similar settings to those\\nsuggested in Radford et al. (2019); Holtzman et al. (2020) for open-text generation. In particular, for\\nUL2-20B and LaMDA-137B we applied temperature sampling with T= 0.5and truncated at the\\ntop-k(k= 40 ) tokens with the highest probability, for PaLM-540B we applied T= 0.7, k= 40 , and\\nfor GPT-3 we use T= 0.7without top- ktruncation. We provide an ablation study in Section 3.5 to\\nshow that self-consistency is generally robust to sampling strategies and parameters.\\n3By default we use the test split for all datasets if the labels are available for evaluation. For CommonsenseQA\\nwe use the dev split; for StrategyQA we use the question-only set from BIG-bench collaboration (2021):\\nhttps://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/strategyqa .\\n4Model checkpoints at https://github.com/google-research/google-research/tree/master/ul2 .\\n5Public API available at https://openai.com/api/ .\\n6Self-consistency is robust to different sets of prompts and we provide a study in Appendix A.1.2.\\n4' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 3}\n",
      "page_content='Published as a conference paper at ICLR 2023\\n3.2 M AINRESULTS\\nWe report the results of self-consistency averaged over 10 runs, where we sampled 40 outputs\\nindependently from the decoder in each run. The baseline we compare to is chain-of-thought\\nprompting with greedy decoding (Wei et al., 2022), referred to as CoT-prompting , which has been\\npreviously used for decoding in large language models (Chowdhery et al., 2022).\\nArithmetic Reasoning The results are shown in Table 2.7Self-consistency improves the arithmetic\\nreasoning performance over all four language models signiﬁcantly over chain-of-thought prompting.\\nMore surprisingly, the gains become more signiﬁcant when the language model’s scale increases,\\ne.g., we see +3%-6% absolute accuracy improvement over UL2-20B but +9%-23% for LaMDA-\\n137B and GPT-3. For larger models that already achieve high accuracy on most tasks (e.g., GPT-3\\nand PaLM-540B), self-consistency still contributes signiﬁcant additional gains with +12%-18%\\nabsolute accuracy on tasks like AQuA and GSM8K, and +7%-11% on SV AMP and ASDiv. With\\nself-consistency, we achieve new state-of-the-art results on almost all tasks: despite the fact that self-\\nconsistency is unsupervised and task-agnostic, these results compare favorably to existing approaches\\nthat require task-speciﬁc training, or ﬁne-tuning with thousands of examples (e.g., on GSM8K).\\nMethod AddSub MultiArith ASDiv AQuA SV AMP GSM8K\\nPrevious SoTA 94.9a60.5a75.3b37.9c57.4d35e/ 55g\\nUL2-20BCoT-prompting 18.2 10.7 16.9 23.6 12.6 4.1\\nSelf-consistency 24.8 (+6.6) 15.0 (+4.3) 21.5 (+4.6) 26.9 (+3.3) 19.4 (+6.8) 7.3 (+3.2)\\nLaMDA-137BCoT-prompting 52.9 51.8 49.0 17.7 38.9 17.1\\nSelf-consistency 63.5 (+10.6) 75.7 (+23.9) 58.2 (+9.2) 26.8 (+9.1) 53.3 (+14.4) 27.7 (+10.6)\\nPaLM-540BCoT-prompting 91.9 94.7 74.0 35.8 79.0 56.5\\nSelf-consistency 93.7 (+1.8) 99.3 (+4.6) 81.9 (+7.9) 48.3 (+12.5) 86.6 (+7.6) 74.4 (+17.9)\\nGPT-3\\nCode-davinci-001CoT-prompting 57.2 59.5 52.7 18.9 39.8 14.6\\nSelf-consistency 67.8 (+10.6) 82.7 (+23.2) 61.9 (+9.2) 25.6 (+6.7) 54.5 (+14.7) 23.4 (+8.8)\\nGPT-3\\nCode-davinci-002CoT-prompting 89.4 96.2 80.1 39.8 75.8 60.1\\nSelf-consistency 91.6 (+2.2) 100.0 (+3.8) 87.8 (+7.6) 52.0 (+12.2) 86.8 (+11.0) 78.0 (+17.9)\\nTable 2: Arithmetic reasoning accuracy by self-consistency compared to chain-of-thought prompting\\n(Wei et al., 2022). The previous SoTA baselines are obtained from: a: Relevance and LCA operation\\nclassiﬁer (Roy & Roth, 2015), b: Lan et al. (2021), c: Amini et al. (2019), d: Pi et al. (2022), e:\\nGPT-3 175B ﬁnetuned with 7.5k examples (Cobbe et al., 2021), g: GPT-3 175B ﬁnetuned plus an\\nadditional 175B veriﬁer (Cobbe et al., 2021). The best performance for each task is shown in bold.\\nMethod CSQA StrategyQA ARC-e ARC-c Letter (4) Coinﬂip (4)\\nPrevious SoTA 91.2a73.9b86.4c75.0cN/A N/A\\nUL2-20BCoT-prompting 51.4 53.3 61.6 42.9 0.0 50.4\\nSelf-consistency 55.7 (+4.3) 54.9 (+1.6) 69.8 (+8.2) 49.5 (+6.8) 0.0 (+0.0) 50.5 (+0.1)\\nLaMDA-137BCoT-prompting 57.9 65.4 75.3 55.1 8.2 72.4\\nSelf-consistency 63.1 (+5.2) 67.8 (+2.4) 79.3 (+4.0) 59.8 (+4.7) 8.2 (+0.0) 73.5 (+1.1)\\nPaLM-540BCoT-prompting 79.0 75.3 95.3 85.2 65.8 88.2\\nSelf-consistency 80.7 (+1.7) 81.6 (+6.3) 96.4 (+1.1) 88.7 (+3.5) 70.8 (+5.0) 91.2 (+3.0)\\nGPT-3\\nCode-davinci-001CoT-prompting 46.6 56.7 63.1 43.1 7.8 71.4\\nSelf-consistency 54.9 (+8.3) 61.7 (+5.0) 72.1 (+9.0) 53.7 (+10.6) 10.0 (+2.2) 75.9 (+4.5)\\nGPT-3\\nCode-davinci-002CoT-prompting 79.0 73.4 94.0 83.6 70.4 99.0\\nSelf-consistency 81.5 (+2.5) 79.8 (+6.4) 96.0 (+2.0) 87.5 (+3.9) 73.4 (+3.0) 99.5 (+0.5)\\nTable 3: Commonsense and symbolic reasoning accuracy by self-consistency compared to chain-\\nof-thought prompting (Wei et al., 2022). The previous SoTA baselines are obtained from: a:\\nDeBERTaV3-large + KEAR (Xu et al., 2021b), b: Chowdhery et al. (2022), c: UniﬁedQA-FT\\n(Khashabi et al., 2020). The best performance for each task is shown in bold.\\n7The standard deviation of self-consistency is ≤0.5for all tasks and is thus omitted in the table. Please refer\\nto Figure 2, Figure 7 and 8 for the standard deviations under varying numbers of sampled paths.\\n5' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 4}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nCommonsense and Symbolic Reasoning Table 3 shows the results on commonsense and symbolic\\nreasoning tasks. Similarly, self-consistency yields large gains across all four language models, and\\nobtained SoTA results on 5 out of 6 tasks. For symbolic reasoning, we test the out-of-distribution\\n(OOD) setting where the input prompt contains examples of 2-letters or 2-ﬂips but we test examples\\nof 4-letters and 4-ﬂips (this setting is more challenging as PaLM-540B or GPT-3 can already achieve\\nperfect in-distribution accuracy). In this challenging OOD setting, the gain of self-consistency is still\\nquite signiﬁcant compared to CoT-prompting with sufﬁcient model sizes.\\nTo show the effect of the number of sampled reasoning paths, we plot the accuracy (mean and\\nstandard deviation over 10 runs) with respect to varying numbers of sampled paths (1, 5, 10, 20, 40)\\nin Figure 2. The results show that sampling a higher number (e.g., 40) of reasoning paths leads to a\\nconsistently better performance, further emphasizing the importance of introducing diversity in the\\nreasoning paths. In Table 4, we show self-consistency yields a richer set of reasoning paths compared\\nto greedy decoding with a few example questions from two tasks.\\n0510152025303540\\n#Sampled Reasoning Paths505560657075Accuracy (%)\\nMultiArith\\n0510152025303540\\n#Sampled Reasoning Paths3336394245485154\\nSVAMP\\n0510152025303540\\n#Sampled Reasoning Paths56586062\\nCommonsense QA\\n0510152025303540\\n#Sampled Reasoning Paths505254565860\\nARC (Challenge)\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\nFigure 2: Self-consistency (blue) signiﬁcantly improves accuracy over CoT-prompting with greedy\\ndecoding (orange) across arithmetic and commonsense reasoning tasks, over LaMDA-137B. Sampling\\na higher number of diverse reasoning paths consistently improves reasoning accuracy.\\nGSM8K StrategyQA\\nQuestion Henry made two stops during his 60-mile bike trip. He ﬁrst stopped after 20\\nmiles. His second stop was 15 miles before the end of the trip. How many miles\\ndid he travel between his ﬁrst and second stops?Yes or no: Is Albany, Georgia the most populous\\nUS Albany?\\nGreedy\\nDecodeHe traveled 60 miles in total. He stopped after 20 miles, so he traveled 60 - 20\\n= 40 miles between the ﬁrst and second stops. The answer is 40.Albany, Georgia is the most populous US Al-\\nbany. Thus, the answer is yes.\\nSampled\\nPath 1Henry travelled a total of 60 miles. His ﬁrst stop was 20 miles in, and his\\nsecond stop was 15 miles before the end. So between his ﬁrst and second stops\\nhe travelled 60 - 20 -15 = 25 miles. The answer is 25.The most populous US Albany is Albany, New\\nYork. Thus, Albany, Georgia is not the most\\npopulous US Albany. So the answer is no.\\nSampled\\nPath 2He made two stops during a 60-mile trip. The ﬁrst was 20 miles into the trip.\\nThe second was 15 miles before the end of the trip. This means the second stop\\nwas 60 - 15 = 45 miles into the trip. Since he made the stops in order, the second\\nstop must have been 45 - 20 = 25 miles after the ﬁrst stop. The answer is 25.Albany, Georgia has a population of about\\n88,000. Albany, New York has a population of\\nabout 95,000. Thus, Albany, Georgia is not the\\nmost populous US Albany. So the answer is no.\\nTable 4: Examples where self-consistency helps repair the errors over greedy decode, on PaLM-540B.\\nTwo sampled reasoning paths that are consistent with the ground truth are shown.\\n3.3 S ELF-CONSISTENCY HELPS WHEN CHAIN -OF-THOUGHT HURTS PERFORMANCE\\nYe & Durrett (2022) show that sometimes chain-of-thought prompting could hurt performance\\ncompared to standard prompting in few-shot in-context learning. Here we perform a study using\\nself-consistency to see if it can help ﬁll in the gap, over a set of common NLP tasks, including (1)\\nClosed-Book Question Answering: BoolQ (Clark et al., 2019), HotpotQA (Yang et al., 2018), and\\n(2) Natural Language Inference: e-SNLI (Camburu et al., 2018), ANLI (Nie et al., 2020) and RTE\\n(Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009).\\nThe results over PaLM-540B are shown in Table 5. For some tasks (e.g., ANLI-R1, e-SNLI, RTE),\\nadding chain-of-thought does hurt performance compared to standard prompting (Brown et al., 2020),\\nbut self-consistency is able to robustly boost the performance and outperform standard prompting,\\nmaking it a reliable way to add rationales in few-shot in-context learning for common NLP tasks.\\nANLI R1 / R2 / R3 e-SNLI RTE BoolQ HotpotQA (EM/F1)\\nStandard-prompting (no-rationale) 69.1 / 55.8 / 55.8 85.8 84.8 71.3 27.1 / 36.8\\nCoT-prompting (Wei et al., 2022) 68.8 / 58.9 / 60.6 81.0 79.1 74.2 28.9 / 39.8\\nSelf-consistency 78.5 /64.5 /63.4 88.4 86.3 78.4 33.8 / 44.6\\nTable 5: Compare Standard/CoT prompting with self-consistency on common NLP tasks.\\n6' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 5}\n",
      "page_content='Published as a conference paper at ICLR 2023\\n3.4 C OMPARE TO OTHER EXISTING APPROACHES\\nWe conduct a set of additional studies and show that self-consistency signiﬁcantly outperforms\\nexisting methods including sample-and-rank, beam search, and ensemble-based approaches.\\nComparison to Sample-and-Rank One commonly used approach to improve generation quality is\\nsample-and-rank, where multiple sequences are sampled from the decoder and then ranked according\\nto each sequence’s log probability (Adiwardana et al., 2020). We compare self-consistency with\\nsample-and-rank on GPT-3 code-davinci-001 , by sampling the same number of sequences from the\\ndecoder as self-consistency and taking the ﬁnal answer from the top-ranked sequence. The results are\\nshown in Figure 3. While sample-and-rank does improve the accuracy with additionally sampled\\nsequences and ranking, the gain is much smaller compared to self-consistency.\\n0510152025303540\\n#Sampled Reasoning Paths12141618202224Accuracy (%)\\nGSM8K\\n0510152025303540\\n#Sampled Reasoning Paths50556065707580Accuracy (%)\\nMultiArith\\n0510152025303540\\n#Sampled Reasoning Paths303540455055Accuracy (%)\\nARC (Challenge)\\nSelf Consistency (Multi-path)\\nSample & Rank (Multi-path)\\nGreedy Decode (Single-path)\\nFigure 3: Self-consistency signiﬁcantly outperforms sample-and-rank with the same # of samples.\\nComparison to Beam Search In Table 6, we compare self-consistency with beam search decoding\\non the UL2-20B model. For a fair comparison we report the accuracy under the same number of\\nbeams and reasoning paths. On both tasks self-consistency outperforms beam search signiﬁcantly.\\nNote self-consistency can also adopt beam search to decode each reasoning path (results are shown\\nas “Self-consistency using beam search”), but its performance is worse compared to self-consistency\\nwith sampling. The reason is that beam search yields a lower diversity in the outputs (Li & Jurafsky,\\n2016), while in self-consistency the diversity of the reasoning paths is the key to a better performance.\\nBeam size / Self-consistency paths 1 5 10 20 40\\nAQuABeam search decoding (top beam) 23.6 19.3 16.1 15.0 10.2\\nSelf-consistency using beam search 23.6 19.8 ±0.321.2±0.724.6±0.424.2±0.5\\nSelf-consistency using sampling 19.7 ±2.524.9±2.625.3±1.826.7±1.026.9±0.5\\nMultiArithBeam search decoding (top beam) 10.7 12.0 11.3 11.0 10.5\\nSelf-consistency using beam search 10.7 11.8 ±0.011.4±0.112.3±0.110.8±0.1\\nSelf-consistency using sampling 9.5 ±1.2 11.3±1.212.3±0.813.7±0.914.7±0.3\\nTable 6: Compare self-consistency with beam search decoding on the UL2-20B model.\\nComparison to Ensemble-based Approaches We further compare self-consistency to ensemble-\\nbased methods for few-shot learning. In particular, we consider ensembling by: (1) prompt order\\npermutation: we randomly permute the exemplars in the prompt 40 times to mitigate model’s\\nsensitivity to prompt order (Zhao et al., 2021; Lu et al., 2021); and (2) multiple sets of prompts\\n(Gao et al., 2021): we manually write 3different sets of prompts. We took majority vote of the\\nanswers from greedy decoding in both approaches as an ensemble. Table 7 shows that compared to\\nself-consistency, existing ensemble-based approaches achieve a much smaller gain.8In addition, note\\nthat self-consistency is different from a typical model-ensemble approach, where multiple models\\nare trained and their outputs are aggregated. Self-consistency acts more like a “self-ensemble” on\\ntop of a single language model. We additionally show the results of ensembling multiple models in\\nAppendix A.1.3 where the model-ensembles perform much worse compared to self-consistency.\\nGSM8K MultiArith SV AMP ARC-e ARC-c\\nCoT (Wei et al., 2022) 17.1 51.8 38.9 75.3 55.1\\nEnsemble (3 sets of prompts) 18.6 ±0.5 57.1±0.7 42.1±0.6 76.6±0.1 57.0±0.2\\nEnsemble (40 prompt permutations) 19.2 ±0.1 60.9±0.2 42.7±0.1 76.9±0.1 57.0±0.1\\nSelf-Consistency (40 sampled paths) 27.7±0.2 75.7±0.3 53.3±0.2 79.3±0.3 59.8±0.2\\nTable 7: Self-consistency outperforms prompt-order and multi-prompt ensembles on LaMDA-137B.\\n8Self-consistency is compatible with both ensemble approaches and we show the results in Appendix A.1.4.\\n7' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 6}\n",
      "page_content='Published as a conference paper at ICLR 2023\\n3.5 A DDITIONAL STUDIES\\nWe conducted a number of additional experiments to analyze different aspects of the self-consistency\\nmethod, including its robustness to sampling strategies and parameters, and how it works with\\nimperfect prompts and non-natural-language reasoning paths.\\nSelf-Consistency is Robust to Sampling Strategies and Scaling We show self-consistency is\\nrobust to sampling strategies and parameters, by varying Tin temperature sampling (Ackley et al.,\\n1985; Ficler & Goldberg, 2017), kin top- ksampling (Fan et al., 2018; Holtzman et al., 2018; Radford\\net al., 2019), and pin nucleus sampling (Holtzman et al., 2020), over PaLM-540B in Figure 4 (left).\\nFigure 4 (right) shows that self-consistency robustly improves performance across all scales for the\\nLaMDA-137B model series. The gain is relatively lower for smaller models due to certain abilities\\n(e.g., arithmetic) only emerge when the model reaches a sufﬁcient scale (Brown et al., 2020).\\n0510152025303540\\n#Sampled Reasoning Paths444852566064687276Accuracy (%)\\nT=0.7, k=40\\nT=0.5, k=40\\nT=0.3, k=40\\nT=0.7, k=20\\nT=0.7, no top k\\np=0.95\\np=0.9\\nGreedy Decode\\n12 51020 50100200\\nModel size (#param in billions)510152025Accuracy (%)\\nSelf Consistency\\nGreedy Decode\\nFigure 4: GSM8K accuracy. (Left) Self-consistency is robust to various sampling strategies and\\nparameters. (Right) Self-consistency improves performance across language model scales.\\nSelf-Consistency Improves Robustness to Imperfect Prompts For few-shot learning with man-\\nually constructed prompts, human annotators sometimes make minor mistakes when creating the\\nprompts. We further study if self-consistency can help improve a language model’s robustness to\\nimperfect prompts.9We show the results in Table 8: while imperfect prompts decrease accuracy with\\ngreedy decoding (17.1 →14.9), self-consistency can ﬁll in the gaps and robustly improve the results.\\nAdditionally, we found that the consistency (in terms of % of decodes agreeing with the ﬁnal\\naggregated answer) is highly correlated with accuracy (Figure 5, over GSM8K). This suggests that\\none can use self-consistency to provide an uncertainty estimate of the model in its generated solutions.\\nIn other words, one can use low consistency as an indicator that the model has low conﬁdence; i.e.,\\nself-consistency confers some ability for the model to “know when it doesn’t know”.\\nLaMDA-137BPrompt with correct chain-of-thought 17.1\\nPrompt with imperfect chain-of-thought 14.9\\n+ Self-consistency (40 paths) 23.4\\nPrompt with equations 5.0\\n+ Self-consistency (40 paths) 6.5\\nPaLM-540BZero-shot CoT (Kojima et al., 2022) 43.0\\n+ Self-consistency (40 paths) 69.2\\nTable 8: Self-consistency works under imperfect prompts, equa-\\ntion prompts and zero-shot chain-of-thought for GSM8K.\\n0 20 40 60 80 100\\nConsistency (%)020406080100Accuracy (%)\\nFigure 5: The consistency is cor-\\nrelated with model’s accuracy.\\nSelf-Consistency Works for Non-Natural-Language Reasoning Paths and Zero-shot CoT We\\nalso tested the generality of the self-consistency concept to alternative forms of intermediate reasoning\\nlike equations (e.g., from “ There are 3 cars in the parking lot already. 2 more arrive. Now there\\nare 3 + 2 = 5 cars. ” to “ 3 + 2 = 5 ”). The results are shown in Table 8 (“Prompt with equations”):\\nself-consistency still improves accuracy by generating intermediate equations; however, compared to\\ngenerating natural language reasoning paths, the gain is smaller since the equations are much shorter\\nand less opportunity remains for generating diversity in the decoding process. In addition, we tested\\nself-consistency with zero-shot chain-of-thought (Kojima et al., 2022) and show that self-consistency\\nworks for zero-shot CoT as well and improves the results signiﬁcantly (+26.2%) in Table 8.\\n9We use the same prompts as before, but swap all the numbers in the reasoning paths with random numbers\\nexcept the ﬁnal answer, e.g., from “ There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 +\\n2 = 5 cars. ” to “ There are 7 cars in the parking lot already. 6 more arrive. Now there are 7 + 6 = 5 cars. ”.\\n8' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 7}\n",
      "page_content='Published as a conference paper at ICLR 2023\\n4 R ELATED WORK\\nReasoning in language models. Language models are known to struggle in Type 2 tasks, such as\\narithmetic, logical and commonsense reasoning (Evans, 2010). Previous work has primarily focused\\nonspecialized approaches for improving reasoning (Andor et al., 2019; Ran et al., 2019; Geva et al.,\\n2020; Pi˛ ekos et al., 2021). Compared to prior work, self-consistency is applicable to a wide range of\\nreasoning tasks without any additional supervision or ﬁne-tuning, while still substantially improving\\nthe performance of the chain-of-thought prompting approach proposed in Wei et al. (2022).\\nSampling and re-ranking in language models. Multiple decoding strategies for language models\\nhave been proposed in the literature, e.g., temperature sampling (Ackley et al., 1985; Ficler &\\nGoldberg, 2017), top- ksampling (Fan et al., 2018; Holtzman et al., 2018; Radford et al., 2019),\\nnucleus sampling (Holtzman et al., 2020), minimum Bayes risk decoding (Eikema & Aziz, 2020; Shi\\net al., 2022), and typical decoding (Meister et al., 2022). Other work has sought to explicitly promote\\ndiversity in the decoding process (Batra et al., 2012; Li et al., 2016; Vijayakumar et al., 2018).\\nRe-ranking is another common approach to improve generation quality in language models (Adiwar-\\ndana et al., 2020; Shen et al., 2021). Thoppilan et al. (2022) collect additional human annotations\\nto train a re-ranker for response ﬁltering. Cobbe et al. (2021) train a “veriﬁer” to re-rank generated\\nsolutions, which substantially improves the solve rate on math tasks compared to just ﬁne-tuning the\\nlanguage model. Elazar et al. (2021) improve the consistency of factual knowledge extraction by\\nextending pre-training with an additional consistency loss. All these methods require either training\\nan additional re-ranker or collecting additional human annotation, while self-consistency requires no\\nadditional training, ﬁne-tuning, nor extra data collection.\\nExtract reasoning paths. Some previous work has considered task-speciﬁc approaches for iden-\\ntifying reasoning paths, such as constructing semantic graphs (Xu et al., 2021a), learning an RNN\\nto retrieve reasoning paths over the Wikipedia graph (Asai et al., 2020), ﬁne-tuning with human\\nannotated reasoning paths on math problems (Cobbe et al., 2021), or training an extractor with\\nheuristic-based pseudo reasoning paths (Chen et al., 2019). More recently, the importance of di-\\nversity in the reasoning processes has been noticed, but only leveraged via task-speciﬁc training,\\neither through an additional QA model over extracted reasoning paths (Chen et al., 2019), or by the\\nintroduction of latent variables in a commonsense knowledge graph (Yu et al., 2022). Compared to\\nthese approaches, self-consistency is far simpler and requires no additional training. The approach\\nwe propose simply couples the generation of reasoning paths and a ﬁnal answer by sampling from\\nthe decoder, using aggregation to recover the most consistent answer without additional modules.\\nConsistency in language models. Some prior work has shown that language models can suffer\\nfrom inconsistency in conversation (Adiwardana et al., 2020), explanation generation (Camburu et al.,\\n2020), and factual knowledge extraction (Elazar et al., 2021). Welleck et al. (2020) use “consistency”\\nto refer to generating an inﬁnite-length sequence in recurrent language models. Nye et al. (2021)\\nimprove the logical consistency of samples from a System 1 model by adding a System 2-inspired\\nlogical reasoning module. In this paper we focus on a slightly different notion of “consistency”, i.e.,\\nutilizing answer consistency among diverse reasoning paths to improve accuracy.\\n5 C ONCLUSION AND DISCUSSION\\nWe introduced a simple yet effective method called self-consistency, and observed that it signiﬁcantly\\nimproves accuracy in a range of arithmetic and commonsense reasoning tasks, across four large\\nlanguage models with varying scales. Beyond accuracy gains, self-consistency is also useful for\\ncollecting rationales when performing reasoning tasks with language models, and for providing\\nuncertainty estimates and improved calibration of language model outputs.\\nOne limitation of self-consistency is that it incurs more computation cost. In practice people can try a\\nsmall number of paths (e.g., 5 or 10) as a starting point to realize most of the gains while not incurring\\ntoo much cost, as in most cases the performance saturates quickly (Figure 2). As part of future work,\\none could use self-consistency to generate better supervised data to ﬁne-tune the model, such that the\\nmodel can give more accurate predictions in a single inference run after ﬁne-tuning. In addition, we\\nobserved that language models can sometimes generate incorrect or nonsensical reasoning paths (e.g.,\\nthe StrategyQA example in Table 4, the two population numbers are not exactly correct), and further\\nwork is needed to better ground models’ rationale generations.\\n9' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 8}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nREPRODUCIBILITY STATEMENT\\nIn experiments, we included four different language models with varying scales. Two of them are pub-\\nlic models: UL2 is a completely open-sourced model with model checkpoints available at https://\\ngithub.com/google-research/google-research/tree/master/ul2 ; GPT-3 is\\nalso a public model with public API available at https://openai.com/api/ . For GPT-3,\\nwe have included two public engines (“code-davinci-001” and “code-davinci-002”) to further aid\\nreproducibility, as Codex is currently free so anyone can reproduce the results. In addition, as our\\nresults make use of LaMDA-137B and PaLM-540B that are not publicly available, we provide the\\nexact input prompts for all tasks in Appendix A.3 (and note that we do not perform any ﬁnetuning\\nand only apply prompting to off-the-shelf language models).\\nETHICS STATEMENT\\nAs we stated in the discussion, language models can sometimes generate nonsensical or non-factual\\nreasoning paths, so one should use language models’ outputs with extra caution. We deal with\\nreasoning tasks mostly and the generated rationales are only used for inspecting how a model reaches\\nits answer. One could potentially use the generated rationales to further check why the model makes\\ncertain mistakes or whether the model contains any biases when performing a certain task. For\\nlanguage model in real-world use, further work is needed to better ground models’ predictions and\\nimprove model’s factuality and safety, to ensure the models do not cause harms to users.\\nREFERENCES\\nDavid H. Ackley, Geoffrey E. Hinton, and Terrence J. Sejnowski. A learning algorithm for boltzmann\\nmachines. Cognitive Science , 9(1):147–169, 1985. ISSN 0364-0213. URL https://www.\\nsciencedirect.com/science/article/pii/S0364021385800124 .\\nDaniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel, Romal Thoppilan,\\nZi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, and Quoc V . Le. Towards a human-like\\nopen-domain chatbot, 2020.\\nAida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh\\nHajishirzi. MathQA: Towards interpretable math word problem solving with operation-based\\nformalisms. In Proceedings of the 2019 Conference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long\\nand Short Papers) , pp. 2357–2367. Association for Computational Linguistics, June 2019. URL\\nhttps://aclanthology.org/N19-1245 .\\nDaniel Andor, Luheng He, Kenton Lee, and Emily Pitler. Giving BERT a calculator: Finding\\noperations and arguments with reading comprehension. In Proceedings of the 2019 Conference on\\nEmpirical Methods in Natural Language Processing and the 9th International Joint Conference\\non Natural Language Processing (EMNLP-IJCNLP) , 2019. URL https://aclanthology.\\norg/D19-1609 .\\nAkari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, and Caiming Xiong. Learn-\\ning to retrieve reasoning paths over wikipedia graph for question answering. In International\\nConference on Learning Representations , 2020. URL https://openreview.net/forum?\\nid=SJgVHkrYDH .\\nRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and\\nIdan Szpektor. The second pascal recognising textual entailment challenge. In Proceedings of the\\nsecond PASCAL challenges workshop on recognising textual entailment , 2006.\\nDhruv Batra, Payman Yadollahpour, Abner Guzman-Rivera, and Gregory Shakhnarovich. Diverse\\nm-best solutions in markov random ﬁelds. In Proceedings of the 12th European Conference on\\nComputer Vision - Volume Part V , ECCV’12, pp. 1–16, Berlin, Heidelberg, 2012. Springer-Verlag.\\nISBN 9783642337147. URL https://doi.org/10.1007/978-3-642-33715-4_1 .\\n10' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 9}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nLuisa Bentivogli, Peter Clark, Ido Dagan, and Danilo Giampiccolo. The ﬁfth pascal recognizing\\ntextual entailment challenge. In TAC, 2009.\\nBIG-bench collaboration. Beyond the imitation game: Measuring and extrapolating the capabil-\\nities of language models. In preparation , 2021. URL https://github.com/google/\\nBIG-bench/ .\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\\nHerbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,\\nJeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\\nand Dario Amodei. Language models are few-shot learners. In Advances in Neural Information\\nProcessing Systems , 2020. URL https://proceedings.neurips.cc/paper/2020/\\nfile/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf .\\nOana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom. e-\\nsnli: Natural language inference with natural language explanations. In S. Ben-\\ngio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett\\n(eds.), Advances in Neural Information Processing Systems 31 , pp. 9539–9549.\\nCurran Associates, Inc., 2018. URL http://papers.nips.cc/paper/\\n8163-e-snli-natural-language-inference-with-natural-language-explanations.\\npdf.\\nOana-Maria Camburu, Brendan Shillingford, Pasquale Minervini, Thomas Lukasiewicz, and Phil\\nBlunsom. Make up your mind! adversarial generation of inconsistent natural language explanations.\\nInProceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pp.\\n4157–4165, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.\\nacl-main.382. URL https://aclanthology.org/2020.acl-main.382 .\\nJifan Chen, Shih-Ting Lin, and Greg Durrett. Multi-hop question answering via reasoning chains.\\nCoRR , abs/1910.02610, 2019. URL http://arxiv.org/abs/1910.02610 .\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\\nKaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large\\nlanguage models trained on code. arXiv preprint arXiv:2107.03374 , 2021.\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\\nKensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\\nShazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\\nBradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\\nskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\\nRobinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph,\\nAlexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M.\\nDai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon\\nChild, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean,\\nSlav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways, 2022. URL\\nhttps://arxiv.org/abs/2204.02311 .\\nChristopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina\\nToutanova. Boolq: Exploring the surprising difﬁculty of natural yes/no questions. In NAACL ,\\n2019.\\nPeter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and\\nOyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge.\\nArXiv , abs/1803.05457, 2018.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\\nMatthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John\\nSchulman. Training veriﬁers to solve math word problems, 2021.\\n11' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 10}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nIdo Dagan, Oren Glickman, and Bernardo Magnini. The pascal recognising textual entailment\\nchallenge. In Machine Learning Challenges Workshop , pp. 177–190. Springer, 2005.\\nBryan Eikema and Wilker Aziz. Is MAP decoding all you need? the inadequacy of the mode in neural\\nmachine translation. In Proceedings of the 28th International Conference on Computational Lin-\\nguistics , pp. 4506–4520, Barcelona, Spain (Online), December 2020. International Committee on\\nComputational Linguistics. URL https://aclanthology.org/2020.coling-main.\\n398.\\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich\\nSchütze, and Yoav Goldberg. Measuring and improving consistency in pretrained language\\nmodels. Transactions of the Association for Computational Linguistics , 9:1012–1031, 2021. doi:\\n10.1162/tacl_a_00410. URL https://aclanthology.org/2021.tacl-1.60 .\\nJonathan St BT Evans. Intuition and reasoning: A dual-process perspective. Psychological Inquiry ,\\n21(4):313–326, 2010.\\nAngela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. In Proceedings\\nof the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long\\nPapers) , pp. 889–898, Melbourne, Australia, July 2018. Association for Computational Linguistics.\\ndoi: 10.18653/v1/P18-1082. URL https://aclanthology.org/P18-1082 .\\nJessica Ficler and Yoav Goldberg. Controlling linguistic style aspects in neural language generation. In\\nProceedings of the Workshop on Stylistic Variation , pp. 94–104, Copenhagen, Denmark, September\\n2017. Association for Computational Linguistics. doi: 10.18653/v1/W17-4912. URL https:\\n//aclanthology.org/W17-4912 .\\nTianyu Gao, Adam Fisch, and Danqi Chen. Making pre-trained language models better few-shot\\nlearners. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguis-\\ntics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long\\nPapers) , pp. 3816–3830, Online, August 2021. Association for Computational Linguistics. doi:\\n10.18653/v1/2021.acl-long.295. URL https://aclanthology.org/2021.acl-long.\\n295.\\nMor Geva, Ankit Gupta, and Jonathan Berant. Injecting numerical reasoning skills into language\\nmodels. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguis-\\ntics, 2020. doi: 10.18653/v1/2020.acl-main.89. URL https://aclanthology.org/2020.\\nacl-main.89 .\\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle\\nuse a laptop? A question answering benchmark with implicit reasoning strategies. Transactions of\\nthe Association for Computational Linguistics , 2021. URL https://aclanthology.org/\\n2021.tacl-1.21 .\\nDanilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. The third pascal recognizing\\ntextual entailment challenge. In Proceedings of the ACL-PASCAL workshop on textual entailment\\nand paraphrasing , pp. 1–9. Association for Computational Linguistics, 2007.\\nAri Holtzman, Jan Buys, Maxwell Forbes, Antoine Bosselut, David Golub, and Yejin Choi. Learning\\nto write with cooperative discriminators. In Proceedings of the 56th Annual Meeting of the\\nAssociation for Computational Linguistics (Volume 1: Long Papers) , pp. 1638–1649, Melbourne,\\nAustralia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1152.\\nURLhttps://aclanthology.org/P18-1152 .\\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. The curious case of neural text\\ndegeneration. In International Conference on Learning Representations , 2020. URL https:\\n//openreview.net/forum?id=rygGQyrFvH .\\nMohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. Learning to\\nsolve arithmetic word problems with verb categorization. In Proceedings of the 2014 Conference on\\nEmpirical Methods in Natural Language Processing (EMNLP) , 2014. doi: 10.3115/v1/D14-1058.\\nURLhttps://aclanthology.org/D14-1058 .\\n12' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 11}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nDaniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, and Han-\\nnaneh Hajishirzi. UNIFIEDQA: Crossing format boundaries with a single QA system. In Findings\\nof the Association for Computational Linguistics: EMNLP 2020 , pp. 1896–1907, Online, Novem-\\nber 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.ﬁndings-emnlp.171.\\nURLhttps://aclanthology.org/2020.findings-emnlp.171 .\\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\\nlanguage models are zero-shot reasoners. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave,\\nand Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems , 2022. URL\\nhttps://openreview.net/forum?id=e2TBb5y0yFf .\\nRik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. MAWPS:\\nA math word problem repository. In Proceedings of the 2016 Conference of the North American\\nChapter of the Association for Computational Linguistics: Human Language Technologies , 2016.\\ndoi: 10.18653/v1/N16-1136. URL https://aclanthology.org/N16-1136 .\\nYihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,\\nand Ee-Peng Lim. MWPToolkit: An open-source framework for deep learning-based math word\\nproblem solvers. arXiv preprint arXiv:2109.00799 , 2021. URL https://arxiv.org/abs/\\n2109.00799 .\\nJiwei Li and Dan Jurafsky. Mutual information and diverse decoding improve neural machine\\ntranslation, 2016. URL https://arxiv.org/abs/1601.00372 .\\nJiwei Li, Will Monroe, and Dan Jurafsky. A simple, fast diverse decoding algorithm for neural\\ngeneration. CoRR , abs/1611.08562, 2016. URL http://arxiv.org/abs/1611.08562 .\\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale genera-\\ntion: Learning to solve and explain algebraic word problems. In Proceedings of the 55th Annual\\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers) , 2017. doi:\\n10.18653/v1/P17-1015. URL https://aclanthology.org/P17-1015 .\\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. Fantastically\\nordered prompts and where to ﬁnd them: Overcoming few-shot prompt order sensitivity. ArXiv ,\\nabs/2104.08786, 2021.\\nClara Meister, Tiago Pimentel, Gian Wiher, and Ryan Cotterell. Typical decoding for natural language\\ngeneration. arXiv preprint arXiv:2202.00666 , 2022.\\nShen Yun Miao, Chao Chun Liang, and Keh Yih Su. A diverse corpus for evaluating and developing\\nEnglish math word problem solvers. In Proceedings of the 58th Annual Meeting of the Asso-\\nciation for Computational Linguistics , 2020. URL https://aclanthology.org/2020.\\nacl-main.92 .\\nYixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. Adver-\\nsarial NLI: A new benchmark for natural language understanding. In Proceedings of the 58th\\nAnnual Meeting of the Association for Computational Linguistics . Association for Computational\\nLinguistics, 2020.\\nMaxwell Nye, Michael Henry Tessler, Joshua B. Tenenbaum, and Brenden M. Lake. Improving\\ncoherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning.\\nIn A. Beygelzimer, Y . Dauphin, P. Liang, and J. Wortman Vaughan (eds.), Advances in Neural\\nInformation Processing Systems , 2021. URL https://openreview.net/forum?id=\\nuyKk_avJ-p4 .\\nArkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve simple\\nmath word problems? In Proceedings of the 2021 Conference of the North American Chapter of\\nthe Association for Computational Linguistics: Human Language Technologies , pp. 2080–2094,\\nOnline, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.\\n168. URL https://aclanthology.org/2021.naacl-main.168 .\\nXinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and\\nWeizhu Chen. Reasoning like program executors, 2022.\\n13' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 12}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nPiotr Pi˛ ekos, Mateusz Malinowski, and Henryk Michalewski. Measuring and improving BERT’s\\nmathematical abilities by predicting the order of reasoning. In Proceedings of the 59th Annual Meet-\\ning of the Association for Computational Linguistics and the 11th International Joint Conference on\\nNatural Language Processing (Volume 2: Short Papers) , 2021. doi: 10.18653/v1/2021.acl-short.49.\\nURLhttps://aclanthology.org/2021.acl-short.49 .\\nAlec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language\\nmodels are unsupervised multitask learners. 2019.\\nJack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John\\nAslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. Scaling language models:\\nMethods, analysis & insights from training gopher. arXiv preprint arXiv:2112.11446 , 2021.\\nQiu Ran, Yankai Lin, Peng Li, Jie Zhou, and Zhiyuan Liu. NumNet: Machine reading comprehension\\nwith numerical reasoning. In Proceedings of the 2019 Conference on Empirical Methods in Natural\\nLanguage Processing and the 9th International Joint Conference on Natural Language Processing\\n(EMNLP-IJCNLP) , 2019. doi: 10.18653/v1/D19-1251. URL https://aclanthology.\\norg/D19-1251 .\\nSubhro Roy and Dan Roth. Solving general arithmetic word problems. In Proceedings of the 2015\\nConference on Empirical Methods in Natural Language Processing , 2015. doi: 10.18653/v1/\\nD15-1202. URL https://aclanthology.org/D15-1202 .\\nJianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, and Qun Liu. Generate\\n& rank: A multi-task framework for math word problems. In Findings of the Association for\\nComputational Linguistics: EMNLP 2021 , pp. 2269–2279, Punta Cana, Dominican Republic,\\nNovember 2021. Association for Computational Linguistics. URL https://aclanthology.\\norg/2021.findings-emnlp.195 .\\nFreda Shi, Daniel Fried, Marjan Ghazvininejad, Luke Zettlemoyer, and Sida I. Wang. Natural\\nlanguage to code translation with execution. In Proceedings of the 2022 Conference on Empirical\\nMethods in Natural Language Processing , pp. 3533–3546, Abu Dhabi, United Arab Emirates,\\nDecember 2022. Association for Computational Linguistics. URL https://aclanthology.\\norg/2022.emnlp-main.231 .\\nKeith E Stanovich and Richard F West. Individual differences in reasoning: Implications for\\nthe rationality debate? Behavioral and brain sciences , 23(5):645–665, 2000. URL https:\\n//pubmed.ncbi.nlm.nih.gov/11301544/ .\\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. CommonsenseQA: A question\\nanswering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference of\\nthe North American Chapter of the Association for Computational Linguistics: Human Language\\nTechnologies, Volume 1 (Long and Short Papers) , 2019. URL https://aclanthology.\\norg/N19-1421 .\\nYi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung,\\nDara Bahri, Tal Schuster, Steven Zheng, Denny Zhou, Neil Houlsby, and Donald Metzler. Unifying\\nlanguage learning paradigms, 2022. URL https://arxiv.org/abs/2205.05131 .\\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze\\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. Lamda: Language models for dialog\\napplications. arXiv preprint arXiv:2201.08239 , 2022. URL https://arxiv.org/abs/\\n2201.08239 .\\nAshwin Vijayakumar, Michael Cogswell, Ramprasaath Selvaraju, Qing Sun, Stefan Lee, David\\nCrandall, and Dhruv Batra. Diverse beam search for improved description of complex scenes.\\nProceedings of the AAAI Conference on Artiﬁcial Intelligence , 32, Apr. 2018. URL https:\\n//ojs.aaai.org/index.php/AAAI/article/view/12340 .\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc\\nLe, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models.\\nConference on Neural Information Processing Systems (NeurIPS) , 2022. URL https://arxiv.\\norg/pdf/2201.11903 .\\n14' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 13}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nSean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang, and Kyunghyun Cho. Consistency\\nof a recurrent language model with respect to incomplete decoding. In Proceedings of the 2020\\nConference on Empirical Methods in Natural Language Processing (EMNLP) , pp. 5553–5568,\\nOnline, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.\\nemnlp-main.448. URL https://aclanthology.org/2020.emnlp-main.448 .\\nWeiwen Xu, Yang Deng, Huihui Zhang, Deng Cai, and Wai Lam. Exploiting reasoning chains\\nfor multi-hop science question answering. In Findings of the Association for Computational\\nLinguistics: EMNLP 2021 , pp. 1143–1156, Punta Cana, Dominican Republic, November 2021a.\\nAssociation for Computational Linguistics. URL https://aclanthology.org/2021.\\nfindings-emnlp.99 .\\nYichong Xu, Chenguang Zhu, Shuohang Wang, Siqi Sun, Hao Cheng, Xiaodong Liu, Jianfeng\\nGao, Pengcheng He, Michael Zeng, and Xuedong Huang. Human parity on commonsenseqa:\\nAugmenting self-attention with external attention, 2021b. URL https://arxiv.org/abs/\\n2112.03254 .\\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and\\nChristopher D. Manning. HotpotQA: A dataset for diverse, explainable multi-hop question answer-\\ning. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing ,\\npp. 2369–2380, Brussels, Belgium, October-November 2018. Association for Computational Lin-\\nguistics. doi: 10.18653/v1/D18-1259. URL https://aclanthology.org/D18-1259 .\\nXi Ye and Greg Durrett. The unreliability of explanations in few-shot prompting for textual reasoning.\\nIn Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in\\nNeural Information Processing Systems , 2022. URL https://openreview.net/forum?\\nid=Bct2f8fRd8S .\\nWenhao Yu, Chenguang Zhu, Lianhui Qin, Zhihan Zhang, Tong Zhao, and Meng Jiang. Diversifying\\ncontent generation for commonsense reasoning with mixture of knowledge graph experts. In\\nFindings of Annual Meeting of the Association for Computational Linguistics (ACL) , 2022.\\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving\\nfew-shot performance of language models. In Marina Meila and Tong Zhang (eds.), Proceed-\\nings of the 38th International Conference on Machine Learning , volume 139 of Proceedings of\\nMachine Learning Research . PMLR, 2021. URL https://proceedings.mlr.press/\\nv139/zhao21c.html .\\n15' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 14}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nA A PPENDIX\\nA.1 A DDITIONAL EXPERIMENT RESULTS\\nA.1.1 R OBUSTNESS TO SAMPLING STRATEGIES AND PARAMETERS\\nIn Figure 6 we ablate the results with respect to different sampling strategies and parameters by\\nvarying Tin temperature sampling and kin Top- ksampling, on LaMDA-137B. We show that\\nself-consistency is robust to various sampling strategies and parameters.\\n481216202428323640\\n#Sampled Reasoning Paths182022242628Accuracy (%)\\nT=0.7, k=40\\nT=0.5, k=40\\nT=0.3, k=40\\nT=0.5, k=20\\nT=0.5, no top k\\nGreedy Decode\\nFigure 6: GSM8K accuracy over LaMDA-137B. Self-consistency works under various sampling\\nstrategies and sampling parameters.\\nIn Figure 7 and Figure 8, we show the results of self-consistency compared with greedy decoding a\\nsingle path over LaMDA-137B and PaLM-540B, respectively. Self-consistency improves over greedy\\ndecode by a quite signiﬁcant margin on both models, on top of high accuracy already achieved by\\nscaling up model sizes.\\n0510152025303540\\n#Sampled Reasoning Paths505560657075Accuracy (%)\\nMultiArith\\n0510152025303540\\n#Sampled Reasoning Paths4446485052545658\\nASDiv\\n0510152025303540\\n#Sampled Reasoning Paths3336394245485154\\nSVAMP\\n0510152025303540\\n#Sampled Reasoning Paths1416182022242628\\nGSM8K\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\n0510152025303540\\n#Sampled Reasoning Paths56586062Accuracy (%)\\nCommonsense QA\\n0510152025303540\\n#Sampled Reasoning Paths62636465666768\\nStrategy QA\\n0510152025303540\\n#Sampled Reasoning Paths687072747678\\nARC (Easy)\\n0510152025303540\\n#Sampled Reasoning Paths505254565860\\nARC (Challenge)\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\nFigure 7: Self-consistency (blue) signiﬁcantly improves accuracy across various arithmetic and\\ncommonsense reasoning tasks, over LaMDA-137B. Sampling a higher number of diverse reasoning\\npaths consistently improves reasoning accuracy.\\nWe further show additional sampled reasoning paths from the LaMDA-137B model in Table 12, and\\nsampled reasoning paths from the PaLM-540B model in Table 13. We see that the diversity in the\\nadditionally sampled reasoning paths indeed helps the model arrive at a more correct ﬁnal answer\\nafter aggregation.\\nA.1.2 R OBUSTNESS TO DIFFERENT SETS OF PROMPTS\\nIn Table 9, we further show that self-consistency is quite robust to different sets of input prompts.\\nWe manually wrote 3 different sets of chain-of-thought as prompts to the model. Across all sets of\\nprompts, self-consistency yields consistent gains over the original CoT approach.\\nA.1.3 C OMPARED TO MODEL ENSEMBLES\\nAdditionally, we provide results of directly ensembling the outputs from multiple language models .\\nThe results are shown in Table 10, by greedily decoding sequences from 3 language models and\\n16' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 15}\n",
      "page_content='Published as a conference paper at ICLR 2023\\n0510152025303540\\n#Sampled Reasoning Chains8688909294Accuracy (%)\\nAddSub\\n0510152025303540\\n#Sampled Reasoning Chains727476788082Accuracy (%)\\nASDiv\\n0510152025303540\\n#Sampled Reasoning Chains30333639424548Accuracy (%)\\nAQuA\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\n0510152025303540\\n#Sampled Reasoning Chains889092949698Accuracy (%)\\nMultiArith\\n0510152025303540\\n#Sampled Reasoning Chains70.072.575.077.580.082.585.087.5Accuracy (%)\\nSVAMP\\n0510152025303540\\n#Sampled Reasoning Chains505560657075Accuracy (%)\\nGSM8K\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\n0510152025303540\\n#Sampled Reasoning Paths7475767778798081Accuracy (%)\\nCommonsense QA\\n0510152025303540\\n#Sampled Reasoning Paths7476788082\\nStrategy QA\\n0510152025303540\\n#Sampled Reasoning Paths8890929496\\nARC (Easy)\\n0510152025303540\\n#Sampled Reasoning Paths788082848688\\nARC (Challenge)\\nGreedy Decode (Single-path)\\nSelf Consistency (Multi-path)\\nFigure 8: Self-consistency (blue) signiﬁcantly improves accuracy across various arithmetic and\\ncommonsense reasoning tasks, over PaLM-540B. Sampling a higher number of diverse reasoning\\npaths consistently helps reasoning accuracy.\\nPrompt set 1 (used in the main text) Prompt set 2 Prompt set 3\\nCoT (Wei et al., 2022) 56.5 54.6 54.0\\nSelf-consistency 74.4 (+17.9) 72.1 (+17.5) 70.4 (+16.4)\\nTable 9: GSM8K accuracy over PaLM-540B. The results show robustness of self-consistency with\\nrespect to different prompts in the input.\\ntaking the majority vote (averaged over 10 runs). Note this is a typical ensemble approach (averaging\\nover the predictions over multiple models) and it achieves a performance signiﬁcantly worse than\\nself-consistency (self-consistency over PaLM-540B gets an accuracy of 74.4%), as lower-capacity\\nmodels drag down the performance of higher-capacity models. In addition, this approach is limited in\\ntwo ways: 1) It requires multiple models for an ensemble which might not always be available, while\\nself-consistency only requires one single model to “self-ensemble”; 2) If one of the models is much\\nweaker, it can actually hurt the ﬁnal performance.\\nMethod GSM8K accuracy\\nSingle model PaLM-540B, greedy / self-consistency 56.5 / 74.4\\nEnsemble of modelsLaMDA-137B + PaLM-540B 36.9 ±0.5\\nPaLM-540B + GPT-3 (code-davinci-001, 175B) 36.6 ±0.4\\nLaMDA-137B + GPT-3 (code-davinci-001, 175B) 16.0 ±0.8\\nLaMDA-137B + PaLM-540B + GPT-3 (code-davinci-001, 175B) 33.3 ±0.7\\nTable 10: Comparison of GSM8K accuracy over multiple-model ensembles.\\nA.1.4 C OMBINING SELF -CONSISTENCY WITH OTHER ENSEMBLING STRATEGIES\\nSelf-consistency is completely compatible with other ensemble strategies, although the gains achieved\\nby self-consistency are signiﬁcantly higher than other ensemble strategies (and can “override” the\\nperformance gains achieved by other ensemble strategies). We further performed experiments and\\ninclude the results in Table 11 (for a fair comparison, we use 40 sets of prompts, or 40 prompt\\npermutations to compare with self-consistency with 40 paths, all experiments are based on PaLM-\\n540B).\\n17' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 16}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nGSM8K accuracy\\nDifferent sets of prompts (x40) 58.9\\nPrompt-permutation (x40) 59.6\\nSelf-consistency (x40) 74.4\\nSelf-consistency + different sets of prompts (x40) 75.4\\nSelf-consistency + prompt-permutation (x40) 73.8\\nTable 11: Combining self-consistency with other ensembling strategies.\\nA.2 D ETAILS ON RESOURCES AND INFERENCE\\nFor all four language models we perform prompting-based inference only. For UL2 we use TPU v3\\n(2x2 conﬁguration, 4 chips, 8 cores). For GPT-3 models the experiments are done though the public\\nAPI.10For LaMDA-137B we use TPU v3 (8x8 conﬁguration, 64 chips, 128 cores). For PaLM-540B\\nwe use TPU v4 (4x4x12 conﬁguration, 192 chips, 384 cores). Most inference jobs take 1 to 4 hours\\n(over about 1,000 examples) for each task on UL2 and LaMDA-137B, and about 2 to 12 hours on\\nPaLM-540B. Some tasks (e.g., commonsense reasoning) take longer but do not exceed 2 days for\\neach task.\\nFor GPT-3 models, we use 128 max tokens for all methods, without frequency penalty or presence\\npenalty. For all models, we take the generated outputs until the start of the next “Q:\" to parse the ﬁnal\\nanswers, consistent with our prompting format.\\nQuestion Greedy Decode Sampled Path 1 Sampled Path 2\\n[MultiArith] Sam had 10 socks.\\nIf he threw away 3 old ones\\nthat didn’t ﬁt and bought 36 new\\nones, how many socks would he\\nhave?Sam had 10 socks. He threw\\naway 3 old ones that didn’t ﬁt.\\nHe bought 36 new ones. That\\nmeans he has 10 + 36 - 3 = 41\\nsocks. The answer is 41.Sam had 10 socks. He\\nthrew away 3 old ones. So\\nnow he has 7 left. Then he\\nbought 36 new ones. So\\nnow he has 7 + 36 = 43\\nsocks. The answer is 43.He had 10 socks. He threw away\\n3 old ones that didn’t ﬁt. He\\nbought 36 new ones. So in total\\nhe has 10 - 3 + 36 = 43 socks. The\\nanswer is 43.\\n[SVAMP] In a school there are\\n697 girls and the rest are boys.\\nIf there are 228 more girls than\\nboys. How many boys are there\\nin that school?There are 697 girls and the rest\\nare boys. That means there are\\n697 + 228 = 925 girls. The\\nrest are boys. So the number of\\nboys is 925 - 697 = 228. The\\nanswer is 228.The number of boys is the\\ndifference between 697\\nand 228. This is 697 - 228\\n= 469. The answer is 469.In the beginning there are 697\\ngirls and the rest are boys. So, the\\nnumber of boys must be 697 - 228\\n= 469 boys. The answer is 469.\\n[AQuA] There are 10 oranges in\\na basket. Find the no. of ways in\\nwhich 2 oranges are chosen from\\nthe basket? (a) 45 (b) 90 (c) 120\\n(d) 150 (e) 180There are 10 oranges in a bas-\\nket. So there are 10 ways\\nin which 2 oranges are chosen\\nfrom the basket.There are 10 oranges in a\\nbasket. We need to choose\\n2 oranges from the basket.\\nSo the number of ways are\\n10C2. So the answer is (a).There are 10 oranges in the bas-\\nket. If you choose 2 oranges, you\\nhave 10C2 = 45 ways of choosing\\n2 oranges. So the answer is (a).\\n[CommonsenseQA] The man\\nlaid on the soft moss and looked\\nup at the trees, where was the\\nman? (a) niagra falls (b) forest\\n(c) waterfall (d) ground (e) treeThe answer must be something\\nthat is soft and mossy. Of the\\nabove choices, only ground is\\nsoft and mossy. So the answer\\nis (d).The answer must be\\nsomewhere where moss\\nis found. Of the above\\nchoices, only forests are\\nknown for having moss.\\nSo the answer is (b).The answer must be a place where\\nthe man is laying down and look-\\ning up at trees. Of the above\\nchoices, only forest is a place\\nwhere people lay down and look\\nat trees. So the answer is (b).\\n[ARC] Which of these will most\\nlikely harm a habitat? (a) plant-\\ning trees. (b) water pollution. (c)\\nrainfall. (d) sunlight.Planting trees will not harm a\\nhabitat. So the answer is (a).The answer is (b), water\\npollution, because it will\\nmost likely harm the habi-\\ntat. The other answers are\\nnot likely to harm the habi-\\ntat.The answer is (b), water pollution.\\nTrees are good for a habitat, rain-\\nfall is necessary for a habitat, and\\nsunlight is necessary for a habitat.\\nSo the answer is (b).\\n[ARC-challenge] Which pro-\\ncess in the carbon cycle takes the\\nlongest to complete? (a) emis-\\nsion of waste. (b) respiration in\\nanimals. (c) photosynthesis in\\nplants. (d) formation of fossil fu-\\nels.The process of photosynthesis\\nin plants takes the longest to\\ncomplete. So the answer is (c).The formation of fossil fu-\\nels takes the longest time\\nto complete. So the an-\\nswer is (d).The process that takes the longest\\ntime to complete is the forma-\\ntion of fossil fuels, which hap-\\npens over millions of years. So\\nthe answer is (d).\\nTable 12: Additional examples where self-consistency helps repair the errors over greedy decode on\\nLaMDA-137B. Two sampled reasoning paths that are consistent with the ground truth are shown.\\n10https://beta.openai.com/docs/api-reference/making-requests\\n18' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 17}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nQuestion Greedy Decode Sampled Path 1 Sampled Path 2\\n[GSM8K] Kyle bought last\\nyear’s best-selling book for\\n$19.50. This is with a 25% dis-\\ncount from the original price.\\nWhat was the original price of\\nthe book?The book was sold for $19.50.\\nThis is 25% less than the origi-\\nnal price. This means the original\\nprice was 100%. 25% of 100%\\nis 25%. So the original price\\nwas 100% - 25% = 75%. The\\noriginal price was 75% of $19.50.\\n75% of $19.50 is 75% * $19.50 =\\n$14.625. The answer is $14.625.The original price of the book\\nis $19.50. Since it was dis-\\ncounted by 25%, the original\\nprice was 19.50 / 0.75 = 26.\\nThe answer is 26.Kyle bought a book that is sold\\nfor $19.50. With a 25% discount,\\nthe original price must be higher.\\nIf we call the original price x,\\nthen the discounted price is 0.75x.\\nSince this is $19.50, we can write\\n0.75x = 19.50. Solving this, we\\nﬁnd that the original price is x =\\n19.50 / 0.75 = $26. The answer is\\n$26.\\n[AQuA] The capacity of a\\ntank of dimensions (8 m x 6\\nm x 2.5 m) is (a) 120 litres (b)\\n1200 litres (c) 12000 litres (d)\\n120000 litres (e) None of theseThe volume of the tank is 8 m *\\n6 m * 2.5 m = 120 m3. So the\\ncapacity of the tank is 120 m3. So\\nthe answer is (c).The volume of the tank is 8m\\n* 6m* 2.5m = 120m3. This is\\nequal to 120000 litres. So the\\nanswer is (d)The volume of the tank is 8 m *\\n6 m * 2.5 m = 120 m3. One cu-\\nbic meter contains 1000 litres, so\\nthe tank contains 120 m3 * 1000\\nliters/m3 = 120,000 liters. So the\\nanswer is (d).\\n[StrategyQA] Yes or no:\\nCan the Great Depression be\\ntreated with Prozac?The Great Depression was an\\neconomic depression. Prozac is\\na drug used to treat depression.\\nThus, the Great Depression could\\nbe treated with Prozac. So the an-\\nswer is yes.Prozac is an anti-depressant\\nmedication. The Great Depres-\\nsion is not a disease. Thus,\\nProzac cannot treat the Great\\nDepression. So the answer is\\nno.The Great Depression is a time pe-\\nriod. Prozac is used to treat de-\\npression (the mental illness). Thus,\\nthe Great Depression can not be\\ntreated with Prozac. So the answer\\nis no.\\n[ARC-easy] Which source of\\nenergy is nonrenewable? (a)\\ncoal. (b) sunlight. (c) water.\\n(d) wood.Coal, sunlight, and water are\\nall renewable sources of energy.\\nWood is a nonrenewable source of\\nenergy. So the answer is (d).A nonrenewable source of en-\\nergy is one in which the source\\nis not replenished in a short\\namount of time. Thus, the only\\noption that is nonrenewable is\\ncoal. So the answer is (a).Coal is a fossil fuel and is formed\\nfrom dead organisms from the past.\\nCoal cannot be produced in a short\\nperiod of time, so it is considered\\na nonrenewable source of energy.\\nSo the answer is (a).\\n[ARC-challenge] Students\\nstudied the revolution of Earth\\naround the Sun. During which\\nmonth will Florida have the\\nmost sunlight energy avail-\\nable? (a) March. (b) June. (c)\\nSeptember. (d) December.The Earth is closest to the Sun\\nin December, hence Florida will\\nhave the most sunlight energy\\navailable in December. So the an-\\nswer is (d).Earth is closest to the Sun on\\nJune 21, the summer solstice.\\nSo the answer is (b).Florida is closer to the sun during\\nJune, so it will have the most sun-\\nlight energy during that month. So\\nthe answer is (b).\\nTable 13: Additional examples where self-consistency helps repair the errors over greedy decode on\\nPaLM-540B. Two sampled reasoning paths that are consistent with the ground truth are shown.\\nA.3 F ULL SETS OF PROMPTS\\nWe list the full details of the prompts used for two newly-introduced datasets, AQUA-RAT (Ling\\net al., 2017) and AI2 Reasoning Challenge (ARC) (Clark et al., 2018), where we manually composed\\nthe example chain-of-thought in this paper, in Table 14 and Table 15, respectively.\\nTable 14: Few-shot exemplars for AQUA-RAT.\\nQ:John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the\\nnumbers is? Answer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\\nA:If 10 is added to each number, then the mean of the numbers also increases by 10. So the new mean\\nwould be 50. The answer is (a).\\nQ:If a / b = 3/4 and 8a + 5b = 22,then ﬁnd the value of a. Answer Choices: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e)\\n7/2\\nA:If a / b = 3/4, then b = 4a / 3. So 8a + 5(4a / 3) = 22. This simpliﬁes to 8a + 20a / 3 = 22, which means\\n44a / 3 = 22. So a is equal to 3/2. The answer is (b).\\nQ:A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then ﬁnd the distance? Answer Choices:\\n(a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km\\nA:The distance that the person traveled would have been 20 km/hr * 2.5 hrs = 50 km. The answer is (e).\\nQ:How many keystrokes are needed to type the numbers from 1 to 500? Answer Choices: (a) 1156 (b) 1392\\n(c) 1480 (d) 1562 (e) 1788\\nA:There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401\\nthree-digit numbers from 100 to 500. 9 + 90(2) + 401(3) = 1392. The answer is (b).\\n19' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 18}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nTable 15: Few-shot exemplars for ARC easy/challenge.\\nQ:George wants to warm his hands quickly by rubbing them. Which skin surface will produce the most\\nheat? (a) dry palms. (b) wet palms. (c) palms covered with oil. (d) palms covered with lotion.\\nA:Dry surfaces will more likely cause more friction via rubbing than other smoother surfaces, hence dry\\npalms will produce the most heat. The answer is (a).\\nQ:Which factor will most likely cause a person to develop a fever? (a) a leg muscle relaxing after exercise.\\n(b) a bacterial population in the bloodstream. (c) several viral particles on the skin. (d) carbohydrates being\\ndigested in the stomach.\\nA:Option (b), bacterial population is the most likely cause for a person developing fever. The answer is (b).\\nQ:Which change in the state of water particles causes the particles to become arranged in a ﬁxed position?\\n(a) boiling. (b) melting. (c) freezing. (d) evaporating.\\nA:When water is freezed, the particles are arranged in a ﬁxed position; the particles are still moving for all\\nother options. The answer is (c).\\nQ:When a switch is used in an electrical circuit, the switch can (a) cause the charge to build. (b) increase\\nand decrease the voltage. (c) cause the current to change direction. (d) stop and start the ﬂow of current.\\nA:The function of a switch is to start and stop the ﬂow of a current. The answer is (d).\\nTable 16: Few-shot exemplars for HotpotQA (closed-book setting).\\nQ:Which magazine was started ﬁrst Arthur’s Magazine or First for Women?\\nA:Arthur’s Magazine started in 1844. First for Women started in 1989. So Arthur’s Magazine was started ﬁrst.\\nThe answer is Arthur’s Magazine.\\nQ:The Oberoi family is part of a hotel company that has a head ofﬁce in what city?\\nA:The Oberoi family is part of the hotel company called The Oberoi Group. The Oberoi Group has its head\\nofﬁce in Delhi. The answer is Delhi.\\nQ:What nationality was James Henry Miller’s wife?\\nA:James Henry Miller’s wife is June Miller. June Miller is an American. The answer is American.\\nQ:The Dutch-Belgian television series that \"House of Anubis\" was based on ﬁrst aired in what year?\\nA:\"House of Anubis\" is based on the Dutch–Belgian television series Het Huis Anubis. Het Huis Anubis is ﬁrst\\naired in September 2006. The answer is 2006.\\nAs additional information, we also list the exact set of prompts used for all arithmetic reasoning tasks\\nin Table 17, since there are multiple sets of prompts introduced in Wei et al. (2022). The prompts for\\nCommonsenseQA and StrategyQA are the same as used in Wei et al. (2022).\\nWe provide the exact prompts used for common NLP tasks in the following tables as well, including\\nNLI (Table 18, Table 19, Table 20) and Closed-Book Question-Answering tasks (Table 16, Table 21).\\n20' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 19}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nTable 17: Few-shot exemplars for all arithmetic reasoning tasks, from Wei et al. (2022).\\nQ:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\\nthere will be 21 trees. How many trees did the grove workers plant today?\\nA:We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\\nSo, they must have planted 21 - 15 = 6 trees. The answer is 6.\\nQ:If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA:There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\\nQ:Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA:Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\\nchocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\\nQ:Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\\ndid Jason give to Denny?\\nA:Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\\nlollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\\nQ:Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does\\nhe have now?\\nA:He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\\nin total he has 7 + 2 = 9 toys. The answer is 9.\\nQ:There were nine computers in the server room. Five more computers were installed each day, from\\nmonday to thursday. How many computers are now in the server room?\\nA:There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\\n20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\\nThe answer is 29.\\nQ:Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\\ngolf balls did he have at the end of wednesday?\\nA:Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\\nWednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\\nQ:Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA:She bought 5 bagels for $3 each. This means she spent 5 * $3 = $15 on the bagels. She had $23 in\\nbeginning, so now she has $23 - $15 = $8. The answer is 8.\\n21' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 20}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nTable 18: Few-shot exemplars for ANLI.\\nPremise:\\n\"Conceptually cream skimming has two basic dimensions - product and geography.\"\\nBased on this premise, can we conclude the hypothesis \"Product and geography are what make cream skimming\\nwork.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:Based on \"cream skimming has two basic dimensions\" we can’t infer that these two dimensions are what\\nmake cream skimming work. The answer is it is not possible to tell.\\nPremise:\\n\"One of our member will carry out your instructions minutely.\"\\nBased on this premise, can we conclude the hypothesis \"A member of my team will execute your orders with\\nimmense precision.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:\"one of\" means the same as \"a member of\", \"carry out\" means the same as \"execute\", and \"minutely\" means\\nthe same as \"immense precision\". The answer is yes.\\nPremise:\\n\"Fun for adults and children.\"\\nBased on this premise, can we conclude the hypothesis \"Fun for only children.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:\"adults and children\" contradicts \"only children\". The answer is no.\\nPremise:\\n\"He turned and smiled at Vrenna.\"\\nBased on this premise, can we conclude the hypothesis \"He smiled at Vrenna who was walking slowly behind\\nhim with her mother.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:the premise does not say anything about \"Vrenna was walking\". The answer is it is not possible to tell.\\nPremise:\\n\"well you see that on television also\"\\nBased on this premise, can we conclude the hypothesis \"You can see that on television, as well.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:\"also\" and \"as well\" mean the same thing. The answer is yes.\\nPremise:\\n\"Vrenna and I both fought him and he nearly took us.\"\\nBased on this premise, can we conclude the hypothesis \"Neither Vrenna nor myself have ever fought him.\" is\\ntrue?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:\"Vrenna and I both\" contradicts \"neither Vrenna nor myself\". The answer is no.\\n22' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 21}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nTable 19: Few-shot exemplars for e-SNLI (the rationales are crowd-sourced annotations from the\\noriginal dataset).\\nPremise:\\n\"A person on a horse jumps over a broken down airplane.\"\\nBased on this premise, can we conclude the hypothesis \"A person is training his horse for a competition.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:The person is not necessarily training his horse. The answer is it is not possible to tell.\\nPremise:\\n\"A person on a horse jumps over a broken down airplane.\"\\nBased on this premise, can we conclude the hypothesis \"A person is at a diner, ordering an omelette.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:One jumping horse cannot be in a diner ordering food. The answer is no.\\nPremise:\\n\"A person on a horse jumps over a broken down airplane.\"\\nBased on this premise, can we conclude the hypothesis \"A person is outdoors, on a horse.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:A broken down airplane is outdoors. The answer is yes.\\nPremise:\\n\"Children smiling and waving at camera.\"\\nBased on this premise, can we conclude the hypothesis \"They are smiling at their parents.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:Just because they are smiling and waving at a camera does not imply their parents or anyone is anyone behind\\nit. The answer is it is not possible to tell.\\nPremise:\\n\"Children smiling and waving at camera.\"\\nBased on this premise, can we conclude the hypothesis \"The kids are frowning.\" is true? OPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:One cannot be smiling and frowning at the same time. The answer is no.\\nPremise:\\n\"Children smiling and waving at camera.\"\\nBased on this premise, can we conclude the hypothesis \"There are children present.\" is true?\\nOPTIONS:\\n- yes\\n- no\\n- it is not possible to tell\\nA:The children must be present to see them smiling and waving. The answer is yes.\\n23' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 22}\n",
      "page_content='Published as a conference paper at ICLR 2023\\nTable 20: Few-shot exemplars for RTE.\\nPremise:\\n\"No Weapons of Mass Destruction Found in Iraq Yet.\"\\nBased on this premise, can we conclude the hypothesis \"Weapons of Mass Destruction Found in Iraq.\" is true?\\nA:\"No Weapons of Mass Destruction Found\" contradicts \"Weapons of Mass Destruction Found\". The answer is\\nno.\\nPremise:\\n\"A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful\\ngathered in downtown Chicago to mark the installation of new Pope Benedict XVI.\"\\nBased on this premise, can we conclude the hypothesis \"Pope Benedict XVI is the new leader of the Roman\\nCatholic Church.\" is true?’\\nA:\"installation of new Pope Benedict XVI.\" means \"Pope Benedict XVI is the new leader\". The answer is yes.\\nPremise:\\n\"A man is due in court later charged with the murder 26 years ago of a teenager whose case was the ﬁrst to\\nbe featured on BBC One’s Crimewatch. Colette Aram, 16, was walking to her boyfriend’s house in Keyworth,\\nNottinghamshire, on 30 October 1983 when she disappeared. Her body was later found in a ﬁeld close to her\\nhome. Paul Stewart Hutchinson, 50, has been charged with murder and is due before Nottingham magistrates\\nlater.\"\\nBased on this premise, can we conclude the hypothesis \"Paul Stewart Hutchinson is accused of having stabbed a\\ngirl.\" is true?\\nA:The premise does not say Paul Stewart Hutchinson \"stabbed\" this girl. The answer is no.\\nPremise:\\n\"Herceptin was already approved to treat the sickest breast cancer patients, and the company said, Monday, it\\nwill discuss with federal regulators the possibility of prescribing the drug for more breast cancer patients.\"\\nBased on this premise, can we conclude the hypothesis \"Herceptin can be used to treat breast cancer.\" is true?\\nA:\"Herceptin was approved to treat breast cancer\" implies that \"Herceptin can be used to treat breast cancer\".\\nThe answer is yes.\\nTable 21: Few-shot exemplars for BoolQ (closed-book setting).\\nQ:does system of a down have 2 singers?\\nA:System of a Down currently consists of Serj Tankian, Daron Malakian, Shavo Odadjian and John Dolmayan.\\nSerj and Daron do vocals, so the band does have two singers. The answer is yes.\\nQ:do iran and afghanistan speak the same language?\\nA:Iran and Afghanistan both speak the Indo-European language Persian. The answer is yes.\\nQ:is a cello and a bass the same thing?\\nA:The cello is played sitting down with the instrument between the knees, whereas the double bass is played\\nstanding or sitting on a stool. The answer is no.\\nQ:can you use oyster card at epsom station?\\nA:Epsom railway station serves the town of Epsom in Surrey and is not in the London Oyster card zone. The\\nanswer is no.\\n24' metadata={'source': 'pdf/SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS.pdf', 'page': 23}\n",
      "page_content='Beyond Chain-of-Thought, Effective\\nGraph-of-Thought Reasoning in Large Language\\nModels\\nYao Yao1,2, Zuchao Li3,∗and Hai Zhao1,2,∗\\n1Department of Computer Science and Engineering, Shanghai Jiao Tong University\\n2MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University\\n3National Engineering Research Center for Multimedia Software,\\nSchool of Computer Science, Wuhan University, Wuhan, 430072, P. R. China\\nyaoyao27@sjtu.edu.cn, zcli-charlie@whu.edu.cn,\\nzhaohai@cs.sjtu.edu.cn\\nAbstract\\nWith the widespread use of large language models (LLMs) in NLP tasks, re-\\nsearchers have discovered the potential of Chain-of-thought (CoT) to assist LLMs\\nin accomplishing complex reasoning tasks by generating intermediate steps. How-\\never, human thought processes are often non-linear, rather than simply sequential\\nchains of thoughts. Therefore, we propose Graph-of-Thought (GoT) reasoning,\\nwhich models human thought processes not only as a chain but also as a graph. By\\nrepresenting thought units as nodes and connections between them as edges, our\\napproach captures the non-sequential nature of human thinking and allows for a\\nmore realistic modeling of thought processes. Similar to Multimodal-CoT [ 1], we\\nmodeled GoT reasoning as a two-stage framework, generating rationales first and\\nthen producing the final answer. Specifically, we employ an additional graph-of-\\nthoughts encoder for GoT representation learning and fuse the GoT representation\\nwith the original input representation through a gated fusion mechanism. We\\nimplement a GoT reasoning model on the T5 pre-trained model and evaluate its\\nperformance on a text-only reasoning task (GSM8K) and a multimodal reasoning\\ntask (ScienceQA). Our model achieves significant improvement over the strong\\nCoT baseline with 3.41% and 5.08% on the GSM8K test set with T5-base and\\nT5-large architectures, respectively. Additionally, our model boosts accuracy from\\n84.91% to 91.54% using the T5-base model and from 91.68% to 92.77% using the\\nT5-large model over the state-of-the-art Multimodal-CoT on the ScienceQA test\\nset. Experiments have shown that GoT achieves comparable results to Multimodal-\\nCoT largewith over 700M parameters, despite having fewer than 250M backbone\\nmodel parameters, demonstrating the effectiveness of GoT.\\n1 Introduction\\nIn the field of human cognition, it has long been recognized that the human thought process is far\\nmore complex and non-linear than could be captured by a simple, sequential chain of thoughts [ 2].\\nHuman thinking is often characterized by its ability to make sudden leaps and connections between\\nseemingly unrelated ideas, which can lead to novel insights and solutions. This non-linear, jumping\\nthought process is a hallmark of human creativity, reasoning, and problem-solving abilities. However,\\nit also poses a significant challenge for cognitive modeling and understanding.\\n∗Corresponding author.†Equal contribution.\\nPreprint. Under review.arXiv:2305.16582v1  [cs.CL]  26 May 2023' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 0}\n",
      "page_content=\"Recently, Large Language Models (LLMs) have been advancing at an unprecedented pace. With the\\nemergence of breakthroughs such as GPT-3 [ 3], PaLM [ 4], and GPT-4 [ 5], the field of natural language\\nprocessing has entered a new era of possibilities. Recent studies [ 6–8] have shown that the reasoning\\nability of LLMs can be unlocked by Chain-of-Thought (CoT) prompting. CoT prompting involves a\\nseries of intermediate natural language rationales that lead to the final answer. In addition, Zhang\\net al. [1]have introduced Multimodal-CoT, which combines both language and visual modalities to\\nhelp surpass the limitations of textual information. More detailed related works about CoT can be\\nfound in Appendix A.1.\\nPrevious works on Chain-of-Thought (CoT) prompting, which have been limited to textual and\\nvisual information, often represented the human reasoning process as sequential thought chains. This\\napproach overlooks the modeling of humans’ jumping thought process and neglects to incorporate\\nthe complex structural information of reasoning thoughts into the model. To address this limitation,\\nwe propose the Graph-of-Thought (GoT), a novel approach to modeling human thought processes\\nnot only as a chain but also as a graph. Our method is based on the assumption that the human mind\\nworks by connecting and recombining ideas in a non-sequential, graph fashion, rather than following\\na strict sequential chain. By representing thought units as nodes and connections between thoughts as\\nedges, the Graph-of-Thought captures the rich, non-sequential nature of human thinking and allows\\nfor a more realistic and logical modeling of reasoning processes.\\nDo ferns produce seeds?Text Features\\n(A) Yes (B) No\\nThis diagram shows the life cycle of \\na fern.\\nVision Features (Optional) Graph -of-Thought Features\\nproduceseedsferns\\nshowslife \\ncycle\\nofdiagram\\nFern plants reproduce using both asexual reproduction \\nand sexual reproduction … The heart -shaped plant \\nbegins the fern's sexual reproduction stage … The mature \\nfern can make spores and begin the fern life cycle again.Rationale\\nFerns do not produce seeds. Mature ferns produce spores, \\nand heart -shaped plants produce eggs and sperm.Answer\\nThe answer \\nis (B)Graph -of-Thought with Rationale\\nproduce seeds ferns\\nshowslife \\ncycle\\nofdiagramhassexual \\nproduction\\nstage\\nFigure 1: An example of GoT reasoning. Vision features are optional and are only required in\\nmultimodal reasoning task.\\nAn example of GoT reasoning is shown in Figure 1. Inspired by Multimodal-CoT [ 1], we have\\nadopted a two-stage reasoning framework. It first generates rationales and then generates the final\\nanswer based on the predicted rationales. In addition to text features, graph features of GoT are\\nintegrated during the rationale generation and answer inference. Specifically, GoT is first constructed\\nwith an Extract-Cluster-Coreference (ECC) process, which simulates the deductive process in human\\nreasoning. We have used T5 [ 9] pre-trained language model as our backbone model. GoT is encoded\\nwith a graph attention network and then fused with the original representation via a gated fusion\\nnetwork.\\nFurthermore, we have also presented a multimodal GoT, which integrates not only text features and\\nGoT features but also visual features. For our experiments, we have used both UnifiedQA (T5)-base\\nand UnifiedQA (T5)-large [10] as our backbone models.\\nWe implement GoT as a two-stage framework and fine-tuning language models and integrating text,\\nthought graph, and vision features for a more realistic and accurate reasoning process. GoT demon-\\nstrates exceptional performance on both text-only GSM8K [ 11] and multimodal ScienceQA [ 12]\\nbenchmarks, surpassing the accuracy of online system ChatGPT [ 5] by 25.08%, 14.46%, strong\\nbaseline Multimodal-CoT [ 1] by 6.63%, and even exceeding human performance, establishing a new\\nstate-of-the-art on ScienceQA test set with far more less parameters.\\n2\" metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 1}\n",
      "page_content='2 Graph-of-Thought\\nThought Graph\\nImage (Optional)\\nGraph -of-Thought \\nConstructor\\nInput Text \\nQuestion: Do ferns \\nproduce seeds?\\nChoices: (A) Yes (B) No\\nContext: This diagram \\nshows the life cycle of \\na fern.\\nPredicted \\nRationalesInput Encoder\\nGoT\\nEncoder\\nText\\nencoder\\nVision \\nencoderGraph \\nAttention \\nNetwork \\nTransformer\\nEncoder\\nFeature\\nExtractorCross\\nAttention\\nCross\\nAttentionGated\\nFusion\\nLayerTransformer\\nDecoder\\nStage 1\\nPredict Rationales\\nLecture：Fern plants reproduce \\nusing both asexual reproduction \\nand sexual reproduction…\\nSolution :  Ferns do not produce \\nseeds. Mature ferns produce \\nspores…\\nThe answer is (B).Decoder\\nOutput Feature FusionStage 2\\nStage 2\\nPredict Answers\\nFigure 2: Graph-of-Thought framework overview\\nThe overview of our proposed GoT can be seen in Figure 2. Inspired by Multimodal-CoT [ 1], GoT\\nalso adopts a two-stage framework. (1) Rationale generation stage: In the first stage, the model\\ngenerates rationales based on the input text (including question, context, and choices) the vision\\nfeatures, and the generated thought graph corresponding to the input text. GoT employs independent\\nencoders to encode input data for each modality. We use a Transformer encoder to encode input text,\\na vision encoder to encode an image, and a graph attention network to encode the thought graph.\\nThe encoded features are further passed into cross-attention to align text tokens with image patches\\nand graph nodes, respectively. We then use a gated fusion layer to fuse these three features further\\nand pass them into the Transformer decoder to predict the target rationales. (2) Answer generation\\nstage: The second stage aims at generating the final answer and is largely similar to the first stage.\\nThe main difference is that the input text is concatenated with the predicted rationales from the first\\nstage. It is worth noting that the above process describes a general multimodal reasoning framework.\\nHowever, for text-only reasoning tasks, there are no image features, so the image encoding and vision\\nfeature fusion processes mentioned above can be omitted. In the following section, we will provide a\\ndetailed exposition of the two key steps of our GoT reasoning framework: GoT construction and GoT\\nencoding and integration.\\n2.1 GoT Construction\\nThe word earthquake \\ncomes from the words \\nearth and quake. The word \\nearth means ground, and \\nthe word quake means to \\nshake.Earthquakecomes \\nfromearth\\nquakemeansground\\nshakeGoT Rationales\\nFigure 3: Graph-of-Thought deduction example\\n3' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 2}\n",
      "page_content='GoT employs thought graphs to simulate human deductive reasoning, thereby modeling humans’\\nability for leaps of thought. Our aim is to reflect the most fundamental deduction process by con-\\nstructing a thought graph. If we have evidence that x→yandy→z, then it follows that x→z. In\\nFigure 3, the deduction reasoning can be formulated as follows: Earthquakecomes from−→ { earth, quake },\\n{earth, quake }means−→ { ground, shake }. It is easy to reason that Earthquake −→{ ground, shake }.\\nWe propose a novel Extract-Clustering-\\nCoreference (ECC) process to construct\\nthought graphs. ECC first extracts deductive\\ntriplets T={ti= (ti\\nx, ti\\ny, ti\\nz)}as the discrete\\nraw graph, where ti\\nx,ti\\ny, and ti\\nzare thought\\nunits of the i-th triplet, and there exists an\\nedgeei\\nxybetween ti\\nxandti\\ny, and an edge ei\\nyz\\nbetween ti\\nyandti\\nz. Then, ECC clusters the\\nnodes that refer to the same mentions to con-\\nduct coreference resolution. Specifically, we\\nreplace every graph node that belongs to a\\ncoreference cluster with the most representa-\\ntive mention in the cluster. By adopting this\\ntechnique, our model is better equipped with\\ndenser thought graphs and the ability for de-\\nductive reasoning. The detailed algorithm is\\nillustrated in Algorithm 1.Algorithm 1 ECC process\\nInput: Input text S\\nOutput: Thought graph G(N,E)\\nExtract deductive triplet set Tfrom S\\nT={t0, t1, ..., tn},ti= (ti\\nx, ti\\ny, ti\\nz)\\nforevery triplet ti∈Tdo\\nNr← N r∪ {ti\\nx, ti\\ny, ti\\nz}\\nEr← Er∪ {ei\\nxy, ei\\nyz}\\nend for\\nextract coreference clusters CforNr\\nforevery node ni∈ Nrdo\\nifni∈ ∀cj∈ Cthen\\nn∗\\nj←most representative mention in cj\\nN ← N ∪ { n∗\\nj}\\nend if\\nend for\\nReconnect Nbased on Erto construct E\\nreturn N,E\\nIn GoT construction, during the rationale generation stage, the input text consists of concatenated\\nquestion, context, and choices. In multimodal GoT, image caption [ 12] is appended to the input text\\nfor GoT to incorporate image information. During the answer inference stage, the predicted rationales\\nfrom the rationale generation stage are further concatenated with the input text for corresponding\\nGoT construction.\\nIn our implementation of ECC process, inspired by [ 13], we utilize open information extraction (Ope-\\nnIE) systems2[14] to extract subject-verb-object triplets as thought unit nodes. We apply coreference\\nresolution to the extracted nodes using the Stanford CoreNLP system [ 15]. The constructed thought\\ngraph is denoted as G(N,E), where Nrepresents the nodes extracted by OpenIE and Erepresents\\nthe adjacency matrix. Rows and columns correspond to the nodes in the graph, and if there is an edge\\nbetween two nodes, the corresponding matrix element is 1; otherwise, it is 0.\\n2.2 GoT Encoding and Integration\\nGoT reasoning utilizes separate encoders to encode input data for each modality. The thought graph\\nis encoded using a graph attention network, while the input text is encoded using a Transformer\\nencoder. In multimodal GoT reasoning, the image is encoded using an additional vision encoder.\\n2.2.1 Base Encoder\\nText Encoder For text representation, we use the Transformer encoder (e.g. T5 [ 9]) to encode the\\ninput text. Given input sentence S={w0, ..., w l}, we extract the hidden states from the last layer of\\nthe Transformer encoder to obtain the text representation HT:\\nHT={h0, h1, ..., h l}=Encoder text(S) (1)\\nwhere hiis the hidden representation of token iandlrepresents the length of the text input.\\nVision Encoder (Optional) For multimodal reasoning where vision modality is required, follow-\\ning [ 1], we extract patch-level features of image Iusing readily available vision extraction model\\n2https://github.com/philipperemy/Stanford-OpenIE-Python\\n4' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 3}\n",
      "page_content='as vision encoder Encoder vision and then employ a trainable projection matrix WIto project the\\nextracted features into the vision representation HIwhich have the same shape with HT.\\nHI=WIEncoder vision(I) (2)\\n2.2.2 GoT Encoder\\nNode Embedding We first use special tokens <s>\\nand</s> to highlight every thought graph node.\\nSpecifically, for node set with jnodesN={n0, ...n j}\\n, we construct the node input as p. we then feed the p\\ninto the same text encoder and utilize the output repre-\\nsentation of the special token <s> as the initial node\\nrepresentation. Formally,\\np= [<s>, n0,</s> , ...,<s>, nj,</s> ] (3)\\n[hs\\n0, hn\\n0, he\\n0, ..., hs\\nj, hn\\nj, he\\nj] =Encoder text(p)(4)\\nwhere the hs\\niandhe\\ni∈RDare the representation of <s>\\nand</s> for node nirespectively, Dis the dimension\\nof node embedding, and the hn\\ni={hn\\ni,1, ..., hn\\ni,m}is\\nthe representations of node niwithmtokens. we use\\nthehs\\nito represent the node representation of ni.\\nGAT Encoder We employ a graph attention network\\n(GAT) [ 16,13] to encode the thought graph. For every\\nnode niin graph G(N,E), thegraph attention layer\\nis designed as:\\nDropout\\nGoT inputG𝑁,𝐸Graph \\nAttention LayerGraph \\nAttention LayerConcatenateDropoutGraph \\nAttention LayerFFNNLayernormGoT representation\\nMulti -head \\nattentionResidual connection\\nℎ𝑔′ℎ𝑔′𝐻𝐺\\n…Figure 4: Architecture of GoT encoder\\naij=Attention (\\x02\\nWhs\\ni||Whs\\nj\\x03\\n); qij=LeakyReLU (aij) (5)\\nαij=Softmax (qij) =exp (qij)P\\nk∈K iexp (qik); hg′\\ni=GELU\\uf8eb\\n\\uf8edX\\nj∈K iαijWhs\\nj\\uf8f6\\n\\uf8f8 (6)\\nwhere ||denotes concatenate operation, the Wis a trainable weight and the set Kicontains the node\\nni’s neighbours in thought graph G. Our graph attention layer first employed a shared attention\\nmechanism Attention (.) :RD′×RD′→Rto compute the attention weights, where D′is the\\nattention layer output dimension. The attention weights aijmeasures the importance of node ni’s\\nfeatures to nj’s features. By only calculating the attention weights between nodes who are neighbours,\\nour graph attention layer demonstrates the ability to perceive structural information of graphs. In\\nour implementation, we adopt a single-layer feed-forward neural network (FFNN) as the attention\\nmechanism which is both simple and straight-forward.\\nThe architecture of our GoT encoder can be seen in Figure 4. Our GoT encoder employs a multi-head\\ngraph attention layer, following [ 16], we concatenate the output of each graph attention layer and\\nfurther pass it to a output graph attention layer with the same architecture:\\nhg′\\ni=∥K\\nk=1GELU\\uf8eb\\n\\uf8edX\\nj∈N iαk\\nijWkhs\\nj\\uf8f6\\n\\uf8f8; hg′′\\ni=GELU\\uf8eb\\n\\uf8edX\\nj∈N iαijWhg′\\nj\\uf8f6\\n\\uf8f8 (7)\\nwhere Kis the number of attention heads, ||is the concatenate operation, and nis the number of\\nnodes in thought graph. We then use a single-layer feed-forward neural network (FFNN) to obtain\\nthe final thought graph embedding HG:\\nhg′′= [hg′′\\n0, ..., hg′′\\nn]; HG=FFNN (hg′′) (8)\\n5' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 4}\n",
      "page_content='2.3 Feature Fusion\\nAfter obtaining the encoded features, we use a single head attention to align the text representation\\nHTwith image representation HIand thought graph representation HG, respectively. The image\\nattention output HIand thought graph attention output HGare calculated by:\\nHI=Softmax\\x12HTHI⊤\\n√\\nd\\x13\\nHI;HG=Softmax\\x12HTHG⊤\\n√\\nd\\x13\\nHG(9)\\nwhere QisHTanddis the dimension of HT. We take both KIandVIasHIandKGandVGas\\nHG. Please note that image representation is optional and is only required for multimodal dataset.\\nNext, a gated fusion mechanism [ 17,1,18,19] is applied to combine the attention outputs HIand\\nHGwith the text representation HT. The feature fusion output Hcan be calculated by:\\nλ=(\\nSigmoid\\x00\\nWTHT+WGHG\\x01\\ntext-only reasoning\\nSigmoid\\x00\\nWTHT+WIHI+WGHG\\x01\\nmultimodal reasoning(10)\\nH=(\\n(1−λ)·HT+λ·HGtext-only reasoning\\n(1−λ)·HT+λ·HI+λ·HGmultimodal reasoning(11)\\nwhere WT,WIandWGare all trainable weights. We then input the fused feature output Hinto the\\ndecoder to predict the rationales or the final answer.\\n3 Experiments\\nDataset We evaluate our model on the text-only GSM8K [ 11] and multimodal ScienceQA bench-\\nmark [ 12]. GSM8K benchmark comprises 8.5K meticulously crafted grade school math problems\\nwith annotated 2 to 8 problem solution steps. For GSM8K, the model is trained to reasoning through\\nthe steps to generate the final answer. ScienceQA benchmark is the pioneering large-scale dataset\\nfor multimodal science questions, equipped with comprehensive annotations for answers, including\\ndetailed lectures and explanations. The dataset contains 21k questions covering three subjects: natural\\nscience, language science, and social science. Each question is presented with a context in the form\\nof natural language or an optional image. The model is trained to elucidate the reasoning process in\\nnatural language while choosing the answer from a set of options. The detailed dataset statistics are\\nshown in Appendix A.2.\\nModel Setup In our experiments, we used T5 [ 9] as our basic model architecture, including both\\nT5-base and T5-large model sizes. Specifically, to ensure a fair comparison, we initialized our model\\nwith the pre-trained T5 checkpoint - UnifiedQA [ 10] and used DETR [ 20] for the vision encoder,\\nfollowing [ 7]. We fine-tuned the models for 50 epochs with a learning rate of 5e-5. The detailed\\ntraining parameters are available in Appendix A.3. We trained our models on four NVIDIA GeForce\\nRTX 4090 24G GPUs.\\n4 Results and Discussion\\n4.1 Main Results\\nBaselines For GSM8K, our baselines include: (1) few-shot LLMs including GPT-3 [ 21], GPT-\\n3.5 [ 5], GPT-4 [ 5], and code-davinci-002 [ 22] (2) LLMs with CoT: To have a fair comparison we\\nalso fine-tuned UnifiedQA baseand UnifiedQA large[10] on GSM8K with traditional two-stage CoT.\\nFor ScienceQA, following [ 1,12], our adopted baselines include: (1) Vision question answering\\n(VQA) baseline models [ 23–30]; (2) Text-to-text LLMs [ 31,32] and (3) Text-to-text LLMs with\\nCoT prompting [ 12,1]. Both UnifiedQA [ 12] and GPT-3.5 [ 12] use generated image captions to\\nincorporate vision semantics. Whereas, Mutimodal-CoT [ 1] injects generated image features into\\ntraditional CoT reasoning.\\n6' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 5}\n",
      "page_content='Table 1: Rationale generation results (%). (*: we re-run the Mutimodal-CoT baseto report the full\\nrouge scores)\\nMODELS ROUGE-L ROUGE-1 ROUGE-2 ROUGE-LSUM\\nGSM8K\\nUnifiedQA base[31] 70.61 75.32 51.13 70.24\\nUnifiedQA large [31] 72.83 76.91 54.25 72.34\\nGoT-T5 base 71.08 75.46 51.85 70.61\\nGoT-T5 large 72.91 76.93 54.57 72.45\\nScienceQA\\nMutimodal-CoT∗\\nbase[1] 96.98 97.26 94.00 97.16\\nGoT-T5 base 98.29 98.43 96.23 98.37\\nGoT-T5 large 98.35 98.45 96.30 98.41\\nResults The rationales generation results can be seen in Table 1. The overall results are reported in\\nTable 2 and Table 3. On the GSM8K dataset, for rationale generation in the first stage, our GoT base\\nmodel achieves a 0.47 improvement in ROUGE-L compared to the UnifiedQA basemodel that did\\nnot incorporate GoT and the GoT largemodel achieves a 0.08 improvement. In the second stage of\\nanswer generation, the GoT base model showed a 3.41% increase in accuracy, while the GoT large\\nmodel achieved a 5.08% improvement. GoT outperformed GPT-3 by 27.18% in accuracy while using\\nsignificantly fewer parameters than GPT-3. Although GPT-4 achieves a result of 92%, there is a high\\nprobability it has over 175 billion parameters. Our model, compared to UnifiedQA large, reduces the\\naccuracy gap by 5%.\\nFor ScienceQA dataset, in rationale generation stage, we can see from Table 1 that our model\\nachieves a ROUGE-L of 98.29 and outperforms the Mutimodal-CoT baseby 1.31. For the final answer\\ngeneration stage, our GoT achieves SOTA in all subjects and all grades. The most direct comparison\\nis that our model achieves an accuracy of 91.68% which is 6.77% higher than that of the Mutimodal-\\nCoT basewith the similar number of parameters and is competitive to the Mutimodal-CoT largewith\\n738M parameters.\\nWe can observe from Table 1 that the impact of GoT on rationale generation is limited. We attribute\\nthis limitation to the fact that the input text for thought graph construction only includes questions\\nand choices. Consequently, the thought graph constructed from such limited information can only\\nfacilitate constrained deductive reasoning. However, in the answer generation stage, when provided\\nwith rationales, the model needs to possess stronger deductive reasoning capabilities to understand the\\nrelationship between rationales, questions, and choices. Therefore, GoT demonstrates a significant\\nadvantage over traditional CoT, elevating the accuracy from 62.70% to 66.11% in GSM8K and\\nfrom 84.91% to 91.54% in ScienceQA task. The results sufficiently suggest that utilizing thought\\ngraph features for deductive reasoning is a more effective approach than the existing methods, which\\nonly consider text or vision features by simply incorporating image captions or fusing generated\\nimage features. In conclusion, our results confirm the effectiveness of utilizing two-dimensional\\ngraph-of-thought and demonstrate the potential of incorporating GoT into reasoning for LLMs.\\nTable 2: Main test accuracy results (ACC%) of GSM8K. Size=backbone model size.\\nMODELS TRAINING SIZE ACC(%)\\nGPT-3 [21] train-set 175B 55.00\\ncode-davinci-002 [22] few-shot 175B 68.01\\nGPT-3.5 [5] few-shot - 57.10\\nGPT-4 [5] few-shot - 92.00\\nUnifiedQA base[10] train-set 223M 62.70\\nGoT-T5 base train-set 223M 66.11\\nUnifiedQA large[10] train-set 738M 77.10\\nGoT-T5 large train-set 738M 82.18\\n7' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 6}\n",
      "page_content='Table 3: Main test accuracy results (%) of ScienceQA. SIZE=backbone model size. Question classes:\\nNAT = natural science, SOC = social science, LAN = language science, TXT = text context, IMG =\\nimage context, NO = no context, G1-6 = grades 1-6, G7-12 = grades 7-12, A VG= average accuracy\\nscores\\nMODEL TRAINING SIZE NAT SOC LAN TXT IMG NO G1-6 G7-12 A VG\\nHuman - - 90.23 84.97 87.48 89.60 87.50 88.10 91.59 82.42 88.40\\nVision question answering baselines\\nMCAN [23] train-set 95M 56.08 46.23 58.09 59.43 51.17 55.40 51.65 59.72 54.54\\nTop-Down [24] train-set 70M 59.50 54.33 61.82 62.90 54.88 59.79 57.27 62.16 59.02\\nBAN [25] train-set 112M 60.88 46.57 66.64 62.61 52.60 65.51 56.83 63.94 59.37\\nDFAF [26] train-set 74M 64.03 48.82 63.55 65.88 54.49 64.11 57.12 67.17 60.72\\nViLT [27] train-set 113M 60.48 63.89 60.27 63.20 61.38 57.00 60.72 61.90 61.14\\nPatch-TRM [28] train-set 90M 65.19 46.79 65.55 66.96 55.28 64.95 58.04 67.50 61.42\\nVisualBERT [29, 30] train-set 111M 59.33 69.18 61.18 62.71 62.17 58.54 62.96 59.92 61.87\\nText-to-text LLMs\\nUnifiedQA base[31] zero-shot 223M 68.16 69.18 74.91 63.78 61.38 77.84 72.98 65.00 70.12\\nGPT-3.5 [32] zero-shot 175B 74.64 69.74 76.00 74.44 67.28 77.42 76.80 68.89 73.97\\nText-to-text LLMs with CoT\\nUnifiedQA base(CoT) [12] zero-shot 223M 71.00 76.04 78.91 66.42 66.53 81.81 77.06 68.82 74.11\\nGPT-3.5 (CoT) [12] 2-shot 175B 75.44 70.87 78.09 74.68 67.43 79.93 78.23 69.68 75.17\\nChatGPT (CoT) [33] few-shot - 78.82 70.98 83.18 77.37 67.92 86.13 80.72 74.03 78.31\\nGPT-4 (CoT) [33] few-shot - 85.48 72.44 90.27 82.65 71.49 92.89 86.66 79.04 83.99\\nMutimodal-CoT base[1] train-set 223M 87.52 77.17 85.82 87.88 82.90 86.83 84.65 85.37 84.91\\nGoT-T5 base train-set 223M92.51 88.98 91.61 92.39 90.84 92.33 91.68 91.27 91.54\\n±0.24 ±0.37 ±0.78 ±0.23 ±0.39 ±0.60 ±0.05 ±0.36 ±0.12\\nMutimodal-CoT large[1] train-set 738M 95.91 82.00 90.82 95.26 88.80 92.89 92.44 90.31 91.68\\nGoT-T5 large train-set 738M96.51 82.26 93.61 96.56 89.56 94.29 93.83 90.86 92.77\\n±0.25 ±0.21 ±0.19 ±0.26 ±0.29 ±0.10 ±0.18 ±0.38 ±0.18\\n4.2 Further Exploration\\n4.2.1 Ablation Study\\nIn order to make sure that: (1) our GoT’s performance gain is not simply due to the increase of\\nparameters. We conduct an ablation study where we enlarge the number of parameters of Mutimodal-\\nCoT baseto the same size 233M with our model. The enlarged model is denoted as Mutimodal-\\nCoT base(enlarged). (2) introducing thought graphs into GoT reasoning indeed boost the performance.\\nWe construct a random thought graph by randomly select graph nodes. (3) the multi-head attention\\nmechanism in GoT encoder is necessary. We employ a single-head attention. The overall ablation\\nresults can be found in Table 4.\\nTable 4: Ablation results of GoT.\\nMODEL MODEL SIZE G1-6 G7-12 A VG ∆\\nGoT-T5 base\\n233M91.68 91.27 91.54 -\\nw/ Random Connection 91.23 90.18 90.85 -0.69\\nw/ Single-head attention 91.08 90.77 90.97 -0.53\\nMutimodal-CoT base(enlarged) 233M 89.28 87.21 88.54 -3.00\\nFrom the table, we can see that our model significantly outperforms the enlarged Mutimodal-CoT by\\nan accuracy of 3.00%. The results sufficiently proved the importance of introducing thought graphs\\ninto multimodal reasoning. When reducing the multi-head attention to single-head attention, GoT\\nsuffers a loss of 0.53% accuracy, indicating the necessity of multi-head attention mechanism for GoT\\nencoder. By randomly construct thought graphs to disrupt the deductive reasoning process, our model\\nsuffers a loss of 0.69%, indicating the effectiveness of GoT.\\n4.2.2 Analysis\\nPerformance on Different Classes In order to investigate the impact of GoT on the overall\\nmodel performance across different subjects , we calculated the accuracy for different subjects and\\ncompared it with that of enlarged Mutimodal-CoT. We also compare the performance of two models\\non different question classes.The radar Figure 5 shows the overall results for our base model. With\\nrespect to various subjects and question classes, our model demonstrates superior performance over\\n8' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 7}\n",
      "page_content='the Mutimodal-CoT baseand attains a more consistent and enhanced outcome. Our model presents\\noutstanding advantages especially in the field of social science, with an accuracy improvement of\\n8.01%. For different question classes, our model demonstrates the largest improvement on questions\\ninvolving images. Our hypothesis is that by constructing a thought graph and integrating the three\\nfeatures of text, image, and thought graph, we can better align the textual and visual information\\nfor the model, thus maximizing the utilization of visual information and obtaining more accurate\\nanswers.\\n75.0080.0085.0090.0095.00100.00NAT\\nSOC\\nLAN\\nTXTIMGNOMutimodal-CoT(enlarged) Ours(base)\\nFigure 5: Performance on different question\\nclasses5 1080859095100\\nGradesAccuracy(%)\\nOurs base\\nMutimodal-CoT base(enlarged)\\nFigure 6: Performance on different grades\\nPerformance on Different Grades It can be seen from the Table 4 that the enlarged Mutimodal-\\nCoT experience a decrease in accuracy of 2.07 as the grade level of the given question increases\\nwhile GoT only has minor decrease of 0.41. We believe the main reason is that by incorporating\\nGoT, models acquires the ability for deductive reasoning and can better comprehend the relationships\\nbetween different entities and thus better understand the meaning of the problems. Through this\\nmethod, for higher-grade problems with greater complexity, the model can construct a thought graph\\nto help itself generate a more complete logical chain for deduction, thereby generating more accurate\\nanswers. More detailed model performance on different grades can be found in Figure 6. We can see\\nfrom the figure that in the lower grade, two models achieves a similar performance. As the grade level\\nincreases and the difficulty of the questions becomes more challenging, the gap between our model\\nand the Mutimodal-CoT model gradually widens. Due to the small number of questions ( ≤130)\\navailable for each grade in grade 1 and grades 9-12, there is greater fluctuation in the accuracy of\\nboth models. Nevertheless, it is evident from the table that our model exhibits stronger and more\\nstable advantages over Mutimodal-CoT in each grade.\\nCase Study and Limitation In order to gain a deeper understanding of the performance of GoT, we\\nconduct a manual investigation of randomly selected examples generated by our approach which can\\nbe found in Appendix A.4. We also visualize the attention weights aijin GoT encoder to demonstrate\\nhow GoT performs deductive reasoning to generate more accurate answers in Appendix A.5\\nFor the limitation of this work, compared to CoT, GoT may result in additional computational costs\\nand slightly slower training times. Detailed limitation analysis can be found in Appendix A.6.\\n5 Conclusion\\nWe introduce a novel Graph-of-Thought (GoT) reasoning approach, which is an innovative method\\nfor modeling the non-sequential nature of human thinking within large language models (LLMs).\\nGoT enhances LLMs with deductive reasoning abilities, providing a more realistic representation of\\n9' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 8}\n",
      "page_content='thought processes. Our experiments showcases the superiority of GoT on the text-only reasoning\\ndataset, achieving an accuracy of 82.18% on the GSM8K test set, outperforming GPT-3 significantly\\nwhile utilizing significantly fewer parameters. Furthermore, GoT establishes a new state-of-the-art\\non the multimodal reasoning benchmark, ScienceQA, achieving an impressive accuracy of 92.77%\\nwith fewer parameters. This performance surpasses strong ChatGPT and GPT-4 systems, as well as\\nhuman performance, demonstrating the efficacy of GoT. Through comprehensive case studies and\\nablation studies, we provide substantial evidence of the effectiveness of GoT in reasoning tasks. If\\nyou want it, you GoT it!\\nReferences\\n[1]Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multi-\\nmodal chain-of-thought reasoning in language models. CoRR , abs/2302.00923, 2023. doi: 10.\\n48550/arXiv.2302.00923. URL https://doi.org/10.48550/arXiv.2302.00923 .\\n[2]Lawrence W Barsalou. Perceptual symbol systems. Behavioral and brain sciences , 22(4):\\n577–660, 1999.\\n[3]Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-\\nwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,\\nAriel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M.\\nZiegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz\\nLitwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish,\\nAlec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learn-\\ners. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and\\nHsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual\\nConference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-\\n12, 2020, virtual , 2020. URL https://proceedings.neurips.cc/paper/2020/\\nhash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html .\\n[4]Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\\nKensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay,\\nNoam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope,\\nJames Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke,\\nAnselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant\\nMisra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek\\nLim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal,\\nMark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor\\nLewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou,\\nXuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language\\nmodeling with pathways. CoRR , abs/2204.02311, 2022. doi: 10.48550/arXiv.2204.02311. URL\\nhttps://doi.org/10.48550/arXiv.2204.02311 .\\n[5]OpenAI. Gpt-4 technical report. 2023. URL https://cdn.openai.com/papers/\\ngpt-4.pdf .\\n[6]Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi, Quoc Le, and\\nDenny Zhou. Chain of thought prompting elicits reasoning in large language models. CoRR ,\\nabs/2201.11903, 2022. URL https://arxiv.org/abs/2201.11903 .\\n[7]Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V . Le, Ed H. Chi, and Denny Zhou. Self-\\nconsistency improves chain of thought reasoning in language models. CoRR , abs/2203.11171,\\n2022. doi: 10.48550/arXiv.2203.11171. URL https://doi.org/10.48550/arXiv.\\n2203.11171 .\\n[8]Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. Automatic chain of thought prompting\\nin large language models. CoRR , abs/2210.03493, 2022. doi: 10.48550/arXiv.2210.03493.\\nURL https://doi.org/10.48550/arXiv.2210.03493 .\\n10' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 9}\n",
      "page_content='[9]Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\\nYanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified\\ntext-to-text transformer. Journal of Machine Learning Research , 21(140):1–67, 2020. URL\\nhttp://jmlr.org/papers/v21/20-074.html .\\n[10] Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark,\\nand Hannaneh Hajishirzi. Unifiedqa: Crossing format boundaries with a single QA system. In\\nTrevor Cohn, Yulan He, and Yang Liu, editors, Findings of the Association for Computational\\nLinguistics: EMNLP 2020, Online Event, 16-20 November 2020 , volume EMNLP 2020 of\\nFindings of ACL , pages 1896–1907. Association for Computational Linguistics, 2020. doi:\\n10.18653/v1/2020.findings-emnlp.171. URL https://doi.org/10.18653/v1/2020.\\nfindings-emnlp.171 .\\n[11] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christo-\\npher Hesse, and John Schulman. Training verifiers to solve math word problems. CoRR ,\\nabs/2110.14168, 2021. URL https://arxiv.org/abs/2110.14168 .\\n[12] Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind\\nTafjord, Peter Clark, and Ashwin Kalyan. Learn to explain: Multimodal reasoning via thought\\nchains for science question answering. In The 36th Conference on Neural Information Process-\\ning Systems (NeurIPS) , 2022.\\n[13] Jiaao Chen and Diyi Yang. Structure-aware abstractive conversation summarization via discourse\\nand action graphs. In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-\\nTür, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou, editors,\\nProceedings of the 2021 Conference of the North American Chapter of the Association for\\nComputational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-\\n11, 2021 , pages 1380–1391. Association for Computational Linguistics, 2021. doi: 10.18653/v1/\\n2021.naacl-main.109. URL https://doi.org/10.18653/v1/2021.naacl-main.\\n109.\\n[14] Gabor Angeli, Melvin Jose Johnson Premkumar, and Christopher D. Manning. Leveraging\\nlinguistic structure for open domain information extraction. In Proceedings of the 53rd Annual\\nMeeting of the Association for Computational Linguistics and the 7th International Joint\\nConference on Natural Language Processing (Volume 1: Long Papers) , pages 344–354, Beijing,\\nChina, July 2015. Association for Computational Linguistics. doi: 10.3115/v1/P15-1034. URL\\nhttps://aclanthology.org/P15-1034 .\\n[15] Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, and David\\nMcClosky. The Stanford CoreNLP natural language processing toolkit. In Proceedings of 52nd\\nAnnual Meeting of the Association for Computational Linguistics: System Demonstrations ,\\npages 55–60, Baltimore, Maryland, June 2014. Association for Computational Linguistics. doi:\\n10.3115/v1/P14-5010. URL https://aclanthology.org/P14-5010 .\\n[16] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua\\nBengio. Graph attention networks. In 6th International Conference on Learning Representations,\\nICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings .\\nOpenReview.net, 2018. URL https://openreview.net/forum?id=rJXMpikCZ .\\n[17] Zhiyong Wu, Lingpeng Kong, Wei Bi, Xiang Li, and Ben Kao. Good for misconceived reasons:\\nAn empirical revisiting on the need for visual context in multimodal machine translation. In\\nProceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the\\n11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) ,\\npages 6153–6166, Online, August 2021. Association for Computational Linguistics. doi: 10.\\n18653/v1/2021.acl-long.480. URL https://aclanthology.org/2021.acl-long.\\n480.\\n[18] Bei Li, Chuanhao Lv, Zefan Zhou, Tao Zhou, Tong Xiao, Anxiang Ma, and JingBo Zhu. On\\nvision features in multimodal machine translation. In Proceedings of the 60th Annual Meeting\\nof the Association for Computational Linguistics (Volume 1: Long Papers) , pages 6327–6337,\\nDublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.\\nacl-long.438. URL https://aclanthology.org/2022.acl-long.438 .\\n11' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 10}\n",
      "page_content='[19] Zhuosheng Zhang, Kehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita, Zuchao Li, and\\nHai Zhao. Neural machine translation with universal visual representation. In 8th International\\nConference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020 .\\nOpenReview.net, 2020. URL https://openreview.net/forum?id=Byl8hhNYPS .\\n[20] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kir-\\nillov, and Sergey Zagoruyko. End-to-end object detection with transformers. In Andrea\\nVedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm, editors, Computer Vision\\n- ECCV 2020 - 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceed-\\nings, Part I , volume 12346 of Lecture Notes in Computer Science , pages 213–229. Springer,\\n2020. doi: 10.1007/978-3-030-58452-8\\\\_13. URL https://doi.org/10.1007/\\n978-3-030-58452-8_13 .\\n[21] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\\nlanguage models are zero-shot reasoners. CoRR , abs/2205.11916, 2022. doi: 10.48550/arXiv.\\n2205.11916. URL https://doi.org/10.48550/arXiv.2205.11916 .\\n[22] Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale\\nSchuurmans, Olivier Bousquet, Quoc Le, and Ed H. Chi. Least-to-most prompting enables\\ncomplex reasoning in large language models. CoRR , abs/2205.10625, 2022. doi: 10.48550/\\narXiv.2205.10625. URL https://doi.org/10.48550/arXiv.2205.10625 .\\n[23] Zhou Yu, Jun Yu, Yuhao Cui, Dacheng Tao, and Qi Tian. Deep modular co-attention\\nnetworks for visual question answering. In IEEE Conference on Computer Vision and Pattern\\nRecognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019 , pages 6281–6290.\\nComputer Vision Foundation / IEEE, 2019. doi: 10.1109/CVPR.2019.00644. URL\\nhttp://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Deep_\\nModular_Co-Attention_Networks_for_Visual_Question_Answering_\\nCVPR_2019_paper.html .\\n[24] Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen\\nGould, and Lei Zhang. Bottom-up and top-down attention for image captioning and vi-\\nsual question answering. In 2018 IEEE Conference on Computer Vision and Pattern\\nRecognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018 , pages 6077–6086.\\nComputer Vision Foundation / IEEE Computer Society, 2018. doi: 10.1109/CVPR.2018.\\n00636. URL http://openaccess.thecvf.com/content_cvpr_2018/html/\\nAnderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.html .\\n[25] Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang. Bilinear attention networks. In Samy Ben-\\ngio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman\\nGarnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on\\nNeural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal,\\nCanada , pages 1571–1581, 2018. URL https://proceedings.neurips.cc/paper/\\n2018/hash/96ea64f3a1aa2fd00c72faacf0cb8ac9-Abstract.html .\\n[26] Peng Gao, Zhengkai Jiang, Haoxuan You, Pan Lu, Steven C. H. Hoi, Xiaogang Wang, and\\nHongsheng Li. Dynamic fusion with intra- and inter-modality attention flow for visual question\\nanswering. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019,\\nLong Beach, CA, USA, June 16-20, 2019 , pages 6639–6648. Computer Vision Foundation\\n/ IEEE, 2019. doi: 10.1109/CVPR.2019.00680. URL http://openaccess.thecvf.\\ncom/content_CVPR_2019/html/Gao_Dynamic_Fusion_With_Intra-_and_\\nInter-Modality_Attention_Flow_for_Visual_CVPR_2019_paper.html .\\n[27] Wonjae Kim, Bokyung Son, and Ildoo Kim. Vilt: Vision-and-language transformer without\\nconvolution or region supervision. In Marina Meila and Tong Zhang, editors, Proceedings of\\nthe 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual\\nEvent , volume 139 of Proceedings of Machine Learning Research , pages 5583–5594. PMLR,\\n2021. URL http://proceedings.mlr.press/v139/kim21k.html .\\n[28] Pan Lu, Liang Qiu, Jiaqi Chen, Tanglin Xia, Yizhou Zhao, Wei Zhang, Zhou Yu, Xiaodan\\nLiang, and Song-Chun Zhu. Iconqa: A new benchmark for abstract diagram understand-\\ning and visual language reasoning. In Joaquin Vanschoren and Sai-Kit Yeung, editors,\\n12' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 11}\n",
      "page_content='Proceedings of the Neural Information Processing Systems Track on Datasets and Bench-\\nmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual , 2021. URL\\nhttps://datasets-benchmarks-proceedings.neurips.cc/paper/2021/\\nhash/d3d9446802a44259755d38e6d163e820-Abstract-round2.html .\\n[29] Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang. Visualbert: A\\nsimple and performant baseline for vision and language. CoRR , abs/1908.03557, 2019. URL\\nhttp://arxiv.org/abs/1908.03557 .\\n[30] Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang. What does BERT\\nwith vision look at? In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel R. Tetreault, editors,\\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL\\n2020, Online, July 5-10, 2020 , pages 5265–5275. Association for Computational Linguistics,\\n2020. doi: 10.18653/v1/2020.acl-main.469. URL https://doi.org/10.18653/v1/\\n2020.acl-main.469 .\\n[31] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\\nYanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified\\ntext-to-text transformer. J. Mach. Learn. Res. , 21:140:1–140:67, 2020. URL http://jmlr.\\norg/papers/v21/20-074.html .\\n[32] Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey E.\\nHinton. Big self-supervised models are strong semi-supervised learners. In Hugo\\nLarochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien\\nLin, editors, Advances in Neural Information Processing Systems 33: Annual Conference\\non Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,\\nvirtual , 2020. URL https://proceedings.neurips.cc/paper/2020/hash/\\nfcbc95ccdd551da181207c0c1400c655-Abstract.html .\\n[33] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-\\nChun Zhu, and Jianfeng Gao. Chameleon: Plug-and-play compositional reasoning with large\\nlanguage models. CoRR , abs/2304.09842, 2023. doi: 10.48550/arXiv.2304.09842. URL\\nhttps://doi.org/10.48550/arXiv.2304.09842 .\\n13' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 12}\n",
      "page_content='A Appendix\\nA.1 Related Works\\nIn chain-of-thought reasoning, one idea leads to the next in a logical sequence and builds on previous\\nknowledge. Each idea is supported by evidence or reasoning, and the conclusions drawn from the\\nchain are logical and sound. Most CoT methods can be divided into two categories based on how to\\ngenerate the final answer: (1) prompting for CoT, including zero-shot CoT and few-shot CoT; and (2)\\nfine-tuning for CoT.\\nZero-shot CoT Prompting As large language models continue to advance rapidly, many re-\\nsearchers are beginning to explore CoT reasoning for LLMs. The zero-shot CoT method proposed\\nby Kojima et al. [21] consists of two stages: (1) adding a \" Let’s think step by step \" prompt to generate\\nCoT, and (2) concatenating the generated CoT and adding the phrase \" So the answer is \" to obtain the\\nfinal answer.\\nFew-shot CoT Prompting Few-shot CoT reasoning for LLMs, however, utilizes multiple input-\\noutput pairs to prompt the LLMs to output CoT and obtain the final answer. Due to its ability to\\nprovide better performance compared to Zero-shot CoT, Few-shot CoT has gained more attention in\\nresearch, particularly through effective demonstrations. Few-shot CoT prompting was first formally\\nexplored by Wei et al. [6]and is a form of discrete prompt learning that involves context learning\\nin large models. Compared to traditional in-context learning, which prompts LLMs with a list of\\ninput-output demonstration pairs along with a test input to allow the model to predict output, Few-shot\\nCoT prompting outputs additional logical reasoning procedures apart from the target output. Wang\\net al. [7]proposed a follow-up method to [ 6]. The main improvement is that the model uses the\\nmajority vote for the answers, which was found to significantly improve the performance of the\\nCoT. However, these few-shot CoT models depend on hand-crafted demonstrations. To solve this\\nproblem, Zhang et al. [8]proposed Auto-CoT, which maintains the diversity of sampled questions\\nand generates reasoning chains to automatically construct demonstrations. Specifically, Auto-CoT\\nconsists of two main stages: (1) Problem clustering: divide the given dataset of problems into several\\nclusters; (2) Demonstration sampling: select a representative problem from each cluster and use a\\nsimple heuristic method to generate its reasoning chain. Furthermore, Lu et al. [33] also explores\\nfew-shot CoT reasoning for recently popular LLMs ChatGPT and GPT-4 [5].\\nCoT Fine-tuning In Zhang et al. [1], it was proposed to fine-tune smaller language models instead\\nof prompting them in LLMs. And this approach enabled the CoT to go beyond textual information\\nand incorporate visual (image) modalities using a gated fusion mechanism into a two-stage CoT. The\\nresults demonstrated that CoT fine-tuning with fewer parameters has potential. Therefore, in this\\nwork, we focus on fine-tuning for CoT to reduce the number of required model parameters and help\\nLLMs better comprehend different modalities. However, previous CoT research has been limited\\nto different modalities, such as textual and vision information, without considering the deduction\\nreasoning process. Therefore, in this work, we move beyond modeling the reasoning process solely\\nas a thought chain and elevate it to a thought graph. We provide a more comprehensive and nuanced\\nrepresentation, enabling LLMs to perceive the deduction reasoning process accurately, resulting in\\nmore precise answer generation.\\n14' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 13}\n",
      "page_content='A.2 Dataset statistics\\nSplits #Problems\\nTrain 7,473\\nTest 1,319\\nTable 5: GSM8K dataset statistics (# denotes\\nnumbers)Statistic Number\\nSplits\\n#Train 12,726\\n#Dev 4,241\\n#Test 4,241\\n#Total 21,208\\nAttribute\\n#Subjects 3\\n#Topic 26\\n#Category 127\\n#Skill 379\\nTable 6: ScienceQA dataset statistics (# denotes\\nnumbers)\\nA.3 Training Parameters\\nParameters Value\\nEpochs 50\\nBatch size for T5-base (per device) 4\\nBatch size for T5-large (per device) 2\\nLearning rate 5e-5\\nWeight decay 0.01\\nMax input length 512\\nMax number of nodes 150\\nTable 7: Training parameters for GoT\\nA.4 Case Study\\nTo facilitate a more illustrative comparison between GoT and the CoT, we have selected several\\nrepresentative examples. Figure 11 demonstrates examples for GSM8K dataset. Figure 8 to Figure\\n10 illustrates examples from ScienceQA dataset. From Figure 7 and Figure 8, we can see that GoT\\ncan better understand the rationales and generate more accurate result. In Figure 9, we can see that\\nwhen provided with wrong rationale, our model is more robust to the noise and can focus on more\\nimportant key information. (We highlight the noisy wrong rationale in red and correct key rationale in\\ngreen). Figure 10 presents a language problem which have less context and requires a certain amount\\nof common sense knowledge. Hence, the impact of constructing a mind map on enhancing the model\\nis not significant. Therefore, both GoT and CoT predict wrong answers.\\nA.5 Representation Visualization\\nIn order to demonstrate the deductive reasoning process of GoT more intuitively, we visualized the\\nattention weights of the GoT encoder. The visualization results can be found in Figure 12. We took\\nFigure 9 as an example. In Figure 9, even given a wrong rationale, GoT still manages to generate the\\nright answer. We select 14 representative thought nodes and found that \"blue\",\"color\", and \"common\"\\nhave the greatest weights which indicates that GoT guides the model to focus on more important\\nwords and conduct correct deductive reasoning. For the disruptive node \"a hard object,\" our model\\ncan effectively discriminate against it and assign a lower attention weight to prevent the model from\\nselecting incorrect answers, as traditional CoT models often do due to erroneous rationales.\\nA.6 Limitation\\nCompared to Mutimodal-CoT [ 1], incorporating GoT may result in additional computational costs\\nand slightly slower training times. The training parameters and inference times of the different\\nmodels are presented in Table 8, which reveals that our model requires a 0.2% increase in parameters\\ncompared to Mutimodal-CoT.\\n15' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 14}\n",
      "page_content='Table 8: The number of training parameters and inference time of different models (# denotes\\nnumbers)\\n#ParametersInference time\\n(eval samples/per second)\\nMutimodal-CoT base[1] 227M 16.33\\nOurs 233M 13.38\\n16' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 15}\n",
      "page_content='Dataset\\nGoT Prediction\\nCoT PredictionQuestion: Would you find the word pink on a dictionary page with the following guide words?\\nparrot –property\\nChoices: (A) yes (B) no\\nRationale :lecture :Guide words appear oneach page ofadictionary .They tellyouthefirst\\nword andlastword onthepage .Theother words onthepage come between theguide\\nwords inalphabetical order .Toputwords inalphabetical order, putthem inorder bytheir\\nfirstletters .Ifthefirstletters arethesame, look atthesecond letters .Ifthesecond letters\\narethesame, look atthethird letters, andsoon.Ifoneword isshorter, andthere areno\\nmore letters tocompare, then theshorter word comes first inalphabetical order .For\\nexample, becomes before bed.\\nsolution :Putthewords inalphabetical order .Since pink isbetween theguide words parrot -\\nproperty, itwould befound onthatpage .\\nAnswer :Theanswer is(A)\\nRationale :Solution :Guide words appear oneach page ofadictionary .They tellyouthefirst\\nword andlastword onthepage .Theother words onthepage come between theguide\\nwords inalphabetical order .Toputwords inalphabetical order, putthem inorder bytheir\\nfirstletters .Ifthefirstletters arethesame, look atthesecond letters .Ifthesecond letters\\narethesame, look atthethird letters, andsoon.Ifoneword isshorter, andthere areno\\nmore letters tocompare, then theshorter word comes first inalphabetical order .For\\nexample, becomes before bed.Putthewords inalphabetical order .Since pink isbetween\\ntheguide words parrot -property, itwould befound onthatpage .\\nAnswer :Theanswer is(A)\\nRationale :Solution :Guide words appear oneach page ofadictionary .They tellyouthefirst\\nword andlastword onthepage .Theother words onthepage come between theguide\\nwords inalphabetical order .Toputwords inalphabetical order, putthem inorder bytheir\\nfirstletters .Ifthefirstletters arethesame, look atthesecond letters .Ifthesecond letters\\narethesame, look atthethird letters, andsoon.Ifoneword isshorter, andthere areno\\nmore letters tocompare, then theshorter word comes first inalphabetical order .For\\nexample, becomes before bed.Putthewords inalphabetical order .Since pink isbetween\\ntheguide words parrot -property, itwould befound onthatpage .\\nAnswer :Theanswer is(B)right rationales right answer\\nright rationales wrong answerFigure 7: Examples of ScienceQA\\n17' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 16}\n",
      "page_content='Dataset\\nGoT Prediction\\nCoT PredictionQuestion: What is the name of the colony shown ?\\nChoices: (A) New Hampshire (B) Vermont\\n(C) New York\\nRationale :The colony isNew York.During the\\ncolonial era,New Hampshire andNew York both\\nclaimed theterritory that would later become the\\nstate ofVermont .Vermont was never itsown\\ncolony .\\nAnswer :Theanswer is(C)\\nRationale :Solution :Thecolony isNew York.During thecolonial era,New Hampshire and\\nNew York both claimed theterritory that would later become thestate ofVermont .\\nVermont wasnever itsown colony .\\nAnswer :Theanswer is(C)\\nRationale :Solution :Thecolony isDelaware York.During thecolonial era,New Hampshire\\nandNew York both claimed theterritory that would later become thestate ofVermont .\\nVermont wasnever itsown colony .\\nAnswer :Theanswer is(D)\\n(D) Delaware\\nright rationales right answer\\nwrong rationales wrong answerFigure 8: Examples of ScienceQA\\n18' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 17}\n",
      "page_content='Dataset\\nGoT Prediction\\nCoT PredictionQuestion: Which property do these three \\nobjects have in common?\\nChoices: (A) blue (B) hard\\n(C) sticky\\nRationale :lecture :Anobject hasdifferent properties .Aproperty ofanobject cantellyou\\nhow itlooks, feels, tastes, orsmells .Properties canalso tellyouhow anobject willbehave\\nwhen something happens toit.Different objects canhave properties incommon .Youcan\\nusethese properties toputobjects intogroups .\\nSolution :Look ateach object .Foreach object, decide ifithasthatproperty .Asticky object\\ncanattach orstick toother things .Thetoothpaste issticky, butthesoccer shorts andthe\\nwater slide arenot.Blue isacolor .Thiscolor isblue.Allthree objects areblue.Ahard object\\ndoes notchange shape when pressed orsqueezed .The water slide ishard, butthe\\ntoothpaste and thesoccer shorts arenot.The property that allthree objects have in\\ncommon isblue.\\nAnswer :Theanswer is(A)\\nRationale :Solution :Anobject hasdifferent properties .Aproperty ofanobject cantellyou\\nhow itlooks, feels, tastes, orsmells .Properties canalso tellyouhow anobject willbehave\\nwhen something happens toit.Different objects canhave properties incommon .Youcan\\nusethese properties toputobjects intogroups .Look ateach object .Foreach object, decide\\nifithasthatproperty .Ahard object canattach orstick toother things .The issticky, butthe\\nshorts andthepitcher arenot.Blue isacolor .Thiscolor isblue.Thethree objects areblue.\\nAhard object does notchange shape when pressed orsqueezed .Thetennis slide andhard,\\nbutthetennis and thewater shorts arenot.Theproperty that allthree objects have in\\ncommon isblue.\\nAnswer :Theanswer is(A)\\nRationale :Solution :Anobject hasdifferent properties .Aproperty ofanobject cantellyou\\nhow itlooks, feels, tastes, orsmells .Properties canalso tellyouhow anobject willbehave\\nwhen something happens toit.Different objects canhave properties incommon .Youcan\\nusethese properties toputobjects intogroups .Look ateach object .Foreach object, decide\\nifithasthatproperty .Asticky object canattach orstick toother things .Theissticky, butthe\\nshorts andtheblue bottle arenot.Blue isacolor .Thiscolor isblue.None three objects are\\nblue.Ahard object does notchange shape when pressed orsqueezed .None tennis slide\\nandhard, buttheisthewater shorts arenot.Theproperty that allthree objects have in\\ncommon issticky .\\nAnswer :Theanswer is(C)wrong rationales right answer\\nwrong rationales wrong answerFigure 9: Examples of ScienceQA\\n19' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 18}\n",
      "page_content=\"Dataset\\nGoT Prediction\\nCoT PredictionQuestion: Select the action that doesn't belong\\nChoices:(A) chop (B) blend\\n(C) stir\\nRationale :Chop doesn't belong .Blend, mix,andstiralldescribe ways tocombine\\nthings\\nAnswer :Theanswer is(A)\\nRationale :Solution :Mixp doesn‘tbelong .Murend, chop, andchop allname things toget\\nthings .\\nAnswer :Theanswer is(D)\\nRationale :Solution :Blendp doesn't belong ..Murend ,chop, andblend allname things to\\ngetAnswer :Theanswer is(B)(D) mix\\nwrong rationales wrong answerwrong rationales wrong answerFigure 10: Examples of ScienceQA\\n20\" metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 19}\n",
      "page_content='Dataset\\nGoT Prediction\\nCoT PredictionQuestion: James is putting together 4 tables.  Each table has 4 legs and each leg needs 2 \\nscrews.  He has 40 screws.  How many screws will he have left over?\\nRationale :Each table will take 4*2=<<4*2=8>>8screws .So he needs\\n8*4=<<8*4=32>>32screws \\\\nThat means hewillhave 40-32=<<40-32=8>>8screws\\nleftover\\nAnswer :Theanswer is8\\nRationale :Each table needs have 4*2=4*2=8>>8screws .Soheneeds 8*4=8*4=32>>32\\nscrews .That means heneeds have 40-32=40-32=8>>8leftleftover\\nAnswer :Theanswer is8\\nRationale :Hetable needs have 4*2=4*2=8>>8screws .Sohewill8*4=8*4=32>>32screws .\\nSomeans heneeds have 40-32=40-32=16>>8screws leftover\\nAnswer :Theanswer is168\\nwrong rationales wrong answerright rationales right answer\\nDataset\\nGoT Prediction\\nCoT PredictionQuestion: The caretaker of the docks needs to buy some new line. He wants 3 feet of line \\nfor every foot of dock. Right now, there is 200 feet of dock, and he has 6 feet of new line. \\nHow many feet of line does he need to buy in total?\\nRationale :200*3=<<200*3=600>>600feetofline.Thecaretaker needs tobuy600-6=\\n<<600-6=594>>594feetofline.\\nAnswer :Theanswer is594\\nRationale :Thefeet3=200*3=3>>600feetofline.Hecaretaker needs 600buy600/6=600-\\n6=1>>>594feetofline.\\nAnswer :Theanswer is594\\nRationale :Thefeet3=200*3=3>>600feetofline.Hecaretaker needs 600buy600/6=600-\\n6=15>>594feetofline.\\nAnswer :Theanswer is1594\\nwrong rationales wrong answerwrong rationales right answerFigure 11: Examples of GSM8K\\n21' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 20}\n",
      "page_content='three objects\\nhave in\\ncommon\\nobject\\nhas\\ndifferent properties\\nput objects into\\ngroups\\na hard object\\ncan attach to\\nother things\\nis\\ncolor\\nblue49.56\\n44.00\\nFigure 12: Representation visualization\\n22' metadata={'source': 'pdf/Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models.pdf', 'page': 21}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nSKELETON -OF-THOUGHT : L ARGE LANGUAGE MOD-\\nELSCANDOPARALLEL DECODING\\nXuefei Ning1∗\\nfoxdoraame@gmail.comZinan Lin2∗\\nlinzinan1995@gmail.com\\nZixuan Zhou1∗\\nzhouzx21@mails.tsinghua.edu.cnZifu Wang3\\nzifu.wang@kuleuven.be\\nHuazhong Yang1\\nyanghz@tsinghua.edu.cnYu Wang1\\nyu-wang@tsinghua.edu.cn\\n1Department of Electronic Engineering, Tsinghua University, Beijing, China\\n2Microsoft Research, Redmond, Washington, USA\\n3ESAT-PSI, KU Leuven, Leuven, Belgium\\nWebsite: https://sites.google.com/view/sot-llm\\nABSTRACT\\nThis work aims at decreasing the end-to-end generation latency of large language\\nmodels (LLMs). One of the major causes of the high generation latency is the\\nsequential decoding approach adopted by almost all state-of-the-art LLMs. In\\nthis work, motivated by the thinking and writing process of humans, we propose\\nSkeleton-of-Thought (SoT) , which first guides LLMs to generate the skeleton of\\nthe answer, and then conducts parallel API calls or batched decoding to com-\\nplete the contents of each skeleton point in parallel . Not only does SoT provide\\nconsiderable speed-ups across 12 LLMs, but it can also potentially improve the\\nanswer quality on several question categories. SoT is an initial attempt at data-\\ncentric optimization for inference efficiency, and further underscores the potential\\nof pushing LLMs to think more like a human for answer quality.\\n1 I NTRODUCTION\\nLarge language models (LLMs) (Brown et al., 2020; Touvron et al., 2023a; Du et al., 2022; OpenAI,\\n2023; Zheng et al., 2023) have shown exceptional performance in natural language processing and\\nchatbot systems. However, the inference process of the state-of-the-art LLMs is slow, hindering their\\ninteractive use. For example, it takes 22 seconds for Claude (Anthropic, 2023) (accessed through\\nSlack API) and 43 seconds for Vicuna-33B V1.3 (a 33B LLaMA-based model, running locally on\\none NVIDIA A100 GPU) to answer the question in Fig. 1.\\nWe conclude three major causes of LLMs’ slow inference: (1) A large model size requires a large\\namount of memory, memory access, and computation. For example, the FP16 weights of 175B GPT-\\n3 take 350GB memory, which means at least 5 ×80GB A100 GPUs are needed to keep the model\\nin GPU memory. Even with enough GPUs, the heavy memory access and computation slow down\\nthe inference. (2) The attention operation in the prevailing transformer architecture is I/O bounded\\nand has a quadratic memory and computation complexity in sequence length. (3) The sequential\\ndecoding approach in inference generates tokens one by one. This approach introduces a significant\\n∗Equal contribution.\\n†The main updates in arXiv V2 are as follows: (1) Add the quality and efficiency evaluation of SoT on\\nGPT-4. (2) Use GPT-4 as the judge for answer quality evaluation. The old results with ChatGPT-3.5 as the\\njudge are moved to App. I.3. (3) Add the SoT with Router (SoT-R) method (§ 4) which adaptively triggers SoT\\non suitable questions. (4) Move detailed answer analysis to the appendices.\\n1arXiv:2307.15337v2  [cs.CL]  8 Oct 2023' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 0}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nAnswer1.Active listening involves fully concentrating on …2.Identify issues. Look into the root causes of …3.Compromise. Look for a middle ground …What are the most effective strategies for conflict resolution in the workplace?QuestionSkeleton-of-Thought Decoding\\nGeneratesanswerssequentially ➔SlowerNormal Decoding1. Active listening2. Identify issues3. CompromiseGeneratesanswersinparallel➔Faster(1)Skeletonstage(2)Point-expandingstage\\n1.0 1.2 1.4 1.6 1.8\\nSpeed-up−0.20.00.20.4Net win ratesVicuna-13B V1.3StableVicuna-13B\\nUltraLM-13B\\nVicuna-33B V1.3\\nLLaMA2-Chat-7B\\nLLaMA2-Chat-13BVicuna-7B V1.3ChatGPT-3.5\\nClaude\\nVicuna-7B V1.1OpenChat-13BGPT-4\\nBaseline\\nFigure 1: Left: An illustration of Skeleton-of-Thought (SoT). Instead of producing answers se-\\nquentially, SoT produces different parts of answers in parallel . In more detail, given the question,\\nSoT first prompts the LLM to give out the skeleton, then conducts batched decoding or parallel API\\ncalls to expand multiple points in parallel, and finally aggregates the outputs to get the final answer.\\nRight: The net win rates and speed-ups of SoT with router (SoT-R) compared to normal generation\\non Vicuna-80. The net win rate is the difference between the fraction of questions that SoT-R has\\nbetter and worse answers than normal generation. The speed-up is the ratio between the latency\\nof normal and SoT-R generation. (1.0,0.0)represents normal generation. Higher is better on both\\naxes. For most models, SoT-R not only accelerates the generation but also improves the quality of\\nthe answers (evaluated with FastChat metric (Zheng et al., 2023)). See § 3.2 and 4 for more details.\\ninference latency since the generation of tokens cannot be parallelized. There is a bunch of literature\\naddressing the first two axes: large model size (Xiao et al., 2022; Frantar et al., 2022; Lin et al., 2023;\\nSheng et al., 2023; Wang et al., 2021) and attention operation (Kitaev et al., 2020; Wang et al., 2020;\\nDao et al., 2022; Zaheer et al., 2020; Chen et al., 2023b). These works either compress/redesign the\\nmodel (Xiao et al., 2022; Frantar et al., 2022; Lin et al., 2023; Kitaev et al., 2020; Wang et al., 2020;\\nDao et al., 2022; Zaheer et al., 2020) or redesign the serving system (Sheng et al., 2023; Chen et al.,\\n2023b) and hardware (Wang et al., 2021).\\nIn contrast to prior work, we tackle the third axis and question the common assumption that LLMs\\nhave to do fully sequential decoding. We show the feasibility of parallel decoding of off-the-shelf\\nLLMs without any changes to their model, system, or hardware . For instance, for the question\\nin Fig. 1, we can reduce the latency from 22 seconds to 12 seconds (1.83 ×speed-up) with Claude,\\nand from 43 seconds to 16 seconds (2.69 ×speed-up) with Vicuna-33B V1.3 on an NVIDIA A100.\\nThe idea stems from reflecting on how humans ourselves answer questions. Humans do notalways\\nthink about questions and write answers in a sequential fashion. In contrast, for many question\\ntypes, we first derive the skeleton according to some protocols and strategies, and then add evidence\\nand details to refine and explicate each point. This is especially the case on formal occasions like\\noffering consultancy, taking tests, writing papers, and so on. Can we make LLMs think in the same\\nway? To this end, we propose Skeleton-of-Thought (SoT) . Specifically, as shown in Fig. 1, we guide\\nthe LLM to derive a skeleton first by itself. Based on the skeleton, the LLMs can complete each\\npoint in parallel so that we get a speed-up. SoT can be utilized to accelerate both open-source\\nmodels with batched decoding and API-based models with parallel API calls.\\nTo make the overall solution more practical, we also design an extension, SoT with router (SoT-R),\\nwhich employs a router to only trigger SoT for suitable questions.\\nWe test SoT on 12 recently released LLMs. Not only does SoT provide considerable speed-ups (up\\nto 2.39 ×), but it can also improve the answer quality in many cases (Fig. 1).\\nNote that in contrast to existing model- and system-level efforts for inference efficiency, SoT takes\\na novel “data-level” pathway by letting the LLM organize its output content. This novel perspective\\nis becoming feasible and is expected to grow in relevance, owing to the evolving capabilities of\\nstate-of-the-art LLMs. We hope this work can stimulate more research in the realm of data-centric\\noptimization (Zha et al., 2023; HazyResearch, 2023) for efficiency.\\n2' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 1}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nPrompt 1. Skeleton Prompt Template Ts\\n[User:] You’re an organizer responsible for only giving the skeleton (not the full content) for answering the question.\\nProvide the skeleton in a list of points (numbered 1., 2., 3., etc.) to answer the question. Instead of writing a full sentence,\\neach skeleton point should be very short with only 3 ∼5 words. Generally, the skeleton should have 3 ∼10 points. Now,\\nplease provide the skeleton for the following question.\\n{question }\\nSkeleton:\\n[Assistant:] 1.\\nPrompt 2. Point-Expanding Prompt Template Tpe\\n[User:] You’re responsible for continuing the writing of one and only one point in the overall answer to the following\\nquestion.\\n{question }\\nThe skeleton of the answer is\\n{skeleton }\\nContinue and only continue the writing of point {point index }. Write it **very shortly** in 1 ∼2 sentence and\\ndo not continue with other points!\\n[Assistant:] {point index }.{point skeleton }\\nThe rest of the paper is organized as follows. We first introduce SoT in § 2 and show its results in\\n§ 3. Then, we expand on the SoT-R extension in § 4. § 5 positions SoT in the research ecosystem\\n(expanded in App. D). Finally, we analyze the limitations and share outlooks of SoT in § 6.\\n2 S KELETON -OF-THOUGHT (SOT)\\n2.1 M ETHOD\\nOverview. Based on the intuition that humans usually think about and answer a question in an\\norganized way, the core idea of this work is to guide the LLM itself to give a skeleton first and then\\nwrite the overall answer parallelly instead of sequentially. Fig. 1 illustrates how SoT produces the\\nfinal answer to a user question q.\\n(1) Skeleton stage. SoT first assembles a skeleton request ,Ts(question =q), using the skeleton\\nprompt template Ts(Prompt 1, and Prompt 3 in App. B.1) with the question qas the parameter. The\\nskeleton prompt template is written to guide the LLM to output a concise skeleton of the answer.\\nThen, we extract the Bpoints from the skeleton response Rsof the LLM.\\n(2) Point-expanding stage. Based on the skeleton, we let the LLM expand on each point in parallel.\\nSpecifically, for the point with index band skeleton Rs\\nb, SoT uses Tpe(question =q,skeleton =\\nRs,point index =b,point skeleton =Rs\\nb)as the point-expanding request for the LLM, where\\nTpeis the point-expanding prompt template (Prompt 2). Finally, after completing all points, we\\nconcatenate the point-expanding responses {Rpe\\nb}b=1,···,Bto get the final answer .\\nParallel point expanding. We conduct parallel point-expanding so that SoT is able to achieve a\\nspeed-up than normal decoding.\\n(1) For proprietary models with only API access , we can issue multiple parallel API calls to get an\\nend-to-end latency gain at the cost of an increased number of API requests and tokens.\\n(2) For open-source models that we can run locally , we let them process the point-expanding re-\\nquests as a batch (paddings are added to the left of the point-expanding requests). We explain below\\nwhy this could achieve speed-ups. A typical LLM generative process consists of two phases: (a)\\ntheprefilling phase in which the prompt is parsed to generate the key-value cache for further use,\\nand (b) the decoding phase in which tokens are generated one by one in a sequential manner. The\\ndecoding phase accounts for the majority of the end-to-end latency, especially when generating a\\nlong response. Note that the decoding phase is bottlenecked by weight loading instead of activation\\n3' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 2}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nloading or computation.1Consequently, running LLM inference with increased batch sizes does not\\nincrease the per-token latency much. Therefore, SoT allows us to decode roughly B×more tokens\\nwithin the same amount of time if we parallelly decode Bpoints. See App. E for the expanded\\ndiscussions and the supporting experiments.\\nPlease refer to App. B for more implementation details of SoT.\\n3 S OT E VALUATION\\nDatasets. We evaluate SoT on two recent assistant-style datasets: (1) Vicuna-80 (Chiang et al.,\\n2023), which contains 80 questions spanning nine categories, such as coding ,math ,writing ,role-\\nplay, and so on, and (2) WizardLM (Xu et al., 2023), which contains 218 questions spanning more\\ncategories and diverse difficulties. Due to space constraints, we only report Vicuna-80 results in the\\nmain paper, and defer WizardLM results to the Apps. G and I.\\nModels. We test SoT on 12 recently released models, including 9 open-source models and 3 API-\\nbased models (Table 1). We obtain the weights of all the open-source models from Hugging Face.\\nSee App. A for more details.\\n3.1 E VALUATION OF EFFICIENCY\\nAPI-based models. We record the latency of every API call with\\nstart = time.time(); ...; elapsed_time = time.time() - start , and\\nadd the latency of the skeleton API call and the slowest point-expanding API call as the SoT latency.\\nOpen-source models. All open-source models we currently evaluate are based on the LLaMA 7B,\\n13B, or 33B architectures. Thus, to enable fast analysis, we first make a latency profiling table for\\neach LLaMA architecture on NVIDIA A100. The table contains the architecture’s (1) latency for\\nprefilling sequences of length 1 to 700 with different batch sizes (from 1 to 16), and (2) decoding\\none token with a context of length 1 to 1024 with different batch sizes (from 1 to 16). With these\\nthree latency profiling tables, given the number of points B, the token lengths of the requests and\\nresponses in the skeleton and point-expanding stages, we can quickly estimate the SoT latency\\nby simply looking up entries in the tables and adding them up. See App. F for a more detailed\\ndescription of how we conduct the profiling and estimate the latency.\\nIn addition to the above approach, we also compare the actual latency of SoT and normal sequential\\ngeneration (abbreviated as “normal” in the following discussion) in App. G.1.4.\\nThe rest of this section shows the speed-ups of SoT on different models (§ 3.1.1) and question\\ncategories (§ 3.1.2). In addition, we also report the latency breakdown of SoT stages in App. G.1.2\\nand the SoT speed-ups on an RTX 3090 GPU in App. G.1.3.\\n3.1.1 S PEED -UPBREAKDOWN : M ODELS\\nWe investigate how SoT reduces the end-to-end latency on different models. Fig. 2a shows the\\naverage speed-up for each model across all question categories. We can see that SoT obtains a >2×\\nspeed-up (up to 2.39 ×) on 8 out of 12 models.\\nWe report the detailed statistics about token lengths and numbers of points in Fig. 11. (1) In terms\\nofthe point number B(Fig. 11a), LLaMA2, Vicuna-7B V1.1, Vicuna-7B V1.3, and ChatGPT-3.5\\nyield relatively fewer points ( <6), while GPT-4 and StableVicuna-13B generates the largest number\\nof points on average ( ≈9). (2) Regarding the point-expanding response length , Figs. 11b to 11d\\nshow that the API-based models, ChatGPT-3.5, Claude, and GPT-4, follow the point-expanding\\nrequest better and generate shorter point-expanding responses than the open-source models. One\\ncan also notice that StableVicuna-13B’s longest point-expanding responses for many question cat-\\negories can be as lengthy as the overall normal answer, since it fails to adhere to the “Write it\\n**very shortly**” instruction in the point-expanding request. Consequently, SoT cannot accelerate\\nStableVicuna-13B well. (3) Regarding the length balance degree between point responses , Fig. 11e\\nshows that LLaMA2 and the API-based models generate more balanced point-expanding responses.\\n1This is true when the number of concurrent queries is small; see § 6 for discussion on other scenarios.\\n4' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 3}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n(4) As for the overall length of the final aggregated answer (Fig. 11f), employing SoT on most\\nmodels results in answers that are, on average, 1 ∼2×longer than the normal answer.\\n1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8StableVicuna-13BClaudeVicuna-13B V1.3ChatGPT-3.5GPT-4Vicuna-7B V1.3UltraLM-13BVicuna-33B V1.3OpenChat-13BVicuna-7B V1.1LLaMA2-Chat-13BLLaMA2-Chat-7B\\n1.13×1.31×1.91×1.97×2.00×2.01×2.18×2.24×2.28×2.30×2.38×2.39×\\n(a) Different models.\\n1.01.21.41.61.82.02.22.42.62.8mathfermicounterfactualroleplaycodingcommon-sensewritinggenericknowledge\\n1.34×1.69×1.89×1.95×2.06×2.24×2.26×2.31×2.33× (b) Different categories.\\nFigure 2: Average speed-ups of SoT on different models and question categories.\\n3.1.2 S PEED -UPBREAKDOWN : QUESTION CATEGORIES\\nHere we investigate how SoT reduces the end-to-end latency for different question categories.\\nFig. 2b shows the average speed-up for each question category across all models. The question\\ncategories for which SoT can provide high-quality answers are marked in green, and other cate-\\ngories are marked in red (see § 3.2.3 for the answer quality evaluation). We can see that SoT can\\nobtain speed-ups for all question categories. For the five question categories that SoT can provide\\nhigh-quality answers (i.e., knowledge ,generic ,common-sense ,roleplay ,counterfactual ), SoT can\\nspeed up the overall answer generation process by 1.89 ×to 2.33 ×in the meantime.\\n3.2 E VALUATION OF ANSWER QUALITY\\nIn order to compare the answer quality of the normal sequential generation (abbreviated as “normal”\\nin the following discussion) and SoT generation, we adopt two LLM-based evaluation frameworks:\\nFastChat (Zheng et al., 2023) and LLMZoo (Chen et al., 2023c). The evaluation process is to present\\na question and a pair of answers (from normal or SoT generation) to an LLM judge (GPT-4 in the\\nmain paper; see App. I.3 for the results evaluated using ChatGPT-3.5) and ask for its preference.\\nThe response can be that SoT’s answer wins/ties/loses compared to the normal answer.\\nHere are more details about the evaluation of the answer quality:\\n(1) Detailed metrics. FastChat evaluation provides one metric for the general quality of the answers.\\nIn addition to a general metric, LLMZoo provides five detailed metrics on the answers’ coherence,\\ndiversity, immersion, integrity, and relevance.\\n(2) Question categories. FastChat provides two special evaluation prompts for coding and math\\nquestions for more accurate evaluation, whereas LLMZoo does not. Following the implementation\\nin LLMZoo, we exclude math and coding questions in all LLMZoo evaluation results.\\n(3) Extentions to avoid evaluation bias. To avoid the potential bias from the order of the two answers\\npresented to the LLM judge, we extend FastChat and LLMZoo evaluation frameworks by running\\nthe evaluation twice with either ordering of the two answers. In either evaluation, a score of 1,\\n0, and -1 is assigned when SoT wins, ties, or loses, respectively. The final evaluation is that SoT\\nwins/ties/loses when the sum of the two scores is positive/zero/negative. For example, if SoT wins\\nin one evaluation and loses in the other evaluation, the result is “tie”. If SoT wins (loses) in one\\nevaluation and ties in the other, the result is “win” (“lose”).\\n(4) Net win rates. We further define net win rates to give a summarized view of the answer quality.\\nGiven the number of questions that SoT wins (#win) and loses (#lose), we define net win rates\\nas#win−#lose/total number of questions . 0% means that SoT performs competitively to the normal baseline\\n(wins and loses in the same number of questions). Higher values mean that SoT performs better.\\nThe organization of this section on answer quality evaluation is as follows. We first present the over-\\nall quality of SoT answers (§ 3.2.1), and then go into the details across different question categories\\n(§ 3.2.3), models (§ 3.2.2), and metrics (§ 3.2.4).\\n5' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 4}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n3.2.1 O VERALL QUALITY\\nIn Fig. 3, we show the win/tie/lose rates (the percentage of the cases when SoT wins/ties/loses\\ncompared to normal generation) across all models and questions using the two metrics from FastChat\\nand LLMZoo that capture the general quality of the answers. We notice a discrepancy between the\\ntwo metrics on when SoT is strictly better than the baseline (45.8% v.s. 29.5%). Despite that, the\\ntwo metrics agree that SoT is not worse than the baseline in around 60% of the cases, and the win\\nrates are close to the lose rates. This result suggests that the answers of SoT maintain good quality\\nof that of the normal generation.\\n0% 20% 40% 60% 80% 100%General quality (LLMZoo)General quality (FastChat)\\n45.8%29.5%\\n19.6%29.3%\\n34.5%41.2%Win Tie Lose\\nFigure 3: Win/tie/lose rates of SoT v.s. normal generation using “general” metrics from FastChat\\nand LLMZoo. SoT performs better than or equal to normal generation in around 60% cases.\\n3.2.2 Q UALITY BREAKDOWN : M ODELS\\nNext, we investigate how SoT performs on different models. We compute net win rates on all\\nmodels in Fig. 4. Again, we see that the two general metrics from FastChat and LLMZoo have\\ndifferent absolute values but similar rankings. In particular, both metrics agree that OpenChat-13B,\\nVicuna-7B V1.1, Claude, LLaMA2-Chat-13B have lownet win rates, whereas Vicuna-13B V1.3,\\nStableVicuna-13B, and UltraLM-13B have high net win rates.\\n-60% -40% -20% 0% 20%StableVicuna-13BUltraLM-13BVicuna-13B V1.3GPT-4LLaMA2-Chat-7BVicuna-33B V1.3Vicuna-7B V1.3ChatGPT-3.5LLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.1Claude\\n(a) Metric: general quality (FastChat).\\n-40% -20% 0% 20% 40% 60%StableVicuna-13BUltraLM-13BVicuna-13B V1.3GPT-4LLaMA2-Chat-7BVicuna-33B V1.3Vicuna-7B V1.3ChatGPT-3.5LLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.1Claude (b) Metric: general quality (LLMZoo).\\nFigure 4: Net win rates of SoT on different models.\\nWe investigate the answers in App. I.1.1, and summarize the key takeaways as follows. Some\\nmodels have low SoT quality as they cannot understand the skeleton and point-expanding prompts\\nwell. Some other models have low SoT quality as their normal answers already have good quality,\\nmaking it hard for SoT to beat them (e.g., Claude). For models that are able to understand the\\nSoT prompts, the answer quality is improved. We expect that further improving SoT prompts or\\nfine-tuning the models can make it easier for LLMs to understand the skeleton and point-expanding\\nprompts and ultimately result in better answer quality.\\n3.2.3 Q UALITY BREAKDOWN : QUESTION CATEGORIES\\nNext, we investigate how SoT performs on different question categories. We compute net win rates\\n(win rates minus lose rates) on all question categories in Fig. 5. Similar to Fig. 3, we see that\\nLLMZoo tends to be more optimistic about the quality of SoT than FastChat. Nevertheless, the\\nconclusions are consistent: SoT performs relatively well ongeneric ,common-sense ,knowledge ,\\nroleplay , and counterfactual . SoT performs relatively poorly onwriting ,fermi ,math , and coding .\\nWe investigate the answers in App. I.1.2, and summarize the key takeaways as follows. SoT per-\\nforms well when the question can be answered in several points whose details can be expanded\\nindependently. This includes a wide range of real-world questions. On the other hand, it is fun-\\ndamentally challenging to apply SoT on questions that require step-by-step thinking, in which the\\n6' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 5}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n-80% -60% -40% -20% 0% 20% 40%counterfactualgenericcommon-senseknowledgeroleplayfermiwritingmathcoding\\n(a) Metric: general quality (FastChat).\\n-20% 0% 20% 40% 60%counterfactualgenericcommon-senseknowledgeroleplayfermiwriting (b) Metric: general quality (LLMZoo).\\nFigure 5: Net win rates of SoT on different question categories.\\nlatter steps require the details from the earlier steps, such as math questions. To make SoT general\\nacross broader question categories, one promising pathway is to enable SoT to adaptively fall back\\nto normal generation, which we explore in § 4. Interestingly, our results suggest that some LLMs\\nare already able to do that occasionally without special prompting or tuning (see App. I.1.2).\\n3.2.4 Q UALITY BREAKDOWN : M ETRICS\\nAll previous evaluations use metrics about the general quality of the answer. In Fig. 6, we show\\nmore detailed metrics from LLMZoo to reveal in which aspects SoT can improve or hurt the answer\\nquality. On average, we can see that SoT improves the diversity and relevance while hurting the\\nimmersion and coherence.\\n0% 20% 40% 60% 80% 100%IntegrityCoherenceImmersionRelevanceDiversity\\n23.2%29.8%40.5%61.4%\\n99.9%34.6%30.6%23.7%11.3%\\n0.1%42.1%39.6%35.8%27.3%Win Tie Lose\\nFigure 6: Win/tie/lose rates of SoT v.s. normal generations using metrics from LLMZoo. SoT\\nperforms well on diversity and relevance, and relatively worse on coherence and immersion.\\nThrough answer investigation (App. I.1.3), we summarize the key takeaways as follows. The skele-\\nton stage of SoT explicitly require LLMs to discuss the answers from multiple aspects without filler\\nwords. This improves the diversity and relevance of the answers. As for coherence and immersion,\\nSoT is not worse than the normal generation around 60% of the time. One future direction is to\\nimprove the SoT prompts or pipeline so that the answers can be better in more metrics.\\n4 S OTWITH ROUTER (SOT-R): A DAPATIVELY TRIGGERING SOT\\nIn § 3, we see that SoT provides considerable speed-ups while maintaining (or even improving)\\nanswer quality for many question types. However, the biggest limitation is that SoT is not suitable\\nfor questions that require step-by-step reasoning (§ 3.2.3). Towards pushing the practical adoption\\nof SoT, we explore the possibility of adaptively triggering SoT only when it is suitable. To achieve\\nthat, we propose a router module that decides if SoT should be applied for the user request, and\\nthen call either SoT or normal decoding accordingly. This paradigm aligns with the recent trends\\nof composing multiple models to solve complicated tasks (Chase, 2022; Shen et al., 2023). To\\nimplement the router, we explore two options: LLM prompting as the router (no model training is\\nneeded) (§ 4.1), and trained RoBERTa as the router (§ 4.2). The evaluation is provided in § 4.3.\\n4.1 P ROMPTING ROUTER\\nWe directly ask an LLM if the question is suitable for SoT. More specifically, we ask the LLM if the\\ndesired answer is in a list of independent points (see App. C.1 for the prompt). If the answer is yes,\\n7' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 6}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nwe will use SoT; otherwise, we will use normal generation (i.e., directly feeding the question to the\\nLLM). We employ GPT-4 as the LLM router given its strong capability.\\n4.2 T RAINED ROUTER\\nWhile leveraging GPT-4 as the router obviates the need for model training, its performance remains\\nsensitive to prompt design. Therefore, we approach the problem as a sequence classification task by\\nfine-tuning a small language model as the router. Specifically, we annotate the LIMA dataset (Zhou\\net al., 2023) as the training set to train a RoBERTa model (Liu et al., 2019), which has only 120M\\nparameters. Comprehensive details regarding the annotation and training processes can be found in\\nApps. C.2.1 and C.2.2, respectively.\\n4.3 S OT-R E VALUATION\\nWe compare SoT and SoT-R under the same evaluation setup in § 3. Besides the prompting and\\ntrained routers, we also consider a “human router” where we manually judge whether SoT should\\nbe applied for each question. This serves as a benchmark for comparison.\\n4.3.1 E VALUATION OF EFFICIENCY\\nFig. 7 shows the speed-ups of SoT and SoT-R for different models on the Vicuna-80 dataset (see\\nApp. G.2 for more results on the WizardLM dataset). We can see that: (1) As expected, SoT-R\\nobtains lower speed-ups than SoT, since SoT is not triggered for some questions and the router\\ninduces a small latency overhead. Nevertheless, SoT-R can still benefit most models with >1×\\nspeed-ups. (2) SoT-R with the trained router obtains slightly higher speed-ups for 7 out of 12 models\\non Vicuna-80, while SoT-R with the prompting router obtains higher speed-ups for all models on\\nthe WizardLM dataset (see Fig. 17 in App. G.2).\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75StableVicuna-13BClaudeVicuna-13B V1.3ChatGPT-3.5GPT-4Vicuna-7B V1.3UltraLM-13BVicuna-33B V1.3OpenChat-13BVicuna-7B V1.1LLaMA2-Chat-13BLLaMA2-Chat-7B\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nFigure 7: Speed-ups of SoT and SoT-R on dif-\\nferent models across all question categories of\\nthe Vicuna-80 dataset.\\n-80% -60% -40% -20% 0% 20% 40%counterfactualgenericcommon-senseknowledgeroleplayfermiwritingmathcoding\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nSoT-R w/ human routerFigure 8: Net win rates of SoT and SoT-R on\\ndifferent question categories of the Vicuna-80\\ndataset (evaluated with the FastChat metrics).\\n4.3.2 E VALUATION OF ANSWER QUALITY\\nFig. 8 shows the net win rates (averaged across all models) of SoT and SoT-R on Vicuna-80 with the\\nFastChat metrics (see App. I.2 for results of the WizardLM dataset and LLMZoo metrics). We can\\nsee that: (1) SoT-R significantly improves the answer quality on questions where SoT is not suitable\\n(e.g., coding ,math ,writing ,fermi ) by falling back to normal decoding. At the same time, SoT-R\\nmaintains answer quality improvements on questions where SoT is good at. (2) The trained router\\nperforms similar to (on Vicuna-80) or better than (on WizardLM; see App. I.2) the prompting router.\\nThis accords with our intuition in § 4.2. (3) The prompting and trained routers could even surpass\\nhuman router (e.g., on roleplay questions; see more examples on WizardLM in App. I.2).\\nWe discuss the consistency across three routers in App. C.3. The primary takeaways include: (1)\\non Vicuna-80, there is a notable consistency among all three routers, and (2) on WizardLM, greater\\ndiscrepancies emerge, with the trained router showing higher alignment with human annotations.\\n5 R ELATED WORK\\nThis section positions SoT in related work to reveal how SoT (1) is connected to, (2) is different\\nfrom, and (3) can harness the power of other methods. See App. D for the expanded discussion.\\nEfficient LLM methods at model and system levels. At the model level, prior work proposes ef-\\nficient architectures, including dynamic mixture-of-experts (Lepikhin et al., 2021), low-complexity\\n8' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 7}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nattention (Kitaev et al., 2020), and multi-query attention (Shazeer, 2019). However, they usually\\nrequire a significant re-training cost. In contrast, compression methods require a smaller amount\\nof fine-tuning cost by reducing the complexity of pre-trained LLMs, such as quantization (Frantar\\net al., 2022) and weight or activation sparsification (Mishra et al., 2021; Zaheer et al., 2020).\\nAt the system level, prior work (1) optimizes the computational graph (Dao et al., 2022), (2) op-\\ntimizes the assignment and scheduling of computational graph on devices (Sheng et al., 2023), or\\n(3) designs batching or caching mechanisms for serving multiple users (Fang et al., 2021). These\\ntechniques address the large memory access and footprint posed by the vast model scale and atten-\\ntion mechanism, and mainly aim at enhancing the throughput rather than the end-to-end latency.\\nAs SoT trades off throughput for end-to-end latency, SoT can make these throughput-oriented tech-\\nniques help with end-to-end latency . This interesting synergy offers opportunities for achieving\\nbetter trade-offs between latency and throughput in future serving systems.\\nIn contrast to model- and system-level techniques, SoT is a data-level technique in a new “content\\nco-organization for efficiency” paradigm . See § 6 for more discussions.\\nEfficient LLM methods through parallel generation. Some prior work also addresses the sequen-\\ntial decoding issues. Speculative decoding (SD) methods (Stern et al., 2018) employ smaller models\\nto generate some consecutive tokens sequentially and apply the target LLMs to verify them paral-\\nlelly. Non-autoregressive generation (NAG) methods (Gu et al., 2018; Xiao et al., 2023) sample and\\nrefine consecutive tokens parallelly, often with the support of a modified and tuned model.\\nRelying on either assisting models or special models and sampling schemes, SD and NAG methods\\nconduct parallel verification or sampling and refinement of consecutive tokens . In contrast, SoT\\nprompts the LLM itself to plan the contents in a way that permits the parallel generation of tokens in\\ndifferent segments , by exploiting the emerging instruction-following and planning ability of LLMs.\\nPrompting methods for LLMs. Recent years have witnessed the emergence of the “pre-train,\\nprompt, and predict” paradigm, which has shown promise in enhancing LLMs’ quality in math and\\ncommonsense reasoning (Wei et al., 2022; Kojima et al., 2022; Wang et al., 2022; Chen et al., 2022)\\nand planning for multi-modality tasks (Shen et al., 2023; Zhu et al., 2023). Instead of focusing on\\nanswer quality, SoT is a first attempt at exploiting the power of prompting to improve efficiency .\\n6 L IMITATIONS , FUTURE WORK,AND OPEN QUESTIONS\\nAnswer quality evaluation. Our answer quality evaluation is far from perfect due to the limited\\nprompt set, the potential bias of GPT-4 judges, and the inherent difficulty of evaluating LLM gener-\\nations. Currently, we did not conduct human evaluation since it is easy for a human to tell whether\\nan answer is generated with SoT due to its distinctive pattern, which might cause evaluation bias.\\nWe leave a more thorough evaluation of answer quality to future work.\\nEliciting or improving LLMs’ ability. § 3.2.4 demonstrates SoT’s potential of enhancing answer\\nquality. It is part of a broader trend in recent research, exemplified by work including CoT (Kojima\\net al., 2022; Wei et al., 2022), ToT (Yao et al., 2023), and ReAct (Yao et al., 2022), which collectively\\naffirm the notion that explicitly articulating the thought process in language can elicit high-quality\\nanswers from LLMs . These findings resemble human thinking: rather than relying solely on the\\nfirst intuition or purely sequential thinking, we often document step-by-step reasoning or thought\\norganization to attain high-quality answers. This intriguing parallel prompts us to explore further\\nhow we can draw from the human thinking process to facilitate more effective and efficient AI.\\nFor instance, SoT currently ignores the dependencies between points. A conceptually better way is\\nto organize the points as Graph-of-Thoughts , where the edges represent the dependencies, and each\\npoint is decoded conditioned on the contents of its ancestor points. In addition, instead of complying\\nwith a static graph, we expect the need of having dynamic Graph-of-Thoughts , where the high-level\\nthought structure is adjusted dynamically by LLMs themselves. This could potentially combine the\\nefficiency and global thinking advantages of SoT with the logical reasoning and impromptu thinking\\nstrengths of methods like CoT (Kojima et al., 2022; Wei et al., 2022). Notably, a contemporary\\nwork (Besta et al., 2023) has attempted to design Graph-of-Thoughts to elicit reasoning.\\nFurthermore, there exist self-improving training pipelines (Zelikman et al., 2022; Huang et al., 2022)\\nthat use rationales generated by CoT to fine-tune LLMs, thereby enhancing their reasoning abilities.\\n9' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 8}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nLikewise, it is interesting to investigate how the more structured answers from SoT can be used to\\nfine-tune LLMs to enhance their ability to generate well-organized and comprehensive answers.\\nEfficiency and overhead of SoT in different scenarios. Serving systems commonly adopt batch\\nprocessing to handle concurrent queries. This raises a concern of whether SoT may hurt serving\\nthroughput due to parallel requests. (1) When there is an unsaturated number of concurrent queries,\\nSoT can effectively reduce latency and enhance GPU utilization. Example scenarios include (a)\\nEdge-side applications with a single user; (b) Centralized services during periods with unsaturated\\nuser requests and underutilized computing capacity. It is interesting to study the appropriate SoT\\ntriggering conditions based on system workloads. (2) When there is a saturated number of concur-\\nrent queries, SoT is still useful for improving answer quality. However, in this case, it is important\\nto consider the computation overhead from SoT. We delve into this concern in App. H.\\nFor API-based models, a notable concern arises regarding the increased number of prefilling tokens\\n(App. H). Given that many APIs charge token usage, SoT may lead to higher costs. To address this,\\none can tune the number of parallel API requests (by expanding multiple points in a single API call),\\nor use prompt tuning to design shorter SoT prompts (see App. H).\\nData-centric efficiency optimization. While data-centric engineering for improving answer qual-\\nity(Zha et al., 2023; HazyResearch, 2023) is gaining popularity, its potential for inference efficiency\\nis not explored yet. SoT is the first attempt. As LLM capabilities and the amount of LLM-generated\\ndata are growing rapidly, data-centric techniques could become more useful in the future. We look\\nforward to more explorations to unlock the full potential of data-centric efficiency optimization.\\nACKNOWLEDGEMENTS\\nWe thank Sergey Yekhanin (Microsoft Research), and Tianji Wu (Infinigence AI) for their support\\nand suggestions on the work. We thank Tianyu Fu for many initial discussions on the idea. We\\nthank Ke Hong and Genghan Zhang for their discussions about profiling. We thank Yue Wu for the\\nhelp on the Claude scripts. We thank Da Yu, Chulin Xie, and Saiqian Zhang for their suggestions\\non revising the first version of the paper. We thank Rui Hu, Cheng Cheng, Jack Jin, Zhoutong Ye,\\nMingze Sun, Jun Yan, Zhi Zhang, Yuxuan Tong, and Nianhui Guo for their suggestions on revising\\nthe second version of the paper.\\nREFERENCES\\nAnthropic. Introducing claude, May 2023. URL https://www.anthropic.com/index/\\nintroducing-claude .\\nMaciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna\\nGajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, et al.\\nGraph of thoughts: Solving elaborate problems with large language models. arXiv preprint\\narXiv:2308.09687 , 2023.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\\nfew-shot learners. Advances in neural information processing systems , 33:1877–1901, 2020.\\nHan Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang, and Song Han. Once-for-all: Train one\\nnetwork and specialize it for efficient deployment. arXiv preprint arXiv:1908.09791 , 2019.\\nHarrison Chase. LangChain, October 2022. URL https://github.com/hwchase17/\\nlangchain .\\nCharlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste Lespiau, Laurent Sifre, and John\\nJumper. Accelerating large language model decoding with speculative sampling. arXiv preprint\\narXiv:2302.01318 , 2023a.\\nWenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. Program of thoughts prompt-\\ning: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint\\narXiv:2211.12588 , 2022.\\n10' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 9}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nZhaodong Chen, Zheng Qu, Yuying Quan, Liu Liu, Yufei Ding, and Yuan Xie. Dynamic n: M\\nfine-grained structured sparse attention mechanism. In Proceedings of the 28th ACM SIGPLAN\\nAnnual Symposium on Principles and Practice of Parallel Programming , pp. 369–379, 2023b.\\nZhihong Chen, Junying Chen, Hongbo Zhang, Feng Jiang, Guiming Chen, Fei Yu, Tiannan Wang,\\nJuhao Liang, Chen Zhang, Zhiyi Zhang, Jianquan Li, Xiang Wan, Haizhou Li, and Benyou Wang.\\nLlm zoo: democratizing chatgpt. https://github.com/FreedomIntelligence/\\nLLMZoo , 2023c.\\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,\\nSiyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An\\nopen-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https:\\n//lmsys.org/blog/2023-03-30-vicuna/ .\\nHyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\\nWang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language mod-\\nels.arXiv preprint arXiv:2210.11416 , 2022.\\nTri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher R ´e. Flashattention: Fast and memory-\\nefficient exact attention with io-awareness. Advances in Neural Information Processing Systems ,\\n35:16344–16359, 2022.\\nEmily L Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Exploiting linear\\nstructure within convolutional networks for efficient evaluation. Advances in neural information\\nprocessing systems , 27, 2014.\\nNing Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong\\nSun, and Bowen Zhou. Enhancing chat language models by scaling high-quality instructional\\nconversations. arXiv preprint arXiv:2305.14233 , 2023.\\nZhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. Glm:\\nGeneral language model pretraining with autoregressive blank infilling. In Proceedings of the\\n60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) ,\\npp. 320–335, 2022.\\nThomas Elsken, Jan Hendrik Metzen, and Frank Hutter. Neural architecture search: A survey. The\\nJournal of Machine Learning Research , 20(1):1997–2017, 2019.\\nJiarui Fang, Yang Yu, Chengduo Zhao, and Jie Zhou. Turbotransformers: an efficient gpu serv-\\ning system for transformer models. In Proceedings of the 26th ACM SIGPLAN Symposium on\\nPrinciples and Practice of Parallel Programming , pp. 389–402, 2021.\\nWilliam Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: Scaling to trillion parameter\\nmodels with simple and efficient sparsity. The Journal of Machine Learning Research , 23(1):\\n5232–5270, 2022.\\nElias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. Gptq: Accurate post-training\\nquantization for generative pre-trained transformers. arXiv preprint arXiv:2210.17323 , 2022.\\nPrakhar Ganesh, Yao Chen, Xin Lou, Mohammad Ali Khan, Yin Yang, Hassan Sajjad, Preslav\\nNakov, Deming Chen, and Marianne Winslett. Compressing large-scale transformer-based mod-\\nels: A case study on bert. Transactions of the Association for Computational Linguistics , 9:\\n1061–1080, 2021.\\nJoao Gante. Assisted generation: a new direction toward low-latency text generation. https:\\n//huggingface.co/blog/assisted-generation , 2023. Accessed: 2023-06-23.\\nGoogle. Tensorflow serving, 2021. URL https://github.com/tensorflow/serving .\\nJiatao Gu, James Bradbury, Caiming Xiong, Victor O.K. Li, and Richard Socher. Non-autoregressive\\nneural machine translation. In International Conference on Learning Representations , 2018. URL\\nhttps://openreview.net/forum?id=B1l8BtlCb .\\n11' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 10}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nSong Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks\\nwith pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149 , 2015.\\nHazyResearch. Data-centric ai. https://github.com/HazyResearch/\\ndata-centric-ai , 2023. Accessed: 2023-07-04.\\nJiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei\\nHan. Large language models can self-improve. arXiv preprint arXiv:2210.11610 , 2022.\\nYanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Dehao Chen, Mia Chen, HyoukJoong\\nLee, Jiquan Ngiam, Quoc V Le, Yonghui Wu, et al. Gpipe: Efficient training of giant neural\\nnetworks using pipeline parallelism. Advances in neural information processing systems , 32,\\n2019.\\nAndrei Ivanov, Nikoli Dryden, Tal Ben-Nun, Shigang Li, and Torsten Hoefler. Data movement is\\nall you need: A case study on optimizing transformers. Proceedings of Machine Learning and\\nSystems , 3:711–732, 2021.\\nNikita Kitaev, Łukasz Kaiser, and Anselm Levskaya. Reformer: The efficient transformer. arXiv\\npreprint arXiv:2001.04451 , 2020.\\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\\nlanguage models are zero-shot reasoners. Advances in neural information processing systems ,\\n35:22199–22213, 2022.\\nRaghuraman Krishnamoorthi. Quantizing deep convolutional networks for efficient inference: A\\nwhitepaper. arXiv preprint arXiv:1806.08342 , 2018.\\nAlex Krizhevsky. One weird trick for parallelizing convolutional neural networks. arXiv preprint\\narXiv:1404.5997 , 2014.\\nWoosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E\\nGonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model\\nserving with pagedattention. arXiv preprint arXiv:2309.06180 , 2023.\\nDmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang,\\nMaxim Krikun, Noam Shazeer, and Zhifeng Chen. {GS}hard: Scaling giant models with condi-\\ntional computation and automatic sharding. In International Conference on Learning Represen-\\ntations , 2021. URL https://openreview.net/forum?id=qrwe7XHTmYb .\\nBrian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt\\ntuning. arXiv preprint arXiv:2104.08691 , 2021.\\nYaniv Leviathan, Matan Kalman, and Yossi Matias. Fast inference from transformers via speculative\\ndecoding. arXiv preprint arXiv:2211.17192 , 2022.\\nGuohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem.\\nCamel: Communicative agents for ”mind” exploration of large scale language model society,\\n2023a.\\nXiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv\\npreprint arXiv:2101.00190 , 2021.\\nXuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy\\nLiang, and Tatsunori B. Hashimoto. Alpacaeval: An automatic evaluator of instruction-following\\nmodels. https://github.com/tatsu-lab/alpaca_eval , 2023b.\\nYifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and Weizhu Chen. Making\\nlanguage models better reasoners with step-aware verifier. In Proceedings of the 61st Annual\\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 5315–\\n5333, 2023c.\\nZhuohan Li, Siyuan Zhuang, Shiyuan Guo, Danyang Zhuo, Hao Zhang, Dawn Song, and Ion Stoica.\\nTerapipe: Token-level pipeline parallelism for training large-scale language models. In Interna-\\ntional Conference on Machine Learning , pp. 6543–6552. PMLR, 2021.\\n12' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 11}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nJi Lin, Jiaming Tang, Haotian Tang, Shang Yang, Xingyu Dang, and Song Han. Awq:\\nActivation-aware weight quantization for llm compression and acceleration. arXiv preprint\\narXiv:2306.00978 , 2023.\\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-\\ntrain, prompt, and predict: A systematic survey of prompting methods in natural language pro-\\ncessing. ACM Computing Surveys , 55(9):1–35, 2023.\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike\\nLewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining\\napproach, 2019.\\nIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International Confer-\\nence on Learning Representations , 2019.\\nWenyan Lu, Guihai Yan, Jiajun Li, Shijun Gong, Yinhe Han, and Xiaowei Li. Flexflow: A flexible\\ndataflow accelerator architecture for convolutional neural networks. In 2017 IEEE International\\nSymposium on High Performance Computer Architecture (HPCA) , pp. 553–564. IEEE, 2017.\\nXupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Zeyu Wang, Rae Ying Yee Wong,\\nZhuoming Chen, Daiyaan Arfeen, Reyna Abhyankar, and Zhihao Jia. Specinfer: Accelerating\\ngenerative llm serving with speculative inference and token tree verification. arXiv preprint\\narXiv:2305.09781 , 2023.\\nAsit Mishra, Jorge Albericio Latorre, Jeff Pool, Darko Stosic, Dusan Stosic, Ganesh Venkatesh,\\nChong Yu, and Paulius Micikevicius. Accelerating sparse deep neural networks. arXiv preprint\\narXiv:2104.08378 , 2021.\\nDeepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek Seshadri, Nikhil R Devanur, Gre-\\ngory R Ganger, Phillip B Gibbons, and Matei Zaharia. Pipedream: Generalized pipeline par-\\nallelism for dnn training. In Proceedings of the 27th ACM Symposium on Operating Systems\\nPrinciples , pp. 1–15, 2019.\\nDeepak Narayanan, Amar Phanishayee, Kaiyu Shi, Xie Chen, and Matei Zaharia. Memory-efficient\\npipeline-parallel dnn training. In International Conference on Machine Learning , pp. 7937–7947.\\nPMLR, 2021.\\nNVIDIA. Fastertransformer, 2019. URL https://github.com/NVIDIA/\\nFasterTransformer .\\nNVIDIA. Triton inference server, 2021. URL https://developer.nvidia.com/\\ntriton-inference-server .\\nOpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 , 2023.\\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow\\ninstructions with human feedback. Advances in Neural Information Processing Systems , 35:\\n27730–27744, 2022.\\nDuy Phung. Stablevicuna-13b, May 2023. URL https://huggingface.co/CarperAI/\\nstable-vicuna-13b-delta .\\nOfir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis. Measuring\\nand narrowing the compositionality gap in language models. arXiv preprint arXiv:2210.03350 ,\\n2022.\\nSamyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. Zero: Memory optimizations\\ntoward training trillion parameter models. In SC20: International Conference for High Perfor-\\nmance Computing, Networking, Storage and Analysis , pp. 1–16. IEEE, 2020.\\nJie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Min-\\njia Zhang, Dong Li, and Yuxiong He. {ZeRO-Offload }: Democratizing {Billion-Scale }model\\ntraining. In 2021 USENIX Annual Technical Conference (USENIX ATC 21) , pp. 551–564, 2021.\\n13' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 12}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nAndrea Santilli, Silvio Severino, Emilian Postolache, Valentino Maiorca, Michele Mancusi, Ric-\\ncardo Marin, and Emanuele Rodol `a. Accelerating transformer inference for translation via paral-\\nlel decoding. In acl, 2023.\\nTimo Schick, Jane Dwivedi-Yu, Roberto Dess `ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\\nNicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\\nuse tools. arXiv preprint arXiv:2302.04761 , 2023.\\nSenseTime. Lightllm. https://github.com/ModelTC/lightllm , 2023a. Accessed:\\n2023-09-26.\\nSenseTime. Openppl. https://github.com/openppl-public/ppl.nn , 2023b. Ac-\\ncessed: 2023-09-26.\\nNoam Shazeer. Fast transformer decoding: One write-head is all you need. arXiv preprint\\narXiv:1911.02150 , 2019.\\nYongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang.\\nHugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint\\narXiv:2303.17580 , 2023.\\nYing Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Daniel Y Fu, Zhiqiang\\nXie, Beidi Chen, Clark Barrett, Joseph E Gonzalez, et al. High-throughput generative inference\\nof large language models with a single gpu. arXiv preprint arXiv:2303.06865 , 2023.\\nTaylor Shin, Yasaman Razeghi, Robert L Logan IV , Eric Wallace, and Sameer Singh. Autoprompt:\\nEliciting knowledge from language models with automatically generated prompts. In Proceedings\\nof the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pp.\\n4222–4235, 2020.\\nMitchell Stern, Noam Shazeer, and Jakob Uszkoreit. Blockwise parallel decoding for deep autore-\\ngressive models. Advances in Neural Information Processing Systems , 31, 2018.\\nZiteng Sun, Ananda Theertha Suresh, Jae Hun Ro, Ahmad Beirami, Himanshu Jain, Felix Yu,\\nMichael Riley, and Sanjiv Kumar. Spectr: Fast speculative decoding via optimal transport.\\nInWorkshop on Efficient Systems for Foundation Models @ ICML2023 , 2023. URL https:\\n//openreview.net/forum?id=d0mGsaheuT .\\nChristian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethink-\\ning the inception architecture for computer vision. In Proceedings of the IEEE conference on\\ncomputer vision and pattern recognition , pp. 2818–2826, 2016.\\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy\\nLiang, and Tatsunori Hashimoto. Alpaca: A strong, replicable instruction-following model.\\nhttps://crfm.stanford.edu/2023/03/13/alpaca.html , 2023. Accessed: 2023-\\n06-23.\\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth ´ee\\nLacroix, Baptiste Rozi `ere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and\\nefficient foundation language models. arXiv preprint arXiv:2302.13971 , 2023a.\\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-\\nlay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher,\\nCristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy\\nFu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn,\\nSaghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel\\nKloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee,\\nDiana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,\\nIgor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi,\\nAlan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh\\nTang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen\\nZhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic,\\nSergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models,\\n2023b.\\n14' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 13}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nGuan Wang, Sijie Cheng, Qiying Yu, and Changling Liu. Openllms: Less is more for open-source\\nmodels, July 2023a. URL https://github.com/imoneoi/openchat .\\nHanrui Wang, Zhekai Zhang, and Song Han. Spatten: Efficient sparse attention architecture with\\ncascade token and head pruning. In 2021 IEEE International Symposium on High-Performance\\nComputer Architecture (HPCA) , pp. 97–110. IEEE, 2021.\\nSinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, and Hao Ma. Linformer: Self-attention\\nwith linear complexity. arXiv preprint arXiv:2006.04768 , 2020.\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\\nery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models.\\narXiv preprint arXiv:2203.11171 , 2022.\\nZifu Wang, Teodora Popordanoska, Jeroen Bertels, Robin Lemmens, and Matthew B Blaschko. Dice\\nsemimetric losses: Optimizing the dice score with soft labels. In Medical Image Computing and\\nComputer Assisted Intervention , 2023b.\\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\\nAndrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint\\narXiv:2109.01652 , 2021.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\\nZhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in\\nNeural Information Processing Systems , 35:24824–24837, 2022.\\nWei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in\\ndeep neural networks. Advances in neural information processing systems , 29, 2016.\\nGuangxuan Xiao, Ji Lin, Mickael Seznec, Julien Demouth, and Song Han. Smoothquant:\\nAccurate and efficient post-training quantization for large language models. arXiv preprint\\narXiv:2211.10438 , 2022.\\nYisheng Xiao, Lijun Wu, Junliang Guo, Juntao Li, Min Zhang, Tao Qin, and Tie-yan Liu. A survey\\non non-autoregressive generation for neural machine translation and beyond. IEEE Transactions\\non Pattern Analysis and Machine Intelligence , 2023.\\nCan Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and\\nDaxin Jiang. Wizardlm: Empowering large language models to follow complex instructions.\\narXiv preprint arXiv:2304.12244 , 2023.\\nYuanzhong Xu, HyoukJoong Lee, Dehao Chen, Blake Hechtman, Yanping Huang, Rahul Joshi,\\nMaxim Krikun, Dmitry Lepikhin, Andy Ly, Marcello Maggioni, et al. Gspmd: general and\\nscalable parallelization for ml computation graphs. arXiv preprint arXiv:2105.04663 , 2021.\\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\\nReact: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629 ,\\n2022.\\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik\\nNarasimhan. Tree of thoughts: Deliberate problem solving with large language models. arXiv\\npreprint arXiv:2305.10601 , 2023.\\nGyeong-In Yu, Joo Seong Jeong, Geon-Woo Kim, Soojeong Kim, and Byung-Gon Chun. Orca: A\\ndistributed serving system for {Transformer-Based }generative models. In 16th USENIX Sympo-\\nsium on Operating Systems Design and Implementation (OSDI 22) , pp. 521–538, 2022.\\nManzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago\\nOntanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et al. Big bird: Transformers for\\nlonger sequences. Advances in neural information processing systems , 33:17283–17297, 2020.\\nEric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman. Star: Bootstrapping reasoning with\\nreasoning. Advances in Neural Information Processing Systems , 35:15476–15488, 2022.\\n15' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 14}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nDaochen Zha, Zaid Pervaiz Bhat, Kwei-Herng Lai, Fan Yang, Zhimeng Jiang, Shaochen Zhong, and\\nXia Hu. Data-centric artificial intelligence: A survey. arXiv preprint arXiv:2303.10158 , 2023.\\nYujia Zhai, Chengquan Jiang, Leyuan Wang, Xiaoying Jia, Shang Zhang, Zizhong Chen, Xin Liu,\\nand Yibo Zhu. Bytetransformer: A high-performance transformer boosted for variable-length\\ninputs. arXiv preprint arXiv:2210.03052 , 2022.\\nYifan Zhang, Jingqin Yang, Yang Yuan, and Andrew Chi-Chih Yao. Cumulative reasoning with\\nlarge language models. arXiv preprint arXiv:2308.04371 , 2023.\\nLianmin Zheng, Zhuohan Li, Hao Zhang, Yonghao Zhuang, Zhifeng Chen, Yanping Huang, Yida\\nWang, Yuanzhong Xu, Danyang Zhuo, Eric P Xing, et al. Alpa: Automating inter-and {Intra-\\nOperator }parallelism for distributed deep learning. In 16th USENIX Symposium on Operating\\nSystems Design and Implementation (OSDI 22) , pp. 559–578, 2022.\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,\\nZi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.\\nJudging llm-as-a-judge with mt-bench and chatbot arena, 2023.\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat,\\nPing Yu, Lili Yu, et al. Lima: Less is more for alignment, 2023.\\nZhe Zhou, Xuechao Wei, Jiejing Zhang, and Guangyu Sun. {PetS}: A unified framework for\\n{Parameter-Efficient }transformers serving. In 2022 USENIX Annual Technical Conference\\n(USENIX ATC 22) , pp. 489–504, 2022.\\nXizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li,\\nLewei Lu, Xiaogang Wang, et al. Ghost in the minecraft: Generally capable agents for open-world\\nenviroments via large language models with text-based knowledge and memory. arXiv preprint\\narXiv:2305.17144 , 2023.\\nBarret Zoph and Quoc V . Le. Neural architecture search with reinforcement learning. In Interna-\\ntional Conference on Learning Representations (ICLR) , 2017.\\n16' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 15}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nAppendix\\nTable of Contents\\nA Model Details 18\\nB Implementation Details of Skeleton-of-Thought 18\\nB.1 Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\nB.2 Supporting Multi-Round Conversation . . . . . . . . . . . . . . . . . . . . . . 20\\nC Implementation Details of Skeleton-of-Thought with Router 20\\nC.1 Prompting Router . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\nC.2 Trained Router . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\nC.3 Router Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nC.4 Concurrent execution for SoT-R . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nD Related Work (Expanded) 22\\nD.1 Efficient LLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nD.2 Prompting Methods for LLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nE Efficiency Analysis 24\\nF Efficiency Profiling 25\\nG Efficiency Evaluation 27\\nG.1 Skeleton-of-Thought . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nG.2 Skeleton-of-Thought with Router . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nH Overhead of SoT in Different Scenarios 31\\nI Answer Quality Evaluation 32\\nI.1 Skeleton-of-Thought . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nI.2 Skeleton-of-Thought with Router . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nI.3 ChatGPT-3.5 as the Judge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\n17' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 16}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nA M ODEL DETAILS\\nTable 1 summarizes the models on which we evaluate SoT. We use GPT-4 in the main paper and\\nChatGPT-3.5 in App. I.3 as the judge in FastChat and LLMZoo evaluation.\\nTable 1: Model evaluated with SoT. All the open-source models are fine-tuned from LLaMA models.\\nAccess Model Name Institution Released Date\\nOpen-SourceLLaMA2-Chat-7B (Touvron et al., 2023b) Meta & Microsoft 2023/07\\nLLaMA2-Chat-13B (Touvron et al., 2023b) Meta & Microsoft 2023/07\\nOpenChat-13B (Wang et al., 2023a) Tsinghua 2023/07\\nVicuna-7B V1.3 (Chiang et al., 2023) LMSYS 2023/06\\nVicuna-13B V1.3 (Chiang et al., 2023) LMSYS 2023/06\\nVicuna-33B V1.3 (Chiang et al., 2023) LMSYS 2023/06\\nStableVicuna-13B (Phung, 2023) CarperAI 2023/05\\nUltraLM-13B (Ding et al., 2023) OpenBMB & Tsinghua 2023/05\\nVicuna-7B V1.1 (Chiang et al., 2023) LMSYS 2023/03\\nAPI-BasedClaude (Anthropic, 2023) Anthropic 2023/05\\nChatGPT-3.5 OpenAI 2022/11\\nGPT-4 OpenAI 2023/03\\nTable 2 shows sources of the models we use in the paper.\\nTable 2: The Hugging Face or API endpoints of the models.\\nAccess Model Name Hugging Face or API Endpoints\\nOpen-SourceLLaMA2-Chat-7B (Touvron et al., 2023b) meta-llama/Llama-2-7b-chat-hf\\nLLaMA2-Chat-13B (Touvron et al., 2023b) meta-llama/Llama-2-13b-chat-hf\\nOpenChat-13B (Wang et al., 2023a) openchat/openchat\\nVicuna-7B V1.3 (Chiang et al., 2023) lmsys/vicuna-7b-v1.3\\nVicuna-13B V1.3 (Chiang et al., 2023) lmsys/vicuna-13b-v1.3\\nVicuna-33B V1.3 (Chiang et al., 2023) lmsys/vicuna-33b-v1.3\\nStableVicuna-13B (Phung, 2023) CarperAI/stable-vicuna-13b-delta2\\nUltraLM-13B (Ding et al., 2023) openbmb/UltraLM-13b2\\nVicuna-7B V1.1 (Chiang et al., 2023) lmsys/vicuna-7b-delta-v1.1\\nAPI-BasedClaude (Anthropic, 2023) Claude extension on Slack3\\nChatGPT-3.5 Azure OpenAI, gpt-35-turbo 0301 version4\\nGPT-4 OpenAI, gpt-4-0613 version\\nB I MPLEMENTATION DETAILS OF SKELETON -OF-THOUGHT\\nB.1 P ROMPT\\nThe skeleton prompt is shown in Prompts 1 and 3 and the point-expanding prompt is shown in\\nPrompt 2.\\nSkeleton prompt template. In order to make the output skeleton short and in a consistent format for\\nthe good of efficiency and ease of point extraction, the skeleton prompt template (1) describes the\\ntask precisely, and (2) provides a partial answer “1.” for the LLM to continue writing. The skeleton\\n2For convenience, we use the non-official endpoint TheBloke/stable-vicuna-13B-HF and\\nTheBloke/UltraLM-13B-fp16 to get merged weights.\\n3https://www.anthropic.com/claude-in-slack\\n4https://azure.microsoft.com/en-us/products/ai-services/openai-service\\n18' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 17}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nPrompt 3. Skeleton Prompt Template Ts(with Two-Shot Demonstrations)\\n[User:] You’re an organizer responsible for only giving the skeleton (not the full content) for answering the question.\\nProvide the skeleton in a list of points (numbered 1., 2., 3., etc.) to answer the question. Instead of writing a full\\nsentence, each skeleton point should be very short with only 3 ∼5 words. Generally, the skeleton should have 3 ∼10\\npoints.\\nQuestion:\\nWhat are the typical types of Chinese dishes?\\nSkeleton:\\n1. Dumplings.\\n2. Noodles.\\n3. Dim Sum.\\n4. Hot Pot.\\n5. Wonton.\\n6. Ma Po Tofu.\\n7. Char Siu.\\n8. Fried Rice.\\nQuestion:\\nWhat are some practical tips for individuals to reduce their carbon emissions?\\nSkeleton:\\n1. Energy conservation.\\n2. Efficient transportation.\\n3. Home energy efficiency.\\n4. Reduce water consumption.\\n5. Sustainable diet.\\n6. Sustainable travel.\\nNow, please provide the skeleton for the following question.\\n{question }\\nSkeleton:\\n[Assistant:] 1.\\nresponses are in the desired format in most cases. Therefore, we can use a simple regular expression\\n(\\\\d+)\\\\.\\\\s?([\\\\s\\\\S]+?)(?=\\\\n|\\\\n *$)to extract point indexes and point skeletons from the\\nskeleton response.\\nWe find that GPT-4 can work well without the two demonstrations in the skeleton prompt. Therefore,\\nwe do not include the two demonstrations for GPT-4 (Prompt 1). For all other models, the two\\ndemonstrations are included, as shown in Prompt 3.\\nPoint-expanding prompt template. It describes the point-expanding task and provides a partial\\nanswer. We also provide instructions “Write it **very shortly** in 1 ∼2 sentence” so that the LLMs\\nkeep the answers concise. Unlike the skeleton prompt template, we find that demonstrations are not\\nnecessary to get reasonable results.\\nWe find that Claude and GPT-4 follows the instruction “Write it **very shortly** in 1 ∼2 sentence\\nand do not continue with other points!” in Prompt 2 very well, so that the answers are very short.\\nTherefore, we delete “**very shortly**” from the prompt template in Claude and GPT-4.\\nPartial answer. In the Prompts 1 and 2, we provide partial answers so that LLMs can follow the\\ndesired response format better.\\nWe can put the partial answer at the end of the prompt for the open-source models to continue\\nwriting. An implementation detail is that different open-source models have different conversa-\\ntion templates (i.e., different ways to combine user and assistant messages into one string). For\\nexample, Vicuna (Chiang et al., 2023) uses the string “USER:” and “ ASSISTANT:” for the place-\\nholder “ [User:] ” and “ [Role] ” in the Prompts 1 and 2, respectively, while UltraLM (Ding et al.,\\n2023) uses “User:” and “ 〈/s〉Assistant:”. We build our open-source model experiments with the\\nhelp of the FastChat codebase (Zheng et al., 2023), in which the conversation templates of many\\nmodels are already handled correctly. We implement the conversation templates of OpenChat-13B,\\nStableVicuna-13B, and UltraLM-13B according to their official guides and codes.\\nFor ChatGPT-3.5, we provide partial answers as a last message in the chat history from the assistant.\\nNote that it is not a documented approach. We find it works well in most cases, in that ChatGPT-3.5\\n19' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 18}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nPrompt 4. LLM Prompting as the Router\\n[User:] Question: {question }\\nHow would you like to answer the question?\\nA. Organize the answer as a list of points or perspectives (in the format of 1., 2., 3., etc.), and the points or perspectives\\ncan be answered independently without referring to the contents of the previous points.\\nB. Organize the answer as a list of points or perspectives (in the format of 1., 2., 3., etc.), and the contents of later points\\nor perspectives cannot be answered independently without referring to the contents of the previous ones.\\nC. Do not organize the answer as a list of points or perspectives.\\nJust say A, B, or C. Do not explain. Do not provide an answer to the question.\\n[Assistant:]\\ncontinues the texts from the provided partial answer. However, in some rare cases, ChatGPT-3.5\\nrepeats the provided partial answers.\\nFor Claude over Slack, there is no obvious way to give the API a partial answer. We resort to\\nmodifying the prompt template slightly by adding\\nPlease start your answer from “ {partial answer }” and do not output other things before that\\nat the end. We find that Claude understands and obeys it well. For GPT-4, we also take this approach.\\nSystem Message. We do not include the system message in the prompts for open-source models\\nexcept LLaMA2.\\nThe partial answer, “**very shortly**”, and the 2-shot demonstrations discussed above are the only\\ndifferences between the prompts we used across all models and all evaluations.\\nB.2 S UPPORTING MULTI -ROUND CONVERSATION\\nTo use SoT in a multi-round conversation, we can just put the question and the final aggregated\\nanswer in the history, removing all the SoT prompts. In this way, using SoT in one conversation\\nround will not introduce additional prefill cost in future rounds.\\nC I MPLEMENTATION DETAILS OF SKELETON -OF-THOUGHT WITH ROUTER\\nC.1 P ROMPTING ROUTER\\nWe use Prompt 4 for querying GPT-4 as the router. If the answer is “A” (i.e., the question can be\\nanswered in a list of independent points), we will use SoT. Otherwise, if the answer is “B” (i.e., the\\nanswer is in a list of points but they depend on each other) or “C” (i.e., the answer should notbe in\\na list of points), SoT is not suitable and we will fall back to normal decoding.\\nC.2 T RAINED ROUTER\\nWe tackle the routing problem as a sequence classification task. We first annotate the LIMA training\\nset (Zhou et al., 2023), and then fine-tune a RoBERTa model (Liu et al., 2019) using the labeled\\ndata. Finally, we apply the tuned RoBERTa as the router on Vicuna-80 and WizardLM. We detail\\nthe steps in the following.\\nC.2.1 A NNOTATION PROCESS\\nIn the classification task, a label of 1 (positive) indicates that this question can be answered with\\nSoT, while a label of 0 (negative) suggests that using the normal generation mode is more suitable.\\nWe annotate the LIMA training set, which consists of 1,030 Q&As sourced from three community\\nwebpages: Stack Exchange, wikiHow, and the Pushshift Reddit. We also annotate the Vicuna-80\\nand WizardLM datasets for evaluation.\\n20' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 19}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nTable 3: Router confusion matrices on the Vicuna-80 dataset. Left: Rows are human annotations\\n(H) and columns are the GPT-4 router (G). Middle: Rows are human annotations (H) and columns\\nare the RoBERTa router (R). Right: Rows are the GPT-4 router (G) and columns are the RoBERTa\\nrouter (R).\\nG0 G1\\nH0 38 5\\nH1 0 37R0 R1\\nH0 37 6\\nH1 5 32R0 R1\\nG0 34 4\\nG1 8 34\\nTable 4: Router confusion matrices on the WizardLM dataset. Left: Rows are human annotations\\n(H) and columns are the GPT-4 router (G). Middle: Rows are human annotations (H) and columns\\nare the RoBERTa router (R). Right: Rows are the GPT-4 router (G) and columns are the RoBERTa\\nrouter (R).\\nG0 G1\\nH0 94 66\\nH1 3 55R0 R1\\nH0 135 25\\nH1 31 27R0 R1\\nG0 93 4\\nG1 73 48\\nWe use GPT-4 to assist the annotation process. Specifically, we present each question to GPT-4 and\\nanalyze its answer to determine whether SoT can be triggered for this question. We assign a positive\\nlabel to a question if GPT-4’s response meets two criteria: (1) it contains a list of points that can be\\nexpanded in parallel, (2) each point provides sufficient details (i.e., the point-expanding response is\\nnot too short), which will enable SoT to achieve a speed-up. Two of the paper’s authors conduct the\\nannotation process independently, and discuss the inconsistent annotations to decide the final label.\\nC.2.2 T RAINING DETAILS\\nWe use roberta-base with 120M parameters as the router model. The finetuning is conducted\\nusing the AdamW optimizer (Loshchilov & Hutter, 2019) with a weight decay of 0.01. The learning\\nrate undergoes a warm-up phase during the first 1% of iterations to 5e-5 and then decays linearly.\\nWe train the model for 2 epochs using a batch size of 32. Input sequences are either padded or\\ntruncated to achieve a consistent length of 512 tokens.\\nIn the application of SoT, false positives (SoT is incorrectly triggered when it should not be, resulting\\nin degraded answer quality) are of more significant concern than false negatives (the router misses a\\npotential SoT trigger, resulting in a reduced speed-up). Thus, to mitigate false positives, we employ\\nthe Tversky loss (Wang et al., 2023b) with parameters α= 0.7andβ= 0.3, which penalizes false\\npositives more heavily than false negatives. We also incorporate label smoothing (Szegedy et al.,\\n2016) with a factor of ϵ= 0.2. Overall, the entire fine-tuning process is efficient, completing in 2\\nminutes on an NVIDIA A100 GPU.\\nC.3 R OUTER CONSISTENCY\\nWe present the confusion matrices for the three routers to illustrate their consistency. The results on\\nVicuna-80 and WizardLM are shown in Tables 3 and 4, respectively.\\nOn Vicuna-80, we can observe a notable level of agreement among the three routers. Compared with\\nthe GPT-4-prompting router, the trained router exhibits a slightly higher number of false negatives\\nw.r.t. the human annotations. Conversely, on WizardLM, given the intricate answer structure and\\nthe presence of many ambiguous cases, the routers show significant discrepancies. Specifically, the\\nGPT-4 router produces many false positives, which pose adverse affects on the answer quality (see\\nApp. I.2). The RoBERTa router aligns more closely with the human annotations.\\nC.4 C ONCURRENT EXECUTION FOR SOT-R\\nIn SoT-R, the router serves as an additional stage that extends the two-stage SoT pipeline. The\\nSoT-R pipeline is illustrated in Fig. 9. To push the limit of latency optimization, we can run the\\nrouter, normal generation, and SoT generation concurrently. Once the router makes a decision, one\\nof the normal and SoT generation processes can be aborted. However, this approach will increase\\n21' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 20}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nRouterSkeleton Expandpositive\\nnegativeDecodeQuestion\\nAnswerAnswer\\nRouterSkeleton Expand\\nDecodeQuestionAnswer\\nAnswerpositive\\nnegative\\nFigure 9: Left: The SoT-R pipeline. Right: A possible approach to further reduce latency at the\\ncost of token overhead.\\nthe token overhead. Therefore, we did not employ this approach in this work and leave it to future\\nwork.\\nD R ELATED WORK (EXPANDED )\\nD.1 E FFICIENT LLM S\\nExtensive research has been dedicated to enhancing the throughput and latency of LLM infer-\\nence. We first discuss model-level architecture design or compression techniques. These techniques\\nchange the model and can benefit both the latency and throughput but require finetuning to retain the\\nmodel quality. Then, we discuss system-level efforts that optimize the computational graph or the\\nassignment and scheduling of the computational graph on computation and storage devices. Most\\nsystem-level efforts accelerate the prefilling phase or focus on improving the throughput. Finally,\\nwe discuss some research efforts that share a similar motivation to ours, namely, addressing the\\nefficiency issue of sequential decoding.\\nModel-level optimization. Considerable architectural design efforts have emerged to (1) improve\\nthe scalability w.r.t. model size by introducing mixture-of-expert inference (Lepikhin et al., 2021;\\nFedus et al., 2022), (2) address the quadratic complexity w.r.t. input size of attention by designing\\nnew attention mechanisms (Kitaev et al., 2020; Wang et al., 2020), (3) reduce the memory access\\nand footprint of attention by using multi-query attention (Shazeer, 2019), and so on. However, these\\nmethods usually require a substantial re-training cost. The model compression techniques require a\\nsmaller amount of fine-tuning by reducing the model complexity of a pre-trained LLM from certain\\naspects (Ganesh et al., 2021). Representative techniques include quantization (Xiao et al., 2022;\\nFrantar et al., 2022; Lin et al., 2023), the static or dynamic pruning of weights, activation, and\\nattention (Mishra et al., 2021; Zaheer et al., 2020; Wang et al., 2021; Chen et al., 2023b), and so on.\\nZooming out from LLM compression to the whole field of model compression, we can see that\\nmodel co-design or compression for efficiency has received tremendous attention in the past few\\nyears and has grown into large research fields, such as pruning (Han et al., 2015; Wen et al., 2016),\\nquantization (Krishnamoorthi, 2018), factorization (Denton et al., 2014), and neural architecture\\nsearch (Zoph & Le, 2017; Elsken et al., 2019; Cai et al., 2019). Different from the model co-design\\nparadigm, SoT is in a “ content co-organization for efficiency ” paradigm for improving the LLM\\nefficiency . Along with the growth in the LLM capabilities and amount of LLM-generated data,\\ndata-level techniques could become important tools in the efficient LLM toolbox.\\nSystem-level optimization. In the realm of lossless acceleration, considerable efforts have been\\ndevoted to addressing the I/O-bound nature of LLMs on modern hardware platforms (Dao et al.,\\n2022). Numerous studies (Dao et al., 2022; Zhai et al., 2022; Ivanov et al., 2021; NVIDIA, 2019)\\nhave focused on adjusting the computational graph by fusing and implementing operations in an\\nI/O-friendly way. As a representative method, FlashAttention (Dao et al., 2022) fuses all operations\\nof one attention into one GPU kernel with spatially tiled computation to reduce the off-chip I/O of\\nthe attention map. While FlashAttention can effectively accelerate training and the prefilling phase\\nof inference, it cannot accelerate the decoding phase much (when the batch size is small), as it is\\nthe I/O of weights rather than activation or attention map that bottlenecks the decoding phase. For\\nexample, when the context length is 64, decoding one token using LLaMA-7B needs to load each\\n22' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 21}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nof the 7B parameters from the off-chip HBM onto the GPU chip at least once, but only transferring\\nabout 20M (0.02B) activation values between the off-chip HBM and GPU chip.\\nIn order to satisfy Service Level Objectives, serving systems focus on improving the serving\\nthroughput under latency constraints. To this end, serving systems (Fang et al., 2021; NVIDIA,\\n2021; Google, 2021) pack multiple queries together into a batch to improve the hardware utiliza-\\ntion. The batching technique has proven highly effective in enhancing throughput, leading to the\\ndevelopment of various variants. For example, some work designs methods to decide which queries\\nto batch together (Fang et al., 2021; Zhou et al., 2022), while others selectively batch parts of the\\nmodel to enable fine-grained iteration-level batching (Yu et al., 2022) or multi-task batching (Zhou\\net al., 2022). Various model parallelism (Lu et al., 2017; Huang et al., 2019; Narayanan et al.,\\n2019; Rajbhandari et al., 2020; Narayanan et al., 2021; Li et al., 2021; Zheng et al., 2022) and\\noffloading (Ren et al., 2021; Sheng et al., 2023) techniques have been proposed to maximize the\\nthroughput of LLM training or inference. In a nutshell, given the computational graph and device\\nconfigurations, these techniques optimize the split, assignment, and scheduling of computations,\\nstorage, and communications on devices. In addition to the model parallelism and batching tech-\\nniques, an efficient memory management mechanism for LLM workloads is also an essential feature\\nin the serving systems (Kwon et al., 2023; SenseTime, 2023a;b).\\nTo sum up, these system-level techniques mainly help with the throughput in training and batched\\ninference. They can be used by SoT to improve the throughput of the batched decoding of multiple\\nsegments. This means that SoT can harness the power of these throughput-oriented techniques and\\nmake them help with the end-to-end latency , offering a new dimension for better trading off latency\\nand throughput in future serving systems.\\nAnother parallelism perspective to position SoT is that SoT guides the LLM to adjust the sequen-\\ntial workload to become “inter-content” parallelizable , which differs from the parallelism levels\\nin existing serving systems, including inter-instance (Krizhevsky, 2014; Rajbhandari et al., 2020),\\ninter-operation (Huang et al., 2019; Narayanan et al., 2019; 2021), intra-operation (Xu et al., 2021),\\nand inter-token (Li et al., 2021). It may be worthwhile to explore the integration of SoT into serving\\nsystems to maximize the hardware utilization .\\nDecoding optimization. One bottleneck for the end-to-end latency lies in the autoregressive de-\\ncoding phase, where tokens must be generated one by one. Due to the dependency between tokens,\\nthe computation of different tokens cannot be parallelized, causing severe under-utilization of GPU.\\nIn order to improve the end-to-end decoding latency of a given LLM, speculative decoding meth-\\nods (Stern et al., 2018; Leviathan et al., 2022; Chen et al., 2023a; Gante, 2023; Sun et al., 2023;\\nMiao et al., 2023) propose to use cheaper approaches to generate short candidate token sequences,\\nfor example, by sequentially decoding with an assisting model much smaller than the given LLM.\\nThen, they use the LLM to parallelly verify the candidates and keep the prefix sequence that matches\\nthe LLM’s verification results.\\nAnother line of work that shares the motivation of addressing the autoregressive efficiency issue is\\nnon-autoregressive generation (NAG) methods (Gu et al., 2018; Xiao et al., 2023). NAG methods\\nsample consecutive tokens parallelly, often with the aid of a modified and tuned model. To maintain\\nthe answer quality, instead of sampling for one iteration, many NAG methods refine the output\\nparallelly for multiple iterations (Xiao et al., 2023; Santilli et al., 2023).\\nTo summarize, the speculative decoding methods use assisting models for letting the LLM conduct\\nparallel verification of consecutive tokens , and the NAG methods rely on specially designed models,\\ntraining schemes, or sampling schemes for the parallel sampling and refinement of consecutive to-\\nkens. In contrast, SoT prompts the LLM itself to plan the contents in a way that permits the parallel\\ngeneration of multiple tokens in different segments . SoT exploits the emerging instruction-following\\nand planning ability of SoTA LLMs rather than relying on specially designed modeling, sampling,\\nand training schemes. This is different from all existing work that targets the autoregressive effi-\\nciency issue.\\nD.2 P ROMPTING METHODS FOR LLM S\\nIn recent years, the “pre-train, prompt, and predict” paradigm has emerged (Liu et al., 2023), which\\ndesigns prompts comprising task descriptions and (optionally) a few demonstrations to guide pre-\\n23' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 22}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nTable 5: The latency and average GPU performance of the prefilling and decoding phases when\\ninferencing LLMs. The prefilling token length is 128, the decoding token length is 64, and the batch\\nsize is 1. The test is run on one NVIDIA A100 GPU.\\nModel Prefill/Decode Latency (ms) Prefill/Decode GPU Perf. (TFLOPS)\\nLLaMA-7B 40 / 2735 43 / 0.31\\nLLaMA-13B 54 / 3725 62 / 0.44\\nLLaMA-33B 100 / 5506 85 / 0.75\\ntrained LLMs in generating answers for a wide range of downstream tasks. Researchers found that\\ninstruction-tuned LLMs (Brown et al., 2020; Wei et al., 2021; Ouyang et al., 2022; Chung et al.,\\n2022; Taori et al., 2023) possess a strong ability to (1) generalize to new tasks thanks to the diverse\\nnatural language descriptions encountered during instruction tuning, and (2) learn in-context using\\na few demonstrations without weight tuning.\\nIn virtue of these abilities, the field has been manually engineering (Brown et al., 2020; Kojima\\net al., 2022; Shen et al., 2023; Li et al., 2023a), automatic searching (Shin et al., 2020), or continu-\\nously tuning (Li & Liang, 2021; Lester et al., 2021) the prompts for uncovering the capabilities of\\nLLMs on downstream tasks. There are a bunch of prompting methods that improves the reasoning\\nperformance of LLMs by designing thinking flows mimicking human reasoning: (1) mimicking the\\nstep-by-step or compositional thinking structure (Wei et al., 2022; Kojima et al., 2022; Press et al.,\\n2022; Yao et al., 2023; Besta et al., 2023; Zhang et al., 2023), (2) designing multiple reasoning paths\\nand their aggregation (Wang et al., 2022; Yao et al., 2023; Li et al., 2023c), and (3) using tools for\\ncalculation and information retrieval (Chen et al., 2022; Yao et al., 2022; Schick et al., 2023). As\\na representative example, the Chain-of-Thought prompts largely improve the performance on tasks\\nthat require logical reasoning by simply providing a “Let’s think step by step” (Kojima et al., 2022)\\ninstruction or a few demonstrations (Wei et al., 2022). Another topic that arises quite a surge of in-\\nterests is to prompt LLMs to help finish complex multi-modality task (Shen et al., 2023; Zhu et al.,\\n2023). For example, HuggingGPT (Shen et al., 2023) design prompts to guide the LLM to generate\\nstructural JSON for the orchestration of multi-model execution to finish complex tasks.\\nTo summarize, the large literature on prompting methods has been aiming at uncovering different\\ncapabilities of LLM and improving the answer quality on different downstream tasks. In contrast,\\nSoT is a first attempt at exploiting the power of prompting to improve efficiency .\\nE E FFICIENCY ANALYSIS\\nThis section gives a detailed explanation on why SoT can reduce the overall decoding latency with\\nthe same computational resource for local models.\\nThe vanilla approach processes only one question and decodes the answers sequentially, whereas\\nSoT processes multiple point-expanding requests and the answers in a batch. We focus on the\\nfollowing question: “Compared to processing only one sequence, how much peak memory overhead\\nand latency increase will be brought by processing a batch of sequences?”\\nA typical LLM generative process consists of two phases: (1) the prefilling phase in which the\\nprompt is parsed to generate the key-value cache for further use, and (2) the decoding phase in\\nwhich tokens are generated one by one in a sequential manner. The decoding phase accounts for\\nthe majority of the end-to-end latency, especially when generating a long response. As shown in\\nTable 5, when running Vicuna-7B on NVIDIA A100-80G, the actual computing performance is\\nonly 0.31 TFLOPS (0.1% utilization) in the decoding phase, compared to 43 TFLOPS (13.8% uti-\\nlization) during prefilling. The utilization is calculated with respect to the FP165tensor core peak\\nperformance – 312 TFLOPS for NVIDIA-A100. As a result, the latency of decoding only one token\\nis comparable to that of prefilling 128 tokens (40ms). This huge gap in actual computing perfor-\\nmance and thereby the latency arises from the fact that all LLM weights need to be loaded onto the\\nGPU chip at least once only for decoding one token, so the decoding is heavily bottlenecked by the\\nI/O of weights and the GPU computation units cannot be well utilized.\\n5All of our experiments are run with FP16 inference.\\n24' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 23}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n1 2 3 4 5 6 7 8 9\\nB300035004000450050005500\\nLLaMA-7B\\nLLaMA-13B\\nLLaMA-33B\\n(a) Latency (ms)\\n1 2 3 4 5 6 7 8 9\\nB0123456\\nLLaMA-7B\\nLLaMA-13B\\nLLaMA-33B (b) Actual GPU Perf. (TFLOPS)\\n1 2 3 4 5 6 7 8 9\\nB203040506070\\nLLaMA-7B\\nLLaMA-13B\\nLLaMA-33B (c) Peak Memory (GB)\\nFigure 10: The trends of latency, average GPU performance of decoding one token, and peak mem-\\nory with respect to the batch size Bof sequences. The prefilling token length is 128, and the\\ndecoding token length is 64. The test is run on one NVIDIA A100 GPU.\\nWhen conducting batched decoding, as the sequence batch size Bincreases, the latency of decoding\\none token for each sequence stays roughly the same (Fig. 10a), as the amount of LLM weights that\\nneeds to be loaded onto the chip does not change. As a result, the GPU computation utilization\\n(Actual GPU Performance\\nPeak GPU Performance) increases almost linearly as Bincreases (Fig. 10b). In other words, for gener-\\nating a final answer of length N, if we cut the answer into Bsegments of length N/B and decode\\nthem as a batch, we can get a B×decoding speed-up compared to sequential decoding. Never-\\ntheless, in practice, as prefilling longer requests brings some overhead, and the lengths of the B\\nsegments could be imbalanced, the actual speed-up of the batched point-expanding stage compared\\nwith the original prefilling and sequential decoding process is smaller than B.\\nAs for the peak memory overhead, the amount of LLM weights can be one to two orders of mag-\\nnitude larger than that of all the intermediate activations as long as the prefilling token length is not\\ntoo large, not to mention that most activations do not need to be saved for back-propagation during\\ninference. Therefore, the LLM weights account for the majority of the memory footprint in our test\\ncases. Consequently, as shown in Fig. 10c, the peak memory overhead due to the increasing size\\nof the KV cache and activation grows at a slow pace as the batch size Bincreases. Thanks to the\\nsmall peak memory overhead, in all of our experiments, we managed to use one GPU to run SoT\\nwithout seeking help from other peak memory optimization techniques (e.g., quantization (Frantar\\net al., 2022; Lin et al., 2023), offloading (Sheng et al., 2023)).\\nF E FFICIENCY PROFILING\\nWe run the profiling on the target GPU (NVIDIA A100-80G and NVIDIA RTX 3090) with CUDA\\n11.7, using the Hugging Face transformer library 4.28.1 and PyTorch 2.0.1. The host of A100-80G\\nhas an Intel Xeon Platinum 8358P CPU and 1T memory. The host of RTX 3090 has an Intel Xeon\\nGold 6246R CPU and 512G memory.\\nLatency profiling and estimation. For the decoding phase, we denote tD\\nB(k)as the latency\\nof batched decoding the k+ 1-th token with batch size B, where the superscript Dstands for\\n“decode”. For each batch size B= 1,···,16and each context length k= 1,···,1024 , we\\nusetorch.cuda.Event to record the latency of decoding one token. We run each decod-\\ning three times continuously and take their geometric mean as {tD\\nB(k)}k=1,···,1024;B=1,···,16. For\\nthe prefilling phase, we profile the latency of batched prefilling the inputs with token length kin\\nrange (1,700,10)and batch size B= 1,···,16, and denote it as tP\\nB(k), where the superscript P\\nstands for “prefill”. We run each test seven times continuously, regard the first two times as the\\nwarmup tests, and take the geometric mean of the last five times as {tP\\nB(k)}k=1,11,···,691;B=1,···,16.\\nOnce we get the latency profiling table, given a request with litokens and the decoding batch size\\nB, the latency of generating lotokens can be estimated as:\\nT(li, lo, B) =˜tP\\nB(li) +li+lo−1X\\nk=litD\\nB(k), (1)\\nwhere the subscripts iandostand for “input” and “output”. Note that we only test the prefill-\\ning latency every ten token lengths (i.e., 1,11,21,···) for fast profiling and estimate ˜tP\\nB(li)by\\ntP\\nB(⌊li\\n10⌋ ×10 + 1) .\\n25' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 24}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nThe SoT decoding process consists of two stages: the skeleton stage and the point-expanding stage.\\nDenoting the token length of the skeleton request and skeleton response as ls\\niandls\\no, the token length\\nof the longest point-expanding request and the longest point-expanding response as lpe\\niandlpe\\no, the\\nnumber of the points as B, we can compute the latency of the skeleton and point-expanding stages\\nas:\\nLs(ls\\ni, ls\\no) =T(ls\\ni, ls\\no,1), (2)\\nLpe(lpe\\ni, lpe\\no, B) =T(lpe\\ni, lpe\\no, B). (3)\\nUsing the latency profiling table, we can further estimate the average GPU computing performance\\nin FLOPS (i.e., FLOPs per second) of decoding lotokens with prefilling length lias\\nPD(li, lo, B) =Pli+lo−1\\nk=lifD\\nB(k)\\nPli+lo−1\\nk=litD\\nB(k), (4)\\nwhere fD\\nB(k)denotes the FLOPs of decoding one token with context length k, which is calculated\\nby DeepSpeed’s FLOPs profiler6. Fig. 10b reports the average GPU computing performance during\\nthe process of decoding 64 tokens (prefilling length=128), i.e., PD(128,64, B).\\nMemory profiling and evaluation. To evaluate the peak memory, we use\\ntorch.cuda.max_memory_allocated to record the memory consumption of prefill-\\ning sequences of different lengths and decoding with different context lengths and a batch size\\nranging from 1 to 16. Then, we calculate the peak memory of each stage as the maximum value of\\nthe prefilling and decoding phases, and calculate the overall peak memory of SoT as the maximum\\nvalue of the skeleton and point-expanding stages.\\n6https://deepspeed.readthedocs.io/en/latest/flops-profiler.html\\n26' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 25}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nG E FFICIENCY EVALUATION\\nG.1 S KELETON -OF-THOUGHT\\nG.1.1 D ETAILED STATISTICS OF TOKEN LENGTHS AND POINT NUMBERS\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage6.4 5.3 4.4 7.3 4.9 7.9 6.6 9.7 7.1 5.0 4.7 5.3 8.6\\n4.4 3.7 3.3 5.7 5.0 4.0 3.7 5.7 5.0 3.3 3.7 4.7 5.3\\n6.3 4.9 5.6 5.4 5.3 6.5 6.9 10.0 5.8 5.5 6.4 4.8 8.5\\n7.4 6.7 6.3 6.7 6.0 7.0 7.3 9.9 9.1 5.3 8.6 6.3 9.9\\n7.5 5.9 6.6 8.2 6.3 8.0 7.8 8.8 8.1 5.8 8.3 5.9 9.8\\n7.4 7.5 5.9 5.9 6.3 7.5 8.6 9.4 8.1 6.4 7.9 6.1 9.4\\n7.8 6.3 6.2 7.4 6.7 8.4 8.6 9.7 9.2 6.4 7.9 6.7 9.5\\n6.8 5.0 6.1 6.1 4.9 9.1 7.7 8.4 8.3 4.4 7.3 4.9 9.5\\n6.8 6.0 5.5 5.5 4.8 8.6 7.8 9.2 8.8 4.1 7.3 5.1 9.3\\n6.8 5.7 5.6 6.5 5.6 7.4 7.2 9.0 7.7 5.1 6.9 5.5 8.9\\n4.05.06.07.08.09.010.0\\n(a) The number of points B.\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage372.4 374.0 462.7 386.9 459.7 394.9 384.9 300.3 338.4 381.4 338.6 343.0 304.3\\n173.5 177.3 208.0 95.0 254.7 159.7 255.0 83.0 273.7 156.7 137.0 139.7 142.7\\n391.8 396.6 350.3 453.0 382.8 429.6 465.3 398.1 272.1 402.1 417.6 333.8 400.2\\n311.4 368.5 356.4 273.4 338.2 285.4 431.7 155.7 361.0 254.3 304.7 235.3 372.5\\n409.8 436.6 478.1 373.9 397.9 404.1 440.4 260.4 325.2 386.0 464.4 366.6 583.6\\n401.0 470.6 488.6 468.9 377.1 369.8 497.8 266.7 376.8 341.1 352.9 320.2 481.8\\n372.7 468.4 469.8 417.2 328.1 341.1 476.3 194.2 417.8 321.8 361.3 231.7 444.3\\n319.0 285.4 419.5 303.3 245.5 332.1 501.9 198.2 399.7 252.3 404.9 173.4 311.3\\n335.6 424.5 487.9 326.0 324.9 307.6 479.6 169.6 337.9 285.9 303.7 206.1 373.5\\n343.0 378.0 413.5 344.2 345.4 336.0 437.0 225.1 344.7 309.1 342.8 261.1 379.4\\n100.0200.0300.0400.0500.0 (b) The normal answer length.\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage114.9 92.6 126.1 151.7 143.0 124.7 104.9 216.0 120.6 128.4 48.0 56.1 67.0\\n95.0 104.3 94.3 27.3 162.0 189.0 101.7 79.3 98.7 108.0 64.7 45.3 65.7\\n116.0 117.2 117.1 170.7 188.9 106.0 126.0 163.3 105.8 80.4 65.0 78.0 74.0\\n89.0 93.1 108.2 63.4 102.0 100.3 118.7 123.4 76.9 71.8 59.4 66.1 84.6\\n97.2 94.4 114.5 161.9 125.1 92.6 118.1 89.5 90.2 85.8 53.8 61.3 79.4\\n94.1 99.9 101.0 98.1 110.5 108.9 114.0 117.8 90.9 81.1 61.2 62.9 83.0\\n86.0 86.3 108.5 106.6 108.6 89.6 105.4 87.3 81.3 76.8 51.3 55.5 75.1\\n93.5 106.2 103.2 101.9 88.9 118.3 113.0 129.2 79.6 75.3 66.6 56.7 83.1\\n86.9 97.4 100.1 75.4 121.3 100.6 98.3 104.2 88.5 75.6 55.0 57.0 69.7\\n97.0 99.0 108.1 106.3 127.8 114.4 111.1 123.3 92.5 87.0 58.3 59.9 75.7\\n50.075.0100.0125.0150.0175.0200.0\\n(c) The maximum point-expanding response length.\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage0.4 0.3 0.4 0.4 0.3 0.3 0.3 0.9 0.5 0.3 0.1 0.2 0.2\\n0.8 0.6 0.5 0.7 0.6 1.3 0.5 3.0 0.6 0.7 0.6 0.3 0.5\\n0.3 0.3 0.4 0.4 0.5 0.3 0.3 0.4 0.5 0.2 0.2 0.2 0.2\\n0.4 0.3 0.4 0.4 0.3 0.4 0.3 1.2 0.3 0.3 0.2 0.3 0.3\\n0.3 0.2 0.2 0.7 0.3 0.2 0.6 0.4 0.6 0.2 0.1 0.2 0.1\\n0.3 0.2 0.2 0.2 0.3 0.3 0.2 0.5 0.3 0.2 0.3 0.2 0.2\\n0.3 0.2 0.2 0.3 0.4 0.3 0.2 0.5 0.3 0.2 0.1 0.2 0.2\\n0.3 0.4 0.2 0.4 0.4 0.4 0.2 0.7 0.3 0.4 0.2 0.3 0.3\\n0.3 0.2 0.2 0.4 0.4 0.3 0.2 0.7 0.4 0.3 0.4 0.3 0.2\\n0.4 0.3 0.3 0.4 0.4 0.4 0.3 0.9 0.4 0.3 0.2 0.3 0.2\\n0.51.01.52.02.5(d) The ratio of the maximum point-expanding re-\\nsponse length to the normal answer length.\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage30.8 13.5 27.6 50.0 42.1 36.2 24.1 64.7 36.6 43.2 10.3 11.8 9.1\\n25.2 23.6 18.4 6.3 48.7 59.1 17.5 22.6 31.8 41.6 13.0 8.9 10.4\\n25.0 21.6 18.9 47.4 49.2 21.8 22.2 35.8 29.8 23.0 12.9 8.7 8.4\\n16.4 9.9 14.8 17.1 21.0 18.0 18.8 26.6 21.5 15.9 9.1 10.8 12.9\\n17.9 10.9 14.3 39.1 27.1 17.1 19.8 17.1 22.1 18.0 9.4 8.4 12.2\\n14.4 9.7 10.6 20.3 17.9 17.2 15.0 19.8 20.4 15.3 8.3 7.4 10.8\\n15.4 9.0 15.9 27.0 24.1 18.4 16.8 16.2 18.0 15.7 7.6 7.6 8.3\\n15.9 12.4 11.4 22.3 13.1 23.8 14.0 34.0 19.6 15.1 8.8 5.3 11.5\\n14.7 10.5 12.1 19.7 27.7 17.6 14.2 19.6 19.0 15.1 7.0 7.4 6.5\\n19.5 13.5 16.0 27.7 30.1 25.5 18.1 28.5 24.3 22.5 9.6 8.5 10.0\\n10.020.030.040.050.060.0\\n(e) The imbalance degree of point-expanding response\\nlengths (standard deviation of point token lengths).\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BVicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3StableVicuna-13BUltraLM-13BVicuna-7B V1.1Claude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage1.5 1.2 1.1 1.1 0.8 1.1 1.1 6.8 1.5 0.7 0.5 0.6 1.4\\n2.1 1.5 1.1 3.4 1.9 2.5 1.0 7.6 1.2 1.0 1.4 1.1 1.8\\n1.3 1.2 1.7 1.2 1.5 1.2 1.3 1.9 1.9 0.6 0.7 0.9 1.3\\n1.9 1.6 1.7 1.9 1.3 2.0 1.3 5.5 1.2 1.1 1.4 1.4 1.9\\n1.7 1.1 1.3 2.8 1.4 1.3 3.5 2.2 3.3 1.0 0.7 0.8 1.0\\n1.5 1.3 1.0 0.8 1.5 1.7 1.5 3.0 1.5 1.1 1.7 1.0 1.3\\n1.4 1.0 1.1 1.0 1.7 1.7 1.3 3.5 1.6 1.1 0.9 1.3 1.3\\n1.7 1.6 1.3 2.0 1.5 2.1 1.3 3.4 1.2 1.1 0.9 1.4 2.0\\n1.7 1.2 0.9 2.0 1.2 2.0 1.2 4.5 1.7 0.9 2.1 1.2 1.5\\n1.6 1.3 1.2 1.8 1.4 1.7 1.5 4.3 1.7 1.0 1.1 1.1 1.5\\n1.02.03.04.05.06.07.0(f) The ratio of the final SoT answer length to the nor-\\nmal answer length.\\nFigure 11: The statistics of the token lengths and point numbers on the Vicuna-80 dataset. Each row\\ncorresponds to one question category, and each column corresponds to one model.\\nG.1.2 L ATENCY BREAKDOWN : SOT S TAGES AND PHASES\\nFig. 12 presents the absolute latencies of normal and SoT generations on Vicuna-80. Again, the\\nspeed-ups of SoT compared with normal generation is evident. We can see that the decoding phases\\npredominantly account for the end-to-end latency. Consequently, although SoT has higher prefilling\\nlatency in the skeleton stage than the normal generation and introduces additional point-expanding\\n27' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 26}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nprefilling latency – which is expected – this has negligible impact on the overall latency and thereby\\nthe overall speed-up.\\n0 5000 10000 15000 20000 25000 30000 35000 40000\\nLatency (ms)ChatGPT-3.5StableVicuna-13BVicuna-7B V1.1Vicuna-7B V1.3LLaMA2-Chat-7BClaudeUltraLM-13BVicuna-13B V1.3OpenChat-13BLLaMA2-Chat-13BGPT-4Vicuna-33B V1.3\\nNormal (prefill)\\nNormal (decode)\\nSoT skeleton (prefill)\\nSoT skeleton (decode)\\nSoT point-expanding (prefill)\\nSoT point-expanding (decode)\\n(a) Average latency across all question categories except\\nmath andcode on different models.\\n0 5000 10000 15000 20000\\nLatency (ms)mathroleplaycounterfactualcommon-sensecodingfermigenericknowledgewriting(b) Average latency across all models on different\\nquestion categories.\\nFigure 12: The latency breakdown of SoT and normal generations on the Vicuna-80 dataset. For\\nopen-source models, the latency breakdown of the prefilling and decoding phases is shown in dif-\\nferent colors. For API-based models, we do not record such latency breakdown information; the bar\\nlabeled as “(decode)” indicates the overall latency of prefilling and decoding phases.\\nG.1.3 E FFICIENCY EVALUATION ON NVIDIA RTX 3090\\nWe present the SoT speed-ups and latency breakdown on RTX 3090 in Fig. 13. We test the three\\n7B models, as their FP16-precision version can be run on an RTX 3090 GPU without further peak\\nmemory optimization techniques such as weight quantization (Frantar et al., 2022; Lin et al., 2023)\\nor offloading (Sheng et al., 2023). On these three models, SoT can obtain 1.94 ×to 2.40 ×speed-up\\non average on Vicuna-80.\\nFor the five question categories that SoT can provide high-quality answers (i.e., knowledge ,common-\\nsense ,generic ,roleplay ,counterfactual ), SoT can speed-up the overall answer generation process\\nby 1.96 ×to 2.52 ×in the meantime. Note that for the math category, despite the average speed-up\\nbeing 1.20 ×by calculating the speed-up across the three math questions, SoT does not reduce the\\nabsolute latency of processing the three questions.\\n0 2000 4000 6000 8000 10000 12000 14000 16000\\nLatency (ms)Vicuna-7B V1.3Vicuna-7B V1.1LLaMA2-Chat-7B\\n1.94×2.26×2.40×\\n0 2000 4000 6000 8000 10000 12000 14000 16000\\nLatency (ms)mathfermicounterfactualcodingroleplayknowledgecommon-sensewritinggeneric\\n1.20×1.70×1.96×2.10×2.12×2.37×2.39×2.43×2.52×Normal (prefill)\\nNormal (decode)\\nSoT skeleton (prefill)\\nSoT skeleton (decode)\\nSoT point-expanding (prefill)\\nSoT point-expanding (decode)\\nFigure 13: The latency breakdown of SoT and normal decoding on the Vicuna-80 dataset. The\\naverage speed-up across questions are also marked on the figure.\\nG.1.4 A CTUAL LATENCY TESTING\\nThis section reports the actual SoT speed-up on the Vicuna-80 with batch testing (instead of analyz-\\ning with pre-made profiling tables), using a single NVIDIA A100 GPU. We test the actual end-to-end\\nlatency of the SoT and normal decoding with the 9 open-source models. For each model, we run the\\nspeed-up test for five times and plot the box in Fig. 14.\\n28' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 27}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nAs shown in Fig. 14a, the current SoT solution obtains a >2×speed-up on 6 out of the 9 open-\\nsource models (i.e., Vicuna-7B V1.1, Vicuna-7B V1.3, UltraLM-13B, LLaMA2-Chat-7B, Vicuna-\\n13B V1.3, and LLaMA2-Chat-13B), and a >1.7speed-up on OpenChat-13B and Vicuna-33B V1.3.\\nSoT achieves no speed-up on StableVicuna-13B. As shown in Fig. 14b, for the five question cate-\\ngories that SoT can provide high-quality answers (i.e., knowledge ,common-sense ,generic ,roleplay ,\\ncounterfactual ), SoT can speed-up the overall answer generation process by 2.15 ×to 2.50 ×in the\\nmeantime.\\n1.0 1.5 2.0 2.5 3.0 3.5StableVicuna-13BVicuna-33B V1.3OpenChat-13BLLaMA2-Chat-13BVicuna-13B V1.3LLaMA2-Chat-7BUltraLM-13BVicuna-7B V1.3Vicuna-7B V1.1\\n0.97×1.75×1.97×2.14×2.19×2.20×2.75×2.82×2.88×\\n(a) Average speed-up on different models.\\n1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8 3.0fermimathroleplaywritingcounterfactualcodingknowledgecommon-sensegeneric\\n1.63×1.67×2.15×2.16×2.18×2.29×2.34×2.45×2.50× (b) Average speed-up on different question categories.\\nFigure 14: Speed-ups on 9 open-source models on the Vicuna-80 dataset with actual batch testing.\\nG.2 S KELETON -OF-THOUGHT WITH ROUTER\\nThe overhead brought by the router inference is relatively small: On the Vicuna-80 dataset,\\nthe prompting and trained router have an average latency of 0.65s (0.39s ∼1.37s) and 0.04s\\n(0.008s ∼1.55s), respectively. On the WizardLM dataset, the average latency of the prompting and\\ntrained router is 0.80s (0.36s ∼2.22s) and 0.03s (0.009s ∼2.52s), respectively.\\nG.2.1 S PEED -UP BREAKDOWN :MODELS\\nFig. 15 shows the speed-ups of SoT-R on different models on the Vicuna-80 dataset. Fig. 16 and\\nFig. 17 show the speed-ups of SoT-R on different models on the WizardLM dataset. We can ob-\\nserve that on Vicuna-80, the two methods yield similar speed-ups, whereas on WizardLM, GPT-4\\nprompting router usually obtains higher speed-ups than the trained router, especially on GPT-4 itself.\\n1.0 1.2 1.4 1.6 1.8 2.0 2.2StableVicuna-13BClaudeChatGPT-3.5Vicuna-13B V1.3Vicuna-7B V1.3UltraLM-13BGPT-4Vicuna-7B V1.1Vicuna-33B V1.3OpenChat-13BLLaMA2-Chat-7BLLaMA2-Chat-13B\\n0.98×1.15×1.24×1.32×1.39×1.51×1.54×1.55×1.62×1.66×1.67×1.70×\\n(a) Average speed-up across all question categories\\nwith prompting router.\\n1.0 1.2 1.4 1.6 1.8 2.0 2.2StableVicuna-13BClaudeChatGPT-3.5Vicuna-13B V1.3Vicuna-7B V1.3GPT-4Vicuna-33B V1.3UltraLM-13BVicuna-7B V1.1LLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13B\\n0.99×1.14×1.33×1.34×1.42×1.49×1.57×1.59×1.59×1.69×1.70×1.82×(b) Average speed-up across all question categories\\nwith trained router.\\nFigure 15: Speed-ups of SoT-R on different models on Vicuna-80 dataset.\\n29' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 28}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75StableVicuna-13BClaudeChatGPT-3.5Vicuna-7B V1.3LLaMA2-Chat-7BLLaMA2-Chat-13BVicuna-7B V1.1UltraLM-13BVicuna-13B V1.3OpenChat-13BVicuna-33B V1.3GPT-4\\n1.13×1.13×1.40×1.49×1.51×1.52×1.56×1.57×1.59×1.66×1.68×2.41×\\n(a) Average speed-up across all question categories\\nwith prompting router.\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75ClaudeStableVicuna-13BVicuna-13B V1.3UltraLM-13BVicuna-33B V1.3Vicuna-7B V1.3LLaMA2-Chat-13BVicuna-7B V1.1LLaMA2-Chat-7BChatGPT-3.5OpenChat-13BGPT-4\\n1.09×1.09×1.31×1.33×1.33×1.34×1.35×1.36×1.37×1.37×1.42×1.74×(b) Average speed-up across all question categories\\nwith trained router.\\nFigure 16: Speed-ups of SoT-R on different models on WizardLM dataset.\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75ClaudeStableVicuna-13BVicuna-7B V1.3LLaMA2-Chat-7BLLaMA2-Chat-13BChatGPT-3.5Vicuna-13B V1.3Vicuna-33B V1.3OpenChat-13BVicuna-7B V1.1UltraLM-13BGPT-4\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nFigure 17: Speed-ups of SoT and SoT-R on different models on the WizardLM dataset.\\nG.2.2 S PEED -UP BREAKDOWN :CATEGORIES\\nFig. 18 and Fig. 19 show the speed-ups of SoT-R on different question categories of Vicuna-80\\ndataset. The trained router achieves slightly higher speed-up on most of the categories (except for\\nknowledge ,writing , and fermi ). Fig. 20 and Fig. 21 show the speed-ups of SoT-R on different\\nquestion categories of WizardLM dataset. We can observe that on 19 out of 29 categories, using the\\nprompting router achieves higher speed-ups than using the trained router.\\n1.001.251.501.752.002.252.502.75mathcodingfermiwritingroleplaycounterfactualknowledgecommon-sensegeneric\\n0.90×0.96×1.01×1.10×1.17×1.75×1.95×2.05×2.11×\\n(a) Speed-ups of SoT-R with prompting router on dif-\\nferent question categories.\\n1.001.251.501.752.002.252.502.75mathwritingcodingfermiroleplaycounterfactualknowledgecommon-sensegeneric\\n1.00×1.00×1.00×1.00×1.23×1.79×1.87×2.10×2.26×(b) Speed-ups of SoT-R with trained router on different\\nquestion categories.\\nFigure 18: Speed-ups of SoT-R on different question categories of Vicuna-80 dataset\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00mathfermicounterfactualroleplaycodingcommon-sensewritinggenericknowledge\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nFigure 19: Speed-ups of SoT and SoT-R on different question categories of the Vicuna-80 dataset.\\n30' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 29}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00MathPhysicsReasoningCode GenerationEntertainmentT oxicityComplex FormatMultilingualCommon-SenseCode DebugBiologyArtMusicComputer ScienceRoleplayChemistryEthicsAcademic WritingTruthfulQAWrittingLiteraturePhilosophyLawSportMedicineHistoryT echnologyEconomyCounterfactual\\n0.85×0.94×1.02×1.02×1.03×1.12×1.14×1.22×1.24×1.25×1.34×1.47×1.54×1.54×1.58×1.62×1.67×1.69×1.74×1.77×1.85×1.90×1.90×1.93×2.08×2.10×2.14×2.18×2.23×\\n(a) Speed-ups of SoT-R with prompting router on dif-\\nferent question categories.\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00Code GenerationEntertainmentArtComplex FormatMathLiteratureCode DebugLawAcademic WritingPhilosophyBiologyReasoningPhysicsHistoryComputer ScienceMultilingualMusicT oxicityRoleplayCommon-SenseTruthfulQAWrittingEconomyChemistryEthicsSportT echnologyMedicineCounterfactual\\n0.99×1.00×1.00×1.00×1.00×1.00×1.00×1.00×1.00×1.00×1.07×1.09×1.14×1.16×1.17×1.17×1.20×1.22×1.36×1.37×1.41×1.49×1.65×1.73×1.82×2.01×2.17×2.26×2.41×(b) Speed-ups of SoT-R with trained router on different\\nquestion categories.\\nFigure 20: Speed-ups of SoT-R on different question categories of WizardLM dataset\\n1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00EntertainmentPhysicsReasoningMultilingualMathCommon-SenseBiologyArtMusicT oxicityEthicsComputer ScienceCode DebugChemistryLiteratureAcademic WritingPhilosophyLawTruthfulQARoleplayCode GenerationComplex FormatSportWrittingMedicineHistoryT echnologyEconomyCounterfactual\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nFigure 21: Speed-ups of SoT and SoT-R on different question categories of the WizardLM dataset.\\nH O VERHEAD OF SOTINDIFFERENT SCENARIOS\\nDespite the optimizations made to the decoding phase, SoT brings overhead to the prefilling phase as\\nthe model needs to handle additional SoT prompts. Table 6 reports SoT’s prefilling overhead for the\\nAPI-based models. These statistics are averaged across the Vicuna-80 questions that are suitable for\\nSoT (according to our manual annotation). We can see that SoT significantly increases the number\\nof prefilling tokens. This is because that SoT issues an independent point-expanding request for\\neach point, with the average number of points being 6.8 on Vicuna-80 dataset across all evaluated\\nmodels. Consequently, the APIs need to prefill the point-expanding request multiple times.\\n31' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 30}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nTable 6: SoT’s prefilling token overhead for API-based models.\\nModelPrefill Phase\\nNormal SoT Stage 1 SoT Stage 2 Ratio (SoT / Normal)\\nClaude 12.52 171.41 808.91 78.30\\nChatGPT-3.5 12.52 171.41 591.31 60.92\\nGPT-4 12.52 171.41 983.09 92.21\\nWhen using SoT to serve the open-source models, a simple and small trick is to prefill the common\\nprefix of point-expanding requests with a batch size of 1 during Stage 2 (i.e., the point-expanding\\nstage). Table 7 shows the prefilling overhead after applying the trick. Although the ratio is consid-\\nerably smaller compared to that of the API-based models, this computational overhead remains a\\nconcern, especially during periods of high system workload.\\nThere are some possibilities to further reduce the token and computational overhead that are worth\\nexploring in future work. To name a few: (1) When using SoT in serving systems, we can simply\\nreuse the key-value cache containing the question and skeleton from Stage 1 during Stage 2, rather\\nthan re-prefilling them as in a multi-round conversation. (2) Generally, as LLM capabilities continue\\nto evolve and prompt tuning techniques advance (Shin et al., 2020; Li & Liang, 2021; Lester et al.,\\n2021), the possibility of using much shorter prompts to activate the SoT mode in the future holds\\npromise, which would significantly mitigate the token or computational overhead.\\nTable 7: SoT’s computational overhead (in terms of the number of prefilling tokens) for open-source\\nmodels.\\nModelPrefill Phase\\nNaive SoT Stage 1 SoT Stage 2 Ratio (SoT / Normal)\\nLLaMA2-Chat-7B 12.52 171.41 216.49 30.98\\nLLaMA2-Chat-13B 12.52 171.41 216.41 30.98\\nOpenChat-13B 12.52 171.41 234.38 32.41\\nVicuna-7B V1.3 12.52 171.41 211.61 30.59\\nVicuna-13B V1.3 12.52 171.41 273.39 35.53\\nVicuna-33B V1.3 12.52 171.41 258.88 34.37\\nStableVicuna-13B 12.52 171.41 312.03 38.61\\nUltraLM-13B 12.52 171.41 290.88 36.92\\nVicuna-7B V1.1 12.52 171.41 196.64 29.40\\nI A NSWER QUALITY EVALUATION\\nI.1 S KELETON -OF-THOUGHT\\nI.1.1 A NSWER ANALYSIS : DIFFERENT MODELS\\nModels on which SoT has low net win rates. We observe two types of reasons for the low net win\\nrates.\\n(1) OpenChat-13B, Vicuna-7B V1.1, and LLaMA2-Chat-13B. For the weak models such as\\nOpenChat-13B and Vicuna-7B V1.1, they are not able to follow the SoT prompts precisely. For\\nOpenChat-13B and LLaMA2-Chat-13B, sometimes the skeleton contains undesired contents (e.g.,\\ncompleting the skeleton points as shown below).\\n32' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 31}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: How many lightning strikes occur on Earth each day? Try to explain your answer. Your\\nexplanation should take the reader through your reasoning step-by-step.\\nSoT’s answer (OpenChat-13B) (Orange texts are the skeleton.)\\n(Only showing the skeleton)\\n1.Introduction.\\n2. The Earth’s atmosphere.\\n3. Lightning formation.\\n4. Electrical discharge.\\n5. Lightning strikes per second.\\n6. Calculating the total.\\nSkeleton:\\n1. Introduction.\\nLightning is a beautiful and awe-inspiring natural phenomenon, but it can also be dangerous. It occurs when positively\\ncharged particles in a thundercloud discharge to the negatively charged Earth. The process is still not fully understood,\\nbut scientists have been able to estimate how many lightning strikes occur on Earth each day.\\nSkeleton:\\n1. The Earth’s atmosphere.\\nThe Earth’s atmosphere plays a crucial role in the formation of lightning. It consists of different layers, with the tropo-\\nsphere being the lowest and most active. The troposphere is where most of the weather occurs, and it is where lightning\\nprimarily forms. The atmosphere’s temperature, humidity, and wind patterns all contribute to the likelihood of a lightning\\nstrike.\\nSkeleton:\\n2. Lightning formation.\\nWhen warm, moist air rises, it cools and forms water ¡more texts are omitted...¿\\nFor both OpenChat-13B and Vicuna-7B V1.1, sometimes they do not write anything in the point-\\nexpanding stage when details are needed.\\nQuestion: As a superhero, how would you explain your origin story to a curious child?\\nSoT’s answer (Vicuna-7B V1.1) (Orange texts are the skeleton.)\\n1. Born with extraordinary abilities.\\n2. Trained to use powers for the greater good.\\n3. Protecting the innocent and fighting villains.I use my powers to defend the defenseless and bring justice to those who\\nhave been wronged.\\n4. Inspired by courage, justice, and selflessness.\\nThese two issues result in bad net win rates.\\n(2) Claude. For strong models such as Claude, we do not see major issues with SoT’s answers except\\nthe common issues across all models discussed in § 3.2.3. We hypothesize that the low net win rates\\nare majorly due to the fact that their normal sequential generation is already very good.\\nModels on which SoT has high net win rates. The models with high net win rates (Vicuna-13B\\nV1.3, StableVicuna-13B, and UltraLM-13B) are between the above two extremes. On one hand,\\nthey are good enough to understand SoT prompts. While we observe that they sometimes have the\\nsame issues as OpenChat-13B and Vicuna-7B V1.1 discussed before, these issues happen much less\\nfrequently. On the other hand, their normal sequential generation performance has a larger room for\\nimprovement than Claude and ChatGPT-3.5 so that the benefits from SoT are more visible on these\\nmodels.\\nI.1.2 A NSWER ANALYSIS : DIFFERENT QUESTION CATEGORIES\\nCategories on which SoT has low net win rates.\\n(1) Math. Math questions require step-by-step thinking. Without knowing the previous steps, it is\\nhard to derive the following steps. Chain-of-Thoughts (Kojima et al., 2022; Wei et al., 2022) empha-\\nsize the importance of expanding the sequential thinking steps to solve these problems successfully.\\nIn contrast, SoT requires the models to (a) come up with the skeleton of the solution first and (b)\\ndeduce each individual step independently without referring to previous results. Both of these are\\nchallenging tasks. Strong models are able to get (a) correct but fail at (b). In the following example,\\nChatGPT-3.5 gets the skeleton steps correct. However, without knowing the results from the first\\nstep, the model starts making mistakes in the second step.7\\n7One additional (minor) issue of the API-based ChatGPT-3.5 is that the skeleton point “1.” is repeated in\\nthe answer.\\n33' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 32}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: (Math) Solve for x in the equation 3x + 10 = 5(x - 2).\\n✗SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Move all x terms to one side. 1. Move all x terms to one side by subtracting 5x from both sides, giving -2x + 10 = -10.\\n2. Move all constant terms to the other side. This can be done by subtracting 5x - 10 from both sides, leaving 3x - 5x =\\n-10 - 10.\\n3. Simplify the equation. Combine like terms on both sides of the equation to get 3x + 10 = 5x - 10.\\n4. Divide both sides by the coefficient of x. Divide both sides by 2 to get x = -5.\\n5. Check the solution by plugging it back into the original equation.Substitute the value of x obtained in step 4 back into\\nthe original equation and verify that both sides are equal.\\n✓Normal answer (ChatGPT-3.5)\\n3x + 10 = 5(x - 2) can be simplified as follows:\\n3x + 10 = 5x - 10 (distribute the 5 on the right side)\\n10 + 10 = 5x - 3x (subtract 3x from both sides)\\n20 = 2x (combine like terms on the right side)\\nx = 10 (divide both sides by 2)\\nTherefore, the solution for x in the equation 3x + 10 = 5(x - 2) is x = 10.\\nFor weaker models, it is hard to even get step (a) correct. For example, as shown below, the third\\nstep “Apply FOIL” in Vicuna-13B V1.3’s SoT solution comes out of nowhere. This makes SoT’s\\nsolution incorrect (though the solution from the normal generation is also incorrect).\\nQuestion: (Math) Solve for x in the equation 3x + 10 = 5(x - 2).\\n✗SoT’s answer (Vicuna-13B V1.3) (Orange texts are the skeleton.)\\n1. Simplify equation.\\nWe can simplify the equation by combining like terms:\\n3x + 10 = 5(x - 2)\\n=¿ 3x + 10 = 5x - 10\\n=¿ x + 5 = 2\\n=¿ x = 2 - 5\\n=¿ x = -3\\n2. Factor 5(x - 2).\\n5(x - 2) = 5x - 10.\\n3. Apply FOIL.\\n* Multiply the binomials in the equation, using the first term of each binomial for the first term of the product, the outside\\nterm for the second term of the product, the second term of each binomial for the third term of the product, and the\\nremaining terms for the fourth term of the product.\\n* 3(x - 2) + 10 = 5x + 5(-2)\\n* 3x - 6 = 5x - 10\\n* 3x = 5x - 10\\n* x = 5x - 10 / 3\\n* x = 5/3x - 10/3\\n* x = 2/3x - 5/3\\n4. Solve for x.\\nAfter applying the FOIL method and simplifying the equation, we get 3x = 17. Therefore, x = 17/3.\\n✗Normal answer (Vicuna-13B V1.3)\\nTo solve for x in the equation 3x + 10 = 5(x - 2), we need to first distribute the 5 to multiply both sides by 5.\\n3x + 10 = 5(x - 2)\\n5(3x + 10) = 5(x - 2)\\n15x + 50 = 5x - 10\\nAdd 5x to both sides:\\n20x + 50 = 5x\\nSubtract 5x from both sides:\\n15x = 0\\nDivide both sides by 15:\\nx = 0\\nTherefore, the solution to the equation is x = 0.\\n(2) Fermi. Similar to math questions, questions in the fermi category require solvers to make as-\\nsumptions and calculate the answer step-by-step. For example, to answer the question in the figure\\nbelow, the solver is required to make an assumption about when life began on Earth. In step 4,\\nChatGPT-3.5 does not know that it has already assumed 3.5 billion years in step 3 and uses the\\nwrong number 4.54 billion in the calculation. In step 5, ChatGPT-3.5 does not know that it has\\nalready made the above assumptions and refuses to answer “due to the uncertainties in estimating\\nthe age of the Earth”. In contrast, normal generation is able to create a consistent solution.\\n34' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 33}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: (Fermi) How many times has the Earth orbited the Sun since the beginning of life? Try\\nto explain your answer. Your explanation should take the reader through your reasoning step-by-step.\\n✗SoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Estimate the age of the Earth. The age of the Earth is estimated to be around 4.54 billion years, based on radiometric\\ndating of rocks and meteorites.\\n2. Determine when life began on Earth. Life on Earth is estimated to have begun around 3.5 billion years ago, based on\\nthe discovery of ancient microfossils.\\n3. Calculate the number of years since life began. The oldest known fossils suggest that life on Earth began around 3.5\\nbillion years ago. Therefore, the number of years since life began on Earth is approximately 3.5 billion years.\\n4. Divide the number of years by the length of one orbit. Assuming an orbital period of 365.25 days, the Earth has\\norbited the Sun approximately 4.54 billion / 365.25 = 12,425,000 times since the beginning of life.\\n5. The Earth has orbited the Sun approximately X times since the beginning of life. Unfortunately, it is impossible to give\\na specific number for the amount of times the Earth has orbited the Sun since the beginning of life due to the uncertainties\\nin estimating the age of the Earth and when life first emerged.\\nNormal answer (ChatGPT-3.5)\\nThe beginning of life on Earth is estimated to have occurred around 3.5 to 4 billion years ago. Since that time, the Earth\\nhas been orbiting the Sun continuously.\\nThe length of one orbit, or one year, is approximately 365.25 days. This means that the Earth completes one full orbit\\naround the Sun every 365.25 days.\\nTo calculate the number of times the Earth has orbited the Sun since the beginning of life, we can divide the total number\\nof days by the length of one orbit:\\nTotal number of days since the beginning of life = (3.5 billion years) x (365 days per year) = 1.2775 trillion days\\nNumber of orbits = (1.2775 trillion days) / (365.25 days per orbit) = 3.5 billion orbits\\nTherefore, the Earth has orbited the Sun approximately 3.5 billion times since the beginning of life.\\nAs the following example shows, there are also cases when SoT solves the question (with minor\\ncomputation errors) by embedding the computation steps in the skeleton directly in the skeleton\\nstage. The point-expanding stage will then add little content (except some undesired repetition of\\nthe following skeletons occasionally). This happens both on small/weak models and large/powerful\\nmodels. Although this behavior is not what we originally expect, it sheds light on a promising direc-\\ntion for making SoT a general framework: in the problem where step-by-step thinking is needed, the\\nSoT model automatically falls back to the sequential generation mode by outputting the complete\\nanswer in the skeleton stage and skipping the point-expanding stage. Future work needs to be done\\nto control and encourage this behavior better.\\nQuestion: (Fermi) How many times does the average human blink in a lifetime? Try to explain your\\nanswer. Your explanation should take the reader through your reasoning step-by-step.\\nSoT’s answer (Vicuna-7B V1.1) (Orange texts are the skeleton.)\\n1. The average human blinks 12-15 times per minute.\\n2. There are 60 minutes in an hour.\\n3. Therefore, the average human blinks 60 x 12-15 = 720-900 times per hour.\\n4. There are 24 hours in a day.Therefore, the average human blinks 720-900 x 24 = 17,520-22,400 times per day.\\n5. Therefore, the average human blinks 720-900 x 24 = 17,520-22,400 times per day.This translates to blinking approxi-\\nmately 50-65 times per hour, which is a significant portion of the day.\\n6. There are 365 days in a year.Therefore, the average human blinks 17,520-22,400 x 365 = 5,857,600-8,124,000 times\\nper year.\\n7. Therefore, the average human blinks 17,520-22,400 x 365 = 5,857,600-8,124,000 times per year.\\n8. The human lifespan is typically 70-80 years.Therefore, the average human blinks 80,000-112,000 times in their\\nlifetime.\\n9. Therefore, the average human blinks 5,857,600-8,124,000 / 70-80 = 80,000-112,000 times in their lifetime.\\nNormal answer (Vicuna-7B V1.1)\\nThe average human blinks about 12-15 times per minute, which translates to about 18,200 to 20,400 blinks per day. Over\\nthe course of a lifetime, the number of blinks is estimated to be around 7,500,000 to 8,000,000.\\nBlinking is a reflexive action that helps to keep the eyes moist and comfortable, as well as to protect the eyes from dust\\nand other foreign particles. The frequency of blinking can vary depending on a variety of factors, including age, health,\\nand environmental conditions. For example, people who work in dusty or dry environments may blink more frequently\\nthan those who work in a clean, moist environment.\\nOver the course of a lifetime, the average person will spend approximately 27,375 days or 700,000 hours awake. This\\nmeans that the majority of the time spent blinking will occur in the first few decades of life, with the frequency of blinking\\ngradually decreasing as people age.\\nIt is important to note that there is a significant amount of individual variation in the frequency of blinking. Some people\\nmay blink more or less than the average, depending on a variety of factors such as age, health, and environmental condi-\\ntions. Additionally, blinking patterns can be affected by factors such as stress, fatigue, and certain medical conditions.\\n35' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 34}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n(3) Coding. While in most cases, the models are able to decompose the coding problem into smaller\\ntasks in the skeleton stage, the generation quality during the point-expanding stage is bad, potentially\\ndue to the fact that we did not carefully craft a special point-expanding prompt for coding. The\\nfailure cases can be grouped into two cases. (a) In some cases, the model only generates a description\\nof how implementation can be done without giving the code.\\nQuestion: (Coding) Develop a C++ program that reads a text file line by line and counts the number\\nof occurrences of a specific word in the file.\\nSoT’s answer (Claude) (Orange texts are the skeleton.)\\n1. Open file stream by declaring an ifstream object and using the open() method to open the file in read mode.\\n2. Read line by line from the file stream into a string using getline().\\n3. Find word by searching each line for the target word using string::find and keeping track of matches.\\n4. Increment counter by one each time the specified word is encountered in the current line.\\n5. Close file\\nThe file stream should be closed after finishing reading the file to free up resources. This can be done by calling the\\nclose() method on the file stream object.\\nThis might be due to the fact that the powerful models (e.g., Claude) follow the point-expanding\\nprompt “Write it **very shortly** in 1 ∼2 sentence” precisely. Better prompts tailed to coding\\ncould help. (b) In some other cases, the model tends to generate the complete code repeatedly in\\nseveral points.\\nQuestion: (Coding) Develop a C++ program that reads a text file line by line and counts the number\\nof occurrences of a specific word in the file.\\nSoT’s answer (OpenChat-13B) (Orange texts are the skeleton.)\\n1. Read file line by line.\\n2. Store lines in a container.\\n3. Count occurrences of specific word.\\n“‘cpp\\n¡more texts are omitted...¿\\n“‘\\nThis code uses the C++ standard library to read a text file line by line, store each line in a container, and count the\\noccurrences of a specific word. The results are printed.\\n4. Print results.\\nHere’s the C++ program that reads a text file line by line and counts the number of occurrences of a specific word in the\\nfile:\\n“‘cpp\\n¡more texts are omitted...¿\\n“‘\\nPlease note that this is a very basic implementation. You may need to adjust it depending on your specific requirements.\\nThis problem might also be alleviated by prompts that explicitly tell the model to only generate a\\n“code snippet” in each skeleton point.\\nAlthough better prompt engineering could lead to better results, we expect that SoT is not suitable\\nfor the coding questions in Vicuna-80. The reason is that the solutions to the problems in Vicuna-\\n80 are usually in a few lines with strong dependencies between each other. Without knowing the\\npreviously defined variable names or imported libraries, it is hard (or even impossible) to implement\\nthe subsequent code correctly. As a consequence, generating different parts of the answers in parallel\\nis not suitable here. Similar to the math questions, automatically falling back to outputting all the\\ncode in the skeleton stage and not triggering the point-expanding stage might be more suitable for\\nanswering this question type.\\nHowever, we expect that SoT could be helpful for larger coding tasks that involve multiple modules\\n(e.g., functions, classes). The skeleton stage could be in charge of defining the interfaces between\\ndifferent modules (e.g., functionalities, names, parameters, return types). The point-expanding stage\\ncould be in charge of implementing these modules or using these modules to complete the final task,\\nwhich can be done in parallel. This mimics the common practice in software engineering.\\n(4) Writing. The writing questions usually ask for an email, a blog post, or a review in a given\\nscenario. In the detailed evaluation output from FastChat and LLMZoo metrics, the major and\\ncommon complaint is that SoT’s answers are (slightly) less detailed. This could potentially be\\nimproved by point-expanding prompts that request more details.\\n36' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 35}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nWhile inspecting SoT’s answers manually, we observe one additional issue. Writing problems usu-\\nally require a coherent passage without embedded skeleton points, whereas our current SoT pipeline\\n(§ 2) concatenates skeleton points as part of the answer. One example is shown below.\\nQuestion: (Writing) Can you help me write a formal email to a potential business partner proposing\\na joint venture?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Introduce yourself and your company. Dear [Recipient],\\nI hope this email finds you well. My name is [Your Name] and I am the [Your Position] at [Your Company Name].\\n2. State the purpose of the email. The purpose of this email is to propose a joint venture between our companies.\\n3. Explain the potential benefits of the joint venture. By combining our resources and expertise, we can increase market\\nshare and profitability for both companies.\\n4. Provide details on the proposed collaboration. Our proposed collaboration would involve combining our expertise in\\nmarketing with your strong manufacturing capabilities to create a new line of products.\\n5. Suggest a follow-up meeting or call. Please let me know your availability for a follow-up call next week to discuss\\nthis opportunity further.\\n6. Thank the recipient for their time and consideration.Thank you for considering this proposal and we look forward to\\nhearing back from you soon.\\nNormal answer (ChatGPT-3.5)\\nOf course, I can help you with that. Here’s a sample email you can use as a guide:\\nSubject: Proposal for Joint Venture\\nDear [Business Partner’s Name],\\nI hope this email finds you well. I am writing to propose a joint venture between our companies, [Your Company Name]\\nand [Potential Partner Company Name]. We believe that our respective expertise can create a successful partnership that\\nwill benefit both of our businesses.\\nWe have conducted thorough research on your company and admire your innovative approach to [insert industry or niche].\\nWe think our [insert expertise or specialty] could complement your [insert potential partner’s specialty or expertise].\\nBy collaborating on this joint venture, we believe we can create a new and innovative product that will appeal to our\\nrespective markets.\\nWe are confident that our companies would work well together and that our joint venture would be successful. We would\\nlike to set up a meeting to discuss the specifics of our proposal and explore how we can move forward with the joint\\nventure.\\nThank you for considering this proposal. We look forward to hearing from you soon.\\nBest regards,\\n[Your Name]\\nIn such cases, simply removing the skeleton points would greatly improve the answer quality. To\\nmake SoT more general, one future direction is to let the LLM itself decide whether the point index\\nand point skeleton should be included to make the final answer more natural and fluent.\\nCategories on which SoT has high net win rates.\\n(1) Counterfactual, knowledge, common sense, generic. All these four categories have the same\\ncharacteristic: the ideal answer should cover several relatively independent points. Having the LLM\\ngenerate a skeleton before expanding the details can result in more comprehensive discussions for\\nthe question. Besides, organizing the answers as a list of points makes the answers easier to read,\\nwhereas the answers from normal generation are sometimes less structured and less readable. Below,\\nwe give one example for each question category to illustrate these points.\\n37' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 36}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: (Counterfactual) What if the Internet had been invented during the Renaissance period?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Advancements in communication.The invention of the Internet during the Renaissance period would have revolution-\\nized communication, allowing for faster and more efficient exchange of ideas and information across vast distances.\\n2. Increased access to knowledge.The invention of the printing press during the Renaissance period already allowed\\nfor greater access to knowledge, but the internet would have revolutionized this even further by providing instantaneous\\naccess to information from all over the world.\\n3. Improved dissemination of ideas.If the internet had been invented during the Renaissance period, the spread of ideas\\nand knowledge would have been much faster and widespread than it was at the time. This could have led to a faster\\nprogression of scientific and artistic innovations.\\n4. Impact on art and literature.The invention of the internet during the Renaissance period would have revolutionized the\\nway art and literature are created, shared, and consumed, leading to a more diverse and globally-influenced artistic and\\nliterary scene.\\n5. Potential for global trade.The invention of the internet during the Renaissance period would have greatly expanded\\nglobal trade opportunities, allowing for easier communication and collaboration between merchants and traders across\\ncontinents.\\n6. Influence on political and social structures.The invention of the internet during the Renaissance period could have led\\nto significant changes in political and social structures, allowing for greater democratization and communication among\\npeople from different regions and classes.\\nNormal answer (ChatGPT-3.5)\\nIf the Internet had been invented during the Renaissance period, it would have had a significant impact on the way people\\ncommunicated, shared ideas, and gained knowledge. The Renaissance was a time of great intellectual and artistic growth,\\nand the Internet would have facilitated the spread of these ideas and innovations.\\nScholars and artists would have been able to share their work more easily, and people from different parts of the world\\nwould have been able to connect and collaborate more easily. The Internet would have also made it easier to access\\ninformation, which could have accelerated the pace of scientific and technological advancements.\\nHowever, it’s important to note that the infrastructure required for the Internet to exist did not exist during the Renaissance\\nperiod. There were no telecommunications networks or electricity grids, so the idea of the Internet would have been\\nimpossible to realize. Nonetheless, it’s interesting to think about how the Renaissance might have been different if the\\nInternet had existed at that time.\\n38' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 37}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: (Knowledge) What are some potential implications of using a single-use plastic bottle\\nversus a reusable bottle on both the environment and human health?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Single-use plastic waste.Single-use plastic bottles contribute to the massive amount of plastic waste that ends up in\\nlandfills and oceans, harming wildlife and ecosystems.\\n2. Pollution of waterways.Single-use plastic bottles contribute to the pollution of waterways, as they often end up in\\nrivers, lakes, and oceans, causing harm to aquatic life and the overall ecosystem.\\n3. Harmful chemicals leaching.Single-use plastic bottles may release harmful chemicals such as bisphenol A (BPA) and\\nphthalates into the water or liquid they contain, posing a risk to human health.\\n4. Greenhouse gas emissions.The production and disposal of single-use plastic bottles contribute to greenhouse gas\\nemissions, which contribute to climate change. Using a reusable bottle reduces the need for constant production and\\ndisposal, therefore reducing greenhouse gas emissions.\\n5. Microplastic ingestion.Single-use plastic bottles contribute to the accumulation of microplastics in the environment,\\nwhich can be ingested by humans through food and water, leading to potential health risks.\\n6. Increased risk of disease.Single-use plastic bottles can harbor harmful bacteria, leading to an increased risk of disease\\nif not disposed of properly. Reusable bottles, when cleaned regularly, pose a lower risk.\\nNormal answer (ChatGPT-3.5)\\nUsing a single-use plastic bottle has significant implications on the environment and human health.\\nEnvironmental implications:\\n1. Plastic pollution: Single-use plastic bottles are one of the major contributors to plastic pollution in oceans and landfills.\\nThey take hundreds of years to decompose, and during that time, they release toxic chemicals and microplastics into the\\nenvironment.\\n2. Carbon emissions: Manufacturing and transporting single-use plastic bottles require a significant amount of energy\\nand resources, which contribute to greenhouse gas emissions and climate change.\\n3. Natural resource depletion: The production of single-use plastic bottles requires large amounts of water and oil, which\\nare finite resources.\\nHealth implications:\\n1. Chemical exposure: Single-use plastic bottles contain chemicals such as Bisphenol A (BPA) and phthalates, which\\ncan leach into the water and pose a risk to human health.\\n2. Microplastics ingestion: When plastic bottles break down, they release microplastics, which can enter the food chain\\nand be ingested by humans.\\nUsing a reusable bottle, on the other hand, has a positive impact on the environment and human health.\\nEnvironmental benefits:\\n1. Reduced plastic waste: Reusable bottles significantly reduce the amount of plastic waste generated.\\n2. Lower carbon emissions: Reusable bottles have a lower carbon footprint as they can be used multiple times.\\n3. Reduced resource depletion: The production of reusable bottles requires fewer resources than single-use plastic bottles.\\nHealth benefits:\\n1. Chemical-free: Reusable bottles are typically made from materials that are free from harmful chemicals, reducing the\\nrisk of chemical exposure.\\n2. Reduced microplastics: Reusable bottles do not break down easily, reducing the release of microplastics into the\\nenvironment.\\nOverall, using a reusable bottle is a more sustainable and healthier option than using a single-use plastic bottle.\\nQuestion: (Common sense) How can you determine if a person is genuinely interested in a conver-\\nsation or simply being polite?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Pay attention to body language.Notice if their posture is open or closed, if they are facing towards you or away, and if\\nthey are fidgeting or relaxed. These can all indicate their level of interest in the conversation.\\n2. Listen for engaged responses.If the person is genuinely interested in the conversation, they will respond with thoughtful\\nand relevant comments or questions rather than short, generic responses.\\n3. Observe eye contact.If the person maintains steady eye contact and their gaze is focused on you, they are likely\\ngenuinely interested in the conversation. On the other hand, if they frequently look away or seem distracted, they may\\njust be being polite.\\n4. Look for follow-up questions.If the person asks follow-up questions and seems genuinely interested in what you’re\\nsaying, then they are likely interested in the conversation and not just being polite.\\n5. Notice tone of voice.A person who is genuinely interested in a conversation will often have a more enthusiastic and\\nanimated tone of voice, compared to someone who is simply being polite and giving short, monotone responses.\\nNormal answer (ChatGPT-3.5)\\nAs an AI assistant, I cannot determine a person’s true intentions or feelings. However, there are some social cues that\\ncan indicate whether a person is genuinely interested in a conversation or not. For example, if they maintain eye contact,\\nlean in, nod their head and ask follow-up questions, it can be a sign that they are engaged in the conversation. On the\\nother hand, if they avoid eye contact, give short or vague responses, or seem distracted, it may indicate that they are\\nnot as interested. Ultimately, it’s important to remember that everyone has different communication styles, and it can be\\ndifficult to accurately interpret someone’s intentions without directly asking them.\\n39' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 38}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: (Generic) How can I improve my time management skills?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Set clear goals. Setting clear goals is important in improving time management skills as it helps you to focus on what\\nneeds to be done and what can be accomplished within a certain timeframe.\\n2. Prioritize tasks. Make a list of tasks and prioritize them based on their importance and deadline. This will help you\\nfocus on the most critical tasks and avoid wasting time on less important ones.\\n3. Create a schedule. Creating a schedule helps you allocate time for each task and ensures that you complete them\\nwithin the allotted time.\\n4. Minimize distractions. Distractions such as social media, emails, and phone notifications can waste a lot of time. Try\\nto limit them by turning off notifications or setting specific times to check them.\\n5. Take breaks. Taking breaks can actually improve productivity and help prevent burnout. It’s important to schedule\\nshort breaks throughout the day to recharge and refocus.\\n6. Learn to say no. It’s important to prioritize your own tasks and not take on too much at once. Saying no to requests\\nthat don’t align with your goals or schedule can help you manage your time more effectively.\\n7. Delegate tasks. If you have too many tasks to handle, consider delegating some of them to others who can help you.\\nThis will allow you to focus on more important tasks and manage your time more effectively.\\n8. Use time management tools.There are a variety of time management tools available, such as calendars, to-do lists, and\\nproductivity apps, that can help you stay organized and on track with your tasks.\\nNormal answer (ChatGPT-3.5)\\nImproving time management skills can be a challenge, but there are several strategies that can help. Here are a few:\\n1. Set clear goals and priorities: Identify your most important tasks and make sure to complete them first.\\n2. Make a schedule: Create a schedule that includes your most important tasks and set aside time for them.\\n3. Use a timer: Set a timer for a specific amount of time to help you stay focused and avoid distractions.\\n4. Take breaks: Take short breaks throughout the day to help you recharge and avoid burnout.\\n5. Eliminate distractions: Try to limit distractions as much as possible, such as by turning off your phone or closing your\\nemail.\\n6. Delegate tasks: If possible, delegate tasks to others to free up time for more important activities.\\nRemember, improving time management skills takes practice and perseverance. Be patient with yourself and keep trying\\nuntil you find strategies that work well for you.\\n(2) Roleplay. Roleplay questions require LLMs to assume a character and present an introduction\\nor speech to other people. LLMZoo and FastChat metrics usually favor the level of details of SoT\\nwhen assigning it a better score. Similar to the writing category discussed before, SoT’s answers\\ncould be even better if the skeleton points are removed from the answer.\\nQuestion: (Roleplay) How would you introduce yourself as a medieval knight at a royal banquet?\\nSoT’s answer (Claude) (Orange texts are the skeleton.)\\n1. Name and house. My name is Sir Percival of Camelot, knight of the Round Table and protector of King Arthur’s\\nrealm.\\n2. Lands and titles. I hold fiefdom over the lands of Westmarch and Ravenshire, and bear the titles of Baron of the\\nWestern Marches and Knight of the Raven.\\n3. Military feats. I have led my men to great victories against the kingdom’s enemies, winning many battles through\\nstrength of arms and tactical cunning.\\n4. Allegiance to king. I pledge my sword, my loyalty, and my life to serve and protect my noble king and this great\\nkingdom.\\n5. Request to join table. Your Highness, it would be the greatest honor to join your exalted table and share in this\\nmagnificent feast with my fellow knights and loyal subjects.\\nNormal answer (Claude)\\nGreetings, your majesty and honored guests. I am Sir Claude, a knight in service of the king. I hail from the province\\nof Assistantia, where I was trained in the knightly virtues of chivalry, courage and courtesy. Though I am but a humble\\nknight, I shall endeavor to serve you and this kingdom with all the strength and valor I possess. I thank you for allowing\\nme to join you at this royal feast, and hope only that my conduct brings further honor to my liege and this noble court.\\nPlease let me know if I can be of any service during the celebrations, as it would be my honor to assist you in any way.\\nI.1.3 A NSWER ANALYSIS : DIFFERENT METRICS\\nMetrics on which SoT has low net win rates.\\n(1) Coherence. In the prompt of LLMZoo evaluation, coherence is defined as “The response should\\nbe coherent and flow logically from one point to the next that is easy to read and understand without\\nmajor gaps or inconsistencies. The more coherent they are, the better.” SoT’s answer is structured in\\na list of points. It is suitable for some questions but not all. For example, in the questions that require\\n40' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 39}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nLLMs to write a passage, email, or script, the introduction and conclusion paragraphs are usually\\nmissing, and the answers usually lack transition sentences between consecutive points. These make\\nthe answers less coherent. Below is one example from Claude.\\nQuestion: Write a script for a YouTube video exploring the history and cultural significance of jazz.\\nSoT’s answer (Claude) (Orange texts are the skeleton.)\\n1. Origins. Jazz originated in the late 19th and early 20th centuries among African Americans in New Orleans, emerging\\nfrom a combination of African rhythmic traditions, blues, ragtime, and other influences.\\n2. Early jazz styles. The early styles of jazz that emerged in the late 19th and early 20th centuries included ragtime,\\nDixieland, and the blues.\\n3. Jazz age. The Jazz Age was the period during the 1920s when jazz music and dance styles like the Charleston became\\npopular cultural phenomena in American and European society.\\n4. Bebop era. Bebop emerged in the early 1940s with artists like Dizzy Gillespie and Charlie Parker experimenting with\\nfaster tempos, complex chord changes, and unpredictable melodic phrasing.\\n5. Cool jazz. Emerging in the late 1940s and early 1950s, cool jazz was a more subdued, mellow style that broke from\\nthe high-energy virtuosic improvisation of bebop.\\n6. Free jazz emerged in the late 1950s and 1960s as musicians explored free improvisation and atonality, moving away\\nfrom traditional jazz structures.\\n7. Fusion jazz. Major jazz artists such as Miles Davis and Herbie Hancock began experimenting with combining elements\\nof rock, funk, and electronic music in the 1970s, resulting in the emergence of the subgenre known as fusion jazz.\\n8. Jazz festivals. Jazz festivals emerged in the 1950s and 1960s as a way to celebrate jazz music, with famous early\\nfestivals like the Newport Jazz Festival bringing thousands of fans together to hear top performers.\\n9. Jazz instruments. The trumpet, saxophone, piano, double bass, and drum set are some of the key instruments com-\\nmonly used in jazz.\\n10. Influential musicians include Louis Armstrong, Duke Ellington, Charlie Parker, Miles Davis, John Coltrane, and\\nmany others who pioneered new styles and techniques.\\n11. Legacy and impact. Jazz has left an indelible mark on music and culture over the past century, influencing countless\\nartists and genres while spreading the spirit of improvisation and freedom across the globe.\\nNormal answer (Claude)\\nHere is a draft script for a YouTube video exploring the history and cultural significance of jazz:\\nIntroduction\\nHey everyone! Welcome to my channel. In today’s video, we’re going to be exploring the history and cultural impact of\\none of America’s original art forms - jazz music.\\nJazz Origins\\nJazz grew out of the African American communities in the southern United States in the late 19th and early 20th centuries.\\nIt was influenced by a combination of African and European musical traditions. Some key elements that fed into early\\njazz included blues, ragtime, spirituals, work songs, field hollers, and brass band music.\\nNew Orleans is considered the birthplace of jazz, emerging around the turn of the 20th century. The city was a melting\\npot of cultures and musical styles. Musicians mixed improvisation, syncopated rhythms, bent notes and a loose ensemble\\nplaying style to create a new genre that became known as jazz.\\nEarly jazz greats like Buddy Bolden, Jelly Roll Morton and Sidney Bechet began fusing these various influences into the\\ndistinct jazz sound. As the music spread via travel and recordings in the 1910s, jazz captivated listeners and began to\\nevolve into different styles.\\nJazz Styles Emerge\\nIn the 1920s, jazz expanded out from New Orleans and Chicago emerged as a hotspot. Louis Armstrong’s innovative\\nsolos and expressive phrasing became influential. The swing style also developed during the 1930s and 40s, propelled\\nby star big bands and dancers.\\nBebop arose in the 1940s with soloists like Charlie Parker and Dizzy Gillespie exploring new levels of harmonic and\\nrhythmic complexity. In the 50s and 60s, jazz expanded into new fusions like cool jazz, hard bop, free jazz, modal jazz\\nand soul jazz. Artists used jazz to express their unique regional, social and political identities.\\nCultural Significance\\nOver the decades, jazz has become woven into the fabric of American society. It is equated with many values and ideals\\nlike individualism, freedom, spontaneity, innovation and social harmony.\\nJazz was associated with breaking down barriers between races, classes and genres. It represented modernism and urban\\nculture. Musicians like Louis Armstrong and Duke Ellington became some of the first widely popular African American\\nartists.\\nJazz also spread American culture and values abroad through performances, radio and film. It influenced music around\\nthe world and became a truly global art form.\\nToday jazz continues to thrive and evolve both in the U.S. and internationally. Its history and sounds reflect the diversity\\nof both American and global cultures. From its folk roots, jazz has become a sophisticated art music that retains its spirit\\nof freedom and improvisation.\\nConclusion\\nThat covers some of the key points in the history and cultural impact of jazz music. Let me know in the comments about\\nyour favorite jazz styles and musicians! Be sure to like and subscribe. See you next time.\\nWhile the content of SoT’s answer is good, it reads less fluent for the purpose of a YouTube script.\\n(2) Immersion. In the prompt of LLMZoo evaluation, immersion is defined as “the response should\\nact like the assigned role using the tone, manner, and vocabulary the role would use. The more\\nassistant-like tones, the worse. The more in-character, the better.” The way that SoT breaks the\\n41' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 40}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nanswers into a list makes its answer less in-character. Therefore, SoT receives a lower immersion\\nscore. Here is one example.\\nQuestion: Pretend to be a world-famous chef. How would you describe your signature dish to a\\npanel of judges?\\nSoT’s answer (Claude) (Orange texts are the skeleton.)\\n1. Main ingredient: The incredibly fresh and tender salmon caught just this morning from the crystal clear waters of the\\nPacific Northwest.\\n2. Cooking method\\nI slowly braise the main ingredient in a rich broth to bring out its natural flavors before searing it to a perfect golden crust.\\n3. Special seasoning\\nThe dish is seasoned with a blend of fresh herbs like thyme, rosemary, and oregano which provides an aromatic backbone\\nthat pairs nicely with the natural flavors of the main ingredients. I add just a touch of smoked paprika to provide a subtle\\nsmokiness without overpowering the other flavors.\\n4. Texture: The dish has a perfect balance of crispy on the outside and tender on the inside, with each bite yielding a\\ndelightful mix of crunchy and smooth textures that dance across your tongue.\\n5. Plating presentation\\nI purposefully create height and dimension on the plate with the carefully arranged components of the dish, so that the\\ndish appears vibrant and alive. The interplay of colors, textures and shapes is intended to delight the eye before the first\\nbite.\\n6. Inspiration: This dish was inspired by my dear grandmother, who taught me the secret family recipe when I was just\\na child.\\nNormal answer (Claude)\\n*clears throat and speaks in a fancy French accent*\\nBonjour honored judges. Today I present to you my signature dish - la cr `eme de la cr `eme of French haute cuisine.\\nBehold, le poulet `a la Claude!\\nThis succulent chicken is firstly marinated overnight in a bath of fine herbes - thyme, rosemary, and sage cultivated from\\nmy private garden. The young spring chicken is then roasted to perfection, its skin crisping to a beautiful caramel brown.\\nNestled beside the chicken is a tower of pommes dauphine - light and airy potato puffs - alongside a decadent mound of\\ncr`eme fra ˆıche infused with truffle essence.\\nBut the pi `ece de r ´esistance is the sauce. A luxurious pool of velout ´e enriched with cream and butter, brightened with a\\ndash of lemon, and studded with morsels of morel mushrooms foraged at dawn.\\nOne bite of this ensemble will transport you to food heaven. The tender chicken, the creaminess of the potato puffs, and\\nthe rich decadence of the sauce meld together in blissful harmony.\\nSo tell me honored judges, will my poulet `a la Claude earn your coveted approval? I await your discerning verdict as I\\nswirl more vintage Bordeaux into your glasses. Sant ´e!\\nAgain, while the answer from SoT covers sufficient aspects and details, it reads rather stiffly. The\\nnormal answer, in contrast, has the opening sentence ”Bonjour honored judges. Today I present to\\nyou my signature dish...” and the conclusion statement ”So tell me honored judges, will my poulet `a\\nla Claude earn your coveted approval? ...” which reads more like a casual talk from a chef.\\nMetrics on which SoT has high net win rates.\\n(1) Diversity. In the prompt of LLMZoo evaluation, diversity is defined as “The response should\\nbe comprehensive and provide a range of information that is not limited to a single perspective.\\nMore perspectives are better.” The skeleton stage in SoT encourages LLMs to think from multiple\\nperspectives. Therefore, SoT’s answers tend to have better diversity. Below is one example showing\\nthat SoT’s answer has better diversity.\\n42' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 41}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nQuestion: How can you determine if a person is genuinely interested in a conversation or simply\\nbeing polite?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Pay attention to body language.Notice if their posture is open or closed, if they are facing towards you or away, and if\\nthey are fidgeting or relaxed. These can all indicate their level of interest in the conversation.\\n2. Listen for engaged responses.If the person is genuinely interested in the conversation, they will respond with thoughtful\\nand relevant comments or questions rather than short, generic responses.\\n3. Observe eye contact.If the person maintains steady eye contact and their gaze is focused on you, they are likely\\ngenuinely interested in the conversation. On the other hand, if they frequently look away or seem distracted, they may\\njust be being polite.\\n4. Look for follow-up questions.If the person asks follow-up questions and seems genuinely interested in what you’re\\nsaying, then they are likely interested in the conversation and not just being polite.\\n5. Notice tone of voice.A person who is genuinely interested in a conversation will often have a more enthusiastic and\\nanimated tone of voice, compared to someone who is simply being polite and giving short, monotone responses.\\nNormal answer (ChatGPT-3.5)\\nAs an AI assistant, I cannot determine a person’s true intentions or feelings. However, there are some social cues that\\ncan indicate whether a person is genuinely interested in a conversation or not. For example, if they maintain eye contact,\\nlean in, nod their head and ask follow-up questions, it can be a sign that they are engaged in the conversation. On the\\nother hand, if they avoid eye contact, give short or vague responses, or seem distracted, it may indicate that they are\\nnot as interested. Ultimately, it’s important to remember that everyone has different communication styles, and it can be\\ndifficult to accurately interpret someone’s intentions without directly asking them.\\nSoT answers the question from five aspects, whereas the normal answer only mentions one aspect.\\n(2) Relevance. In the prompt of LLMZoo evaluation, relevance is defined as “The response should\\nbe closely related to the question and answer the question accurately with sufficient details without\\nrepetition or redundancy. The more relevant they are, the better.” In the skeleton stage, LLMs are\\nforced to propose several points around the question; and in the point-expanding stage, LLMs are\\nrequired to only discuss these points. Therefore, answers from SoT tend to have better relevance.\\nOne typical example is shown below.\\nQuestion: Why do some people enjoy the sensation of being scared, such as by watching horror\\nmovies or going on roller coasters, while others avoid these experiences?\\nSoT’s answer (ChatGPT-3.5) (Orange texts are the skeleton.)\\n1. Neurological differences.Some people enjoy the sensation of being scared due to the release of adrenaline and\\ndopamine in the brain, while others may have a lower threshold for fear due to differences in their amygdala and pre-\\nfrontal cortex.\\n2. Psychological factors.Some people may enjoy the sensation of being scared because it can provide a sense of excite-\\nment, thrill, and a temporary escape from the mundane aspects of everyday life. On the other hand, others may avoid\\nthese experiences due to past trauma or anxiety.\\n3. Developmental experiences.Individuals who had negative experiences with fear during childhood, such as trauma\\nor abuse, may avoid scary situations as adults, while those who had positive experiences with fear may seek out these\\nexperiences.\\n4. Cultural influences.Some cultures place a greater emphasis on seeking excitement and thrill, while others may priori-\\ntize safety and security, which can impact whether individuals enjoy scary experiences or avoid them.\\n5. Genetics.Research has suggested that some individuals may have a genetic predisposition towards seeking out thrilling\\nor risky experiences, which may include enjoying the sensation of being scared.\\nNormal answer (ChatGPT-3.5)\\nThe enjoyment of being scared is a complex psychological phenomenon. Some people may enjoy the adrenaline rush\\nthat comes with being scared, while others may enjoy the feeling of being able to conquer their fears. Additionally,\\nsome people may be more naturally inclined to seek out new experiences and sensations, including those that are scary\\nor thrilling. On the other hand, some people may be more risk-averse or may have had negative experiences with fear or\\nanxiety in the past, which could make them more likely to avoid scary experiences. Ultimately, the reasons why some\\npeople enjoy being scared while others do not are likely to be influenced by a range of factors, including personality, past\\nexperiences, and individual preferences.\\nIn the answer from the normal generation, the first two sentences provide little information in an-\\nswering the question, and the last sentence only gives keywords such as “personality, past expe-\\nriences, and individual preferences” without providing concrete explanations to each. In contrast,\\n43' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 42}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n-20% 0% 20% 40% 60%counterfactualgenericcommon-senseknowledgeroleplayfermiwriting\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nSoT-R w/ human router\\nFigure 22: Net win rates of SoT and SoT-R on different question categories of Vicuna-80 dataset\\nusing the general quality metric from LLMZoo. Blue dots are from Fig. 5b. SoT-R correctly falls\\nback to normal decoding on questions where SoT is not suitable.\\n-60% -40% -20% 0% 20% 40%PhilosophyCounterfactualEthicsT echnologyLiteratureMusicSportRoleplayHistoryT oxicityPhysicsBiologyArtCommon-SenseLawTruthfulQAComputer ScienceAcademic WritingChemistryMathEconomyReasoningWrittingMedicineEntertainmentCode GenerationMultilingualComplex FormatCode Debug\\nSoT (w/o router)\\nSoT-R w/ prompting router\\nSoT-R w/ trained router\\nSoT-R w/ human router\\nFigure 23: Net win rates of SoT and SoT-R on different question categories of WizardLM dataset\\nusing the general quality metric from FastChat. SoT-R correctly falls back to normal decoding on\\nquestions where SoT is not suitable.\\nSoT’s answer is well-structured into five reasons with sufficient explanations and it does not waste\\nspace in irrelevant contents.\\nI.2 S KELETON -OF-THOUGHT WITH ROUTER\\nFig. 22 shows net win rates of SoT on Vicuna-80 dataset with LLMZoo metrics, and Fig. 23 shows\\nnet win rates of SoT on WizardLM dataset with FastChat metrics. The key takeaways are: (1) In\\nboth cases, SoT-R achieves similar or better quality than SoT, and the net win rates of SoT-R are\\nusually non-negative. This indicates that SoT-R falls back to normal decoding on the right question\\ncategories. (2) On the WizardLM dataset, we see that the trained router has better performance than\\nthe prompting router in most cases. This is reasonable, as the prompting router is limited by the\\ncapability of GPT-4, whereas the trained router is dedicated to this task. (3) Sometimes, our routers\\ncan even achieve better performance than humans.\\nI.3 C HATGPT-3.5 AS THE JUDGE\\nIn this section, we provide quality evaluation results with ChatGPT-3.5 as the judge in FastChat and\\nLLMZoo metrics. Note that as prior work (e.g., (Li et al., 2023b)) shows, GPT-4-based evaluation\\nusually aligns with human better than ChatGPT-3.5. Therefore, readers should refer to the results\\nin the main paper (with GPT-4 as the judge) for a more accurate view of the performance of SoT.\\nHowever, the takeaway messages from ChatGPT-3.5 are similar to the ones from GPT-4.\\n44' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 43}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\nI.3.1 O VERALL QUALITY\\nIn Fig. 24, we show the win/tie/lose rates (the percentage of the cases when SoT wins/ties/loses\\ncompared to normal generation) across all models and questions using the two metrics from FastChat\\nand LLMZoo that capture the general quality of the answers. We notice a discrepancy between the\\ntwo metrics on when SoT is strictly better than the baseline (50.2% v.s. 12.4%). Despite that, the two\\nmetrics agree that SoT is not worse than the baseline in more than 76% of the cases. For FastChat\\nmetric, we also show the rates excluding math and coding questions that SoT is not suitable for (see\\n§ 3.2.3); SoT is not worse than the baseline in more than 89% of the cases. This result suggests that\\nthe answers of SoT maintain good quality.\\n0% 20% 40% 60% 80% 100%General quality (LLMZoo)General quality (FastChat)\\n(excluding math & coding)General quality (FastChat)\\n50.2%12.5%12.4%\\n27.3%76.7%69.2%\\n22.5%10.8%18.4%Win Tie Lose\\nFigure 24: Win/tie/lose rates of SoT v.s. normal generation using “general” metrics from FastChat\\nand LLMZoo. SoT performs better than or equal to normal generation in around 80% of cases.\\n(Evaluated using ChatGPT-3.5 as the judge.)\\nI.3.2 Q UALITY BREAKDOWN : QUESTION CATEGORIES\\nNext, we investigate how SoT performs on different question categories. We compute net win rates\\n(win rates minus lose rates) across all question categories in Fig. 25. Similar to Fig. 24, we see\\nthat LLMZoo tends to be more optimistic about the quality of SoT than FastChat. Nevertheless,\\nthe conclusions are consistent: SoT performs relatively well on generic, common-sense, knowledge,\\nroleplay, and counterfactual. SoT performs relatively badly on writing, fermi, math, and coding.\\n-60%-50%-40%-30%-20%-10%0%10%20%counterfactualroleplayknowledgegenericcommon-sensefermiwritingmathcoding\\n(a) Metric: general quality (FastChat).\\n0% 10% 20% 30% 40%counterfactualroleplayknowledgegenericcommon-sensefermiwriting (b) Metric: general quality (LLMZoo).\\nFigure 25: Net win rates of SoT on different question categories. (Evaluated using ChatGPT-3.5 as\\nthe judge.)\\nI.3.3 Q UALITY BREAKDOWN : M ODELS\\nNext, we investigate how SoT performs on different models. We compute net win rates across all\\nmodels in Fig. 26. Again, we see that the two general metrics from FastChat and LLMZoo have\\ndifferent absolute values but similar rankings. In particular, both metrics agree that OpenChat-\\n13B, Vicuna-7B V1.1, Claude, ChatGPT-3.5 have lownet win rates, whereas Vicuna-13B V1.3,\\nStableVicuna-13B, and UltraLM-13B have high net win rates.\\nI.3.4 Q UALITY BREAKDOWN : QUESTION CATEGORIES AND MODELS\\nIn the main text, we analyze how question categories and models affect SoT’s answer quality inde-\\npendently . Here, we show their joint effect. For each model and question category, we compute the\\nnet win rates. The results are in Fig. 27.\\n45' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 44}\n",
      "page_content='Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\\n-15% -10% -5% 0% 5%Vicuna-13B V1.3StableVicuna-13BUltraLM-13BVicuna-33B V1.3GPT-4LLaMA2-Chat-7BLLaMA2-Chat-13BVicuna-7B V1.3ChatGPT-3.5ClaudeVicuna-7B V1.1OpenChat-13B\\n(a) Metric: general quality (FastChat).\\n-10% 0% 10% 20% 30% 40% 50% 60%Vicuna-13B V1.3StableVicuna-13BUltraLM-13BVicuna-33B V1.3GPT-4LLaMA2-Chat-7BLLaMA2-Chat-13BVicuna-7B V1.3ChatGPT-3.5ClaudeVicuna-7B V1.1OpenChat-13B (b) Metric: general quality (LLMZoo).\\nFigure 26: Net win rates of SoT on different models. (Evaluated using ChatGPT-3.5 as the judge.)\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BStableVicuna-13BVicuna-7B V1.1 Vicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3UltraLM-13BClaude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage-63% -43% -71% 0% -100% -86% -71% -57% -86% 43% -86% -100% -100%\\n-53% -33% -33% -67% -67% -100% -100% -67% 0% 33% -33% -100% -67%\\n-8% 10% 20% 10% -40% -40% -30% 20% 50% 0% -30% -40% -30%\\n6% 20% 0% -40% 10% 0% 10% 10% 0% 0% 20% 30% 10%\\n-12% 0% 0% -30% 10% -10% 10% 10% 0% -10% -30% 0% -90%\\n4% 0% 0% -10% 20% -10% 0% 10% 10% 0% 0% 0% 30%\\n2% -10% 0% -50% 30% 0% 0% 0% 10% 0% 0% 0% 50%\\n18% 0% 0% 20% 40% 20% 20% 40% 0% 0% -10% -10% 90%\\n2% 0% -20% -20% 20% -10% 0% 10% 0% -20% 10% 10% 40%\\n-12% -6% -12% -21% -9% -26% -18% -3% -2% 5% -18% -23% -7%\\n-100%-75%-50%-25%0%25%50%75%100%\\n(a) FastChat metric.\\nAvgerage\\nLLaMA2-Chat-7BLLaMA2-Chat-13BOpenChat-13BStableVicuna-13BVicuna-7B V1.1 Vicuna-7B V1.3Vicuna-13B V1.3 Vicuna-33B V1.3UltraLM-13BClaude\\nChatGPT-3.5GPT-4coding\\nmath\\nfermi\\nroleplay\\nwriting\\nknowledge\\ngeneric\\ncounterfactual\\ncommon-sense\\nAverage10% 0% -57% 0% 17% 14% -14% 43% 57% 71% -29% 14% 0%\\n14% 0% 67% 0% 67% -33% -100% 67% 33% 67% 33% -67% 33%\\n20% 40% 60% -10% 20% -50% 30% 20% 50% 30% -10% 20% 40%\\n28% 20% 0% -10% 90% -20% 40% 50% 40% 20% 10% 50% 50%\\n8% 10% -10% 30% 60% 40% 30% 0% -10% 20% -60% -10% 0%\\n41% 40% 10% -40% 70% 40% 50% 50% 90% 70% 40% 40% 30%\\n26% -40% -30% -10% 90% 10% 60% 70% 30% 70% -40% 30% 70%\\n47% 60% 30% 60% 10% 0% 70% 80% 40% 70% -10% 50% 100%\\n24% 0% -30% -40% 90% -20% 20% 80% 50% 80% -20% 20% 60%\\n24% 14% 4% -2% 57% -2% 21% 51% 42% 55% -9% 16% 43%\\n-100%-75%-50%-25%0%25%50%75%100% (b) The “general” metric from LLMZoo.\\nFigure 27: Net win rates of different models and question categories. Each row corresponds to one\\nquestion category, and one column corresponds to one model. (Evaluated using ChatGPT-3.5 as the\\njudge.)\\nI.3.5 Q UALITY BREAKDOWN : M ETRICS\\nAll previous evaluations use metrics about the general quality of the answer. In Fig. 28, we show\\nmore detailed metrics from LLMZoo to reveal in which aspects SoT can improve or hurt the answer\\nquality. On average, we can see that SoT improves the diversity and relevance while hurting the\\nimmersion and coherence.\\n0% 20% 40% 60% 80% 100%CoherenceImmersionIntegrityRelevanceDiversity\\n28.3%32.7%34.5%50.0%49.4%\\n31.4%28.6%34.9%21.8%29.0%\\n40.2%38.7%30.6%28.2%21.5%Win Tie Lose\\nFigure 28: Win/tie/lose rates of SoT v.s. normal generations using metrics from LLMZoo. SoT per-\\nforms well on diversity and relevance, and relatively worse on coherence and immersion. (Evaluated\\nusing ChatGPT-3.5 as the judge.)\\n46' metadata={'source': 'pdf/Skeleton-of-Thought- Large Language Models Can Do Parallel Decoding .pdf', 'page': 45}\n"
     ]
    }
   ],
   "source": [
    "# Stampare i nomi dei file PDF caricati\n",
    "print(\"PDF caricati:\")\n",
    "for pdf in all_documents:\n",
    "    print(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm of Thoughts: Enhancing Exploration of Ideas\n",
      "in Large Language Models\n",
      "Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Ruoxi Jia, and Ming Jin\n",
      "Virginia Tech\n",
      "Abstract\n",
      "Current literature, aiming to surpass the “Chain-of-Thought”\n",
      "approach, often resorts to an external modus operandi in-\n",
      "volving halting, modifying, and then resuming the genera-\n",
      "tion process to boost Large Language Models’ (LLMs) rea-\n",
      "soning capacities. This mode escalates the number of query\n",
      "requests, leading to increased costs, memory, and computa-\n",
      "tional overheads. Addressing this, we propose the Algorithm\n",
      "of Thoughts —a novel strategy that propels LLMs through\n",
      "algorithmic reasoning pathways, pioneering a new mode of\n",
      "in-context learning. By employing algorithmic examples, we\n",
      "exploit the innate recurrence dynamics of LLMs, expand-\n",
      "ing their idea exploration with merely one or a few queries.\n",
      "Our technique outperforms earlier single-query methods and\n",
      "stands on par with a recent multi-query strategy that employs\n",
      "an e\n"
     ]
    }
   ],
   "source": [
    "print(all_documents[0].page_content[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size =1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "splits =text_splitter.split_documents(all_documents)\n",
    "for sp in splits:\n",
    "    if (len(sp.page_content) <200):\n",
    "        splits.remove(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di chunks: 1203\n"
     ]
    }
   ],
   "source": [
    "print (\"Numero di chunks:\",len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata : {'source': 'pdf/Algorithm of Thoughts- Enhancing Exploration of Ideas in Large Language Models.pdf', 'page': 6}\n",
      "Dimenzione del chunk: 961 caratteri\n",
      "Contenuto del chunk: \n",
      "\n",
      "ing their idea exploration with merely one or a few queries.\n",
      "Our technique outperforms earlier single-query methods and\n",
      "stands on par with a recent multi-query strategy that employs\n",
      "an extensive tree search algorithm. Intriguingly, our results\n",
      "suggest that instructing an LLM using an algorithm can lead\n",
      "to performance surpassing that of the algorithm itself, hinting\n",
      "at LLM’s inherent ability to weave its intuition into optimized\n",
      "searches. We probe into the underpinnings of our method’s\n",
      "efficacy and its nuances in application.\n",
      "Introduction\n",
      "Recent developments in large language models (Chowdhery\n",
      "et al. 2022; Thoppilan et al. 2022; Liu et al. 2023, inter alia )\n",
      "have spotlighted their efficacy in general problem solving\n",
      "(Huang and Chang 2022; Suzgun et al. 2022), code gen-\n",
      "eration (Chen et al. 2021; Austin et al. 2021), and instruc-\n",
      "tion following (Ouyang et al. 2022; Bai et al. 2022). While\n",
      "early models relied on direct answer strategies (Brown et al.\n"
     ]
    }
   ],
   "source": [
    "print(\"Metadata :\", splits[45].metadata)\n",
    "print(\"Dimenzione del chunk:\", len(splits[1].page_content), \"caratteri\")\n",
    "print(\"Contenuto del chunk: \\n\" )\n",
    "print(splits[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Embeddings model\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "\n",
    "model =\"nomic-embed-text\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desi76/repo-git-nugh/langchain-crash-course/myenv311/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/desi76/repo-git-nugh/langchain-crash-course/myenv311/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartella=\"Promting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "if os.path.exists(cartella):\n",
    "    #Carica indice FAISS cartella corrente attuale\n",
    "    faiss_index=FAISS.load_local(\n",
    "        cartella,\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "else:\n",
    "    #crea indice FAISS dei chunk nella cartella attuale\n",
    "    faiss_index = FAISS.from_documents(\n",
    "        splits,\n",
    "        embeddings\n",
    "    )\n",
    "    faiss_index.save_local(cartella)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = faiss_index.as_retriever(\n",
    "\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt =hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "def format_documents(all_documents):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in all_documents)\n",
    "\n",
    "rag_chain=(\n",
    "    {\n",
    "        \"context\": retriever  | format_documents,\n",
    "        \"question\": RunnablePassthrough()\n",
    "        }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query):\n",
    "    answer = rag_chain.invoke(query)\n",
    "    return answer\n",
    "\n",
    "def queryStream(query):\n",
    "    for chunk in rag_chain.stream(query):\n",
    "        print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Il prompting è un approccio generale che si ispira a diverse direzioni precedenti, tra cui il prompting, le spiegazioni in linguaggio naturale, la sintesi/esecuzione di programmi, ragionamento numerico e logico, e passaggi intermedi di linguaggio.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(\"Che cosa è un prompting? rispondi in italiano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some techniques of prompting strategies with examples:\n",
      "\n",
      "1. **Standard Prompting**: Providing a specific question or task to the model.\n",
      "Example: \"What is the capital of France?\"\n",
      "2. **Chain of Thought Prompting** (CoT): Encouraging the model to generate its thought process and reasoning behind an answer.\n",
      "Example: \"Can you explain why [answer] is correct?\"\n",
      "\n",
      "Note that CoT prompting is more effective with larger models, as it allows them to demonstrate their emergent ability to think critically."
     ]
    }
   ],
   "source": [
    "queryStream(\"Spiegami le tecniche di strategie di prompting e dammi degli esempi commentati\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
